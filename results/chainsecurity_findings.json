[
    {
        "title": "6.1   Missing Sanity Check of Chainlink Oracle",
        "body": " Price  Options smart contract calculates the required ETH price by querying a YFi/ETH ChainLink oracle and the curve oracle. Apart from the price of the YFi tokens, the oracle returns information about the point in time when its price was updated. However, this information is ignored by the current implementation. The stale prices might be used for estimations.    A check that the update time of the price oracle complies with the ChainLink heartbeat parameter for the YFI/ETH pool (24 hours or 86400 seconds) was added.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Not Initialized Variables",
        "body": "  On multiple occasions, some state variables are used which are never set and there are no functions that can update them. In particular:  In  Options.exercise,  ETH  is  sent  to  self.payee.  However,  this  variable  is  never  set. Hence, ETH will be sent to 0x0 address.  In  Gauge._getReward,  the  recipients  mapping  is  read.  However,  this  mapping  is  never written, thus the recipient[account] will always be 0x0. This means, that no other recipient than the owner of the Gauge tokens can receive the rewards.  Yearn - oYfi -   11  CriticalHighMediumCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedDesignMediumVersion1CodeCorrectedDesignMediumVersion1CodeCorrected                  \f   The  Options.payee  is  set  to  the  owner  in  the  constructor.  In  addition,  set_payee  function,  restricted to the owner, was added. It can change this field.   The Gauge.setRecipient function was added. It allows users to set the recipients mapping.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Divisions Before Multiplications",
        "body": "  In  the  implementation  in  the  scope,  there  are  multiple  instances  where  divisions  happen  before multiplications.  Such  sequences  of  operations  yield  less  precise  results.  In  particular,  the  following expressions can be rearranged:  In Options._eth_required,  amount * eth_per_yfi / PRICE_DENOMINATOR * discount / DISCOUNT_NUMERATOR  In Gauge._boostedBalanceOf,  ((_realBalance * BOOSTING_FACTOR) +     (((totalSupply() * IVotingYFI(VEYFI).balanceOf(_account)) /         veTotalSupply) *         (BOOST_DENOMINATOR - BOOSTING_FACTOR))) /     BOOST_DENOMINATOR,  Code partially corrected:   The Options._eth_required does the multiplications first and only then the divisions.   The  Gauge._boostedBalanceOf  is  left  unchanged.  This  numerical  imprecision  won't  affect  the functionality of the contract. No \"dust\" will be accumulated due to this because the penalty is defined in a way, that will sweep the leftover dust.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Sweeping Non-ERC20-Compatible Tokens",
        "body": "  Options.sweep allows any user to transfer any ERC20 compatible tokens owned by the contract to its owner. However, this call will fail for tokens that are not compliant with the ERC20 standard. The most prominent example is the USDT. USDT's transfer does not return any value in contrast to the ERC20 standard.  This  means  that  transfer  call  will  fail.  In  Solidity,  this  issue  is  tackled  with  the safeTransfer call (see Openzeppelin's safeERC20).    The default_return_value=True parameter was added in the Options.sweep token transfer call, that enables safeTransfer functionality in Vyper smart contracts.  Yearn - oYfi -   12  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                  \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   EIP-4626 Event Field Names",
        "body": "  Event  Deposit  and  event  Withdrawal  in  IERC4626  are  defined  with  address  indexed  caller. According  to  the  https://eips.ethereum.org/EIPS/eip-4626#events,  these  fields  should  be  named  as sender.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Full YFI Locked Discount Reverts",
        "body": "  In  the  case  of  the  quite  improbable  event,  when  the  total  supply  of  Yfi  is  locked  in  veYfi,  the  discount cannot be computed.  DISCOUNT_TABLE[total_locked * DISCOUNT_GRANULARITY / total_supply]  The DISCOUNT_TABLE has 500 elements. However, the max index is 499. This index access during the computation will revert, if total_locked == total_supply, because the element with index 500 is not present in the DISCOUNT_TABLE.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Incorrect Documentation",
        "body": "  In OYfiRewardPool.burn, the documentation reads as follows:  @notice Receive YFI into the contract and trigger a token checkpoint  The documentation is incorrect as OYFI is transferred instead of YFI.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   Missing Indices in Events",
        "body": "  For some events, some arguments are not indexed even if this would make sense. In particular:  In Options.Sweep, the token argument could be indexed.  In Gauge.BoostedBalanceUpdated, the account argument could be indexed.  Yearn - oYfi -   13  InformationalVersion1InformationalVersion1InformationalVersion1InformationalVersion1                  \f7.5   Non-informative Error Message  BaseGauge.queueNewRewards  checks  whether  the  _amount  argument  is  non  0.  Should  this  check fail,  the  non-informative  ==0  message  will  be  returned.  Note  that  Solidity  0.8  allows  for  error  values instead of just strings to be returned upon check failure.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.6   Redundant Function Modifiers",
        "body": "  Multiple functions are defined using a public modifier, while they are not called within the contract. These functions could be set as external instead:   Gauge.convertToShares   Gauge.convertToAssets   Gauge.maxDeposit   Gauge.previewDeposit   Gauge.maxMint   Gauge.previewMint   Gauge.kick  Solidity  compiler  needs  to  perform  extra  routines  for  public  functions,  which  can  result  in  higher  gas usage.  Yearn - oYfi -   14  InformationalVersion1InformationalVersion1      \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Gauge Assumed Decimals",
        "body": "  The  Gauge  contract  uses  default  18  decimals.  However,  the  asset  can  have  a  different  number  of decimals. While the Yearn vault tokens have 18 decimals, this might not be true for any asset that might be used in Gauge. If an asset with a different number of decimals is introduced, the respective Gauge will misbehave.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Manipulation of Curve Oracle",
        "body": "  Options  calculates  the  price  of  YFI/ETH  by  querying  the  price  oracle  of  the  respective  Curve-pool. Curve  uses  a  time  weighted  price  oracle  or  (TWAP-oracle).  TWAP  oracles  have  been  shown  to  be manipulatable to an extent. Users should be aware that the system in scope does not perform any further sanity checks on the correctness of the reported price.  Yearn - oYfi -   15  NoteVersion1NoteVersion1      \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Outdated Interfaces",
        "body": "  The  zkSync  interfaces  for  L2Log  and  L2Message  have  been  updated  and  the  ones  used  in  the  DAI bridge current codebase are deprecated. The malformed L2 logs or messages would block any attempt of withdrawal or claim of a failed deposit.    The structs used correspond now to the most recent version of the zkSync 2.0 structs.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Refund Recipient Is Not Aliased",
        "body": "  On ZkSync the contract addresses are aliased using the AddressAliasHelper.applyL1ToL2Alias function,  to  distinguish  between  L1  and  L2  initiated  transactions.  However,  the  refund  recipient  in  the Mailbox.requestL2Transaction  call  in  the  L1DAITokenBridge  contract  doesn't  alias  the msg.sender address, even if it is a contract address.    Refund recipient address is aliased if the msg.sender is a contract.  MakerDAO - zkSync DAI Bridge -   12  CriticalCodeCorrectedHighMediumCodeCorrectedCodeCorrectedLowCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCorrectnessCriticalVersion1CodeCorrectedDesignMediumVersion5CodeCorrected                 \f6.3   Critical Tests Missing  Some critical tests are missing in the test suite, for example, the e2e test for claiming a failed deposit is incomplete.    After  Matter  Labs  provided  the  necessary  sdk  functions  to  generate  the  proof  required  by claimFailedDeposit a test case was added.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Inconsistent Use of Interfaces",
        "body": "  When L1DAITokenBridge calls finalizeDeposit, it uses the L2DAITokenBridgeLike interface. The L2DAITokenBridge implements IL2Bridge, but IL2Bridge and L2DAITokenBridgeLike are not connected.    MakerDAO  uses  the  IL2Bridge  interface  now  and  has  removed  the  L2DAITokenBridgeLike interface.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Lack of Documentation",
        "body": "  The  main  functionality  is  sufficiently  documented.  However,  the  interaction  with  zkSync  2.0  remains undocumented.  This  is  of  high  importance  as  zkSync  2.0's  documentation  is  incomplete.  Furthermore, the emergency shutdown process remains undocumented.  Specification changed:  Natspec documentation was added.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Remaining TODO in the Source Code",
        "body": "  There is a leftover TODO comment in the code of L1DAITokenBridge.    The TODO was removed.  MakerDAO - zkSync DAI Bridge -   13  DesignMediumVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1Speci\ufb01cationChangedDesignLowVersion1CodeCorrected                                \f6.7   Unused enum  There is an unused QueueType enum in the file L1GovernanceRelay.sol.    MakerDAO has removed the unused enum.  MakerDAO - zkSync DAI Bridge -   14  DesignLowVersion1CodeCorrected        \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   zksolc Not Up-To-Date",
        "body": "  The version of the compiler that currently used is 1.3.3, at the time of writing the latest compiler version is 1.3.5.  MakerDAO - zkSync DAI Bridge -   15  InformationalVersion1  \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Contract Address Aliasing Maps to",
        "body": " Non-Operational Addresses  The contract deployment processes are different on zkSync and Ethereum mainnet, this discrepancy has as an effect that two similar contracts deployed by the account will not have the same address on L1 and L2, even considering address aliasing.  The  L1DAITokenBridge  specifies  the  msg.sender  (or  it's  alias  for  smart  contracts)  as  the  refund recipient.  The contracts that plan to use the L1DAITokenBridge need to be able to access the refunded funds. While the refunded funds will be credited on L2, the L1 contracts should be able to call zkSync bridges to spend those funds.  MakerDAO - zkSync DAI Bridge -   16  NoteVersion6  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Slashing Can Be Avoided",
        "body": "  CS-SUL12-002  The smart contract layer does not immediately know when a slashing event on the Consensus Layer has happened. Offchain, however, it is easy to immediately know when a validator has been slashed.  A user of an enzyme vault that uses one of the staking external positions could monitor for slashings and immediately  withdraw  from  the  vault  when  such  an  event  happens.  By  doing  this,  they  will  be  able  to redeem their assets (up to the available liquidity) at the pre-slashing price.  Once the slashing is accounted for in the vault (after about 12 hours in Stakewise), the slashing loss of the users that withdrew previously will instead be taken by those users that are still deposited in the vault.  Also,  note  that  the  same  behaviour  is  present  in  Stakewise's  vaults.  There,  any  user  can  withdraw immediately  up  to  the  available  liquidity  and  also  dodge  slashing.  However,  it  is  expected  that  the available  liquidity  in  Stakewise  vaults  should  never  be  more  than  32  ETH,  as  otherwise,  it  would  have been possible to stake them with an additional validator.  Risk accepted:  Avantgarde Finance acknowledged the issue and replied:  Since consensus layer slashing is not readable directly from the execution layer, slashing can only be made known by posting to the execution layer, and there will always be an opportunity to front-run posting (the same goes for Chainlink aggregators).  Fund managers must be aware of this risk and take any necessary precautions to mitigate the risk where needed, e.g., via policies and/or queued redemptions.  Avantgarde Finance - Sulu Extensions XII -   9  DesignCriticalHighMediumRiskAcceptedLowRiskAcceptedDesignMediumVersion1RiskAccepted           \f5.2   StakeWise Deposit May Revert  The following is an excerpt from the StakeWise documentation:  When keeper.canHarvest(<vault address>) returns false, the user can stake ETH to the vault without a state update. Otherwise, the updateStateAndDeposit function must be used.  The  enzyme  external  position  only  uses  deposit(),  not  updateStateAndDeposit().  If  a  state update is required, the manager currently needs to call updateState() from a separate address and then deposit() through the vault. Otherwise, deposit() reverts.  The same issue also applies to redeem().  CS-SUL12-003  Risk accepted:  Avantgarde Finance replied:  For now, managers can wait until a non-harvestable (i.e., depositable) moment. At a later time, we may update this or include a link/button to call `updateState()` directly.  Avantgarde Finance - Sulu Extensions XII -   10  DesignLowVersion1RiskAccepted        \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings  -Severity Findings   StakeWise V3 Position Ticket Valuation   0  0  0  1  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   StakeWise V3 Position Ticket Valuation",
        "body": "  CS-SUL12-001  The  StakeWise  position's  value  is  the  sum  of  the  value  of  the  vault  tokens  held  and  the  value  of  the position tickets.  A  position  ticket's  withdrawal  value  is  determined  in  Stakewise's  calculateExitedAssets  function. This function does not use the current share price, it uses a checkpointed price which is set when the update happens that lets the contract know that a withdrawal is completed.  The external position uses the current exchange rate instead of the fixed exchange rate at the relevant state update.  As a result, a fund could be under- or overvalued.    The code has been changed. Tickets not exited yet are evaluated as previously. However, exited tickets are evaluated based on calculateExitedAssets() which returns the claimed amount.  Avantgarde Finance - Sulu Extensions XII -   11  CriticalHighMediumLowCodeCorrectedDesignLowVersion1CodeCorrected        \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Assessement of Finalized After Authed Action",
        "body": "  CS-CSC-001  In  ScribeOptimistic,  _afterAuthedAction()  will  be  called  after  every  change  to  the  parameters  to drop opPokeData if it's not yet finalized. The evaluation whether the optimistic poke is finalized is done using the possibly new value for opChallengePeriod however.  This has the following consequences:  In case the new challenge period is bigger, _afterAuthedAction will evaluate the finality based on  the  increased  challenge  period.  Consequently  an  already  finalized  opPokeData  becomes challengeable again and may be dropped.  In case the new challenge period is smaller, _afterAuthedAction will evaluate the finality based on  the  decreased  challenge  period.  Consequently  an  previously  un-finalized  opPokeData  will  be regarded finalized immediately.  Risk accepted:  Chronicle has accepted the risk of finality reevaluation and states:  The \"reevaluation of finality\" based on a possibly updated opChallengePeriod is accepted. We plan to update the challenge period in the beginning a few times to find \"the best\" reasonable value. Afterwards, we don't intend to update the challenge period anymore following a \"never stop a running system\" approach.  Chronicle - Scribe -   13  SecurityDesignCorrectnessCriticalHighMediumRiskAcceptedLowRiskAcceptedRiskAcceptedRiskAcceptedCorrectnessMediumVersion1RiskAccepted             \fFurthermore, the code has been adjusted that in case a finalized opPokeData is more recent than the _pokeData,  it  will  also  be  pushed  into  _pokeData  and  deleted.  This  avoids  resetting  the  challenge period for a finalized opPokeData. Chronicle states:  _afterAuthedAction has been updated to ensure the challenge period of an opPoke is not reset, which would decrease the possible update frequency via opPoke (). This is achieved via either moving _opPokeData to _pokeData storage if _opPokeData is finalized and newer than _pokeData, or deleting opPokeData otherwise.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Drop of opPoke if Authed Action Does Not",
        "body": " Update Anything  setOpChallengePeriod(),  setMaxChallengeReward(),  and  setBar()  will  always  call _afterAuthedAction() to drop unfinalized opPokeData, even if the updated parameter is the same as the old parameter.  CS-CSC-002  Risk accepted:  Chronicle states:  Skipping the afterAuthedAction in special cases changes the definition of the action, which is defined to be called after every authe'd configuration change.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   Lift Does Not Drop Unfinalized opPoke",
        "body": "  ScribeOptimistic generally drops unfinalized optimistic poke data after the update of parameters to avoid any issues connected to an unexpected change of the verification result.  _lift()  is  not  overridden  in  ScribeOptimistic  to  call  _afterAuthedAction()  which  drops  the unfinalized opPokeData. This may allow not yet but soon to be feeds to sign the price update.  CS-CSC-003  Assume Alice is not a member of the current feeds at t   and t   < t   < t  .  2 , Alice signs a price with other bar-1 feeds, and opPoke() it.  1  0  0   At t 0  At t 1  At t  2  , wards add Alice to the feeds.  pokeData becomes valid.  , one comes to challenge the opPokeData, the challenge fails (verification succeeds) and the  In  this  example,  Alice's  signed  data  successfully  passes  the  verification,  though  Alice  has  not  been authorized at t  , the time the price data was aggregated.  0  Risk accepted:  Chronicle states:  Chronicle - Scribe -   14  DesignLowVersion1RiskAcceptedCorrectnessLowVersion1RiskAccepted                \fThis is a valid issue from a theoretical point of view. However, practically we don't see any problems arising through this.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.4   Race of Feeds",
        "body": "  Given  the  gas  and  runtime  limitation,  bar  shouldn't  be  too  large,  whereas  there  could  be  254 (maxFeeds) feeds at most. In case feeds' amount is larger than bar, feeds may form different subsets and sign with different views of the current price. As the price update frequency is at most once per block (limited by the freshness check of the pokeData.age), there could be a race case among the feeds.  CS-CSC-004  Risk accepted:  Chronicle states:  The bar-to-feed ratio will be set conservatively, i.e. \"far more\" feeds than bar. While the relationship will always be that bar > #feeds/2 to ensure that only a consensus of >50% can advance the oracle to a new price, we want to have more feeds than bar to not risk downtime due to feeds being dropped.  The current configuration is: 22 feeds with a bar of 13.  Chronicle - Scribe -   15  SecurityLowVersion1RiskAccepted          \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings   Update Using Stale PokeData   -Severity Findings   Unreset opPokeData After Unsuccessful Challenge   -Severity Findings  Incorrect Formula in Docs   Indexed Fields of Event Poked   0  1  1  2  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Update Using Stale PokeData",
        "body": "  In  ScribeOptimistic  an  optimistic  poke  is  considered  finalized  after  the  challenge  period  elapsed.  If  the optimistic  poke  (opPokeData.age)  is  finalized  and  more  recent  than  the  last  stored  poke  data (pokeData.age), the pricefeed returns the optimistic value:  CS-CSC-011  function _currentPokeData() internal view returns (PokeData memory) {     // Load pokeData slots from storage.     PokeData memory pokeData = _pokeData;     PokeData memory opPokeData = _opPokeData;      // Decide whether _opPokeData is finalized.     bool opPokeDataFinalized =         opPokeData.age + opChallengePeriod <= uint32(block.timestamp);      // Decide and return current pokeData.     if (opPokeDataFinalized && opPokeData.age > pokeData.age) {         return opPokeData;     } else {         return pokeData;     } }  Scribe.poke(), the function to update the pricefeeds _pokeData, only checks whether the new value is more recent than the stored data. It does not check whether there is a more recent finalized optimistic poke:  // Revert if pokeData stale.  if (pokeData.age <= _pokeData.age) {  Chronicle - Scribe -   16  CriticalHighCodeCorrectedMediumCodeCorrectedLowSpeci\ufb01cationChangedCodeCorrectedCorrectnessHighVersion1CodeCorrected          \f     revert StaleMessage(pokeData.age, _pokeData.age);  }  This update is then stored with the current block.timestamp as age:  // Store pokeData's val in _pokeData storage and set its age to now. _pokeData.val = pokeData.val; _pokeData.age = uint32(block.timestamp);  Resulting a stale pokeData could be used to update the pricefeed.  This issue arises in the state (_opPokeDate: finalized, _pokeData: set-older or uninitialized)    _poke() has been marked as virtual in Scribe and overridden in ScribeOptimistic, where it checks the stored  _pokeData  and  the  recent  finalized  optimistic  poke  to  determine  the  most  recent  age.  Thus  it prevents a stale pokeData to update the pricefeed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Unreset opPokeData After Unsuccessful",
        "body": " Challenge  In  ScribeOptimistic,  in  an  unsuccessful  challenge  (successful  signature  verification),  opPokeData  is finalized  and  pushed  to  _pokeData.  _opPokeData  remains  unchanged  however.  This  will  block opPoke() even though the current opPokeData has been finalized until the challenge period is over.  CS-CSC-009  if (ok) {         // Decide whether _opPokeData stale already.         bool opPokeDataStale = opPokeData.age <= _pokeData.age;          // If _opPokeData not stale, finalize it by moving it to the         // _pokeData storage.         if (!opPokeDataStale) {             _pokeData = _opPokeData;         }          emit OpPokeChallengedUnsuccessfully(msg.sender); }    _opPokeData will be deleted in case it is verified successfully and is more fresh than the _pokeData. Thus, this finalized _opPokeData will not block a new opPoke() anymore.  Chronicle - Scribe -   17  DesignMediumVersion1CodeCorrected          \f6.3   Incorrect Formula in Docs  In docs/Schnorr.md, the formula of re-computing challenge in signature verification is incorrect compared to the ones in signing and in code implementation. The order of the last two parameters is wrong.  e = H(Px || Pp || Re || m) mod Q  CS-CSC-012  Specification changed:  The  signature  verification  formula  in  docs/Schnorr.md  has  been  corrected  to  align  with  the  signing formula and the code implementation.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Indexed Fields of Event Poked",
        "body": "  CS-CSC-008  /// @notice Emitted when oracle was successfully poked. /// @param caller The caller's address. /// @param val The value poked. /// @param age The age of the value poked. event Poked(address indexed caller, uint128 val, uint32 age);  Indexing fields in events allows to easily search for certain events. The val and age of the event above are not indexed. Indexing e.g. the age field would allow off chain observers to easily search for prices in the past.    The val and age of the event have been marked as indexed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Gas Optimizations",
        "body": "   getSignerIndexLength() could load the length by assembly.  In _verifySchnorrSignature(), lift(), and drop() the counter i inside of the for loop can be increased in an unchecked scope, as it is always bounded.  CS-CSC-010   There  is  no  amount  limitation  of  inputs  for  abi.encodePacked(),  thus  one  invocation  should and  constructPokeMessage()   parameters   pack   the   all   to   in   suffice  _constructOpPokeMessage().  In _verifySchnorrSignature(), loading a public key at an index can be abstracted into another internal function to decrease code duplication.  In _lift(), the require statement index <= maxFeeds can be moved into the if branch, as we only need to check the number of feeds when a new public key is added.  Chronicle - Scribe -   18  CorrectnessLowVersion1Speci\ufb01cationChangedDesignLowVersion1CodeCorrectedInformationalVersion1CodeCorrected                       \f The first condition check (opPokeDataFinalized) can be removed in _opPoke(), as the function  would already revert if it is false.  if (!opPokeDataFinalized) {     revert InChallengePeriod(); }  uint32 age = opPokeDataFinalized && opPokeData.age > _pokeData.age         ? opPokeData.age : _pokeData.age;  In LibSchnorr, the following line can be wrapped in an unchecked scope.  uint s = LibSecp256k1.Q() - mulmod(challenge, pubKey.x, LibSecp256k1.Q());  In addAffinePoint(), some intermediate results can be cached to avoid computing repeatedly. For example:  uint left = mulmod(addmod(z1, h, _P), addmod(z1, h, _P), _P);  uint v = mulmod(x1, mulmod(4, mulmod(h, h, _P), _P), _P);  uint j = mulmod(4, mulmod(h, mulmod(h, h, _P), _P), _P);  In  addition,  the  following  optimizations  only  work  if  the  external  view  functions  are  called  by  a  smart contract.  In feeds(), the for loop counter i can start from 1 as the public key at index 0 is an zero point. And i can be increased in an unchecked scope.  In feeds(uint index), the input index can be checked towards 0 for early revert. And the public key at a specific index is not loaded by assembly as before.    Code has been corrected to adopt some of the optimizations.  Chronicle - Scribe -   19      \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Authed and Tolled May Return Array With",
        "body": " Duplicates  authed() will return the existing wards addresses as an array. Upon rely() the address is inserted into the mapping and the array. Upon deny() the address is only reset in the mapping and not removed from  the  array.  Consequently,  in  case  an  address  is  added,  then  removed,  and  later  added  back, authed() will return an array that contains a duplicate of this address. The same applies to tolled().  CS-CSC-005  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Timestamp of PokeData Aggregation Equal to",
        "body": " Block.Timestamp  Scribe._poke()  rejects  PokeData  with  timestamps  in  the  future  but  accepts  PokeData  with block.timestamp.  CS-CSC-006  // Revert if pokeData from the future. if (pokeData.age > uint32(block.timestamp)) {     revert FutureMessage(pokeData.age, uint32(block.timestamp)); }  It's a theoretical observation only with no impact in practice, but aggregating the price data and updating the  data  on  chain  seems  infeasible.  In  practice  when  _poke()  is  executed  it  should  hold block.timestamp > pokeData.age or the aggregation of the price data off chain likely happened for a timestamp (slightly) in the future.  Acknowledged:  Chronicle has acknowledged this theoretical observation with no impact in practice.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Undropped schnorrData Commitment and",
        "body": " opFeedIndex  CS-CSC-007  Chronicle - Scribe -   20  InformationalVersion1InformationalVersion1AcknowledgedInformationalVersion1Acknowledged              \f_schnorrDataCommitment stores the schnorr data digest of an optimistically poked data, ensuring it will  be  challenged  by  the  same  schnorr  signature  later.  opFeedIndex  stores  the  feed  who  signs  to endorse  the  opPokeData  and  the  schnorr  signature.  Upon  a  successful  challenge,  these  variables  are not deleted consistently with the _opPokeData. However, as opPokeDataFinalized is computed by the following statement and opChallengePeriod is at most max(uint16), it would always be true after _opPokeData  is  deleted.  Consequently  double  challenging  an  already  dropped  _opPokeData  is  not possible.  bool opPokeDataFinalized =         opPokeData.age + opChallengePeriod <= uint32(block.timestamp);  Acknowledged:  Chronicle states:  You  are  correct  in  that  we  could  drop  the  schnorrDataCommitment  and  opFeed  Index.  However, doing  so  will  increase  the  costs  of  the  subsequent  opPoke  as  writing  to  zero-storage  is  more expensive than overwriting non-zero storage. Note furthermore, that the gas-stipend for emptying the storage is attributed to the opChallenge caller, i.e. a searcher.  Therefore, cleaning the storage would practically give external entities a gas stipend that relays have to pay during the next opPoke().  Chronicle - Scribe -   21  \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Considerations of pokeData.age",
        "body": "  pokeData.age is interpreted differently at different stages.   User submitted pokeData.age: it refers to the time it is generated offchain for freshness check and  signature verification.   Onchain stored pokeData.age: it refers to the time the offchain generated data is poked or opPoked  onchain.  In ScribeOptimistic, there could be a potential delay to read the most recent valid opPokeData.age, as it only takes effect after being finalized.  In addition, systems integrate the ScribeOptimistic should aware that an old pokeData could be carried over to the current time (by updating the age to current block.timestamp) in following cases:   A  successful  challenge  (a  failed  verification)  will  drop  the  current  opPokeData  and  advance  the  existing _pokeData.age to current block.timestamp.   An  update  of  the  oracle  parameters  (setBar(),  setOpChallengePeriod(),  drop())  by  the  wards will always advance the valid most fresh pokeData.age to current block.timestamp.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Decimals of Price Feed",
        "body": "  Scribe oracles use 18 decimals for price values. Besides implementing own interfaces to read the price, the  Chainlink  interface  is  implemented  to  serve  potential  customer  already  integrating  with  Chainlink. Note  that  Chainlink  usually  uses  18  decimals  for  ETH  denominated  assets  but  8  decimals  for  USD denominated assets. Hence projects need to be careful especially when switching from Chainlink USD based pricefeeds to Scribe.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.3   Implications Regarding the Value of Bar",
        "body": "  setBar()  incorporates  a  check  to  restrict  the  bar  value  from  being  set  to  zero.  However,  the  upper boundary is only limited by the uint8 datatype, which is 255.   The  system  can  accommodate  a  maximum  of  254  feeds  (assuming  no  feed  is  ever  removed).  Therefore, if the bar is set to 255, the processing of any poke becomes unfeasible.   Once the bar value crosses a certain threshold, verifying the aggregated signature may surpass the  block gas limit, thereby rendering on-chain verification impossible.   Dropping  feeds  (e.g.  directly  or  in  ScribeOptimistic  after  a  successful  challenge)  may  result  in  the  number of feeds remaining being insufficient to cover bar.  The privileged role is expected to set the value for bar correctly.  Chronicle - Scribe -   22  NoteVersion1NoteVersion1NoteVersion1          \f8.4   Max 254 Feeds Over the Contracts Lifetime  By design, a Scribe Pricefeed can have a maximum of 254 feeds added: Adding a new pricefeed pushes the public key into the _pubKeys array. Removing a price feed resets the pricefeeds public key entry to the  zero  point,  however  this  does  not  free  up  the  space.  Feeds  IDs  are  hence  never  reused  but  the tradeoff is the maximum number of possible feeds that can be added.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.5   Penalty to Rogue Feeds",
        "body": "  If  a  feed  endorses  an  invalid  schnorrData  /  pokeData  combination  in  ScribeOptimistic,  the  feed  will  be dropped when challenged. In addition to dropping the feed, there is no more penalty to the feeds on the contract level.  Chronicle states:  Any kind of penalty regarding misbehaving feeds will be handled on the social layer.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.6   Price Change",
        "body": "  Systems  that  integrate  with  Scribe  or  ScribeOptimistic  should  be  aware  of  the  possible  ways  that  can change the price (pokeData.val).  Below we list occasions where the price can change immediately as well as some potential ways how this could be leveraged (i.e. bundled):   Authenticated (in Scribe and ScribeOptimistic): _poke() invoked with a valid new pokeData and  schnorr signature from feeds. The current price will advance to a new price.   Wards  (only  in  ScribeOptimistic):  _afterAuthedAction()  invoked  by  the  wards  which  drops  a previously  finalized  opPokeData  according  to  the  new  challenge  period.  In  case  this  dropped opPokeData is the freshest one, the current price will rollback to the _pokeData.   Permissionless  (only   in  ScribeOptimistic):  onChallenge()  which   fresh opPokeData  and  pushes  it  to  _pokeData.  The  current  price  will  advance  to  the  new  price (opPokeData). Similarly, after an optimistic poke, anyone could execute poke() using this signed data to advance the price immediately.  finalizes  a  valid   When  integrating  with  ScribeOptimistic  projects  must  be  aware  that  an  optimistic  price  update  is generally but not always subject to the challenge period delay: anyone may finalize it at any point during the challenge period.  Chronicle - Scribe -   23  NoteVersion1NoteVersion1NoteVersion1            \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Expired Domains Look Valid for the",
        "body": " Subdomains  The  desired  invariant  that  fuses  can  be  inspected  individually  and  care  only  needs  to  be  taken  when domains expire, can be broken. This is because an expired domain can be rewrapped with new fuses and  wrapped  subdomains  are  not  aware  of  the  expiry  of  higher-level  domains.  Please  consider  the following scenario:  1. User U controls example.eth, wraps it and burns the CANNOT_REPLACE_SUBDOMAIN fuse.  2. The domain expires and user V takes control of it and makes sure it will not expire any time soon.  3. User V assigns control to W over sub.example.org.  4. User W wraps sub.example.org:  1. W also decides to burn the CANNOT_UNWRAP fuse.  2. During   the  execution   the  parent  node   (example.eth)   is  checked  where   the  CANNOT_REPLACE_SUBDOMAIN fuse has been burnt.  3. Hence, the wrapping succeeds.  5. Now  third  parties  check  the  wrapped  state  of  sub.example.org:  According  to  the  invariant  it cannot be unwrapped as it will not expire any time soon and as the CANNOT_UNWRAP fuse has been burnt.  6. User  V  can  freely  reassign  sub.example.org  (independently  of  the  NameWrapper).  Hence,  the permission  system  has  been  bypassed  as  a  non-wrapped  and  a  wrapped  version  exists  for sub.example.org.  ENS - NameWrapper -   10  CriticalHighMediumCodeCorrectedSpeci\ufb01cationChangedLowCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCorrectnessMediumVersion1CodeCorrected         \fHence,  fuses  are  indifferent  to  the  expiry  of  domains  and  they  enforce  the  corresponding  permissions only for never-expired domains.    The code was rewritten so that it checks the hierarchy of a name for safety.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Old State From Expired Domains Can Block",
        "body": " Legitimate Actions  In case a domain is wrapped, then expires and is later controlled by another user and wrapped again, the following problem can arise, which blocks the new legitimate owner from performing an action they would have been allowed to.  Please consider the following sequence:  1. User U controls example.eth and wraps it.  2. User U creates a subnode sub.example.org and sets themselves as owner.  3. The domain expires and user V takes control of it.  4. User V wraps example.eth again and burns the CANNOT_REPLACE_SUBDOMAIN fuse.  5. Now, user V tries to create sub.example.org:  1. The function canCallSetSubnodeOwner is evaluated, it should return true as V has the  permission to create new subdomains.  2. The owner of sub.example.org is queried and it returns U.  3. As the owner is non-zero, the CANNOT_REPLACE_SUBDOMAIN fuse is checked.  4. Finally,  canCallSetSubnodeOwner  returns  false  and  hence  the  legitimate  creation  of  the subnode fails.  Specification corrected:  The specification has been made more explicit so that it covers the case above.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Variable node Assigned but Never Used in",
        "body": " wrapETH2LD  the   In  _makeNode(ETH_NODE, labelhash). However, this value is never used.  wrapETH2LD   functions,   node   new   the   is   calculated   using    The redundant variable was removed.  ENS - NameWrapper -   11  CorrectnessMediumVersion1Speci\ufb01cationChangedDesignLowVersion2CodeCorrected                \f6.4   Incorrect Specification for Unwrapping Functions  The README says about unwrapping:  Wrapped  names  can  be  unwrapped  by  calling  either  unwrapETH2LD(label,  newRegistrant, newController)  or  unwrap(parentNode,  label,  newController)  as  appropriate.  label  and  parentNode have meanings as described under \"Wrapping a name\"  Furthermore, the docstring says:   @param label label as a string of the .eth domain to wrap e.g. vitalik.xyz would be 'vitalik'  However, the implementation works differently. Instead of passing a label, a labelhash should be passed to the unwrapping functions, as seen for unwrapETH2LD below:  function unwrapETH2LD(     bytes32 label,     address newRegistrant,     address newController ) public override onlyTokenOwner(_makeNode(ETH_NODE, label)) {     _unwrap(_makeNode(ETH_NODE, label), newController);  Specification changed:  The documentation has been updated.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Repetitive Code",
        "body": "  There are multiple instances of repetitive code that could be avoided. These instances include:   Within the function wrapETH2LD, two calls are made to registrar.ownerOf(tokenId).   Within  the  functions  unwrapETH2LD,  unwrap,  and  burnFuses,  two  calls  are  made  to  _makeNode(parentNode, labelhash).   Within the function burnFuses, getData is called multiple times in different spots.  The cost impact of these repetitions has been lowered by the recently introduced EIP-2929, however gas optimizations remain possible.    The  superfluous  call  to  registrar.ownerOf(tokenId)  has  been  removed  as  well  as  the  duplicate calle to getData in burnFuses.  ENS - NameWrapper -   12  CorrectnessLowVersion1Speci\ufb01cationChangedDesignLowVersion1CodeCorrected                  \f6.6   Specification Unclear for setSubnode* Functions  The docstring for the setSubnodeRecord function says:   @notice Sets records for the subdomain in the ENS Registry   @param node namehash of the name  However, the node parameter should contain the namehash for the parent node. This is not entirely clear from the description. Especially, in comparison with the setSubnodeRecordAndWrap function, where the docstring says:   @notice Sets the subdomain owner in the registry with records and then wraps the subdomain   @param parentNode parent namehash of the subdomain  A consistent naming of node versus parentNode for these very similar functions would be beneficial to avoid  confusion.  This  also  extends  to  the  setSubnodeOwner  and  setSubnodeOwnerAndWrap functions. Furthermore, the label parameter is missing from the setSubnodeRecord description.    The parameter names were changed to reflect their status.  ENS - NameWrapper -   13  CorrectnessLowVersion1CodeCorrected      \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Dirty Bits in Return Value of getData",
        "body": "  The  getData  function  is  one  of  the  most  important  functions  of  the  NameWrapper  as  it  retrieves information about the different nodes.  function getData(uint256 tokenId)     public     view     returns (address owner, uint96 fuses) {     uint256 t = _tokens[tokenId];     owner = address(uint160(t));     fuses = uint96(t >> 160); }  Functions calling getData need to be aware that the owner return value will contain \"dirty bits\". This is dangerous  if  assembly  is  being  used,  because  assembly  will  access  the  raw  data.  Writing  normal solidity code should be fine.  Hence, we recommend to avoid assembly in connection with getData. We have attached an example file for this behaviour.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Note to Integrators: onERC1155Received",
        "body": " Hook  This  note  is  meant  for  any  developers  wanting  to  build  upon  the  NameWrapper.  Similarly  to  ERC223, ERC721, ERC777, and others the implementation of ERC1155 invokes the onERC1155Received hook at the end of safeTransferFrom. Developers building services which interact with the NameWrapper should  be  aware  of  that  and  implement  the  hook,  as  these  hooks  have  historically  led  to  reentrancy attacks.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Restrictions on Custom Permissions",
        "body": "  The README documents that additional fuses might be designated to additional permissions. While this generally can be implemented with the current contract, not all types of permissions will be feasible this way.  Any permissions, requiring checks \"up the chain\" of custody would not work without modifications to the contract  or  without  breaking  the  invariant  that  fuses  can  be  inspected  individually.  As  a  somewhat  ENS - NameWrapper -   14  NoteVersion1NoteVersion1NoteVersion1          \fcontrived example, a permission enforcing that TTL values of subnodes must be strictly larger than TTL values of parent nodes, currently could not be enforced.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   The Transitive Permission Structure",
        "body": "  Users  should  be  aware  of  the  transitive  permission  structure  of  the  system.  This  permission  structure involves the NameWrapper, Registry and Registrar. Given a typical user setup, setting an operator O using NameWrapper.setApprovalForAll does not only pass control over all wrapped domains but O also controls all non-wrapped domains. Furthermore, domains that are acquired in the future, can be controlled by O.  In  short  becoming  an  operator  for  a  particular  account  on  the  NameWrapper  is  more  powerful  than becoming  an  operator  for  the  same  account  on  the  Registrar  or  the  Registry.  Hence,  operator permissions should be given out with great care.  ENS - NameWrapper -   15  NoteVersion1    \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Staking Does Not Prevent Misbehavior",
        "body": "  Resolvers have to join a whitelist which is governed by the staking of 1inch tokens.  The documentation states:  The stake determines a resolver\u2019s ability to get orders and ensures that a resolver follow the protocol rules (like in proof of stake model).  On the smart contract level the implementation of the staking does not allow to seize stake of bad actors. Their stake is not at risk and can simply be withdrawn at the end of the lock period hence this staking does not ensure that a resolver follows the protocol rules.  Risk accepted:  1inch states:  They'll need only follow what is required to be able to settle the order batch. Staking is only used as a threshold entry requirement.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Missing Events",
        "body": "  Events  are  used  to  be  informed  of  or  to  keep  track  of  transactions  changing  the  state  of  a  contract. Generally, any important state change should emit an event.  1inch - Limit Order Settlement -   15  SecurityDesignCriticalHighMediumRiskAcceptedLowAcknowledgedDesignMediumVersion1RiskAcceptedDesignLowVersion1Acknowledged                  \fThe functions used for deposits and withdrawals in FeeBank do not emit an event, hence it's hard for an observer to track deposits and withdrawals  Acknowledged:  1inch acknowledged the issue and decided to leave the code as it is.  1inch - Limit Order Settlement -   16    \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings   St1inch Can Be Locked Indefinitely   -Severity Findings   Resolver Can Set Arbitrary Callback   0  0  1  1  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   St1inch Can Be Locked Indefinitely",
        "body": "  It is possible for an attacker to lock the staked amount of 1inch token of any staker by using one of the St1inch.depositFor  functions  for  the  target  address.  By  depositing  a  small  amount  of  tokens  and specifying the duration, one can force a target staker to see its stake locked for more time, preventing the staker to withdraw. The only way to break that attack would be to activate the emergency exit to allow the target staker to withdraw.    The functions St1inch.depositFor and St1inch.depositForWithPermit have been updated so the duration cannot be specified and is hardcoded to be 0. This will only increase the deposited amount and not the timelock duration.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Resolver Can Set Arbitrary Callback",
        "body": "  can   Resolvers  in Settlement._settleOrder()  and  execute  arbitrary  code  which  may  severely  interfere  with  the process.  (interactionTarget   address)   callback   address   called   the   set     The Settlement contract now ensures that the address is the settlement contract itself:  let target := shr(96, calldataload(add(data.offset, interactionOffset))) if iszero(eq(target, address())) {     mstore(0, errorSelector)  1inch - Limit Order Settlement -   17  CriticalHighMediumCodeCorrectedLowCodeCorrectedSecurityMediumVersion1CodeCorrectedSecurityLowVersion1CodeCorrected                \f    revert(0, 4) }  1inch - Limit Order Settlement -   18  \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Competing Resolvers May Result in Failing",
        "body": " Transactions  Since resolvers are competing against each other, it may happen that more than one resolver submits the same order in their respective batch, in the same block. In such cases, only the first batch including the order will not revert and all the other resolvers will suffer from pure loss of gas.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Gas Optimization",
        "body": "  Some operations can be in an unchecked block to save gas, examples are:   update of i and addition in FeeBank.gatherFees()   addition in FeeBank._depositFor()   addition in FeeBankCharger.increaseAvailableCredit()   for loop in WhitelistRegistry.register()   WhitelistRegistry._shrinkPoorest()  Intermediary memory variable can save storage reads. Example is:   St1inch._deposit()  does  two  SLOAD  for  deposits[account],  storing  the  updated  deposit  amount in memory will save gas.  Code partially corrected:  The function St1inch._deposit() has been updated to do only one SLOAD for the depositor.  Other gas optimizations have been addressed in future commits.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Preview Functions Accept Invalid Durations",
        "body": "  functions  (previewBalance,  previewPowerOf,previewPowerOfAtTime)  may The  preview  accept  a  duration  parameter  that  may  exceed  the  maximum  locking  period  and  make  the  transaction revert if applied in the St1inch contract.  1inch - Limit Order Settlement -   19  InformationalVersion1InformationalVersion1InformationalVersion1          \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Allowed Sender of Orders",
        "body": "  Makers wishing to benefit from the protections of the limit settlement protocol must ensure the order they sign has the settlement contract set as allowed sender.  Technically  the  settlement  contract  allows  resolvers  to  batch  any  orders  which  gives  them  greater freedom  to  aggregate  transactions.  While  execution  of  orders  without  the  allowed  sender  restricted works,  such  orders  can  also  be  executed  through  the  limit  order  protocol  directly  and  hence  lack  the protection limit settlement order offers.  It's vital to understand that this field has to be set correctly or that the protections offered by limit order settlement don't apply. Although this might be obvious there should be documentation emphasizing this. Even the tests within the limit-settlement-order repository use public orders (since allowed sender is not set and hence anyone, not just the settlement contract, can call limitOrderProtocol.fillOrder() for this order).  This is an easy source of errors, hence it`s important to be explicit and not assume users/integrators will understand and do this correctly.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   User Responsibility for Setting Trusted",
        "body": " Resolvers  Nothing  enforces  the WhitelistRegistry.  It  is  the  user's  responsibility  to  ensure  that  the  resolvers  addresses  they  sign over are trusted.  to  be  actually  part  of   in  Order.interaction   the  resolvers   listed   1inch stated:  That\u2019s also the responsibility of the frontend to provide correct whitelists to the user. And also responsibility of the backend to filter out maliciously created orders without the proper whitelist.  1inch - Limit Order Settlement -   20  NoteVersion1NoteVersion1      \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Pool and Configurator May Not Match",
        "body": "  Nothing  enforces  the  pool  address  to  be  the  one  set  in  the  configurator.  If  the  pool  address  and  the poolConfigurator  pool  were  to  differ,  the  SparkLendFreezerMom  contract  may  not  work  as expected.  CS-SPRKFRZR-001  Acknowledged:  Client states:  Acknowledged, no change. Will ensure configuration is correct with adequate end to end testing.  MakerDAO - SparkLend Freezer -   10  DesignCriticalHighMediumLowAcknowledgedDesignLowVersion1Acknowledged         \f6   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Events Emission Inconsistency",
        "body": "  In  the  functions  rely  and  deny,  the  event  is  emitted  after  the  storage  update,  but  in  the  functions setAuthority and setOwner the event is emitted before. A consistent codebase is easier to maintain and understand.  CS-SPRKFRZR-002  Risk accepted:  Client states:  Acknowledged, no change. This pattern was done on purpose to efficiently emit the previous and new values of the setters for setAuthority and setOwner before the value is updated in storage.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Gas Optimizations",
        "body": "  CS-SPRKFRZR-003  1. In   the   and SparkLendFreezerMom.pauseAllMarkets, the length of reserves can be cached before the loop to save gas.  SparkLendFreezerMom.freezeAllMarkets   functions   2. The  incrementation  of  the  index  in  the  function  SparkLendFreezerMom.freezeAllMarkets  and SparkLendFreezerMom.pauseAllMarkets can be unchecked.  Acknowledged:  Client chose to not implement gas optimizations.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Unused Code",
        "body": "  1. The function SparkLendFreezerMom.isAuthorized has a branch src == address(this)  that cannot be reached.  CS-SPRKFRZR-004  MakerDAO - SparkLend Freezer -   11  InformationalVersion1RiskAcceptedInformationalVersion1AcknowledgedInformationalVersion1Acknowledged                \fAcknowledged:  Client  acknowledged  the  code  is  unused,  isAuthorized()  is  a  common  function  present  in  multiple contracts and intentionally not modified.  MakerDAO - SparkLend Freezer -   12  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Locked Assets After Repay",
        "body": "  A manager could try to repay an amount bigger than what they owe to Aave. In such cases, the leftover amount will not be transferred back to the vault. Consider the following case:  1. A manager owes 100 DAI  2. The manager tries to repay 110 DAI  3. 110 DAI will be transferred from the vault to the external position  4. The  call  to  Aave  will  only  consume  100  DAI.  The  remaining  amount  will  remain  in  the  external  position    After the debt owed to Aave is repaid, the remaining balance of the repayment token is sent back to the vault proxy. Since the repayment token is an underlying and not an aToken, the transfer will not affect the health factor of the positions.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Rebasing aToken Balance",
        "body": "  ATokens are rebasing tokens. This means that the balance an account holds changes in time and, thus, between the time a transaction is submitted and mined. In the current implementation, there is no way to remove  the  full  amount  of  the  collateral  by  querying  the  balance  the  external  position  holds  during  the execution of the transaction. This could result in dust remaining in the external position.  Avantgarde Finance - Extensions III -   11  CriticalHighMediumCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedDesignMediumVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \f  By specifying the maximum integer as the amount, the full aToken balance will be withdrawn:  uint256 collateralBalance = ERC20(aTokens[i]).balanceOf(address(this));  if (amounts[i] == type(uint256).max) {     amounts[i] = collateralBalance; }  // If the full collateral of an asset is removed, it can be removed from collateral assets if (amounts[i] == collateralBalance) {     collateralAssets.removeStorageItem(aTokens[i]);     emit CollateralAssetRemoved(aTokens[i]); }  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Redundant Call",
        "body": "  __addCollateralAsset  call  the  lending  pool  function  setUseReserveAsCollateral  which enables  an  asset  to  be  used  as  a  collateral.  However,  the  implementation  of  regular  transfers  will automatically  use  the  underlying  of  the  transferred  aToken  as  collateral  if  a  zero-balance  is  increased (see AToken code and lending pool\u2019s finalizeTransfer). Hence, the call may be redundant.    The call has been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Sanity Check Missing",
        "body": "  compatible  with   An added collateral token is never sanitized. Assume a malicious manager to create an evil token which a  method is  UNDERLYING_ASSET_ADDRESS()  which  returns  a  token  used  by  Aave.  Since  this  token  is  never sanitized, it could be added as collateral since the call  the  AToken,   interface   exposes   the   i.e.   of   it   (lendingPoolAddress).setUserUseReserveAsCollateral(AaveAToken(aTokens[i]).UNDERLYING_ASSET_ADDRESS(), true);  will  succeed.  Adding  such  a  token,  however,  could  block  the  function  ControllerLib.calcGaV() which calculates the external position value. During the calculation, the managed assets are queried with getManagedAssets in order to be priced but no price feed for the evil token exists.    The AaveDebtPositionParser will now validate that the token added as collateral is a whitelisted token. Ultimately supported non-aTokens could be deposited. However, that does not block execution nor could it lock tokens.  Avantgarde Finance - Extensions III -   12  DesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Aave Paused",
        "body": "  The  lending  pool  of  Aave  could  be  paused  and,  hence,  actions  on  the  vault  will  not  be  possible  to execute. Ultimately, positions could be not modifiable, and funds could be stuck.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Sandwiching Transactions for Liquidation",
        "body": "  It is known that the behavior of the managers is monitored. However, we would like to point out that there are sequences of actions from which the manager can benefit. In particular, a malicious fund manager, who  sees  a  price  drop  in  the  Aave  oracle  of  a  collateral  asset,  could  create  a  malicious  sequence  of transactions  through  MEV  capabilities  to  borrow  with  user  funds  while  liquidating  the  position immediately. Consider the following sequence of transactions:  1. Move aDai to the Aave external position proxy and borrow WETH such that the health factor is 1.  2. The sandwiched oracle price changes: Dai price drops compared to WETH.  3. The fund manager liquidates the position and profits.  Avantgarde Finance - Extensions III -   13  NoteVersion1NoteVersion1      \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Locked Refunded Provision",
        "body": "  When  a  maker  submits  an  order  to  the  Mangrove  orderbook,  they  need  to  provide  some  ETH,  also known as the provision, to compensate the takers in case the makerExecute hook reverts. A maker can update their offer by calling Forwarder.updateOffer. Note that at this point a maker can update most of the parameters of the order including gasreq, i.e. the gas required for the makerExecute hook to execute. A maker could reduce the gas requirements meaning that some provision will be refunded to them. Forwarder.updateOffer does not handle this refunding (the ownerData.weiBalance is not updated) and Mangrove system only sees MangroveOrder as a maker. This means that the refunded amount is essentially lost for the end-user of the MangroveOrder. Note that if the provision needs to be increased again, the end-user must provide extra ETH.  Code Corrected:  In the current implementation, the provision can only be increased therefore no funds are locked.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Wrong Calculation of Locked Provision",
        "body": "  Giry SAS - MangroveOrder -   11  CriticalHighCodeCorrectedCodeCorrectedMediumCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCorrectnessHighVersion1CodeCorrectedCorrectnessHighVersion1CodeCorrected                 \fWhen a user updates their offer through Forwarder.updateOffer, MangroveOrder tries to calculate the new gas price by calling deriveGasprice. The gas price depends on the total provision available for  this  order.  That  is  the  sum  of  the  extra  provision  attached  which  is  stored  in  args.fund  and  the already locked provision. Currently, the locked amount is calculated with the following snippet:  vars.offerDetail.gasprice() * 10 ** 9 * args.gasreq + vars.local.offer_gasbase()  This formula is wrong for two reasons:  1. It depends on args.gasreq which is the updated gas requirement of the order as passed by  the user.  2. There are parentheses missing around args.gasreq + vars.local.offer_gasbase(),  as this entire term should be multiplied by the gas price.  This miscalculation can have multiple consequences:  1. Can allow users to steal funds (see relevant issue).  2. An  order  can  be  submitted  with  smaller  gasprice  since  the  calculated  total  provision  is  too  small.  Code Corrected:  Forwarder.updateOffer has been updated. Currently, users can only increase the provision for an order.  Users  cannot  determine  args.gasreq  as  it  is  set  to  be  equal  to  the  offerGasreq().  It  is important  to  notice  that  offerGasreq()  is  not  constant  but  depends  on  the  configuration  of  the MangroveOrder and in particular the gas requirements of the router.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Expiration Date Cannot Be Updated",
        "body": "  A  user  can  update  most  of  the  offer  details  by  calling  Forwarder.updateOffer.  However,  the expiration date cannot be changed. In order to change the expiration date of an order, one must retract it and submit a new one.  Code Corrected:  MangroveOrder.setExpiry has been added to allow users to update the expiration date of the order.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Underflow in postRestingOrder",
        "body": "  Once the market order part of GTC order has been filled as much as possible, the remaining amount the user  wants  to  trade  is  put  into  a  resting  order.  Note  that  if  fillWants  ==  true,  then  the  Mangrove engine will have stopped matching the order either when it is fully filled, there are no more orders on the books, or when the total average price of the order would fall below the threshold of the ratio between the order's initial wants and gives. Hence, if the matching stops before the order's wants are fully filled, we are  guaranteed  not  to  have  given  away  more  than  the  order  initially  had  (else  the  total  average  price would be below what we initially wanted).  Giry SAS - MangroveOrder -   12  DesignMediumVersion1CodeCorrectedCorrectnessMediumVersion1Speci\ufb01cationChanged                \fHowever,  if  fillWants  ==  false,  this  condition  no  longer  holds.  The  order  can  receive  arbitrarily many tokens before giving away all the tokens it has to give away. As the price of a trade is defined by the  maker,  there  could  be  orders  on  the  books  which  give  away  arbitrarily  many  tokens  for  a  very  low price.  Hence,  the  user  can  receive  more  tokens  in  the  market  order  part  of  the  trade  than  they  were expecting to. As such, res.takerGot + res.fee can exceed tko.takerWants despite only having partially filled the order.  When we go to post a resting order, the following code is executed:  res.offerId = _newOffer(   OfferArgs({     outbound_tkn: outbound_tkn,     inbound_tkn: inbound_tkn,     wants: tko.makerWants - (res.takerGot + res.fee), // tko.makerWants is before slippage     gives: tko.makerGives - res.takerGave,     gasreq: offerGasreq() + additionalGasreq, // using default gasreq of the strat + potential admin defined increase     gasprice: 0, // ignored     pivotId: tko.pivotId,     fund: fund,     noRevert: true, // returns 0 when MGV reverts     owner: msg.sender   }) );  When  the  wants  for  the  resting  order  are  calculated,  an  underflow  can  occur  in  the  case  described above, as the market order part of the GTC order could have received arbitrarily many tokens. As Solidity ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "0.8.10  is  used,  this  will  simply  revert  the  transaction,  but  will  unnecessarily  prevent  the  user  from",
        "body": " completing their trade.  Specification Changed:  Currently,  the  order  is  posted  with  the  same  price  as  the  taker  originally  wanted.  Thus,  the  issue  has been mitigated.  Giry SAS replied:  this  problem  made  use  reevaluate  our  specification:  requiring  the  (instant)  market  order  and  the (asynchronous) maker order to respect a limit average price is not well defined. In some cases this would lead the maker order to be posted for a 0 price. We decided to change the specification and post the maker order at the price initially set by the taker for the market order (irrespectively of the obtained price).  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Users Can Steal Funds From MangroveOrder",
        "body": "  The core Mangrove system maintains the balanceOf mapping which stores how much ETH is available for each maker to be used as a provision for their orders. Importantly, the MangroveOrder contract is seen  as  one  single  maker  by  the  system,  even  though  there  might  be  many  end  users  creating  their orders through it. Let us assume that at some point the balance of MangroveOrder is positive and an attacker has already submitted an order. It is possible as we show in another issue that there might be some non-claimable balance since updateOrder does not handle refunds. An attacker can steal money from mangrove by employing any of the following two vectors:  1. Updating an order without sending funds:   The attacker calls Forwarder.updateOrder for their order with msg.value == 0 and  they increase the gas requirement of their order.   This means that args.fund == 0 so gas price will remain the same, however, the total  provision needed has been increased as the gas requirements have been increased!   At this point MGV.updateOffer is called with msg.value == 0.  Giry SAS - MangroveOrder -   13  SecurityMediumVersion1CodeCorrected        \f Mangrove core does not perform any check if there are enough funds attached to the call  since it relies on the balanceOf mapping by calling debitWei.   Mangrove core uses the amount stored in balanceOf for the extra provision.   The  attacker  now  retracts  the  order  and  withdraws  the  provision  of  the  order  which  includes the stolen amount.  2. Updating an order by attaching funds:   The attacker calls Forwarder.updateOrder for their order with msg.value != 0 and  they increase the gas requirement of their order.   Since funds have been attached to the transaction, the gas price will be recalculated.   The  new  provision  at  this  point  is  calculated  wrongly  since  the  provision  parameter passed  to  derivePrice  depends  on  args.gasreq  which  represents  the  updated  gas requirements  of  that args.gasreq can be freely set by the users so arbitrarily large value could be passed. As a result, the new gas price is greater than it should be but the extra funds passed are not enough to cover for the extra provision needed by the offer.  the  offer  and  not  vars.offerDetail.gasreq().  Note    Mangrove core uses the amount stored in balanceOf for the extra provision.   The  attacker  now  retracts  the  order  and  withdraws  the  provision  of  the  order  which  includes the stolen amount.  A  similar  attack  can  be  performed  when  some  of  the  global  parameters  change,  which  could  result  in inaccurate accounting of provisions. If the gasbase of the token pair related to an order changes in the core  mangrove  system,  calling  updateOffer  can  result  in  an  increased  (or  decreased)  provision without  providing  any  additional  funds.  This  will  credit  (or  debit)  funds  to  the  MangroveOrder  contract which  aren't  attributed  to  any  user.  In  particular,  if  the  global  gas  price  is  increased,  calling updateOffer  of  Mangrove  core  with  an  unchanged  gasprice  which  is  lower  than  the  new  global  gas price,  the  mangrove  core  system  will  set  the  gas  price  higher  without  receiving  any  funds.  This  again changes the balance of the MangroveOrder contract, without attributing it to any individual user. While _newOffer and _updateOffer in Forwarder have checks to make sure the offer's gas price is higher than the global gas price, __posthookSuccess__ in MangroveOffer does not. Hence, if the global gas price changes, then an order is partially filled and attempts to repost, its provision will be increased with no additional submitted funds. While the amounts of funds are small, it is conceivable that a malicious user could be able to exploit a change in the global gas price or the gasbase in order to steal funds.  It  is  important  to  note  that  this  issue  cannot  result  in  users  losing  funds  since  the  excessive  provision which can be stolen cannot be claimed by any specific user. In the normal case, no excessive provision should  be  available.  Therefore,  it  is  expected  the  amount  that  can  be  stolen  to  be  low.  Hence,  we consider the issue as medium severity.  Code partially corrected:  The issue has been addressed in multiple different ways:  1. In the current implementation there shouldn't be unallocated users' funds in Mangrove core.  2. Users can only increase the provision of an order using MangroveOrder.updateOrder, not decrease  it.  Hence,  they  must  provide  additional  provision  and  can  not  submit  orders  which could make use of funds that are already stored in the Mangrove core.  3. The __posthookSuccess__ uses Forwarder._updateOffer.  Giry SAS - MangroveOrder -   14    \f6.6   Inaccurate Comment  In MangroveOrder.checkCompleteness, the following is mentioned:  // when fillWants is true, the market order stops when takerWants units of outbound_tkn have been obtained;  However, this comment is inaccurate since part of the takerWants goes to cover the fees, so not the full takerWants amount can be obtained.  In AbstractRouter.push, the return value is described as follows:  ///@return pushed fraction of amount that was successfully pushed to reserve.  However,  for  tokens  with  fees,  provided  the  TransferLib  is  used,  the  whole  amount  will  always  be reported.  Code Corrected:  The comments have been updated.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Missing Natspec",
        "body": "  The Natspec is missing in the following cases:   For AbstractRouter.bind, the maker parameter.   For AbstractRouter.unbind, the maker parameter.   For SimpleRouter.__pull__, the strict parameter.   For IOfferLogic.OfferArgs, the gasprice field.  Code Corrected:  The Natspec has been added to the respective functions.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   Redundant pragma abicoder v2",
        "body": "  Many contracts include the pragma abicoder v2 directive. However, for solidity 0.8 the abicode v2 is the default one, so the pragma is redundant.  Code Corrected:  The pragma has been removed from most of the contracts.  Giry SAS - MangroveOrder -   15  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \f6.9   Setting Expiration Date  A user can define the time-to-live of a resting order submitted through MangroveOrder by specifying the TakeOrder.timeToLiveForRestingOrder.  It  is  important  to  note  that  an  order  can  remain  in  the mempool  for  a  long  time  before  it's  executed.  Specifying  an  explicit  expiration  date  instead  of  the time-to-live might be more convenient for users since it's independent of the time it takes for a transaction to be included in a block.  Code Corrected:  The  expiration  date  is  now  absolute  and  no  longer  relative  to  the  time  the  transaction  is  added  to  the blockchain.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   Forwarder.provisionOf Calculation Is",
        "body": " Wrong  As its natspec suggests Forwarder.provisionOf computes the amount of native tokens that can be redeemed  when  In MgvOfferMaking.retractOffer, the provision is calculated as follows:  offer.  However,   deprovisioning   given   true.   this   not   is   a   provision = 10 ** 9 * offerDetail.gasprice() //gasprice is 0 if offer was deprovisioned   * (offerDetail.gasreq() + offerDetail.offer_gasbase());  The important part to notice is that provision depends on offerDetail.offer_gasbase().  This is not the same for Forwarder.provisionOf where the provision is calculated as follows:  provision = offerDetail.gasprice() * 10 ** 9 * (local.offer_gasbase() + offerDetail.gasreq());  Here,  offerDetail.offer_gasbase().  provision   the   depends   on   local.offer_gasbase()   instead   of  Code Corrected:  The provision is now calculated using the offerDetail.offer_gasbase().  Giry SAS - MangroveOrder -   16  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected              \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Updating Approvals on Order Update",
        "body": "  A  user  can  update  their  orders  by  using  Forwarder.updateOffer.  It  is  important  for  users  to remember  that,  in  case  the  makerExecute  hook  to  their  order  fails,  they  will  have  to  reimburse  the taker. A reason for an order to fail is that there is not enough allowance given to the router to transfer funds from the maker's reserve to MangroveOrder contract. This is highly likely to happen after a user updates their offer by having it give more funds to the taker.  Giry SAS - MangroveOrder -   17  NoteVersion1  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Gas Optimizations",
        "body": "  1. In the _mint function, the update of totalSupply can be done in the unchecked block to save gas.  The  total  supply  of  shares  is  bound  to  be  <=  total  supply  of  DAI,  which  is  bound  to type(uin256).max.  2. The internal function _rpow always take RAY as base, replacing base by RAY in the code will save  a bit of gas at runtime.  ISSUEIDPREFIX-001    1. The update of totalSupply has been moved in the unchecked block.  2. The base parameter of the function _rpow has been removed, and replaced by RAY everywhere.  Oazo Apps Limited - Savings Dai -   10  InformationalVersion1  \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Known Attack Vector on approve()",
        "body": "  Users should be aware of the well known attack vector on approve() (front running changes to existing approvals, spending more tokens than intended by the owner). If needed, they should use the provided increaseAllowance() / decreaseAllowance() to mitigate this risk.  Oazo Apps Limited - Savings Dai -   11  NoteVersion1  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Manipulable Price Calculation in",
        "body": " AggregateStablePrice Method  0  0  1  0  The price() function in the AggregateStablePrice contract calculates the price of the stablecoin based on the total supply of stableswap pools.  CS-CRVUSD-004  pool_supply: uint256 = price_pair.pool.totalSupply()  It is possible to manipulate this value, as a malicious actor could significantly change the total supply of pools by using a large amount of capital (obtained for example with a flashloan). This manipulation could alter the computed stablecoin price between the range of the stableswap pool with the lowest price to the stableswap  pool  with  the  greatest  price.  Given  the  function's  role  in  determining  the  price  used  by  the main price oracle, the pegkeepers, and the monetary policies, this may represent a risk.  Code partially corrected:  The new AggregateStablePrice2 contract implements an exponential moving average over the total supplies  of  the  pools.  Note  that  the  first  time  the  price  is  calculated  in  a  block  is  then  valid  for  the remainder  of  that  block.  This  means  that  the  price  is  still  manipulable  to  some  extent  (e.g.  using  a flashloan), although due to the moving average the effect will be reduced. An solution such as using the last price from the previous block may be a more suitable alternative, however it would require moving the totalSupply EMA oracle from an external contract to the StableSwap contract.  Curve - Curve Stablecoin -   10  SecurityDesignCorrectnessCriticalHighMediumCodePartiallyCorrectedLowSecurityMediumVersion1CodePartiallyCorrected             \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  0  3  6  20  -Severity Findings  -Severity Findings   Checks-effects-interactions Pattern and Reentrancy Locks   Incorrect Verification of Health Limit    Oracle Price Updates Can Be Sandwiched   -Severity Findings   PegKeeper Can Be Drained if Redeemable Stablecoin Permanently Depegs   Incorrect Max Band   Interest Rate Does Not Compound    Manipulation of Active Band    Non-Tradable Funds    Potential Denial of Service (DoS) Attack on Peg Keeper   -Severity Findings   A User's Liquidation Discount Can Be Updated by Anyone at Any Time    ApplyNewAdmin Event Emitted With Wrong Argument in PegKeeper    Draining Funds   Inaccurate _p_oracle_up(n) for High/Low Values of n   Incorrect Array Length   Incorrect Calculations in health_calculator   Incorrect Comments    Meaningful Revert Reasons    Missing Sanity Checks    Multiple Calls to the AMM    No Events    Non-Indexed Events    Potential Optimization With Immutable PriceOracle    Potentially Incorrect Admin Fees    Simpler Calculations Possible    Superfluous Check    Superfluous Interface Definitions    Superfluous Variable Assignment for Number of Bands    Unnecessary Subtraction   Curve - Curve Stablecoin -   11  CriticalHighCodeCorrectedCodeCorrectedCodeCorrectedMediumCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrected       \f Unused Variables   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Checks-effects-interactions Pattern and",
        "body": " Reentrancy Locks  CS-CRVUSD-015  Some  external  calls  to  the  collateral  token  deviate  from  the  checks-effects-interactions  pattern.  If  no reentrancy  lock  is  present,  these  calls  might  introduce  reentrancy  possibilities  (especially  read reentrancies)  before  the  state  is  fully  updated.  We  could  not  find  a  case  where  the  non-updated  state the relevant  might  be  checks-effects-interactions pattern.  it  might  be  worth  considering   information.  Still,   fully  adhering   to   For example,  in AMM.exchange(), the transfer is done before the bands are updated;  in AMM.withdraw(), the old rate information would still be returned;  in Controller.create_loan(), the intermediate stable coin balance is returned.  The Reentrancy locks appear to be set inconsistently. We at least cannot see the underlying logic of how they are added. Some admin setters have a nonreentrant decorator and some do not.  For important functions like exchange the decorator seems to be forgotten after a code change. For this reason, the issue was rated higher.  Code corrected  The  missing  reentrancy  lock  on  exchange()  has  been  added.  Some  missing  reentrancy  locks  have been  explained.  All  but  one  of  the  remaining  external  functions  without  locks  seem  to  be  safe  even without a lock.  The  Controller's  total_debt()  function  will  return  outdated  /  inconsistent  values  compared  to  the AMM's  state  if  called  during  the  callback  of  repay_extended  and  _liquidate.  More  precisely,  the AMM's  state  will  already  reflect  the  withdrawal  /  liquidation,  whereas  the  Controller's  state  has  not  yet been updated. It should be carefully considered if this might pose problems for integrators or third-party contracts interacting with the Controller.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Incorrect Verification of Health Limit",
        "body": "  The _liquidate function checks whether the user's health is below a certain health limit. This health limit is passed as the user's liquidation discount by liquidate (and 0 by self_liquidate). But the health  function  already  accounts  for  the  user's  liquidation  discount  and  is  supposed  to  return  a  value below 0 when the liquidation can start.  CS-CRVUSD-019  Code corrected  Curve fixed and identified this issue while the audit was ongoing.  Curve - Curve Stablecoin -   12  CodeCorrectedDesignHighVersion1CodeCorrectedCorrectnessHighVersion1CodeCorrected                     \f6.3   Oracle Price Updates Can Be Sandwiched  The  AMM  price  range  in  a  band  (p_cd,  p_cu)  depends  cubically  on  the  oracle  price  p_o (p_cd  =  \\frac{p_o^3}{p_\\uparrow^2},  p_cu  =  \\frac{p_o^3}{p_\\downarrow^2}).  Since trading can happen out of band, AMM price changes because of changes in p_o are greatly amplified for bands far from the current oracle price. The previous consideration makes it profitable for an attacker to leverage small oracle price increases by accessing the liquidity of low price bands. The attack scenario is like this:  1. Stablecoin is exchanged for collateral, in a large amount such that the active band is shifted toward  CS-CRVUSD-031  lower prices bands  2. The oracle price is increased  3. part  of  the  collateral  obtained  in  step  1  is  exchanged  back  at  a  higher  price,  recouping  the  stablecoin and allowing the attacker to keep part of the collateral.  Since after a price update the AMM price will move the most for bands which have a low price compared to  the  current  oracle  price  (high  collateral  ratio),  overcollateralized  borrowers  are  most  affected  by  this issue.  Positions  that  should  be  the  safest  might  suffer  the  most  losses  from  sandwiching,  more  than supposedly \"riskier\" positions.  Code corrected  A new dynamic fee has been introduced, such that the fee scales in the same amount as the theoretical profit from sandwiching an oracle update.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   PegKeeper Can Be Drained if Redeemable",
        "body": " Stablecoin Permanently Depegs  If  one  of  the  reference  stablecoins  depegs,  for  example  USDC  falls  to  p  =  $0.95,  the  price  in  the corresponding  StableSwap  (crvUSD/USDC)  will  follow  the  external  market  price  and  also  fall  to  $0.95. The PegKeeper will then try to raise the price, by supplying crvUSD to the StableSwap pool. Essentially the PegKeeper will try to keep USDC from depegging. This opens up the following arbitrage opportunity, where p is the current market price of USDC:  CS-CRVUSD-001  The arbitrage profit depends on the liquidity available in all the pools. If the following (for the purpose of a worst-case analysis) we assume no slippage for the arbitrageur. Assuming all pools have fee f, then the arbitrage becomes profitable if the price p of the depegged stablecoin is:  Curve - Curve Stablecoin -   13  SecurityHighVersion1CodeCorrectedSecurityMediumVersion5CodeCorrected              \fp < \u2212  (f \u2212 1)3 4f 3 \u2212 12f 2 + 12f + 1  Currently, f = 0.0001 meaning that the arbitrage would become profitable for:  p < 0.998502  Assuming that the market price of the depegged stablecoin permanently falls to p, this arbitrage would happen repeatedly until the PegKeeper has been drained. In this case the PegKeeper would suffer a loss trying to prop up the price of the depegging stablecoin.  Furthermore, the PegKeeper would try to keep crvUSD pegged to a depegging stablecoin, which would put the crvUSD price under pressure, but (assuming reasonably distributed liquidity) should not result in a depegging.  Lastly, please note that as part of the arbitrage crvUSD would accumulate in the crvUSD/USDT pool, but the PegKeeper of crvUSD/USDT pool would not be able to withdraw, due to the  assert p_agg <= 10**18  check, as p_agg would presumably be bigger than 10**18 due to the depegging stablecoin.  If  the  depegging  is  only  temporary,  meaning  that  the  price  recovers,  then  the  PegKeeper  was temporarily drained, but should have made a profit in the process.  Theoretically,  this  issue  could  also  exist  in  the  opposite  direction,  with  a  stablecoin  gaining  value. However, this seems less likely except for DAI in Maker endgame scenarios.    In PegKeeperV2 at commit 5a46bb9c1f43b7d4062127b9919e3c2ed366ad34, which is object of a  separate  ChainSecurity  audit,  the  pegkeepers  for  different  redeemable  stablecoins  interact  and communicate to each other limits on how much crvUSD can be supplied to a pool. In the case of a single redeemable stablecoin depegging, the pegkeeping action on its pool will be limited.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Incorrect Max Band",
        "body": "  The  AMM  contract  tracks  the  max_band  variable.  Bands  above  this  band  are  empty.  In  the  withdraw function the max_band is potentially updated:  CS-CRVUSD-034  if self.max_band <= ns[1]:     self.max_band = max_band  If  this  withdrawal  emptied  all  the  touched  bands,  then  this  update  would  set  the  max_band  to  0.  This might be incorrect, as other non-empty bands might still exist inbetween.  As the max_band variable is used in calc_swap_out exchanges on the AMM might work incorrectly because of this.  Code corrected  max_band is now set to the last known band with non-empty coins in the withdrawing loop.  Curve - Curve Stablecoin -   14  CorrectnessMediumVersion1CodeCorrected          \f6.6   Interest Rate Does Not Compound  The AMM contract has a function _rate_mul to compute the rate multiplier. The function simply adds the rate multiplied by the time difference to the previous rate multiplier:  CS-CRVUSD-002  return self.rate_mul + self.rate * (block.timestamp - self.rate_time)  This  approach,  however,  does  not  account  for  the  compounding  of  interest  over  time.  Linearly  adding interest could lead to significant underestimation of the accrued interest over time.  The code should be modified to include interest compounding in line with common financial practice.    The calculation was updated in order to compound each time the _rate_mul function is called (though the rate increases linearly over the time periods between these calls):  return unsafe_div(self.rate_mul * (10**18 + self.rate * (block.timestamp - self.rate_time)), 10**18)  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Manipulation of Active Band",
        "body": "  CS-CRVUSD-020  It is possible to manipulate the active band. The lower the market liquidity the easier the manipulation is. Multiple  other  parameters  are  depending  on  the  active  band  and,  hence,  are  also  manipulated.  The manipulation  is  possible  when  liquidity  which  is  in  a  band  far  above  the  current  band,  is  reachable through trading. And is done by manipulated deposits, paybacks and trades.  The consequences of this manipulation might be manifold. E.g.:   Deposits  which  should  still  be  possible  are  impossible  because  they  would  be  below  the  manipulated active band.   The health ratio would be affected as it depends on the active band  It  could  result  in  an  active  band  that  is  more  than  1024  +  50  away  from  the  \"true\"  active  band. \"True\" if the external price oracle is assumed to be the truth.  Code corrected  It is now impossible to increase the distance between the active band and the oracle price further than 50 ticks. The active band is otherwise used as a reference point of the AMM, but its value does not affect where loans are created or the value of their health ratio.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   Non-Tradable Funds",
        "body": "  CS-CRVUSD-026  Curve - Curve Stablecoin -   15  CorrectnessMediumVersion1CodeCorrectedSecurityMediumVersion1CodeCorrectedDesignMediumVersion1CodeCorrected                       \fIn case of a very small trade in a band far away from the active band, the funds might be inaccessible through normal trading. It is caused by the new code in_amount_done == 0 change which fixes the issue Draining funds but blocks the reversal trade now.    Input amounts are now rounded up.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   Potential Denial of Service (DoS) Attack on",
        "body": " Peg Keeper  The  PegKeeper  contract  contains  a  update  function  that  imposes  a  delay  of  15  minutes  between actions.  CS-CRVUSD-005  if self.last_change + ACTION_DELAY > block.timestamp:     return 0  This design makes it susceptible to a potential Denial of Service (DoS) attack. A malicious actor could effectively  keep  the  PegKeeper  occupied  by  directly  rebalancing  the  stableswap  pools,  calling update(), and then unbalancing the pools again within a single transaction. The PegKeeper would be locked  for  the  next  15  minutes,  without  having  provided  or  withdrawn  any  amount  of  stablecoin.  This strategy could be performed by an actor seeking to destabilize the peg.    PegKeeperV2, included at commit 5a46bb9c1f43b7d4062127b9919e3c2ed366ad34, which is in the scope of a separate ChainSecurity audit, addresses this issue by preventing a pegkeeper update when  the  spot  price  of  the  underlying  pool  is  in  disagreement  with  the  oracle  price  of  the  pool  by more than 5 basis points.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   A User's Liquidation Discount Can Be",
        "body": " Updated by Anyone at Any Time  The repay function allows anyone to repay any loan \u2014 even just partially. This function will also update the liquidation discount of the user who has taken the loan to the current liquidation discount. This implies that someone can repay a tiny amount for another user's loan just to change their liquidation discount. In the case where the liquidation discount has increased significantly since the loan was taken, this will be disadvantageous to the borrower. Conversely, borrowers can update their liquidation discounts to their advantage. The liquidation discount can also be updated by adding collateral.  CS-CRVUSD-006    Curve - Curve Stablecoin -   16  SecurityMediumVersion1CodeCorrectedSecurityLowVersion1CodeCorrected                \fOnly the debt owner can repay in such a way that their position becomes or stays unhealthy. Moreover, the liquidation_discount of a position is only updated if the debt owner is the message sender.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.11   ApplyNewAdmin Event Emitted With Wrong",
        "body": " Argument in PegKeeper  The  __init__  constructor  function  of  a  PegKeeper  emits  a  ApplyNewAdmin(msg.sender)  event. However  msg.sender  is  not  necessarily  the  contract  admin,  which  is  specified  as  the  _admin constructor argument.  CS-CRVUSD-007    The _admin constructor argument is now emitted in the event.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.12   Draining Funds",
        "body": "  It is possible to drain 1 WEI per trade from the exchange when a loan is present. Simply by trading back and  forth  with  a  very  small  amount.  On  Ethereum,  the  transaction  cost  should  always  outweigh  the drained WEI.  CS-CRVUSD-016  Code corrected  in amounts are now rounded up.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.13   Inaccurate _p_oracle_up(n) for High/Low",
        "body": " Values of n  CS-CRVUSD-008  The  AMM  contract  implements  the  _p_oracle_up  function,  which  performs  numerical  computations  to determine its return value. The maximum and minimum values of the power variable (which is derived from the parameter n) are constrained by assert statements.  However,  these  bounds  are  too  permissive,  allowing  extreme  values  of  n  to  pass  through,  leading  to potential  issues.  When  the  value  of  n  is  excessively  high  or  low,  the  output  of  the  _p_oracle_up function can result in collisions (identical results for different n) or return a value of 0.  For example, when n = 4124, the function returns 0. It does not revert until n = 4193.  The AMM expects non-zero prices, and non-overlapping bands. The bounds on the possible input values for _p_oracle_up should therefore be narrowed.  Curve - Curve Stablecoin -   17  CorrectnessLowVersion1CodeCorrectedSecurityLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                        \f  The result of the exponential is asserted to be more than 1000, corresponding to a maximum value of n = 3436.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.14   Incorrect Array Length",
        "body": "  The  Stableswap  contract  needs  to  be  initialized  with  a  _coins  array  of  length  4.  However,  only  two values are needed (and can be used), as the maximum number of coins is two.  CS-CRVUSD-017  Specification changed  Curve explained this is intentional to keep compatibility with the factory.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.15   Incorrect Calculations in ",
        "body": " health_calculator  When  calculating  the  health  factor  in  Controller.health_calculator,  the  collateral  value  for  a non-converted deposit is calculated as follows:  CS-CRVUSD-018  collateral = convert(xy[1], int256) + d_collateral n1 = self._calculate_debt_n1(xy[1], convert(debt, uint256), N)  As the function wants to predict the health ratio after the collateral change, n1 should be calculated with d_collateral  included  and  not  on  the  present  value  xy[1].  Later,  p0  is  calculated  to  convert  the collateral into stablecoins. But this is only needed if ns[0] > active_band. The following code block might be written into the first condition checking ns[0] > active_band:  Code corrected  The calculation of n1 has been corrected.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.16   Incorrect Comments",
        "body": "  The following comments contain inaccuracies:   The  NatSpec  of  function  withdraw  says:  Withdraw  all  liquidity  for  the  user.  However, partial withdrawals are also possible.   The  NatSpec  of  function  _get_dxdy  says  that  parameter  amount  is  an  amount  of  input  coin.  In fact,  amount  could  specify  either  an  input  or  an  output  amount,  depending  on  the  function parameter is_in.  CS-CRVUSD-009  Curve - Curve Stablecoin -   18  CorrectnessLowVersion1Speci\ufb01cationChangedDesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                        \fFixed:  The NatSpec have been edited to reflect the actual behavior of the functions.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.17   Meaningful Revert Reasons",
        "body": "  CS-CRVUSD-021  Multiple asserts do not throw a revert reason, making it hard to determine where the code failed while E.g., debugging.  assert  xy[0]  >=  min_x,  \"Sandwich\".  It  might  be  clear  to  developers  but  might  cause  some confusion for anyone else reading the message (e.g., just \"Sandwich\") as a revert reason. Technically, the error is also not necessarily caused by a sandwich attack.  Additionally,   messages   revert   short.   many   quite   are   Specification changed  The \"Sandwich\" revert message was renamed to \"Slippage\". Curve explained that the contract is close to the bytecode limit. The chosen revert messages are the trade-off between bytecode limit and meaningful reverts.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.18   Missing Sanity Checks",
        "body": "  The  following  functions  set  important  parameters  but  have  no  sanity  checks  for  the  arguments.  Even though some are permissioned and called by a trusted account, sanity checks might prevent accidents. E.g.:  CS-CRVUSD-022  In ControllerFactory:   __init__   add_market performs no checks for debt_ceiling.   set_admin   set_debt_ceiling  In AggMonetaryPolicy:   __init__ .. corrected   setRate .. corrected   setAdmin   ConstantMonetaryPolicy has no checks in the setters.  In CryptoWithStablePrice   __init__ for ma_exp_time .. corrected  In PegKeeper:   __init__ the _receiver and _caller_share  Curve - Curve Stablecoin -   19  DesignLowVersion1Speci\ufb01cationChangedDesignLowVersion1CodeCorrected                \fIn the AMM contract:   __init__   set_rate might be a problem when no check in the policy was done.   create_loan might fail earlier for no amounts.  In Stableswap   exchange could perform checks to fail early.  Some sanity checks might be a trade-off between security and performance.  Code corrected  Some of the missing sanity checks were fixed by Curve independently while the audit was ongoing. We assume the issue raised awareness and the sanity checks were added as intended by Curve.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.19   Multiple Calls to the AMM",
        "body": "  In Controller repay and health_calculator, there is the following loop:  CS-CRVUSD-023  for i in range(MAX_SKIP_TICKS):     if AMM.bands_x(active_band) != 0:         break     active_band -= 1  This loop might be executed inside of the AMM contract to avoid an external call in each iteration.  Code corrected  The loop execution was moved from the Controller to the AMM.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.20   No Events",
        "body": "  The following functions perform an important state change but don't emit an event.  In  ControllerFactory:  set_admin,  set_implementations,  set_debt_ceiling, rug_debt_ceiling   ConstantMonetaryPolicy: Does not emit any events at all.   PegKeeper:  Functions  that  apply  and  commit  admin,  commit  and  apply  new  receiver  and  set_new_caller_share .. corrected  CS-CRVUSD-024  Code corrected  Curve - Curve Stablecoin -   20  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                 \fWhile  the  audit  was  ongoing  some  events  have  been  added.  Without  specification,  it  is  unclear  which events  are  intended.  We  assume  the  issue  raised  awareness  and  all  events  have  been  added  as intended.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.21   Non-Indexed Events",
        "body": "  Multiple events allow no filtering for a specific address as they miss indexing. This includes the following examples:  CS-CRVUSD-025   All events in ControllerFactory   SetPriceOracle in AMM   Multiple events in the AggMonetaryPolicy   AddPricePair in AggregateStablePrice   Multiple events in PegKeeper   SetMonetaryPolicy in Controller  Code corrected  Curve indexed multiple events. We assume that after reviewing the events, the current event indexing is the intended indexing as no specification is provided.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.22   Potential Optimization With Immutable",
        "body": " PriceOracle  The  AMM  contract  declares  price_oracle_contract  as  a  public  storage  variable.  This  address  is accessed frequently and cannot be replaced in the current implementation.  However, this public declaration results in a storage access each time the price_oracle_contract is accessed.  Since  this  is  a  frequent  operation  and  price_oracle_contract  cannot  be  overwritten, typing it as an immutable variable could have significant effects on overall gas usage.  CS-CRVUSD-013    The price_oracle_contract variable is now declared immutable.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.23   Potentially Incorrect Admin Fees",
        "body": "  In AMM.exchange the following check is done before the in and out amounts are transferred:  CS-CRVUSD-027  Curve - Curve Stablecoin -   21  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \fif out_amount_done == 0:     return 0  If the trade does not return any tokens, the function returns 0 but does not revert. Before that point, the state variables admin_fees_x and admin_fees_y are incremented.  When  testing,  we  could  not  get  the  system  into  the  desired  state.  Therefore,  we  list  this  as  a  more theoretical low-severity issue.  Code corrected  The admin fees are updated after the potential zero return.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.24   Simpler Calculations Possible",
        "body": "  In the AMM's get_xy_up function, some calculations can be simplified to save gas:  1. The calculation for p_current_mid:  p_current_mid: uint256 = unsafe_div(unsafe_div(p_o**2 / p_o_down * p_o, p_o_down) * Aminus1, A)  CS-CRVUSD-014  This is equivalent to the simpler formula:  pmid =  3  po p \u2193 p \u2191  2. The calculations for y_o and x_o in the general case:  y_o = unsafe_sub(max(self.sqrt_int(unsafe_div(Inv * 10**18, p_o)), g), g) x_o = unsafe_sub(max(Inv / (g + y_o), f), f)  These equations can be simplified to the following expressions:  yo = Ay0(1 \u2212  p \u2193 po  )  xo = Ay0po(1 \u2212  po p \u2191  )    Both suggestions have been implemented.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.25   Superfluous Check",
        "body": "  Under  the  assumption  that  the  AMM  is  always  called  by  the  controller,  the  following  checks  in AMM.deposit_range are not needed because the controller will pass them in ascending order:  CS-CRVUSD-029  Curve - Curve Stablecoin -   22  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \fband: int256 = max(n1, n2) lower: int256 = min(n1, n2)  Code corrected  The checks have been removed as the controller passes sorted values to the AMM.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.26   Superfluous Interface Definitions",
        "body": "  CS-CRVUSD-028  In Stableswap Factory.convert_fees  The following interface definitions were not needed and removed:  In Controller LLAMMA.get_y_up is unused.  In Stablecoin the Controller.admin interface is unused.  In AMM the ERC20's balanceOf function is unused.   The  AggMonetaryPolicy  and  AggregateStablePrice  contracts  implement  the  ERC20  interface but do not use it.   AggregateStablePrice does not use the balances definition of Stableswap   PegKeeper  does  not  use  StableAggregator.stablecoin  and  CurvePool.lp_token  an  ERC20.balanceOf  In Controller LLAMMA.get_base_price and ERC20.totaSupply  In ControllerFactory ERC20.transferFrom  Code corrected  Curve removed most of the unused definitions.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.27   Superfluous Variable Assignment for",
        "body": " Number of Bands  In AMM.deposit_range() the variable n_bands is defined as:  i: uint256 = convert(unsafe_sub(band, lower), uint256) n_bands: uint256 = unsafe_add(i, 1)  The variable dist is defined as  dist: uint256 = convert(unsafe_sub(upper, lower), uint256) + 1  CS-CRVUSD-030  Curve - Curve Stablecoin -   23  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                      \fand upper: int256 = band.  Code corrected  The redundant calculation was removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.28   Unnecessary Subtraction",
        "body": "  In Controller.__init__, the variable Aminus1 is set to _A - 1. Later in the code Aminus1 is not used but recalculated as _A - 1.  CS-CRVUSD-032  Code corrected  The calculation is now done once in __init__ and the variable Aminus1 is reused in the code.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.29   Unused Variables",
        "body": "  In Stableswap we found EXP_PRECISION which is not used in the contract anymore.  CS-CRVUSD-033  Code correct  The unused variable EXP_PRECISION has been removed.  Curve - Curve Stablecoin -   24  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Dirty Wipe",
        "body": "  The state variable AMM.user_shares is never completely cleared. Only the first values are emptied to indicate the user has no shares anymore. The other values are not accessible but remain in storage until they are overwritten. This is more gas efficient if the user wants to deposit again, and we could not find a way  to  access  the  outdated  values.  Still,  this  might  be  worth  keeping  in  mind  as  future  code  changes might make the values accessible.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Exchange Does Not Revert if It Did Not",
        "body": " Succeed  When exchanging on an empty LLAMMA or the desired token has no balance, there is no error message for the exchange transaction.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Liquidate Callback Passes Address of the",
        "body": " Liquidated User  In the Controller's _liquidate function, the execute_callback function is called with the user set as the address being liquidated, not the liquidator (msg.sender). Special care has to be taken by callback contracts to know the initiator of the liquidation.  CS-CRVUSD-003  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   Lost Dust Balance on Exchange",
        "body": "  In  the  presence  of  dust  balances  in  an  AMM  band,  the  _get_y0()  calculation  can  return  0.  The consequence is that the band content is not traded because f == 0 if dumping and g == 0 if pumping, which causes the exchange code for the band in calc_swap_in and calc_swap_out to be skipped even if some balance is present. When the DetailedTrade struct is inspected in _exchange(), it is assumed  no  amount  of  out  token  is  left  in  the  bands  between  the  trade  start  and  the  last  band.  This means that the dust balance that was in the bands where _get_y0() == 0 is forgotten, and its value becomes untransferable.  CS-CRVUSD-011  An  to  _get_y0(1, 1, int(1000e18), int(1000e18*1.01**1)) == 0.  _get_y0()   example   state   for   equal   0   is  Curve - Curve Stablecoin -   25  NoteVersion1NoteVersion1NoteVersion1NoteVersion1              \fAs the client states, this doesn't prevent from trading over that band. The small amount of dust lost does not affect the operation otherwise.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   Magic Numbers and Constants",
        "body": "  Some \"magic numbers\" are used in the code. For example, in ControllerFactory.vy, the collaterals index is updated as follows:  for i in range(1000):     if self.collaterals_index[token][i] == 0:         self.collaterals_index[token][i] = 2**128 + N         break  We recommend defining all such numbers as constants with clear names.  Ideally, how these constants are picked should also be described. For example, it was not clear how a MAX_RATE of 43959106799 corresponds to 400% APY (as commented), or why MAX_TICKS = 50 and MAX_SKIP_TICKS = 1024 are appropriate values.  Also, the number of decimals (10**18) is often hardcoded.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.6   Max Band Over-Estimates the Actual Maximal",
        "body": " Band  The max_band variable which tracks the maximum band of the AMM might not be decreased to the actual maximum band with liquidity when liquidity is withdrawn. max_band only provides an upper bound on the bands which could currently hold liquidity, but could overstate it. This has no visible effect except making swaps that exhaust all the available liquidity more gas expensive.  CS-CRVUSD-012  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.7   Min Band Update",
        "body": "  The min and max band indicate in which range liquidity is provided. Everything above and below should be  empty.  In  withdraw  the  min  and  max  bands  are  updated.  In  case  a  user  who  has  liquidity  in  the lowest  ticks  withdraws  their  liquidity,  the  min  band  is  set  to  the  former  max  band  n[1]  of  this  user. Hence, min band guarantees that there is no liquidity below it but it's not the lowest band with liquidity.  Similarly, the max band will not be decreased if a single user owns all the liquidity in all of their bands, and max_band == n[1]. In this case, max_band will not be changed when they withdraw their funds.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.8   Peg Keeper Assumptions",
        "body": "  The Peg Keeper actions will always balance a pool. This implies a constant 1:1 target ratio, assuming that no token loses its peg. Events have shown, however, that stablecoins can lose their peg and even  Curve - Curve Stablecoin -   26  NoteVersion1NoteVersion1NoteVersion1NoteVersion1                \fbecome quite volatile. It might be beneficial to have additional security mechanisms in place to monitor and pause the actions of a peg keeper.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.9   Sandwiching Peg Keeper Actions",
        "body": "  The Peg Keeper acts on the simple condition of an unbalance pool combined with some sanity checks on the  post-price  changes.  As  the  pool  balances  can  easily  be  manipulated  with  flash  loans  and  the  Peg Keeper acts in a deterministic way without slippage protection, this action is prone to be sandwiched in an attack. Yet, we could not think of a scenario that would directly hurt the audited system itself. In all scenarios,  the  Peg  Keeper  will  balance  the  pool  in  the  \"correct\"  direction  (balancing  the  pool).  This  is usually beneficial and not harmful to the system.  Even  though  the  actions  of  the  Peg  Keeper  should  be  monitored  closely,  it  might  be  beneficial  to  add security  mechanisms  to  pause  the  Peg  Keeper's  actions  and  absolute  investment  limits  instead  of relative ones.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.10   Use of LLAMMA Price",
        "body": "  The  LLAMMA  price  is  easy  to  manipulate.  The  price  and  the  functions  AMM.get_p()  and Controller.amm_price (that return the price) should not \u2014 or very carefully \u2014 be used in any critical operation. Especially, in third party contracts querying this information.  Curve - Curve Stablecoin -   27  NoteVersion1NoteVersion1        \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Code With No Effect",
        "body": "  In  UniswapV3LiquidityPositionLib.__mint,  token0  and  token1  are  overwritten  by  their  own value, hence this code has no effect.   The related assignments have been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Missing Sanity Check",
        "body": "  NonfungiblePositionManager   Upon  UniswapV3  LP  external  position  creation,  sorting  of  token0  and  token1  is  not  enforced. UniswapV3  sorted (address(token0)  <  address(token1)),  otherwise  the  transaction  will  revert.  This  means  that  a non-functional  external  position  can  be  instantiated.  For  example,  passing  non-sorted  tokens  to NonfungiblePositionManager.mint will revert on PoolAddress.computeAddress which requires the tokens to be sorted.  tokens   needs   the   be   to     Ordering of the tokens is now enforced on the external position initialization.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Redundant Deadline",
        "body": "  Avantgarde Finance - Sulu Extensions -   10  CriticalHighMediumLowCodeCorrectedCodeCorrectedCodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \fWhen  UniswapV3LiquidityPositionLib._removeLiquidity  is  called,  the  deadline  is  set  to block.timestamp + 1. This is not needed since the call to the NonfungiblePositionManager is part of an already executing transaction.    +1 has been removed.  Avantgarde Finance - Sulu Extensions -   11  \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   PoolTogether V4 Early Exit Fee",
        "body": "  Upon redeem, PoolTogetherV4 is assumed to have no penalty fee for early withdraws as described in https://docs.pooltogether.com/faq/v3-to-v4-differences.  An  exit  fee  like  in  V3  could  prevent  the  fund manager  to  withdraw  from  PoolTogetherV4.  More  specifically,  pools  that  make  use  of  PrizePool  are assumed get the full amount requested on withdrawal. When the PrizePool.withdrawFrom is called, the  amount  to  be  redeemed  is  calculated  using  _redeem  internal  function.  In  the  case  of PrizePool._redeem, this function calls one of the yield sources implementations which determines the actual amount to be redeemed. Should such a yield source return a redeemed amount that is less than the amount initially requested, the call on integration will fail.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Price Oracle Discrepancies",
        "body": "  In order to calculate the value of a position the actual price between the two tokens is required. For this, the default oracles for the two tokens are used. We assume that there are no big discrepancies between the actual price of the Uniswap pool for the specific pair and the price calculated by the system.  Avantgarde Finance - Sulu Extensions -   12  NoteVersion1NoteVersion1      \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   ZkBobPool Withdrawal Sandwich Attack",
        "body": "  When the withdrawal with native_amount is submitted to the ZkBobPool, the sale of tokens for ETH happens using the UniswapV3Seller contract. However, the amountOutMinimum parameter of this swap is 0. A potential attacker can place orders that would manipulate the price, forcing the sellForETH trade  to  be  executed  with  a  bad  price.  Thus,  due  to  the  lack  of  spread  control,  any  use  of UniswapV3Seller can result in a bad trade, allowing price manipulators to pocket the profit from this trade.  Risk accepted:  BOB Protocol responded:  This  feature  is  only  intended  to  swap  small  amounts  of  tokens,  purely  for  funding  wallets  with  gas tokens. UI will strongly dissuade users for doing swaps that are larger than e.g. 100$ in value. Added a warning comment to the sellForETH function.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   BaseERC20 Overflow",
        "body": "  BOB Protocol - zkBob -   10  SecurityDesignCorrectnessTrustCriticalHighMediumRiskAcceptedLowRiskAcceptedRiskAcceptedRiskAcceptedDesignMediumVersion1RiskAcceptedCorrectnessLowVersion1RiskAccepted                    \fThe _increaseBalance function of the BaseERC20 contract can overflow. While it is checked that the account  is  not  frozen  (i.e.  the  first  bit  of  the  balance  is  zero),  it  is  not  guaranteed  that  the  addition  will result in a number smaller than 2^255. Hence, an account could become frozen by increasing its balance above this value.  Risk accepted:  Assuming  a  reasonable  total  supply  of  the  token  (less  than  2^255),  it  is  impossible  for  any  individual account  to  have  a  balance  large  enough  to  cause  this  overflow  to  happen.  Thus,  the  overflow  cannot occur under normal circumstances.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   Daily Limits Can Be Avoided",
        "body": "  If the MutableOperatorManager is used and the operator variable is set to 0, then effectively every user becomes an operator / relayer. This means that any user could spread funds between multiple addresses and easily avoid the daily limits imposed by the ZkBobAccounting contract.  Risk accepted:  BOB Protocol accepts the risk regarding users avoiding daily limits and states:  Allowing  users  to  submit  transactions  themselves  introduces  multiple  potential  problems,  including the one described with the limits. For now, it can be assumed that deposit transactions might only go through  the  chosen  relayer,  which  is  also  responsible  for  detecting  abnormal  limit  usage.  Even though we cannot assume that one address is equal to one user, we think that making per-address limits in the contract can still be useful in certain use-cases.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.4   ERC20Permit.receiveWithPermit Signature",
        "body": " Can Be Front-Run  Similar  to  issue  ERC20Permit.receiveWithSaltedPermit  signature  can  be  front-run,  the  signatures between  ERC20Permit.permit  and  ERC20Permit.receiveWithPermit  are  interchangeable  as well.  Thus, the attacker can front-run the signatures and use them in unintended functions to cause a user's transactions  to  fail.  However,  this  does  not  render  the  ZkBob  system  unsecure  itself  but  might  cause problems for 3rd party integrations. Thus, the severity of this issue is low.  Risk accepted:  BOB Protocol accepted the risk and stated:  Third  party  integrations  relying  on  permit/receiveWithPermit  are  advised  to  implement  necessary fallbacks for failing permit/receiveWithPermit calls, avoiding entire transaction failures.  BOB Protocol - zkBob -   11  TrustLowVersion1RiskAcceptedDesignLowVersion1RiskAccepted                  \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings   ZkBobPool Fees Can Drain the Deposits of the User   -Severity Findings   ERC20Permit.receiveWithSaltedPermit Signature Can Be Front-Run   -Severity Findings   Admin Reentrancy in ERC20Recovery    Avoiding Recovery by Admin    BobVault Uint Conversions    Missing Sanity Checks    No Events on State Changes   0  1  1  5  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   ZkBobPool Fees Can Drain the Deposits of the",
        "body": " User  When depositing using the transact function, the caller can specify a negative token amount. Normally, this would revert as it is checked that the deposit amount is positive. However, if the user also specifies the  fee  to  be  greater  than  the  absolute  value  of  the  deposit  amount,  the  total  token_amount  will  be positive, hence passing the check. Thus, the deposit will go through. This can be exploited by a malicious operator in the following scenario:  1. Operator (msg.sender) specifies txType = 0 (deposit), _transfer_token_amount = -400,  fee = 500.  2. Computed token_amount will be 100.  3. 100 * TOKEN_DENOMINATOR will be transferred to the ZkBobPool from the user address.  4. accumulatedFee[msg.sender] will be increased by 500.  5. Operator withdraws 500 * TOKEN_DENOMINATOR of fees.  Thus, by depositing only 100 tokens malicious operator was able to withdraw 500 tokens as fees. The malicious operator can drain the contract via the fees.  Note  that  the  transact  function  is  only  callable  by  the  privileged  Operator  role.  However,  the OperatorManager contracts can be configured such that every user would be an operator.    BOB Protocol - zkBob -   12  CriticalHighCodeCorrectedMediumCodeCorrectedLowCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedSecurityHighVersion1CodeCorrected        \fBOB Protocol confirmed that the case of asset drain was prevented by the verifier and the snark circuits which  are  out  of  scope  for  this  engagement.  However,  the  deposit  of  a  negative  value  still  could  have been  used  as  an  undesired  withdrawal.  Stronger  checks  were  introduced,  namely  a  requirement  that _transfer_token_amount  must  be  positive  for  deposits.  The  check  during  the  withdrawal  correctly constrains  the  token_amount,  since  otherwise  the  same  issue  would  occur  in  the  other  direction  -  a small negative _transfer_token_amount + big positive fee can be positive, causing a withdrawal to count as a deposit.  The full response of BOB Protocol team:  This confusing case is handled correctly by the verifier and snark circuits.  During usual deposit, the following happens:  1. User deposit amount is 400 (_transfer_token_amount is 400)  2. Relayer adds a 100 fee on top  3. Pool contract executes transferFrom for 500 (400 + 100) tokens  4. User shielded balance is increased by _transfer_token_amount (400), which is verified by the  circuit verifier  5. Relayer receives a 100 fee  6. So 500 transferred tokens were divided between user (+400) and relayer (+100)  During the suggested negative deposit, the following happens:  1. User deposit amount is -400 (_transfer_token_amount is -400, better to think of it as a balance  delta, rather than deposit amount)  2. Relayer adds a 500 fee on top  3. Pool contract executes transferFrom for 100 (-400 + 500) tokens  4. User shielded balance is increased by _transfer_token_amount (-400), which is verified by the circuit verifier. As the balance delta is negative, the balance is actually being decreased by 400.  5. Relayer receives a 500 fee.  6. In  the  end,  relayer  receives  500  tokens,  comprised  of  user  shielded  balance  decrease  (400)  and external token transfer (100)  7. Essentially, this turned a deposit into a very strange version of withdrawal  Although balance accounting works correctly here, this situation is indeed very confusing. It cannot be triggered via the UI or SDK, as it just does not make sense for users to do something like that. To get  rid  of  this  unnecessary  source  of  confusion,  we  will  introduce  a  bit  stricter  validation  on  the deposit amounts, so that negative _transfer_token_amount are not allowed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   ERC20Permit.receiveWithSaltedPermit",
        "body": " Signature Can Be Front-Run  The  ZkBobPool  permittable  deposit  relies  on  the  ERC20Permit.receiveWithSaltedPermit function.  However,  the in  ERC20Permit.saltedPermit  function  as  well.  An  attacker  can  intercept  the  deposit  transaction, extract the signature and use it in the call to saltedPermit. As a result of this action, the permittable deposit  will  fail  due  to  the  nonce  already  having  been  used.  Thus,  the  attacker  can  front-run  the signatures and use them in unintended functions to cause a user's transactions to fail.  signature   function   used   used   can   this   the   be   in   BOB Protocol - zkBob -   13  DesignMediumVersion1CodeCorrected        \f  The  saltedPermit  function  was  removed.  Hence,  a  permittable  transaction  can't  be  front-run  with  a call that uses the same signature for another function.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Admin Reentrancy in ERC20Recovery",
        "body": "  The  executeRecovery  function  in  ERC20Recovery  can  only  be  called  by  the  owner  or  the  recovery admin. When recovering the tokens, they are transferred to the recoveredFundsReceiver address. If this address is a contract, the onTokenTransfer function is called. This call could be used to reenter the  executeRecovery  function  in  order  to  double-claim  the  funds  to  recover.  This  would  allow  the recovery admin or the owner to exceed the intended recoveryLimit.  As  the  recoveredFundsReceiver  can  only  be  set  by  the  owner,  and  both  the  owner  and  recovery admin are trusted addresses, the impact of this issue is limited.    The recoveryRequestExecutionTimestamp and recoveryRequestHash are now deleted before any external calls are made. Hence, if a reentrant call later calls executeRecovery again, there will be no stored timestamp or hash, so the funds can't be double-claimed anymore.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Avoiding Recovery by Admin",
        "body": "  a   that   user   sees   (using account  If  ERC20Recovery.requestRecovery()),  they  can  simply  transfer  funds  to  another  account  to  stop them from being recovered. It may also make sense from the perspective of trustworthiness to only allow recovery  of  funds  e.g.  if  the  account  is  already  frozen,  or  at  least  enforcing  that  an  account  must  be frozen in order to recover its funds.  recovery   marked   their   for   is   Specification corrected:  BOB Protocol responded:  Recovery  functionality  is  intended  to  be  used  only  on  dormant  or  non-existing  users,  if  the  user  is able  to  move  his  funds  to  a  different  address,  his  token  should  not  be  allowed  for  recovery. Recovering  frozen  is  a  different  use-case,  although  it  can  be  also  executed  through  the  same functionality.  With  the  assumption,  that  the  proper  checks  will  be  performed  before  account  recovery,  this  issue  is resolved.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   BobVault Uint Conversions",
        "body": "  BOB Protocol - zkBob -   14  SecurityLowVersion1CodeCorrectedDesignLowVersion1Speci\ufb01cationChangedDesignLowVersion1CodeCorrected                        \fTo track the token.balance the BobVault contract uses uint128 values. Theoretically, it is possible to provide a value that is great than type(uint128).max. This case will not be handled correctly by the code due to the unsafe conversion to uint128, which truncates the value. As a result, internal accounting will be broken. This happens in multiple functions such as: buy, sell, swap, give.  token.balance += uint128(sellAmount);  The amount before conversion in most cases is used as an argument for token transfer. However, the practical safety of this conversion depends on the external contract, which is not optimal.    BOB Protocol responded:  Although  such  extremely  high  amounts  won\u2019t  be  seen  in  practice,  we  added  additional  overflow checks where necessary.  The checks were introduced in buy, swap, give. Check performed in sell is sufficient to prevent the overflow.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Missing Sanity Checks",
        "body": "  Many  state-changing  operations  do  not  include  sanity  checks  to  ensure  incorrect  values  are  not  set. Consider adding checks to ensure these values aren't accidentally set incorrectly. This can happen e.g. due to a bug in a front-end application resulting in empty values in calldata.  These operations include:  ERC20Blocklist:   updateBlocklister() does not check that _newBlocklister is not address(0).  ERC20Recovery:   setRecoveryAdmin() does not check that _recoveryAdmin is not address(0).   setRecoveredFundsReceiver()  does  not  check  that  _recoveredFundsReceiver  is  not  address(0).  Claimable:   setClaimingAdmin does not check that _claimingAdmin is not address(0).  ZkBobPool:   constructor() does not check any of the provided addresses.   initialize() does not check that _root is not 0.   setTokenSeller() does not check that _seller is not address(0).   setOperatorManager() does not check that _operatorManager is not address(0).  BobVault:   constructor() does not check that _bobToken is not address(0).   setYieldAdmin() does not check that _yieldAdmin is not address(0).   setInvestAdmin() does not check that _investAdmin is not address(0).  BOB Protocol - zkBob -   15  DesignLowVersion1CodeCorrected        \f  Checks  were  added  where  necessary.  Explanation  was  added  why  certain  cases  do  not  need  sanity checks.  BOB Protocol responded:  We added a few sanity checks in places there we think they might be important:   ZkBobPool: constructor(), initialize(), setOperatorManager()   BobVault: constructor()  In other places, zero addresses are used for unsetting the specific privileges and rights:   ERC20Blocklist:  updateBlocklister()  \u2013  zero  address  is  used  to  limit  the  ability  to  block/unblock  accounts only by the governance.   ERC20Recovery: setRecoveryAdmin() \u2013 zero address is used to limit the ability to recover funds only  by  that recoveredFundsReceiver  is  not  zero  in  _remainingRecoveryLimit  (link)  so  it  is  safe  to  not introduce additional checks  the  governance.  setRecoveredFundsReceiver()  \u2013   is  a  check   there    Claimable: setClaimingAdmin() \u2013 zero address is used to limit the ability to claim tokens only by  the governance.   ZkBobPool: setTokenSeller() \u2013 zero address is used to disable the ability for users to swap small  amount of BOB tokens to MATIC during the withdrawal process.   BobVault: setYieldAdmin() - zero address is used to limit the ability to collect generated yield by the governance; setInvestAdmin() \u2013 zero address is used to limit the ability invests tokens into the yield provider only by the governance.  Moreover,  these  functions  should  only  be  called  by  the  admin  via  governance  process  (e.g.  from Safe UI), making real UI typos very unlikely to happen.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   No Events on State Changes",
        "body": "  Many  state-changing  operations  do  not  emit  events.  Consider  emitting  events  for  important  state changes.  These operations include:  ZkBobPool:   initialize()   setTokenSeller()   setOperatorManager()  ZkBobAccounting:   _setLimits()   _resetDailyLimits()   _setUsersTier()  BobVault:   setYieldAdmin()  BOB Protocol - zkBob -   16  DesignLowVersion1CodeCorrected        \f setInvestAdmin()  MutableOperatorManager:   _setOperator()  ERC20Recovery:   setRecoveryAdmin()   setRecoveredFundsReceiver()   setRecoveryLimitPercent()   setRecoveryRequestTimelockPeriod()  Claimable:   setClaimingAdmin()    Events were added to the following functions:  ZkBobPool:   setTokenSeller()   setOperatorManager()   withdrawFee()  ZkBobAccounting:   _setLimits()  MutableOperatorManager:   _setOperator()  The remaining functions are either not expected to be called regularly, or it was deemed unimportant for the functions to emit events.  BOB Protocol - zkBob -   17  \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   BobVault.disableCollateralYield Potential",
        "body": " Reentrancy  The  token  buffer,  dust  and  yield  fields  are  updated  after  the  external  call.  If  the  yield  contract  has  a reentrancy point, where BobVault can be called again - this update can happen in an invalid state. The external calls should happen after all the state variable updates.    Statements were reordered to make the reentrancy impossible.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   ERC20Permit Deletes Existing Approvals",
        "body": "  Using any of the public functions in ERC20Permit will zero out any pre-existing approval a user may have had  from  the  signer.  Hence,  a  user  should  use  any  existing  approval  from  the  signer  before  calling permit or its variations.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Incorrect Comment",
        "body": "  In the CustomABIDecoder contract, the _memo_fixed_size function features the following comment:  else if (t == 2) {     // fee + recipient + native amount     // 8 + 20 + 8     r = 36; }  in   However,  is  actually ... | fee | native_amount | receiver | .... The given sizes for the fields are correct (but also in the wrong order).  the  case  of  a  Withdraw  operation   in  calldata   the  order     The comment was fixed.  BOB Protocol - zkBob -   18  NoteVersion1NoteVersion1NoteVersion1            \f7.4   Reentrant Tokens  The BobVault contract should not use any tokens with reentrant transfers, such as an ERC777 token, as collateral.  This  could  lead  to  inconsistent  event  orderings  or  potentially  more  severe  issues.  This  audit was performed with the assumption that any tokens used as collateral do not have reentrant functionality.  Similarly,  the  ZkBobPool  contract  should  not  use  an  underlying  token  with  reentrant  calls,  as  it  would open  up  critical  vulnerabilities  such  as  draining  the  contract's  balance  through  the  withdrawFee function.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   Unused Constant",
        "body": "  In CustomABIDecoder.sol, the sign_r_vs_size constant is defined but never used.  BOB Protocol responded:  We  won\u2019t  delete  the  constant,  as  keeping  it  does  not  impact  the  size/gas  cost  of  the  produced bytecode (most likely it is being pruned by the optimizer), but it might become useful in the future, for adding more extra fields.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.6   Unused Return Data in YieldConnector",
        "body": "  The  YieldConnector's  _delegateFarmExtra  function  does  not  return  anything,  even  though  the farmExtra function of the IYieldImplementation interface returns a bytes type.  Similarly,  the  claimTokens  function  of  the  Claimable  contract  does  not  check  the  return  value  of IERC20(_token).transfer(_to,  balance).  Hence,  false  could  be  returned  (meaning  the transfer did not actually take place).    BOB Protocol responded:  Acknowledged  and  added  missing  function.  The _delegateFarmExtra()  function  is  unused  in  the  context  of  existing  AAVE  deployments,  however,  it to might  be  used  IERC20(_token).transfer(_to,  balance)  in  the  Claimable  contract  are  only  intended  to  be  executed within the manual governance process, thus actual transfer result does not imply any considerable impact on the system.  (e.g.  Compound).  Calls   return  statement   lending  markets   integrations   farmExtra()   for  other   from   BOB Protocol - zkBob -   19  NoteVersion1NoteVersion1NoteVersion1          \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   extract32's Input Is Not Cached",
        "body": "  The  input  b  of  the  built-in  extract32  is  not  cached  but  instead,  only  its  location  and  length  are.  This means that if the evaluation of the argument start's side effect leads to the modification of b, the result of extract32 could be inconsistent and access memory out of bounds.  CS-VYPER_DECEMBER_2023-001  Vyper - Vyper Compiler -   11  DesignCorrectnessCriticalHighMediumLowCorrectnessMediumVersion1              \fexample,   foo  For  b'uuuuuuuuuuuuuuuuuuuuuuuuuuu\\x00\\x00789'  function   calling   the   of   the   following   contract   returns  var:Bytes[96]  @internal def bar() -> uint256:     self.var = b'uuuuuuuuuuuuuuuuuuuuuuuuuuuuuu'     self.var = b''     return 3  @external def foo() -> bytes32:     self.var = b'abcdefghijklmnopqrstuvwxyz123456789'     return extract32(self.var, self.bar(), output_type=bytes32)     # returns b'uuuuuuuuuuuuuuuuuuuuuuuuuuu\\x00\\x00789'  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Assertion Error _abi_encode With Invalid",
        "body": " Method ID  If _abi_encode is given a literal method ID that is not 4 bytes long, the compiler will fail on an assertion in  _parse_method_id  during  code  generation  instead  of  failing  at  type-checking  time  with  some meaningful error message.  The following contract would fail to compile with an AssertionError:  CS-VYPER_DECEMBER_2023-002  @external def foo():     a:Bytes[68] = _abi_encode(b'', method_id=b'')  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   Buffer Too Large in ",
        "body": " create_minimal_proxy_to  In  CreateMinimalProxyTo._build_create_IR(),  the  buffer  buf  uses  128  bytes  of  memory, however, MSTORE is performed at buf, buf + 19 and buf + 39. This means that a buffer of length 96 would be sufficient to store the whole creation bytecode.  Note  that  although  the  bytecode  stored  in  the  buffer  is  only  54  bytes  long,  a  buffer  of  64  bytes  is  not sufficient because the last MSTORE is unaligned and would write to the next 32-byte word.  CS-VYPER_DECEMBER_2023-003  Vyper - Vyper Compiler -   12  DesignLowVersion1DesignLowVersion1              \f5.4   Builtins Fail to Compile With Empty  ByteStringT  In  general,  BytesT  and  StringT  IR  nodes  are  assumed  to  be  locations  to  values  of  the  mentioned types. However, the special value empty(...) is not and is treated as a special case by the compiler.  The  compiler  fails  compilation  when  the  given  builtins  are  given  empty  ByteString:  concat, extract32 and slice.  The compilation of the following three contracts respectively fails with the following errors:  CS-VYPER_DECEMBER_2023-004   CompilerPanic: tried to modify non-pointer type   AssertionError: ~empty <empty(Bytes[32])>   AttributeError: 'NoneType' object has no attribute 'load_op'  @external def baz() :     a:String[32] = concat(empty(String[31]), \"a\")  @external def foo() :     a:Bytes[32] = slice(empty(Bytes[32]), 0, 1)  @external def bar() :     a:uint256 = extract32(empty(Bytes[32]), 0, output_type = uint256)  Note that for both extract32 and slice, if it wasn't for this issue, either the compilation would fail, or the execution would revert as slicing/extracting 32 bytes from an empty byte array is not possible.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.5   Condition Always True in raw_call",
        "body": "  In RawCall.fetch_call_return(), the following if block is always evaluated since if outsize is None or 0, the function is returning earlier.  CS-VYPER_DECEMBER_2023-005  if outsize.value:     return_type = BytesT()     return_type.set_min_length(outsize.value)      if revert_on_failure:         return return_type     return TupleT([BoolT(), return_type])  Vyper - Vyper Compiler -   13  DesignLowVersion1DesignLowVersion1            \f5.6   Delegate or Static raw_call With Value  Although both EVM's delegatecall and staticcall opcode cannot be given some value to be sent with  the  call,  raw_call  does  not  prevent  having  a  non-null  value  when  is_delegate_call  or is_static_call is set to true. Note that the value is then ignored when generating IR/bytecode for the call.  CS-VYPER_DECEMBER_2023-006  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.7   Expression Builtins Are Treated as",
        "body": " Statements  The following builtins are in STMT_DISPATCH_TABLE although they cannot be used as statements since they return a value:  CS-VYPER_DECEMBER_2023-007   create_minimal_proxy_to   create_forwarder_to   create_copy_of   create_from_blueprint  Although using them as statements will currently raise a StructureException, it would be better to remove them from STMT_DISPATCH_TABLE altogether.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.8   Imprecise Out-Of-Bounds Check for slice",
        "body": "  In the function Slice.fetch_call_return, when is_adhoc_slice is false and start_literal is not None, the following check is performed:  CS-VYPER_DECEMBER_2023-008  if start_literal > arg_type.length:     raise ArgumentException(f\"slice out of bounds for {arg_type}\", start_expr)  To be more precise, one could also raise if start_literal == arg_type.length.  The following contract currently compiles (but calling foo() reverts) although the slice can be inferred to be out of bounds at compile time:  @external def foo():     a:String[3] = \"foo\"     l: uint256 = 1     b:String[3] = slice(a,3,l)  Vyper - Vyper Compiler -   14  DesignLowVersion1DesignLowVersion1DesignLowVersion1                  \f5.9   Inconsistent Folding of keccak256  Although the built-in keccak256 function should only accept StringT, bytes32 and BytesT types, it also accepts bytesN where N!=32 provided that the node is folded. In other words, the semantics of the built-in differ when it is folded or not.  CS-VYPER_DECEMBER_2023-009  @external def foo():     v:bytes1 = 0x12      a:bytes32 = keccak256(0x12) # compiles     b:bytes32 = keccak256(v) # does not compiles     c:bytes32 = keccak256(0x1111111111111111111111111111111111111111111111111111111111111111111111) # compiles  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.10   Inconsistent Folding of len",
        "body": "  The built-in len can be folded when given some literal Hex node but the compilation fails if given some non-literal bytesN as the type is not accepted.  CS-VYPER_DECEMBER_2023-010  @external def foo():     a:uint256 = len(0x12) # compiles     x:bytes1 = 0x12     b:uint256 = len(x) # does not compile  Moreover,  no  restriction  is  enforced  on  the  length  of  such  literal  Hex  nodes  when  used  in  len,  which could mean that there is a Hex value for which no Vyper type can be inferred (The program would not compile if it wasn't for folding).  @external def foo():     # length of 35 is not allowed for bytesN     a:uint256 = len(0x1111111111111111111111111111111111111111111111111111111111111111111111)  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.11   Inconsistent Folding of shift",
        "body": "  The  built-in  shift  only  accepts  non-negative  values  x  when  folding  is  performed  but  in  the  case  the operation is done at runtime, any (negative) int256 value is accepted.  CS-VYPER_DECEMBER_2023-011  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.12   Incorrect Error Message",
        "body": "  CS-VYPER_DECEMBER_2023-012  Vyper - Vyper Compiler -   15  DesignLowVersion1DesignLowVersion1DesignLowVersion1DesignLowVersion1                      \fExtract32.infer_kwarg_types()  may  raise  an  InvalidType  exception  if  output_type  is  not valid,  says the  \"Output  type  must  be  one  of  integer,  bytes32  or  address\"  although  any  bytesX  is valid.  however,   message   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.13   Incorrect Type Checking for slice",
        "body": "  CS-VYPER_DECEMBER_2023-013  When providing to the builtin slice a byte array which is an Attribute AST node whose attribute is code (for example a struct field access), the function Slice.fetch_call_return will misunderstand the  byte  array  as  msg.code  (is_adhoc_slice  evaluates  to  true),  leading  to  several  checks  being missed.  In  the  current  state  of  the  compiler,  this  is  not  an  issue  because  of  #3521_  as  the  compilation  would revert  with  a  TypeCheckFailure.  However,  if  the  issue  is  fixed  with  PR3527,  the  issue  described above would arise.  For example in the following contract, assuming that PR3527 is merged, the declaration of b will compile, but the declaration of c will not.  struct A: code: String[4] not_code: String[4]  @external def foo() -> uint256:     a:A = A({code: \"abc\",not_code: \"abc\"})     b:String[4] = slice(a.code, 1,0) # compiles     c:String[4] = slice(a.not_code, 1,0) # does not compile     return b  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.14   Redundant Validation _abi_decode",
        "body": "  CS-VYPER_DECEMBER_2023-014  In  ABIDecode.infer_arg_types(),  self._validate_arg_types()) is called just before and performs the same validation  to  validate_call_args()   the  call   is  redundant  as  validate_call_args(node, expect_num_args, list(self._kwargs.keys()))  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.15   Unused Allocated Memory in raw_call",
        "body": "  In  the  case  raw_call  is  given  max_outsize=0,  the  function  RawCall.build_IR  still  allocates  32 bytes for output_node. This is not necessary and could be avoided.  CS-VYPER_DECEMBER_2023-015  Vyper - Vyper Compiler -   16  CorrectnessLowVersion1DesignLowVersion1DesignLowVersion1                    \f5.16   extract32 and slice With Transient Storage  In the builtins extract32 and slice, given that storage is addressed in words, some custom logic is implemented  when  the  given  buffer  lives  in  the  storage  as  opposed  to  other  locations  that  are  byte addressable.  Since  transient  storage  will  also  be  addressed  in  words,  a  similar  logic  should  be implemented for buffer in transient storage.  CS-VYPER_DECEMBER_2023-016  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.17   shift's Incorrect Return Type",
        "body": "  The  class  Shift  defines  _return_type  as  UINT256_T  but  is  never  used  since BuiltinFunctionT.fetch_call_return()  is  overridden  by  Shift  to  return  the  type  of  the argument x which can differ from UINT256_T.  it   CS-VYPER_DECEMBER_2023-017  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.18   sqrt Colliding Fresh Variables",
        "body": "  The built-in sqrt calls generate_inline_function to compile some piece of Vyper code to IR using a  new  context.  As  the  context  is  new,  the  fresh_varname  counter  is  reset  and  does  not  follow  the counter  of  the  initial  context.  This  can  lead  to  the  collision  of  variables,  as  shown  in  the  following examples where the loop iterators are colliding and leading to the compiler panicking:  CS-VYPER_DECEMBER_2023-018  @external def foo() : # the loop iterator variable of each sqrt's loop collide a:decimal = sqrt(sqrt(100.0))  @external def foo() : # The loop iterator of sqrt collides with the range iterator for i in range(10):     a:decimal = sqrt(100.0)  Vyper - Vyper Compiler -   17  DesignLowVersion1DesignLowVersion1DesignLowVersion1                \f6   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   EIP1167 Bytecode Sanity Checks",
        "body": "  CS-VYPER_DECEMBER_2023-019  The  function  eip1167_bytecode  returns  the  EIP1167  bytecode  as  well  as  a  \"loader\"  used  to  deploy the bytecode. As the resulting bytecode is known and should be constant across Vyper versions, having sanity checks comparing the different outputs of assembly_to_evm with hardcoded bytecode could be a good failsafe.  Moreover,  the  length  of  different  bytecode  sections  is  used  (e.g  0x2D,  the  sum  of  the  lengths  of  the forwarder_pre_asm, the address and the forwarder_post_asm), having sanity check that makes sure that such literal integer is indeed equal to the length of the given bytecode section would increase both readability and maintainability of the code.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   extract32 Unnecessarily Complex",
        "body": "  the  built-in  Extract32.buildIR  seems  unnecessarily  complex  and  could  probably  be  simplified similarly to the slice slice. In particular, for locations that are byte-addressable when start is not word aligned,  the  use  of  a  helper  like  copy_bytes  could  avoid  the  need  for  loading  two  words  and  then masking and shifting.  CS-VYPER_DECEMBER_2023-020  Vyper - Vyper Compiler -   18  InformationalVersion1InformationalVersion1      \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Missing Input Sanitization",
        "body": "  1. The addresses in the constructor of GovernorV3 are not sanitized.  CS-GEARGOV-002  2. The   addresses   and GovernorV3.updateVetoAdmin()  are  not  sanitized.  Even  though  the  veto  admins  are expected to prevent setting addresses wrong, the contract logic should also prevent it.  GovernorV3.addQueueAdmin()   given   to   3. The eta parameter of the GovernorV3.queueTransaction is only sanitized by the Timelock contract as to whether the execution time is beyond some minimum required delay. Moreover, an action can be executed within a time window. However, there's no check on whether all the batched actions can be executed within the same window. Thus, a batch could be submitted but not be able to be executed.    In version 2, the eta is defined on a per-batch basis. All transactions in the batch should have the same eta.  Gearbox - Gearbox V3 Governance -   11  CriticalHighMediumLowCodeCorrectedDesignLowVersion1CodeCorrected        \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Veto Admin Can Veto Its Own Update",
        "body": "  In  the  GovernorV3  (Governor  in  V2)  contract,  with  the  assumption  that  vetoAdmin  is  a  multisig requiring fewer signatures than the queueAdmins, it is theoretically easier to compromise vetoAdmin rather  one  of  the  queueAdmin.  If  some  keys  of  the  vetoAdmin  multisig  are  compromised,  all  the queued  transactions  could  be  vetoed  including  a  veto  admin  update.  This  issue  is  only  relevant  if  the multisig does not allow the rest of the signers to replace the compromised keys.  CS-GEARGOV-001  Gearbox - Gearbox V3 Governance -   12  InformationalVersion1  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Missing Sanity Checks",
        "body": "  When  opening  a  short  position  in  the  Gearbox  system  by  calling  shortOpenUniV2,  the  user  must provide  multiple  parameters.  These  parameters  are  not  sanitized,  thus  arbitrary  behavior  may  occur. More  specifically  it  is  never  checked  that  path[path.length  -  1]  ==  collateral  and collateral == longParams.path[0].  The  lpInterface  and  lpContract  in  the  struct  LongParameters  used  in  _openLong  are  not checked  to  match.  Similarly,  an  arbitrary  router  can  be  passed  as  shortSwapContract  as  long  as there is an adapter for it. Note that this is currently not an issue since different adapters/routers do not share the same interface and the transaction would revert. However, the addition of more adapters in the future might require some kind of sanity check.  Code partially corrected:  shortOpenUniV2 now features an additional check ensuring that the token out of the exchange using shortSwapContract  is  the  collateral.  Similar  checks  have  been  added  to  openShortUniV3  and openShortCurve.  Gearbox Protocol - Gearbox -   11  SecurityDesignCorrectnessCriticalHighMediumLowCodePartiallyCorrectedDesignLowVersion4CodePartiallyCorrected             \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  0  3  8  12  -Severity Findings  -Severity Findings  Incorrect Arguments in checkCollateralChange    Non-Accessible Credit Accounts    Retain Ownership of Credit Account   -Severity Findings   DoS of LeverageActions   Incorrect params.amountOutMinimum    Contracts Implement Proxy Pattern    Trust Model of External Adapters    Users Can Avoid Paying Fees On Closure    Wrong Approval To Pool    maxAmount Can Be Circumvented   takeOut May Break the Account List   -Severity Findings   Discrepancy Between openShortUniV2 and openShortUniV3    Use of transfer    Rounding Errors    Head Cannot Be Taken Out    Pointers Not Updated On takeOut    Redundant Multiplication    Storage Optimizations    Taking Out the First-Ever Created Account    allowToken Can Be Blocked    cancelAllowance Cannot Be Called    connectCreditManager Access Control    rayMul and rayDiv Are Used With No Ray Values   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Incorrect Arguments in ",
        "body": " checkCollateralChange  Gearbox Protocol - Gearbox -   12  CriticalHighCodeCorrectedCodeCorrectedCodeCorrectedMediumCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCorrectnessHighVersion2CodeCorrected             \fIn  YearnV2.withdraw(uint256,  address,  uint256),  the  checkCollateralChange  is  called with wrong arguments. Particularly, the following snippet is used:  creditFilter.checkCollateralChange(     creditAccount,     token,     yVault,     balanceInBefore.sub(IERC20(yVault).balanceOf(creditAccount)),     balanceOutBefore.add(IERC20(token).balanceOf(creditAccount)) );  Note that token is the tokenOut in this particular case, we convert yVault tokens to the underlyings and yVault is the tokenIn. This error later results in querying the oracles with wrong balances.  Code Corrected:  The arguments are now passed correctly to checkCollateralChange.  *While the final round of the review was ongoing Gearbox Protocol informed us of an issue in the new implementations  of  the  adapters.  The  adapters  were  calculating  the  delta  of  the  incorrectly  and  hence were passing wrong parameters to `checkCollateralChange`. The issue has been fixed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Non-Accessible Credit Accounts",
        "body": "  The transferAccountOwnership function of a CreditManager contract allows the owner of a credit account to transfer it onwards to a new owner. Per CreditManager an address is only allowed to hold one credit  account.  trasferAccountOwnerhip().  However,  there  is  no  check  on  whether  the  recipient already  holds  a  credit  account  at  this  CreditManager  contract  and  simply  overwrites  the  entry  for  the credit  account  of  the  recipient.  Hence  a  credit  account  which  holds  funds  can  become  non-accessible and its funds will be trapped.    In the updated code the transferAccountOwnership function no longer overwrites an existing credit account entry of the recipient, hence the issue no longer exists.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Retain Ownership of Credit Account",
        "body": "  In Gearbox, Credit Accounts are reused after they have been returned to the factory. Due to a reentrancy issue, account ownership can be retained and after the next user got this credit account assigned, the previous owner may access its funds belonging to the new owner.  Function transferAccountOwnership does not feature the non nonReentrant modifier and hence can be executed during another operation. Consider the follwowing scenario:  Alice owns a healthy credit account 0xA which holds some WETH balance.  1. Alice prepares a contract that allows her to execute all necessary actions. As a first step, the credit  account ownership is transferred to this contract.  Gearbox Protocol - Gearbox -   13  SecurityHighVersion1CodeCorrectedSecurityHighVersion1CodeCorrected                \f2. The credit account is repaid using repayCreditAccount specifying the contract as to address. This  transfers  all  assets  to  the  provided  to  address.  Notably  the  WETH  asset  is  unwraped  into Ether, the Ether is transferred in a call to the reciepient's address to. This call executes code at the contract.  3. At  the  specified  to  address  a  contract  exists.  This  contract  transfers  the  ownership  of  the  credit that  (newAddress)  Alice  controls.  This  means   to  another  address  account  onwards  creditAccounts[newAddress] will point to the credit account  4. The closure of the credit account continues as normal. All assets are transferred to address to, the  debt is repaid to the pool and the credit account is returned to the AccountFactory.  5. Next delete creditAccounts[borrower]; is executed, this should delete the assignment of this  credit  account  to  the  borrower.  However,  as  we  already  transferred  the  ownership  from borrower which is the contract address back to Alice, creditAccounts[borrower] contains no entry at this point and deleting it has no effect.  At the end of this sequence, the credit account has been returned to the AccountFactory but the entry creditAccounts[newAddress] in this CreditManager still points to this account.  The  next  time  this  CreditAccount  is  reused  at  the  same  CreditManager  by  a  new  user,  due  to  the entry  in  creditAccounts  Alice  will  still  have  access  to  this  account  and  can  collect  its  funds  by  e.g. closing or repaying the account.    transferAccountOwnership()  now  features  the  nonReentrant  modifier.  Hence,  the  reentrancy issue described is no longer possible.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   DoS of LeverageActions",
        "body": "  LeveragedActions can be blocked completely or for specific collaterals only in different ways:  1. When  opening  an  account  the  credit  manager  will  check  if  onBehalfOf  already  has  an account. In case a malicious user has already transferred the ownership of a credit account to the LeverageActions contract then the CreditManager will fail to open a new one:  function openCreditAccount(     ...     require(         !hasOpenedCreditAccount(onBehalfOf) && onBehalfOf != address(0),         Errors.CM_ZERO_ADDRESS_OR_USER_HAVE_ALREADY_OPEN_CREDIT_ACCOUNT     ); // T:[CM-3]     ...  2. Although this is more a theoretical attack, assume a credit manager which prohibits the user to invest more that A amount of tokens. A malicious user sends to the the contract A + 1 tokens. When the contract will try to open a leveraged position it will do so using the total balance of the token  it  holds.  If  this  amount  is  greater  than  the  allowed  one  the  account  opening  will  block. The snippets which dictate the above behavior are the following:  LeverageActions:  function _openLong(LongParameters calldata longParams, uint256 referralCode){  Gearbox Protocol - Gearbox -   14  DesignMediumVersion4CodeCorrected        \f    ...     uint256 amount = IERC20(collateral).balanceOf(address(this)); // M:[LA-1]     ... }  CreditManager:  function openCreditAccount(     ...     require(         amount >= minAmount &&             amount <= maxAmount &&             leverageFactor > 0 &&             leverageFactor <= maxLeverageFactor,         Errors.CM_INCORRECT_PARAMS     ); // T:[CM-2]     ... }    For the case #1, an allowance system was implemented for the transfer of credit account. In order to get a credit account transferred, the receiver needs to pre-approve the sender of the credit account. Hence one  can  no  longer  transfer  a  credit  account  to  the  LeveragedAction  contract  and  the  issue  no  longer exists.  To mitigate case #2 the LeveragedActions contract now uses the actual balance difference.  *Moreover, Gearbox Protocol pointed out a third way to use the attack described above. Specifically, a user  can  open  an  account  on  behalf  of  the  LeverageAccount  contract  which  would  result  in  a Denial-of-Service  for  the  LeverageAction  contract.  The  issue  has  been  resolved  by  also  restricting  the address on behalf of which the credit account is opened.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Incorrect params.amountOutMinimum",
        "body": "  The  parameter  params.amountOutMinimum  passed  to  the  call  to  the  UniswapV3  adapter  in _openLong() is calculated incorrectly and does not include the leverage.  _openLong  executes  a  swap  using  the  funds  of  the  opened  leveraged  account  given  the  swap parameters in longParams. The relevant parameters for the swap are in bytes swapCalldata which are  first  extracted  and  prepared  for  the  call  to  the  swap  contract.  Note  however  the  parameters representing  amountIn  and  amountOutMinimum  extracted  from  swapCalldata  do  not  include  the leverage, hence the actual values for the swap have to be calculated:  else if (longParams.swapInterface == Constants.UNISWAP_V3) {     ISwapRouter.ExactInputParams memory params = abi.decode(         longParams.swapCalldata,         (ISwapRouter.ExactInputParams)     );      params.amountIn = leveragedAmount;     params.amountOutMinimum = params     .amountOutMinimum  Gearbox Protocol - Gearbox -   15  CorrectnessMediumVersion4CodeCorrected        \f    .mul(leveragedAmount)     .div(params.amountIn);     ISwapRouter(adapter).exactInput(params);     (, asset) = _extractTokensUniV3(params.path); }  First params.amountIn is overwritten with leveragedAmount. Next params.amountOutMinimum is calculated, this calculation uses params.amountIn which is equal to leveragedAmount at this point.  Hence  the  params.amountOutMinimum.mul(leveragedAmount).div(params.amountIn);  actually  params.amountOutMinimum.mul(leveragedAmount).div(leveragedAmount);  simplifies to params.amountOutMinimum.  calculation: is which  The leverage is not included in params.amountOutMinimum.    The calculation of the leveraged value for params.amountOutMinimum is now done correctly using the unchanged  value  of  to leveragedAmount afterwards.  the  decoded  params.amountIn.  params.amountIn   is  only  set   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Contracts Implement Proxy Pattern",
        "body": "  All adapters and the YearnPriceFeed contract inherit from OpenZeppelin's abstract Proxy contract and implement an _implementation function pointing to the address of the 3rd party system contract the adapter connects to. However, this proxy functionality is not needed nor used. The intended functionality of the adapter is implemented in functions inside the adapter contract itself.  Inheriting the proxy contract, however, has serious consequences. Calls to non-existing functions in the contract  execute  the  fallback  function,  which  is  implemented  by  the  inherited  proxy.  This  function forwards the call by delegate-calling into the implementation contract. During a delegate-call, the code at the target is executed in the context of the caller. Notably, it is read from and written to the storage of the caller,  the  adapter  contract.  This  can  have  an  adverse  effect  on  the  stored  variables  of  the  adapter contract. For example the stored values for the creditManager or the creditFilter.    The adapter contracts were rewritten and the proxy pattern was removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Trust Model of External Adapters",
        "body": "  The  trust  model  for  the  external  adapters  has  not  been  properly  specified.  Moreover,  all  four  available adapters behave differently and the assumptions these adapters rely on have not been documented.  After the action on the external system which is invoked by an adapter, there is a check on the collateral of the credit account. All currently available adapters use the following function which takes the following parameters:  Gearbox Protocol - Gearbox -   16  SecurityMediumVersion1CodeCorrectedDesignMediumVersion1Speci\ufb01cationChangedCodeCorrected                  \ffunction checkCollateralChange(     address creditAccount,     address tokenIn,     address tokenOut,     uint256 amountIn,     uint256 amountOut )  The  concern  is  about  what  is  passed  as  amount  especially  for  the  spent  asset.  It  is  vital  that  these amounts represent the actual state of the credit accounts holding or the check may be circumvented.  Some adapters rely on the values returned by the 3rd party system, some query the actual balance.  While  querying  the  actual  balance  for  the  assets  involved  in  the  action  is  the  safest  option,  it  may  be expensive  in  terms  of  gas.  However  note  that  in  the  current  implementation  of  the  EVM  (London hardfork), repeated access to the same contract/storage location got significantly cheaper the overhead in terms of gas may not be that big.  Using values returned by the call to the third-party contract may be an option if the third-party contract is fully  trusted  to  do  so  correctly.  Similarly,  this  holds  for  input  parameters.  This  critical  part  should  be documented  and  assessed  thoroughly.  In  case  of  doubts/uncertainties,  it  may  be  safer  to  query  the balances and calculate the delta of the balances and use this.  Regarding  the  YearnAdapter,  it  can  be  inspected  and  documented:  Querying  the  balances  could  be Vault.withdraw avoided  [https://github.com/yearn/yearn-vaults/blob/main/contracts/Vault.vy]  return  the  change  in  the  balance  of the tokens of interest. However, the current YearnAdapter does not do this but queries the balance and calculates the delta.  Vault.deposit   since   both   and   The  UniswapV3  Adapter  relies  on  the  returned  values  by  the  3rd  party  system.  However,  there  is  no documentation why this assumption holds.  Specification changed and code corrected:  A pattern of how all adapters should be built has been created. All existing adapters have been rewritten to adhere to this pattern: The balance is queried before and after the action and the difference is used for the check of the collateral change.  Note that due to the existing token allowances for the adapters from the credit accounts these checks are not 100% failsafe. It is vital that the 3rd party system is fully trusted to not transfer any other tokens of the credit  account.  The  system  performs  the  fast  check  only  for  the  tokens  passed  as  arguments  to  the check. Any other change in balance will be ignored.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   Users Can Avoid Paying Fees On Closure",
        "body": "  On  account  closure,  all  the  assets  held  by  the  account  are  converted  to  the  underlying  token  through defaultSwapContract which is set to be UniswapV2. For this conversion, the user defines a path of tokens to the underlying. This path can contain arbitrary tokens, tokens even controlled by the user. A check  in  _closeCreditAccountImpl  assures  that  the  closure  of  a  credit  account  will  not  lead  to losses for the protocol i.e., require(loss <= 1). On the closure of an account users are supposed to return to pool the amount they borrowed, the interest accrued for that amount and an extra amount for fees  namely,  feeSuccess  and  feeInterest.  It  is  important  to  note  that  if  the  funds  do  not  suffice totalFunds < amountToPool then only the borrowed amount with the interest accrued is returned and no fees are required to be paid. This means that draining a credit account to the point that does not make losses can allow a user to avoid paying fees to the protocol.  Gearbox Protocol - Gearbox -   17  DesignMediumVersion1CodeCorrected        \fCode Corrected:  A new check has been introduced which requires that remainingFunds > 0. This way it is guaranteed that the user has paid their fees. Due to this requirement, a closure that does not result in fee payout will be reverted. Hence, the only option for the users will be to repay.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   Wrong Approval To Pool",
        "body": "  *While the review was ongoing Gearbox Protocol informed us about this issue independently in parallel.  In the WETHGateway.repayCreditAccountETH an approval is given to the pool:  _checkAllowance(pool, amount); // T: [WG-11]  However, this approval is wrong and should be given to the credit manager who performs the transfer from the WETHGateway to the pool.    The code has been corrected in a further commit and the allowance is now given to the CreditManager instead of the pool in order for the credit manager to be able to transfer the tokens from the user to the pool.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   maxAmount Can Be Circumvented",
        "body": "  When opening a credit account, a check of the amount invested is performed:  require(     amount >= minAmount && amount <= maxAmount,     Errors.CM_INCORRECT_AMOUNT );  By limiting the amount originally invested, one can limit the amount of leverage that can be borrowed by the pool. However, this limitation can be circumvented as follows:  1. The user opens an account with an allowed account.  2. She calls CreditManager.addCollateral.  3. She calls increaseBorrowedAmount.  Note, that addCollateral does not perform any checks and increaseBorrowedAmount only checks that the borrowed amount does not turn the account unhealthy.  Code Corrected:  The  implementation  has  been  extended  to  prevent  increasing  the  borrowed  amount  more  than  the predetermined maximum:  Gearbox Protocol - Gearbox -   18  DesignMediumVersion1CodeCorrectedDesignMediumVersion1CodeCorrected                \frequire(      borrowedAmount.add(amount) <          maxAmount.mul(maxLeverageFactor).div(              Constants.LEVERAGE_DECIMALS          ),      Errors.CM_INCORRECT_AMOUNT  );  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.11   takeOut May Break the Account List",
        "body": "  The  configurator  can  take  out  an  account  by  calling  AccountFactory.takeOut().  During  account removal, there is no check whether this is the tail nor is the tail updated in case this account is taken out. Should the tail account be taken out this is problematic:  New  accounts  added  will  not  be  connected  to  the  original  list,  hence  they  cannot  be  taken  using takeCreditAccount() which takes the head of the original list.  Similarly,  returned  accounts  will  be  added  to  the  list  after  the  removed  tail  account  which  no  longer exists  in  the  list.  Again,  the  connection  to  the  original  list  starting  at  head  is  interrupted  and  these accounts cannot be used anymore.  Code Corrected:  The implementation has been extended to correctly update tail when the last account is taken out.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.12   Discrepancy Between openShortUniV2 and",
        "body": " openShortUniV3  LeverageAction.openShortUniV2  sets  the  deadline  for  the  short  swap  to  the  current  block timestamp:  bytes memory data = abi.encodeWithSelector(     bytes4(0x38ed1739), // \"swapExactTokensForTokens(uint256,uint256,address[],address,uint256)\",     amountIn,     amountOutMin,     path,     address(this),     block.timestamp ); // M:[LA-5]  the  call  cannot   This  way  the  other  hand, LeverageAction.openShortUniV3  lets  users  define  the  deadline  themselves.  This  means  that  a transaction that takes long to be included into a block might fail.  to  a  passed  deadline.  On   fail  due     Gearbox Protocol - Gearbox -   19  DesignMediumVersion1CodeCorrectedDesignLowVersion4CodeCorrected                \fThe  code  of  openShortUniV2  was  changed  and  now  uses  the  user-specified  parameter  deadline instead  of  block.timestamp.  It's  the  caller's  responsibility  to  specify  a  proper  deadline.  With  this change, the behavior of the functions for UniV2 and V3 are now consistent.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.13   Use of transfer",
        "body": "  _returnTokenOrUnwrapWETH uses transfer instead of safeTransfer for transferring tokens. This call will fail for tokens which do not adhere to the ERC20 interface e.g., USDT.    The code was changed to use safeTransfer.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.14   Rounding Errors",
        "body": "  In CreditManager.increaseBorrowedAmount the following check is performed:  require(     borrowedAmount.add(amount) <         maxAmount.mul(maxLeverageFactor).div(             Constants.LEVERAGE_DECIMALS         ),     Errors.CM_INCORRECT_AMOUNT );  This check includes a division with Constants.LEVERAGE_DECIMALS which results in a rounding error. This error can be avoided, if one multiplies the left side of the inequality with the same value instead.  In  the  following  snippet  of  PoolService.expectedLiquidity  a  division  before  multiplication  takes place:  uint256 interestAccrued = totalBorrowed .mul(borrowAPY_RAY) .div(Constants.RAY) .mul(timeDifference) .div(Constants.SECONDS_PER_YEAR);  Division  before  multiplication  can  interestAccrued will be smaller.  result   in   rounding  errors.   In   this  particular  case,   the  Code Corrected:  Regarding the first issue, the division has been replaced with a multiplication. Regarding the second one, the order of operations has changed and the multiplications take place first.  Gearbox Protocol - Gearbox -   20  DesignLowVersion4CodeCorrectedDesignLowVersion2CodeCorrected                  \f6.15   Head Cannot Be Taken Out  Calling  AccountFactory.takeOut  requires  to  pass  the  previous  account  of  the  one  to  be  deleted (prev). This means that the head credit account of the list cannot be taken out since there is no prev defined for it.  Code Corrected:  The implementation has been extended to handle the removal of the head.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.16   Pointers Not Updated On takeOut",
        "body": "  A  credit  account  can  be  function AccountFactory.takeOut.  Under  normal  circumstances  this  account  cannot  be  accessed  again  by the function. However, consider the following scenario:  the  configurator  using   the  system  by   taken  out  of   1. The  controller  removes  the  head  account  (A1).  In  this  case,  the  head  is  just  updated  to  the second account (A2). Note that at the removal of the head, the pointers of the head account _nextCreditAccount[head] is not reset.  2. Later A2, the current head is also removed.  3. This  means  that  the  controller  can  take  out  A2  again  by  calling  takeOut(A1,  A2)  and  connect it to a new to address.  The  reason  for  the  above  is  that  _nextCreditAccount[A1]  is  not  updated  upon  removal  and  still points to A2 which has also been removed. The check  require(             _nextCreditAccount[prev] == creditAccount,             Errors.AF_CREDIT_ACCOUNT_NOT_IN_STOCK         );  is still satisfied despite the accounts being no longer part of the system.  Code Corrected:  The pointers are now updated correctly.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.17   Redundant Multiplication",
        "body": "  In PoolService.removeLiquidity a part of the amount requested by the user is sent back to them determined by withdrawMultiplier and an amount determined by the withdrawFee is sent to the treasury.  that withdrawMultiplier + withdrawFee == PERCENTAGE_FACTOR. These two amounts should add up to underlyingTokensAmount. Hence, there is no need to perform two safe multiplications with both withdrawFee and withdrawMultiplier and the following multiplication is redundant:  construction   know   we   By   Gearbox Protocol - Gearbox -   21  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                      \fIERC20(underlyingToken).safeTransfer(     ...     underlyingTokensAmount.percentMul(withdrawFee) ); // T:[PS-3, 34]  Code Corrected:  The  issue  has  been  resolved.  In  the  current  implementation,  only  one  multiplication  takes  place.  The amount  from underlyingTokensAmount.  subtracting  amountSent   calculated  by   is  now   treasury   sent   the   to   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.18   Storage Optimizations",
        "body": "  There are various small optimizations that can be applied to the contracts of the system to improve gas efficiency:  1. Storage variable can be declared as constants: In GearToken contract totalSupply can be  declared as constant.  2. Some functions can be declared as external:   AccountFactory.countCreditAccountsInStock()   CreditFilter.checkCollateralChange(address,address,address,uint256,uint256)   CreditFilter.allowedContractsCount()   CreditFilter.allowedContracts(uint256)   GearToken.delegate(address)   GearToken.delegateBySig(address,uint256,uint256,uint8,bytes32,bytes32)   GearToken.getPriorVotes(address,uint256)  3. Dead code which can be removed:   BytesLib.slice(bytes,uint256,uint256)   BytesLib.toUint24(bytes,uint256)  Code Corrected:  Issues 1. and 2. have been resolved. Regarding 3., the client states:  BytesLib functions are used in support contracts which are not in the scope  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.19   Taking Out the First-Ever Created Account",
        "body": "  The configurator can call AccountFactory.takeOut to remove an account completely and connect it to an address of their choice. To do so, they provide the address of the account to be removed and the address of the previous account in the list of the available accounts. Let us consider the addition of the  Gearbox Protocol - Gearbox -   22  DesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                \ffirst-ever  created  account.  The  account  is  added  during  the  deployment  of  the  AccountFactory  i.e., when the constructor is invoked. At this point, both the head and the tail are 0. This means that in the following snippet, it holds _nextCreditAccount[0] == clonedAccount.  function addCreditAccount() public {     ...      _nextCreditAccount[tail] = clonedAccount; // T:[AF-2]      ...  first-ever  created  account.   Note that _nextCreditAccount[0] is never updated. This means that there is always a pointer at 0 to the  configurator  calls  takeOut  with  prev  ==  0x0  and the  creditAccount the first ever created account they can control it even though the account might be in use at the time of the call. In other words, there is always a pointer to the first ever created account even if the account is not in stock. The case above makes the following check in AccountFactory.takeOut and the error message emitted imprecise:  If   require(     _nextCreditAccount[prev] == creditAccount,     Errors.AF_CREDIT_ACCOUNT_NOT_IN_STOCK ); // T:[AF-15]  The check whether the account is in stock doesn't work as expected in the scenario described above.  Code Correct:  The  pointer  of  _nextCreditAccount[0]  now  points  to  address(0)  and  not  the  first-ever  created account.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.20   allowToken Can Be Blocked",
        "body": "  The purpose of creditFilter.allowToken is twofold. On one hand, it allows the system to use new tokens. On the other hand, in the case of an already registered token, it allows updating the liquidation threshold for this token.  Due to the bitmask optimization used, the following check assures that no more than 256 different tokens can be tracked by the system.  require(allowedTokens.length < 256, ...);  However,  in  the  unlikely  case  of  256  registered  tokens,  the  liquidation  threshold  cannot  be  updated anymore since the above check will fail, leading the transaction to revert.  Code Corrected:  The code has been corrected. The requirement will be satisfied when the function is called with a token for which tokenMasksMap[token] > 0 as shown in the following in snippet:  Gearbox Protocol - Gearbox -   23  DesignLowVersion1CodeCorrected        \frequire(     tokenMasksMap[token] > 0 || allowedTokens.length < 256, ... );  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.21   cancelAllowance Cannot Be Called",
        "body": "  When  an  account  is  closed,  it  is  returned  to  the  factory.  It  is  important  to  note,  however,  that  the allowances the account has given to other addresses remain in place. This can be dangerous in case of malfunctioning approved contracts. In order to mitigate this risk, the configurator is allowed to reduce or remove the allowances. This functionality is implemented by CreditManager.cancelAllowance. This function is supposed to be called by the factory. However, no function that calls cancelAllowance is implemented, thus the allowance cannot be revoked.  Code Corrected:  the  current  The  code  has  been  corrected.  AccountFactory.cancelAllowance which then calls CreditAccount.cancelAllowance.  implementation   the  configurator  can  call  In   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.22   connectCreditManager Access Control",
        "body": "  The  CreditFilter.connectCreditManager  function  does  not  implement  proper  access  control. The  first  caller  to  this  function  can  set  CreditManager  to  his  address.  This  does  not  pose  threat  to  the system but could lead to wasted deployments of the Credit Filter.  Code Corrected:  The code has been fixed, now only the configurator is allowed to set the creditManager for the filter.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.23   rayMul and rayDiv Are Used With No Ray",
        "body": " Values  PoolService.expectedLiquidity()  performs  a  multiplication  using  rayMul  passing totalBorrowed  as  a  parameter.  However  totalBorrowed  is  not  in  RAY  but  in  the  decimals  of  the underlying token.  uint256 interestAccrued = totalBorrowed.rayMul(     borrowAPY_RAY.mul(timeDifference).div(Constants.SECONDS_PER_YEAR) ); // T:[GM-1]  This contradicts the specification for rayMul which states the following:  * @dev Multiplies two ray, rounding half up to the nearest ray  Gearbox Protocol - Gearbox -   24  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                        \fSimilarly this applies for fromDiesel(). Additionally getDieselRate_RAY() uses and toDiesel() use rayDiv which is annotated with:  * @dev Divides two ray, rounding half up to the nearest ray    rayMul and rayDiv are now correctly used.  Gearbox Protocol - Gearbox -   25  \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Blocking updateContributors",
        "body": "  block.   TokenDistributor.updateContributors  of can  TokenDistributor.updateVesting for each holder. Consider the following scenario: A receiver RA of  the  Vesting  contract  calls  setReceiver  to  an  address  RB  which  is  a  receiver  of  another  contract. Then for updateVesting(RA), it holds vestingContracts[RB].contractAddress != 0 which makes the transaction revert. This leads the execution of updateContributors to revert as well. Note that users do not have an incentive to change the receiver address to another's receiver address. Moreover, the  new  receiver  can  change  again  the  address  to  another  public  address  they  control.  This  would unblock the execution of TokenDistributor.updateContributors. However, it is up to the specific user to address the issue.  function  makes   The   use   This  just  affects  the  updateContributors  function  which  attempts  to  update  all  holders.  The unaffected holders can always be updated individually through updateVesting().  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Handling Of Reward Tokens",
        "body": "  Users  of  the  Gearbox  system  are  allowed  to  trade  through  specific  adapters.  Moreover,  the  credit accounts  are  only  enabled  to  access  the  balance  of  the  enabled  tokens  which  are  specified  by  the governance.  However,  there  might  be  the  case  where  one  of  the  allowed  tokens  accrues  rewards  in another token which is not part of the enabled tokens. Currently, users can only collect their rewards by repaying their accounts and receive the tokens which accrue the rewards.  Furthermore, rewards may be accrued by the credit account address e.g., due to a user interacting with a certain third-party system. Such a reward may be only claimable in the future, notably e.g., after a credit account user returned his account to the factory. Such a reward may be claimable by the next user of this credit account.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Liquidity Removal Not Always Possible",
        "body": "  Users can remove liquidity they have offered to the pool by calling PoolService.removeLiquidity. During this call, a transfer is performed from the pool to the msg.sender with the requested amount. It is important  to  be  aware  that  in  case  of  high  utilization  of  the  pool,  the  amount  requested  might  not  be available since it is used as leverage in some positions.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   Oracles Do Not Handle Stale Prices",
        "body": "  Gearbox Protocol - Gearbox -   26  NoteVersion7NoteVersion1NoteVersion1NoteVersion1              \fThe Gearbox system relies on chainlink oracles to derive the value of the assets a credit account holds. The chainlink interface allows the consumers of the data to know whether a price returned is stale or not timestamps  https://docs.chain.link/docs/price-feeds-api-reference/#latestrounddata. based  on  However, Gearbox does not take advantage of these timestamps meaning that stale data could be used by the system.  the   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   Price Feeds Cannot Be Updated",
        "body": "  A price feed can be added by the configurator of the system by calling PriceOracle.addPriceFeed. The logic of the addition is implemented inside an if statement with the following condition:  if (priceFeeds[token] == address(0)) {  This  means  that  if  the  price  feed  for  a  token  T  is  already  defined  i.e.,  priceFeeds[T]  !=  0  then  it cannot be updated. This becomes important especially when it comes to custom price feed such as the yearn price feed which might require an upgrade at some point.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.6   Special ERC-20 Token Behavior May Be",
        "body": " Problematic  Some ERC-20 tokens have transfer fees. Supporting such tokens may lead to accounting errors as the actual amount received after a transfer may not match the expected amount, e.g. when funds are repaid to the pool.  Furthermore, note that the _convertAllAssetsToUnderlying() used during the closure of a credit account uses UniswapV2's swapExactTokensForTokens function which does not support token with transfer fees.  In general, when adding tokens to the system they should be carefully inspected for any special behavior such  as  hooks.  If  any  special  behavior  is  detected,  the  impact  on  the  system  should  be  evaluated carefully.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.7   Users Can Turn Their Account Liquidatable",
        "body": " Inadvertently  Gearbox uses fast check and health factor in order to prevent users from draining funds that should be returned back to the pool.  However  an  unaware  user  may  turn  his  account  into  a  liquidatable  state  inadvertently.  Consider  the following scenario:  Assume  that  a  healthy  account  holds  only  token  A  with  value  V_A  (in  the  underlying  token)  and  owes amount B. The health factor of the account is H_f = V_A * LT_A / B.  Now, this user trades the balance of A to token C, which is worth slightly when evaluated in the underlying asset.  After  the  trade  through  the  adapter  is  completed,  the  check  on  the  collateral  takes  place.  Let's assume  we're  eligible  for  the  fast  check  and  this  passes  as  the  value  in  terms  of  the  underlying  has increased.  Gearbox Protocol - Gearbox -   27  NoteVersion1NoteVersion1NoteVersion1            \fHowever,  it  could  be  that  the  liquidation  threshold  of  token  A  and  token  C  are  different,  e.g. LT_C << LT_A. This means that the health factor H_f' = V_C * LT_C / B may become less than 1 after the trade even though the value of the holdings has not been decreased.  Gearbox Protocol - Gearbox -   28  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   CurrentSupply Can Be Underestimated",
        "body": "  CapAutomator  computes  the  new  SupplyCap  based  on  the  current  supply,  the  gap,  and  the  max.  The current supply is estimated based on the scaled aToken total supply, the cached amount that should be accrued to treasury, and the last updated liquidity index.  CS-SPRKCAP-001  uint256 currentSupply = (             IScaledBalanceToken(reserveData.aTokenAddress).scaledTotalSupply()             + uint256(reserveData.accruedToTreasury)         ).rayMul(reserveData.liquidityIndex)         / 10 ** ERC20(reserveData.aTokenAddress).decimals();  The  liquidityIndex  could  be  underestimated  if  it  hasn't  been  updated  up  to  now  (interest  has  not been accrued for the period between reserveLastUpdateTimestamp and block.timestamp).  In  addition,  decimals  have  been  removed  for  currentSupply  to  align  with  gap  and  cap,  while  this rounds currentSupply down.  As  a  result,  currentSupply  could  be  underestimated  and  influence  the  new  cap  computation (_calculateNewCap()).  Risk accepted:  MakerDAO states:  We acknowledge and accept the fact that the current total value of the pool can be assumed slightly inaccurately.  MakerDAO - Sparklend Cap Automator -   9  SecurityDesignCorrectnessCriticalHighMediumLowRiskAcceptedRiskAcceptedDesignLowVersion1RiskAccepted           \f5.2   DoS Cap Increase  CapAutomator  allows  any  user  to  increase  the  supply  cap  by  gap  if  the  increaseCooldown  has passed.  // Cap cannot be increased before cooldown passes, but can be decreased if (newCap > currentCap     && block.timestamp < (capConfig.lastIncreaseTime + capConfig.increaseCooldown)) {         return currentCap;  CS-SPRKCAP-002  Furthermore,  the  computation  of  the  new  cap  relies  on  the  current  amount  of  liquidity  supplied  or borrowed:  uint256 newCap = _min(currentValue + capConfig.gap, max);  A malicious user supplying or borrowing funds can frontrun a call to execSupply(), execBorrow() or exec() to remove supply or repay his loan in order to manipulate currentValue.  More precisely, it is possible to manipulate currentValue to increase the supply or borrow cap by 1 instead of gap. It is then not possible to increase the cap again before increaseCooldown expires.  Selecting the values of increaseCooldown and gap with care is crucial, as poor choices can worsen the problem, although even carefully selected values cannot fully eliminate this issue.  Risk accepted:  MakerDAO states:  The same vector is present in other Maker modules and it was never proved to be used. In case of users abusing this possibility, we will upgrade to a more robust solution.  MakerDAO - Sparklend Cap Automator -   10  SecurityLowVersion1RiskAccepted          \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings  -Severity Findings   Cap of 0 Ignores Increase Cooldown   0  0  0  1  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Cap of 0 Ignores Increase Cooldown",
        "body": "  CapAutomator intends to prevent the supply and borrow cap to be increased for increaseCooldown seconds after an increase.  if (newCap > currentCap &&     block.timestamp < (capConfig.lastIncreaseTime + capConfig.increaseCooldown)) {     return currentCap;  CS-SPRKCAP-008  In SparkLend, a cap of 0 means no cap at all (see SparkLend Caps Specifications). In other words, the cap becomes infinity.  In CapAutomator, a newCap equal to 0 is considered as a cap decrease instead of an increase from the condition (newCap > currentCap). As a result, the increaseCooldown period will not be taken into account when the newCap is 0.  The aforementioned behavior could happen in case the gap is set to 0 and there is no supply or borrows (currentValue==0).  uint256 newCap = _min(currentValue + capConfig.gap, max);  In summary:  1. The code does not eliminate the possibility of setting gap to 0, which implies the risk of lifting the  cap by setting cap to 0.  2. The increaseCooldown period will not be respected per specification in case the cap becomes  infinity (cap==0).    An extra check has been added in setSupplyCapConfig() and setBorrowCapConfig() to ensure the gap is greater than 0.  MakerDAO - Sparklend Cap Automator -   11  CriticalHighMediumLowCodeCorrectedCorrectnessLowVersion1CodeCorrected          \f6.2   Event Emission Before State Change  In  functions  _updateSupplyCap  and  _updateBorrowCap,  events  are  emitted  before  the  configs (state variables) are updated. The emission of an event should indicate that changes have been made to state variables, whereas by the time the event is emitted, state changes haven't been made yet.  CS-SPRKCAP-006    Emission  of  the  event  UpdateSupplyCap  and  UpdateBorrowCap  has  been  moved  to  the  end  of _updateSupplyCap() and _updateBorrowCap() respectively.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Remove Non-Existing Config Is Possible",
        "body": "  The owner of CapAutomator can remove the supply or borrow caps via removeSupplyCapConfig() and removeBorrowCapConfig() respectively. Both of them do not check if the config has been set in the first place. As a result, removing non-existing config will succeed and an event will be emitted even though there is no state changes.  CS-SPRKCAP-007    removeSupplyCapConfig()  and  removeBorrowCapConfig()  have  been  updated  to  ensure  the config exists by checking if config.max>0. As config.max can only be set to a positive value for valid configs, this check effectively prevents removing a non-existing config.  MakerDAO - Sparklend Cap Automator -   12  InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected          \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Cap Can Be Updated in the Flashloan",
        "body": " Callback  CS-SPRKCAP-004  SparkLend  supports  the  end  of  which,  a  debt  position (executeBorrow()) will be opened for the user if one does not repay the flashloan. In case the borrow limit has been reached, executeBorrow() will fail and the whole flashloan will revert.  (flashLoan()),  at   flashloan   With the deployment of CapAutomator, the user can increase the borrow cap in the flashloan callback via execBorrow() in case the borrow limit has been reached. Note that updating the borrow cap first and then doing the flashloan implies the same execution result, nevertheless, the ability to change of a key pool parameter may not be expected to happen in a flashloan callback.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Cap May Decrease Fast and Recover Slowly",
        "body": "  CS-SPRKCAP-005  Situations  may  arise  where  a  cap  can  be  reduced  significantly.  E.g.  a  whale  or  many  borrower  repay significant amounts or significant amounts of supply are withdrawn at the same time.  Should  the  CapAutomator  be  activated  it  will  significantly  reduce  the  respective  cap,  leaving  only  gap amount available for use.  Bringing the respective cap back up to its original limit could take a considerable amount of time due to the increaseCooldown feature.  This is especially likely to happen in case a reserve is frozen, no more supply and borrow is possible, but users can withdraw and repay. This means it is possible that the current supply and borrow will decrease to a small value, hence the cap could be decreased significantly. Arguably a significant reduction in the cap coupled with a slow increase over a period of time may not be unwarranted. Special care needs to be taken in this scenario.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Gas Optimizations",
        "body": "  When  updating  the calculation of the new cap (_calculateNewCap()) will return early if the configuration is unset or the cap has already been updated in the current block.  the  supply/borrow  cap  (_updateSupplyCap(),  _updateBorrowCap()),   CS-SPRKCAP-003  if (max == 0 || capConfig.lastUpdateBlock == block.number) return currentCap;  MakerDAO - Sparklend Cap Automator -   13  InformationalVersion1AcknowledgedInformationalVersion1AcknowledgedInformationalVersion1              \fThis check could be brought forward in _updateSupplyCap() and _updateBorrowCap() to enable an early return, which would occur before the external call to pool.getReserveData() is executed, saving gas.  MakerDAO - Sparklend Cap Automator -   14  \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Supply and Borrow Are Subject to",
        "body": " Front-Running  When  the  current  available  volume  (to  be  supplied  /  borrowed)  is  above  the  gap,  a  user's  action  to consume  the  available  volume  can  be  front-run  by  an  update  of  the  cap,  which  may  leave  insufficient volume to be consumed in case the cap is lowered. In the former case, users can only supply / borrow up to the current cap and wait at least cooldown period to increase the cap for the consecutive operations. For instance:   Assume the current borrow cap = 15, current total borrow = 3, gap = 5.   Alice send tx1 to borrow 10.   Bob front-runs tx1 to update the cap to 8.   Now tx1 will fail due to exceeding the cap.  In addition, it is obvious that user's operation (supply / borrow) can also be front-run by others' (supply / borrow) which may leave insufficient volume afterwards.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Token Unit, Decimals and Integer Division",
        "body": "  In CapAutomator, the new cap is determined by currentValue, gap and max. These value are in \"full tokens\", token amounts without decimals.  uint256 newCap = _min(currentValue + capConfig.gap, max);  The currentValue is computed as currentSupply in _updateSupplyCap():  uint256 currentSupply = (             IScaledBalanceToken(reserveData.aTokenAddress).scaledTotalSupply() +             uint256(reserveData.accruedToTreasury)         ).rayMul(reserveData.liquidityIndex)         / 10 ** ERC20(reserveData.aTokenAddress).decimals();  and it is computed as currentBorrow in _updateBorrowCap():  uint256 currentBorrow = ERC20(reserveData.variableDebtTokenAddress).totalSupply()         / 10 ** ERC20(reserveData.variableDebtTokenAddress).decimals();  In both cases currentValue is rounded down when removing the decimals.  Due  to  this,  the  difference  between  the  new  cap  and  the  actual  current  value  could  be  below  the  gap even though the max has not been reached.  MakerDAO - Sparklend Cap Automator -   15  NoteVersion1NoteVersion1      \fIn  practice,  these  minor  rounding  effects  are  typically  negligible.  Nonetheless,  they  can  result  in  the following consequences:  If gap is 0, the new cap could be set lower than the current amount. For instance, if gap is 0, cap is 10, and the actual current supply is 9.99. The calculation of currentSupply would result in 9 due to integer division. Consequently, the update would set the cap to 9, which is less than the actual current supply.   Users should not expect to fully utilize the gap amount (expanded to its decimal representation) after  triggering exec(). There may be less space due to rounding and hence this action might fail.  MakerDAO - Sparklend Cap Automator -   16   \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Cancel Order Authorization Differs From",
        "body": " Match  Function validate of OrderValidator contract permits matches in cases when the message sender is not the order maker. This can be done when the order maker is an ERC1271 implementation or when the sender provides a valid signature. During the cancellation the only check that is done is:  require(_msgSender() == order.maker, \"not a maker\");  This  check  is  more  strict  than  the  matchOrders  authorization  rules  and  limits  the  possible  pool  of parties that can use this entry-point, for example, ERC1271 contracts cannot cancel their orders.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Dependency on EIP712Upgradeable",
        "body": "  Contract  OrderValidator  uses  EIP712Upgradeable  contract  from  openzeppelin  library,  which  is currently  in  a  draft  stage.  That  increases  the  risk  of  bugs  and  errors  in  all  contracts  that  use  this dependency. In addition draft library contracts tend to be inefficient. For example in current version, every call  (_EIP712NameHash(), two  _EIP712VersionHash()) which together cost 4200. That is fairly unnecessary.  _hashTypedDataV4   lookups   storage   triggers   to   import \"@openzeppelin/contracts-upgradeable/drafts/EIP712Upgradeable.sol\";  Rarible Inc. - Exchange V2 -   8  SecurityDesignCorrectnessCriticalHighMediumRiskAcceptedLowRiskAcceptedRiskAcceptedDesignMediumVersion1RiskAcceptedSecurityLowVersion1RiskAccepted                   \f5.3   Missing Indexes In Events  In ExchangeV2Core the events Cancel and Match contain no indexed fields. Indexing order hashes will help to avoid performance issues on node clients.  Rarible Inc. - Exchange V2 -   9  DesignLowVersion1RiskAccepted          \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings   doTransfers Does Not Hanlde LibFeeSide.FeeSide.NONE   -Severity Findings   Function safeGetPartialAmountFloor Precision Problems    Order Salt Problems    Orders With Salt 0 Can Be Canceled   -Severity Findings   Compiler Version Not Fixed    Contracts Can Be Order Makers    Precision Check in calculateRemaining Problem   0  1  3  3  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   doTransfers Does Not Hanlde",
        "body": " LibFeeSide.FeeSide.NONE  doTransfers  performs  the  transfer  of  assets  after  choosing  which  is  the  feeable  side.  However, getFeeSide can return the value LibFeeSide.FeeSide.NONE in the case none of the assets are ETH or  ERC20  or  ERC1155.  This  value  is  not  handled  by  the  function  doTransfers  which  results  to  the transfer not being performed.    doTransfers was changed to handle LibFeeSide.FeeSide.NONE.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Function safeGetPartialAmountFloor",
        "body": " Precision Problems  target)   The function safeGetPartialAmountFloor( uint256 numerator, uint256 denominator,  uint256  LibMath  the numerator * target / denominator and reverts on too much divergence from the correct value. Due to the different nature of tokens ( ETH, ERC20, ERC721, etc.) and different decimals on them, the actual values sent to this function can be of different orders. In cases when the denominator is greater  effectively   computes   contract   defined   in   Rarible Inc. - Exchange V2 -   10  CriticalHighCodeCorrectedMediumSpeci\ufb01cationChangedSpeci\ufb01cationChangedCodeCorrectedLowCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedDesignHighVersion1CodeCorrectedCorrectnessMediumVersion1Speci\ufb01cationChanged                \fthan  the  numerator  *  target  the  0  will  be  returned.  This  can  lead  to  situations  when  the  orders cannot be matched. For example order \"Buy 30 for 600X\" cannot be matched with order \"Sell X for 10\", because  the  fillRight  function  that  relies  on  safeGetPartialAmountFloor  will  return  (10,  0) value that later will fail the check in matchAndTransfer function.  The safeGetPartialAmountFloor function is used in following places:   Function fillLeft in LibFill contract.   Function fillRight in LibFill contract.   Function calculateRemaining in LibOrder contract. In this case, big, close to filling values may  fail.  Specification corrected:  Now the specification correctly communicates the behavior of the contract.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Order Salt Problems",
        "body": "  The  salt  is  effectively  a  field  of  an  order  that  allows  different  orders  of  the  same  asset  types  from  the same maker to be distinguishable from each other. This field is also part of the hashKey of the order that is  used  to  track  the  filling  of  the  order.  However,  due  to  the  lack  of  Asset  values  in  the  hashKey,  the same value for salt can be resubmitted with higher-order take value, and thus lead to multiple full filling of the  same  order.  For  example,  an  order  that  makes  20  take  X  after  filling  can  be  resubmitted  with  the same salt and higher take limit: make 30 take 2X. Note that after cancellation the salt becomes unusable for the maker. From a specification point of view, it the order with same hashKey shouldn't be fully filled multiple times.  function hashKey(Order memory order) internal pure returns (bytes32) {     return keccak256(abi.encode(             order.maker,             LibAsset.hash(order.makeAsset.assetType),             LibAsset.hash(order.takeAsset.assetType),             order.salt         )); }  Specification corrected:  The behavior was documented and properly described in exchange-v2/readme.md.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Orders With Salt 0 Can Be Canceled",
        "body": "  The  filling  degree  of  orders  with  salt  0  is  not  tracked  in  the  matchOrders  function.  But  the calculateRemaining function will use the value from fills map to compute the remaining value that needs  to  be  filled.  The  cancel  function  effectively  sets  the  fills  map  value  to  the  UINT256_MAX value. Users can also cancel orders with salt 0, effectively making the asset pair not longer usable with salt 0.  Rarible Inc. - Exchange V2 -   11  DesignMediumVersion1Speci\ufb01cationChangedDesignMediumVersion1CodeCorrected                \f  A check that prevents 0 salt order cancellation was added.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Compiler Version Not Fixed",
        "body": "  The  solidity  compiler  is  not  fixed  in  the  code.  In  addition,  different  files  define  different  pragmas.  The version, however, is defined in the truffle-config.js to be 0.7.6. In the code the following pragma directives are used:  pragma solidity >=0.6.2 <0.8.0; pragma solidity >=0.6.9 <0.8.0;    The pragma was fixed to 0.7.6 for all contracts.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Contracts Can Be Order Makers",
        "body": "  Maker  and  Taker  of  orders  can  be  contracts  with  the  help  of  the  ERC1271  standard.  In  addition,  fee receiving parties can be contracts too. If native ether is used as an asset during the match, the transfers can  fail  if  the  contracts  do  not  implement  a  payable  fallback  function.  The  system  specification  should clearly communicate this requirement to the users.  Specification corrected:  The expectations from contracts were documented and described in exchange-v2/readme.md.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Precision Check in calculateRemaining",
        "body": " Problem  Due  to  a  precision  check  in  function  calculateRemaining  orders  with  different  magnitudes  of  take and make values can become unfillable even with a small filling degree. For example, Order with make 10 take 100 cannot be filled if fill amount of take is 15. In calculateRemaining the remaining make value for that order will be approximated with value 8. Because the true value of 8.5 cannot be expressed with integer numbers, the error of 0.5 will exceed 0.1% limit that is built-in in calculateRemaining due to utilization of LibMath.safeGetPartialAmountFloor function.    precision   The  commit 839710b1bd7ed11fc22fa2093f408934b92ccf35.  This  fix  prevents  premature  order  freeze.  With  the  fix,  in  calculateRemaining   function  was   removed   check   in   Rarible Inc. - Exchange V2 -   12  DesignLowVersion1CodeCorrectedDesignLowVersion1Speci\ufb01cationChangedDesignLowVersion1CodeCorrected                        \fonly  the  last  make  item  of  the  order  can  be  unsellable.  For  example,  an  order  with  make  10  take  100 cannot  be  fully  filled  if  the  fill  amount  of  take  is  95,  as  the  0.5  make  value  will  be  estimated  by calculateRemaining  function  as  0.  With  help  of  order  extension  functionality,  such  orders  can  be fixed  via  signature  resubmission  with  greater  values.  The  precision  check  for  price  computation  is  still used.  Rarible Inc. - Exchange V2 -   13  \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Accumulation of Rounding Errors",
        "body": "  The  fullfilment  of  an  order  is  tracked  by  the  fills  mapping.  The  remaining  part  comes  from  the subtraction of the value the fills mapping holds for a particular order from the total take value of the order.  if (orderLeft.salt != 0) {      fills[leftOrderKeyHash] = leftOrderFill.add(newFill.takeValue); } if (orderRight.salt != 0) {     fills[rightOrderKeyHash] = rightOrderFill.add(newFill.makeValue); }  the  value  added   However,  in LibOrder.calculateRemaining.  Division  might  introduce  some  rounding  erros  which  gradually accumulate  if  an  order  is  partially  filled  multiple  times.  Notice  that  the  implemenation  tolerates  a  0.1% rounding error.  is  a  result  of  a  division  occuring   the  fills  mapping   to   function calculateRemaining(Order memory order, uint fill) internal pure returns (uint makeValue, uint takeValue) {     takeValue = order.takeAsset.value.sub(fill);     makeValue = LibMath.safeGetPartialAmountFloor(order.makeAsset.value, order.takeAsset.value, takeValue); }  function safeGetPartialAmountFloor(     uint256 numerator,     uint256 denominator,     uint256 target ) internal pure returns (uint256 partialAmount) {     if (isRoundingErrorFloor(numerator, denominator, target)) {         revert(\"rounding error\");     }     partialAmount = numerator.mul(target).div(denominator); }  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   AssetMatcher Gas Efficiency",
        "body": "  The matchAssetOneSide function in AssetMatcher contract effectively decides if two assets types can be matched. It also contains logic for matching assets that are not yet known to the systems:  if (classLeft == classRight) {     bytes32 leftHash = keccak256(leftAssetType.data);     bytes32 rightHash = keccak256(rightAssetType.data);     if (leftHash == rightHash) {         return leftAssetType;     } }  Rarible Inc. - Exchange V2 -   14  NoteVersion1NoteVersion1      \fThis piece of code works for all known asset types as well. In addition, it is more efficient than the current matchAssetOneSide for most of the known asset types.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Incentives for Front-Running",
        "body": "  In  case  when  2  assets  that  can  pay  fees  are  exchanged,  the  order  of  arguments  in  matchOrders function might matter. Moreover it determines the price and thus the amounts exchanged between the two  parties.  There  might  be  third  parties  that  are  incentivised  to  front-run  the  transactions  in  order  to determine the position of the orders for their own interest. The users should be aware of such events. In addition,  once  the  transactions  are  visible  in  the  mining  pool,  any  other  parties  can  try  to  frontrun  the match, to profit from matching with lower fees or good price.  Illustration of order importance:  Let  A  and  B  be  an  ERC20  and  ERC1157  token  respectively.  Accoring  to  the  contract  logic  currently implemented,  the  feeable  token  is  A.  Assume  two  orders  O1:(10A,  20B)  and  O2:(50B,11A)  Executing matchOrder(O1, O2) yields fillResult(10A, 20B) (fillLeft will be called). On the other hand, executing  matchOrder(O2,  O1)  yields  fillResult(20B,  220/50A)  (fillRight  will  be  called). Assuming a fee of 10% then in the first case we have 0.1 * 10A and the second 0.1* 220/50 A  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   Orders Can Pay No Fees",
        "body": "  Before transfering the assets to the corresponding parties the fee side is chosen. The side is chosen to be the one that offers ETH or ERC20 or ERC1155. If there is no such types in make and take assets of the order, the fees won't be deducted.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   Reentrancy Risk",
        "body": "  In  the  matchOrders  can  occur  calls  to  other  contacts  and  addresses.  For  example,  during  the  native ether transfer or during the transfer of tokens that allow user hooks e.g. ERC777 (extension of ERC20). While we haven't identified a direct way, how this can be abused. But risk of reentrancy is nullified when a non-reentrant lock is used, for a price of small gas cost increase.  In addition, following transfers of ether will send all the gas to the callee, allowing it to execute any other contract with no restrains.  (bool success,) = to.call{ value: value }(\"\");  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.6   The Order of Orders Determines The Price",
        "body": "  In centralized order book-based exchanges, the price of matchable orders with different prices is usually determined  by  the  order  with  the  earliest  submission  time.  In  the  current  implementation,  the  price  is determined by the left order. While the centralized method is not applicable to this system, the current behavior should be documented in specification, as the users should be aware of the price formation.  Rarible Inc. - Exchange V2 -   15  NoteVersion1NoteVersion1NoteVersion1NoteVersion1                \f7.7   Use of SafeMath  There are many instance where the SafeMath is not used. Such calculations can lead to overflows and, thus, unexpected behavior. No dangerous overflows have been found during the overflow, however, the use  of  SafeMath  is  recommended.  For  example  such  calculations  happen  in  transferPayouts function on sumBps accumulator.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.8   Validate Gas Efficiency",
        "body": "  Function  validate  in  OrderValidator  contract  can  be  restructured  for  a  lower  gas  cost.  The isContract check is performed in all cases when the message sender is not the maker. Assuming that the most popular cases are when the maker is not a contract, the signature check can be performed first, before the isContract check.  Rarible Inc. - Exchange V2 -   16  NoteVersion1NoteVersion1        \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Inefficient _validate",
        "body": "  0  0  0  3  _validate  may  be  refactored  to  be  more  efficient.  The  amount  of  external  calls  executed  may  be reduced.  By checking whether a check of the credit line or the peace is even required first, the call to the Vat and the calculation of the tab could be skipped in case it's not needed. The current code however calls the Vat  initially  and  then  calculates  the  tab,  before  determining  whether  a  credit  line  or  peace  check  is needed.  Acknowledged:  Maker acknowledged the issue.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Skip Calls When No Additional Debt Is Needed",
        "body": "  DssProxyActionsCharter.draw() generates the debt required before exiting the DAI amount to the user's wallet:  // Generates debt in the CDP _frob(charter, ilk, 0, _getDrawDart(charter, vat, jug, ilk, wad)); ... // Exits DAI to the user's wallet as a token DaiJoinLike(daiJoin).exit(msg.sender, wad);  MakerDAO - DSS-Charter -   10  DesignCriticalHighMediumLowAcknowledgedAcknowledgedAcknowledgedDesignLowVersion1AcknowledgedDesignLowVersion1Acknowledged                  \f_getDrawDart() may return 0 if no additional debt is required to exit the specified amount of DAI. The calls  to  CdpManager.frob()  and  Vat.frob()  will  execute  nevertheless  in  this  case,  despite  not being required.  Acknowledged:  Maker acknowledged the issue.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   getOrCreateProxy() or",
        "body": " proxy[msg.sender]  The CharterManager implementation has a function getOrCreateProxy() which returns the address of  an  urn  managed  by  the  CharterManager  for  a  user,  or  creates  a  new  urn  if  it  does  not  exist  yet. Although, the Charter Manager features a public mapping proxy which stores the list of urns and their respective  users,  multiple  functions  in  the  DssProxyActionsCharter  use  getOrCreateProxy  function even when not necessary, i.e., there is no need to create a new urn if it does not exist already. Examples of such functions are wipe(), wipeAll(), cashETH(), or cashGem.  Similarly this also applies to CharterManager.quit().  The CharterManager features functions exit and flux. Both operate on the collateral of the user in the Vat. While flux transfers the collateral in the accounting of the Vat to another address, exit exits the collateral to the user.  From  an  users  perspective,  for  the  account  which  is  the  source  of  the  collateral  these  should  behave similarly.  Exit()  however  uses  proxy[msg.sender]  to  load  the  address  of  the  Urnproxy,  while flux() uses getOrCreateProxy(src).  Acknowledged:  Maker acknowledged the issue.  MakerDAO - DSS-Charter -   11  DesignLowVersion1Acknowledged          \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings   Possible Revert Due to Underflow   -Severity Findings  Inconsistent Retrieval of Ilk Parameter    Possible Optimization on Getting vat Address    Unused Function _toRad()   0  0  1  3  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Possible Revert Due to Underflow",
        "body": "  Should  the  recorded  DAI  balance  of  the  DSProxy  at  the  Vat  exceed  the  amount  required  to  repay  the debt,  the  subtraction  in  DssProxyActionsCharter._getWipeAllWad()  will  underflow  causing  the transaction to revert.    _getWipeAllWad() now returns 0 when enough DAI is available to cover the debt.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Inconsistent Retrieval of Ilk Parameter",
        "body": "  The function cashETH in the DssProxyActionsCharter contract takes as parameters ethJoin and ilk among  others.  However,  in  other  functions,  e.g.,  freeETH(),  wipeAllAndFreeETH(),  etc.  only ethJoin  the  adapter: bytes32 ilk = GemJoinLike(ethJoin).ilk().  is  passed  as  parameter,  while   the  ilk  value   retrieved   from   is     cashEth() and cashGem() now retrieve the ilk from the adapter as the other functions do.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Possible Optimization on Getting vat Address",
        "body": "  MakerDAO - DSS-Charter -   12  CriticalHighMediumCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedDesignMediumVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                         \fMultiple functions in the DssProxyActionsCharter and DssProxyActionsEndCharter contracts receive the vat address as follows: address vat = CharterLike(charter).vat(). Considering that the vat contract is already deployed and its address is not expected to change, the contracts can store this value as immutable or constant to optimise gas costs.    Both  the  address  of  the  VAT  and  the  CharterManager  (which  was  previously  passed  as  function argument) are now stored as immutables.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Unused Function _toRad()",
        "body": "  The function _toRad() is implemented in DssProxyActionsCharter but it is not used.    The unused function has been removed.  MakerDAO - DSS-Charter -   13  DesignLowVersion1CodeCorrected        \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Overflow When Drawing More Than 100",
        "body": " Trillion Debt  Theoretically, the function _getDrawDart() can overflow when computing dart: dart = _toInt256( _mul(netToDraw,  WAD)  /  _sub(_mul(rate,  WAD),  _mul(rate,  nib))).  netToDraw  is  in rad  (45  decimals)  and  wad  has  18  decimals,  therefore  for  large  netToDraw  (greater  than  10**14)  the computation overflows.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Possible Overflow in exit()",
        "body": "  The  function  exit()  in  ManagedGemJoin  contract  converts  uint256  wad  into  a  negative  value: -int256(wad).  Before  the  conversion,  the  following  check  is  performed  to  prevent  overflows: require(wad <= 2 ** 255). Theoretically, if wad == 2 ** 255 the overflow will happen twice, but the result matches the expected value in this case.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Unaware Users and Permissioned Ilks",
        "body": "  Unaware users may deposit collateral for a permissioned ilk. Only when a user attempts to draw debt for such a permissioned ilk the transaction will revert.  The reason is that for a permissioned ilk an unpermissioned user has a credit line of 0, hence cannot take on  debt.  The  error  message  CharterManager/user-line-exceeded  and  the  place  where  the transaction reverts may be confusing for an unaware user.  MakerDAO - DSS-Charter -   14  NoteVersion1NoteVersion1NoteVersion1          \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Fees May Block Slow Path",
        "body": "  The  slow  path  goes  through  L1DAIWormholeBridge.finalizeRegisterWormhole()  which  calls requestMint with maxFee = 0.  When the vat is live, the computed fee in _withdraw function of WormholeJoin may be > 0 and the transaction would revert due to:  require(fee <= maxFee, \"WormholeJoin/max-fee-exceed\");  This essentially prevents users who are censored by the oracle to redeem using the slow path.    The only fee currently present, the WormholeConstantFee, now features a ttl after which the fee returned for this WormholeGUID is 0.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   L2 Addresses",
        "body": "  MakerDAO - DAI Wormhole -   13  CriticalHighCodeCorrectedMediumCodeCorrectedCodeCorrectedLowCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedDesignHighVersion1CodeCorrectedDesignMediumVersion1CodeCorrected                  \fThe address format can differ across L2 systems / different domains the DAI wormhole connects. While the majority work with address of 20 bytes, compatible with the solidity address type, other systems can use other address format. One example of those is StarkNet where addresses of are of type felt which are larger than 20 bytes.    The  receiver  and  operator  fields  of  the  WormholeGUID  struct  have  been  replaced  by  bytes32 types to accommodate for address formats up to 32 bytes.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Minting Pending DAI Incurs Additional Fees",
        "body": "  Using the DAI Wormhole may take a fee from the user. This fee is taken on L1 and transferred to the VOW.  The  fee  is  accounted  for  inside  _withdraw()  and  calculated  using  an  external  Fee  adapter contract based on the wormholeGUID which contains all information about the transfer, the current debt and the line, the debt ceiling according to the source domain.  The amount of the fee taken is calculated before determination of the amount that is withdrawn.  uint256 fee = vatLive ? FeesLike(fees[wormholeGUID.sourceDomain]).getFees(wormholeGUID, line_, debt_) : 0; require(fee <= maxFee, \"WormholeJoin/max-fee-exceed\");  uint256 amtToTake = _min(                         pending,                         uint256(int256(line_) - debt_)                     );  The fee is based on the full amount of the wormholeGUID being processed, not on the actual amount withdrawn in this transaction. The actual amount withdrawn is limited by the maximum debt that can be created without exceeding the ceiling. The remaining amount can be retrieved later when more debt can be  accrued  using  mintPending().  This  however  again  uses  function  _withdraw  which  again calculates the fee based on the full amount of the wormholeGUID, the current debt and debt ceiling. The pending amount is not taken into account for the calculation of the fee.  Hence, should the amount to be withdrawn be limited by the remaining space between the debt ceiling (line) and the current debt, the user pays fees based on the full amount, not the amount being withdrawn. Later,  when  the  remaining  pending  amount  is  withdrawn,  the  user  again  pays  fees  based  on  the  full amount of the wormholeGUID, effectively paying again for the same transfer.    The fee computation function getFee takes more parameters (pending, amtToTake) into account. This allows  more  versatile  ways  to  compute  the  fee.  For  example,  WormholeConstantFee  can  now compute the fee relative to the amount being withdrawn instead of the full fee every time the full amount is partially withdrawn.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   Missing or Incomplete Natspec",
        "body": "   requestMint,  _mint  and  mintPending  are  missing  the  natspec  for  their  second  return  value  totalFee.  MakerDAO - DAI Wormhole -   14  DesignMediumVersion1CodeCorrectedDesignLowVersion2CodeCorrected                \fthe cure and getFee functions specification should specify the unit of its return value.  the isValid function specification should describe the return value.  the v, r and s parameters of BasicRelay.relay should be described in the specification    The issues raised above have been addressed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   Specification Mismatch",
        "body": "  The  specification  of  the  mintPending  function  says  that  it  is  only  callable  by  the  operator,  but  the receiver is also allowed to call the function.  Specification changed:  The description of the mintPending function has been fixed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.6   Code Inefficiency",
        "body": "   signers mapping in WormholeOracleAuth is address => bool, it would be more gas efficient  to have a address => uint256.  in  WormholeOracleAuth,  threshold  is  passed  as  a  function  parameter  in  isValid. threshold is a storage variable in the contract and thus can be accessed directly from isValid function and does not need to be passed as a parameter, this would save gas.  in  _withdraw  function  of  WormholeJoin,  the  overflow  check  for  _line  happens  every  time. Checking for overflow only once in the file function where the line for a domain is set would save gas.    the signers mapping has been changed to a mapping(address => uint256).   MakerDAO  wants  the  isValid  function  to  be  used  by  anyone  who  wants  to  verify  an  oracle  attestation.  the  file  function  checks  for  _line  validity  and  the  check  has  been  removed  from  _mint  (new version of _withdraw).  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.7   Interface Mismatch",
        "body": "  MakerDAO - DAI Wormhole -   15  CorrectnessLowVersion2Speci\ufb01cationChangedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                               \f The   of   signature   is function approve(address, uint256) external returns(bool);, but WormholeJoin as and  function  approve(address,  uint256)  external;  in  the  interface  they  define  for TokenLike.  L1DAIWormholeBridge   approve   token's   have   DAI   the   it   Version 2:   The interface signature of requestMint in WormholeRouter exposes only one return value out of two. The interface signature of requestMint in L1DAIWormholeBridge exposes no return value at all.  The  compiler  will  just  drop  the  unused  return  values  without  causing  an  error,  but  this  design choice does not reflect the correct signatures and should be documented.     WormholeJoin  and  L1DAIWormholeBridge  have  the  correct  interface  for  the  DAI  token's  approve function.   The interface signature of requestMint() in WormholeRouter has been fixed in   .   L1DAIWormholeBridge  is  now  called  L1DAIWormholeGateway.  The  interface  is  now  defined  correctly in the imported WormholeInterface.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.8   Missing Index",
        "body": "   domain fields are indexed in WormholeJoin events. It could be useful to index the domain field of  WormholeRouter's File event to make it more easily searchable.   targetDomain  field  in  Flushed  event  of  L2DAIWormholeBridge  can  be  indexed  to  ease  its  search.    the domain fields in the File events are indexed.  the targetDomain field in the Flushed event is indexed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.9   file() Casting Bytes32 to Uint256",
        "body": "  Contrary to the other contracts which have multiple file functions with the data parameter of the actual type of the data passed, the WormholeOracleAuth has a file function taking a bytes32 argument as data which is then casted to uint256.    The  file  function  responsible  for  the  threshold  parameter  now  takes  directly  a  uint256  data  to avoid an unnecessary conversion.  MakerDAO - DAI Wormhole -   16  Version3DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                  \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Breaking Changes of the Solidity Compiler",
        "body": "  The new compiler version behaves differently on code related to integer conversion/negation when the value is exactly 2**255.  The core DSS system which has been compiled with compiler version 0.6.12 first ensures that the value of the uint is below or equal to 2**255 before converting it to a (negative) integer.  An example of this pattern can be found in e.g. GemJoin.exit():  require(wad <= 2 ** 255, \"GemJoin/overflow\");        vat.slip(ilk, msg.sender, -int(wad));  This  project,  DSS-Wormhole  uses  a  more  recent  compiler  version  0.8.9.  Negating  2**255  is  no  longer possible and will result in the transaction reverting.  In DSS-Wormhole, WormholeJoin.settle() features such a pattern:  function settle(bytes32 sourceDomain, uint256 batchedDaiToFlush) external {     require(batchedDaiToFlush <= 2 ** 255, \"WormholeJoin/overflow\");     daiJoin.join(address(this), batchedDaiToFlush);     if (vat.live() == 1) {         (, uint256 art) = vat.urns(ilk, address(this)); // rate == RAY => normalized debt == actual debt         uint256 amtToPayBack = _min(batchedDaiToFlush, art);         vat.frob(ilk, address(this), address(this), address(this), -int256(amtToPayBack), -int256(amtToPayBack));  Note  that  in  this  case  the  check  is  superflous:  The  multiplication  in  daiJoin.join()  will  revert  due  to  an overflow on even lower values.  Nevertheless  it's  important  to  be  aware  of  this  behavior,  the  same  code  pattern  behaves  differently depending on the compiler version. This requires careful attention especially when such contracts, which have been compiled with different compiler versions, e.g. DSS-Wormhole and the VAT interact.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Finality and State Change on L2",
        "body": "  The notion of finality of transactions and the resulting state change differs across the L2 solutions. The Wormhole  system,  especially  the  Maker  Oracle  Feeds  must  be  aware  of  that  and  take  each  finality definition into account. Ideally this is properly assessed and documented for each Domain the Wormhole connects to.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.3   Slow Path Requires Zero Fee",
        "body": "  The  slow  path  successful redemption of the wormhole with no fee due to:  through  L1DAIWormholeBridge.finalizeRegisterWormhole()   requires  MakerDAO - DAI Wormhole -   17  NoteVersion1NoteVersion1NoteVersion1          \ffunction finalizeRegisterWormhole(WormholeGUID calldata wormhole)     external     onlyFromCrossDomainAccount(l2DAIWormholeBridge) {     wormholeRouter.requestMint(wormhole, 0, 0); }  The interface definition of WormholeFees emphasizes this:  It should return 0 for wormholes that are being slow withdrawn.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.4   Surplus DAI for WormholeJoin in the VAT",
        "body": "  Function  settle()  of  the  WormholeJoin  contract  is  permissionless  and  given  enough  DAI  token balance  of  the  WormholeJoin  contract  (e.g.,  provided  by  the  caller)  can  be  executed  by  anyone. DaiJoin.join() returns the DAI tokens into the system and the contract's balance tracked by the DAI mapping  of  the  VAT  increases  accordingly.  This  increased  balance  however  is  stuck  when  everything has been settled.  Note  that  the  sourceDomain  can  be  chosen  arbitrarily  by  the  untrusted  caller.  Listeners  of  the  event Settle  must  be  aware  that  this  event  may  be  triggered  by  anyone  and  may  not  represent  a  debt repayment coming from the bridges.  MakerDAO - DAI Wormhole -   18  NoteVersion1    \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Slashing Can Be Avoided",
        "body": "  For Kiln, the smart contract layer does not immediately know when a slashing event on the Consensus Layer  has  happened.  Offchain,  however,  it  is  easy  to  immediately  know  when  a  validator  has  been slashed.  A user of an enzyme vault that uses one of the staking external positions could monitor for slashings and immediately  withdraw  from  the  vault  when  such  an  event  happens.  By  doing  this,  they  will  be  able  to redeem their assets (up to the available liquidity) at the pre-slashing price.  Once the slashing is accounted for in the vault (after about 36+ days for Kiln), the slashing loss of the users that withdrew previously will instead be taken by those users that are still deposited in the vault.  CS-SUL11-001  Risk accepted:  Avantgarde Finance acknowledged the issue and replied:  Since consensus layer slashing is not readable directly from the execution layer, slashing can only be made known by posting to the execution layer, and there will always be an opportunity to front-run posting (the same goes for Chainlink aggregators).  Fund managers must be aware of this risk and take any necessary precautions to mitigate the risk where needed, e.g., via policies and/or queued redemptions.  Avantgarde Finance - Sulu Extensions XI -   10  DesignCorrectnessCriticalHighMediumRiskAcceptedLowRiskAcceptedRiskAcceptedDesignMediumVersion1RiskAccepted            \f5.2   Pricing ERC4626  The pricing of ERC-4626 tokens could be off. Namely, convertToAssets() does not include:  fees   variations among callers (no price per user but rather an average among users)  CS-SUL11-002   slippage or other on-chain conditions  Ultimately, the fund could be under-/overvalued.  Risk accepted:  Avantgarde Finance replied:  The Enzyme Council will need to review each new class of erc4626 asset to determine whether convertToAssets() is potentially significantly deviant from actual redemption  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   Unclaimed Staking Rewards Are Not Valued",
        "body": "  In KilnStakingPositionLib, getManagedAssets simply returns validatorCount * 32ETH.  However, there may be a significant amount of staking rewards that are owed to the vault, if they haven't been  claimed  recently.  Rewards  are  only  accounted  for  in  the  vault's  valuation  once  they  are  claimed, which only the vault manager can do using the claimFeesAction. This action is very gas-intensive, so it will likely not be called often.  The  actual  value  of  the  external  position  will  be  under-represented,  which  may  lead  to  share  price arbitrage.  CS-SUL11-005  Risk accepted:  Avantgarde Finance replied:  Since accrued rewards live in distinct execution layer and consensus layer contracts per validator, it is too gas-intensive to query balances across all validators on every position value query.  Fund managers must be aware of this risk and take any necessary precautions to mitigate the risk where needed, e.g., claiming rewards with reasonable frequency, policies, and/or queued deposits and redemptions.  Avantgarde Finance - Sulu Extensions XI -   11  CorrectnessLowVersion1RiskAcceptedDesignLowVersion1RiskAccepted               \f6   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Convex and Aura removeToken Clarification",
        "body": "  The  Convex  and  Aura  staking  wrappers  implement  the  function  removeExtraRewardToken()  to remove certain extra tokens. The function intends to remove extra reward tokens that led to errors in the previous  implementation  so  that  they  can  be  readded  later  on  in  a  correct  way  using  the  logic  for  the stash tokens. Its intention is not to remove extra reward tokens forever (since all reward tokens will be added automatically even if they had been removed).  The  wrappers  wrap  the  addition  of  extra  reward  tokens  in  a  try/catch  block.  When  adding  multiple tokens, if the addition of any of the extra reward tokens would fail, none of the reward tokens would be added. This is the intended behaviour that enzyme expects.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   ERC4626 Considerations",
        "body": "  No extra steps needed to deposit or redeem (besides ERC-20 approval) should be present. Otherwise, the adapter will not work as intended. Any additional logic on top of what is specified in the ERC should be carefully evaluated.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   ERC4626 minIncomingShares Must Be Used",
        "body": "  ERC4626 vaults can be affected by rounding issues when depositing.  This is mitigated in the ERC4626Adapter by letting managers specify a minIncomingSharesAmount.  It is important that managers specify a reasonable amount, to limit the impact of rounding errors.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Kiln Bad Accounting",
        "body": "  In Kiln, the admin of the staking contract can withdraw from the CL fee recipient contract. If that occurs after an exit, and the vault manager performs an action that sweeps ETH from the external position (e.g. claim  fees,  sweep  ETH),  then  the  accounting  will  be  off.  Namely,  the  exited  validator  will  be  still accounted for (32 ETH) while the exited ETH will be in the vault proxy. Ultimately, double-counting assets could be possible. Hence, the share price will be too high.  Further,  donations  could  be  made  to  the  CL  fee  recipient  contract  so  that  the  threshold  is  reached. Ultimately,  when  claiming  CL  fees,  the  validator  count  would  be  reduced  even  though  there  was  no validator exit. The value of the fund could be reduced.  Avantgarde Finance - Sulu Extensions XI -   12  NoteVersion1NoteVersion1NoteVersion1NoteVersion1              \fSlashed validators will not be removed in the case of a mass slashing event, where the slashed amount is  larger  than  32  ETH  -  EXITED_VALIDATOR_THRESHOLD.  The  value  of  the  fund  would  be overestimated in this case.  Note that the threshold should be very carefully chosen so that the system works properly all of the time while not allowing arbitrage opportunities. Fund managers and asset managers are expected to actively monitor for bad scenarios so that they can pause the external position's valuation. Once paused, they are expected to reconcile with Avantgarde Finance so that a contract upgrade can be released that fixes the issue.  Further, note that Avantgarde Finance is aware of this but decided to implement more complex logic for these rather unlikely corner cases only if necessary.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Kiln Fees on Slashing",
        "body": "  Note the following documented behaviour in Kiln:  In case of slashing, the exit is not requested we don't exempt anything [from fees]. This is in case of slashing,  the  staker  will  be  rebated  manually.  A  slashed  validator  may  have  accumulated  enough skimmed  rewards  to  still  have  a  balance  >  32  ETH.  All  of  this  will  be  taken  into  account  and  the staker will be compensated for the commission taken. on its principal and the loss according to the SLA described in the Terms&Conditions.  Kiln takes a fee on the total leftover ETH balance if a slashing event leaves a position under 31 ETH. As this amount must be manually returned by Kiln, it will not be considered in the valuation of the enzyme vault  until  that  process  is  completed.  This  may  lead  to  undervaluing  the  vault.  If  Kiln  returns  the  owed amount to the external position rather than the vault directly, the amount will only be counted once the vault manager calls the sweepETH action.  Avantgarde Finance - Sulu Extensions XI -   13  NoteVersion1    \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   ERC-20 Missing Return Value",
        "body": "  ArrangerConduit handles ERC-20 transfers in the following way:  require(     ERC20Like(asset).transfer(destination, amount),     \"ArrangerConduit/transfer-failed\" );  0  0  0  2  CS-MDAC-001  This assumes that all ERC-20 contracts that can be called return a boolean value in their transfer() and  transferFrom()  functions.  This  is  however  not  the  case.  Popular  tokens  like  USDT  are  not returning any value in the mentioned functions. If it were to happen that the arranger sends such tokens to the contract, the tokens would be locked and require an update of the contract.  Specification changed:  Transfers  are  now  performed  without  checking  the  return  values  of  ERC20  tokens  at  all.  MakerDAO assures that only tokens that revert on failure are used as assets in the contract.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Floating Pragma",
        "body": "  The ArrangerConduit contract is not set to a fixed solidity version - neither in the contract nor in the Foundry  configuration.  This  can  lead  to  unintended  side-effects  when  the  contract  is  compiled  with different compiler versions.  CS-MDAC-002    MakerDAO - ArrangerConduit -   10  CriticalHighMediumLowSpeci\ufb01cationChangedCodeCorrectedDesignLowVersion1Speci\ufb01cationChangedDesignLowVersion1CodeCorrected                \fThe compiler version 0.8.16 has been added to the Foundry configuration.  MakerDAO - ArrangerConduit -   11  \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Incorrect maxDeposit() Return Value",
        "body": "  ArrangerConduit.maxDeposit()  always  returns  type(uint256).max.  This  value  is,  however, only  correct  if  the  contract  does  not  hold  any  tokens  of  the  given  asset  at  the  time  of  the  call. Furthermore, some tokens have a lower maximum (e.g., type(uint96).max in the COMP token).  CS-MDAC-003  MakerDAO - ArrangerConduit -   12  InformationalVersion1  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Outdated Compiler Version",
        "body": "  The project uses an outdated version of the Solidity compiler.  pragma solidity 0.6.6;  in  Known  https://github.com/ethereum/solidity/blob/develop/docs/bugs_by_version.json#L1416  version   bugs   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "0.6.6 ",
        "body": "  0  0  0  2  are:  More information about these bugs can be found here: https://docs.soliditylang.org/en/latest/bugs.html  At  the  time  of  writing  the  most  recent  Solidity  release  is  version  0.6.12.  For  version  0.6.x  the  most recent release is 0.6.12 which contains some bugfixes but no breaking changes.  The compiler was not changed as the client responded:  We will address this later for an overall code review.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   _weth Could Be a Constant",
        "body": "  The  constant  _weth  which  represents  the  same  address  across  all  Enzyme  Bridges  could  be  set  as constant. This would reduce unnessesary storage operations.  Acknowledged:  Avantgarde Finance - Unslashed-Enzyme Bridge -   8  DesignCorrectnessCriticalHighMediumLowRiskAcceptedAcknowledgedDesignLowVersion1RiskAcceptedDesignLowVersion1Acknowledged                  \fAvantgarde Finance is aware of this and commented that it does have a significant impact as the variable will be accessed a few times only.  Avantgarde Finance - Unslashed-Enzyme Bridge -   9    \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings  -Severity Findings   Denomination Asset Check on Initialization    Redeem Shares Return Value Not Used    withdrawEthToInvestor Specification Discrepancy   0  0  0  3  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Denomination Asset Check on Initialization",
        "body": "  For the correct operation of the bridge, it is critical that the denomination asset of the vault is correctly set to WETH during initialization. Such a check is not present in the code.  Code Changed:  A check has been introduced in the initialize function  require(IComptrollerProxy(controllerProxy).getDenominationAsset() == weth, \"EnzymeBridge: wrong fund asset\");  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Redeem Shares Return Value Not Used",
        "body": "  The return values of  IComptrollerProxy(_controllerProxy).redeemShares()  and  IComptrollerProxy(_controllerProxy).redeemSharesDetailed(...)  are  not  used.  Both  functions  return  the  payout  assets  and  amounts.  Instead,  the  resulting  amount  of tokens  is  checked  using  balanceOf(...),  incurring  additional  gas  costs.  The  benefit  of  the  current implementation  is  the  fact  that  one  can  withdraw  tokens  that  were  already  in  the  vault  before  the redemption. However, this choice is inconsistent with the later choice to only send the ether which was recently unwrapped.  Avantgarde Finance - Unslashed-Enzyme Bridge -   10  CriticalHighMediumLowCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \fuint256 result = IWETH9(_weth).balanceOf(address(this)); IWETH9(_weth).withdraw(result); // returns eth to us IInvestable(_investor).receiveEthFromFund{value: result}();  Code Corrected:  return  value  of  redeemShares  and The  code  has  been  changed  so  redeemSharesDetailed. Moreover, the returned result is used to ensure that only one returned asset is used. Finally, the code now withdraws a consistent amount of WETH and ETH. of  it  uses   the   (, payoutAmounts) = IComptrollerProxy(_comptrollerProxy).redeemShares();  ....  (, payoutAmounts) = IComptrollerProxy(_comptrollerProxy).redeemSharesDetailed(sharesQuantity, empty, empty); ...  require(payoutAmounts.length == 1, \"EnzymeBridge: fund not converted\"); ...  uint256 result = payoutAmounts[0]; IWETH9(_weth).withdraw(result); // returns eth to us IInvestable(_investor).receiveEthFromFund{value: result}();  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   withdrawEthToInvestor Specification",
        "body": " Discrepancy  The comment for withdrawEthToInvestor reads as follows: Note that due to possible sha re value rounding the resulting amount may be slightly greater than requested .  Another rounding error may happen when the shares' quantity required is calculated:  uint256 sharesQuantity = amount.mul(PRECISION_18E).div(shareValue18ePrecision);  Consider  the  case  when  the  share  value  is  not  affected  by  rounding  errors.  Due  to  possible  rounding errors  when  the  shares'  quantity  is  calculated,  the  shares'  quantity  required  to  receive  the  amount  in WETH may be underestimated. Hence the Ether amount withdrawn might be slightly smaller and thus the comment does not hold.  Specification Changed:  The documentation correctly now states:  /// Note that due to possible share value or division rounding /// the resulting amount may be slightly greater or smaller than requested.  Avantgarde Finance - Unslashed-Enzyme Bridge -   11  CorrectnessLowVersion1Speci\ufb01cationChanged        \f7   Notes  We leverage this section to highlight further findings that are not necessarily issues. The bridge contract in  scope  for  this  review  connects  Unslashed  to  Enzyme  which  consists  of  many  interacting  contracts. Hence, the mentioned topics serve to clarify or support the report, but do not require a modification inside the project. Instead, they should raise awareness in order to improve the overall understanding for users and developers  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Illiquid Lending Providers",
        "body": "  The  basket  can  only  withdraw  when  all  assets  of  the  fund  have  been  exchanged  into  WETH.  Illiquid liquidity protocols may be unable to redeem a large amount of tokens at times. Hence a fund manager may be unable to redeem all assets into their underlying.  E.g. a large amount of WETH has been lent into the Aave liquidity pool. When the fund manager wants to redeem this large amount of derivative tokens back into the underlying WETH, it could be the case that the liquidity may be insufficient as currently a large amount of WETH is lent out.  During this period Ether withdrawal is blocked.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Migration to New Enzyme Release Is Not",
        "body": " Supported  This  Enzyme  Bridge  in  connection  with  the  current  implementation  of  the  Basket  contract  does  not support the migration of a fund to a new release of Enzyme.  When a fund is upgraded in Enzyme, the ComptrollerProxy is replaced by a new one while the old one is selfdestructed. The VaultProxy holding the funds remains.  After such a migration all calls from the bridge to the comptroller will fail as the contract no longer exists. This affects all three functions ( deposit / withdraw / getBalance ).  Note that function setFund() of the basket contract cannot be used to recover from this situation: This function  requires  the  fund's  balance  to  be  0.  The  call  to  the  non-existing  comptroller  will  revert  the transaction.  All shares should be redeemed before a migration is initiated. Shares remaining after a migration might be stuck with the current code.  After looking at the migration scripts present, we understand that the EnzymeBridge is to be used via a Proxy. This would allow to upgrade the implementation and recover the shares.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   No Fees",
        "body": "  Funds of Enzyme can configure fees investors have to pay in order to participate in a fund. These fees are paid to the fund manager in the form of shares. Note that the implementation of the Enzyme Bridge relies  on  the  fact  that  the  basket  is  the  only  shareholder  of  the  fund  and  no  other  address  holds  such shares. Hence enabled fees for the fund are not compatible with the bridge, funds of the bridge must not have fees configured.  Avantgarde Finance - Unslashed-Enzyme Bridge -   12  NoteVersion1NoteVersion1NoteVersion1          \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Pull DAI From Vow All at Once",
        "body": "  During  a  kick()  call,  two  operations  (a  swap  and  a  mint)  on  the  UniswapV2  pair  are  executed consecutively. For each operation, an external call to the vat and daiJoin are invoked beforehand to pull the  required  DAI.  However,  the  pool  state  after  the  swap  can  be  precomputed,  which  means  the  total amount of DAI needed can be precomputed as well. It might be worth to do this to reduce the gas used and hence make the transactions slightly cheaper.  CS-MUF-003    The amount of DAI is now precomputed and pulled once.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Incorrect Comment",
        "body": "  The comment 997 is the Uniswap LP fee in _getAmountOut() is incorrect. 99.7% represents the amount after deducting the fee, and the fee is 0.3%.  CS-MUF-002  function _getAmountOut(uint256 amtIn, uint256 reserveIn, uint256 reserveOut) internal pure returns (uint256 amtOut) {     uint256 _amtInFee = amtIn * 997; // 997 is the Uniswap LP fee     amtOut = _amtInFee * reserveOut / (reserveIn * 1000 + _amtInFee); }  Specification changed:  The incorrect comment has been removed.  MakerDAO - FlapperUniV2 -   12  CriticalHighMediumLowCodeCorrectedDesignLowVersion1CodeCorrectedInformationalVersion1Speci\ufb01cationChanged              \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Revert Reason When FlapperMom Stops",
        "body": " Flapper  FlapperMom can inhibit FlapperUniV2 in an emergency. It does so by setting the minimum time between two  executions  of  kick()  to  type.max(uint256).  kick()  will  then  revert  due  to  the  addition overflow:  CS-MUF-001  require(block.timestamp >= zzz + hop, \"FlapperUniV2/kicked-too-soon\");  Except when kick() has never been executed before and zzz is still equal to 0, the require statement will cause the revert and emit the error MessageChannel.  MakerDAO - FlapperUniV2 -   13  InformationalVersion1  \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   More Than bump Amount of DAI Used",
        "body": "  The Vow contract has been designed and documented with the original Flapper auctioning surplus DAI for MKR tokens in mind.  // Surplus auction function flap() external returns (uint id) {     require(vat.dai(address(this)) >= add(add(vat.sin(address(this)), bump), hump), \"Vow/insufficient-surplus\");     require(sub(sub(vat.sin(address(this)), Sin), Ash) == 0, \"Vow/debt-not-zero\");     id = flapper.kick(bump, 0); }  By design, the new FlapperUniV2 may utilize up to 2.2 times the bump amount. The Vow contract may not anticipate the Flapper using more than the bump amount of DAI.  Depending  on  the  values  set  for  bump  and  hump,  this  could  result  in  the  Vow  contract  unexpectedly holding  less  than  hump  (surplus  buffer)  amount  of  DAI  after  a  call  to  kick(),  or  a  call  to  kick() unexpectedly reverting if the required amount of DAI is not available.  This behavior is now described in the README.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Unexpected Pair State",
        "body": "  Generally  it  is  assumed  that  the  free  market  ensures  the  pair  represents  the  current  market  rate. However this can not be relied on as the state of the pair might be changed just before calling kick(). There  are  various  possibilities  why  the  pair  could  be  in  a  state  not  matching  the  current  market  rate. Notably e.g. in case there is an unaccounted donation of tokens in the Uniswap pool (balance > reserve), the flapper will first call sync() on the pair and swap on the updated balances afterwards. This state can also be reached by an attacker donating and calling sync directly. Furthermore the state may be changed by trading.  Generally the possible manipulation is bounded by the following checks:  In case the swapping ratio deviates too much from the reference price feed, kick() will revert.  In case the liquidity of the pool is too shallow and the amount of surplus deposited back goes over 120% of swapped, kick() will also revert.  In theory, the following manipulations by donations are possible:   One can donate within the price tolerance want to make the flapper trade at a bad price.   One  can  intentionally  donate  to  revert  a  kick()  by  pushing  the  price  out  of  the  price  tolerance  want.   One  can  also  donate  to  increase  the  liquidity  and  make  a  kick()  which  was  going  to  revert  (deposited larger than 120% of swapped) succeed.  MakerDAO - FlapperUniV2 -   14  NoteVersion1NoteVersion1        \fMakerDAO is aware and adds the following considerations:  * One can donate within the price tolerance want to make the flapper trade at a bad price - the assumption is that any trade above `want` is viable. It is of course possible for anyone to move the price with a swap, which is probably even more economical than a donation. As long as `want` and `lot` are set correctly both type of attempts should not be economical and are of course known limitations of a permissionless system.  * One can intentionally donate to revert a kick() by pushing the price out of the price tolerance want - same as above, this can happen with a swap and is a known given. Keepers can use flashbots to avoid it.  * One can also donate to increase the liquidity and make a kick() which was going to revert (deposited larger than 120% of swapped) succeed - if the kick succeeds it is intended behavior.  MakerDAO - FlapperUniV2 -   15  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Weights in Balancer Managed Pools Can",
        "body": " Change  The Balancer V2 price feed reads the weights of the Balancer pool during deployment and stores them as  immutable.  The  oracle  also  supports  managed  pools,  with  getActualSupply(),  but  from  the Balancer documentation (https://web.archive.org/web/20230928124529/https://docs.balancer.fi/concepts /pools/managed.html#weights) the weights can be changed by the pool owner. Changing the weights of the pool will break the oracle as the price of the respective lp tokens depends on these weights.  CS-GEARV3ORACLES-004  Spec changed:  Gearbox Protocol responded that they do not intend to support Balancer-managed pools.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Missing Duplicate Signer Check",
        "body": "  In the constructor of the RedstonePriceFeed contract, there is no check for duplicate signer address in the _signers array. If the number of unique signers does not exceed the required threshold, the oracle will not be able to update its price and will become unusable.  CS-GEARV3ORACLES-005    Gearbox Protocol - Gearbox V3 Oracles -   12  CriticalHighMediumSpeci\ufb01cationChangedLowCodeCorrectedCodeCorrectedCodeCorrectedDesignMediumVersion1Speci\ufb01cationChangedDesignLowVersion1CodeCorrected                \fA  check  for  duplicates  has  been  added  to  the  constructor.  The  deployment  will  revert  if  there  are duplicates or if the number of signers does not reach the required threshold.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Gas Optimizations",
        "body": "   The  function  latestRoundData  of  contracts  ZeroPriceFeed  and  RedstonePriceFeed  unnecessarily define the variables answer and updatedAt.  CS-GEARV3ORACLES-002    The unnecessary variables have been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Permissionless Updating Bounds",
        "body": "  LPPriceFeed.updateBounds() allows everyone to update the bounds of an LP price oracle should updateBoundsAllowed  be  set  to  true.  The  bounds  depend  on  the  current  LP  price  reported  by  the reserve oracle and the prices of the underlying assets. It is important to note that if the price of the LP protocol  can  be  manipulated,  then  the  bounds  will  also  be  wrongly  updated.  Hence,  enabling  the permissionless update of the bound should be carefully considered by the governance of the protocol.  CS-GEARV3ORACLES-003    The buffer size has been increased from 0.2% to 1%, allowing a lower lower-bound.  The function LPPriceFeed.setUpdateBoundsAllowed() has been split into two functions:   LPPriceFeed.allowBoundsUpdate(): only the configurator can enable permissionless updates   LPPriceFeed.forbidBoundsUpdate():   the  configurator  and   the  controller  can  disable  permissionless updates  The function LPPriceFeed.updateBounds() has been modified in the following ways:   a cooldown of 1 day between to permissionless updates is enforced  the current LPPriceFeed explicitly cannot be its own reserve price feed  the reserve exchange rate must be within the bounds  Gearbox Protocol - Gearbox V3 Oracles -   13  InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected              \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Pricefeed Addresses Order",
        "body": "  CS-GEARV3ORACLES-001  In  the  contracts  BPTStablePriceFeed  and  CurveStableLPPriceFeed,  the  number  of  assets  is derived from the content of the priceFeeds array. The number of assets will be the number of non-zero addresses  before  the  first  zero  address  in  the  array.  It  means  that  if  an  array  of  the  form [priceFeed0,  priceFeed1,  address(0),  priceFeed2]  the  construction arguments, the oracle will only consider 2 assets.  is  passed   in   Acknowledged:  Gearbox Protocol is aware of this special case.  Gearbox Protocol - Gearbox V3 Oracles -   14  InformationalVersion1Acknowledged    \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Implementation of the Integrated ERC4626",
        "body": "  The  implementation  of  the  ERC4626  that  are  whitelisted  for  use  within  Gearbox  Protocol  V3  must  be carefully  reviewed.  As  the  standard  makes  very  few  assumptions  about  the  implementation  of  a tokenized vault, many issues might arise such as the possibility of read-only reentrancy.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Read-only Reentrancy on Curve and Balancer",
        "body": " Pools  to  possible   Some of the ETH Curve pools send ETH to the LP before the other tokens when removing liquidity, this leads  returned  by get_virtual_price() is over-evaluated. An attacker could use this to do bad trades or increase its leverage, but it will become liquidatable right after the transaction.  reentrancy.  During  such   reentrancy,   the  value   read-only   This is also valid for Balancer V2 and the function getRate() and getActualSupply (see https://web .archive.org/web/20230928133723/https://docs.balancer.fi/reference/contracts/apis/managed.html#getac tualsupply).  The prices of all LP price feeds are bounded. This means an attack-based read-only reentrancy can have very limited if any benefit for the attacker. Of course, this is based on the assumption that the bounds are set to reasonable values the prevent such attacks.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.3   RedStone Price Update Frequency",
        "body": "  The  use  of  RedStone  price  oracle  in  the  system  allows  for  high-frequency  price  updates  compared  to more  traditional  price  oracles  like  ChainLink.  This  means,  in  case  of  rapid  price  fluctuations,  credit accounts  may  become  liquidatable  or  seem  like  they  hold  a  higher  value  allowing  them  to  borrow  or withdraw more assets.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.4   Use of Stored Exchange Rate for Compound",
        "body": " V2  In  CompoundV2PriceFeed  the  price  of  the  lp  tokens  is  computed  using  exchangeRateStored(). The  alternative  is  exchangeRateCurrent()  which  returns  a  more  recent  price  as  it  iternally  calls accrueInterest(). It is important to note that exchangeRateStored() is called from within a view  Gearbox Protocol - Gearbox V3 Oracles -   15  NoteVersion1NoteVersion1NoteVersion1NoteVersion1              \ffunction and thus it's a view function itself. exchangeRateCurrent() cannot be used as it is not a view function.  Gearbox Protocol - Gearbox V3 Oracles -   16  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Some CryptoSwap Pools Do Not Implement",
        "body": " the lp_price() Function  Not every CryptoSwap pool of the Curve protocol implements the lp_price() function that is used in the CurveNPAPTokensPriceProvider. The only exception that was added is the tricrypto2.  Acknowledged:  Silo Finance replied:  We will implement them if we need it. For now we need only tricrypto2.  Silo Finance - Curve & Convex Feature -   11  SecurityDesignCorrectnessCriticalHighMediumLowAcknowledgedCorrectnessLowVersion1Acknowledged             \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings   Curve LP Oracle Is Vulnerable to Read-Only Reentrancy Attacks    CurvePriveProvider Uses the Spot Price   -Severity Findings   Collateral Token Transfers Are Not Taken Into Account   -Severity Findings   Missing Shutdown Logic   -Severity Findings   A Metapool Could Have More Than One Nested LP Token    Metapool Setup Recursion Lacks Sanity Check    Metapools With Two LP Underlying    Missing Events for State Modifying Actions    The Reward Integral Computation Can Overflow   IWrapperDepositor Not Implemented   2  1  1  6  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Curve LP Oracle Is Vulnerable to Read-Only",
        "body": " Reentrancy Attacks  The Curve LP oracle smart contracts can be manipulated by using the read-only reentrancy vulnerability. This is because no checks are done regarding the reentrant state of the curve pool. For further details please see our blog post: https://chainsecurity.com/curve-lp-oracle-manipulation-post-mortem/.    A protection mechanism has been implemented.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   CurvePriveProvider Uses the Spot Price",
        "body": "  The  CurvePriceProvider  smart  contract  uses  the  spot  price  of  the  curve  pool  to  get  the  price  of assets. This is done by calling the get_dy() function on the curve pool.  Silo Finance - Curve & Convex Feature -   12  CriticalCodeCorrectedCodeCorrectedHighCodeCorrectedMediumCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedDesignCriticalVersion1CodeCorrectedSecurityCriticalVersion1CodeCorrected                 \fHence, an attacker could easily manipulate the price with a flash loan or a lot of liquidity. If this oracle is used  as  a  source  of  truth  for  a  borrowing  or  liquidation  mechanism,  funds  could  be  stolen  from  the protocol.  Further note, that also the IPriceProvider's NatSpec is not accurate in that case as it specifies that the TWAP is calculated.  Code removed:  All related code has been removed. Curve is not used as a price provider anymore.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Collateral Token Transfers Are Not Taken Into",
        "body": " Account  The balance used for payouts is the sum of the ERC-20 balance and the user's Silo collateral-only shares (converted to the ERC-20). Hence, each change in one of these balances must ensure the correctness of payouts. While the ConvexStakingWrapperSilo contract performs reward checkpointing for each ERC-20 balance change, the integration with the Silo fails to integrate such checkpoint fully, thus allowing both theft and loss of rewards.  A lack of checkpointing is present   When  a  user  transfers  the  collateral  tokens:  Transferring  collateral  tokens  does  not  trigger  any  checkpointing.   When a user uses the depositFor() function in the silo: The checkpointing will be done for the  transfer, however, minting collateral tokens will not checkpoint for the recipient.   When a user is being liquidated: The liquidated user will not be involved in checkpointing and loses  his rewards. The liquidator does not receive the rewards as a liquidation bonus.   When a user uses the router to withdraw the collateral: The router will be checkpointed. The user will  temporarily get a smaller balance accounted which will lead to unfair checkpointing for the user.  Most  notably,  the  collateral  token  transfers  would  allow  for  a  simple  attack  by  transferring  collateral tokens from address to address to claim rewards with each.  Further,  note  that  the  function  syncSilo()  could  change  the  silo  which  is  used  for  additional accounting. However, that could break the contract and unfairly distribute rewards.  To summarize, collateral token transfers do not checkpoint and transfers of tokens between the silo and a user, who was not the prior owner of these tokens, update the rewards only for the receiver.    Silo  Finance  has  added  a  Silo  type  called  SiloConvex  which  updates  reward  for  concerned  users before  any  actions.  Router,  current  silo  and  deprecated  silos  cannot  be  checkpointed  for  rewards anymore.  Further,  ShareCollateralTokenConvex  has  been  introduced  that  checkpoints  before  any  direct transfer between users.  Note that when the collateralVault variable is updated through syncSilo(), some rewards could still be lost, but this is now part of the specification.  Silo Finance - Curve & Convex Feature -   13  CorrectnessHighVersion1CodeCorrected          \f6.4   Missing Shutdown Logic  Each ConvexStakingWrapper smart contract can be shut down by the owner so that accounting of the rewards  stops  and  users  are  only  able  to  withdraw  their  shares  of  the  pool.  Rewards  will  not  be accounted  for  anymore  when  moving  wrapped  tokens  around  because  the  _checkpoint()  function does not apply any logic when the isShutdown flag is set to true.  However, the _checkpointAndClaim() function does not have any such check for the flag, meaning that  users  are  still  able  to  claim  their  rewards  after  the  shutdown.  Users  could  also  still  transfer  the wrapped tokens without the wrapper checkpointing it so an attacker could manipulate its balance to steal some rewards.    Both functions now implement the shutdown logic.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   A Metapool Could Have More Than One",
        "body": " Nested LP Token  The CurvePAPTokensPriceProvider retrieves all the underlying tokens for the LP token. For meta pools, the underlying LP token's coins are retrieved.  However, when the nested depth is equal to or greater than 2, it directly tries to fetch the price of the last lp token instead of continuing to fetch the underlying tokens.    Code  now  correctly  fetches  all  nested  tokens  recursively.  Note  that  if  the  total  amount  of  underlying tokens exceeds eight, the code will revert which is expected.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Metapool Setup Recursion Lacks Sanity",
        "body": " Check  Metapools are StableSwap pools where at least one underlying is a Curve LP token. To set up such a metapool LP token, setupAsset() in CurvePAPTokensPriceProvider recursively sets up all underlying LP tokens. However, the recursive iterations of _setUp() lack the _MIN_COINS sanity check and the LPTokenEnabled event emission.  Code Corrected:  The  check  and  the  event  emission  are  now  in  the  _setUp()  function  which  is  used  for  recursively iterating over the potentially nested LP tokens.  Silo Finance - Curve & Convex Feature -   14  DesignMediumVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                        \f6.7   Metapools With Two LP Underlying  Note that Metapools can have only one LP underlying. However, the current design would allow for bad pools with two LP tokens as underlyings - one as a regular coin and one as the base asset.    The code now reverts if there are two lp underlyings.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   Missing Events for State Modifying Actions",
        "body": "  In ConvexStakingWrapper, some important state-modifying actions do not trigger events:   Shutting down a staking wrapper   Adding a reward token   Setting the hook   Checkpointing users  Emitting events could ease following the state of the contract.    Events have been added for all of the above.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   The Reward Integral Computation Can",
        "body": " Overflow  ConvexStakingWrapper  uses  solidity  0.6.12  which  can  overflow  on  arithmetic  operations.  The staking wrapper uses a variable called reward_integral to track each token reward by increasing it proportionally to the received rewards. Note that this variable should only be able to increase.  At line 275, it computes it in such a way:  reward.reward_integral = reward.reward_integral + uint128(bal.sub(reward.reward_remaining).mul(1e20).div(_supply));  The  addition  here  can  overflow  to  a  decrease  of reward_integral. A decrease in the variable would mean that some users would have their rewards locked forever in the smart contract.  in  some  conditions,  which  would   lead   Also  note  that  the  truncation  to  a  uint128  in  the  second  part  of  the  code  line  can  also  lead  to  a truncation overflow, which would miscompute the received rewards.  While the supply is low, the overflow can be triggered very easily. Using this capability, an attacker could grieve users from receiving rewards by pushing the users' reward integrals to the maximum so that the global reward integral cannot exceed the users' reward integral.  Silo Finance - Curve & Convex Feature -   15  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                      \f  The reward variables are now stored as uint256.  Silo Finance noted:  Contract is updated to store the rewards integral in 256 bits variables. This fix makes the integral overflow improbable for regular reward tokens, even if the total supply of the wrapped token is 1 wei.  Here  reward_integral  could  still  overflow  but  as  stated  by  Silo  Finance,  it  is  much  less  probable given that reward tokens should not be of very low value or with unusually high decimals.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   IWrapperDepositor Not Implemented",
        "body": "  Most  of  the  contracts  interact  with  each  other  based  on  the  interface  definitions.  However,  the ConvexStakingWrapperSilo contract itself does not implement the IWrapperDepositor. Without this,  there  are  no  compile-time  guarantees  that  the  contract  will  be  compatible  with  the  calls  to  the functions that the interface defines. This can lead to potential runtime errors and exceptions that are hard to debug. Explicitly defining that a contract implements an interface could minimize such errors.    ConvexSiloWrapper now implements IConvexSiloWrapper.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.11   A Collateral-Only Silo Can Have Its ",
        "body": " siloAsset Borrowed  During the audit, we uncovered that a silo with a collateral-only asset could still have this asset borrowed. More specifically, this can happen when tokens are sent directly to the silo. The collateral-only funds are not affected but the specification is violated.  /// @notice Modification of the Silo where a siloAsset can be deposited /// only as collateral only asset and can't be borrowed.    if (_isSiloAsset(_asset)) revert(); has been added to borrow() and borrowFor() in the specialized Silos for Curve and Convex. However, note that the exact mechanics are out of scope, and if there is alternative way to borrow, the issue could still persist.  Silo Finance - Curve & Convex Feature -   16  DesignLowVersion1CodeCorrectedInformationalVersion1CodeCorrected                \f6.12   Missing NatSpec  Most functions are provided with documentation. However, CurvePriceProviderETH does not have any  NatSpec  for ICurvePriceProvider's  getAssetPool()  and  isAssetPoolUint256()  functions.  Also, _getDy() in the CurvePriceProvider is not fully documented.  for  NULL_ADDRESS,  WETH  and  _getCoin().  Further,  NatSpec   lacks     The files have been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.13   Usage of registryId",
        "body": "  Pool.registryId is never used.    Silo Finance removed the registryId as it was unused.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.14   Variables Visibility",
        "body": "  In  CurveLPTokenDetailsBaseCache,  coins  is  public  and  has  hence  an  automatic  getter. However, getCoins() has the same behavior as the automatic getter and thus there is a double getter for the elements.  In CurvePriceProvider, NOT_FOUND_INDEX is public. However, it is only used for protocol internal logic.    getCoins() was removed. Hence, coins() remains the only public getter.  CurvePriceProvider has been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.15   isMeta for Crypto Pools",
        "body": "  The isMeta flag is present for Curve crypto pools. However, note that these pools are not meta pools. The CurveCryptoSwapRegistryFetcher can set it to true. However, it has no effect.    Client added a sanity check to ensure the validity of the pools data returned by fetchers.  Silo Finance - Curve & Convex Feature -   17  InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected                      \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Balancer Oracles Are Deprecated",
        "body": "  During  the  audit  we  discovered  that  the  protocol  uses  the  Balancer  V2  oracles.  However,  note  that their  oracles  here:  https://docs.balancer.fi/products/oracles Balancer  discourages  (snapshot).  the  usage  of   Acknowledged:  Silo Finance replied:  The Silo team is aware of this  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Code With No Effects",
        "body": "  The ConvexStakingWrapper smart contract contains code without any real effects.  On line 215:  if(registeredRewards[_token] == 0){         ... }else{         uint256 index = registeredRewards[_token];         if(index > 0){...} }  The second if will always be executed as index will always be greater than 0.  On lines 167, 169, 210: Token transfers to self has no effect.  Acknowledged:  Silo Finance replied:  We decided to make minimal changes in external contracts that we inherit. Refactoring is out of scope of this feature.  Silo Finance - Curve & Convex Feature -   18  InformationalVersion1AcknowledgedInformationalVersion1Acknowledged            \f7.3   Commented Code  The following comment contains a line of commented-out code.  // collateralVault = _vault;  Removing the line could improve readability.  Acknowledged:  Silo Finance replied:  We decided to make minimal changes in external contracts that we inherit. Refactoring is out of scope of this feature.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   Gas Inefficiencies",
        "body": "  The staking wrapper for convex contains several gas inefficiencies. The following is an incomplete list of examples:   More state variables could be constants and immutables.   \"Double-initialization\" performs some storage writes twice (e.g. setting the owner)   When adding rewards, the rewards length is always read from storage.   registeredRewards is read twice in the else branch of addTokenReward().   _calcRewardIntegral reads variables multiple times from storage (e.g. reward_remaining)  Acknowledged:  Silo Finance replied:  We decided to make minimal changes in external contracts that we inherit. Gas optimization in external contracts is out of scope of this feature.  Silo Finance - Curve & Convex Feature -   19  InformationalVersion1AcknowledgedInformationalVersion1Acknowledged          \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Collateral-only Assets",
        "body": "  Neither  the  Curve  LP  tokens  nor  the  wrapped  Convex  tokens  are  suitable  for  borrowing  due  to  their prices  being  easily  but  legitimately  pushed  upwards.  Hence,  the  tokens  are  only  suitable  as  collateral assets.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Convex DOS Potential",
        "body": "  In the convex staking wrapper contract, checkpointing could iterate over many tokens. If Convex adds too many reward tokens, the checkpointing could be DOSed. While Convex is trusted in that sense, users should be aware of such a possibility.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.3   Duplicate Tokens Undervalue Estimation of",
        "body": " Rewards  In  the  ConvexStakingWrapper  smart  contract,  extra  reward  tokens  are  queried  from  the  convex reward pool and can also be added manually by the owner.  If there is a case of a pool that receives rewards of the same token from two different reward pools, then only  one  of  these  will  be  queried  with  the  earned()  to  estimate  the  rewards  for  this  token  in  the earnedView() function of the staking wrapper, leading to low reward estimations.  Further  note  that  any  reward  token  that  has  no  reward_pool  associated  will  have  its  rewards undervalued in the view functions. However, note that Convex is not expected to behave in such a way.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.4   Function Interface Is Not Validated",
        "body": "  In  CurvePriceProvider,  the  manager  must  provide  a  GET_DY_INTERFACE  enum  due  to  the interfaces of the get_dy() function being different across curve pools. However, this enum is not sanity checked while most other set-up arguments are and a pool with the wrong interface could be saved to storage.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.5   Oracle Manipulation",
        "body": "  Silo Finance - Curve & Convex Feature -   20  NoteVersion1NoteVersion1NoteVersion1NoteVersion1NoteVersion1                  \fNote  that  any  on-chain  oracle  is  manipulatable  to  some  degree.  Hence,  the  prices  of  assets  could  be manipulable to some extent.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.6   Read-only Reentrancy Protection",
        "body": "  Users and Silo Finance should be careful when the gas costs of opcodes change in new hardforks as this could lead to breaking changes. Hence, this should be monitored. Further, the selection of parameters should be carried out with gas measurements on the pools since different Vyper versions and pools may need to different parameters.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.7   The Curve LP Oracles Fetch the Minimum",
        "body": " Price  The  Curve  lp  oracles  will  fetch  a  price  that  is  a  lower  bound  on  the  LP  token  price.  When  used  as  a collateral, users should know that this is the case and be extra careful to avoid unnecessary liquidations.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.8   Unsupported Reward Tokens",
        "body": "  Users  should  be  aware  that  reward  tokens  that  can  change  the  amount  differently  from  the  amount transferred could unfairly distribute rewards and could break the contract.  Especially,  rebasing  tokens  could  break  the  contract  if  a  rebase  downwards  occurs.  Further,  reward tokens with transfer fees could create problems.  Silo Finance - Curve & Convex Feature -   21  NoteVersion1NoteVersion1NoteVersion1            \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   setMaxAnswer Missing Sanity Check",
        "body": "  The  function  MCAGAggregator.setMaxAnswer  simply  sets  the  storage  variable  _maxAnswer  to  the input argument. As the input argument is defined as signed-integer, mistakenly setting _maxAnswer to a negative value, blocks any further calls with positive arguments to MCAGAggregator.transmit().  CS-MCAG-004    Checks to prevent setting negative values have been added to setMaxAnswer() and in the constructor:  if (maxAnswer_ < 0) {     revert Errors.MAX_ANSWER_TOO_LOW(maxAnswer_, MIN_MAX_ANSWER); }  and MCAGAggregator.setMaxAnswer():  if (newMaxAnswer < 0) {     revert Errors.MAX_ANSWER_TOO_LOW(newMaxAnswer, MIN_MAX_ANSWER); }  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Mcag accessController Uses Undocumented",
        "body": " Roles  The following two roles are used in AccessController of mcag, but not documented in the README:  CS-MCAG-002  1. MCAG_SET_TNC_ROLE  2. MCAG_SET_MAX_COUPON_ROLE  Mimo Capital AG - MCAG Contracts -   11  CriticalHighMediumLowCodeCorrectedCorrectnessLowVersion1CodeCorrectedInformationalVersion1Speci\ufb01cationChanged              \fSpecification changed:  Mimo Capital AG has added the definition of the two aforementioned roles to the README, as well as functions callable by these two roles.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Unused Constant MIN_TERM",
        "body": "  The defined constant MIN_TERM in the contract KIBTAggregator is defined but not used.  CS-MCAG-003    Mimo Capital AG has removed the definition of this unused constant.  Mimo Capital AG - MCAG Contracts -   12  InformationalVersion1CodeCorrected      \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Define Relevant Fields in the Events as",
        "body": " Indexed  Although some event fields are already defined as indexed, it might make sense to define further ones as indexed as well. Defining event fields as indexed makes searching for specific addresses/values easier.  CS-MCAG-001  Mimo Capital AG - MCAG Contracts -   13  InformationalVersion1  \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   KIB Price Determination & Volatility",
        "body": "  It  may  be  obvious  that  one  KIB  token  should  be  priced  at  one  unit  of  the  underlying  principal  token. However  due  to  low  liquidity,  constraints  around  the  redemption  of  KIB  tokens  (accruing  sufficient  KIB tokens, buying the bond of the protocol, off-chain redemption) the price may fluctuate. Furthermore, low liquidity in e.g. Uniswap pools results in notable price volatility / slippage when trading as well as potential price manipulation.  KIBTAggregator  serves  as  a  price  feed  for  KIB  tokens.  This  pricefeed  returns  a  value  that  is  manually updated. Its price might deviate from the tokens actual valuation across the DeFi system and must be used with care.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Updating Terms and Conditions",
        "body": "  KUMABondToken  allows  to  update  the  terms  and  conditions  URL  for  an  already  existing  Bond  NFT. Although being callable only by holder of MCAG_SET_TNC_ROLE role, it might bring legal complexities, as users  buy  a  bond  token  given  the  terms  and  conditions  during  the  purchase.  Changing  terms  and conditions for a sold bond token should be treated with extra caution.  Mimo Capital AG - MCAG Contracts -   14  NoteVersion1NoteVersion1      \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Proxy Wallet DoS",
        "body": "  0  0  2  0  As  can  be  seen  in  RelayHub  account  can  be  drained,  all  the  funds  of  the  ProxyWalletFactory account  on  the  GSN  RelayHub  can  be  completely  drained.  Since  Polymarket  currently  executes signatures  with  a  gasPrice  set  to  1,  the  calls  can  only  be  successfully  relayed  as  long  as  there  are funds  available.  If  an  attacker  were  to  completely  drain  the  account,  no  new  transactions  can  be performed until either:  CS-PMPWF-002   The process is changed to create signatures with a gasPrice of 0.   The RelayHub balance is replenished.  Specification changed:  Relayer clients will now use a gas price of 0.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   RelayHub Account Can Be Drained",
        "body": "  CS-PMPWF-001  calls   Relayed  calling the  ProxyWalletFactory.acceptRelayedCall() to determine, whether a call is paid for by the funds deposited to the RelayHub by Polymarket. Using the GSNModule01 always accepts any call that targets the factory's proxy() function.  RelayHub   executed   GSN   over   are   Since  neither  the  relayer  nor  the  transactionFee  are  verified,  any  account  can  perform  a transaction on the RelayHub with a transactionFee set to an amount that completely drains the balance of the ProxyWalletFactory. This fee is then credited to the relayer's balance and can be withdrawn.  Specification changed:  Polymarket - Proxy Wallet Factories -   11  CriticalHighMediumSpeci\ufb01cationChangedSpeci\ufb01cationChangedLowSecurityMediumVersion1Speci\ufb01cationChangedSecurityMediumVersion1Speci\ufb01cationChanged                \fPolymarket  now  publishes  signatures  with  a  gas  price  of  0,  allowing  them  to  execute  the  transactions without  any  balance  changes  in  the  RelayHub.  The  balance  in  the  RelayHub  can  therefore  be withdrawn completely, mitigating any possible draining.  Polymarket - Proxy Wallet Factories -   12  \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Ambiguous Naming",
        "body": "  The name of the function ProxyWalletFactory.deployImplementation() does not start with an underscore although all other internal functions do so.  CS-PMPWF-003  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Code Copies",
        "body": "  ProxyWalletLib  computeCreationCode()). The libraries could be merged into one.  FactoryLib   contain   and   overlapping   CS-PMPWF-004  code   parts   (e.g.,  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Gas Optimizations",
        "body": "  The following gas inefficiencies can be improved:   The  implementation  address  in  ProxyWalletFactory  could  be  replaced  by  an  immutable  CS-PMPWF-005  variable.   The whitelistedRelayer in GSNModule03 can be immutable.   The storage variables of SafeProxyFactory can be immutable.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   Irregular Rejection Code",
        "body": "  All GSN modules return 1 when rejecting a call. According to the GSN specification, however, the correct code for rejection is at least 11 as codes 1 - 10 are reserved.  CS-PMPWF-008  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   Lost Revert Errors",
        "body": "  RevertCaptureLib can not handle custom error messages. Instead, a default error is returned which removes information in the output.  CS-PMPWF-006  Polymarket - Proxy Wallet Factories -   13  InformationalVersion1RiskAcceptedInformationalVersion1RiskAcceptedInformationalVersion1RiskAcceptedInformationalVersion1RiskAcceptedInformationalVersion1RiskAccepted                            \f7.6   Missing Event  ProxyWalletFactory.makeWallet() does not emit an event on successful proxy wallet creation.  CS-PMPWF-007  Polymarket - Proxy Wallet Factories -   14  InformationalVersion1RiskAccepted      \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Rogue Strategy Can Override Storage",
        "body": "  Core accounting logic is done by the code of TokenizedStrategy which is executed as Delegatecall inside the context of the strategy.  The documentation states the following:  In order to limit the strategists need to think about their storage variables all TokenizedStrategy specific variables are held within and controlled by the TokenizedStrategy. A BaseStrategyData struct is help at a custom storage location that is high enough that no normal implementation should be worried about hitting.  CS-YTS-004  This means all high risk storage updates will always be handled by the TokenizedStrategy, can not be overriden by a rogue or reckless strategist and will be entirely standardized across every strategy deployed, no matter the chain or specific implementation.  A  rogue  or  reckless  strategist  can  overwrite  any  storage  slot,  including  those  at  the  address keccak256(\"yearn.base.strategy.storage\") - 1 and subsequent addresses.  While a genuine strategy wouldn't do this and the concept to separate the storage ensures that with high probability a specific implementation is unlikely do to so by accident, a rogue or reckless strategies can do so intentionally.  Specification changed:  Yearn acknowledged this risk and corrected the specification.  Yearn - Tokenized Strategy -   12  CriticalHighMediumSpeci\ufb01cationChangedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedRiskAcceptedSpeci\ufb01cationChangedCorrectnessMediumVersion1Speci\ufb01cationChanged           \f6.2   Initializing TokenizedStrategy  The deployed instance of TokenizedStrategy is only intended to be used via Delegatecall by the custom strategies.  However  the  functions  of  the  contract  are  also  directly  callable.  For  example  the  first  caller  of TokenizedStrategy.init() can initialize the contract. While this doesn't break it's intended use as base for the delegatecalls, it's not desirable.  It's worth noting that after initialization, deposits will still fail due to the callback to the invest() function.  Other functions may execute successfully, such as approvals, role assignments, and parameter updates.  CS-YTS-008    A  constructor  has  been  added  to  TokenizedStrategy  which  initializes  the  implementation  with _strategyStorage().asset=address(1).  As  a  result,  further  direct  calls  to  initialize()  will revert.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Non ERC-4626 Compliant Functions",
        "body": "  maxMint  may  revert  due  to  an  overflow  in  a  calculation,  however  according  to  the  specification  this function  must  not  revert.  This  may  happen  in  an  edge  case  the  availableDepositLimit  returns  a large number and pps<1, convertToShares may overflow.  CS-YTS-007  function maxMint(address _owner) public view returns (uint256 _maxMint) {     _maxMint = IBaseTokenizedStrategy(address(this)).availableDepositLimit(         _owner     );     if (_maxMint != type(uint256).max) {         _maxMint = convertToShares(_maxMint);     } }  In  case  the  strategy  is  in  shutdown  mode,  no  further  deposit  can  be  made.  However,  maxDeposit() may not return 0 when the strategy is shutdown.  The ERC-4626 specification however requires the function to return 0 in this case:  ... if deposits are entirely disabled (even temporarily) it MUST return 0.  More  informational,  the  ERC-4626  specification  is  loosely  defined  in  these  corner  cases  for  these functions. Nevertheless we want to highlight the potentially unexpected amounts returned:  previewRedeem(): In case totalAssets is zero, the conversion is done at a 1:1 ratio. At this point either no shares exist (I) or the value of the existing shares has been dilluted to 0 (II). For (I) the returned value  of  0  is  appropriate.  For  (II)  previewRedeem()  does  not  revert  while  redeem()  reverts;  the specification reads:  Yearn - Tokenized Strategy -   13  DesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                \fMAY revert due to other conditions that would also cause redeem to revert.  previewWithdraw()  returns  the  amount  in  a  1:1  exchange  rate  when  assets==0  but  shares!=0. Again for non-zero values the amount returned may be misleading.  Strictly  speaking  the  value  returned  is  not  breaking  the  specification  but  might  be  unexpected  by  the caller.  The  caller  should  be  aware  of  this  and  any  external  system  should  exercise  caution  when integrating with these functions.    A  comment  has  been  added  to  availableDepositLimit  to  alert  the  strategist  of  the  potential overflow of maxMint() if the deposit limit is too large. In addition, maxDeposit() and maxRedeem() have  been  updated  to  return  0  when  the  strategy  is  shutdown.  previewWithdraw()  and convertToShares()  have  been  adjusted  to  return  0  instead  of  pps=1  in  case  assets==0  but supply>0.  Yearn  also  acknowledged  return  value  of previewRedeem()  if  all  shares  are  diluted  to  0.  Strategists  and  external  systems  are  expected  to  be aware of these behaviors.  the  potential  misleading  non-zero   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Payable Fallback Functions",
        "body": "  The fallback function of `BaseTokenizedStrategy` is marked as payable. However, the code of the delegatecalled  TokenizedStrategy  contract  doesn't  feature  any  functionality  able  to  receive  Ether.  Any such call with a non zero msg.value will revert.  Furthermore, there is a receive() function:  CS-YTS-006  /**  * We are forced to have a receive function do to  * implementing a fallback function.  *  * NOTE: ETH should not be sent to the strategy unless  * designed for within the Strategy. There is no defualt  * way to remove eth incorrectly sent to a strategy.  */ receive() external payable {}  There  is  no  requirement  to  implement  a  receive  function  when  incorporating  a  fallback  function.  In  the absence of a receive function, plain Ether transfers would be handled by the fallback function, which then delegatecalls into the TokenizedStrategy. However, this would cause the call to revert since the contract does not support Ether reception. By including a receive function, the strategy can be enabled to accept Ether. As the comment states, Ether shouldn't be sent to the strategy unless the strategy is design for it.  For  https://docs.soliditylang.org/en/v0.8.18/contracts.html#receive-ether-function  information   please   more   refer   the   to   Solidity   documentation:    The payable modifier and the receive function have been removed to avoid unintentional Ether reception.  Yearn - Tokenized Strategy -   14  DesignLowVersion1CodeCorrected          \f6.5   Problematic Self-Minting When Fee Recipient Is the Contract Itself  CS-YTS-005  Transferring  shares  of  the  strategy  to  itself  is  prevented  since  it  can  interfere  with  the  locked  shares mechanism  which  guards  against  abrupt  price  per  share  increases.  Unlike  _transfer(),  _mint() does  not  feature  this  restriction  since  it  is  intended  to  mint  shares  for  this  contract  as  part  of  the  profit locking mechanism. An explicit check must be done in the function calling _mint(). While this is done in _deposit(), such a check isn't done on the fee recipients.  When  the  performanceFeeRecipient  is  set  as  the  strategy  itself,  it  becomes  possible  to  mint additional shares to the strategy, which are not intended to be locked shares.  Once  enough  time  passes  and  the  fullProfitUnlockDate  is  reached,  _unlockedShares()  will treat the entire balance of this contract, including these additional shares, as unlocked shares.  if (_fullProfitUnlockDate > block.timestamp) {     unchecked {         unlockedShares =             (S.profitUnlockingRate * (block.timestamp - S.lastReport)) /             MAX_BPS_EXTENDED;     } } else if (_fullProfitUnlockDate != 0) {     // All shares have been unlocked.     unlockedShares = S.balances[address(this)]; }  Due  to  the  presence  of  extra  shares,  there  may  be  a  sudden  increase  when  querying  the unlockedShares just before and right after the fullProfitUnlockDate.  This effect may have an impact whenever _totalSupply() is called and may influence the the price per share.  Additionally process_report() is affected. In case the fullProfitUnlockDate has already been reached these shares would simply get burned in _burnUnlockedShares(). Otherwise these shares will be considered as part of the previouslyLockedShares and are locked in the new locking period. Note as this is an increase of the previouslyLockedShares it will impact the calculation of and reduce the newProfitLockingPeriod:  // new_profit_locking_period is a weighted average between the remaining     // time of the previously locked shares and the PROFIT_MAX_UNLOCK_TIME     uint256 newProfitLockingPeriod = (previouslyLockedShares *         remainingTime +         sharesToLock *         _profitMaxUnlockTime) / totalLockedShares;  The issue description focuses on the performanceFeeRecipient as fee recipient, in theory the same situation could arise if the protocolFeesRecipient is set as the strategy contract.    An  extra  check  has  been  added  in  setPerformanceFeeRecipient()  as  well  as  in  init()  which prevents setting the fee recipient to address(this).  Risk accepted:  Yearn - Tokenized Strategy -   15  CorrectnessLowVersion1CodeCorrectedRiskAccepted        \fThe protocolFeeRecipient is set once for all strategies by Yearn Governance and should not be an issue.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Staticcall",
        "body": "  CS-YTS-009   * Using address(this) will mean any calls using this variable will lead  * to a static call to itself. Which will hit the fallback function and  * delegateCall that to the actual TokenizedStrategy.  ITokenizedStrategy internal TokenizedStrategy;  The comment says that using address(this) will result in a static call to itself, but the term \"static call\" might be misleading. In Ethereum, a \"static call\" typically refers to a STATICCALL, which is a read-only call that cannot modify the contract state. However, in this case, the comment seems to be referring to the fact that the call will simply be to the contract itself. Such calls can lead to state changes.  Specification changed:  Yearn has rephrased the comment to avoid misunderstandings. A legitimate strategist should not use this variable for state-changing calls.  Yearn - Tokenized Strategy -   16  CorrectnessLowVersion1Speci\ufb01cationChanged        \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Uncovered Loss Not Visible in Reported Event",
        "body": "  An event Reported will be emitted after report() is called. If an uncovered loss has been realized, this crucial information won't be visible in the event. In case a net loss occurs, price per share decrease (pps) instantly. Revealing this in the event may be useful.  event Reported(uint256 profit,uint256 loss,uint256 performanceFees,uint256 protocolFees)  CS-YTS-001  Yearn states:  The event is meant to match the Vaults event as close as possible and only reveal the amounts determined within the report call. It should be expected that most reports in strategies will be done after all shares have been unlocked since the previous reports, and therefore any loss will cause a PPS decrease. Specific strategies can use this functionalities if desired to offset losses but is not normal behavior, simply extra functionality. PPS is not tracked on chain.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Use ADDRESS Instead of SLOAD",
        "body": "  BaseTokenizedStrategy.initialize()  sets  the  storage  variable  TokenizedStrategy  to  the address of the executing context:  CS-YTS-002  // Set instance of the implementation for internal use. TokenizedStrategy = ITokenizedStrategy(address(this));  To call itself, the code of the BaseTokenizedStrategy and the custom strategy implementation would use this  variable  which  results  in  an  SLOAD  operation.  Note  that  opcode  ADDRESS  (in  solidity address(this))  would  return  the  same  address  (the  address  of  the  executing  account)  and  is significantly cheaper.  Yearn states:  The setting of the `TokenizedStrategy` variable in initialization is meant to make it as simple as possible for a strategist to access readable data from the StrategyData struct so having an extra SLOAD is  Yearn - Tokenized Strategy -   17  InformationalVersion1InformationalVersion1      \fworth the reduced complexity of not having to understand what is being called, just that the variable will work.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   tendTrigger",
        "body": "  The description of TokenizedStrategy.tend() reads:  * @dev Both 'tendTrigger' and '_tend' will need to be overridden * for this to be used.  However this is not enforced in the code, where tendTrigger() has no effect on tend(), e.g. it could return false and tend() may still execute successfully.  CS-YTS-003  Yearn states:  `tendtrigger` is only to be used off chain, by a keeper bot or management to easily determine if tend should be called, not a requirement for it to be. Tend is able to be called at any point even if the trigger does not say it should.  Yearn - Tokenized Strategy -   18  InformationalVersion1    \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Withdraw With Unrealized Loss",
        "body": "  In case there is an unrealized loss, the most vigilant users will come to withdraw funds directly from the idle to avoid the loss. As a result, the tardy users will take the unrealized loss. Besides, tardy users may take an unrealized loss in different ways depending on the actual implementation of _freeFunds().  If custom strategy implementation simply tries to free the funds from the yield source as closer to the requested amount as possible or simply reverts due to insufficient funds, the remaining funds will be withdrawn in a FCFS way where the last users will take all of the unrealized loss and get nothing back.  If  custom  strategy  implementation  distributes  the  unrealized  loss  according  to  the  accounting variables in StrategyData, then all tardy user will share the unrealized loss proportionally.  Different  strategists  may  take  different  choices,  whereas  the  vigilant  users  can  always  drain  the  idle regardless of the unrealized loss in both cases.  Yearn states:  So for the most part those types of decisions are to be left to the strategist to determine what to do in _freeFunds(). The majority of strategies will likely simply withdraw the amount requested, since its 1. not applicable and 2. would require a lot more gas and code to check the actual current state and calculate the full unrealized loss etc. Though if a strategy expects to have this be a common case (like with an options strategy) that specific strategist can add whatever they wish to _freeFunds. It is recommended that _freeFunds revert if losses would be realized by temporary situations. Such as liquidity constraints, that are not expected to last, rather than count it as a loss.  While its possible there are unrealized losses, normal behavior is to not account for those in between reports, but rather losses are handled withdraw by withdraw. Though that can lead to disproportionate amounts depending on when funds are withdrawn its much cheaper and simpler considering its a non-issue for the majority of strategies and the ones it is can choose how to deal with it.  Yearn - Tokenized Strategy -   19  NoteVersion1    \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Code Duplication Balance Getters",
        "body": "  The engine contract implements two functions: balanceRisky() and balanceStable() which return the balance of the engine for the respective token. These two functions implement the same functionality and have the same logic, therefore can be merged into a single function that takes the token address (for stable or risky) as an input parameter.  Acknowledged  The client prefers two separate functions.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Event Optimization",
        "body": "  The  swap()  function  emits  two  events:  UpdatedTimestamp()  and  Swap()  which  can  be  integrated into one event to reduce the gas consumption.  Acknowledged  This behavior is desired by Primitive.  Primitive Finance - Core Engine -   9  SecurityDesignCorrectnessCriticalHighMediumLowAcknowledgedAcknowledgedCodePartiallyCorrectedAcknowledgedAcknowledgedDesignLowVersion1AcknowledgedDesignLowVersion1Acknowledged                   \f5.3   Sanity Checks  When  depositing,  withdrawing,  allocating,  and  swapping  (VERSION4)  the  receiving  account  can  be chosen. No basic sanity check if it is accidentally address zero is performed. Additionally, the strike price could be validated if it is not zero in create.  Code partially corrected  A sanity check for the strike price in create is implemented but no checks for address zero are added.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.4   Unused Function getRiskyGivenStable",
        "body": "  The function getRiskyGivenStable is declared internal but not used in the code.  Acknowledged  Primitive Finance acknowledged the issue but communicated that the function is kept as it is for now.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.5   Unused Storage Fields",
        "body": "  The PrimitiveEngine contract is deployed by the PrimitiveFactory contract. The engine stores the  factory  address  as  state  variable  address  public  immutable  override  factory;  and  an owner but these variables are not used.  Acknowledged  Primtive acknowledged the behavior and informed us that this is intended.  Primitive Finance - Core Engine -   10  DesignLowVersion1CodePartiallyCorrectedDesignLowVersion1AcknowledgedDesignLowVersion1Acknowledged                          \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  0  7  7  9  -Severity Findings  -Severity Findings   Low Decimal Token Issues    Anyone Can Call the Repay Function After Pool's Maturity    Borrower Locks Liquidity in the Pool    Disable Unnecessary Functionalities After Expiry    Flawed Fee and Premium Structure    No Slippage Protection    Violation of Maximum Ratio of Float Liquidity   -Severity Findings   Token Decimal Validation    Explicitly Handling Positive Invariant Restriction   Incorrect Tracking of Cumulative Values for Pool Reserves    Liquidity Providers Get Rewards Without Supplying Float Liquidity    Possible Overflows    Possible to Frontrun on Claim Request    Redundant and Improper Revert Condition   -Severity Findings  Inconsistency of Input Parameters    Unused Error Definition    Redundant Storage Read    Code Duplication    Duplicated Calculation of Invariant   Implementation of getStableGivenRisky Function    Possible Gas Optimization in the Deposit Function    Return Value in safeTransfer    MANTISSA_INT Constant   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Low Decimal Token Issues",
        "body": "  Primitive Finance - Core Engine -   11  CriticalHighCodeCorrectedSpeci\ufb01cationChangedSpeci\ufb01cationChangedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedSpeci\ufb01cationChangedMediumCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedLowCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedDesignHighVersion3CodeCorrected           \fThe  lower  the  decimals  of  a  token  are  and  the  higher  the  value,  the  more  severe  rounding  issues  will become. Simultaneously, the liquidity position accounting with 18 decimals will cause issues.  Examples issues are:  Burning one unit of a low decimal but high value token (in create) might be a huge loss for the user.  There  is  a  dependency  between  the  delta  when  creating  a  pool  and  the  decimals  of  a  token.  delta cannot be chosen freely because of this dependency (1e18 - delta) - 1e(18-decimals) needs to  be  bigger  than  1,  else  the  create  will  revert.  This  basically  eliminates  the  support  of  zero  decimal tokens (as the only viable option is delta = 0). Low decimals limit the range of delta and the step accuracy  with  which  the  risky  token  amount  is  calculated.  E.g.  the  maximum  value  of  delta  can  be 9e17  (should  be  1e18)  for  1  decimals,  99e16  for  2  decimals  and  so  on.  The  step  size  should  be accordingly high to increase the resulting delRisky one unit.  With decreasing decimals this calculation will lose precision if the token decimals are not dividable by the fraction delLiquidity / PRECISION with modulo zero.  delRisky = (delRisky * delLiquidity) / PRECISION; // liquidity has 1e18 precision, delRisky has native precision delStable = (delStable * delLiquidity) / PRECISION;  The  function  getAmounts  has  a  similar  problem  and  will  losing  precision.  This  can  be  exploited  in allocate  to  receive  more  liquidity  tokens  than  the  user  would  be  entitled  to  as  the  rounding  in allocate is in the user's favor.  Code corrected  The  issues  above  have  been  tackled  by  only  accepting  token  decimals  between  six  and  18.  Six  was chosen to support famous stable coins and did not lead to issues in tests. However, tests and fuzzing does not cover all possible states and due to the complex math, there might be a state that still results in issues regarding to the decimals.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Anyone Can Call the Repay Function After",
        "body": " Pool's Maturity  After the pool's maturity has passed, i.e., the pool has expired, anyone can call the function repay() for any borrower and receive their premiums in case the borrower's possition yields profit. The first three lines of the function repay() allow any msg.sender to receive the premiums for any borrower:  Since the borrower is incentivized to call the function repay() only when there is profit, the function allows any attacker to collect the unclaimed profit of any borrower after the pool's maturity. Furthermore, if the legitimate borrwers calls the function repay() at the maturity of the pool, the attacker has still a possibility to frontrun the legitimate transaction.   Specification changed  This  version  of  the  code  introduces  a  grace  period,  around  24h,  to  permit  only  borrowers  calling  the function repay() after pool's maturity. In case a borrower does not call the function during this period, anyone can call the function repay() and exit the borrowers' positions, therefore releasing the locked liquidity.   Specification changed  The respective code has been removed according to the new specifications of   .  Primitive Finance - Core Engine -   12  DesignHighVersion1Speci\ufb01cationChangedVersion2Version3Version3        \f6.3   Borrower Locks Liquidity in the Pool  the  function  borrow()  with  a  given  delLiquidity   call Calling  reserve.borrowFloat() which decreases the amount of available float in the pool and increases the debt  of  the  pool  reserve  accordingly.  This  way,  the  borrower  locks  delLiquidity  from  the  available float in the pool reserve. Below is the borrowFloat function.  triggers   the   function borrowFloat(Data storage reserve, uint256 delLiquidity) internal {         reserve.float -= delLiquidity.toUint128();         reserve.debt += delLiquidity.toUint128(); }  A liquidity provider that has supplied its liquidity as float needs to first call the function claim() which converts the float into liquidity before removing the liquidity from the pool. However, the only way for all liquidity providers to claim all their float liquidities is if all borrowers call the function repay() which triggers a call to reserve.repayFloat():      function repayFloat(Data storage reserve, uint256 delLiquidity) internal {     reserve.float += delLiquidity.toUint128();     reserve.debt -= delLiquidity.toUint128(); }  But,  if  the  price  of  the  risky  token  is  below  the  strike  price,  the  borrower  has  no  incentive  to  call  the function  repay(),  therefore  potentially  keeping  locked  the  float  liquidity.  Moreover,  the  function repay() does not impose any time restriction to borrowers when they can exercise their option, i.e., the borrower  can  potentially  call  the  repay()  function  at  an  arbitrary  time  after  the  maturity.  This  puts pressure on the liquidity providers to call it themselves which is possible because in the current version of the  PrimitiveEngine  contract,  anyone  can  call  the  function  repay()  after  the  maturity  of  the pool. If liquidity provider have the burden to call the functions, they also bear the costs.   Specification changed  This  version  of  the  code  introduces  a  grace  period,  around  24h,  to  permit  only  borrowers  calling  the function repay() after pool's maturity. In case a borrower does not call the function during this period, anyone can call the function repay() and exit the borrowers' positions, therefore releasing the locked liquidity. Still, the additional costs need to be payed by the caller / LP if they call it to relase their funds.   Specification changed  The respective code has been removed according to the new specifications of   .  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Disable Unnecessary Functionalities After",
        "body": " Expiry  In the current version of the PrimitiveEngine contract all functions, except function swap(), can be called after the pool has expired. For example, a liquidity provider could close the opened positions of borrowers,  claim  its  share  of  the  float  liquidity,  and  then  call  function  borrow()  for  the  remaining amount of float.  Primitive Finance - Core Engine -   13  DesignHighVersion1Speci\ufb01cationChangedVersion2Version3Version3DesignHighVersion1CodeCorrected                \fCode corrected  The updated version of the contract has new checks if the pool is still valid in the respective functions.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Flawed Fee and Premium Structure",
        "body": "  When swapping, a fee is charged and borrows pay a premium on their position. Both amounts end up in the  pool  without  separate  accounting.  This  has  various  implication.  All  arising  from  the  fact  that  the underlying  calculation  are  based  on  the  pool's  reserve,  which  includes  the  fees  and  premiums.  All operations  that  pay  out  a  proportion  of  the  reserve  amounts  -  also  pay  out  parts  of  the  fees  and premiums. Hence, each time remove, repay, swap or borrow is called, fees and premiums are payed out. Regardless of the callee is entitled to receive these fees.  The  most  severe  issue  is  the  swap  function.  Swapping  on  the  pool's  reserve,  which  includes  the collected fees, will nullify all previous fees and prevent fee accumulation. Hence, liquidity providers will not earn fees collected during the lifetime of the pool, but only the fee from the last swap.  Other examples for issues are shared (even with non-eligible users) premiums and fees, participating on fees and premiums repeatedly. E.g. a liquidity provider that does not take the risk of lending their token gets  a  share  of  the  premium.  A  borrower  gets  part  of  the  premium  and  fees  of  others.  All  this  can  be leveraged through repeating the operation.   Specification changed  This version of the code introduces a novel fee structure.   Specification changed  The  respective  code  has  been  updated  according  to  the  new  specifications  of  fees only during swaps.    which  assume  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   No Slippage Protection",
        "body": "  All transactions have a lag between the time they are sent and the time they are executed as they remain in  the  mem  pool  for  some  time  prior  to  being  executed.  Between  sending  and  execution,  other transaction might change the contract's state. This is critical for all transaction where the user receives or  all action function in the Engine contract except for supply and claim do has to pay funds. In  not  offer  any  protection  against  slippage.  In  VERSION4  this  affects  allocate,  remove,  and  swap. Without  checking  if  the  transaction  is  still  executed  under  the  desired  conditions,  the  user  may  suffer losses.  This issue can be maliciously exploited by front running certain transactions. However, as the system is designed to interact with smart contracts, the slippage protection could be implemented on their side.  Code corrected  The user is now able to define the delta in and delta out when swapping. Hence, the user either gets the defined values or the swap will revert due to a violation of the invariant check. The check verifies that the invariant can only increase.  Primitive Finance - Core Engine -   14  DesignHighVersion1Speci\ufb01cationChangedVersion2Version3Version3DesignHighVersion1CodeCorrectedVersion1                \f6.7   Violation of Maximum Ratio of Float Liquidity  The amount of liquidity supplied as float should be less than a threshold value, hard coded to 80% in the current version of the contract. This restriction is enforced in the function addFloat() as follows:  function addFloat(Data storage reserve, uint256 delLiquidity) internal {         reserve.float += delLiquidity.toUint128();         if ((reserve.float * 1000) / reserve.liquidity > 800) revert LiquidityError();     }  This restriction is enforced only when a liquidity provider supplies its liquidity as float, but it does not hold always as any liquidity provider can freely remove available liquidity from the pool. For example, if the float  the function remove() to remove the 20% of the remaining liquidity, thus putting the pool reserve in a state with 100% of its liquidity as float.  liquidity  provider  could  call   (i.e.,  80%),  one   its  maximum   liquidity   is  at   level   function remove(         Data storage reserve,         uint256 delRisky,         uint256 delStable,         uint256 delLiquidity,         uint32 blockTimestamp     ) internal {         reserve.reserveRisky -= delRisky.toUint128();         reserve.reserveStable -= delStable.toUint128();         reserve.liquidity -= delLiquidity.toUint128();         update(reserve, blockTimestamp);     }   Code corrected  The Reserve library now defines a function checkUtilization() which checks if the invariant holds whenever float is added, float is payed, or the liquidity is removed.  :  Specification  changed  The  respective  code  has  been  removed  according  to  the  new  specifications of   .  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   Token Decimal Validation",
        "body": "  The engine contract supports tokens with different decimals. However, tokens with very few decimals and more than 18 decimals cause severe issues but are allowed to be deployed by the factory.  Code corrected  The  factory  now  validates  decimals  for  both  tokens  before  deploying  an  engine.  Tokens  with  6  to  18 decimals are supported.  Primitive Finance - Core Engine -   15  SecurityHighVersion1Speci\ufb01cationChangedVersion2Version3Version3DesignMediumVersion3CodeCorrected                  \f6.9   Explicitly Handling Positive Invariant Restriction  The current implementation checks that the invariant grows assuming it is negative and, when updated by a swap, grows closer to zero: if (invariant > nextInvariant && nextInvariant.sub(in variant) >= Units.MANTISSA_INT).  A  zero  invariant  implies  a  balanced  pool  at  the  time  of  the  swap.  Typically,  the  invariant  should  not become  positive  but  could  happen  in  specific  scenarios  such  as  high  trading  frequency  and  high  fee accumulation. If this is the case, besides major other problems, the pool cannot recover as the invariant needs to decrease back to zero to be in balance again. This is because of the check, that the invariant is only allowed to grow after a trade. However, in case of a positive invariant, it should not become more positive.  : Code changed  The updated version of the code checks explicitly if the invariant is positive and prevents the invariant to grow in the wrong direction.  :  Specification  and  code  changed  The  issue  theoretically  exists  in  version  3.  However, according to Primitive Finance, a positive invariant is not an undisired state any more and a swap should not lead to a decreasing invariant - even if it is positive.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   Incorrect Tracking of Cumulative Values for",
        "body": " Pool Reserves  Primitive  Finance  pointed  out  this  issues  while  the  audit  was  ongoing.  They  are  aware  that  calling  the function update() after the pool reserve values are updated, results in incorrect cumulative values.  Code corrected  The function update() is called before the new amounts have been applied to the pool reserves.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.11   Liquidity Providers Get Rewards Without",
        "body": " Supplying Float Liquidity  In order for users to borrow liquidity from the pools, liquidity providers should allocate liquidity to a pool and then supply it as float which can be borrowed. Users pay a premium when borrowing liquidity and the float liquidity of the pool reserve is deducted. After the borrowers pay their debt, the liquidity providers should claim at first their share of liquidity as float, and then remove it from the reserve.  Since the liquidity providers do not get tokens for their supplied liquidity, the premiums paid by borrowers go to the pool reserve. This way, all liquidity provider get tokens out according to their share of liquidity and independently if they have supplied float liquidity to the pool. Hence, a liquidity provider that supplies  Primitive Finance - Core Engine -   16  DesignMediumVersion1Speci\ufb01cationChangedVersion2Version3DesignMediumVersion1CodeCorrectedDesignMediumVersion1Speci\ufb01cationChanged                      \ffloat liquidity and is more exposed (cannot remove liquidity unless borrowers repay it, or the maturity has passed) do not get any additional reward.   Specification and code changed  Version  2  introduces  a  novel  fee  structure  that  collects  fees  when  borrow()  function  is  called  and distributes the collected fees to liquidity providers that have supplied float. In case of a positive invariant, swap fees are also distributed to float providers.   Specification changed  The respective code has been removed according to the new specifications of   .  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.12   Possible Overflows",
        "body": "  Primitive Finance pointed out these issues while the audit was ongoing. They are aware that the following expressions could overflow:  res.cumulativeRisky += res.reserveRisky * deltaTime; uint256 reserveRisky = (res.reserveRisky * 1e18) / res.liquidity;  Code corrected  The overflow is avoided by casting the variables to uint256 as follows:  res.cumulativeRisky += uint256(res.reserveRisky) * deltaTime; delRisky  =  (delLiquidity  *  reserve.reserveRisky)  /  reserve.liquidity;,  where delLiquidity is of type uint256.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.13   Possible to Frontrun on Claim Request",
        "body": "  In  some  situations,  e.g.,  the  price  of  the  underlying  token  changes  significantly,  one  (or  more)  liquidity providers might want to exit their positions and call function claim() to remove their liquidity from float. However, an attacker might frontrun this transaction and call function borrow() and prevent the liquidity provider from exiting their position.   Specification changed  The respective code has been removed according to the new specifications of   .  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.14   Redundant and Improper Revert Condition",
        "body": "  The  two  functions  balanceRisky()  and  balanceStable()  verify  if  the  call  returns  the  balance correctly by checking: if(!success && data.length < 32) and revert if the condition is true. This makes sense if success is false or the call did not return a value (data.length < 32). With using &&  instead  of  or  the  condition  would  not  revert  for  the  combination  of  success  =  false  and data.length > 32 (which is possible). As the function needs the balance to work properly, we do not see  a  case  where  this  should  not  revert  if  data.length  <  32.  The  data.length  check  is  also  Primitive Finance - Core Engine -   17  Version2Version3Version3SecurityMediumVersion1CodeCorrectedDesignMediumVersion1Speci\ufb01cationChangedVersion3Version3DesignMediumVersion1CodeCorrected                        \fredundant  because  it  is  also  performed  in  abi.decode(data,  (uint256)).  Additionally,  it  might make sense to reevaluate if the less than condition makes sense or an equal condition would be more suitable.  Code corrected  The client has updated the check as follows: if (!success || data.length < 32).  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.15   Inconsistency of Input Parameters",
        "body": "  The engine contract is not consistent on the number of decimals an input value should have when called externally.  More  precisely,  the  function  create()  expects  the  strike  price  to  have  18  decimals, independently from the decimals of the stable token. However, the function swap() expect the deltaIn to  have  the  same  decimals  as  the  token  being  swapped  in.  A  similar  format  is  expected  by  functions deposit() and withdraw().  Code corrected  The  function  create()  expects  the  strike  price  to  have  the  same  number  of  decimals  as  the  stable token. Also, the specification has been updated accordingly.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.16   Unused Error Definition",
        "body": "  The error ZeroLiquidityError is defined in IPrimitiveEngineErrors but not used.  Code corrected  The ZeroLiquidityError error is now used in remove and allocate.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.17   Redundant Storage Read",
        "body": "  Reading from state storage consumes more gas than reading from memory. The compiler often handles redundant  storage  reads.  To  avoid  paying  multiple  times  for  storage  reads,  storage  variables  can  be buffered  in  memory  if  used  more  than  once.  This  is  tha  case  for  precisionStable  and precisionRisky in create and swap as they are accessed more than once from storage.  Specification changed  The decimal accounting was changed in   . This issue does not exist anymore.  Primitive Finance - Core Engine -   18  DesignLowVersion3CodeCorrectedDesignLowVersion3CodeCorrectedDesignLowVersion2Speci\ufb01cationChangedVersion3                          \f6.18   Code Duplication  The following functions share the same code which could be reused:  In borrow, repay, remove and allocate:  delRisky = (delLiquidity * reserve.reserveRisky) / reserve.liquidity; // amount of risky from removing delStable = (delLiquidity * reserve.reserveStable) / reserve.liquidity; // amount of stable from removing  Code corrected  The duplicated statements are moved into a function getAmounts() in the Reserve library.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.19   Duplicated Calculation of Invariant",
        "body": "  The  function  swap()  after  updating  the  timestamp  of  the  pool,  calculates  the  invariant  for  the  new time  until  expiry  (tau):  int128  invariant  =  invariantOf(details.poolId);.  Afterwards, calls  either depending  on  getStableGivenRisky()  getRiskyGivenStable().  call function  invariantOf(),  which  recalculates  the  invariant  for  the  same  pool  and  the  same timestamp.  Although  recalculating  the  invariant  is  reasonable  for  external  calls,  it  increases  the  gas consumption for calls from the swap function.  value  of  riskyForStable  parameter,   functions   function   these   Both   the   the   or   Code corrected  The  updated  function  swap()  calls  the  getRiskyGivenStable()  and  getStableGivenRisky() functions  from  the  ReplicationMath  library  which  take  the  invariant  as  an  argument  and  do  not recalculate it.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.20   Implementation of getStableGivenRisky",
        "body": " Function  The function specification for calculating the stablePerLiquidity do not include the value of the last invariant. However, the function implementation adds the last invariant in the computed stables, therefore resulting in this formula: stablePerLiquidity = K*CDF(CDF^-1(1 - riskyPerLiquidity) -  sigma*sqrt(tau)) + invariantLastX64.  Code corrected  The code comment has been updated correctly.  Primitive Finance - Core Engine -   19  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                        \f6.21   Possible Gas Optimization in the Deposit Function  The function deposit() in the engine contract allows users to deposit a single token to their margin account, therefore the function calls the balanceof() function only for the token with a positive delta. However,  after  the  callback  function  for  the  transfer  executes,  the  function  checks  the  balance  of  both tokens  (performs  two  balanceOf()  calls).  The  function  can  optimize  the  gas  consumption  again  by calling the balanceOf() only for the token added.  Code corrected  The updated version of the function deposit() now checks if the delta value is greater than 0 before reading the balance (before and after the transfer) for the stable and the risky tokens.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.22   Return Value in safeTransfer",
        "body": "  The function safeTransfer() in the library Transfers checks if an ERC20 token transfer completed successfully, otherwise the function reverts. Currently, the function returns a boolean value but it is never checked in the caller functions.  Code corrected  The return value in safeTransfer() has been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.23   MANTISSA_INT Constant",
        "body": "  MANTISSA_INT is a constant defined in units library and its value in 64x64 format corresponds to 10x the value of the constant variable Mantissa in units library.  Code corrected  The unused MANTISSA_INT has been removed.  Primitive Finance - Core Engine -   20  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                      \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Engine Shall Not Have Privileges in Other",
        "body": " Smart Contracts  With  the  current  setup,  for  security  reasons,  the  engine  contract  must  not  have  privileges  in  any  other smart contracts. The main reason is that the engine contract supports several callbacks which potentially could have the same function signature as a sensitive function in the contract being called.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Limited Supported Token Pairs",
        "body": "  PrimitiveFactory  contract  deploys  a  unique  PrimitiveEngine  contract  for  a  pair  of  ERC20  tokens.  The function deploy() takes as arguments the addresses of the two ERC20 tokens and assumes that they  are  implemented  correctly  and  behave  as  expected.  The  function  deploy  checks  only  if  the provided  addresses  of  the  risky  token  and  the  stable  one  are  not  the  same  and  that  they  are  different from address(0).  Technically,  it  is  possible  to  deploy  a  PrimitiveEngine  with  any  arbitrary  pair  of  tokens,  such  as: compromised/malicious tokens, two risky tokens, two stable tokens, or with switched addresses for the risky and stable tokens. Therefore, the filtering of the bad or malicious engines and their respective pools should  happen  on  the  application  level  (outside  the  audited  smart  contracts)  in  order  to  protect  users from interacting with incorrect engines.  We explicitly mention that the contract ONLY works with standard ERC20 tokens that do not have any unusual  behavior  like  inflation,  deflation,  locking,  fees,  two  addresses  etc.  Users  needs  to  carefully evaluate if the pool's token fulfill the requirements!  A check in the factory before deploying the engine might at least prevent accidentally adding a token with unsupported decimals.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   More Testing for CDF",
        "body": "  The correctness of the cumulative normal distribution function and its inverse function are important for the whole protocol. The functions getCDF() and getInverseCDF() ensure that the pool maintains the correct values of stable and risky tokens at any time. Both functions compute approximate values and the current  testing  shows  that  the  error  falls  below  a  chosen  threshold.  However,  the  code  calls  these (refer  functions  to getRiskyGivenStable()  and  getStableGivenRisky()  is  highly recommended to expand the testing for checking how the combine error changes when the functions are called as in the above example.  getCDF(getInverseCDF(x)   volatility)   functions),   therefore   pattern   the   +   in   it   Primitive Finance - Core Engine -   21  NoteVersion1NoteVersion1NoteVersion1            \f7.4   Oracle Usage  In case any project uses the current marginal prices as oracles, the oracle price would be an easy target to price manipulation.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   Stuck Funds",
        "body": "  When the PrimitiveEngine contract calls callbacks from other contracts to make a token transfer, the engine  only  checks  that  its  token  balance  increased  by  a  value  equal  or  greater  than  an  expected amount. Afterwards, the engine updates the reserve balances with the expected amount. However, if the external  contract  transfers  more  token  than  expected,  the  difference  (tokens  transferred  -  expected tokens)  are  locked  in  the  engine  contract  and  neither  pools,  nor  liquidity  providers  can  access  them. Below is a code example from the function create():  if (balanceRisky() < delRisky + balRisky) revert RiskyBalanceError(delRisky + balRisky, balanceRisky()); if (balanceStable() < delStable + balStable) revert StableBalanceError(delStable + balStable, balanceStable());  Funds can also be locked during liquidity allocation if either delRisky or delStable does not match the delLiquidity that the user intents to allocate. The function allocate() computes the respective delta liquidities for both tokens (risky and stable) and rewards the smallest delta liquidity to the user. The code is shown below:  uint256 liquidity0 = (delRisky * reserve.liquidity) / uint256(reserve.reserveRisky); uint256 liquidity1 = (delStable * reserve.liquidity) / uint256(reserve.reserveStable); delLiquidity = liquidity0 < liquidity1 ? liquidity0 : liquidity1; ... liquidity[recipient][poolId] += delLiquidity; // increase position liquidity  The same is true for all other funds that are accidentally send to the contract or intentionally forced into the contract.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.6   Timestamp Conversion Limit",
        "body": "  The  _blockTimestamp  function  converts  the  block.timestamp  from  a  uint256  to  a  uint32. Hence, limiting the maximum value for the timestamp to Sunday, February 7, 2106. This is in 84 years. The contract will have issues in case it is used this long at that point in time.  Primitive Finance - Core Engine -   22  NoteVersion1NoteVersion1NoteVersion1          \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Arbitrage Opportunities",
        "body": "  0  0  1  2  CS-SWAAP-EARN-013  Arbitrage opportunities due to price update could arise if the default implementation of Fund (Fund.sol) was  deployed  with  deposit/withdraw  fees  that  are  low.  In  this  case,  an  attacker  could  deposit  funds, observe  a  price  change  transaction,  and  withdraw  the  funds  to  profit  from  the  price  change.  This  can happen  if  an  arbitrageur  observes  a  price  change  transaction  and  sandwich  it  with  a  deposit  and  a withdraw transaction.  Note that such opportunities might be discouraged by the application of enter and exit fees on deposit and withdraw.  Finally,  it  is  important  to  highlight  that  the  Fund  variants  FundWithShareLockPeriod.sol  and FundWithShareLockFlashLoansWhitelisting.sol  offer  have  an  additional  layer  of  protection against this attack vector. The shares of the fund are locked for a certain period of time after a deposit. This prevents the attacker from withdrawing the funds immediately after a deposit.  Acknowledged:  The  FundWithShareLockFlashLoansWhitelisting.sol variation.  acknowledged.   Swaap   issue   is   will   only   use   the  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Call to applyFeesBeforeJoinExit Can Burn",
        "body": " All Gas  Swaap Labs - Swaap Earn Protocol -   15  SecurityDesignCriticalHighMediumAcknowledgedLowRiskAcceptedAcknowledgedSecurityMediumVersion1AcknowledgedDesignLowVersion1RiskAccepted                  \fThe call to FEES_MANAGER.applyFeesBeforeJoinExit is done using try catch, so if the call fails, the flow with continue without fees. However, in some case the call can cause EVM-level panic and burn all gas, so there will be no gas left to continue the flow.  CS-SWAAP-EARN-002  Risk accepted:  Swaap Labs has acknowledged the issue and has decided to keep the code unchanged in  . In case the FeeManager panics, the Fund can be shut down, allowing LPs to withdraw without calling the FeesManager.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   Donation Can Break Performance Fees",
        "body": "  Just  after  the  deployment,  by  default  Fund  is  required  to  have  at  least  10^4  of  assets  and 10^4  *  10^  (_FUND_DECIMALS  -  _ASSET_DECIMALS)  of  shares.  The  FeeManager  stores  the highWaterMarkPrice as type(uint72) with 18 decimals precision ~ 4.72e21. When the first deposit is made,  the  highWaterMarkPrice  is  set  to  the  new  value.  However,  an  attacker  can  donate  a  small amount  of  assets  to  the  fund  via  token  transfer  and  make  the  highWaterMarkPrice  more  than type(uint72).max.  This  way  the  performance  fee  will  be  broken  and  the  Fund  will  keep  operating without  fees.  Inflating  initial  10^4  of  shares  for  18  decimal  asset  won't  require  a  lot  of  value  for  some tokens.  CS-SWAAP-EARN-003  . Swaap Labs has acknowledged the issues and has decided to keep the code unchanged in  However, to tackle any possible risk, Swaap Labs will initiate the Fund with at least 1$ worth of assets such that the attack would be expensive to perform.  Swaap Labs - Swaap Earn Protocol -   16  Version2SecurityLowVersion1AcknowledgedVersion2          \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings   Fees Calculation Discrepance   -Severity Findings   Deployer Cannot Accept Ether    resetHighWaterMark() Ignores Pending Fees   Informational Findings   Specifications Problems    Events    A Fund Cannot Take Flashloans From Both Balancer and Swaap    Gas Efficiency   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Fees Calculation Discrepance",
        "body": "  0  0  1  2  4  The enter and exit fees are computed in a way that introduces discrepancies in the system.  1. maxDeposit returns an incorrect amount compared to the maximum amount that will be possible  to actually withdraw using withdraw.  2. When depositing, mint will be a cheaper option compared to deposit.  CS-SWAAP-EARN-001  Example of 1.  Assume that the Fund that has 1000 shares and 1000 assets. Also, it has 1100 shares cap and a 20% fee. No fee shares pending to be minted.  When user calls maxDeposit(), the function will return:  100 shares * 1000 assets / 1000 shares * (100% + 20%) / 100% = 120 assets  When user calls deposit() with 120 assets, the function will mint:  120 assets * 1000 shares / 1000 assets * (100% - 20%) / 100% = 96 shares  The  difference  is  4  shares.  Calling  deposit  with  125  assets  will  mint  100  shares,  which  is  what maxDeposit()  in _applyEnterOrExitFees() function. In one case, (100% + fee)/100% is used, and in the other, (100% - fee)/100% is used. But the one is not the inverse of the other.  value.  The  discrepancy   calculated   to  how   is  due   fee   the   is   Example of 2.  Swaap Labs - Swaap Earn Protocol -   17  CriticalHighMediumCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedDesignMediumVersion1CodeCorrected        \fA 50% entrance fee will increase the number of assets needed by mint by 1.5 times, while decrease the number of minted shares by 2 in deposit. Thus mint() will effectively be cheaper.  Code  corrected:  Swaap  Labs  has  corrected  the  code  in    by  changing  the  way  the  fees  are applied. Now, when entering the fund, the number of assets is virtually increased by the fee, and when exiting, the number of assets is decreased by the fee. This way the discrepancy is removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Deployer Cannot Accept Ether",
        "body": "  Deployer  has  deployContract()  function  that  deploys  a  contract  using  CREATE3  library.  This function  accepts  a  value  parameter  that  is  supposed  to  be  transferred  to  the  deployed  contract.  The library  function  CREATE3.deploy(salt,  createCode,  value)  will  try  to  transfer  value  of  ether together with the deployment transaction. However, deployContract() function does not accept Ether and Deployer contract does not have any other way to receive Ether. This limits the functionality of the deployContract() function and complicates the deployment process if ether transfer is required.  CS-SWAAP-EARN-004  Code  corrected:  Swaap  Labs  has  corrected  the  code  by  making  the  function  deployContract payable and by passing msg.value to the CREATE3 library.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   resetHighWaterMark() Ignores Pending",
        "body": " Fees  The resetHighWaterMark() function can be called by Registry owner to reset the high-water mark. However,  the  function  does  not  take  into  account  the  fees  that  would  have  been  minted  if collectFees() was called before computing the new mark. When mark is reset and fees are minted afterward, the high water mark will be higher than the new price of shares.  CS-SWAAP-EARN-005    Swaap Labs has corrected the code in  collectFees(), before resetting the high-watermark price.   by collecting the management and performance fees via  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   A Fund Cannot Take Flashloans From Both",
        "body": " Balancer and Swaap  A  fund  can  request  a  flash  loan  from  Balancer  or  Swaap  thanks  to  the  SwaapV2Adaptor  and BalancerFlashLoanAdaptor adaptors.  CS-SWAAP-EARN-012  Swaap Labs - Swaap Earn Protocol -   18  Version2DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedVersion2InformationalVersion1CodeCorrected                      \fit   is   However,  in FundWithBalancerFlashLoans  will  only  be  callable  by  the  immutable  address  balancerVault. Therefore,  the  contract  FundWithBalancerFlashLoans  will  have  to  be  configured  at  deployment  to either receive flash loans from Balancer OR from Swaap.  receiveFlashLoan()   function   noting   worth   that   the     Registry   approvedFlashLoanSource. The  FundWithBalancerFlashLoans  verifies  that  msg.sender  is  the  approved  flash  loan  source  before executing receiveFlashLoan().  mapping   contract   holds   now   a   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Events",
        "body": "  CS-SWAAP-EARN-007  The following events could be improved:   Deployer.ContractDeployed(name,  contractAddress,  creationCodeHash)  name  could be indexed.   Registry.DepositorOnBehalfChanged(depositor, state) depositor could be indexed.   Registry.TargetPaused(target)  and  Registry.TargetUnpaused(target)  target  could  be indexed.   Fund.AdaptorCalled(adaptor, data) could have adaptor indexed.    Swaap Labs has corrected the code in   .  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Gas Efficiency",
        "body": "  CS-SWAAP-EARN-008  The following code could be optimized to consume less gas:  Fund  1. cachePriceRouter:  computing  assetsAfter  does  not  serve  any  purpose  unless  checkTotalAssets is enabled.  2. maxdeposit: sharesupplycap is read twice from storage and assigned to _cap.  PriceRouter  1. completeTransition: the requirement that pendingOwner != 0 is redundant.  2. getValue,  _getValues,  getExchangeRate  and  getExchangeRates:  all  redundantly  check  that the derivative is non-zero; the check is already performed in _getPriceInUSD.  Registry  1. completeTransition:  the  requirement  that  pendingOwner  !=  0  is  redundant,  since  msg.sender == pendingOwner.  Swaap Labs - Swaap Earn Protocol -   19  InformationalVersion1CodeCorrectedVersion2InformationalVersion1CodeCorrected            \f2. setMaxAllowedAdaptorVolumeParams: some of the variables in the event could be replaced  with equivalent stack variables.  AaveV3ATokenManagerAdaptor  1. depositToAave:  when  revoking  approval,  the  conversion  of  _revokeExternalApproval  to  ERC20 is redundant.    Swaap Labs has corrected the code in   .  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Specifications Problems",
        "body": "  The specifications of the codebase present some issues:  Fund  1. deposit and redeem have outdated comment \"Check for rounding error since we round down in  CS-SWAAP-EARN-010  previewDeposit.\".  2. _MAX_POSITIONS has a typo in the natspec.  3. _DELAY_UNTIL_END_PAUSE has a typo in the natspec.  4. cachePriceRouter has a typo in the natspec.  5. Swaap  Governance  and  Swaap  Strategist  used  interchangeably  when  onlyOwner  modifier  is  used.  PriceRouter  1. _updateAsset has a missing parameter in the natspec.  Registry  1. setMaxAllowedAdaptorVolumeParams  has  an   incorrect  natspec   for   the  parameter  resetVolume.  2. checkAndUpdateFundTradeVolume has incorrect natspec.  BaseAdaptor #. _verifyConstructorMinimumHealthFactor has incorrect natspec.  AaveV3DebtManagerAdaptor #. Contract natspec \"Adaptor Data Specification\" is incorrect.  AaveV3ATokenManagerAdaptor #. In the contract natspec, the statement \"Funds with multiple aToken positions MUST only specify minimum health factor on ONE of the positions\" is outdated.    Swaap Labs has corrected all the issues mentioned above in   .  Swaap Labs - Swaap Earn Protocol -   20  Version2InformationalVersion1CodeCorrectedVersion2      \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Circular Dependencies",
        "body": "  It is possible for a Swaap fund to have a position in another Swaap fund. This means that funds might be configured  such  that  a  circular  dependency  is  created.  This  might  break  the  price  evaluation,  due  to  a loop.  Circular dependencies should be avoided, however, when adding a new position into a fund, there are no mechanisms in place to prevent this issue.  CS-SWAAP-EARN-006  Acknowledged:  Swaap  Labs  has  acknowledged  the  potential  risks  and  has  decided  to  leave  the  code  unchanged  in  .  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Output Token From Swaap Fund Positions",
        "body": "  A fund can have a position in another Swaap Fund. Let's call the fund with the position fund1 and the fund as asset - fund2.  However,  when  withdrawing,  the  function  SwaapFundAdaptor.withdraw()  does  not  check  that  the assets the fund2 can transfer to fund1 are tracked. This might might cause big slippage of share prices of fund1.  CS-SWAAP-EARN-009  Acknowledged:  Swaap  Labs  has  acknowledged  this  limitation  and  will  pay  additional  attention  when  adding  such positions.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Withdrawal Priority",
        "body": "  The  Fund  stores  withdrawable  assets  in  creditAssets  array.  During  withdrawal,  the  assets  are withdrawn  from  the  creditAssets  array  in  the  order  of  their  list  index,  until  the  needed  amount  is withdrawn. This makes that assets with higher indices less likely to be withdrawn. Fund owners must be aware of this behavior and adjust the asset list when needed.  CS-SWAAP-EARN-011  Acknowledged:  Swaap Labs - Swaap Earn Protocol -   21  InformationalVersion1AcknowledgedVersion2InformationalVersion1AcknowledgedInformationalVersion1Acknowledged                \fSwaap Labs is aware of this behavior and intends to support Funds with properly arranged assets.  Swaap Labs - Swaap Earn Protocol -   22  \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Manipulating the Price of",
        "body": " SwaapSafeguardPools  While  highly  unlikely,  it  is  possible  that  the  asset  composition  SwaapSafeguardPool  can  be manipulated  by  3rd  parties,  due  to  AMM  nature  of  the  pool  Thus,  the  price  returned  by  the  price extension SwaapSafeguardPools could be subject to manipulation  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Staking Reward Tokens",
        "body": "  Certain protocols like AAVE and COMP have a staking reward token that is not the same as the underlying token. Fund might need a special adapter to handle these rewards.  Swaap Labs - Swaap Earn Protocol -   23  NoteVersion1NoteVersion1      \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   No Documentation",
        "body": "  0  0  0  4  No  documentation  is  available  for  ERC20Pods.  This  abstract  contract  is  intended  to  be  used  by  third parties hence documentation is vital to avoid issues. For authors of pods it must be clearly documented what they have to take into account and what they can rely on, such as:   Failed calls to Pod.updateBalances() are ignored, consequently authors of pods must be aware  of the consequences for their pods   Amount of gas available   When  exactly  the  token  triggers  Pod.updateBalances():  Upon  non-zero  token  transfers  and when the pod is added/removed from an account having non-zero balance. Misunderstandings by a developer of a Pod may lead to correctness issues.  The trust model should be clearly specified, including:   How exactly pods are trusted / untrusted   Whether only trusted parties can add/remove pods to/from an account. If this holds, the docs should  clearly state that a developer extending ERC20Pods must adhere to this  Furthermore  not  all  token  holders,  e.g.  contracts  can  call  addPod()  themselves.  The  documentation may elaborate on this topic, e.g., what can be assumed / what the limitations are.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Consistency on Zero Amount Transfers",
        "body": "  1inch - ERC20 Pods -   10  SecurityDesignCriticalHighMediumLowAcknowledgedRiskAcceptedAcknowledgedSecurityLowVersion1DesignLowVersion1Acknowledged                \fThe ERC20 standard specifies Note Transfers of 0 values MUST be treated as normal t ransfers  and  fire  the  Transfer  event..  For  consistency,  it  may  make  sense  to  inform  the registered pods about 0 balance actions and 0 amount transfers. If this behavior is desired the way it is, it should be mentioned somewhere so that Pod developer are aware that 0 balance or 0 amount transfers are not notified to the Pod.  Acknowledged:  1inch acknowledged the issue and decided to leave the code as it is.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   Side Effects of _updateBalances()",
        "body": "  While  the  gas  check  prevents  direct  reentrancy  into  the  token  on  functions  changing  the  balance, 200_000 gas is enough to make some other state changes that could affect to-be-updated pods. Notably upon updating the first pod A, this contract may interact with another pod B which is to be updated later in the  sequence  and  hence  does  not  yet  know  about  these  balance  changes  pod  A  currently  executing already is aware of. While we have not uncovered any direct issue, a badly designed or adversarial pod could be problematic. No trust model nor specification covering this scenario is available.  Risk accepted:  1inch is aware of and accepts the risk.    introduced  a  reentrancy  guard.  Note  that  this  can  be  leveraged  by  a  pod  to  detect  such  a scenario  and  revert.  While  the  state  of  the  reentrancy  guard  itself  cannot  be  querried  direcly,  public functions  balanceOf  and  podBalanceOf  now  feature  the  nonReentrant(View)  modifier  and  will revert if called in such a situation. Hence in the scenario described above pod B could call balanceOf() and be protected.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.4   Zero Address Consistency in AddressArray",
        "body": "  When querying an index that is out-of-bounds with AddressArray.at, the function does not revert and returns  address(0).  Thus,  it  is  not  possible  to  distinguish  between  an  address(0)  that  would effectively be part of the array, and an out-of-bounds access.  Acknowledged:  1inch  is  aware  of  the  issue  and  states  that  in  the  current  use  case,  no  pod  with  address(0)  can  be added. While this is true in the case of ERC20Pods, it can still be an issue for other contracts using the library.  1inch - ERC20 Pods -   11  SecurityLowVersion1RiskAcceptedVersion2DesignLowVersion1Acknowledged                  \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings  -Severity Findings   ERC20Pods podsLimit Sanitization    Missing Events    Operations Order on Pod Removal   0  0  0  3  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   ERC20Pods podsLimit Sanitization",
        "body": "  The  podsLimit  in  the  ERC20Pods's  constructor  is  never  sanitized.  If  podsLimit  is  zero,  the functionality  added  by  ERC20Pods  cannot  be  used,  so  it  would  not  make  sense  to  allow  setting podsLimit=0.    The constructor of the ERC20Pods contract now checks that podsLimit is not zero.  Note  that  in  sanitized. Unsuitable values could make the ERC20Pods unusable.    the  constructor  takes  a  second  parameter  podCallGasLimit_  which  is  not  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Missing Events",
        "body": "  Typically, events help track the state of the smart contract. To be able to reconstruct the state offchain, events should be emitted when users add and remove pods.    Two  events  PodAdded  and  PodRemoved  have  been  added  and  are  emitted  whenever  a  pod  is added/removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Operations Order on Pod Removal",
        "body": "  1inch - ERC20 Pods -   12  CriticalHighMediumLowCodeCorrectedCodeCorrectedCodeCorrectedDesignLowVersion1CodeCorrectedVersion2DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \fWhen a pod is removed with removePod, it is first removed from the internal address set, and then the balances are updated. But when calling removeAllPods, the balances are updated before the pod is removed  from  the  address  set.  Thus,  there  are  two  different  behaviors  for  the  same  action  and  the potential for inconsistencies arises.    The function removeAllPods now follows the order of removePod by first removing the pod from the address set and then update the balances.  1inch - ERC20 Pods -   13  \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Failed Call to Pod Is Silent",
        "body": "  ERC20Pods._updateBalances()  calls  the  pod  with  a  fixed  amount  of  gas.  If  this  call  fails,  the execution nonetheless continues normally in order to not block the ERC20. Users must be aware that a failed call to a pod is silent and will not emit any event.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Integrations May Break Due to Gas",
        "body": " Requirements  A  transfer  of  an  ERC20Pods  may  require  significantly  more  gas  than  the  transfer  of  a  normal  ERC20. This especially applies when sender and receiver are connected to multiple distinct pods. Moreover, the current abstract contract ERC20Pods allows an user to register any arbitrary pod for his address.  In the worst case each of the pods uses the full 200'000 gas available. When sender and receiver have distinct pods this amounts to 2 * podsLimit gas.  Integrations must take this into account in order to avoid running into problems such as, but not limited to:  An example could be a liquidation of a position where in an extreme case multiple different ERC20Pods where each sender/receiver is connected to several pods must be transferred. The liquidation may not be possible due to the gas requirement exceeding the block gas limit.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Not Exactly _POD_CALL_GAS_LIMIT",
        "body": " Available  A  Pod  cannot  rely  on  having  exactly  200'000  gas  available  upon  being  called.  While  it  is  taken  into account that a maximum of 63/64 of the remaining gas can be passed to the call, due to the overhead between the check and the call:  if lt(div(mul(gas(), 63), 64), _POD_CALL_GAS_LIMIT) {         mstore(0, exception)         revert(0, 4)     }         pop(call(_POD_CALL_GAS_LIMIT, pod, 0, ptr, 0x64, 0, 0))     }  in a corner case scenario the call may receive slightly less gas.  1inch - ERC20 Pods -   14  NoteVersion1NoteVersion1NoteVersion1            \f7.4   Order of Pods in AddressSet  Users msut be aware that upon pod removal, the order in the pods in the AddressSet may change, so two calls to podAt with index X, with a call to removePod in-between, may not yield the same result.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   Unaffected Elements of the Output Memory",
        "body": " Array on AddressArray.get()  providing   function When  AddressArray.get(Data storage self, address[] memory output), users must be aware that if length(self) < output.length(), only the length(self) first elements of output will be overwritten, leaving the remaining elements of output untouched.  memory   output   array   the   an   to   1inch - ERC20 Pods -   15  NoteVersion1NoteVersion1      \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Complexity of Commands Effect Evaluation",
        "body": "  Due to the novelty and non-standard encoding of Weiroll, the end user will need to sign a transaction, without knowing full details about the execution consequences. Standard hardware and software wallets won't  be  able  to  decode  the  content  of  the  commands.  As  a  result,  users  will  need  to  perform blind-signing - signing without verifying the full transaction details. Phishing attacks can be performed on users  to  trick  them  to  sign  commands  that  will  impact  the  token  balances  in  an  undesired  way.  Users should be notified about this risk and only sign transactions from trusted sources and ideally after careful inspection.  Enso - Enso-Weiroll -   10  DesignCorrectnessCriticalHighMediumLowRiskAcceptedDesignLowVersion1RiskAccepted            \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings   Function writeOutputs Can Corrupt Memory   -Severity Findings   Assumptions on Output From Unsuccessful Call    Dynamic Variable Encoding Is Assumed to Be Correct    The Index Is Not Masked    Value for the Call Can Be Loaded From Wrong Memory Location   -Severity Findings  IDX_USE_STATE Case Not Handled Inside Tuples and Arrays    Non-terminated Indices Fail Silently    Unbalanced Tuple Starts and Ends Cause Silent Failure   0  1  4  3  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Function writeOutputs Can Corrupt Memory",
        "body": "  To store the pointer of the return data the writeOutputs function performs a write to memory at the index  state  +  32  +  (idx  &  IDX_VALUE_MASK)  *  32  .  However,  a  check  that  this  location  still belongs to the state array of pointers is not performed. This effectively permits writing to locations in memory  that  can  contain  other  variables,  including  data  of  other  state  elements.  The  command (maliciously or accidentally) can trigger such writing and cause unexpected results.    A check was introduced that verifies that idx & IDX_VALUE_MASK < state.length.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Assumptions on Output From Unsuccessful",
        "body": " Call  Unsuccessful calls are assumed to revert with no output data, with output data of the type Panic() (4 bytes  selector,  empty  payload),  or  with  output  data  of  the  type  Error(string)  (4  bytes  selector,  32 bytes pointer, 32 bytes string size, string content).  Errors can however have arbitrary signatures, which are up to the contract implementors to define.  Enso - Enso-Weiroll -   11  CriticalHighCodeCorrectedMediumCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCorrectnessHighVersion1CodeCorrectedDesignMediumVersion1CodeCorrected                 \fFor example, an error of type Error(uint256,uint256) will have its second integer interpreted as a string length in the VM error handling, potentially causing a memory expansion that will consume all the gas, if the uint256 value is big enough.    Additional checks have been introduced to interpret the return data of the error as a string only when it is appropriate to do so.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Dynamic Variable Encoding Is Assumed to Be",
        "body": " Correct  When CommandBuilder builds inputs from the state, the variable length case for bytes and strings (not array, not tuple) does not verify that the state element at the given index is correct abi encoded data. The following consequences are possible:  The case when state[idx & IDX_VALUE_MASK].length == 0 is not handled correctly. During the encode  loop,  this  is  executed  free  +=  state[idx  &  IDX_VALUE_MASK].length  at  line  113,  or offset += state[idx & IDX_VALUE_MASK].length at line 320. However if the state element is the empty bytes sequence \"\", the free or offset/pointer pointer does not change. The encoding of such  a  state  element  will  write  a  pointer  to  unallocated  free  memory.  If  any  other  dynamic  variable  is allocated  afterward  the  pointer  of  the  empty  state  element  will  point  to  the  same  location.  The  checks performed  requires state[idx & IDX_VALUE_MASK].length % 32 == 0 - this does not prevent the empty state case.  setupDynamicVariable()   in     The following fix was done to address the issue:  A  constraint  was  added  for  the  dynamic  variable  case  in  the  setupDynamicVariable  function:  in addition to state[idx & IDX_VALUE_MASK].length % 32 == 0 check, a check that this lengths does not equal 0 was added. This resolves the issue.  Enso responded:  Added check to revert if argLen == 0 (weiroll.js already encodes 0x as a full bytes32 value, so the state generated with weiroll.js will be unaffected). Also, we now check the variable\u2019s encoded size is the same as the content size.  Note:  The weiroll.js library is out of scope for this assessment, however, encoding of an empty string as full  bytes32  value  does  not  fully  comply  with  abi  encoding.  Such  behavior  was  considered  a  bug  in solidity. Some contracts with strict decoding rules might not accept empty strings encoded this way.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   The Index Is Not Masked",
        "body": "  The IDX_VALUE_MASK is not applied to index values at certain places:  1. Mask is not applied on the index in VM smart contract at line 94.  Enso - Enso-Weiroll -   12  CorrectnessMediumVersion1CodeCorrectedCorrectnessMediumVersion1CodeCorrected                \f2. Mask is not applied on the index in CommandBuilder smart contract at line 396.    The appropriate index masking has been applied.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Value for the Call Can Be Loaded From Wrong",
        "body": " Memory Location  When a call with value is performed in VM the first index is treated as an index for the state element. The read from this memory location is done via assembly instruction.  bytes memory v = state[uint8(bytes1(indices))]; assembly {     callEth := mload(add(v, 0x20)) }  This mload skips 1 word - the length of the state element. However, the state element can be empty. In this  case,  the  mload  will  read  memory  allocated  for  other  data.  Since  callEth  should  be  a  uint256 typed argument, it should be treated the same way as any other static variable.    Enso responded:  We now validate that the state element\u2019s length is 32 bytes and convert it into a uint256.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   IDX_USE_STATE Case Not Handled Inside",
        "body": " Tuples and Arrays  Indices with the value IDX_USE_STATE behave differently according to whether they belong to dynamic tuples or not. Inside dynamic tuples, the 0xfe == IDX_USE_STATE index is treated as variable length data (bytes or string). 0xfe value is masked and used as an index to 126 state bytes element. Outside of dynamic tuples, it causes the whole state to be ABI encoded at that position. This difference in behavior is not mentioned in the specification.    IDX_USE_STATE now explicitly reverts when used inside a dynamic tuple or array.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Non-terminated Indices Fail Silently",
        "body": "  Enso - Enso-Weiroll -   13  CorrectnessMediumVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \fIf FLAG_EXTENDED_COMMAND is used, and no FF index is included in the indices list, an invalid input will be produced by CommandBuilder.buildInputs() instead of reverting, causing the external contract call to have invalid data.    A new variable, indicesLength, keeps track of the number of indices that needs to be considered by commandBuilder.buildInputs()  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   Unbalanced Tuple Starts and Ends Cause",
        "body": " Silent Failure  In  CommandBuilder.buildInputs()  every  dynamic  array  or  tuple  start  should  be  matched  by  an index of value IDX_DYNAMIC_END. Failing to match opening and closing structures causes offsets not to  be  updated,  and  invalid  output  to  be  produced.  The  invalid  result  risks  being  passed  to  arbitrary external calls.  Since  functions  setupDymamicTuple  and  encodeDynamicTuple  need  to  encounter  an  index IDX_DYNAMIC_LENGTH  to  exit  correctly,  the  alternative  return  statements  at  lines  226  and  343  are superfluous and should never happen.    Function setupDynamicTuple now reverts if no terminating index is found for a dynamic tuple or array.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   DELEGATECALL and SELFDESTRUCT",
        "body": "  The VM abstract contract allows DELEGATECALL to the address specified in the command. Any contract that  will  inherit  this  functionality  must  not  perform  a  call  to  an  arbitrary  user-specified  address.  The delegate  call  to  an  address  that  has  a  bytecode  with  SELFDESTRUCT  opcode  will  cause  permanent destruction  of  the  smart  contract.  Thus,  it  is  important  to  allow  DELEGATECALL  only  to  trusted  smart contracts.    Enso responded:  We have removed delegate calls from the VM entirely as there was both risks to the contract via self destruct as well as the ability to change storage values of the importing contract, potentially bricking the contract.  Enso - Enso-Weiroll -   14  DesignLowVersion1CodeCorrectedInformationalVersion1CodeCorrected              \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Calls to Addresses With No Code",
        "body": "  The low-level delegatecall, call, and staticcall operations will succeed when used with addresses with no code,  however,  in  the  VM  there  seems  to  be  no  reason  to  use  them  on  addresses  with  no  code, excluding the precompiled contracts. Only VALUECALL has a reason for being used on an address with no code.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Floating Pragma",
        "body": "  Enso-Weiroll uses the floating pragma ^0.8.16. Several assumptions about the layout of memory are made in the code, which could potentially change without a major version upgrade. Any solidity compiler version needs to be carefully tested before the deployment of the code to ensure stable functionality.  Enso - Enso-Weiroll -   15  NoteVersion1NoteVersion1      \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Wrong Formula in Documentation",
        "body": "  0  0  2  3  the  documentation  of   In  previousEpochCumulativeYield is incorrect:  interest  bearing   the   logic   the   formula   for   the  calculation  of   the  CS-MKP-008  previousEpochCumulativeYield is calculated as follows:  newPreviousEpochCumulativeYield=oldPreviousEpochCumulativeYield*(1+yield)^ timeElapsedToEpoch  Here timeElapsedToEpoch refers to the time elapsed between the last cumulativeYield refresh and the previousEpochTimestamp.  It's not oldPreviousEpochCumulativeYield but _cumulativeYield, the value calculated at the last cumulative yield refresh. While the last refresh could be at the last epoch timestamp, this generally isn't the case.  Furthermore the in the Docs, yield is calculated as  yield = 1 + annualRate  1  31536000 \u00d7 1027  On the same page, the following is mentioned:  newCumulativeYield = oldCumulativeYield \u00d7 (1 + yield)elapsedTime  Hence, it is not totally clear for the reader if this yield and the variable _yield in the codebase is the exponential yield or 1 + exponential yield.  Specification changed:  Mimo Initiative lt - Kuma Protocol -   13  CriticalHighMediumSpeci\ufb01cationChangedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCorrectnessMediumVersion1Speci\ufb01cationChanged         \fThe  oldPreviousEpochCumulativeYield has been replaced with oldCumulativeYield.  newPreviousEpochCumulativeYield   formula   been   has   for   corrected,  the   In  newPreviousEpochCumulativeYield, (1 + yield) has been corrected to yield.  calculation   formulas   newCumulativeYield   the   for   of   and  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   getRate() Blocks the System in Case of",
        "body": " Stale Data  CS-MKP-007  In MCAGRateFeed.getRate(), if for any reasons, the queried oracle fails to return a fresh, non-stale response, this function reverts. Consequently, all functions which eventually call into getRate() will fail as well. This includes any action where the yield is refreshed, including minting, burning and transfers of the KIB tokens.  Most notably this inhibits the following functions (incomplete list):  1. KUMASwap.expireBond()  -  As  long  as  the  oracle  data  is  stale  it  will  not  be  possible  to  mark  bonds as expired.  2. KUMASwap.enableDeprecationMode() - Deprecation mode cannot be enabled.  3. KIBToken.setEpochLength() - Epoch length cannot be changed.    Mimo Initiative lt addresses the issue in KIBToken._refreshYield through a try-catch statement. Should the rate feed fail for any reason the rate used is the current minimum coupon.  This resolves the issue for all functions that query the rate through _refreshYield(). Besides them, direct queries of the rate occur in initialize() and sellBond(). Successful calls to these functions are prevented if the call to the rate feed fails.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Initialize Implementation Contract",
        "body": "  The  first  caller  can  execute  KUMASwap.initialize()  directly  on  the  implementation  contract.  The protection  intended  to  prevent  this  is  ineffective.  Note  that  this  has  no  actual  implications  since  this implementation contract is intended to be used via the Proxy.  CS-MKP-006  The constructor of KUMASwap looks as follows:  constructor() initializer {}  The  initializer()  modifier  is  called  to  set  _initialized  to  1.  It  appears  that  this  is  done  to prevent execution of the initialize function on the implementation contract which is protected by the initializer modifier.  In  this  second  iteration  of  KUMASwap  the  initialize  function  is  protected  by  another  modifier: reinitiliazer(2).  Mimo Initiative lt - Kuma Protocol -   14  DesignMediumVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \fSince during deployment _initialized is set to 1 in the storage of the implementation, the first caller can pass the modifier reinitializer(2):  modifier reinitializer(uint8 version) {     require(!_initializing && _initialized < version, \"Initializable: contract is already initialized\");     _initialized = version;     _initializing = true;     _;     _initializing = false;     emit Initialized(version); }  OpenZeppelin  offers  a  function  to  disable  initializer:  _disableInitializers()  and  recommends  to not leave an implementation contract uninitialized.  It is recommended to use this to lock implementation contracts that are designed to be called through proxies.  See: https://docs.openzeppelin.com/contracts/4.x/api/proxy#Initializable    In the constructor of every implementation contract, _disableInitializers() is invoked to lock the (re)initialize function.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Setting _lastRefresh to the Next Epoch",
        "body": " Initially  When  KIBToken  gets  initialized,  if  block.timestamp  is  not  divisible  through  epochLength, _lastRefresh is set to the next epoch.  KIBToken.mint(),  which  is  executed  when  a  bond  is  sold  to  the  protocol  would  revert  in  case  of block.timestamp < _lastRefresh.  The intention of this is unclear. Anyone can advance _lastRefresh to the current block.timestamp by calling KIBToken.refreshYield().  CS-MKP-005    Mimo Initiative lt changed KIBToken.initialize() to set _lastRefresh to block.timestamp.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Unused Event",
        "body": "  The  event  IKUMASwap.MaxCouponsSet  is  defined  but  not  used.  In  the  current  implementation, MAX_COUPONS is defined as a constant.  CS-MKP-004    This event has been removed.  Mimo Initiative lt - Kuma Protocol -   15  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Define Relevant Fields in the Events as",
        "body": " Indexed  Although some event fields are already defined as indexed, it might make sense to define further ones as indexed as well. Defining event fields as indexed makes searching for specific addresses/values easier.  CS-MKP-001  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Epochs to Avoid Dust",
        "body": "  The documentation states:  CS-MKP-002  Avoid leftover residual dust amounts when transferring all of a user's balance, since most frontend wallets do not refresh a user's balance on a per second basis.  Working  with  epochs  helps  to  reduce  this  from  happening  but  it  still  happens  when  a  user  crafts  a transaction before an epoch has ended but this transaction is only included in a block in the next epoch.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Gas Optimizations",
        "body": "  Gas consumption may be reduced in many different parts of the code. Following is a non-exhaustive list of possible gas optimizations:   Corresponding KIBToken and KUMABondToken could be stored locally in KUMASwap, rather than  fetching them through 2 external calls every time   KIBToken._getPreviousEpochTimestamp()   can   be   simplified   to   return  (block.timestamp/epochLength)*epochLength  CS-MKP-003  In  KIBToken._calculatePreviousEpochCumulativeYield()  less-comparison (<) to less-or-equal and simplifying the rest of the function  KIBToken._calculateCumulativeYield()   ,  by  changing   and the  strict   The if-else-statement on _coupons.length() in KUMASwap.sellBond() can be reordered, as during  the  execution  life-cycle  of  the  smart  contract,  the  possibility  of  having  no  coupons  in  the reserve list is low   Adding  an  existing  element  to  a  Set  does  not  fail  but  returns  a  boolean.  Therefore,  it  is  not  necessary to check whether the element is already present in the set  Mimo Initiative lt - Kuma Protocol -   16  InformationalVersion1InformationalVersion1InformationalVersion1           \fIn  KUMAFeeCollector.changePayees():  _totalShares  after  clearing  the  already  existing payees, is zero. Therefore, KUMAFeeCollector.changePayees() does not need to set the local variable totalShares to zero explicitly  The following functions are executed once or rarely, nevertheless:   Parameter  newUri  in  KBCToken.setUri()  could  be  defined  as  calldata,  similarly  name  and  symbol in KIBToken.initialize()   KIBToken.initialize() the first if-statement (check on epochLenght) can be removed, as it is  a subset of the second if-statement  Not a gas optimization but code duplication could be avoided:   Calling  _updateMinCoupon()  in  KUMASwap.buyBond()  can  be  moved  out  of  if-else  to  avoid  duplication of code  Mimo Initiative lt - Kuma Protocol -   17   \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Bond Default",
        "body": "  If  a  bond  defaults  or  is  expected  to  default,  it  may  start  to  trade  at  a  sharply  reduced  price.  The  KIB tokens  are  still  backed  by  the  bonds  which  now  have  a  much  lower  value  than  anticipated.  Hence  the valuation  of  the  KIB  tokens  will  drop  accordingly.  buyBond()  /  sellBond()  continue  to  buy/sell KUMABond NFTs for the usual exchange rate - except that the actual value of a KIB token is now much lower.  It  is  unclear  if  the  market  price  of  the  KIB  tokens  reflect  this  or  whether  there  is  an  arbitrage opportunity.  If yield accrual is not halted, KIB tokens will devaluate further.  When  redeeming  such  a  KUMABond  NFT  through  MCAG  the  underlying  bond  will  be  sold  on  the secondary market.  Bonds of the same risk category can have a different expiry dates as they could be issued at different times.  Some  bonds  of  a  risk  category  might  expire  in  1  month,  some  in  6  months.  If  the  default  of  an issuer is foreseeable or expected within prolonged timeframe, KUMASwap might end up with the bonds expiring far in the future, while all bonds that expires soon have been bought from the protocol.  In rare cases, a bond might be restructured to avoid a default. The current smart contracts do not support this.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Bridges and Rebasing Tokens",
        "body": "  The  documentation  mentions  the  KIB  https://docs.kuma.bond/kuma-protocol/kuma-protocol/defi-integrations/bridges  tokens  are   intended   to  be  bridged   to  other  chains:  While technically possible, bridging rebasing tokens is tricky to be done correctly and requires extra care. Even  with  only  dust  amounts  of  KIB  tokens  remaining  locked  at  the  bridge,  eventually  the  deprecation mode will have to be used since insufficient KIB tokens to buy back all the bonds will be available.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.3   CloneBond Token Does Not Respect Blacklist",
        "body": "  Contrary  to  the  KUMABondNFT,  the  CloneBondToken  does  not  respect  the  blacklist.  The  following interesting behavior can be observed: If a blacklisted address calls buyBond() it succeeds when a clone bond is issued but fails if the KUMABondNFT is transferred.  Mimo Initiative lt states this behavior is intended and blacklisted users won't be able to redeem with Mimo Capital.  Mimo Initiative lt - Kuma Protocol -   18  NoteVersion1NoteVersion1NoteVersion1            \f8.4   Deprecation Mode Possibility  As mentioned in the Docs:  KIBT is minted and burned such that the total supply is always sufficient to buy out all of the KUMA Bonds NFTs held in the contract. However, in extreme cases, some of the KIBT supply may become inaccessible (e.g. if large amounts of KIBT are hacked or lost to unknown addresses).  It  is  worth  mentioning  that  the  likelihood  of  requiring  Deprecation  Mode  is  likely  higher  than  what  is outlined in the documentation. To buy a bond of the protocol one party must accrue sufficient KIB tokens. This  may  prove  to  be  hard  in  practice,  even  when  ignoring  that  some  of  the  KIBT  supply  may  be inaccessible. Especially, when the liquidity of the token is low compared to the bond value to be bought, acquiring  tokens  from  pools  like  Uniswap  might  be  prohibitively  expensive  as  their  price  increases especially if large quantities are bought.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.5   KIB Price Determination & Volatility",
        "body": "  It  may  be  obvious  that  one  KIB  token  should  be  priced  at  one  unit  of  the  underlying  principal  token. However due to low liquidity, constrains around redemption of KIB tokens (accruing sufficient KIB tokens, buying the bond of the protocol, off-chain redemption) the price may fluctuate. Furthermore, low liquidity in e.g. Uniswap pools result in notable price volatility / slippage when trading as well as potential price manipulation.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.6   KUMAAddresProvider:",
        "body": " KUMAAccessController Not Immutable  The KUMAAccessController contract is the sole contract that does not implement upgradability features. In  the  KUMAAddressProvider,  the  KUMAAccessControler  is  the  only  address  that  cannot  be  updated after it has been initialized.  Note that since the KUMAAddressProvider is upgradable, the implementation may change and allow to update the address of the KUMAAccessController.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.7   Risks of Low Liquidity",
        "body": "  Low liquidity of the KIB tokens may have negative effects when using the token in DeFi systems such as Uniswap,  Balancer,  Curve  and  more.  This  includes  price  volatility/manipulation,  slippage  and  arbitrage opportunities.  Furthermore low liquidity may have negative consequences when attempting to raise sufficient liquidity to buy a bond of KUMASwap. Notably this may delay the removal of expired bonds  Mimo Initiative lt - Kuma Protocol -   19  NoteVersion1NoteVersion1NoteVersion1NoteVersion1                \f8.8   Stuck Stablecoins  Deprecation mode can be enabled if it is no longer possible to acquire sufficient KIB tokens to buy back bonds. In this mode, the KUMA_MANAGER_ROLE can buy back the bonds for the defined stablecoin. KIB token  holders  can  then  exchange  their  tokens  for  a  proportional  share  of  the  stablecoin  held  by  the contract. By design, if some KIB tokens are no longer accessible they cannot be redeemed for their share of the stablecoins, hence these stablecoins will then be locked at the KUMASwap contract.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.9   Use as Collateral",
        "body": "  The  upgradability  of  both  the  KIB  token  contracts  and  the  contracts  that  control  token  minting (KUMASwap)  and  to  a  smaller  extent  the  deprecation  mode  could  discourage  lending  protocols  from accepting the token as collateral.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.10   _couponTolerance Protection Mechanism",
        "body": "  When a bond is sold to the protocol, a check ensures that the bond's coupon is not considerably lower than the existing minCoupon rate. However, this check is only applicable to the coupon rate of the newly offered  bond.  Multiple  bond  sales  to  the  protocol,  potentially  in  quick  succession,  could  reduce  the minCoupon by a larger margin.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.11   balanceOf, totalSupply and",
        "body": " getUpdatedCumulativeYield Potentially Returning Virtual State  balanceOf and totalSupply are both view functions according to the ERC-20 standard, hence can't modify state.  To  determine  the  balance  /  totalSupply  the  last  _calculatePreviousEpochCumulativeYield() has to be evaluated. If refreshYield() has already been executed in this epoch, the value is simply read from storage and returned. Otherwise the new value is calculated and returned but not stored.  these   this  happens  after  an  execution  of internally,  Whenever  _refreshCumulativeYield()  and  _refreshYield()  hence  the  value  has  already  been  updated and is just returned from storage.  functions  are  used   External callers should be aware that when calling these functions they may get \"virtual\" balance and the contract state itself has not updated yet. The values will only be updated with the next state changing call to _refreshCumulativeYield().  Similarly, this applies to the external view function getUpdatedCumulativeYield() which is called by KUMASwap  in  buyBond()  and  sellBond()  before  a  state  changing  function  (e.g.  minting/burning) tokens are called which recalculates and this time stores the updated the value.  Mimo Initiative lt - Kuma Protocol -   20  NoteVersion1NoteVersion1NoteVersion1NoteVersion1              \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Traders Pay More Collateral Than Specified",
        "body": "  Users buying call or put options (spear or shield tokens) specify the amount of collateral they are willing to  pay  and  receive  as  many  options  as  possible.  Traders  also  pay  transaction  fees  on  top  of  option premiums. Fees are computed as follows:  CS-DPV1-005  step.feeAmount = FullMath.mulDiv(step.amountOut, fee.transactionFee, 1e6); ... state.transactionFee += step.feeAmount;  Note that step.amountOut refers to the amount of options that are bought in a trading step. However, fees are collected in the collateral asset:  cAmount = params.amountSpecified - state.amountSpecifiedRemaining     + state.transactionFee + state.protocolFee;  Tenet Technology Ltd - Divergence Protocol v1c -   13  SecurityDesignCorrectnessCriticalHighMediumAcknowledgedLowCodePartiallyCorrectedCodePartiallyCorrectedAcknowledgedCodePartiallyCorrectedAcknowledgedRiskAcceptedCodePartiallyCorrectedRiskAcceptedCorrectnessMediumVersion1Acknowledged           \fIf fees are set for a battle, cAmount will be larger than params.amountSpecified for a trade, hence the function reverts if traders do not have enough balance (cAmount) or they have not provided enough allowance to Manager.  Acknowledged:  Tenet  Technology  Ltd  is  aware  of  this  issue  but  has  decided  to  keep  the  smart  contracts  unchanged. Tenet  Technology  Ltd  will  inform  users  in  the  UI  for  the  fee  amount  that  should  be  paid  on  top  of  the premiums. However, users that interact directly with the smart contracts should be aware of this behavior and take the respective measures.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Unused Imports",
        "body": "  Several  contracts  in  the  codebase  import  libraries  or  contracts  that  remain  unused.  We  present  a non-exhaustive list below:  CS-DPV1-012  Manager.sol  import { IERC20 } from \"@oz/token/ERC20/IERC20.sol\"; import { SafeCast } from \"@oz/utils/math/SafeCast.sol\"; import { IManagerState } from \"./interfaces/IManagerState.sol\";  Arena.sol  import { IBattleActions, IBattleMintBurn } from     \"core/interfaces/battle/IBattleActions.sol\";  Battle.sol  import { IBattleBase } from \"core/interfaces/battle/IBattleActions.sol\"; import { IBattleState } from \"core/interfaces/battle/IBattleState.sol\"; import { IBattleInit } from \"core/interfaces/battle/IBattleInit.sol\"; import { IBattleMintBurn } from \"core/interfaces/battle/IBattleActions.sol\"; import { IArenaState } from \"core/interfaces/IArena.sol\"; import { DiverSqrtPriceMath } from \"core/libs/DiverSqrtPriceMath.sol\";  Code partially corrected:  Some of the unused imports have been removed, while other are still present. For example:  Manager.sol  import { IManagerState } from \"./interfaces/IManagerState.sol\";  Battle.sol  import { IBattleBase } from \"core/interfaces/battle/IBattleActions.sol\"; import { IBattleInit } from \"core/interfaces/battle/IBattleInit.sol\"; import { IBattleMintBurn } from \"core/interfaces/battle/IBattleActions.sol\";  Tenet Technology Ltd - Divergence Protocol v1c -   14  DesignLowVersion2CodePartiallyCorrected        \fimport { IArenaState } from \"core/interfaces/IArena.sol\"; import { DiverSqrtPriceMath } from \"core/libs/DiverSqrtPriceMath.sol\";  Please note that the aforementioned list is non-exhaustive and there might still exist some other unused imports in the codebase.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   LiquidityDelta Check in Position.update",
        "body": "  The  function  Position.update  performs  a  check  whether  liquidityDelta  ==  0.  Following  all callpaths suggests it can never be a case, as update() is called from Battle._updatePosition() which  is  called  from  Battle._modifyPosition().  The  latest  is  called  only  during  minting  and burning.  In  Battle.mint()  an  earlier  check  is  done  on  liquidity  being  non-zero.  Once  minted  with non-zero  liquidity,  calling  Manager.removeLiquidity()  assures  that  the  liquidity  of  this  position  is also non-zero.  CS-DPV1-001  Code partially corrected:  As mentioned above, when minting there already exists a check that the liquidity amount to be added to a position  is  non-zero,  hence  minting  on  the  battle-side  is  also  called  with  a  non-zero  liquidity.  When removing liquidity from a position, as upon adding liquidity, the liquidity is already non-zero. Hence, this check is redundant.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.4   Mismatch of Min/Max Ticks With the Edge",
        "body": " Prices  The whitepaper suggests that prices 0.01 and 0.99 are valid priced in the curve:  In implementation   ,    are bounded within [0.01, 0.99].  Library  TickMath  sets  the  minimum  tick  to  -45953  and  maximum  tick  to  45953,  which  correspond  to prices 0.0101 and 0.9899 respectively, hence prices 0.01 and 0.99 cannot be reached in the curve.  CS-DPV1-007  Acknowledged:  Tenet Technology Ltd has decided to keep the min/max ticks unchanged, and they provide the following reasoning:  The difference in prices computed from min/max ticks and the theoretical limits set in the whitepaper is so minuscule that it is deemed fit for production.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.5   Missing Sanity Checks",
        "body": "  Tenet Technology Ltd - Divergence Protocol v1c -   15  DesignLowVersion1CodePartiallyCorrectedCorrectnessLowVersion1AcknowledgedDesignLowVersion1CodePartiallyCorrected                        \fThe following functions set important state variables but do not implement any sanity check on the inputs:  CS-DPV1-009  1. _fee in Arena.setFeeForUnderlying().  2. fee in setUnderlyingWhitelist().  3. bk.strikeValue   in   createBattle(),   i.e.,   after   calling   getAdjustPrice(),  bk.strikeValue should not be rounded down to 0.  4. _oracleAddr and _battleImpl in Arena.constructor().  5. _manager in Arena.setManager().  6. _arena and _WETH9 in contract PeripheryImmutableState.  Code partially corrected:  The sanity checks reported in points 3-6 have been added.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.6   NFTs Are Never Burned in Manager",
        "body": "  The NFTs minted in Manager are not burned after an LP removes its liquidity and/or withdraws/redeems its  obligations.  Hence,  the  state  is  not  cleared  and  old  NFTs  remain  in  the  balance  of  users,  possibly degrading user experience.  CS-DPV1-010  Acknowledged:  Tenet Technology Ltd acknowledged this behavior and provided the following reasoning:  NFTs are kept in order to provide historical records to users, who may need reference for past trade.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.7   Possible to Frontrun Fee Updates in Arena",
        "body": "  The mapping fees in the contract Arena stores the fees for an underlying. On battle deployment, Arena sets battle's fees for the respective underlying. Fees in the battle cannot be changed after deployment even  if  they  are  updated  in  the  Arena.  Consider  the  scenario,  in  which  owner  of  Arena  decides  to increase fees for an underlying. In this case, users can front-run this transaction to deploy their battles with lower fees, hence making them more attractive for traders.  CS-DPV1-011  Risk accepted:  Tenet Technology Ltd is aware of this issue but has decided to keep the relevant codebase unchanged.  Tenet Technology Ltd - Divergence Protocol v1c -   16  DesignLowVersion1AcknowledgedSecurityLowVersion1RiskAccepted                  \f5.8   Unclear Specifications for the Format of Strike Price  CS-DPV1-015  should   specify  a   function Users  createAndInitializeBattle  field battleKey.strikeValue. This value is expected to be in 18 decimals, however the specifications do not clarify the format of the strike price and its quote token. Incomplete or missing specifications increase the likelihood of mistakes from users or third-party systems that interact with the system.  strike  price  when  deploying  a  new  battle.  The   struct  which   includes   takes   input   the   as   a   Code partially corrected:  In   , the following inline comment is added for function getAdjustPrice:  /// @param price price of underlying. price has decimal 18, eg. eth price 1500 will be 1500 * 10**18  However,  public  and  external  functions  such  as  createAndInitializeBattle()  that  are  called  by end users do not describe the expected format of inputs.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.9   Update of Oracle Addresses",
        "body": "  The  account  owner  in  the  contract  Oracle  can  update  the  address  of  an  oracle  for  an  underlying (symbol) via the function setExternalOracle. The address change of an external oracle effects only the  new  battles  that  are  deployed  afterwards,  while  the  ongoing  battles  do  not  reflect  the  change. Therefore,  ongoing  battles  cannot  settle  if  the  external  oracles  fail  to  publish  prices  as  expected.  The function getPriceByExternal that gets called by battles do not check that cOracleAddr is still the correct oracle for the respective symbol.  CS-DPV1-016  Rick accepted:  Tenet Technology Ltd is aware of this behavior and has decided to keep the code unchanged, providing the following motivation:  The update of oracle addresses during on-going battles is disabled as it is considered an attack vector, in which a malicious actor may update the oracle address to affect settlement results. In case of external oracles fail to publish prices as expected, the owner will be given the ability to address the issue an hour post expiry, only after all prior processes fail to settle a pool.  In   of the codebase, the severity of the issue presented above is limited as the oracle defaults to prices reported by owner in case the external oracle does not work as expected. However, this requires additional trust for owner to behave correctly.  Tenet Technology Ltd - Divergence Protocol v1c -   17  CorrectnessLowVersion1CodePartiallyCorrectedVersion2DesignLowVersion1RiskAcceptedVersion2                \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings  Incorrect Iteration of Rounds From Chainlink Oracle    Missing Sanity Checks on Price From Oracle    Missing Slippage Protection When Providing Liquidity   -Severity Findings   Events Missing in Arena    Hardcoded Balances for Spear and Shield in getAllBattles   Intended Oracle Address for a Battle   Intended Use of Owed Values in Battle    Missing Natspec    Rounding Errors    Special Behavior of getAdjustPrice    Special Case in Function Pay    Storage Variable deploymentParameters in Arena    Unused Functions in PeripheryPayments    _safeMint Not Used in Manager   Informational Findings  Indistinguishable Spear and Shield Tokens    Redundant Import of Library    Commented Code and Remaining ToDos    Possible Event Reentrancy in addLiquidity    Unused Error NotNeedChange    NFT Approvals Not Considered in Manager   0  0  3  11  6  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Incorrect Iteration of Rounds From Chainlink",
        "body": " Oracle  CS-DPV1-002  Tenet Technology Ltd - Divergence Protocol v1c -   18  CriticalHighMediumCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCorrectnessMediumVersion1CodeCorrected            \fThe internal function Oracle._getPrice iterates backward through the rounds reported by a Chainlink oracle as follows:  for (uint80 i = id; i > 0; i--) {     (, int256 answer, uint256 startedAt,,) = cOracle.getRoundData(i);     ... }  As described in the docs of oracles, there is no guarantee that round IDs are monotonically increasing. More  specifically,  when  the  aggregator  updates  the  implementation,  a  gap  in  the  between  two consequent  roundIDs  is  created.  If  such  an  update  happens  between  a  battle's  expiry  and  its settlement, the function _getPrice reverts as it queries prices for invalid roundID. Therefore, the battle cannot settle and neither liquidity providers, nor traders can claim their collateral tokens.    , the first round in the current phase is fetched and the code iterates backward from the latest In  ID to the starting ID in the current phase. Hence, all the round IDs are valid. Note, if there is an update of phase ID after the expiry of a battle, oracle returns the manually set prices by its owner.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Missing Sanity Checks on Price From Oracle",
        "body": "  The internal function Oracle._getPrice does not enforce a restriction on the maximum delay between the battle expiration and the first price reported by the Chainlink oracle after expiration:  CS-DPV1-003  for (uint80 i = id; i > 0; i--) {     (, int256 answer, uint256 startedAt,,) = cOracle.getRoundData(i);     if (startedAt < ts) {         break;     }     if (startedAt >= ts) {         p = decimalDiff * answer.toUint256();         actualTs = startedAt;     } } require(p != 0, \"price not exist\");  It might happen that the Chainlink publishes a price shortly before the expiration and the next overwritten with a significant delay which possibly deviates from the correct price at expiration, however it still gets used as the settlement price by the battle.  Specification changed:   and the specifications of the function _getPrice The contract Oracle has been refactored in  have  changed.  The  new  specifications  consider  prices  from  the  external  oracles  (i.e.,  Chainlink)  to  be valid  if  they  are  published  in  the  first  hour  after  the  expiration  of  a  battle,  otherwise  fallback  prices provided by the owner of the contract Oracle are used.  Tenet Technology Ltd - Divergence Protocol v1c -   19  Version2DesignMediumVersion1Speci\ufb01cationChangedVersion2          \f6.3   Missing Slippage Protection When Providing Liquidity  The function Manager.addLiquidity does not implement any slippage protection mechanism, hence leaving LPs susceptible to front-running attacks. In a scenario where an LP intends to provide liquidity into a slot that covers the current price, the transaction can be front-run to move the current price outside the slot such that less liquidity is minted for the victim transaction.  Similarly, a victim LP that deploys a new battle with a target initial price and adds liquidity to it can be attacked  by  front-runners  to  deploy  the  same  battle  (same  battle  key)  but  with  a  malicious  initial  price such that the honest LP receives less liquidity.  CS-DPV1-004    In  LiquidityManagement._addLiquidity():  protection   slippage   a   ,   in   the   following   form   has   been   added   to  if (sqrtPriceX96 < params.minSqrtPriceX96 || sqrtPriceX96 > params.maxSqrtPriceX96) {     revert Errors.Slippage(); }  Hence,  if  due  to  the  front-running,  the  current  price  on  the  battle-side  has  changed  unexpectedly,  the transaction reverts.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Events Missing in Arena",
        "body": "  The  function  setFeeForUnderlying  modifies  the  state,  however  the  respective  event  FeeChanged declared  in  the  interface  IArena  is  not  emitted.  Similarly,  the  function  setManager  updates  an important state variable but does not emit an event.  CS-DPV1-006    In Arena for evey state changing function, a relevant event gets emitted.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Hardcoded Balances for Spear and Shield in",
        "body": " getAllBattles  The  function  getAllBattles  queries  the  state  of  all  battles,  except  for  spearBalance  and shieldBalance which are set to 0:  CS-DPV1-036  Tenet Technology Ltd - Divergence Protocol v1c -   20  SecurityMediumVersion1CodeCorrectedVersion2DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                      \finfos[i] = BattleInfo({     ...     spearBalance: 0,     shieldBalance: 0,     ... });  However,  as  the  balance  of  spear  and  shield  in  a  battle  is  not  defined,  holding  these  values  is meaningless.    Tenet Technology Ltd has removed these fields from the struct BattleInfo.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Intended Oracle Address for a Battle",
        "body": "  The  struct  CreateAndInitBattleParams  includes  a  field  named  oracle,  however  the  function createBattle  uses  the  address  in  the  state  variable  oracleAddr  when  setting  the  deployment parameters for a new battle.  CS-DPV1-033    Tenet Technology Ltd has removed the oracle field from the struct CreateAndInitBattleParams.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Intended Use of Owed Values in Battle",
        "body": "  Struct PositionInfo has the field insideLast that accounts for the growth inside a position per unit of  liquidity,  and  another  field  owed  which  accounts  the  growth  inside  the  position.  However,  the  field owed  is  not  read  by  the  contracts  in  scope  and  appears  to  be  redundant  as  all  positions  in  battle contracts are held by the manager.  CS-DPV1-034    The unused field owed has been removed from the updated codebase.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   Missing Natspec",
        "body": "  A  large  number  of  functions  are  missing  proper  documentation  and  description.  Natspec  helps  to understand more quickly the intention of functions which improves code readability. Natspec of external  CS-DPV1-008  Tenet Technology Ltd - Divergence Protocol v1c -   21  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \ffunctions also helps third-parties that integrate with the system, e.g., by providing information regarding the format of input values.    The inline comments and specifications have been extended in the   .  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   Rounding Errors",
        "body": "  In Battle._modifyPosition(), in case of adding collateral liquidity to a position covering the current tick, spear and shield collaterals (csp and csh) are rounded down. When called from Battle.mint(), seed  =  csp  +  csh  is  used  as  the  amount  of  collateral  an  LP  has  to  pay.  Hence,  LP  pays  less collateral than expected.  CS-DPV1-013  Specification changed:  The function _modifyPosition has been refactored in  rounding errors has been removed.   and the computation that was prone to  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   Special Behavior of getAdjustPrice",
        "body": "  The function getAdjustPrice behaves differently depending on the value of the input price: i) values smaller than 10**11 are rounded down to 0; ii) values smaller than 10**12 are rounded down to one significant digit; ii) other values are rounded down to two significant digits.  The implementation of getAdjustPrice() does not match the formula in the Natspec of the function.  CS-DPV1-014    Tenet Technology Ltd has revised the function to require that input price is larger than 10**12, so for any allowed price, getAdjustPrice() returns the price with 2 decimals.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.11   Special Case in Function Pay",
        "body": "  The internal function pay in PeripheryPayments considers a case when payer == address(this).  else if (payer == address(this)) {     // pay with tokens already in the contract (for the exact input multihop case)     TransferHelper.safeTransfer(tokenAddr, recipient, value); } else {     // pull payment  CS-DPV1-035  Tenet Technology Ltd - Divergence Protocol v1c -   22  Version3CorrectnessLowVersion1Speci\ufb01cationChangedVersion2CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \f    TransferHelper.safeTransferFrom(tokenAddr, payer, recipient, value); }  This case is redundant.    Tenet Technology Ltd has correctly removed this redundant case.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.12   Storage Variable deploymentParameters in",
        "body": " Arena  The  contract  Arena  defines  a  storage  variable  named  deploymentParameters.  It  is  set  during createBattle()  and  practically  stores  the  deployment  information  about  the  last  instance  of  battle being deployed. This increases gas costs on both deployment and runtime.  CS-DPV1-032    The  state  variable  deploymentParameters  has  been  removed  from  the  updated  codebase  in  .  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.13   Unused Functions in PeripheryPayments",
        "body": "  The abstract contract PeripheryPayments that is inherited by Manager implements several functions that are declared as payable, do not implement any access control, and transfer any token balance held by Manager to arbitrary addresses:  CS-DPV1-031   unwrapWETH9()   sweepToken()   refundETH    The functions listed above have been removed from the updated codebase.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.14   _safeMint Not Used in Manager",
        "body": "  CS-DPV1-017  Tenet Technology Ltd - Divergence Protocol v1c -   23  DesignLowVersion1CodeCorrectedVersion2DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \fThe  function  Manager.addLiquidity  mints  new  NFTs  by  calling  the  internal  function  _mint  which does not perform any check on the recipient address. Therefore, if recipient is a smart contract that cannot handle NFTs, the newly minted NFT would be locked.  If  recipient  is  a  smart  contract,  then  the  function  _safeMint  checks  whether  it  implements  the interface IERC721Receiver. Note that _safeMint performs a call to untrusted address recipient.    In  recipient of the NFT is a smart contract that does not implement the interface IERC721Receiver.  ,  function  _safeMint  is  used  when  creating  a  new  NFT.  _safeMint()  reverts  if  the  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.15   Possible Event Reentrancy in addLiquidity",
        "body": "  The function addLiquidity calls ERC721._safeMint which triggers the onERC721Received hook on  the  recipient,  effectively  giving  control  to  an  untrusted  contract.  At  this  point,  the  external  contract could reenter the contract and call addLiquidity() again which mints a new NFT token. In this case, events  LiquidityAdded  would  not  be  ordered  sequentially,  therefore  potentially  complicating  the monitoring and reconstruction of contract state based on the events info.  CS-DPV1-030    The minting of the NFT has been moved into the end of the function addLiquidity.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.16   Commented Code and Remaining ToDos",
        "body": "  Commented  out  code  is  present  in  the  function  Battle.trade  and  in  the  contract  Manager.  Also,  a todo note is remaining in the Natspec of the function getSTokenDelta. Removing commented code and addressing remaining note could help improve the readability.  CS-DPV1-018    The commented code and remaining ToDos have been removed from the updated codebase.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.17   Indistinguishable Spear and Shield Tokens",
        "body": "  Arena  deploys  a  set  of  ERC20  tokens  named  spear  and  shield  for  each  battle  created.  These  ERC20 tokens  have  the  same  name  (Spear/Shield)  and  symbol  (SPEAR/SHIELD)  for  all  battles,  hence possibly confusing for users to distinguish them.  CS-DPV1-022  Tenet Technology Ltd - Divergence Protocol v1c -   24  Version2InformationalVersion2CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected                  \f  The  function  Arena.createBattle  has  been  revised  to  deploy  STokens  with  distinguishable  name and symbol by appending the battle number after their name and symbol (Spear-X/Shield-X):  string memory indexString = Strings.toString(battleList.length); address spear = address(new SToken(string.concat(\"Spear\", indexString),      string.concat(\"SPEAR\", indexString), decimals, battle)); address shield = address(new SToken(string.concat(\"Shield\", indexString),      string.concat(\"SHIELD\", indexString), decimals, battle));  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.18   NFT Approvals Not Considered in Manager",
        "body": "  The ownership of LP positions in Manager is tracked with NFTs. The contract ERC721 allows holders of NFTs  to  provide  approvals  for  a  specific  NFT  or  all  NFTs  to  other  trusted  accounts.  However,  this functionality is not considered in Manager as only the owner of an NFT can call functions that modify the position of an NFT.  CS-DPV1-025    Functions  removeLiquidity(),  withdrawObligation()  and  redeemObligation  now  use  the following modifier to restrict the access:  modifier isAuthorizedForToken(uint256 tokenId) {     require(_isApprovedOrOwner(msg.sender, tokenId), \"Not approved\");     _; }  Hence, a user holding approvals of NFT, can withdraw the liquidity on behalf of the owner. The recipient of collateral is the onwer of the NFT.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.19   Redundant Import of Library",
        "body": "  Library FixedPoint128 is imported twice in the contract Manager.    The redundant import of this library is removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.20   Unused Error NotNeedChange",
        "body": "  CS-DPV1-027  CS-DPV1-029  Tenet Technology Ltd - Divergence Protocol v1c -   25  InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected                  \fLibrary Errors declares the error NotNeedChange which is unused in the codebase.    This error has been removed.  Tenet Technology Ltd - Divergence Protocol v1c -   26  \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Compiler Version",
        "body": "  following  The  https://github.com/ethereum/solidity/blob/develop/docs/bugs_by_version.json#L1834  compiler   (0.8.19)   version   used   has   the   CS-DPV1-019  known   bugs:  This is just a note as we do not see any issue applicable to the current code.  The contracts should be deployed using a compiler version they have been thoroughly tested with. Using a very recent version may not be recommend as it may not be considered battle-proof yet. At the time of writing the most recent version is 0.8.21.  For more information please refer to the release notes: https://github.com/ethereum/solidity/releases  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Dependency Versions",
        "body": "  The smart contract libraries used by the project are:  openzeppelin chainlink uniswap/v3-core uniswap/v3-periphery  CS-DPV1-020  These libraries are either not up-to-date (openzeppelin and chainlink), or do not refer to a tagged commit (v3-core and v3-periphery) in the third-party repository.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Gas Optimizations",
        "body": "  CS-DPV1-021  The codebase could be more efficient in terms of gas usage. Reducing the gas costs may improve user experience. Below is an incomplete list of potential gas inefficiencies:  1. The mapping Oracle.externalOracleOf is declared public, however a public getter function  getCOracle is redundantly implemented.  2. Function  Oracle.getPriceByExternal  could  exit  early  if  latestRoundData()  returns  a  price before the option's expiry.  3. Function  Arena.setPermissionless  performs  redundant  SLOADs  when  accessing  the  state variable  isPermissionless.  Instead  of  toggling  the  state  variable  isPermissionless  it  can take the intended value as input parameter.  Tenet Technology Ltd - Divergence Protocol v1c -   27  InformationalVersion1InformationalVersion1InformationalVersion1CodePartiallyCorrected            \f4. Function Arena.createBattle performs redundant SLOADs when accessing the state variable  managerAddr.  5. Functions  initState  and  init  in  the  Battle  could  be  merged  to  avoid  one  external  call  from  Manager contract to the Battle during deployment.  6. Function addLiquidity creates a new memory variable p1 with the field recipient overwritten,  however it's not used.  7. The external call spearAndShield() in function _addLiquidity can be avoided if collateral is  being deposited.  8. Function  Battle.mint  performs  external  calls  to  verify  that  the  intended  amount  of  tokens  has been  transferred  to  battle,  however,  as  the  function  can  be  called  only  by  manager, mintCallback ensures that the funds are transferred.  9. Contract  Arena  could  deploy  the  pair  of  SToken  contracts  as  proxies  to  reduce  the  gas  costs  of  battle deployment. However, note that this approach would increase gas costs on execution.  10. The code assigning the value of pmMemory.liquidityType to bp.liquidityType in function  removeLiquidity could be simplified.  11. The  modifier  lock  in  contract  Battle  could  be  more  gas  efficient  if  non-zero  values  are  used  to  record the state.  12. The calculation of state.protocolFee could be moved outside the while-loop.  13. The  check  params.amountRemaining  <  0  in  function  computeTradeStep  is  redundant  as  amountRemaining is of type uint256, hence cannot be negative.  14. Function  computeTradeStep  calculates  first  the  capacity  (cap),  then  in  the  else  branch computes again the same value for amountIn (except rounding). The computation of amountIn could be avoided if cap was rounded up.  15. Function  Manager.tradeCallback   implements   a   redundant   logic  with   function  verifyCallback.  16. Battle.maxLiquidityPerTick is set to Tick.tickSpacingToMaxLiquidityPerTick(1)  which has a predefined value. Hence, it can be changed to constant.  17. Battle._modifyPosition() calculates the seed using the same formula for Spear and Shield  liquidity. Hence, those two can be merge to a single else-statement.  18. TradeMath.computeTradeStep()  calculates  amountIn  and  amountOut  in  the  same  way, whether params.amountRemaining < cap or not. Therefore, those lines calculating amountIn and amountOut can be moved out of if-else-statement.  19. Input arguments of Oracle.setExternalOracle() can be defined as calldata.  20. sAmount input argument in Manager.tradeCallback() is not used and could be commented  out.  21. data input argument in Quoter.tradeCallback() is not used and could be commented out.  22. DiverSqrtPriceMath.getSTokenDelta(),  in  the  current  status  of  the  codebase,  is  always  called with non-negative liquidity. Hence, checking for negative liquidity is unnecessary.  :  23. The field DeploymentParams.arenaAddr is not used.  24. Function Battle.init() performs two checks to ensure that the battle has not been initialized  before.  25. Function  Battle.init()  performs  an  external  call  to  retrieve  decimals  of  the  collateral  token  which could be passed as function argument from Arena.  26. Function Battle.mint() declares a storage pointer positionInfo which remains unused.  Tenet Technology Ltd - Divergence Protocol v1c -   28  Version2\f27. Arena.createBattle() checks if params.bk.strikeValue == 0. This cannot happen, as params.bk.strikeValue is the return value of getAdjustPrice() which never returns 0.  28. Oracle.getPriceByExternal() can be defined as external.  29. Position.update()  needs  to  calculate  liquidityNext  if  liquidityDelta  !=  0.  Hence,  this calculation can be moved inside the if-statement.  30. Position.tokenId is a redundant field, as on the manager-side, the respective position is stored  in a mapping with the tokenId as key.  31. BattleInitializer.createAndInitializeBattle()  does  not  need  to  check  if  the  the  battle is already deployed in the Arena, as the same check is done in the Arena.  Code partially corrected:  The codebase has been updated to implement several gas savings reported above. However, points 3, 8, 11, 16, 19-27, 29 and 31 are still present.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   Magic Values in Codebase",
        "body": "  Several  magic  values  are  used  in  the  codebase  that  could  be  declared  as  constant.  For  instance,  the function  Arena.createBattle  uses  values  28_800  and  86_400  that  could  be  replaced  with constants. Similarly, the contract Battle uses the value 1 for tick spacing which can be replaced with a constant variable to improve code readability.  CS-DPV1-023  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   Missing Functions in Interfaces",
        "body": "  The interface IBattleState does not include the getter function for the state variable fee. Similarly, the interface IQuoter does not include the function quoteExactInput among others.  CS-DPV1-024  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.6   Possible Packing of State Variables",
        "body": "  Several struct data types in the codebase could be optimized to use less storage by reordering or using smaller types. For instance, the field expiries stores timestamps which can be saved in less than 256 bits, hence its type can be changed so that both collateral and expiries fit into a single storage slot. Similarly, the struct Fee could be optimized by changing variable types given that values stored do not exceed 10**6, while struct Position could be optimized by reordering its fields.  CS-DPV1-026  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.7   Relaxed Condition on Collateral",
        "body": "  Tenet Technology Ltd - Divergence Protocol v1c -   29  CS-DPV1-037  InformationalVersion1InformationalVersion1InformationalVersion1InformationalVersion1                \fManager.getObligation() calculates the return value collateral in the following way:  collateral = pm.owed.collateralIn + pm.seed == obligation ?     0 : pm.owed.collateralIn + pm.seed - obligation - 1;  for  liquidity  type  of  collateral.  Relaxing  the  condition  by  changing  ==  to  <=  could  prevent  some  corner cases in which due to rounding errors, pm.owed.collateralIn + pm.seed is slightly rounded down. The same argument holds for other liquidity types.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.8   Rounding Errors on Computing sTokens",
        "body": "  The function getSTokenDelta in library DiverSqrtPriceMath takes as last input the flag roundUp. The function rounds up all intermediary values when the flag roundUp is set to true. Therefore, it is possible that the function returns an amount with a higher difference than 1 compared to the amount returned by the same function when called with roundUp set to false.  CS-DPV1-028  Tenet Technology Ltd - Divergence Protocol v1c -   30  InformationalVersion1    \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Battles Should Be Settled After Expiration",
        "body": "  The  contract  Battle  implements  a  public  function  settle  that  can  be  called  by  anyone  to  decide  the winning token (spear/shield). However, there is no additional incentive to call this function, hence can be called with a delay.  Function settle triggers a call to Oracle._getPrice() which implements a for-loop that iterates through  historical  prices  reported  by  the  oracle  until  the  correct  one  (closest  to  and  after  the  battle's expiration) is found. The loop could run out-of-gas if settle() is called with a considerable delay and enough prices have been published by the oracle. In this case, for-loop will run out of gas to reach the desired price and will consequently fail.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Battles With Malicious Starting Prices",
        "body": "  The deployer of a battle can freely choose the initial price startSqrtPriceX96 as long as it falls in the range of allowed prices. Therefore, it is possible that for an attacker to initialize battles with a malicious price  (which  does  not  reflect  the  fair  price  of  options  at  the  time  of  deployment)  to  degrade  user experience  or  cause  denial-of-service  (DoS).  The  attacker  has  to  pay  for  the  gas  costs  to  deploy  new battles, while the process and cost to recover the battle (set a fair price) depends on the behavior of the attacker.  A  battle  initialized  with  a  malicious  starting  price  could  recover  more  easily  if  the  attacker  did  not  add liquidity into it. In this scenario, an honest LP should add collateral as liquidity around the fair price and then a trade should happen. However, the trade is limited on buying the option that was priced higher by the attacker on deployment which might be inconvenient for traders.  If an attacker initializes a battle with a malicious price and adds liquidity into it, the process of recovering becomes more costly. In this scenario, the attacker sets the starting price to one edge of the curve (e.g., around minimum tick where spear is very expensive), then adds collateral as liquidity into a range above the current tick where spear is still priced higher than the fair price. The only way for the battle to recover is  for  traders  to  consume  all  liquidity  provided  by  the  attacker  which  means  buying  options  for  a  price higher than the fair one. Hence, such battles could remain unused, which degrades the user experience.  An attacker can even cause temporary DoS for a pair of collateral and underlying assets. As described in Limited Entropy for Battle Keys, an attacker could deploy all possible battles for a target expiration date (e.g., end of month), and a price change range (\u00b110%) to render such battles useless.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.3   Fallback Prices in Oracle",
        "body": "  Oracle.getPriceByExternal()  gets  called  when  the  battle  is  to  be  settled  after  the  expiry.  Tenet Technology Ltd has informed us that they have an off-chain agreement with Chainlink to publish prices between 8 A.M. and 9 A.M. UTC (1 hour interval) for all collateral tokens used in battles. If for any reason  Tenet Technology Ltd - Divergence Protocol v1c -   31  NoteVersion1NoteVersion1NoteVersion2          \fChainlink  fails  to  publish  valid  prices  during  this  interval,  Oracle  contract  defaults  to  the  fixPrices which are manually set by the owner.  Furthermore, getPriceByExternal() queries Chainlink prices sequencially to find out the first price published after a battle expires. However, if it happens that the aggreggator implementation of the oracle is  updated  during  this  time,  getPriceByExternal()  fails  to  query  older  prices  (due  to  phaseId change). In this scenario also, the contract Oracle defaults to the fixPrices set by the owner.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.4   Function quoteExactInput Is Gas Inefficient",
        "body": "  The function Quoter.quoteExactInput is a helper function that allows traders to estimate how much collateral they should pay and how many option tokens they receive for a set of trading parameters. The function is implemented in such a way that it calls the actual Battle.trade function to find out spend (collateral) and get (options) amounts. This means that quoteExactInput() triggers all state changes that  a  normal  trade  would  do,  but  reverts  in  the  end.  Therefore,  the  gas  costs  of  calling  this  function on-chain are comparable with gas costs of Battle.trade.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.5   Limited Entropy for Battle Keys",
        "body": "  The battle key in Arena is computed as follows:  bytes32 battleKeyB32 = keccak256(abi.encode(bk.collateral, bk.underlying, bk.expiries, bk.strikeValue));  The entropy for battle keys comes from expiries and strikeValue for a given pair of collateral and underlying. However, both expiries and strikeValue can be values from discrete sets, and it is feasible for one to deploy all possible battles for a target expiry (e.g., end of month) and a price range (e.g., \u00b110%).  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.6   String Type Used as Key in Mappings",
        "body": "  The mappings externalOracleOf in Oracle, and fees and underlyingWhitelist in Arena use keys  of  type  string.  We  highlight  the  possibility  to  have  different  Unicode  characters  that  render similarly or using invisible Unicode characters, which could be misused by attackers to trick users.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.7   Users Should Validate Collateral Tokens",
        "body": "  If  Arena.isPermissionless  is  set,  users  can  deploy  battles  with  arbitrary  tokens  as  collateral. However, the smart contracts in scope of this review work as expected only with standard ERC20 tokens that  do  not  implement  special  features  such  as  transfer  hooks,  rebasing,  or  transfer  fees.  See  Section Roles and Trust Model for more details.  Tenet Technology Ltd - Divergence Protocol v1c -   32  NoteVersion1NoteVersion1NoteVersion1NoteVersion2                \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Decimals Mismatch in CappedOracle",
        "body": "  The  function  CappedOracle.decimals  returns  8  regardless  of  the  decimals  of  the  source,  that  is expected to be a Chainlink price oracle. This creates a decimals mismatch when the source is an ETH for  stETH/ETH  has  18  decimals pair.  For  example,  (https://etherscan.io/address/0x86392dc19c0b719886221c78ab11eb8cf5c52812#readContract#F3).  If the  price  of  an  ETH  pair  is  computed  with  the  decimals  of  the  CappedOracle,  the  price  will  be  either heavily  over-evaluated  if  maxPrice  has  18  decimals,  or  always  capped  to  maxPrice  if  it  has  8 decimals.  the  Chainlink  price  oracle   CS-SPRKADV-002    The oracle is designed to work with source oracles that have 8 decimals. An additional check has been added  to  the  constructor  to  enforce  this  8-decimal  precision  in  the  source  oracle,  preventing  possible misconfiguration and resulting decimal mismatch.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Gas Optimizations",
        "body": "  1. The  vars.totalDebt  =  params.totalStableDebt  +  params.totalVariableDebt;  computation can ignore the total stable debt, as it should always be 0.  CS-SPRKADV-001    totalDebt has been removed and instead params.totalVariableDebt is now used directly.  MakerDAO - SparkLend Advanced -   11  CriticalHighCodeCorrectedMediumLowCorrectnessHighVersion1CodeCorrectedInformationalVersion1CodeCorrected              \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   ETH Oracle Is Used for LST Pricing",
        "body": "  Users should be aware that the oracles for rETH and wstETH will not handle depeg scenarios by design.  More  specifically,  the  wstETH  oracle  and  the  rETH  oracle  both  use  the  ETH/USD  price  feed  for estimating  the  value  of  the  tokens.  However,  the  LSTs  could  depeg  so  that  the  market  may  offer  the LSTs at a discount (e.g. due to long waiting times for withdrawals).  Consequently, pricing the LSTs with a ETH/USD oracle may introduce a systematic risk. For example, some users may not be liquidated which could lead to protocol losses.  While  severe  depegs  are  rather  unlikely,  they  may  happen  under  extreme  conditions.  Ultimately,  the ETH/USD oracle could lead to inaccuracies.  MakerDAO - SparkLend Advanced -   12  NoteVersion1  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   weETH Oracle Manipulation",
        "body": "  The weETH oracle can be manipulated upwards by burning eETH. Ultimately, such manipulations may lead to draining the protocol.  Consider that EtherFi will compute the weETH/eETH rate as  CS-SPRKADV-001  function amountForShare(uint256 _share) public view returns (uint256) {     uint256 totalShares = eETH.totalShares();     if (totalShares == 0) {         return 0;     }     return (_share * getTotalPooledEther()) / totalShares; }  where  _share  is  10**18.  Note  that  totalShares()  can  be  reduced  by  arbitrary  users  by  burning eETH:  function burnShares(address _user, uint256 _share) external {     require(msg.sender == address(liquidityPool) || msg.sender == _user, \"Incorrect Caller\");     ...     totalShares -= _share;     ...  Consequently, the rate can be increased by decreasing the total shares.  Consider now a scenario where a user borrows 1M USD worth in weETH with 1.5M USD worth in ETH collateral. If the borrower managed to increase the rate by a factor of 2, his position would immediately become unhealthy. Ultimately, that would generate bad debt for Spark.  Note that such an attack requires a donation to EtherFi and could be made more profitable by leveraging high-value positions, especially those that are highly leveraged.  MakerDAO - SparkLend Advanced -   11  SecurityCorrectnessCriticalHighRiskAcceptedMediumLowSecurityHighVersion1RiskAccepted          \fRisk Accepted:  Spark  acknowledged  the  issue  but  deems  it  no  practical  risk  given  the  LTV  parameters  for  weETH Collateral on Sparklend Mainnet and borrowing being disabled. The oracle may be replaced in the future if deemed necessary for higher LTV configurations.  The intended configuration on Github.  MakerDAO - SparkLend Advanced -   12    \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings   Decimals Mismatch in CappedOracle   -Severity Findings  -Severity Findings  0  1  0  0  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Decimals Mismatch in CappedOracle",
        "body": "  The  function  CappedOracle.decimals  returns  8  regardless  of  the  decimals  of  the  source,  that  is expected to be a Chainlink price oracle. This creates a decimals mismatch when the source is an ETH for  stETH/ETH  has  18  decimals pair.  For  example,  (https://etherscan.io/address/0x86392dc19c0b719886221c78ab11eb8cf5c52812#readContract#F3).  If the  price  of  an  ETH  pair  is  computed  with  the  decimals  of  the  CappedOracle,  the  price  will  be  either heavily  over-evaluated  if  maxPrice  has  18  decimals,  or  always  capped  to  maxPrice  if  it  has  8 decimals.  the  Chainlink  price  oracle   CS-SPRKADV-004    The oracle is designed to work with source oracles that have 8 decimals. An additional check has been added  to  the  constructor  to  enforce  this  8-decimal  precision  in  the  source  oracle,  preventing  possible misconfiguration and resulting decimal mismatch.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Gas Optimizations",
        "body": "  1. The  vars.totalDebt  =  params.totalStableDebt  +  params.totalVariableDebt;  computation can ignore the total stable debt, as it should always be 0.  CS-SPRKADV-003    totalDebt has been removed and instead params.totalVariableDebt is now used directly.  MakerDAO - SparkLend Advanced -   13  CriticalHighCodeCorrectedMediumLowCorrectnessHighVersion5CodeCorrectedInformationalVersion1CodeCorrected              \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Inconsistent setSource() Event Emission",
        "body": "  setSource()  emits  the  SourceChanged  event  before  performing  the  state  change  which  is inconsistent  with  the  constructor's  behavior  where  the  state  change  occurs  first.  Additionally, setSource()  emits  the  event  even  when  setting  the  source  to  its  current  address,  which  can  be confusing due to the event's name SourceChanged.  CS-SPRKADV-002  MakerDAO - SparkLend Advanced -   14  InformationalVersion5  \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   ETH Oracle Is Used for LST Pricing",
        "body": "  Users should be aware that the oracles for LSTs (e.g. rETH and wstETH) and LRTs (e.g. weETH) will not handle depeg scenarios by design.  More  specifically,  the  oracles  use  the  ETH/USD  price  feed  for  estimating  the  value  of  the  tokens. However, the LSTs could depeg so that the market may offer the LSTs/LRTs at a discount (e.g. due to long waiting times for withdrawals).  Consequently, pricing the LSTs and LRTs with a ETH/USD oracle may introduce a systematic risk. For example, some users may not be liquidated which could lead to protocol losses.  While  severe  depegs  are  rather  unlikely,  they  may  happen  under  extreme  conditions.  Ultimately,  the ETH/USD oracle could lead to inaccuracies.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Morpho Upgradeable Oracle",
        "body": "  MorphoUpgradeableOracle  follows  the  assumptions  made  on  Chainlink  oracles  in  Morpho  (e.g.  no staleness).  Essentially,  no  checks  on  the  data  provided  by  Chainlink  are  made  which  may  introduce some  risk  to  the  managed  markets.  Governance  is  expected  to  be  able  to  react  quickly  on  Morpho markets.  Further,  the  only  meaningful  data  returned  by  latestRoundData  is  the  answer.  All  other  values  are not meaningful (zero values).  MakerDAO - SparkLend Advanced -   15  NoteVersion1NoteVersion5      \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Missing Checks",
        "body": "  0  0  0  1  1  AllocatorInit.initIlk() does not check whether the uniV3Factory address is correctly set in the DepositorUniV3 contract. While the deployer can not use a different, random contract instead of the correct Uniswap factory contract, they can still deploy another factory with the same bytecode. This way, _getPool() can still correctly determine pool addresses. The deployer is now able to set themself as the owner of the factory which in turn allows them to set and collect the protocol fee.  Also, AllocatorInit.initIlk() does not check whether nstJoin in AllocatorVault has been set correctly. This is documented to be added later-on but currently not implemented.  CS-ALD-001    The correct uniV3Factory address in DepositorUniV3 is now checked in the initialization script.  Note that a check for nstJoin in AllocatorVault is still to be added when NstJoin has been added to the chainlog.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Dynamic Debt Ceiling Missing",
        "body": "  The specification for the Allocator system states that:  The  Allocator  Vaults  have  dynamic  Debt  Ceiling  modification  modules  (IAMs)  that  are  set  to  a medium \u201cttl\u201d and medium \u201cgap\u201d value resulting in a throttling effect on the amount of NewStable that can be generated at once. The IAM acts as a circuit breaker in case of technical problems with the AllocatorDAOs Deployment Layer, limiting the potential for damage.  AllocatorInit, however, only sets a static debt ceiling and never deploys the required modules.  CS-ALD-002  MakerDAO - Allocator -   11  CriticalHighMediumLowCodeCorrectedCodeCorrectedCorrectnessLowVersion1CodeCorrectedInformationalVersion1CodeCorrected              \f  The debt ceiling is now set to a gap value in the vat. Additionally, the DssAutoLine contract is setup for the new ilk by calling the setIlk() function with the given gap along with a ttl and a maximum debt  ceiling.  Calling  DssAutoLine.exec()  increases  the  line  of  the  ilk  by  gap  in  steps  of  ttl seconds.  MakerDAO - Allocator -   12  \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Deployment Verification",
        "body": "  Since deployment of the contracts is not performed by the governance directly, special care has to be taken  that  all  contracts  have  been  deployed  correctly.  While  some  variables  can  be  checked  upon initialization through the PauseProxy, some things have to be checked beforehand.  We therefore assume that all mappings in the deployed contracts are checked for any unwanted entries (by  verifying  the  bytecode  of  the  contract  and  then  looking  at  the  emitted  events).  This  is  especially crucial for wards mappings, and for Approve events emitted in the AllocatorBuffer.  MakerDAO - Allocator -   13  NoteVersion1  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Loosely Restricted Account Type",
        "body": "  In  contract  evm  facts  registry,  function  get_account_field  and  get_account  accepts  an  input account (Ethereum address) as a felt252. As an Ethereum address is only 160-bit long, it is loosely restricted. Though the internal get_account() will eventually revert upon casting u256 into u64 if the input's upper 96 bits are not zeros.  CS-HRDS-001  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Floating Pragma and Dependency",
        "body": "  For the L1 Solidity contracts, the pragma is floating and no compiler version has been fixed.  Similarly  the  cairo_lib  dependency  is  not  fixed  in  Scarb.toml,  instead  the  most  recent  version  of master is used.  Contracts  should  be  deployed  using  dependencies  and  compiler  version  they  have  been  thoroughly tested with.  CS-HRDS-002  Code partially corrected:  The Solidity compiler version has been fixed to version 0.8.21. However, the cairo_lib dependency is still floating, now tracking the branch audit.  Herodotus - Herodotus on Starknet -   13  SecurityDesignCorrectnessCriticalHighMediumLowCodePartiallyCorrectedDesignLowVersion1DesignLowVersion1CodePartiallyCorrected                   \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings   Wrong Values for Non-Existing Accounts    Broken CairoLib Dependency    Empty/inexistent Storage Slots Can Not Be Proven    MMR: Verify Against an Intermediate Node Is Possible   -Severity Findings  Incorrect Expected Block Computation    Remapper Last_Timestamp Can Be Reset to 0    Unchecked Slot Length   -Severity Findings   End Block May Underflow if the Start Block Is 0    Missing OwnershipRenounced Event by Transferring to Zero Address   Informational Findings   Option<T> but Only Actual Element Supported    Unnecessary Retrieval of Header Store    Duplicated Peaks of Proof_Element    Unused FormatWords64 Library    Unused ProofElement.last_pos    Close to Ressource Limit in Starknet   0  4  3  2  6  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Wrong Values for Non-Existing Accounts",
        "body": "  Version  5  added  support  to  prove  non-inclusion  of  accounts  in  the  state  trie,  which  means  there  is  no valid path in the world state trie that matches the input key (keccak of account address). For accounts not present in the given world state trie, the following default values are returned:  CS-HRDS-006  const EMPTY_STORAGE_HASH: u256 =     0x56e81f171bcc55a6ff8345e692c0f86e5b48e01b996cadc001622fb5e363b421; const EMPTY_CODE_HASH: u256 =     0xc5d2460186f7233c927e7db2dcc703c0e500b653ca82273b7bfad8045d85a470;  Herodotus - Herodotus on Starknet -   14  CriticalHighCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedMediumCodeCorrectedCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCorrectnessHighVersion5CodeCorrected         \fconst EMPTY_BALANCE: u256 = 0x0; const EMPTY_NONCE: u256 = 0x0;  This is incorrect: For non-existing accounts at a given block, all fields are 0x0.  For  existing  accounts  without  code  or  storage  the  fields  are  set  to  EMPTY_CODE_HASH  or EMPTY_STORAGE_HASH respectively.    Code has been corrected to return 0x0 for fields of inexistent accounts.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Broken CairoLib Dependency",
        "body": "  CS-HRDS-017  The  smart  contracts  are  built  on  Herodotus  CairoLib  and  inherits  the  vulnerabilities  it  has.  Here  we provide a non-exhaustive list:   Keccak Discards Leading Zero Bytes In Last Little Endian Words64:  1. HeaderStore.process_batch()  will  revert  in  case  the  RLP-encoded  header  satisfies  the  condition.  2. EVMFactsRegistry's internal get_account() will compute account hash incorrectly in case the  account satisfies the condition.   MMR: Incorrect Root Update possible, Insufficient Peaks Validation:  1. All the calls to MMR.append() in HeaderStore and TimestampRemappers are subject to this  vulnerability.   Missing Length Validation In MPT Verify:  1. EVMFactsRegistry's get_storage() and internal get_account() may revert on some valid  proofs. And a forged key may succeed in verification.   reverse_endianness_u64() Discards Leading Zeros:  1. TimestampRemappers's  extract_header_block_number_and_timestamp()  may  return incorrect block number and timestamp if their little endian representations have leading zero bytes.  The  Herodotus  CairoLib  has  been  reviewed  in  a  separate  report,  please  refer  to  it  for  details  on  the underlying issues.    All issues have been resolved in the underlying CairoLib code. For details please refer to the separate report.  Herodotus - Herodotus on Starknet -   15  SecurityHighVersion1CodeCorrected          \f6.3   Empty/inexistent Storage Slots Can Not Be Proven  Unused  /  non-existing  storage  slots  of  an  account  default  to  a  value  of  0x0.  These  slots  cannot  be proven successfully as the mpt.verify() fails or starting from   of the code, mpt.verify() returns an empty list which cannot be successfully RLP-decoded.  This e.g. prevents proving zero balance of an ERC20 token.  CS-HRDS-007    Proving  unset  slots  /  slots  with  a  value  of  zero  is  now  possible.  The  change  introduced  in  related  trie. evm_facts_registry.get_storage()  has  been  updated  to  handle  the  case  of  a  successful  non inclusion verification.  to  prove  non-existence  of  a  key   inclusion  proofs  allows   to  non   in  a   Note  that  the  code  doesn't  allow  to  prove  any  storage  slot  for  non-existing  accounts.  Similarly  for accounts  without  storage  - 0x56e81f171bcc55a6ff8345e692c0f86e5b48e01b996cadc001622fb5e363b421.  No  storage slots can be proven for these accounts.  the  keccak  of  0x80   the  storage   initialized   root   to   is   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   MMR: Verify Against an Intermediate Node Is",
        "body": " Possible  CS-HRDS-018  From the perspective of mmr.verify_proof(), it cannot distinguish the value verifying against is a leaf or an intermediate node (a Poseidon hash of its two children). Thus theoretically you can verify against any  node  that  is  inside  the  MMR.  Herodotus  on  Starknet  uses  MMRs  in  both  Headers  Store  and Timestamp  Remappers.  It  is  unlikely  to  abuse  the  verification  of  an  intermediate  node  in  the  former, nevertheless, it is feasible in the latter.  In the following we denote a block header as h, Poseidon hash double operation as F and hash many as G, and Poseidon hash of a block header as ph=G(h).  Headers  Store:  the  MMRs  leaves  store  the  Poseidon  hashes  of  RLP-encoded  block  headers (leaf=G(h)). In case one wants to abuse an intermediate node (node=F(ph1, ph2)), it needs to find a fake block header(h3), so that the following equation holds:  F(ph1, ph2) = = G(h3)  Since hash double and hash many starts with different third states in the underlying hades permutation, it is unlikely to find a header (h3) that satisfies the equation above.  Timestamp  Remappers:  the  MMRs  leaves  store  the  block  timestamps  directly  without  hashing.  Upon querying  get_closest_l1_block_number(),  users  need  to  pass  the  MMR  inclusion  proofs  of  mid point leaf nodes against one mapper's MMR during the binary search.  It seems unlikely to replace a leaf node with an intermediate node as the leaf index is fixed with respect to the mid point. However, mmr.verify_proof() reconstructs the peak according to the length of the proofs instead of the tree height reflected by the index. Consequently, one can replace a leaf node (a block timestamp) with an intermediate node (a Poseidon hash) to manipulate the result of binary search.  Herodotus - Herodotus on Starknet -   16  CorrectnessHighVersion1CodeCorrectedVersion5Version5SecurityHighVersion1CodeCorrected              \f  This  has  been  fixed  in  the  underlying  library.  Verification  against  intermediate  nodes  is  no  longer possible.  issue ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.5 MMR Verify Proof: Different Nodes Can Us the Same Index of the CairoLib report.",
        "body": "  please   details   refer   For   to   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Incorrect Expected Block Computation",
        "body": "  In contract timestamp remapper's reindex_batch(), the expected_block will be computed based on the start block (start_block) and the element amount (elements_count) of this remapper:  CS-HRDS-009  let mut expected_block = 0; if (mapper.elements_count == 0) {     expected_block = mapper.start_block; } else {     expected_block = mapper.start_block + mapper.elements_count + 1; }  This calculation in the else branch is incorrect. For example, in case the start block number is 0 and the current elements count is 1, the expected next block should be block 1, nevertheless, the else branch will return 2.    The computation of expected_block has been simplified and corrected.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Remapper Last_Timestamp Can Be Reset to 0",
        "body": "  In  contract  timestamp  remapper's  reindex_batch(),  the  corresponding  mapper.last_timestamp will be set to a local variable last_timestamp, which is 0 at the beginning, and gets updated according to the last element in the input block headers. However, if there is no element in the input batch, one can skip the loop and directly reset the mapper.last_timestamp to 0.  This  can  invalidate  all  the  consecutive  calls  to  get_closest_l1_block_number(),  since  all  valid block  timestamps  are  larger  than  0,  which  will  be  larger  than  mapper.last_timestamp  and  the function will revert.  CS-HRDS-010    The function now reverts if the input is an empty batch, this resolves the issue described above.  Herodotus - Herodotus on Starknet -   17  CorrectnessMediumVersion1CodeCorrectedCorrectnessMediumVersion1CodeCorrected                  \f6.7   Unchecked Slot Length  CS-HRDS-012  In evm facts registry, function prove_storage accepts an input slot, whose name is misleading since what it actually expects is keccak256(slot) as per Ethereum MPT specification (see ref.1 and ref.2). Moreover, users have full control over the input slot_len, which indicates the length of the key in the MPT. This leads to the following consequences:   The legitimate keys of storage slots are keccak256 digest with a 64-nibble (32-byte) fixed length. Thus the slot values should be stored in leaf nodes. However, now a user can get the value stored in a branch node with a key less than 64-nibble long, which should not be a valid use case.  In prove_storage(), the storage value will be retrieved according to the slot_len (only partial of input slot), nevertheless, the whole slot (instead of the first slot_len nibbles) will be stored as the key for the retrieved value.  In summary, this enables the proving of values in branch node and storing values in branch node as slot values. This applies to get_storage() as well.    The input argument slot is now hashed inside the functions before being used as key. This guarantees that the keys length is always fixed to 64 nibbles. The name of the variable is no longer misleading since it now actually represents the slot.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   End Block May Underflow if the Start Block Is",
        "body": " 0  CS-HRDS-008  In contract headers store, users can append a batch of block hashes (process_batch()) to an MMR via two approaches:  1. First  block  received  from  the  inbox:  submit  a  reference  block  to  query  from  received_blocks.  And the start_block will be set to the reference_block-1  2. First block already included in an MMR: submit an inclusion proof of the first element towards the current  MMR.  In  case  the  reference_block  is  None,  the  start_block  will  be  read  directly from the first header.  The  function  parameters  with  data  for  both  approaches  (reference_block  and  mmmr_index  + mmr_proof) are of type Option<T>, since for normal usage only one of both should be supplied.  In  case  the  reference_block  is  not  None  in  the  second  approach  (passing  mmr_index  with mmr_proof), the start_block (initialized to 0) will not be updated, and the function may revert due to underflow when computing the block_end.    Passing a reference block alongside an MMR proof is now prevented.  Herodotus - Herodotus on Starknet -   18  DesignMediumVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                 \f6.9   Missing OwnershipRenounced Event by Transferring to Zero Address  CS-HRDS-011  inbox  contract,   the  commitments   in In  transfer_ownership().  Thus,  its  ownership  by  either  calling renounce_ownership()  or  transferring  ownership  to  zero  address  (transfer_ownership()). event However,  OwnershipTransferred instead of OwnershipRenounced.  there  the  owner  can   is  no  sanity  checks  of   transfer_ownership()   the  new_owner   renounce   second   option,   emits   only   the   an   in     If  the  ownership  is  transferred  to  the  zero  address  using  transfer_ownership(),  the  event OwnershipRenounced is now emitted instead of the event OwnershipTransferred.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   Close to Ressource Limit in Starknet",
        "body": "  As of October 2023 with Starknet v0.12.2 the current step limit per transaction is 3 million, and gas limit is 3 million per block.  The complexity of executing prove_account() and prove_storage() depend on the position of the account and the storage slot in the state trie. For most accounts and slots this is feasible to execute with less than 2.5 million steps.  It is anticipated that the step limit and gas efficiency in starknet will be increased in the near future.  CS-HRDS-020    The code was optimized significantly:   The  RLP  decoder  now  implements  rlp_decode_list_lazy  which  allows  to  decode  only  the  required elements.   The eth_mpt() implementation now makes use of lazyBranch helpers: Instead of having to load all elements within a branch node entirely, it only loads the designated element of a branch node.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.11   Duplicated Peaks of Proof_Element",
        "body": "  In mmr_binary_search() of Timestamp Remappers, each proof to be verified against a mid point has a  peaks  field  in  proof_element.  Given  the  fact  that  the  MMR  will  not  be  modified  during  the  binary search, it is redundant to duplicate the peaks within every proof element.  CS-HRDS-015    Herodotus - Herodotus on Starknet -   19  DesignLowVersion1CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected                  \fHerodotus has removed the peaks entry from the individual proof element and only submit it once in the input.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.12   Option<T> but Only Actual Element",
        "body": " Supported  CS-HRDS-013  Struct  BinarySearchTree  of  field  left_neighbor  as Option<ProofElement>.  The  implementation  doesn't  support  an  option  of  this  element  /  None  and only works if there is a ProofElement.  remapper  defines   timestamp   the     Code  has  been  updated  to  only  verify  the  left_neighbor  in  case  it  has  not  been  verified  within  the binary search.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.13   Unnecessary Retrieval of Header Store",
        "body": "  In  the  Timestamp  Remappers  mmr_binary_search  function,  the  address  of  the  headers  store  is retrieved:  CS-HRDS-014  // Retrieve the header store address let headers_store_addr = self.headers_store.read();  The headers store however is not used in this function. The validity of the data in the MMR is verified in reindex_batch() when new elements are added. When doing the binary search in the MMR it is only ensured that the elements are indeed part of the MMR.    This has been removed from the code.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.14   Unused FormatWords64 Library",
        "body": "  FormatWords64 is implemented and imported in L1MessagesSender, whereas it is never used.  CS-HRDS-016    FormatWord64 has been removed from the codebase.  Herodotus - Herodotus on Starknet -   20  InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected                    \f6.15   Unused ProofElement.last_pos  Struct ProofElement of the timestamp remapper defines a field last_pos which is never used.  CS-HRDS-019    The unused element has been removed from the struct.  Herodotus - Herodotus on Starknet -   21  InformationalVersion1CodeCorrected    \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Front-running Process Batch, Verify Mmr,",
        "body": " Reindex Batch  CS-HRDS-003  If front-running is feasible (consider decentralized sequencers in the future), this could be leveraged to revert certain transactions:   Header_store.process_batch():  if  an  MMR  inclusion  proof  is  submitted,  it  will  be  verified against  the  current  MMR.  A  call  to  process_batch()  can  be  front-run  by  another  call  to process_batch() to update the peaks and revert the former call.   verify_mmr_inclusion(): a call to this function can be front-run by another call to update the  MMR and thus invalidate the previous proofs.   timestamp_remappers.reindex_batch():  a  call  to  reindex_batch  can  be  front-run  by  a  another call to it, which invalidates the previous call.  public   functions   and For  create_branch_single_element())  callers  now  additionally  supply  last_pos  in  addition  to  the mmr_id.  This  allows  to  verify  the  supplied  proof  against  the  historic  mmr  successfully  even  in  case  a preceding transaction updated the specific mmr.  (create_branch_from()   existing  mmr's   branching   from   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Merge128 Discards Higher 128 Bits of Upper",
        "body": " Input  merge128() accepts two uint256 inputs (lower and upper) and merges them into one uint256. It is expected that both inputs only use the lower 128 bits of u256. It checks the lower does not exceeds max(uint128),  whereas  the  upper  is  not  checked  and  its  higher  128  bits  will  be  discarded  if  they contain non zero bits.  CS-HRDS-004  Herodotus is aware and states this is not applicable to their codebase.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Unrestricted Aggregator ID and MMR Size",
        "body": "  CS-HRDS-005  Herodotus - Herodotus on Starknet -   22  InformationalVersion1InformationalVersion1InformationalVersion1          \fIn  L1MessagesSender,  the  aggregator  id  and  MMR  size  are  represented  as  uint256.  They  are  not checked and directly used as fields in the L1 -> L2 message payload. As a result, they may exceed the maximum usize, which is the expected type of inputs in Commitments Inbox.  Besides,  in  Starknet  the  basic  data  type  is  felt252.  As  the  aggregator  id  and  MMR  size  are  not restricted to fit in a felt252, in case they exceed max(felt252), the message will be stuck and never consumed on L2.  Herodotus - Herodotus on Starknet -   23  \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   EIP-161",
        "body": "  In the early days of Ethereum, empty accounts could remain in the state trie. Empty in this context means the account has a nonce of zero, zero balance and no code but might have some storage entries.  EIP-161 introduced in the Spurious Dragon hardfork at Block 2'675'000 on mainnet prevents new empty accounts  and  enables  removal  of  existing  empty  accounts  out  of  the  state  trie  if  a  transaction  touches them.  Since these empty accounts are valid accounts of the state trie, these accounts and their storage can be proven with Herodotus.  As per block 14049881 all empty accounts are supposed to have been removed from the state trie.  For more information please refer to the EIP: https://eips.ethereum.org/EIPS/eip-161  This  https://eips.ethereum.org/EIPS/eip-4747  stagnant   EIP   contains  more   examples   and   lists   affected   addresses:  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Ethereum Block Header May Be Subject to",
        "body": " Future Updates  The fields included in an Ethereum block header may change in future upgrades. It is expected that new fields  will  only  be  appended  to  the  current  block  header,  which  shall  not  break  the  compatibility  with Herodotus.  upgrade: from  https://eips.ethereum.org/EIPS/eip-4895#new-field-in-the-execution-payload-header-withdrawals-root. Other  changes  of  the  block  header  (which  are  unlikely  and  not  expected  to  happen)  would  break Herodotus.  Shanghai   example   See   last   the   an   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.3   None Block Header Exists in MMR",
        "body": "  In  the  constructor  of  header  store,  the  MMR  with  id  0  is  initialized  with  the  hash  of  an  initial  element \"brave new world\", which is not a legitimate block hash. This MMR can also be forked to another MMR with  a  different  integrate  with verify_mmr_inclusion()  or  verify_historical_mmr_inclusion()  should  execute  caution and enforce the target it verifies against is a legitimate block hash.  id  via  create_branch_from().  All  external  systems   that   Herodotus - Herodotus on Starknet -   24  NoteVersion1NoteVersion1NoteVersion1          \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Admin Set Too Early in ",
        "body": " LiquidityGaugeV4Strat  The  admin  is  transferred  via  a  commit-accept  scheme  in  LiquidityGaugeV4Strat.  However,  the scheme is bypassed by directly setting the new admin in commit_transfer_ownership:  @external def commit_transfer_ownership(addr: address):     \"\"\"  StakeDAO - LiquidLockers -   10  DesignCorrectnessCriticalHighMediumAcknowledgedAcknowledgedLowAcknowledgedAcknowledgedAcknowledgedAcknowledgedAcknowledgedAcknowledgedAcknowledgedAcknowledgedAcknowledgedAcknowledgedAcknowledgedAcknowledgedAcknowledgedAcknowledgedCorrectnessMediumVersion1Acknowledged           \f    @notice Transfer ownership of Gauge to `addr`     @param addr Address to have ownership transferred to     \"\"\"     assert msg.sender == self.admin  # dev: admin only     assert addr != ZERO_ADDRESS  # dev: future admin cannot be the 0 address      self.future_admin = addr     self.admin = addr     log CommitOwnership(addr)  While this doesn't compromise the security of the contract, it causes the emitted event to be incorrect and is misleading to users who don't believe an immediate transfer of ownership is possible. Furthermore, the function accept_transfer_ownership is made redundant if this behavior is intended.  Acknowledged  StakeDAO  acknowledges  the  issue  and  noted  that  they  had  to  implement  this  function  for  the  factory contract so that it can transfer the admin of the contract in one transaction.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Zero Address Reward Distributor",
        "body": "  The add_reward functions in all gauge contracts do not check that the _distributor address is not the  zero  address.  This  is  problematic  as  set_reward_distributor  asserts  that  the  distributor address  is  not  zero.  Therefore,  if  add_reward  is  called  with  the  zero  address  as  the  _distributor parameter, a reward distributor can never be set for this reward token entry.  Acknowledged  StakeDAO  acknowledges  the  issue  without  changes  as  they  rate  the  chances  as  very  low  that  the described issue happens. They state the issue only occurs when they add a reward distributor manually to the LiquidityGaugeV4.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   Functions Marked public Should Be",
        "body": " external  The following functions are public but not called from within the corresponding contract. Hence, they should be marked external.   AngleStrategy.deposit   AngleStrategy.withdraw   AngleVault.init   AngleVault.deposit   AngleVaultGUni.deposit   BalancerVault.init  StakeDAO - LiquidLockers -   11  CorrectnessMediumVersion1AcknowledgedDesignLowVersion1Acknowledged                \f BalancerVault.deposit   BalancerVault.provideLiquidityAndDeposit   BalancerVault.withdraw   CurveVault.init   CurveVault.deposit  Acknowledged  Client acknowledges the issue without changing the code.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.4   Inconsistent Limits on Fees",
        "body": "  The  constraints  for  which  fees  can  be  set  is  inconsistent  between  strategies.  For  example,  the AngleStrategy  contract  allows  each  individual  fee  to  be  as  high  as  BASE_FEE,  whereas  the BalancerStrategy contract only allows the sum of all fees for a gauge to be as high as BASE_FEE.  Acknowledged  StakeDAO is aware of the issue and acknowledges it.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.5   MANAGEFEE Enum Defined Multiple Times",
        "body": "  The  MANAGEFEE  enum  is  defined  once  in  each  Strategy  contract.  It  would  be  simpler  and  less error-prone to instead define it in the shared interface instead.  Acknowledged  StakeDAO is aware of the issues and acknowledges it. They might change it in future releases.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.6   Misleading Governance Addresses",
        "body": "  A Strategy contracts calls its respective Locker contract in its deposit, withdraw and claim functions. It  specifically  calls  the  Locker's  execute  function,  which  has  the  onlyGovernance  modifier.  Any reasonable user would assume that onlyGovernance modifier means that the execute function could only be called by the governance contract. However, the Locker's governance address is instead set to the Strategy contract's address in order to allow this functionality.  Acknowledged:  StakeDAO - LiquidLockers -   12  DesignLowVersion1AcknowledgedDesignLowVersion1AcknowledgedDesignLowVersion1Acknowledged                        \fAccording  to  StakeDAO,  this  is  related  to  their  flow.  There  are  many  layers  of  governance.  The governance address of the Locker contract is the Strategy contract. The governance of the Strategy is the  voter  contract,  which  is  a  helper  contract  to  facilitate  on-chain  voting  and  admin  functionality.  The voter contract is owned by a multisig.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.7   Missing Check if withdrawFee Is Zero",
        "body": "  In  the  Angle  vault  contract's  withdraw  function  a  transfer  to  the  governance  contract  is  done  to  send potential fees. The transfer is also done if the fees are actually zero.  Acknowledged:  StakeDAO acknowledges this issue as it is only present in the AngleVault contract and has been fixed for other vault implementations.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.8   Missing Events",
        "body": "  Multiple  functions  perform  important  state  changes  without  emitting  an  event.  For  example,  the  setter functions in the vault and strategy contracts.  Acknowledged:  StakeDAO does not see the necessity to emit these events and acknowledges the issue.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.9   Missing Sanity Checks",
        "body": "  There are multiple setter functions missing the address zero sanity check.   toggleVault and all setter functions in AngleStrategy except for setVaultGaugeFactory   Multiple setter functions in the different vault contracts  Additionally, withdraw and deposit in LiquidityGaugeV4Strat can be called with _addr = 0.  There are no limits imposed when setting the keeperFee and withdrawalFee for a vault. This allows setting an arbitrarily high fee, even above 1.  Acknowledged  StakeDAO states that they do the checks on their side.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.10   NatSpec Missing",
        "body": "  StakeDAO - LiquidLockers -   13  DesignLowVersion1AcknowledgedDesignLowVersion1AcknowledgedDesignLowVersion1AcknowledgedDesignLowVersion1Acknowledged                                \fMany contracts are missing NatSpec. Some only have partial or incomplete NatSpec.  Acknowledged:  StakeDAO is implementing NatSpec documentation in newer deployments.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.11   Non-indexed Events",
        "body": "  The  events  in  the  following  contracts  signal  important  state  updates  which  include  addresses.  The corresponding address is part of the event but not indexed.  In liquidityGaugeV4Strat:   UpdateLiquidityLimit   CommitOwnership   ApplyOwnership  All Events in AngleVault, AngleVaultGUni, BalancerVault, CurveVault and BaseStrategy.  Acknowledged:  As indexed events cost more gas, StakeDAO decided not to add them but handle fetching and filtering events on their side.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.12   State Variable Could Be Immutable",
        "body": "  The state variable token in the AngleVaultGUni contract could be made immutable to save gas.  Acknowledged:  StakeDAO will take this gas optimization into consideration in future implementations.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.13   Superfluous Variable Assignment",
        "body": "  The  BalancerVault  contract  writes  assets[i]  =  address(tokens[i])  in  a  loop.  This  variable assignment seems superfluous.  Acknowledged:  StakeDAO  has  decided  to  acknowledge  this  unnecessary  gas  consumption  as  it  does  not  have  any impacts on security.  StakeDAO - LiquidLockers -   14  DesignLowVersion1AcknowledgedDesignLowVersion1AcknowledgedDesignLowVersion1Acknowledged                          \f5.14   Unnecessary External Call to approve  In  AngleVault.deposit,  BalancerVault.setLiquidityGauge  and  CurveVault.deposit  the corresponding contract's approve function is called with an external call when an internal call could have been performed.  Acknowledged:  StakeDAO  will  consider  changing  this  unnecessary  external  call  to  a  function  call  in  future implementations.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.15   Unused Imports",
        "body": "  Some contracts import code that is not used in the contract. E.g., AddressUpgradeable is imported in AngleVault  and  used  in  the  using  statement  without  ever  using  functionality  from  the  library. Removing all unused imports and library contracts enhances the code quality and readability.  Acknowledged:  StakeDAO acknowledged the issue.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.16   Wrong Event Emitted",
        "body": "  The Transfer event emitted at the end of the withdraw function in the LiquidityGaugeV4Strat contract has incorrect parameters. It emits msg.sender as the _from address instead of _addr.  Acknowledged:  StakeDAO acknowledges the issue. To track the correct event, they would track the vault's withdraw event.  StakeDAO - LiquidLockers -   15  DesignLowVersion1AcknowledgedDesignLowVersion1AcknowledgedCorrectnessLowVersion1Acknowledged                      \f6   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Inconsistent Withdraw Fees",
        "body": "  When withdrawing from a Vault it matters if the vault currently has accumulated a token balance due to deposits being made without using the earn option. If the withdrawn amount is smaller than the balance, the users end up in a race condition to save the withdraw fees.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Known Issues Before the Audit",
        "body": "  The following two issues were known before the audit:  In AngleVault:  > withdrawAll() wrongly defined. Since that every LP obtained will be staked directly into the related LGV4, for this reason the msg.sender's balance would be always 0.  In CurveStrategy:  > An edge case can happen within the harvest() for certain type of curve gauges, with more than one extra reward.  StakeDAO - LiquidLockers -   16  NoteVersion1NoteVersion1      \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Unnecessary Additional Transfers",
        "body": "  In  functions  exitGem,  wipeAndFreeGem,  wipeAllAndFreeGem  of  the  DssProxyActionsCropper  as well  as  in  function  freeGem  of  the  DssProxyActionsEndCropper  the  collateral  is  first  exited  to  the DSProxy  before  being  transferred  onward  to  msg.sender.  The  gems  may  be  exited  to  msg.sender directly.  Acknowledged:  MakerDAO replied:  This is intentional to keep the rewards in the ds-proxy account. This way the ds-proxy owner can choose when to withdraw them. This paradigm of leaving the rewards in the ds-proxy is used for all actions calling join and exit. It was preferred by some of the UI projects integrating with Maker.  MakerDAO - DSS Crop Join -   13  DesignCorrectnessCriticalHighMediumLowAcknowledgedDesignLowVersion3Acknowledged            \f7   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings  -Severity Findings   Documentation Not up to Date    Event Fields Consistency   Incorrect Decimal Annotation    Urn Proxy Load Inefficiency    NewProxy Event Consistency   0  0  0  5  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Documentation Not up to Date",
        "body": "  README.md describes tack and the auction process:  The winner of a collateral auction claims their collateral via flip.deal  This  describes  the  old  liquidation  process  using  the  Cat.  The  ilks  of  CropJoin  however  will  use liquidations 2.0 with the Dog and a slightly altered auction contract. Flip.deal() is not part of this.  Other  recent  maker  projects  contained  a  \"Risk\"  section  in  their  documentation.  Different  than  the traditional GemJoin adapter which just locks the collateral, CropJoin stakes the collateral into a third party system. This introduces new risks which should be documented appropriately.  Specification changed:  The readme was updated and now describes the liquidation process using the Dog. Risk consideration have not been added.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Event Fields Consistency",
        "body": "  1. In CropJoin, the Join and Exit events differ from the system's default ones in the sense that  they do not contain the indexed address field.  2. The  Flee  event  has  no  fields.  Emitting  this  event  will  cost  gas  and  will  not  give  any  useful  information off-chain.  MakerDAO - DSS Crop Join -   14  CriticalHighMediumLowSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedDesignLowVersion1Speci\ufb01cationChangedDesignLowVersion1CodeCorrected                 \f  1. The events now include the addresses of the urn and the user.  2. The Flee event now features following fields: The addresses for the user and the urn, the amount.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Incorrect Decimal Annotation",
        "body": "  The decimals of bonus and total could differ.  uint256     public share;  // crops per gem    [ray] uint256     public total;  // total gems       [wad] uint256     public stock;  // crop balance     [wad]  Share is calculated and updated in CropJoin.harvest():  function harvest(address from, address to) internal {     if (total > 0) share = add(share, rdiv(crop(), total));     uint256 last = crops[from];     uint256 curr = rmul(stake[from], share);     if (curr > last) require(bonus.transfer(to, curr - last));     stock = bonus.balanceOf(address(this)); }  share is in ray, crop() is decimals of bonus and total is wad. Note that rdiv() multiplies crop() with a ray. The resulting unit for share is bonus decimals * ray, bonus decimals may not be in 18 decimals.  rmul(stake[from],  share);  correctly  calculates  the  amount  in  bonus  token  unit.  The calculations are correct but the unit annotations are not accurate.    The annotations have been updated:  uint256     public share;  // crops per gem    [bonus decimals * ray / wad] uint256     public total;  // total gems       [wad] uint256     public stock;  // crop balance     [bonus decimals]  mapping (address => uint256) public crops; // crops per user  [bonus decimals]  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   Urn Proxy Load Inefficiency",
        "body": "  The flux function of Cropper calls getOrCreateProxy to load the source urn proxy. Here a check similar to the one in move would save gas, firstly by saving a function call, and secondly by reverting the transaction  earlier  in  case  the  urn  does  not  exist.  If  the  source  urn  does  not  exist,  tack  will  revert  on non-zero wad parameter.  MakerDAO - DSS Crop Join -   15  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \f  Flux() now loads the source urn proxy directly from the proxy mapping and reverts if no entry exists.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   NewProxy Event Consistency",
        "body": "  The  event  NewProxy,  which  is  triggered  when  a  new  urn  proxy  is  deployed,  is  implemented  in  the Charter  contract  but  not  in  Cropper.  Since  the  two  contracts  are  meant  to  behave  similarly,  the NewProxy event should consistent.    The NewProxy event has been added to the UrnProxy contract in Cropper.sol.  MakerDAO - DSS Crop Join -   16  DesignLowVersion1CodeCorrected        \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   UrnProxy With Different ilk",
        "body": "  It is possible to send gem that do not correspond to any ilk managed by the Cropper to an urn proxy and generate debt from this collateral. Since the urn proxy is managed by the Cropper it is not possible to get this gem out of the urn proxy.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Withdraw Value on Flee",
        "body": "  The internal accounting inside CropJoin is based on shares with 18 decimals:  Upon  join(),  the  amount  of  tokens  brought  is  converted  into  shares  by  expanding  the  value  to  an  18 decimals representation and a division through the net value per share:  The opposite is done during exit().  This amount of shares is used for all accounting purposes, namely to update the gem balance in the VAT, the stake[urn] and the total.  SynthetixJoin.flee() retrieves the value stored in the gem mapping at the VAT. This value is in the unit of shares. This value however is used as the amount of tokens to withdraw from the pool.  function flee(address urn, address usr) public override {     if (live == 1) {         uint256 val = vat.gem(ilk, urn);         if (val > 0) pool.withdraw(val);     }     super.flee(urn, usr); }  The  unit  mismatch  (shares  vs  tokens)  is  not  problematic  for  SynthetixJoin  under  the  condition  that  the gem  token  has  18  decimals.  Due  to  the  asset  valuation  in  SynthetixJoin  (nav())  the  exchange  rate between token and shares is 1:1.  In general, for an arbitrary CropJoin contract this may not hold. It's problematic when the exchange rate is  not  1:1  or  the  token  doesn't  have  18  decimals.  If  too  little  tokens  are  withdrawn  from  the  pool  the amount of tokens available at the Join adapter are insufficient to transfer the required amount to the user and the whole transaction fails blocking withdrawals. The other way, rounded surplus tokens will remain at the CropJoin contract.  MakerDAO - DSS Crop Join -   17  NoteVersion1NoteVersion1      \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Encumbered Balances Can Be Transferred",
        "body": "  transferFrom() allows a user to spend tokens encumbered to them from a given src address and then, if there are still more tokens to be transferred, spend additional allowance of the same src:  CS-COMPSPT-007  uint256 excessAmount = amount - encumberedToTaker;  _releaseEncumbrance(src, msg.sender, encumberedToTaker);  if (availableBalanceOf(src) < excessAmount) revert InsufficientAvailableBalance();  _spendAllowance(src, msg.sender, excessAmount);  In this case, the encumbrance is first released and then the available balance of the src is checked. This is  problematic  because  availableBalanceOf()  relies  on  the  encumberedBalanceOf  variable which  has  just  been  decreased  in  _releaseEncumbrance().  The  result  is  that  if  src  has  given encumbrance  to  more  than  one  address  (and  additional  allowance  to  the  msg.sender  that  is  greater than the available balance of src), the msg.sender is able to spend its allowance on an amount that is encumbered to someone else.  Note: This issue has been disclosed by Compound after the first intermediate report has been released.  Compound - SUPTB -   11  CriticalCodeCorrectedHighCodeCorrectedMediumLowCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCorrectnessCriticalVersion1CodeCorrected          \f  The availableBalanceOf() check is now performed before the encumbrance of the msg.sender is released. The excessAmount can no longer be higher than the actual available balance.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Permission Can Be Bypassed in ",
        "body": " transferFrom()  transferFrom() checks the permissions of the src address only when there is nothing encumbered to the msg.sender:  CS-COMPSPT-008  uint256 encumberedToTaker = encumbrances[src][msg.sender]; if (encumberedToTaker == 0 && !permissionList.getPermission(src).isAllowed) {     revert InsufficientPermissions(); }  Users could encumber 1 wei of the token to themselves and would then still be able to transfer all of their balance to another (permissioned) address by approving it first and then using transferFrom(). This is possible because the check above does not make sure that the amount being transferred is less or equal to encumberedToTaker before disabling the permission check.    The  check  has  been  corrected  to  revert  in  case  the  encumbrance  is  insufficient  and  the  transfer permission check failed. As a result, bypassing the permission check with a small non-zero encumbrance is no longer possible.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Unpaused Approve",
        "body": "  In case the admin pauses the contract, permit() will also be paused so that users cannot update their allowance  by  signatures.  However,  users  can  still  use  approve(),  increaseAllowance(),  and decreaseAllowance()  to  update  the  allowance,  as  these  functions  are  not  overridden  with  the whenNotPaused modifier.  CS-COMPSPT-006    The modifier whenNotPaused has been removed from permit() since users will not be able to transfer in a paused contract anyways.  Compound - SUPTB -   12  CorrectnessHighVersion1CodeCorrectedDesignLowVersion1CodeCorrected                  \f6.4   Gas Optimizations  The following code parts can be further optimized to improve gas efficiency:  1. In case of using allowance in transferFrom(), the check towards available funds and the call of _spendAllowance() can be conducted before the call to _releaseEncumbrance() to reduce gas waste for reverting transactions.  2. Some  subtractions  can  be  done  in  an  unchecked  scope  in  case  the  order  has  already  been  checked before. For example:  CS-COMPSPT-001  if (amount > encumberedToTaker) {     uint256 excessAmount = amount - encumberedToTaker;     ... }  3. DOMAIN_SEPARATOR  can  be  cached  as  an  immutable  and  only  recomputed  in  runtime  in  case  there is a fork.  4. Since  permissions  are  often  retrieved  for  two  different  addresses  in  one  call,  a  bulk  version  of  PermissionList.getPermission() could be implemented.    The code has been corrected to check available funds first, see the fix to Encumbered balances can be transferred.  The  computation  of  excessAmount  has  been  wrapped  into  an  unchecked  scope  since  the  order  is already checked before.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Incorrect Specs",
        "body": "  A doc comment of the transfer() function states:  CS-COMPSPT-002  Includes extra functionality to burn tokens if ``dst`` is the contract address  This is not true as burning occurs when dst == address(0).  Furthermore, a doc comment of the function release() states:  Spends all of the encumbrance if ``amount`` is greater than ``owner``'s  This is also not true as the function reverts in that case.  Specifications changed:  The specifications have been changed to reflect the actual function behaviors.  Compound - SUPTB -   13  InformationalVersion1CodeCorrectedInformationalVersion1Speci\ufb01cationChanged            \f6.6   Irregular Naming  The function PermissionList.setPermissionAtIndex() is defined as internal but the function name  does  not  start  with  an  underscore.  This  is  in  contrast  to  other  functions  in  the  contract  such  as _requireAuthorized().  CS-COMPSPT-009    The function has been renamed to _setPermissionAtIndex().  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   No Caller in Burn Event",
        "body": "  The Burn event contains a burner address, while the Mint event contains a minter address. In case of the Mint event, the minter address is set to the address that performs the minting. In the Burn event however, burner is set to the address from which tokens are burned (equivalent to the dst address in the Mint event). The address that performs the burning is not emitted at all.  CS-COMPSPT-003    Burn event has been updated to contain a from address where tokens are burned, and the burner now represents the address that performs the burning.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   PausableUpgradeable Is Not Initialized",
        "body": "  __Pausable_init()  is  not  invoked  in  initialize().  Though  this  is  not  necessarily  required (because the function simply initializes a storage variable to the default value), it might be considered bad practice.  CS-COMPSPT-004    The function initialize() has been updated to explicitly initialize PausableUpgradeable by calling __Pausable_init().  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   Unreachable Branch",
        "body": "  permit() checks the returned boolean flag of isValidSignature() and reverts in case it is false. However, isValidSignature() always returns true in case it does not revert, thus the else branch in permit() can never be reached.  CS-COMPSPT-005  Compound - SUPTB -   14  InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected                      \f  The unreachable branch has been removed.  Compound - SUPTB -   15  \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Encumbrance Can Bypass permissionList and",
        "body": " Burning  PermissionList can only block transfers of idle (i.e., unencumbered) funds. The admin can also only burn idle funds of a user. If a user encumbers all the funds to itself (any address is possible as takers are not subject to permissions), future un-whitelisting and burning attempts will fail.  The  user  won't  be  able  to  encumber  any  funds  to  another  address  though  (contrary  to  the  issue permission can be bypassed in transferFrom()).  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   balanceOf() Semantics",
        "body": "  EIP-7246  changes  the  semantics  of  the  ERC-20  balanceOf()  function.  While  one  would  typically expect  from  an  ERC-20  token  that  the  return  value  of  the  balanceOf()  function  is  the  full  balance  a user is able to spend, this is no longer true for EIP-7246 tokens.  This  might  be  problematic  for  third-party  integrations  that  expect  the  token  to  behave  like  a  regular ERC-20 token.  Compound - SUPTB -   16  NoteVersion1NoteVersion1      \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Cached Rate May Be Wrong",
        "body": "  0  0  3  5  OracleMulti  allows  to  read  rates  from  Chainlink  and  Uniswap  circuits  with  _readAll().  First  the Uniswap rate is computed. However, the Uniswap circuit may not be final, meaning that the last pair (e.g. WETH to USD) requires a Chainlink rate. Next the Chainlink rate is read from the circuit. The rate of the last Chainlink circuit pair is cached, to be used for further computations on the Uniswap rate.  However,  the  constructor  allows  for  the  last  Chainlink  and  Uniswap  pairs  to  be  different.  Thus,  the following scenario is possible:  1. OracleMulti  is  initialized  with  a  Chainlink  circuit  (UNI-WBTC,  WBTC-USD)  and  a  Uniswap  circuit (UNI-WETH). That means that the Uniswap is not final and a Chainlink rate has to be read for the rate WETH-USD.  2. The Chainlink rate is calculated and the WBTC-USD rate is cached.  3. The Uniswap UNI-WETH rate is computed. Inside the branch if (uniFinalCurrency > 0) the calculation  of  the  rate  is  finalized  using  the  cached  WBTC-USD  rate  which  leads  to  an  incorrect result, as the rate for WETH-USD should have been used instead.  Angle - Angle Protocol -   13  SecurityDesignCorrectnessCriticalHighMediumRiskAcceptedCodePartiallyCorrectedAcknowledgedCodePartiallyCorrectedLowRiskAcceptedAcknowledgedRiskAcceptedRiskAcceptedRiskAcceptedCorrectnessMediumVersion1RiskAccepted              \fRisk accepted:  Angle will make sure that the Uniswap and Chainlink circuits are compatible. A comment has been made in the code.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Missing Slippage Protection for Users",
        "body": "  There  is  no  slippage  protection  for  users  interacting  with  the  mint(),  burn(),  deposit()  or withdraw()  functions  of  a  StableMaster  contract  nor  for  actors  interacting  with  certain  functions  of  a PerpetualManager contract which calculate the cash out amount of a perpetual.  A user can get caught unlucky, especially as fees depend on the current state of the system or as the cash out amount of a perpetual depends on the current rate returned by the Oracle. There is a risk of sandwich  attacks  on  user's  transaction:  A  user's  transaction  may  be  sandwiched  between  two  of  the attacker's transaction. The first transaction of the attacker may change the state of a system resulting in an  unfavorable  outcome  of  the  user's  transaction  while  the  attacker  profits  with  his  second  transaction just after the user's transaction.  Code partially corrected:  A slippage protection has been added for stable seekers minting and burning. Slippage protection has been introduced for hedging agents.  Acknowledged:  However,  it  was  concluded  that  not  further  slippage  protection  for  standard  liquidity  providers  is necessary.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Problematic Revocation of a Collateral",
        "body": "  StableMaster  allows  for  revokeCollateral()  to  be  called  by  the  governance.  That  transfers  all  the funds of the pool manager to a settlement contract. Afterwards users can make claims for withdrawing from the settlement contract. However, some user may lose.  This issue attempts to highlight two key points:  (I).  While this function is part of the emergency shutdown process of a stablecoin, this function can also be called on a single collateral only. In both situation following scenario (simplified that no HAs exist) which is mentioned in the documentation may occur:  1. revokeCollateral() gets called on a pool with 1000 WETH. 1 WETH is worth 1000 USD. 100 WETH-SanTokens  are  minted  and  have  value  of  200  WETH.  The  pool  manager  transfers  his balance to the settlement contract.  2. CollateralSettler.triggerSettlement()  is  executed.  The  amount  to  redistribute  is  the  balance of the settlement contract. All the rates are frozen.  3. SLPs claim their collateral. totalLpClaims increases.  4. A day before the claiming period ends, the price of WETH doubles. 1 WETH is worth 2000 USD now  in the current markets.  5. Many users see the bargain and start claiming WETH for their AgUSD.  Angle - Angle Protocol -   14  SecurityMediumVersion1CodePartiallyCorrectedAcknowledgedDesignMediumVersion1CodePartiallyCorrected                  \f6. The  claiming  period  ends.  The  claim  of  stable  holders  is  1000  WETH.  The  claim  by  SLPs  is  200  WETH.  7. The WETH will be distributed only to stable holders. SLPs do not receive anything.  The documentation specifies this behaviour. However, it highly concerning for SLPs and HAs. Anybody with enough capital could take their investments into the protocol.  (II).  Furthermore,  SLPs  and  HAs  could  the funds  revokeCollateral() call. The pools balance could be moved to another pool using a flashloan and an external exchange. Then, the revokeCollateral() call will be executed but close to nothing would be transferred to the settlement contract and SLPs and HAs will not be able to receive their funds.  if  an  attacker  decides   frontrun   lose   to   Code partially corrected:  Different changes have been made:   As  stocksUser  now  tracks  the  amount  of  created  stable  coins  it  can  also  be  used  to  limit  the  claims.   The oracle value is queried at the end of the claim period to reduce issues due to price fluctuation.  Lastly, the front-running issue will be partially mitigated through pausing, but as in comparable systems cannot be entirely avoided.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Inputs for Triggering Settlement",
        "body": "  When the StableMaster contract triggers a settlement on the CollateralSettler contract it passes the current sanRate along. During this process any queued lockedInterests that were supposed to be added to the sanRate later are ignored. Hence, the sanRate is not entirely correct.  Risk Accepted:  Angle replied:  We decided to leave it as is. lockedInterests supposed to be added to the sanRate remain ignored. It could be a vector of attack to include these interests to SLPs. If trigger settlement was to be activated, then this means that governance failed to maintain the pool in a healthy way, and in this situation, interests should not be distributed to SLPs (we expect that there will also be fees aside)  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Removing From Perpetual Potentially",
        "body": " Impossible  When a perpetual position develops well and its margin has significantly increased, users might decide to remove some of the margin through the removeFromCollateral function. However, if the amount of collateral to be removed exceeds the initially set margin, this removal is not allowed, even though it might not violate any of the system restrictions such as maximum leverage:  Angle - Angle Protocol -   15  CorrectnessLowVersion2RiskAcceptedDesignLowVersion2Acknowledged                \frequire(         ...         (amount < perpetual.margin) &&  Acknowledged:  Angle replied:  In fact the margin of a perpetual never increases if the perpetual develops well: the margin is the initial amount of collateral in the perpetual, and this does not evolve with price. If we allowed HAs to remove more than their margin in case of price increase, we would be back to the situation we had before your audit where we also update the oracle value, and what we called the cashOutAmount at each perpetual update. For the HA to get more collateral than the margin, position should be cashed out  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Sandwich Attacks Against harvest",
        "body": " Invocations  The harvest functions of certain strategies, e.g., GenericAave, are susceptible to sandwich attacks. As these harvest functions can be called by anyone and perform a token sale, the following attack is possible:   An attacker contract manipulates the relevant Uniswap pools   That attacker contract calls the harvest function of one of the strategies, which triggers a Uniswap  trade   The attacker contract arbitrages the Uniswap pools to benefit from the previous trade  In the currently present strategies, such attacks are limited to the reward tokens.  Risk accepted:  Angle replied:  We forked these strategies from Yearn, we have hence decided to keep it as is, and we are aware of this risk. It is important to note that to mitigate such attacks, however costly it is, the harvest function needs to be called pretty regularly.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   HA Fees May Exceed 100%",
        "body": "  There are no limitations for the values of haBonusMalusDeposit or haBonusMalusWithdraw. These can  be  set  arbitrarily  by  the  Guardian  /  Governor  in  the  FeeManager  and  are  later  propagated  to  the PerpetualManager.  Inside the PerpetualManager, the fee for HAWithdraw is calculated as follows:  haFeesWithdraw = (haFeesWithdraw * haBonusMalusWithdraw) / BASE; return (amount * (BASE - haFeesWithdraw)) / BASE;  Angle - Angle Protocol -   16  SecurityLowVersion2RiskAcceptedDesignLowVersion1RiskAccepted                \fIn case haFeesWithdraw exceeds BASE the transaction will revert and the withdrawal is blocked. The same applies for HADeposit accordingly.  Risk accepted:  Angle replied:  No specific change has been made for that, if this situation happens, then the transaction will fail anyway and there is no need to add a require for that.  We thought of adding a require in the setters of the fees to make sure that fees will never be able to be bigger than 100% (especially for users minting/burning fees), but we decided not to do it. The reason is that our fees are of the form f(x)g(y), with 0 <= f(x) <= 1.  Therefore it may happen that for some value of the y parameters, you have g(y) > 1, and for some couples (x,y), you have f(x)g(y)>1. We do not want to enforce that the product is always <1.  In our case, the evolution of the bonusMalus (depending on the collateral ratio for users) and the evolution of the fees computed using the coverage curve are different. It is possible that the product in the max element in the array yBonusMalusMint and in the array yFeeMint are superior to BASE but that this situation is never observed in practice because the evolution of the collateral ratio is not correlated to the evolution of the coverage curve.  Governance will still have to be wary and to make sure when setting these parameters that even though a situation where  f(x) g(y)>1 can happen in theory, it will never happen in practice.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   Small Perpetual Position, Too Low Keeper",
        "body": " Incentive  The system enforces no minimum amount for a perpetual position and corresponding minimum fee paid. The  reward  /  incentive  for  a  keeper  to  liquidate  a  perpetual  that  meets  the  condition  to  be  liquidated respectively to be forcefully cashed out is a part of fees paid by this perpetual.  The  incentive  for  keepers  must  at  least  cover  their  transaction  costs.  As  no  minimum  amount  for  a perpetual (hence keeper fee) is enforced, perpetuals bringing a small amount of collateral to the system and hence paying a small fee may not be liquidated as the reward exceeds the keeper's transaction fees.  Risk accepted:  Angle replied:  Although we slightly changed the keeper incentives (as a portion of the cashOutAmount at the time the perpetual is cashed out), we decided not to have a minimum position or a minimum incentive for keeper. If the incentives are too low, we will do it ourselves, even if it implies loosing money on it. Another thing we think about implementing is an off-chain reward mechanism based on on-chain verifiable data. This way we/our community could reward keepers which performed actions for which they did not make a profit but that were still helpful for the protocol. We could also upgrade our smart contracts to arrive to the solution you propose (minimum incentive for keeper coupled with a minimum position - you cannot do one without the other otherwise you may be subject to attacks).  Angle - Angle Protocol -   17  SecurityLowVersion1RiskAccepted          \f7   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  0  4  15  32  -Severity Findings  -Severity Findings   Burning AgTokens in BondingCurve Does Not Update stocksUsers    Collecting Keeper Fees, Closing Perpetuals   Incorrect Maximum Collateral Amount    Untracked Bad Debt / System Health   -Severity Findings   Everybody Can Pause Pools   Incorrect Check During removeFromPerpetual   Incorrect Handling of profitFactor    Potentially Incorrect Strategy Report    Reentrancy When Creating Perpetual Position    Adding to Unhealthy Perpetual Liquidates and Consumes New Collateral    Broken/Partial ERC165 Support    Conversion of Locked Interest to SanRate in the Same Block*    Governance Not Fully Propagated    Guardian Cannot Be Managed by Guardian   Incorrect Cash Out Amount    Non 18 Decimals Protocol Tokens    Unaccounted Collateral, Unrestricted updateStocksUsersGov()    Unit Errors for Tokens With Decimals Different Than 18    safeApprove Not Used, USDT Not Supported   -Severity Findings   BondingCurve Specification Mismatches    Gas-inefficient Strategies   Inefficiency in Binary Search    No Slippage Protection in BondingCurve    Reference Coin Changes May Affect the Bonding Curve    Specification Mismatch in Strategy    StableMaster Might Be Unnecessarily Paused    Cache Value Instead of Reading From Storage    Consistency Checks for Oracles Missing   Angle - Angle Protocol -   18  CriticalHighCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedMediumCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrected     \f Different Calculation of Cashout Fees    Double Getters    Enhance Check During Deployment of Collateral    Events Missing    Gas Inefficiencies When Removing From List    Gas Inefficiencies When Searching Lists    Governance Changes   Inconsistencies Between Staking Contract   Inconsistent Parameters in RewardsDistributor Possible   Incorrect Comment   Inefficient Structs    No Check if onERC721Received Is Implemented    No Checks Performed in Constructor    Outdated Compiler Version    Overhead Due to Loading Struct Into Memory    Possibly Failing Assert    Potential Confusing readLower(uint256 lower)    Reward Token Issues    Specification Mismatch in OracleMath    Unnecessary Double Checks    Updated SanRate When Converting to SLP    Wrong Incentive for Which Perpetuals to Forcefully Cash Out    capOnStablecoin May Be Violated by Guardians   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Burning AgTokens in BondingCurve Does Not",
        "body": " Update stocksUsers  The BondingCurve contract allows users to buy tokens (most likely Angle tokens). To receive tokens from the  BondingCurve,  AgTokens  get  burned  according  to  the  bonding  curve  price.  This  may  significantly reduce  the  amount  of  AgTokens  minted  and  improve  the  protocol  health.  However,  no  stocksUsers variable  is  updated.  Several  issues  may  arise  regarding  such  accounting  issues.  For  example,  the coverage  ratio  of  the  protocol  may  be  much  higher  than  the  one  indicated  and  the  system  create  bad debt through that mismatch.  Note that regular burn operations also do not update the stocksUsers variable.    When  buying  tokens  the  AgTokens  are  transferred  to  the  bonding  curve  contract  and  not  burned. and Governance   BondingCurve.recoverERC20   functions   make   use   can   of   Angle - Angle Protocol -   19  CodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedAcknowledgedCodeCorrectedCorrectnessHighVersion2CodeCorrected              \fAgToken.burnNoRedeem which calls StableMaster.updateStocksUsers to transfer AgTokens to itself and burn them while updating the stocks users for a specified pool manager.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Collecting Keeper Fees, Closing Perpetuals",
        "body": "  Should  the  maximum  covered  amount  of  collateral  be  exceeded,  anyone  can  forcefully  cash  out  any perpetual  in  order  to  bring  the  amount  of  covered  collateral  back  below  the  limit.  However  this  can  be abused as one can manipulate the amount of collateral to be covered.  Assume a working StableMaster issuing AgUSD with several collateral pools like USDC, DAI and WETH. There is a decent amount of liquidity provided by standard liquidity providers and the coverage ratio of the pools is around 80% with a limit at 90%. Many perpetuals of different sizes exist. An arbitrary attacker can now do the following:  1. Either the Attacker has funds available or borrows them using a flashloan  2. These funds are exchanged into AgUSD on a third party exchange  3. These AgUSD are now burned for the collateral under attack.  4. Burning  the  AgUSD  tokens  increases  the  collateralization  ratio  for  this  collateral  as  collateral  is  withdrawn. The attacker does this at least until the coverage limit is exceeded.  5. The attacker is now able to forcefully cash out perpetuals until the amount covered is below the limit.  While forcefully cashing out perpetuals the attacker collects the fees.  6. Pay back the flashloan using the collateral.  This  attack  is  profitable  when  the  transaction,  flashloan  and  burn  fees  are  below  the  keeper  reward collected for closed perpetuals. As keeper fees for each perpetual have to cover for the transaction base fees (as they may have to be closed individually by keepers due to reaching the cashout leverage) the collected  rewards  likely  exceed  the  fees  when  the  attacker  manages  to  forcefully  cash  out  multiple perpetuals during this action.    The  new  fee  structure  rewards  keepers  reaching  the  targeted  coverage  ratio.  Moreover,  the  keeper reward  is  capped  such  that  the  profit  of  the  keeper  is  lower  than  the  estimated  cost  of  the  flash  loan needed for such an attack. For more information see the description of System Accounting.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Incorrect Maximum Collateral Amount",
        "body": "  The  function  _testMaxCAmount  computes  the  \"Maximum  amount  of  collateral  that  can  be  insured\". This is computed as follows:  1. The stocksUsers variable is queried from the StableMaster contract.  2. The amount of minted stable coins is queried from the StableMaster contract and converted into  a collateral amount using the current rate.  3. The smaller of the two values above is multiplied with maxALock (the maximum percentage to be  insured) and then returned.  Both of these values are sometimes incorrect and hence shouldn't be used for the calculation:  1. stocksUsers is defined as:  Angle - Angle Protocol -   20  SecurityHighVersion1CodeCorrectedCorrectnessHighVersion1CodeCorrected                \f// Amount of collateral in the reserves that comes from users // + capital losses from HAs - capital gains of HAs  Due to the capital losses and capital gains it might be bigger or smaller than needed for the present calculation. Consider the following example:  After  a  late  liquidation  stocksUsers  =  15  ETH,  with  a  rate  of  500,  but  previously  10,000  stable coins have been minted. The system needs to insure 20 ETH, but would return 15 ETH * maxALock.  2. The amount of minted stable coins can only be used for this calculation if only a single collateral is used for this stable coin. However, multiple collaterals might be available to mint this stable coin and hence the system would calculate an incorrect amount of insurable collateral.    Now,  the  stocksUsers  variable  represents  the  amount  of  stablecoins  minted  per  collateral  and  the system  separates  the  stable  coins  minted  against  different  collaterals.  For  more  information  see  the description of System Accounting.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   Untracked Bad Debt / System Health",
        "body": "  A  stablemarket  attempts  to  keep  the  equilibrium  between  the  positions  of  stable  seekers  and  hedging agents. At times the attempt to keep the equilibrium may not be successful:   Should they price of a collateral decrease too fast and keepers can't or don't forcefully cash out bad perpetuals in time, the situation arises where the collateral put up by the perpetual evaluated at the current rate can no longer cover its committed amount at the rate the perpetual has been created. In this case the perpetual is liquidated leaving bad debt to the system.  Should the collateral of the stablecoin not be fully covered at all times (This means the collateral brought by stable seekers equals the amount covered by the hedging agents), 2 kinds of bad debt can occur:   Coverage of the collateral is less than 100% and the price of the collateral decreases from x to y:  For the uncovered collateral stablecoins have been minted a the higher collateral price x. Now the value of the collateral dropped to y. The minted stablecoins are now only partially covered by the value of the collateral. Note that should a new Hedging Agent now enter the system and covers some more of the collateral, this is done at the current exchange rate, not the rate used to mint the stablecoin. At this point the virtual loss of the system is converted into actual bad debt of the system.  Vice versa, should the price of uncovered collateral increase the system makes a profit.   Coverage of the collateral is more than 100% and the price of a collateral increases.  (Note that this cannot happen if maxALock is set to less than 100%)  Here profits made by Hedging Agents would exceed the increase in value of the collateral held by the system to back the minted stablecoins. This loss is taken by the system.  Overall  bad  debt  is  neither  tracked  nor  handled  otherwise.  If  possible  it  could  be  accounted  for  and compared with what is currently called \"system surplus\" which includes the fees collected and other gains made by the system.  No  functionality  to  query  the  health  of  the  system  exist.  Such  information  however  is  vital  for  all  users investing funds into the system.  Angle - Angle Protocol -   21  DesignHighVersion1CodeCorrected        \f  The  new  stocksUsers  enables  to  keep  better  track  of  the  current  system  health  and  the  bad  debt. However, these computations need to be performed off-chain, e.g., in the front-end. For more information see the description of System Accounting.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   Everybody Can Pause Pools",
        "body": "  In the second version of the code, a pool will be paused, if during a user's burn, the amount of AgTokens to  be  burned  is  higher  than  the  stocks  users  of  the  collateral.  However,  there  is  no  check  whether  the user  actually  owns  the  necessary  amount  of  AgTokens.  Thus,  any  user  can  specify  a  high  amount  to burn  to  pause  the  contract.  The  pool  will  remain  paused  until  the  governance  unpauses  this  change. Malicious parties could act as follows:   Stableholders: In case of expected collateral price drop can pause to make HAs and SLPs lose.   SLPs: A SLP providing much liquidity in a state with much HA capital could pause the contract to  keep other SLPs from entering the protocol so that his profit is maximized.   HAs:  HAs  can  front-run  liquidations  and  force-cashouts  by  pausing  the  contract.  Ultimately,  that  could lead to a highly unbalanced state.  In  conclusion,  anybody  can  pause  the  protocol  at  any  time.  Such  actions  could  be  profitable  for  the parties and could throw the system into an unhealthy state if they are executed repeatedly.    When  the  amount  of  AgTokens  burned  exceeds  the  stocksUsers,  the  transaction  reverts  instead  of pausing the contracts.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.6   Incorrect Check During ",
        "body": " removeFromPerpetual  The function removeFromPerpetual contains the following check:  // Withdrawing collateral should not make the leverage of the perpetual too important perpetual.committedAmount * BASE_PARAMS <= (perpetual.margin - amount) * maxLeverage,  The  maxLeverage  check  is  performed  based  on  perpetual.margin  -  amount,  however,  in  case the  cashOutAmount  <  perpetual.margin  then  this  check  underestimates  the  actual  leverage. Hence, a perpetual above the leverage limit might go undetected.    Now, an additional check was added to ensure that the new cashout amount is not exceeded.  Angle - Angle Protocol -   22  DesignMediumVersion2CodeCorrectedDesignMediumVersion2CodeCorrected                  \f7.7   Incorrect Handling of profitFactor  The  profit  factor  serves  to  reduce  the  profit  keepers  can  make  from  calling  harvest.  Thus,  following condition occurs:  profitFactor * rewardAmount < want.balanceOf(address(this)) + profit  This condition needs to be fulfilled for a reward payment to be made and is hence quite important.  Incorrectly, the condition is unaware of the decimals of the tokens since profitFactor is initialized to be 100 for any pair. Moreover, it is unaware of the prices of the tokens.  The decimal unawareness may cause the following behaviour:   Assume  the  reward  token  is  USDC  (6  decimals)  and  the  want  token  is  DAI  (18  decimals).  The condition  will  almost  always  pass  since  profit  factor  does  not  account  for  the  base  differences between the tokens.   Assume the reward token is DAI (18 decimals) and the want token is USDC (6 decimals). Then, this condition  will  almost  never  pass  to  since  the  reward  amount  will  already  be  much  larger  than  the right-hand-side.  The price unawareness may cause the following behaviour:   Assume the reward token is AgEUR and one strategy's want token is DAI while for the second one the want token is WETH. If now both strategies have similar balances and profits (when converted to USD), they will still be treated very differently.  To  conclude,  inconsistencies  in  the  keeper  reward  payouts  between  strategies  could  occur  since  the above condition is unaware of the decimal representation and prices of the tokens.    profitFactor  has  been  removed.  Now,  a  minimum  amount  minimumAmountMoved  denotes  how much needs to be at least in the contract plus the profits. Also, this amount and the reward amount are set jointly now to prevent errors.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.8   Potentially Incorrect Strategy Report",
        "body": "  Calling the harvest function on a strategy contract may result in a bad report to the pool manager. If the reward  token  the  keepers  receive  is  equal  to  the  want  token  of  the  strategy,  then  the  transfer  to  the keeper can be successful even though no specific allocation of funds to the strategy for the rewards was made.  Incorrectly,  the  keeper's  fee  will  still  be  part  of  the  reported  profit  as  the  profit  is  computed beforehand and not adjusted.    In the constructor of the strategy it checked that want and reward token are not the same.  Angle - Angle Protocol -   23  CorrectnessMediumVersion2CodeCorrectedCorrectnessMediumVersion2CodeCorrected                \f7.9   Reentrancy When Creating Perpetual Position  When creating a new perpetual position there is a possibility for a reentrancy attack. During the mint() operation of the token a callback is triggered that can be used for a reentrancy attack.  Among other things, possible consequences of such an attack could be:  that the coverage exceeds the expected values  that a non-liquidatable perpetual exists  that a mismatch between NFTs and positions exists    The call to _mint() is done after all state changes.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.10   Adding to Unhealthy Perpetual Liquidates",
        "body": " and Consumes New Collateral  addToPerpetual() allows a hedging agent to increase the cash out amount of the perpetual. Should a hedging agent attempt to add collateral to an unhealthy perpetual, the perpetual is liquidated while the collateral  amount  intended  to  increase  the  position  is  transferred  to  the  pool  manager  contract  without being accounted for.  Unaware  users  are  at  risk,  especially  as  a  hedging  agent  may  attempt  to  increase  the  collateral  of  a position which is just short of being liquidated. Any oracle update now may change the situation and the perpetual can be liquidated while the hedging agent loses his added collateral to the pool manager.    Attempting to add collateral to an unhealthy perpetual results in the perpetual being liquidated, which is intended. In this case, the new collateral amount however is no longer transferred to the pool manager in the updated code.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.11   Broken/Partial ERC165 Support",
        "body": "  Through inheritance, mostly when inheriting AccessControl or AccessControlUpgradable multiple contracts inherit ERC165.  This contract implements the ERC165 standard which defines a standard method to publish and detect what interfaces a smart contract implements.  function supportsInterface(bytes4 interfaceID) external view returns (bool);  The more derived contracts of Angle with the exception of the PerpetualManager contract, that does it partially,  do  not  expand  or  overwrite  this  function.  Hence,  their  functionality  is  not  included  and supportedInterface() will not return true for the public/external functions they implement.  Angle - Angle Protocol -   24  SecurityMediumVersion2CodeCorrectedDesignMediumVersion1CodeCorrectedDesignMediumVersion1CodeCorrected                         \fEither the more derived contracts should implement this function in order to make complete the ERC165 functionality  or  if  this  is  not  required,  overwrite  supportsInterface()  with  an  empty  function  which would even slightly reduce the contract's code size.    Angle  forked  the  code  of  AccessControl  and  AccessControlUpgradaeable  and  removed  the ERC165 support. The only contract which implements the ERC165 interface is the PerpetualManager as it emits the perpetual futures as ERC721-NFTs. The supportsInterface function will return true for all interfaces it implements.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.12   Conversion of Locked Interest to SanRate in",
        "body": " the Same Block*  *While the review was ongoing Angle informed us about this issue independently in parallel.  _updateSanRate() consists of two parts: In the first half the locked interest accrued in previous blocks are added to the sanRate while in the second part the new amount of tokens to be distributed are added to the locked interests. These should be distributed in the next block this function is executed.  lastBlockUpdated however is only updated if some of the locked interest where added to the sanRate in this block.  This leads to following corner case when _updateSanRate() is executed: In case there are no locked interest to distribute, lastBlockUpdated is not updated to the current block.timestamp but rewards to be distributed are added to lockedInterests. However a second call to _updateSanRate() will now convert these lockedInterests and add them to the sanRate before updating lastBlockUpdated blocking a future update in this same block.  The  sanRate  is  updated  upon  collection  of  profit  from  strategies  or  when  a  part  of  the  fees  for  stable seeker is distributed to standard liquidity provider.  The profit from strategies can be attacked as follows:  At a time where lockedInterests is equal to zero and a strategy has a significant amount of rewards to collect, the attacker executes the following steps:   Deposits  a  large  amount  of  collateral  (e.g.  acquired  through  a  flashloan)  for  San  Tokens.  While updateSanRate()  is  called,  this  currently  has  no  effect  as  lockedInterests  is  equal  to  zero and the amount to distribute is 0, so lockedInterests remains zero.   Call  harvest()  on  the  Strategy.  This  collects  the  profit  and  executes  _updateSanRate().  As currently  no  locked  interests  are  to  be  distributed,  the  first  part  is  skipped  and  lastBlockUpdated` remains unchanged. In the second part the  lockedInterests to be distributed in the future are updated.   Withdraw  the  collateral  by  burning  the  san  tokens.  _updateSanRate()  is  executed  once  again, this  times  with  lockedInterests  being  nonzero  the  sanRate  is  now  actually  updated  and lastBlockUpdated is set to the current block. Hence the user can withdraw more collateral than deposited.  This may be abused to drain the profit of the strategy.  Note that this is a rough description only and the actual execution of this attack is a bit more complicated: In order to extract most of the protocols interest more calls will be needed than described above. As the initial deposit() by the attacker will have significantly increased the amount of total assets available to  Angle - Angle Protocol -   25  SecurityMediumVersion1CodeCorrected        \fthe PoolManager, the PoolManager will push a lot of funds into the strategy during the call to report (in order  to  keep  the  planned  debtRatio).  Hence  the  withdraw()  cannot  really  withdraw  sufficient amounts. Multiple calls with carefully crafted arguments to withdraw() and harvest() are necessary to complete the attack successfully and repay the flashloan.    lastBlockUpdated is now updated each time updateSanRate() is executed, this prevents the issue described above.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.13   Governance Not Fully Propagated",
        "body": "  The documentation specifies the following:  The Core contract has the ability to add a new governor or remove a governor from the system and propagate this change across all underlying contracts of the protocol.  Similarly, the Core contract should propagate guardian changes. However, that is not the case for some contracts.  For  example,  the  changes  are  not  propagated  to  OracleMulti  or  RewardsDistributor.  That mismatches  the  specification.  Fortunately,  the  governance  can  use  functions  grantRole()  and revokeRole() to perform the changes jointly with the functions from Core.  Specification changed:  The documentation has been updated and now describes how the governance change propagates from the Stablemaster. Additionally the code of the core contract now contains following comment:  Keeps track of all the StableMaster contracts and facilitates governance by allowing the propagation include  oracle  contract, of  changes  across  most  contracts  of  RewardsDistributor, and some  the  protocol   (does  not   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.14   Guardian Cannot Be Managed by Guardian",
        "body": "  The documentation specifies the following:  The guardian is indeed able to transfer its power to another address or to revoke itself.  However,  that  is  not  possible.  Core  functions  setGuardian  and  revokeGuardian  call  the  inherited grantRole() and revokeRole(). The administrator of the guardian role is the governor role. Thus, the calls grantRole() and revokeRole() would fail since the guardian is not allowed to access these and the guardian cannot set or revoke guardians.    Access control has been reimplemented. In the new implementation the guardian can transfer its power to another address or revoke itself.  Angle - Angle Protocol -   26  CorrectnessMediumVersion1Speci\ufb01cationChangedCorrectnessMediumVersion1CodeCorrected                  \f7.15   Incorrect Cash Out Amount  Existing  perpetual  positions  can  be  updated.  Any  perpetual  position  that  is  modified  through addToPerpetual or removeFromPerpetual results in the wrong cashOutAmount. Please consider the following example in which all transactions happen shortly after each other. Hence, we assume that the oracle prices do not change and are 1000 and 1125 respectively. Please note that changing oracle prices can make the problem worse. We will also ignore fees in this example.  1. A new position is created and its cashOutAmount = 10 ETH, while committedAmount = 20 ETH.  The initialRate = 1125.  2. The  position  is  updated  through  addToPerpetual  and  1  ETH  is  added.  The  new  committed amount  is  calculated  as  20  ETH  *  1125  /  1000  =  22.5  ETH.  Hence  the  new  cashOutAmount  is calculated as 20 ETH + 10 ETH - 22.5 ETH + 1 ETH = 8.5 ETH. The initialRate remains 1125.  3. The  user  performs  a  cash  out  using  cashOutPerpetual.  The  newly  committed  amount  is calculated as 20 ETH * 1125 / 1000 = 22.5 ETH. Hence the new cashOutAmount is calculated as 20 ETH + 8.5 ETH - 22.5 ETH = 6 ETH. Therefore, the user receives 6 ETH, despite depositing 11 ETH.  In short, whenever the oracle rates significantly deviate from each other, users can lose significant value. This issue can grow in severity with fees, repetitive operations and price fluctuations.    This issue has been addressed by only storing the initial rate. Hence, errors can no longer accumulate with the number of actions.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.16   Non 18 Decimals Protocol Tokens",
        "body": "  The documentation states:  Decimals  To be consistent with the BASE chosen when computing numbers, it has been decided that all the ERC20 tokens created by the Angle protocol would involve 18 decimals.  Although this is not specified anywhere in the code, this means that the base for agTokens and sanTokens is 18.  The  decimal  of  the  sanToken  however  is  set  equal  to  the  decimal  of  the  underlying  collateral.  For collaterals with decimals different than 18, the sanTokens decimal will not be equal to 18.  function initialize(     string memory name_,     string memory symbol_,     address poolManager ) public initializer {     __ERC20Permit_init(name_);     __ERC20_init(name_, symbol_);     stableMaster = IPoolManager(poolManager).stableMaster();     decimal = IERC20MetadataUpgradeable(IPoolManager(poolManager).token()).decimals(); }  Angle - Angle Protocol -   27  CorrectnessMediumVersion1CodeCorrectedCorrectnessMediumVersion1Speci\ufb01cationChanged              \fSpecification changed:  The developer documentation will be changed to accurately reflect this.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.17   Unaccounted Collateral, Unrestricted ",
        "body": " updateStocksUsersGov()  Function updateStocksUsersGov of a stablemaster contract allows the Guardian / the Governance to update col.stocksUsers arbitrarily. There are no checks at all, e.g. whether the update respects the actual amount of free collateral available.  This variable is described as:  // Amount of collateral in the reserves that comes from users // + capital losses from HAs - capital gains of HAs  While  col.stocksUsers  is  updated  as  described  during  the  actions  of  stable  seekers  and  hedging agents an additional function updateStocksUsersGov exists allowing the Guardian / the Governance to change this variable arbitrarily.  Amongst others, this function is annotated with  Updates the `stocksUsers` for a given collateral to allow or prevent HAs from coming in This function can typically be used if there is some surplus that can be put in `stocksUsers`.  The system surplus arises due to the fees collected by the system. When minting or burning stablecoin only a part of the fee collected is incorporated into the sanrate. The rest remains as surplus collateral in the  poolmaster  contract.  When  creating  or  cashing  out  a  perpetual  a  fee  is  taken.  This  fee  collected resides in form of unaccounted for collateral at the poolmaster. A part of the fee must be set aside while the perpetual is active as it may be needed to pay the keeper slashing this perpetual.  Note that not all balance of the collateral token held by the poolmaster is available to use freely. Some of this balance may belong to standard liquidity providers.  Overall  there  is  no  automatic  accounting  of  the  fees  collected,  the  system  rather  relies  on  a  manual update where the caller can freely specify the parameter. The description of the function hints that the function  may  be  used  to  steer  whether  to  allow/prevent  more  HAs  from  coming  in.  Note  this  can  also steer  whether  perpetual  can  be  cashed  out  forcefully.  Allowing  the  update  of  this  value  without  any checks may let the system reach an incorrect state.    The  function  name  was  changed  to  rebalanceStocksUsers.  It  reduces  the  stocksUsers  of  one collateral and adds it to another one. However, the cap for the maximum stocks users value cannot be exceeded with this operation. Hence, the number of stablecoins minted in total stays the same. For more information see the description of System Accounting.  Angle - Angle Protocol -   28  CorrectnessMediumVersion1CodeCorrected          \f7.18   Unit Errors for Tokens With Decimals Different Than 18  Perpetuals  earn  a  reward  in  form  of  governance  tokens.  Additionally  the  staking  contract  may  allow AgToken and SanToken to be staked in order to earn governance tokens. For both, the calculation of the reward does not work correctly for collaterals with decimals different than 18.  Using the example of the PerpetualManager, the reward per committed collateral token of the perpetual is calculated as follows:  function _rewardPerToken() internal view returns (uint256) {     if (totalCAmount == 0) {         return rewardPerTokenStored;     }     return         rewardPerTokenStored + ((_lastTimeRewardApplicable() - lastUpdateTime) * rewardRate * BASE) / totalCAmount; }  and  function _earned(uint256 perpetualID) internal view returns (uint256) {     return         (perpetualData[perpetualID].committedAmount *             (_rewardPerToken() - perpetualRewardPerTokenPaid[perpetualID])) /         BASE +         rewards[perpetualID]; }  The  governance  token,  the  angle  token  has  18  decimals.  Hence  rewardPerTokenStored  and  the returned value of _rewardPerToken() should be in 18 decimals as well for the calculation in _earn() to work correctly.  In  both  calculations  however,  BASE  is  used  as  unit  instead  of  the  actual  base  of  the  collateral.  As  a consequence, the calculation breaks for tokens not having 18 decimals.    Now, the calculations are done correctly.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.19   safeApprove Not Used, USDT Not",
        "body": " Supported  some   Since not all ERC-20 tokens adhere to the standard, it is recommended to use safeApprove such that interactions with a broader range of tokens are possible. Especially, this is important since interactions with  function _changeTokenApprovalAmount  in  PoolManagerInternal.sol  a  simple  approve  call  is  made  with regards to the underlying pool tokens. As this method is used during the deployment of some collateral to give  infinite  approval  to  the  perpetual  manager  and  the  stable  master,  this  means  that  USDT  pools cannot be deployed.  safeApprove.   However,   tokens,   require   USDT,   e.g.   in     Angle - Angle Protocol -   29  CorrectnessMediumVersion1CodeCorrectedDesignMediumVersion1CodeCorrected              \fThe new version of the code now uses either safeApprove or safeIncreaseAllowance.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.20   BondingCurve Specification Mismatches",
        "body": "  There  are  several  mismatches  between  the  implementation  of  BondingCurve  and  its  documentation. Examples are:   The power parameter is fixed in the implementation. However, it is not stored anywhere but instead the  formulas  have  been  implemented  assuming  power  to  be  two.  In  contrast,  the  specification states only that power should be strictly greater than one.   The documentation specifies that the guardian should have the same powers as the governors with  the exception of recovering tokens.   Moreover, the code is divided in different sections. changeOracle() is in the guardian role section. Both documentation and code structuring imply that this function should be callable by the guardian. However, only governors can call this function.  The inconsistencies may confuse users.    The specification has changed for the power parameter while the code has been corrected to restrict the guardian's power.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.21   Gas-inefficient Strategies",
        "body": "  The gas consumption of the strategies could reduced by reducing the storage reads. Some examples of inefficiencies in the strategies are:   _estimateAdjustPosition: the element with the highest and the element with the lowest APR are searched. The code iterates through the lenders array twice and always reads from storage. Storage reads could be reduce by a factor of two.   _removeLender: lenders[i] is read first in the if condition and then in the first line of the if  body.   _withdrawSome: in the while loop the for loop reads always from storage, hence wasting gas.    Gas consumption has been reduced for the functions.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.22   Inefficiency in Binary Search",
        "body": "  The binary search within the _piecewiseLinear function works as follows:  Angle - Angle Protocol -   30  CorrectnessLowVersion2CodeCorrectedDesignLowVersion2CodeCorrectedDesignLowVersion2CodeCorrected                        \fuint256 lower; uint256 upper = xArray.length - 1; uint256 mid = (upper - lower) / 2; while (upper - lower > 1) {     if (xArray[mid] <= x) {         lower = mid;     } else {         upper = mid;     }     mid = lower + (upper - lower) / 2; }  Here the following improvements can be made:  1. The  initial  value  of  mid  is  computed  using  the  wrong  formula  as  the  computation  should  read upper  +  lower  rather  than  upper  -  lower.  However,  it  doesn't  matter  in  the  current  code version  as  lower  is  always  initialized  to  0.  Hence,  it  is  unclear  why  lower  is  part  of  this computation.  2. The value of mid is needlessly computed once at the end of the loop. This could be refactored to  save a computation of mid.  The  gas  savings  of  these  improvements  are  negligible,  however,  they  might  contribute  to  more maintainable code.    The code is now more gas-efficient.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.23   No Slippage Protection in BondingCurve",
        "body": "  The  BondingCurve  contract  allows  the  purchase  of  governance  tokens  (most  likely  Angle  tokens)  in exchange for other tokens. However, the function buySoldToken does not protect users from growing prices.  The  user  could  experience  an  unexpectedly  trade  result  if  they  have  given  a  high  or  infinite approval to the BondingCurve contract.    Users  can  now  specify  the  maximum  amount  of  AgTokens  they  are  willing  to  pay  for  the  specified amount of ANGLE tokens.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.24   Reference Coin Changes May Affect the",
        "body": " Bonding Curve  The BondingCurve contract contains a referenceCoin variable. This referenceCoin can be set to the zero-address by being revoked. This may affect the BondingCurve in several ways:   getCurrentPrice()  will  return  the  price  in  the  reference  coin.  However,  there  is  no  reference  coin.  Angle - Angle Protocol -   31  SecurityLowVersion2CodeCorrectedCorrectnessLowVersion2CodeCorrected                \f buySoldToken() will take the oracle value based on the previous stablecoin. However, having the  0-address suggests that the reference price is currently to be determined.  Similar issues may occur if the referenceCoin is set then to another token. Now, if the oracles are not updated,  the  price  will  differentiate  highly  from  what  governance  would  have  expected.  Also,  the startPrice  variable  is  in  the  currency  of  the  reference  token.  Thus,  it  could  be  possible  that  the bonding curve changes if the start price stays the same when the reference currency changes.    The contract will be paused to give the governance time to change the parameters.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.25   Specification Mismatch in Strategy",
        "body": "  The documentation of rewardAmount specifies in Strategy.sol:  /// @dev If this is null rewards will never be distributed  In contrast, the documentation of setRewardAmount in Strategy.sol specifies:  /// @dev A null reward amount corresponds to reward distribution being activated  However,  if  the  reward  amount  is  null,  then  the  rewards  can  be  eventually  distributed  if  the  reward amount  is  changed.  Moreover,  the  reward  amount  being  null  means  that  the  reward  distribution  is deactivated.  Specification changed:  The specification has been changed to correctly specify the reward amount.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.26   StableMaster Might Be Unnecessarily",
        "body": " Paused  When  the  signalLoss  function  registers  a  loss  exceeding  sanRate  *  sanMint  it  will  pause  the StableMaster contract. However, during this calculation it does not consider any lockedInterests that  were  queued  to  increase  the  sanRate.  Hence,  when  factoring  in  the  correct  sanRate  pausing might not be necessary.    The code has been corrected.  Angle - Angle Protocol -   32  CorrectnessLowVersion2Speci\ufb01cationChangedCorrectnessLowVersion2CodeCorrected                  \f7.27   Cache Value Instead of Reading From Storage  In function update of the PerpetualManager, perpetual.fees is first updated and later read from storage in order be emitted in the event.  Caching the value would result in lower gas used.    Function _update has been removed from the PerpetualManagerInternal contract.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.28   Consistency Checks for Oracles Missing",
        "body": "  ModuleChainlinkMulti  checks  whether  circuitChainlink  and  circuitChainlinkIsMultiplied have  the  same  length.  In  contrast,  ModuleUniswapMulti  does  not  check  this  property  for  Uniswap circuits.    The check was added.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.29   Different Calculation of Cashout Fees",
        "body": "  Should the coverage of a collateral exceed the limit, the fees for withdrawal differ depending on whether the perpetual is cashed out using forceCashOutPerpetual() or cashOutPerpetual():  In forceCashOutPerpetual() the withdrawal fee is computed with a margin of 0 (representing the status before the cashout of this perpetual).  In  cashOutPerpetual()  the  withdrawal  fee  is  computed  based  on  the  new  margin  calculated after the perpetual has been cashed out.    The  structure  of  the  two  functions  has  been  changed.  Both  initially  cashout  the  perpetual  and  then compute the withdrawal fee.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.30   Double Getters",
        "body": "  Angle - Angle Protocol -   33  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                                \fIn  Core.sol,  governorList()  can  be  accessed  through  the  automatically  generated  governorList getter and through the manually implemented getGovernorList(). Having only one getter will reduce code size, gas consumption on deployment, and confusion.  In OracleAbstract.sol, inBase has two getters: the automatically generated one and getInBase().    governorList was made internal and getInBase() was removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.31   Enhance Check During Deployment of",
        "body": " Collateral  deployCollateral()  of  the  StableMaster  contract  checks  that  the  passed  arguments  are  non-zero address before the struct for the collateral is initialized.  Some of these checks may be made more thorough with low effort:  It may be checked whether the collateral token of the perpetual manager matches the collateral.  Furthermore, it is possible to create a shared SanToken for multiple pool managers which may lead to unwanted behaviour. Also the number of decimals of the SanToken is not checked when a new collateral is deployed.  Also the oracle is not checked for compatibility with the pool manager.    Checks were added.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.32   Events Missing",
        "body": "  Even though many events are emitted by the protocol, not all important state changes emit events. For example,  guardians  are  allowed  to  set  a  new  fee  manager  with  function  setFeeManager()  in StableMaster. As this sets a new address as a fee manager, emitting an event could help users notice this  change.  Another  example  is  that  not  all  ERC-721  events  are  emitted.  For  example,  no  events  are emitted for approvals.    ERC-721  event  are  now  emitted.  For  setFeeManager(),  an  event  was  added  to  the  StableMaster contract.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.33   Gas Inefficiencies When Removing From List",
        "body": "  Angle - Angle Protocol -   34  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \fCore  keeps  track  of  governors  and  stable  masters  with  governorList  and  stablecoinList. StableMaster  keeps  track  of  all  pool  managers  with  managerList.  PoolManager  records  all  active strategies in strategyList. Each strategy registers lenders in lenders and RewardsDistributor keeps all staking contracts in stakingContractList.  In all cases, elements from the arrays can be removed. Removing a list item is always done using the following scheme (code from removing a governor in Core).  for (uint256 i = 0; i < governorList.length - 1; i++) {     if (governorList[i] == _governor) {         indexMet = 1;     }     if (indexMet == 1) {         governorList[i] = governorList[i + 1];     } } require(indexMet == 1 || governorList[governorList.length - 1] == _governor, \"governor not in the list\"); governorList.pop();  Assume  the  element  to  be  removed  is  the  first  in  the  array.  That  shifts  all  elements  by  one  position creating many storage reads and writes. Since the order of the array is not system relevant, the item to be  removed  could  be,  if  found,  overwritten  with  the  value  of  the  last  element  in  the  array,  and  the  last entry could then be popped. That would reduce the number of storage reads and writes significantly for large arrays and, hence, reduce gas consumption.    Instead of moving all element, the value of the last entry is written to the position of the element to be removed. Then, the last entry is popped.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.34   Gas Inefficiencies When Searching Lists",
        "body": "  When pushing a new StableMaster to stablecoinList in deployStableMaster() of Core.sol, it is checked if the item to push is already in the array. However, once found the loop continues and does not early  quit.  The  overhead  in  storage  reads  could  be  avoided  in  a  similar  way  as  in  function addGovernor().  Also, the search in _piecewiseLinear() could be optimized. Since xArray is sorted, a binary search may reduce the total number of operations if the array is large enough.    Checking whether an element is pushable to an array is now implemented using a mapping to booleans, faciliating the search. For the piecewise linear interpolation, a binary search was implemented.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.35   Governance Changes",
        "body": "  The documentation specifies the following:  The way a governance change occurs is that it is notified by governance (or by the guardian) to the Core which then propagates this change to all the StableMaster contracts of the protocol. Each StableMaster then notifies the AgToken contract it relates to as well as all the PoolManager.  Angle - Angle Protocol -   35  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \fChanges in governance should be propagated from Core to all other contracts.  However,  usage  of  access  control  functions  inherited  from  OpenZeppelin's  contracts  may  lead  to inconsistencies.  For example following scenarios could occur:  In function removeGovernor in Core.sol, the call reverts if there is only one governor. However, it is still possible to remove the last governor by calling one of the inherited methods renounceRole or revokeRole. Ultimately, the check in removeGovernor() can easily be circumvented.   A governor may change the Core role using grantRole() and revokeRole() for a StableMaster. This may lead to inconsistencies with the core state variable in StableMasterStorage.sol. Moreover, removing or adding a guardian or governor would always revert in such a scenario (if the change is not manually undone). Also, multiple core contracts could be allowed in StableMaster.   A governor could grant or revoke a governor or guardian role to someone in Core. These changes are not propagated and may lead to inconsistencies in governance between the different contracts.    The  core  does  not  inherit  any  access  control  functionality  anymore.  The  access  control  for  Core  was customly implemented. Thus, the issues cannot occur anymore.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.36   Inconsistencies Between Staking Contract",
        "body": "  There are two types of staking contracts. The StakingRewards and the perpetual managers. They have similar  functionality  and  their  staking  mechanism  should  be  similar.  However,  inconsistencies  in  their implementations can be found.  Some of the inconsistencies are:   Difference  in  setNewRewardsDistributor():  The  perpetual  manager  checks  whether  a  new reward distributor contract has the same reward token as itself. StakingRewards does not do that.   Difference in emitting events: In the above function the two contracts emit different events.   Recovered event is not emitted in recoverERC20() in PerpetualManager but in StakingRewards.    The  same  events  are  now  emitted  and  the  RewardsDistributor,  the  only  contract  allowed  to  call  the staking  contracts'  setNewRewardsDistributor(),  checks  whether  the  new  rewards  distributor  has the same reward token as itself.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.37   Inconsistent Parameters in",
        "body": " RewardsDistributor Possible  In  contract  RewardsDistributor  consistency  checks  are  missing  and  some  parameters  could  contradict each other. Examples are:  Angle - Angle Protocol -   36  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                 \f No   check   StakingParameters.updateFrequency  StakingParameters.duration in function setUpdateFrequency.  that   is   smaller   than   No   check   that   StakingParameters.updateFrequency   is   smaller   than  StakingParameters.duration in function setDuration.    Checks were added in the mentioned functions.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.38   Incorrect Comment",
        "body": "  In PerpetualManagerFront.forceCashOutPerpetual() there is a check whether a perpetual can forcefully be cashed out due to the maximal collateralization amount has been exceeded:  // Now checking if too much collateral is not covered by HAs (uint256 currentCAmount, uint256 maxCAmount) = _testMaxCAmount(0, rateUp); // If too much collateral is covered then the perpetual can be cashed out canBeCashedOut = currentCAmount > maxCAmount ? 1 : 0;  The \"not\" in the first comment is incorrect. The code is checking if too much collateral is currently covered by HAs.  Specification changed:  The comment has been corrected to suit the modified force cashout functionality.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.39   Inefficient Structs",
        "body": "  There are multiple structs with multiple uint256 fields. Each of these fields uses a full storage slot of 32 bytes. Storing data in Ethereum is expensive. A significant amount of gas is used when reading from or writing  to  storage.  For  example  struct  SLPData  stores  eight  uint256.  Given  the  nature  of  the  data stored in SLPData all of these variables would not need to be of type uint256. Using smaller datatypes would  allow  to  group  multiple  of  the  variables  into  one  storage  slots.  If  done  appropriately,  this  would reduce the total amount of storage reads/writes resulting in lower gas costs. The same applies for other structs which could be optimized similarly.    Smaller  datatypes  have  been  chosen  for  some  parameters  and,  hence,  gas  consumption  has  been reduced.  Angle - Angle Protocol -   37  CorrectnessLowVersion1Speci\ufb01cationChangedDesignLowVersion1CodeCorrected                  \f7.40   No Check if onERC721Received Is Implemented  Perpetuals are treated as NFTs and are implemented as ERC-721 tokens. Much code is adapted from OpenZeppelin's  ERC-721  implementation.  In  createPerpetual()  of  PerpetualManagerFront.sol, _mint() is is used to mint tokens. The documentation of _mint() specifies that using this method is unsafe  and  _safeMint()  should  be  used.  However,  the  _safeMint()  method  was  removed  when code  from  OpenZeppeling  was  adapted.  The  intention  behind  this  function  is  to  check  if  the  address receiving  the  NFT,  if  it  is  a  contract,  implements  onERC721Received().  Thus,  there  is  no  check whether  the  receiving  address  supports  ERC-721  tokens  and  perpetuals  could  be  not  transferrable  in some cases.    mint() checks if a receiving contract implements onERC721Received().  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.41   No Checks Performed in Constructor",
        "body": "  Contrary  to  the  constructor  of  ModuleChainlinkMulti,  the  constructor  of  ModuleUniswapMulti  does  not perform sanity checks on the length of _circuitUniswap and _circuitUniIsMultiplied.    The check was added to the constructor of ModuleChainlinkMulti.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.42   Outdated Compiler Version",
        "body": "  The project uses an outdated version of the Solidity compiler.  pragma solidity 0.8.2;  Known bugs in version 0.8.2 are:  https://github.com/ethereum/solidity/blob/develop/docs/bugs_by_version.json#L1530  More information about these bugs can be found here: https://docs.soliditylang.org/en/latest/bugs.html  At the time of writing the most recent Solidity release is version 0.8.6 which contains some bugfixes but no breaking changes.    In  the  meantime,  the  compiler  version  has  been  updated  to  0.8.7  which  was  also  set  in  the  hardhat configuration file.  Angle - Angle Protocol -   38  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \f7.43   Overhead Due to Loading Struct Into Memory  loaded   Inside the else branch in function removeFromPerpetual the whole perpetual struct of this perpetual that  only  perpetual.creationBlock  and is  perpetual.committedAmount  are  read  later  on,  loading  the  whole  struct  into  memory  is  an unnecessary overhead.  into  memory.  Given   from  storage     The  code  of  removeFromPerpetual  has  changed  significantly,  loading  from  storage  into  memory  is now more efficient.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.44   Possibly Failing Assert",
        "body": "  In  UniswapUtils.sol  in  function  _readUniswapPool()  an  assert  statement  checks  if  the  cast  of twapPeriod  from  uint32  to  int32  overflowed.  However,  this  may  fail  and,  thus,  consume  all remaining gas. The usage of require, in contrast, would refund the remaining gas to the user.  Actually, the value is checked in the constructor and could be checked in function changeTwapPeriod, removing the need for checking it in every execution of _readUniswapPool().    The  check  is  now  in  the  constructor  and  the  setter.  Moreover,  the  assert  has  been  replaced  with  a require statement.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.45   Potential Confusing ",
        "body": " readLower(uint256 lower)  Function readLower defined in OracleAbstract returns the lower rate if parameter lower is equal to 1 or else the higher rate returned by _readAll().  The  function  name  increases  the  risk  that  the  function  is  used  incorrectly  in  the  future.  It  could  be considered to split this functionality in two functions with distinct names.    readLower() always returns the lower rate. rateUpper() was introduced to get the upper rate and avoid confusion.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.46   Reward Token Issues",
        "body": "  Angle - Angle Protocol -   39  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                              \fThe  documentation  specifies  that  governance  could  decide  to  choose  a  reward  token  different  from ANGLE.  Thus,  RewardDistributor  must  be  generic  in  terms  of  tokens.  However,  some  inconsistencies can be found.   event  ANGLEWithdrawn  is  emitted  in  function  governorWithdrawRewardToken.  The  event  name is inconsistent with the possible use cases.  In  _incentivize(),  the  error  message  in  the  require  statement  specifies  that  an  ANGLE transfer failed. That does not have to be the case since it could be the COMP token.   Function _incentivize uses transfer(). Non ERC-20 compliant tokens may fail, e.g. USDT is unsupported  as  a  reward  token.  Generally  when  interacting  with  unknown  ERC-20  tokens  the safeXYZ  functions  may  be  used.  These  wrappers  allow  a  safe  interaction  with  non-compliant ERC-20 tokens.  Furthermore, since rewardToken cannot be modified, it can be made immutable.    The code, comments and the naming was generalized to fit the general purpose of this class as specified in the documentation. Furthermore, safeXYZ functions are used to support a broader ranger of reward tokens. Also, rewardToken is now immutable.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.47   Specification Mismatch in OracleMath",
        "body": "  The  OracleMath  contract  implements  functionality  for  retrieving  UniSwap  rates.  The  documentation specifies the following:  /// @return rate uint256 representing the ratio of the two assets `(token1/token0) * decimals(token1)`  However,  this  is  not  correct.  The  specification  should  specify  that  the  rate  is  multiplied  with  base 10**decimals instead of the number of decimals.  Specification changed:  The specification was changed to document the correct base.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.48   Unnecessary Double Checks",
        "body": "  The Angle Protocol uses the access control library of OpenZeppelin to restrict access to some functions. However,  some  functions  have  double  checks  whether  a  caller  can  execute  a  certain  function.  This occurs when rights are granted or revoked. For example, in StableMaster.sol in deploy(), the core sets the governors and guardian. First, the onlyRole modifier of deploy() checks whether the caller has the  appropriate  role  or  not.  Then,  for  each  governor  grantRole()  is  called  from  the  access  control library. grantRole() calls the onlyRole modifier. Thus, many redundant checks are executed due to the modifier of deploy() and the repetitive calls to onlyRole modifier in the grantRole() function. Similar inefficiencies occur in other contracts and function with grantRole() and revokeRole().  Angle - Angle Protocol -   40  CorrectnessLowVersion1Speci\ufb01cationChangedDesignLowVersion1CodeCorrected                 \f  OpenZeppelin's access control libraries have been forked and modified such that _grantRole() and _revokeRole()  are  now  internal.  Now,  these,  instead  of  the  public  methods,  are  used  to  avoid double checks.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.49   Updated SanRate When Converting to SLP",
        "body": "  Function convertToSLP of the StableMaster contains following commented out code:  // we could potentially add // _updateSanRate(0, col);  This function is used during the cash out of perpetuals should there be an insufficient amount of collateral available.  It  converts  an  amount  of  collateral  into  santokens,  hence  should  be  treated  equally  as depositing  this  amount  of  collateral.  The  san  rate  should  be  updated  indeed,  this  distributes  accrued interests which have been collected before the collateral of this HA is converted into san tokens.  Note that contrary to the deposit() function, there is no check whether the stablemaster is paused.    The  line  was  uncommented.  Now,  the  sanrate  is  updated  and  it  is  checked  if  the  contract  is  paused. Thus, the behaviour is consistent with deposit().  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.50   Wrong Incentive for Which Perpetuals to",
        "body": " Forcefully Cash Out  Whenever the covered amount of collateral exceeds the maximum allowed amount, keepers can freely choose which perpetuals to liquidate.  The  incentive  for  how  the  perpetuals  to  be  liquidated  are  chosen  may  not  be  ideal.  Although  the maximum  fee  for  the  keeper  can  be  capped  (depending  on  the  parameter  set  by  the  governance),  in general the reward for the keeper depends on the fee the perpetual has paid.   Although fees are variable, generally larger perpetuals have paid more in fees and hence may be  more attractive for keepers  to forcefully cash out.   Using functions addToPerpetual() or removeFromPerpetual() increases the fees paid by the  perpetual and hence increases the  risk of the perpetual to be selected by keepers.  For the system however, it would be more beneficial if keepers choose to liquidate perpetuals which bring the covered amount just short of the limit for the maximum amount to be covered. E.g. the coverage limit may be 90%, however currently 91% is covered. Multiple perpetuals exist, one of them may cover 2% while another covers 20%. In case a keeper cashes out the perpetual that covered 20%, the system now only  has  roughly  70%  of  its  collateral  covered,  significantly  below  the  targeted  90%.  If  the  keeper however  had  chosen  to  cashout  the  smaller  perpetual,  the  resulting  new  covered  amount  would  have been just short of the target.  Angle - Angle Protocol -   41  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedAcknowledged                  \f  The system introduced changes on how fees are computed. Keepers are now earning more fees if they cashout/liquidate perpetuals so that the covered amount is close to the target amount.  Acknowledged:  Since  now  multiple  perpetuals  can  be  liquidated  at  the  same  time,  cashing  out  multiple  perpetuals  will cost more gas than one big one. Angle acknowledged that a commented:  In a future protocol upgrade, we could weight the amount of fees going to keepers by using another piecewise linear function that depends on the number of perpetuals cashed out: this would kill the incentive to only cash out in priority the biggest perpetuals.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.51   capOnStablecoin May Be Violated by",
        "body": " Guardians  capOnStableCoin is documented as follows:  /// @notice Maximum amount of stablecoin in circulation  Assume that currently 1000 AgUSD are minted. Then a guardian may call setCapOnStablecoin and set  capOnStablecoin  invariant AgUSD.totalSupply() <= capOnStablecoin could be violated in such a scenario.  though  no  new  stablecoins  can  minted   to  500.  Even   the     capOnStablecoin  was  removed.  However,  there  is  now  a  cap  on  the  issueable  stablecoins  per collateral for which it is checked that it is always higher than or equal to stocksUser.  Angle - Angle Protocol -   42  DesignLowVersion1CodeCorrected        \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  Hence,  the mentioned topics serve to clarify or support the report, but do not require a modification inside the project. Instead,  they  should  raise  awareness  in  order  to  improve  the  overall  understanding  for  users  and developers.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Frontrunning Keepers",
        "body": "  Keepers  are  responsible  to  keep  the  system  in  balance.  As  an  incentive  they  collect  part  of  the  fees. However, another party could see the transactions coming from the keepers and front run them without much computational effort. The incentive for keepers may be lost.  Note that Angle is aware of this and it's documented in the code above the respective keeper functions:  As keepers may directly profit from this function, there may be front-running problems with miners bots, /// we may have to put an access control logic for this function to only allow white-listed addresses to act /// as keepers for the protocol  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   New BASEFEE Opcode",
        "body": "  The recent hardfork introduced EIP-1559 and EIP-1398. While the first EIP introduces a new fee system for  transaction,  the  later  introduces  a  new  opcode  BASEFEE  allowing  to  query  the  new  basefee parameter of the transaction.  Roughly speaking the previous gasprice now consist of the basefee + a tip. Overall transaction prices are now much more predictable.  Appropriate  Keeper  rewards  should  cover  their  transaction  costs  and  an  additional  incentive.  While previously  the  GASPRICE  opcode  could  not  really  be  used  as  this  opened  possibilities  for  abuse  for miners, the new BASEFEE opcode is now much more suitable. It may be considered to use it as base for the keeper reward calculation.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.3   Oracle-related Issues",
        "body": "  The system uses two different oracles: Chainlink and Uniswap.  In principle these oracles provide reliable data sources, however, it is not impossible to manipulate them. For Uniswap the cost of manipulation depends on the liquidity and the activity within the affected pools.  As  volumes  increase  within  the  system  the  following  oracle-based  attacks  become  possible.  We  split them  between  attacks  that  require  manipulation  of  one  oracle  and  attacks  that  require  manipulation  of both oracles.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.3.1   Single-Oracle Manipulation",
        "body": "   Whenever there is a big mint or burn operation of agTokens, existing system participants have an incentive  to  attack  this  mint  or  burn  with  a  manipulated  oracle.  As  a  result  the  system  will accumulate a surplus. The value of the attack is limited by the value of the mint or burn.  Angle - Angle Protocol -   43  NoteVersion1NoteVersion1NoteVersion1          \f When there an innocent user cashes out a perpetual, existing system participants have an incentive to manipulate an oracle in order to increase the system surplus. The value of the attack is limited by the value of the perpetual position.   A  malicious  user  could  perform  an  oracle  attack  to  liquidate  a  large  percentage  of  the  perpetual positions to collect the keeper fees. The value of the attack is limited by the combined keepers fees of the perpetual positions.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.3.2   Multi-Oracle Manipulation",
        "body": "   A  malicious  user  can  extract  large  amounts  of  collateral  by  manipulating  both  oracles  before performing  an  agToken  burn  operation.  The  value  of  the  attack  is  limited  by  the  total  collateral deposited of this type.   A  malicious  user  can  extract  large  amounts  of  collateral  by  manipulating  both  oracles  before performing a cashout of a perpetual position. The value of the attack is limited by the total collateral deposited of this type.  As seen from the list, some of these attacks increase in impact as the system accumulates more liquidity. Hence, the risk of such attacks grows with the rise of the system and hence needs to be monitored.  Please  note  that  some  of  the  mentioned  attacks  against  other  users  can  be  evaded  through  slippage protections as mentioned in the separate issue above.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.4   Perpetual NFTs May Not Be Composable With",
        "body": " Other Protocols  Perpetual  positions  are  represented  as  NFTs.  That  allows  them  to  be  transferrable.  Thus,  users  may want to sell the NFTs on secondary marketplaces. However, the design of the NFTs is not composable with other protocols.  1. A perpetual is opened and an NFT for it is issued.  2. The user wants to sell the NFT on a marketplace. The NFT is deposited on a marketplace contract.  3. The perpetual is force-closed by a keeper. The NFT is burned.  The  marketplace,  as  the  current  owner,  receives  the  underlying  funds  while  the  NFT  gets  burned. However, the marketplace is unaware of the NFT being burned and the funds being received. Thus, the underlying funds could be lost.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.5   SLPs Timing Their Entry",
        "body": "  Although the san rate is updated before a new standard liquidity provider enters the system, a new SLP may still profit from interest accrued previously:   Due to the maximum update of the san rate in one block there may be some locked interest  which are to be distributed in the next / over the next block.   An outsider may observe the performance of the strategies and may forsee that a call to  Strategy.harvest() will be profitable.  Angle - Angle Protocol -   44  NoteVersion1NoteVersion1        \fIn  both  scenarios  an  SLP  entering  at  the  right  time  may  benefit  from  interests  accrued  before  his participations at the cost of other participants.  To mitigate both, Strategy.harvest() should be called frequently in order to distribute the rewards accrued smoothly.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.6   Setting Variables May Lead to Inconsistent",
        "body": " State  When  setting  a  new  core  from  the  old  core,  it  is  ensured  that  the  governors  and  the  guardian  of  both However, cores  deployedStableMasterMap  is  not  checked.  That  should  be  ensured  in  the  constructor  of  the  new core contract. Otherwise, stable masters could be redeployed.  stablecoinList   Similarly,   checked.   same.   are   the   the   is   Moreover,  a  guardian  can  set  a  new  fee  manager  through  the  stable  master  contract.  However,  it  is never checked whether this fee manager has the same governance structure. The governance structure must be setup in the constructor.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.7   Special ERC-20 Token Behavior May Be",
        "body": " Problematic  Tokens  with  fees  or  rebasing  tokens  may  be  errorneous  if  added  as  collateral.  Some  ERC-20  tokens have transfer fees. Supporting such tokens as collateral for a stablecoin may lead to accounting errors. When a user mints some AgToken in exchange for collateral, he specifies how many collateral tokens should  be  transferred  from  him  to  the  pool  manager.  This  amount  is  used  to  update  stocksUsers. However, the amount received by the pool manager may differ from the amount specified by the user due to transfer fees. Not only would accounting issues occur but also too many AgTokens would be minted. The amount of AgTokens the user would receive depends on the amount he sent but not on the amount the  pool  manager  received.  To  conclude,  the  current  system  will  not  work  as  intended  if  tokens  have fees.  Similarly this applies for rebalancing tokens where the balance of token holders changes.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.8   System Accounting",
        "body": "  Certain system states are not tracked by the smart contracts and need to be tracked by interested users and the operators separately in order to properly react.  1. Bad  debt  and  system  surplus  are  not  obviously  visible  in  the  system  but  can  be  computed  by retracing all the relevant system actions or by through a computation based on system variables and token balances.  2. The  amount  of  stablecoins  minted  against  a  particular  collateral  (which  is  newly  saved stocksUsers)  can,  for  different  reasons,  become  out-of-sync  with  the  actual  backing  collateral. The operators need to step in by adjusting parameters accordingly.  3. Certain stablecoin-collateral imbalances can be rebalanced using the system function, however, this  only works if there is a roughly matching positive and negative imbalance.  Angle - Angle Protocol -   45  NoteVersion1NoteVersion1NoteVersion2            \f4. Certain payments, such as the fees paid by hedging agents are not being accounted but generally support the system's health. Users hence need to query token balances to evaluate collateral value.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.9   The Devil Takes the Hindmost",
        "body": "  Contrary to other similar systems, the loss of the system is not evenly distributed across all participants. For  example,  such  loss  may  stem  from  uncovered  collateral  and  a  decreasing  price,  or  keepers  not liquidating  perpetuals  timely.  In  such  situations,  the  system  continues  to  operate  normally  as  long  as there are sufficient funds available. The first actors redeeming / withdrawing their assets get everything at market  prices  while  slow  users  are  left  behind  as  they  can  no  longer  burn  their  stable  tokens,  redeem their san tokens or cash out their perpetuals due to insufficient funds.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.10   Transferable Perpetuals and Reward",
        "body": "  Perpetual  positions  are  NFT  tokens  adhering  to  the  ERC-721  standard,  hence  perpetuals  are transferable. Note that Perpetuals are eligible to earn a reward. While such a reward is associated with the NFT, holders of the perpetual should be aware that it's to their advantage to claim their reward before transferring the perpetual.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.11   Unbounded Decrease of sanRate",
        "body": "  The sanRate which is the conversion rate of SanTokens cannot increase arbitrarily to limit economic attacks. However, it can decrease arbitrarily when a strategy reports losses. Such a change is harder to exploit by an economic attacker, however, it is still possible if there exists a platform when SanTokens can be borrowed. Through such a borrow operation the sanRate drop can be exploited.  Angle - Angle Protocol -   46  NoteVersion1NoteVersion1NoteVersion2            \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Gas Inefficiencies",
        "body": "  0  0  0  1  addExtraRewards  iterates  over  all  extra  reward  tokens  to  check  whether  the  rewardTokens  array contains them. However, the rewardTokens array is loaded from storage on every iteration. The gas consumption  could  be  reduced  by  caching  the  array  into  memory  or  using  a  set  like  data  structure  for checking whether a token is already present.  Acknowledged:  Avantgarde Finance replied:  We attempted implementing the suggested optimization, but rather than leading to savings, it led to inefficiencies in the most frequent case and a more complex code surface area. The case where Convex extra pool tokens are >1 is extremely rare (the vast majority of Curve pools have 0 or 1 extra rewards tokens), and the extra logic involved with copying `rewardTokens` into memory, validating that it is a unique set, etc makes the refactor more expensive rather than less in the vast majority of cases. For those rare cases, since `rewardTokens` is already accessed in the first loop, all SLOAD operations are already warm lookups, so the gas hit isn\u2019t significant.  Avantgarde Finance - Sulu Extensions II -   10  SecurityDesignCriticalHighMediumLowAcknowledgedDesignLowVersion1Acknowledged            \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings  -Severity Findings   Potential Reentrancy   0  0  0  1  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Potential Reentrancy",
        "body": "  Transfers  modify  balances  of  users.  Hence,  checkpointing  is  required  to  be  performed  before  any balances  modification  to  ensure  fair  distribution  of  rewards.  However,  transfer  functions  are  not reentrancy-protected which offers the following attack vector:  1. Assume a Convex pool staking wrapper contract where one user holds 50 out of 100 tokens while no rewards have been earned so far. Also assume that one reward token has an on-receive-hook to the recipient of the token.  2. Now,   the  attacker  contract  calls  claimRewardsFor()   itself. ___checkpointAndClaim is called internally which harvests the Convex pool and then proceeds to checkpointing and claiming with __updateHarvestAndClaim.  to  send   rewards   to   3. 100  reward  tokens  are  harvested.  The  total  and  the  user  integral  are  updated  accordingly.  The amount to transfer to the attacking contract is 50 reward tokens. However, the claimable amount is set to 0 in storage due to the transfer. Note, that lastCheckpointBalance is not updated.  4. The transfer starts and modifies the balance to 50 and then calls the attacking contracts  hook.  1. The  attacking  contract  reenters  the  wrapper  contract  in  the  reentereable  transfer()  function inherited from ERC20.  2. ___checkpoint   is  called.  Harvesting  Convex  has  no  effect  but  now  __updateHarvest is called.  3. The last checkpointed balance (still 0) and the current balance (now 50) are queried. The  difference implies more rewards.  4. Now, the integrals are updated and so is the claimable amount is now set to 25 for the  attacking contract. The checkpointed balance is now set to 150.  5. The  execution  returns  and  nothing  happens  since  the  checkpointed  balance  is  equal  to  the  balance. No event is emitted.  6. The attacking contract claims his claimable amount. Totally, the attacking contract has claimed 75  instead of 50 reward tokens.  Ultimately,  accounting  issues  occur  since  there  are  less  rewards  available  than  expected.  Also,  some user will potentially not be able to withdraw their LP tokens due to impossible transfers.  Avantgarde Finance - Sulu Extensions II -   11  CriticalHighMediumLowCodeCorrectedSecurityLowVersion1CodeCorrected        \fEven though we specify reward tokens to be regular ERC-20 tokens, it could be possible that, since the future is unforeseeable, ERC-777 tokens could be added as rewards, which would open up such attack vectors. Hence, the underlying issue is that the Checks-Effect-Interaction design pattern is not followed.    The  nonReentrant  modifier  was  added  to  _transfer.  Hence,  all  entrypoints  that  perform checkpointing  are  protected  from  reentrancy.  Additionally,  all  checkpointing  variables  were  made private.  Hence,  more  derived  contracts  are  protected  from  reentrancy  attack  vectors  modifying checkpointing state.  Avantgarde Finance - Sulu Extensions II -   12  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Inefficient Defaulting to _newton_y",
        "body": "  The analytical solution implemented in get_y defaults back to the iterative _newton_y in the following situation:  CS-TRICRYPTO-NG-001  if sqrt_arg > 0:     sqrt_val = convert(isqrt(convert(sqrt_arg, uint256)), int256) else:     return [self._newton_y(_ANN, _gamma, x, _D, i), 0]  However, this means that the _newton_y starts over from scratch and has to recalculate everything from the initial values. Instead, a new method could be written that uses the existing values for a, b, c, and d which calculates K0 using Newton's method to solve the equation: 0 + cK0 + d = 0  0 + bK 2  aK 3  Then,  the  value  for  y  could  be  determined  from  this  result.  This  way,  the  get_y  function  can  return  a useful value for K0 instead of just defaulting to 0. This value can then be used as an initial guess for the next call to newton_D, saving further gas in the future.  Acknowledged:  Defaulting  to  _newton_y()  is  rare  when  running  the  new  code  on  historic  tricrypto  data,  so  Curve accepts the risk of incurring more gas costs in rare edge cases.  Curve - tricrypto-ng -   12  SecurityDesignCorrectnessCriticalHighMediumLowAcknowledgedCodePartiallyCorrectedRiskAcceptedDesignLowVersion1Acknowledged              \f5.2   Typo in Event, Unused Variables  Event  UpdatePoolImplementation  first  argument  called _implementtion_id.  Field  token  in  struct  PoolArray  of  CurveTricryptoFactory  is  unused. Argument calc_price of _calc_withdraw_one_coin() is unused.  in  CurveTricryptoFactory  has   CS-TRICRYPTO-NG-002  Code partially corrected:  The token field of the PoolArray struct was removed. The calc_price argument was removed from the _calc_withdraw_one_coin() function.  The first argument of the UpdatePoolImplementation event was changed to _implemention_id, which is still spelled incorrectly.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   CREATE in Pool Deployment Could Reuse",
        "body": " Addresses on Different Chains  If  the  address  of  the  pool  factory  is  the  same  on  two  blockchains,  then  the  deployment  addresses  of pools will match on different chains, even if the pool parameters are different (different coins). This can result in user mistakes or scam attempts.  CS-TRICRYPTO-NG-003  Risk accepted:  Curve accepts the risk of pool contracts on different chains having the same address.  Curve - tricrypto-ng -   13  DesignLowVersion1CodePartiallyCorrectedSecurityLowVersion1RiskAccepted                \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  0  1  5  10  -Severity Findings  -Severity Findings   Loss of Precision in get_p() for Some Values of A   -Severity Findings   First Depositor Can Manipulate the Share Value to Steal Future Deposits    Safety Parameters Differ Between Factory, Swap, and Math Contract    Simpler Price Calculations    Unsafe Operations    _log2() Returns Incorrect Results   -Severity Findings   Admin Can Set Unsafe Parameters Through commit_new_parameters()    Fee on remove_liquidity_one_coin() Is Computed on Initial Balance   Incomplete Validation of Coins in Factory   Initial Value K0_prev Recalculated Needlessly    Magic Number 10000 Used Instead of Constant A_MULTIPLIER    Math Implementation Cannot Be Upgraded in the Factory    No Getter for Length of Markets List in Factory    Pool Registered Twice in the Markets List for Each Key    Possible Precision Loss in get_y    Redundant Asserts in Call to _newton_y()   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Loss of Precision in get_p() for Some Values",
        "body": " of A  Line 851 of CurveCryptoMathOptimized3.vy performs a division of ANN by 10000:  CS-TRICRYPTO-NG-014  unsafe_div(ANN, 10000)  Value ANN ranges from 2700 to 270000000. The division can incur a substantial loss of precision that affects the return value of get_p(). With ANN = 1707629, the current USDT/WBTC/WETH A value, a price error of close to 1% is returned by get_p()  Curve - tricrypto-ng -   14  CriticalHighCodeCorrectedMediumCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedLowSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCorrectnessHighVersion1CodeCorrected          \f  The  order  of  operation  has  been  modified  so  that  the  division  by  10000  is  performed  when  the denominator has sufficient precision. The relative loss of precision on the c coefficient is now at most of 1e-5.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   First Depositor Can Manipulate the Share",
        "body": " Value to Steal Future Deposits  A malicious user can mint a single wei of shares before any deposit exists, then increase the price of the single  share  through  a  direct  transfer  to  the  pool  followed  by  calling  claim_admin_fees(),  which sweeps unaccounted tokens and recomputes D. The next depositors will suffer severe rounding errors on the number of shares they receive.  The shares distributed for the next deposits are calculated according to  CS-TRICRYPTO-NG-004  d_token = token_supply * D / old_D - token_supply ... d_token -= 1  Since  token_supply  will  be  1,  if  D  is  between  2*old_D  and  3*old_D,  the  tokens  received  by  the victim  will  round  down  to  zero,  but  their  deposit  will  still  be  transferred  to  the  pool.  old_D  is  under complete control of the attacker, who can steal legitimate deposits by investing half of the deposit value.    The  share  value  manipulation  was  enabled  by  being  able  to  call  claim_admin_fees()  to  increase significantly the value of single shares, when the total supply is low. claim_admin_fees() now will not gulp tokens when the total supply is below 10**18. This makes the attack unfeasible, while not affecting general operation, since the total supply in normal conditions will be in the order of magnitude of the D parameter, which is between 10**17 (generally more) and 10**33.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Safety Parameters Differ Between Factory,",
        "body": " Swap, and Math Contract  CS-TRICRYPTO-NG-016  Safety bounds on pools parameters are different in the factory and the math contract.  Some are more restrictive in the factory:  1. MAX_GAMMA is 2*10**16 in the factory and swap, and 5*10**16 in MATH  2. MIN_A is 27000 in the factory and 2700 in MATH and swap  Some are less restrictive in the factory, which may lead to the deployment of invalid pools:  1. MAX_A is 27*10**9 in the factory, but 27*10**7 in MATH and swap  Curve - tricrypto-ng -   15  SecurityMediumVersion1CodeCorrectedDesignMediumVersion1CodeCorrected                \f  1. MAX_GAMMA is 5*10**16 across all contracts.  2. MIN_A is 2700 across all contracts.  3. MAX_A is 27 * 10**7 across all contracts.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Simpler Price Calculations",
        "body": "  The  derivation  of  the  price  calculations  leads  to  more  expensive  calculations  than  necessary.  The  gas costs  of  the  get_p  can  be  greatly  reduced  by  simplifying  the  formula  for  the  price.  For  example,  by defining the value G as follows:  The formula for the price of y with respect to x becomes:  G \u22c5 K0 = 2K0  3 \u2212 K0  2(2\u03b3 + 3) + (\u03b3 + 1)2  CS-TRICRYPTO-NG-017  An efficient implementation of this formula can reduce the costs of the price calculation by around 66%.  py = x y \u22c5  G \u22c5 K0 + N NA\u03b32K0 G \u22c5 K0 + N NA\u03b32K0  y D x D    The suggested formula was implemented in get_p. The _snekmate_mul_div function was removed as it was no longer used.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Unsafe Operations",
        "body": "  Some  multiplications  in  the  get_y  function  are  performed  using  unsafe_mul.  However,  several  of these can potentially overflow:  1. The following multiplication in the calculation of b can overflow:  CS-TRICRYPTO-NG-019  unsafe_mul(unsafe_mul(unsafe_div(D**2, x_j), gamma**2), ANN)  For example with the following values:  D=10**33, x_j=10**31, gamma=5*10**16, ANN=2.7*10**8  In this case, the result is greater than 2**255 and hence overflows the int256 type.    The outermost unsafe_mul, where the second factor is ANN, which could cause an overflow, has been replaced with a safe multiplication.  2. This multiplication occurs when calculating delta1:  unsafe_mul(9, a * c)  Curve - tricrypto-ng -   16  DesignMediumVersion1CodeCorrectedCorrectnessMediumVersion1CodeCorrected                \fIt can overflow when 2**255 / 9 < a*c < 2**255 / 3. Previously, only the multiplication of 3a * c is done using overflow checks.    The expression is now evaluated as 3 * (unsafe_mul(3, a) * c), which is safe.  3. Again in the calculation of delta1:  unsafe_mul(27, a**2)  This can overflow when a**2 is close to 2^255, but not greater. For example, this can occur when b is very close to zero.    The expression has been replaced with 27 * a**2, which is safe.  4. Lastly, the following multiplication in the calculation of sqrt_arg could potentially overflow when  delta0**2 is close to 2^255:  unsafe_mul(4, delta0**2)    The expression has been replaced with 4 * delta0**2, which is safe.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   _log2() Returns Incorrect Results",
        "body": "  Results of function _log2() in CurveCryptoMathOptimized3 are off by one.  CS-TRICRYPTO-NG-009  Example:  In [2]: math.log2_(2**1) Out[2]: 0  In [3]: math.log2_(2**2) Out[3]: 1  In [4]: math.log2_(2**130) Out[4]: 129  In [5]: math.log2_(2**255) Out[5]: 254  In [6]: math.log2_(2**256-1) Out[6]: 254  The only values for which a correct result is produced are x = 0, and x in [2**128, 2**129-1]  In [7]: math.log2_(2**0) Out[7]: 0  In [8]: math.log2_(2**128)  Curve - tricrypto-ng -   17  CorrectnessMediumVersion1CodeCorrected        \fOut[8]: 128  In [9]: math.log2_(2**129-1) Out[9]: 128    The  custom  _log2()  implementation  has  been  replaced  with  Snekmate  log_2().  The  new implementation is correct, except for the value of log2(0), which evaluates to 0 but which ought to be undefined.  In  the  context  where  _snekmate_log_2()  is  used,  which  is  evaluation  of  the  cube  root, returning 0 for log2(0) leads to the correct result.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Admin Can Set Unsafe Parameters Through ",
        "body": " commit_new_parameters()  The  same  bounds  are  not  applied  when  setting  parameters  at  commit_new_parameters().  CS-TRICRYPTO-NG-005  initialization  or  with  mid_fee can be set down to 0 through commit_new_parameters(), but must be at least MIN_FEE in deploy_pool().  allowed_extra_profit  can  be  set  commit_new_parameters(), but it can be at most 10**16 with deploy_pool().  to  values  between  10**16  and  10**18   through  Specification changed:  The  MIN_FEE  check  has  been  allowed_extra_profit has been increased from 10**16 to 10**18  removed   from   the   factory.  Max  value   for  parameter  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   Fee on remove_liquidity_one_coin() Is",
        "body": " Computed on Initial Balance  The fee for remove_liquidity_one_coin() is computed in _calc_withdraw_one_coin() at line 1349 as  CS-TRICRYPTO-NG-015  fee: uint256 = self._fee(xp)  At  this  point,  xp  is  still  the  unchanged  balance  of  the  pool.  Removing  liquidity  with  one  coin  from  a perfectly  balanced  pool,  and  making  it  unbalanced,  will  ask  for  mid_fee.  Making  an  unbalanced  pool balanced by removing liquidity will ask for out_fee. This is the opposite of what should happen.    Curve - tricrypto-ng -   18  DesignLowVersion1Speci\ufb01cationChangedCorrectnessLowVersion1CodeCorrected                \fA  rough  but  gas  inexpensive  calculation  of  the  resulting  balance  is  performed,  for  the  purpose  of calculating the fee. The fee calculation is not exact but more accurate than in the previous version.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   Incomplete Validation of Coins in Factory",
        "body": "  Coins in a pool shouldn't be duplicated, the following line in CurveTricryptoFactory.vy asserts it:  CS-TRICRYPTO-NG-008  assert _coins[0] != _coins[1] and _coins[1] != _coins[2], \"Duplicate coins\"  However,  the  case  where  coins[0]  ==  coins[2]  is  not  covered.  Therefore,  a  pool  could  be deployed with the same coin listed twice.    The missing check has been included.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   Initial Value K0_prev Recalculated",
        "body": " Needlessly  The value K0_prev is used to compute an initial value for newton_D(). In _exchange(), K0_prev is first computed during the call to MATH.get_y(), but is discarded and the same value is recomputed a few lines later in MATH.get_K0_prev(). This is unnecessary since the same value is returned during both calls.  The method get_K0_prev() of CurveCryptoMathOptimized3 is redundant.  CS-TRICRYPTO-NG-018    The  K0_prev  value  obtained  from  MATH.get_y()  is  now  used.  The  get_K0_prev  function  was removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.11   Magic Number 10000 Used Instead of",
        "body": " Constant A_MULTIPLIER  Despite  the  constant  A_MULTIPLIER  being  defined,  code  in  CurveCryptoMathOptimized3.vy  at lines 737, 766, 835, 851 uses the magic number 10000 directly.  CS-TRICRYPTO-NG-010    Curve - tricrypto-ng -   19  SecurityLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \fThe magic numbers have been replaced with the constant.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.12   Math Implementation Cannot Be Upgraded in",
        "body": " the Factory  New  pool  implementations  can  be  deployed  in  the  factory,  but  the  math  implementation  can't  be changed.  The  event  UpdatePoolImplementation  is  unused.  A  new  pool  implementation  using another math contract could still be added to the factory, by changing the hardcoded value of the math contract in the pool implementation's constructor, instead of receiving it from the factory.  CS-TRICRYPTO-NG-011    Function  set_math_implementation  has  been  introduced  in  the  factory  so  that  the  admin  can change the math implementations of newly deployed pools.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.13   No Getter for Length of Markets List in",
        "body": " Factory  Private variable self.market_counts does not have a getter. The only way to know how many pools have been deployed for a coin pair is to iterate find_pool_for_coins() until a zero value is returned.  CS-TRICRYPTO-NG-012    Public function get_market_counts has been introduced to return the market count for a token couple.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.14   Pool Registered Twice in the Markets List for",
        "body": " Each Key  The following logic includes pools in the self.markets[key] list of the factory:  CS-TRICRYPTO-NG-013  for coin_a in _coins:     for coin_b in _coins:          if coin_a == coin_b:             continue          key: uint256 = (             convert(coin_a, uint256) ^ convert(coin_b, uint256)  Curve - tricrypto-ng -   20  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                        \f        length = self.market_counts[key]         self.markets[key][length] = pool         self.market_counts[key] = length + 1  Each coin pair is iterated twice, first as (A,B) and then as (B,A). The keys for the two pairs are the same. As a consequence, each pool is included twice for a certain key.    The code has been refactored so that the three token couples are now individually added.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.15   Possible Precision Loss in get_y",
        "body": "  In the get_y function, additional precision is added conditionally:  CS-TRICRYPTO-NG-007  d0: int256 = abs(unsafe_mul(3, a) * c / b - b)  # <------------ a is smol.  divider: int256 = 0 if d0 > 10**48:     divider = 10**30 elif d0 > 10**44:     divider = 10**26 elif d0 > 10**40:     divider = 10**22 elif d0 > 10**36:     divider = 10**18 elif d0 > 10**32:     divider = 10**14 elif d0 > 10**28:     divider = 10**10 elif d0 > 10**24:     divider = 10**6 elif d0 > 10**20:     divider = 10**2 else:     divider = 1  additional_prec: int256 = 0 if abs(a) > abs(b):     additional_prec = abs(unsafe_div(a, b))     a = unsafe_div(unsafe_mul(a, additional_prec), divider)     b = unsafe_div(b * additional_prec, divider)     c = unsafe_div(c * additional_prec, divider)     d = unsafe_div(d * additional_prec, divider) else:     additional_prec = abs(unsafe_div(b, a))     a = unsafe_div(unsafe_mul(a, additional_prec), divider)     b = unsafe_div(b * additional_prec, divider)     c = unsafe_div(c * additional_prec, divider)     d = unsafe_div(d * additional_prec, divider)  Curve - tricrypto-ng -   21  DesignLowVersion1CodeCorrected        \fHowever,  there  are  some  cases  where  divider  >  additional_prec  and  a  precision  loss  occurs instead. For example, when b \u00bb a, divider can still be as large as 10**18, but additional_prec will be 1. Therefore, up to 18 decimals are removed from a, b, c and d, resulting in a precision loss.  It  should  be  considered  whether  it  is  necessary  to  adjust  the  decimals  in  the  case  where divider > additional_prec.    The  additional  precision  calculations  were  incorrect  in  the  original  version.  The  else  branch  has  been updated to the following:  else:     additional_prec = abs(unsafe_div(b, a))     a = unsafe_div(a / additional_prec, divider)     b = unsafe_div(unsafe_div(b, additional_prec), divider)     c = unsafe_div(unsafe_div(c, additional_prec), divider)     d = unsafe_div(unsafe_div(d, additional_prec), divider)  Curve also provided an explanation for the precision adjustment:  The idea behind this is that a is always high-precision constant 10**36 / 27 while b, c, and d may have  excessive  or  insufficient  precision,  so  we  compare  b  to  a  and  add  or  remove  precision  via additional_prec. But we should also take into account not only difference between a and other coefficients, but their value by themselves (10**36 precision will lead to overflow if coin values are overflow.  The reduce  high),  divider > additional_prec case is fine unless it produces vulnerability.  use  divider   precision   so  we   avoid   and   to   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.16   Redundant Asserts in Call to _newton_y()",
        "body": "  The arguments of get_y() are checked to be in a reasonable range through the following asserts:  # Safety checks assert _ANN > MIN_A - 1 and _ANN < MAX_A + 1, \"dev: unsafe values A\" assert _gamma > MIN_GAMMA - 1 and _gamma < MAX_GAMMA + 1, \"dev: unsafe values gamma\" assert _D > 10**17 - 1 and _D < 10**15 * 10**18 + 1, \"dev: unsafe values D\"  CS-TRICRYPTO-NG-006  The same checks are duplicated when entering the internal function _newton_y(), which is only called in the body of get_y()    The redundant asserts were removed from _newton_y().  Curve - tricrypto-ng -   22  DesignLowVersion1CodeCorrected        \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Funds Could Be Transferred Before Callback",
        "body": "  When  using  exchange_extended(),  a  callback  to  the  caller  is  executed  to  transfer  the  inbound exchange  amount.  The  callback  is  executed  before  the  outgoing  tokens  are  received  by  the  user. Executing  the  callback  after  the  outgoing  tokens  have  been  received  would  allow  more  flexible  use cases, by acting as a flashloan.  Curve - tricrypto-ng -   23  NoteVersion1  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   ChainExitERC1155Predicate No Exit Event",
        "body": "  No  Exit  event  is  defined  in  ChainExitERC1155Predicate.  Hence,  upon  calling  exitTokens  no useful  and  informative  event  gets  emitted.  Furthermore  this  behavior  is  inconsistent  with  the  other predicates.  Specification changed:  Polygon has acknowledged lack of an exit event in ChainExitERC1155Predicate mentioning that:  \"Contract is deprecated and was never deployed.\"  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   ChildChainManager cleanMapToken Emits",
        "body": " Wrong Event  By  calling  cleanMapToken,  a  certain  bijection  mapping  between  root  and  child  tokens  gets  removed. However, the event emitted wrongly indicates a mapping has taken place.    Polygon defined a new event TokenUnmapped which gets emitted once a certain mapping between a root and a child token gets removed.  Polygon - PoS Portal -   13  CriticalHighMediumLowSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedDesignLowVersion1Speci\ufb01cationChangedCorrectnessLowVersion1CodeCorrected                  \f7.3   Unused ExitedERC721Batch Event  ERC721Predicate  defines  event  ExitedERC721Batch,  however;  exitTokens  does  not  support batch exiting of tokens and this event is not used at all.    Polygon has removed the definition of ExitedERC721Batch from their codebase.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   _processMessageFromChild Comment",
        "body": " Incorrect  The  comment  of  _processMessageFromChild()  in  BaseRootTunnel  says  that  is  called  from  the onStateReceive function. This is incorrect. It is actually called from receiveMessage().  Specification changed:  Polygon  has  corrected  the  comments  on  the  function  _processMessageFromChild  saying  that  it  is called from receiveMessage().  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   MetaTransactionExecuted Event Has No",
        "body": " Indexed Arguments  The aforementioned event is defined as  event MetaTransactionExecuted(     address userAddress,     address payable relayerAddress,     bytes functionSignature );  None of its arguments are marked as indexed, which could degrade user experience. Indexing fields of events, e.g. addresses, allows to search for them easily.    Polygon  defined  userAddress  and  relayerAddress  as  MetaTransactionExecuted.  indexed   fields  of   the  event  event MetaTransactionExecuted(     address indexed userAddress,     address payable indexed relayerAddress,  Polygon - PoS Portal -   14  DesignLowVersion1CodeCorrectedCorrectnessLowVersion1Speci\ufb01cationChangedDesignLowVersion1CodeCorrected                      \f    bytes functionSignature );  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.6   Gas Optimisation Issues Informational",
        "body": "  The  codebase  has  several  inefficiencies  in  terms  of  gas  costs  when  deploying  and  executing  smart contracts. Here, we report a list of non-exhaustive possible gas optimizations:  1. ChildMintableERC1155.deposit  performs  a  sanity  check  on  user  !=  address(0)  after decoding depositData. This check however has already been done by the RootChainManager.  2. NativeMetaTransaction.executeMetaTransaction  has  a  visibility  of  public.  As  this function in the current implementation gets called only externally, it ca be defined as external, which subsequently  lets  memory  location  of  functionSignature  be  calldata.  In  this  way,  gas consumption can be reduced.  3. UpgradableProxy.updateImplementation checks _newProxyTo is non-zero. However, the  exact same check is done when calling into isContract.  4. UpgradableProxy.updateAndCall  is  a  public  function.  Its  visibility  can  be  changed  to  external letting its argument data be defined as calldata.  5. RootChainManager.receive  calls  into  _depositEtherFor  with  _msgSender  as  the  input argument. However, given the fact that sending ETH does not happen through a meta transaction, simply using msg.sender can be used.  6. ITokenPredicate.exitTokens takes an address as its first argument (sender). However, this  argument is never used in any implementation of the token predicates.  7. exitTokens  function  for  tokens  with  multiple  transfer  signatures  is  implemented  as  an  if-else body, and in each branch same flow of subfield extractions is done. To reduce code footprint, these operations can be moved out of if-else and only logic be kept in each branch.  8. exitTokens  function  in  call  predicates  can  have  an  external  visibility  and  calldata  memory  location for it log argument.  9. In  mintable  version  of  each  token,  inside  an  if-else  statement,  it  checks  whether  an  excessive amount  should  be  minted  and  then  transfers  the  actual  amount  to  the  receiver.  Calling  transfer functions can be done outside of if-else to decrease code footprint and reduce deployment cost.  10. NativeMetaTransaction.getNonce,  which  returns  current  valid  nonce  of  each  user.  As  this  view function gets called only externally, its visibility can be changed to external.  11. ChainExitERC1155Predicate.exitTokens  checks  the  withdrawer  is  not  address  zero. However, as the log data fed to it comes from a valid burn event on the child chain, from cannot be zero.  12. BaseChildTunnel.onStateReceive can be defined as external with message having calldata  type.  13. BaseRootTunel.receiveMessage  is  never  called  internally.  Therefore,  it  can  be  define  as  external with inputData being calldata.    Polygon has addressed most of the gas optimisation issues. However, for those below they have decided to keep the code as-is:  Polygon - PoS Portal -   15  Version1CodeCorrected    \f1. \"That is correct but we are in favour of retaining this as an assertion.\"  5. \"some relayers support ETH metatxs, retaining for backwards compatibility.\"  7. No further explanations.  9. No further explanations.  11. \"That is correct but we are in favour of retaining this as an assertion.\"  Polygon - PoS Portal -   16       \f8   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Enhance Documenation of Inline Assembly",
        "body": "  Code  forked  from  Biconomy  is  used  to  implement  support  for  Meta  Transactions.  The  assembly  in function msgSender() used to retrieve the sender of the message is not as trivial as it might look. The comment documenting the code section is not appropriately describing what's happening.  if (msg.sender == address(this)) {     bytes memory array = msg.data;     uint256 index = msg.data.length;     assembly {         // Load the 32 bytes word from memory with the address on the lower 20 bytes, and mask those.         sender := and(             mload(add(array, index)), //@okaudit-issue todo investigate calculation here, what data do we read?             0xffffffffffffffffffffffffffffffffffffffff         )     }  Intuitively the code seems to read 32 bytes past the end of msg.data. However, note that for variable length  data  in  memory  solidity  uses  the  first  32  bytes  to  store  the  length  of  the  data.  Hence, mload(add(array, index)) loads the last 32 bytes of msg.data and the code works correctly. Due to the delicate nature of assembly within Solidity, this might be documented appropriately.  Polygon - PoS Portal -   17  InformationalVersion1  \f9   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "9.1   ChildERC721 Static domainSeparator",
        "body": "  In  all  variants  of  ChildERC721,  once  and  only  once  upon  deployment,  domainSeparator  gets calculated using the name of token and chain ID:  domainSeperator = keccak256(     abi.encode(         EIP712_DOMAIN_TYPEHASH,         keccak256(bytes(name)),         keccak256(bytes(ERC712_VERSION)),         address(this),         bytes32(getChainId())     ) );  However, in RootChainManager and UChildERC20, a functionality is devised to let recomputation of domainSeparator,  e.g.  when  name  of  token  gets  updated.  Despite  the  fact,  that  forking  and  a consequent change of chain ID may not be very possible, implementing this functionality in derivations of ERC721Child could make the system more robust.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "9.2   Exiting MintableERC721",
        "body": "  MintableERC721Predicate offers several exit possibilities:   TRANSFER_EVENT_SIG   WITHDRAW_BATCH_EVENT_SIG   TRANSFER_WITH_METADATA_EVENT_SIG  Due to the uniqueness of an NFT (tokenID) a token can only exist once. However, please consider all withdrawal  options  emit  the  Transfer  event  on  the  child  chain  and  hence  all  can  be  exited  using  the TRANSFER_EVENT_SIG. This has the following consequences:  For an exit initiated using:   withdrawBatch: If one transfer has been exited using the TRANSFER_EVENT_SIG, all transfers of  the batch must be individually exited using their individual transfer event.   withdrawWithMetadata: If the TRANSFER_EVENT_SIG is used for the exit, the metadata is lost.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "9.3   Minting of ERC721 Tokens",
        "body": "  Polygon - PoS Portal -   18  NoteVersion1NoteVersion1NoteVersion1          \fWhen  using  ChildMintableERC721  and  MintableERC721Predicate,  it  is  important  that  only  the predicate has minting rights for the token on the root chain.  On the child chain ChildMintableERC721 allows addresses holding an admin role to mint tokens with arbitrary token ID's given they do not exist on the child chain and have not been withdrawn to the root chain yet.  This protection is only effective when no arbitrary token can be minted on the root chain.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "9.4   Recipient of Withdrawn Tokens",
        "body": "  None of the withdraw functions of the child tokens allows to specify the recipient on the root chain. The recipient address is the token owner on the child chain.  It is important to ensure one can access these tokens on the root chain before initiating the withdrawal. Although this generally is not an issue for EOAs, special care must be taken for contracts.  For ERC721/ERC1155 if the recipient is a contract, the contract must implement the appropriate interface or the tokens may be stuck in the bridge as they cannot be exited successfully.  Polygon - PoS Portal -   19  NoteVersion1    \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Default Arguments Evaluated Incorrectly for",
        "body": " Internal Calls  Internal  calls  with  default  arguments  are  compiled  incorrectly.  Depending  on  the  number  of  arguments provided in the call, the defaults are added not right-to-left, but left-to-right. If the types are incompatible, typechecking is bypassed. In the bar() function in the following code, self.foo(13) is compiled to self.foo(13,12) instead of self.foo(13,1337).  CS-VYPER_MARCH_2023-001  @internal def foo(a:uint256 = 12, b:uint256 = 1337):  Vyper - Vyper Compiler -   10  SecurityDesignCorrectnessCriticalHighMediumLowCorrectnessHighVersion1            \f    pass  @internal def bar():     self.foo(13)  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Out of Bound Memory Accesses With",
        "body": " DynArray  Access  to  invalid  memory  can  be  performed  through  the  use  of  DynArray  assignments  and  mutating operations.  In  the  following  code  snippets,  uninitialized  memory  can  be  read.  Since  memory  frames  are  reused between function calls, that memory can contain information belonging to other functions.  CS-VYPER_MARCH_2023-002  Literal assignment to ``DynArray``:  @internal def foo():     c:DynArray[uint256, 1] = []     c = [c[0]]  In the previous example, in line c = [c[0]], the out-of-bound access check is perform after having set the length of c to 1. The check succeeds but the memory is uninitialized.  append:  @internal def foo():     c:DynArray[uint256, 1] = []     c.append(c[0])  In the previous example, c.append(c[0]) reads uninitialied memory, but the bounds check succeed because .append() increases the length of c before evaluating its arguments.  Furthermore, writing to locations beyond an array length is possible with the use of pop().  pop:  @internal def foo():     c:DynArray[uint256, 1] = [1]     c[0] = c.pop()  Here the check to write to c[0] is performed before the length of the array is reduced by pop() to 0. It should revert but it succeeds.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   StringT Not Handled in HashMap Access",
        "body": "  Vyper - Vyper Compiler -   11  SecurityHighVersion1CorrectnessHighVersion1            \fThe code generation for index HashMap index should treat in the same way StringT and BytesT. The condition  at  line  337  of  vyper.codegen.expr  only  checks  isinstance(index.typ,  BytesT), instead of isinstance(index.typ, _BytesArray). BytesLike got incorrectly turned into BytesT in  the  context  of  PR3182.  As  a  consequence,  the  pointer  to  a  string  is  used  to  access  a  HashMap, instead of its hash.  CS-VYPER_MARCH_2023-003  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.4   Skip_Contract_Check Skips Return Data",
        "body": " Existence Check  CS-VYPER_MARCH_2023-004  When  calling  an  external  function,  the  contract  existence  check  can  be  skipped  with  the  keyword argument skip_contract_check. The skip_contract_check however also bypasses the checks that the external function call returned the right amount of data, by foregoing the following assert (line 111 of vyper.codegen.external_call) :  [\"assert\", [\"ge\", \"returndatasize\", min_return_size]]  Since the arguments buffer is reused as the return data buffer for the external call, if the called contract does not return data, the unchanged input data is mistaken as the output data of the called function.  As  an  example,  we  are  calling  address  0  with  function  selector  for  f(uint256,uint256)  and arguments  1337  and  6969.  The  call  should  revert,  because  it  resulted  in  no  return  data,  or  at  most  it should return (0,0). However the call returns (1337, 6969). The only reason for this is that the argument buffer is reused as the return buffer.  interface A:     def f(a:uint256, b:uint256) -> (uint256, uint256): view  @external @view def foo() -> (uint256, uint256):     return empty(A).f(1337, 6969, skip_contract_check=True)  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.5   String to Bool Conversion Incorrect",
        "body": "  The  to_bool  conversion  of  _convert.py  accepts  StringT,  which  should  be  treated  likely  like BytesT. However it receives the same treatement as value types, so the pointer is converted to a bool (is zero comparison).  CS-VYPER_MARCH_2023-005  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.6   BytesT to BytesM_T Conversion Can Perform",
        "body": " Invalid Memory Access  CS-VYPER_MARCH_2023-006  Vyper - Vyper Compiler -   12  DesignMediumVersion1CorrectnessMediumVersion1DesignLowVersion1                  \fAn out-of-bound memory access is performed, with no consequences, when converting from an empty byte sequence (b\"\") to bytes32.  The following code:  @internal def f() -> bytes32:    return convert(b\"\", bytes32)  generates the following IR:  /* convert(b\"\", bytes32) */ [with,   arg,   /* b\"\" */ [seq, [mstore, 64, 0], 64],   [with,     bits,     [shl, 3, [sub, 32, [mload, arg]]],     [shl,       bits,       [shr, bits, [mload, [add, arg, 32]]]]]]  An mload to arg + 32 is performed, which is out of bounds with respect to the memory size allocated, which is of 1 word for a bytestring of length 0. However, the loaded value is accessed only after shifting it by 256 bits, which means it is zeroed, and its value does not leak to the user.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.7   Contract With Only Internal Functions Is",
        "body": " Executable  If a contract only has internal functions, beside the constructor, it might still compile to executable code. Internals are not pruned, and execution of the internal functions section is not guarded. Upon calling the contract, execution will start at the first internal function. The execution will however generally fail when POPping the RETURN_PC from the stack, which should be empty upon function exit.  CS-VYPER_MARCH_2023-007  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.8   Cost of Memory Expansion for Callees Always",
        "body": " Payed  For functions that perform internal calls conditionally, the gas cost of the memory expansion caused by the  internal  call  is  payed  even  when  the  internal  functions  are  not  called,  because  the  caller  memory frame is placed at higher memory addresses than the the callees memory frame.  CS-VYPER_MARCH_2023-008  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.9   Dead Code",
        "body": "  Vyper - Vyper Compiler -   13  CS-VYPER_MARCH_2023-009  DesignLowVersion1DesignLowVersion1DesignLowVersion1                  \fArgument  constant_override  of  method  FunctionSignature.from_definition  defined  in vyper.ast.signatures.function_signature is unused throughout the codebase.  Function  parse_Name  in  vyper.codegen.stmt  is  likely  never  executed,  as  a  Name  can't  be  a statement. The vdb directive seems to be a left-over from long ago.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.10   IR Labels for Different Functions Can Collide",
        "body": "  Labels for goto statements are generated in vyper.ast.signatures.function_signature. The function _ir_identifier is in charge of generating unique IR labels for every function. Depending on the  function  and  the  type  names,  different  functions  can  generate  the  same  labels.  IR  generation  will succeed but assembly generation wil fail.  CS-VYPER_MARCH_2023-010  Example:  struct A:     a:uint256 struct _A:     a:uint256 @external @view def f(b:_A) -> uint256:    return 1 @external def f_(b:A):     pass  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.11   Internal Function Arguments Location Set to",
        "body": " CALLDATA in Typechecking  In vyper.semantics.analysis.local, when a FucntionNodeVisitor is created, its arguments DataLocation are set to CALLDATA, regardless if they belong to an internal or external function. For internal  functions,  the  DataLocation  should  be  memory.  DataLocation  is  not  used  during  code generation, so there are currently no consequences beside a wrong error message when trying to assign an internal function argument.  CS-VYPER_MARCH_2023-011  As an example, compiling the following:  @internal def foo(a:uint256):     a = 1  raises the following exception: ImmutableViolation: Cannot write to calldata. In this case we would not be writing to calldata.  Vyper - Vyper Compiler -   14  CorrectnessLowVersion1CorrectnessLowVersion1              \f5.12   Internal Functions Only Called by __init__ Are Also in the Runtime Code  Internal functions that are only called in the constructor are still included in the runtime code, increasing its size.  Furthermore, the constructor can call internal functions, but these can't call other internal functions. This is not checked at compile time, but it causes an excecution failure upon deployment.  CS-VYPER_MARCH_2023-012  Example of failing deployment:  @external def __init__():     self.f() @internal def f():     self.g()  @internal def g():     pass  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.13   parse_type() Can Be Avoided in Favor of",
        "body": " Annotations  In the code generation phase, types are parsed from AST objects when they could be recovered from the annotation metadatas added during typechecking.  CS-VYPER_MARCH_2023-013  In  vyper.ast.signatures.function_signature,  at  line  135  and  169,  the  arguments  and  return type  are  already  contained  instance  of ContractFunctionT.  in  func_ast._metadata['type'],  which   is  an   In parse_AnnAssign` in vyper.codegen.stmt, the type could be stored in the AST node during local function analysis (AnnAssign nodes currently do not store _metadata['type']).  Vyper - Vyper Compiler -   15  DesignLowVersion1DesignLowVersion1          \f6   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Default Return Value Evaluated Conditionally",
        "body": "  Calling an external function with default_return_value=a() will only evaluate a() after the external call  has  been  performed,  if  the  call  resulted  in  no  return  data.  This  behavior  is  undocumented  and clashes with the usual semantics, where all arguments are evaluated.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Order of Evaluation of Event Arguments",
        "body": "  As in solidity, the order of evaluation of event arguments in Vyper is counter-intuitive, and doesn't follow the  usual  conventions.  First  the  indexed  parameters  are  evaluated  right  to  left,  then  the  non-indexed parameters are evaluated left to right.  In the example, the internal calls are performed in the order self.a(), self.b(), self.c(), self.d():  event A:     b:indexed(uint256)     c:uint256     d:uint256     a:indexed(uint256)  @internal def a() -> uint256:     return 1 @internal def b() -> uint256:     return 2 @internal def c() -> uint256:     return 3 @internal def d() -> uint256:     return 4  @internal def foo():     log A(self.b(), self.c(), self.d(), self.a())  This unusual behavior should be highlighted.  Vyper - Vyper Compiler -   16  NoteVersion1NoteVersion1      \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Curve Base Adapter Misconfiguration",
        "body": "  The Curve base adapter does not sanitize _nCoins and could be initialized with only one coin. Such a misconfiguration  would  not  have  security  implication,  but  the  adapter  is  likely  to  revert  on  most  of  the interactions.  CS-GEARV21-001  Risk accepted:  Gearbox Protocol states:  This contract is never deployed by itself, and we never have to manually enter the value for this parameter, since it\u2019s defined as constant in derived adapters.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Unusable Inherited Functions",
        "body": "  The contract CurveV1AdapterDeposit inherits CurveV1AdapterBase but the inherited exchange* and  functions  do  not  exist  on  the  Curve's  deposit  zappers.  These  functions  will  be  available  through CurveV1AdapterDeposit but will revert if called.  CS-GEARV21-002  Risk accepted:  Gearbox Protocol states:  Gearbox Protocol - Gearbox V2.1 -   20  DesignCorrectnessCriticalHighMediumLowRiskAcceptedRiskAcceptedDesignLowVersion1RiskAcceptedDesignLowVersion1RiskAccepted                  \fPotential costs of changing contracts hierarchy exceed additional deployment costs.  Gearbox Protocol - Gearbox V2.1 -   21    \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings   Wrong WaToken Distribution   -Severity Findings   Compound Adapter's redeemUnderlying() Not Executed   Inheriting ACLTrait Includes Pause/Unpause   -Severity Findings  Inconsistent Test for Reward Token Wrapper    Missing Event    Query of Curve's Tricrypto Pool Virtual Price    BlacklistHelper Claimable Balance Is 1 Wei off    UniswapConnectorChecker Missing Sanity Check   0  1  2  5  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Wrong WaToken Distribution",
        "body": "  The  exchange  rate  depends  on  the  contract's  balance  of  aTokens  and  the  total  supply  of  the WrappedAtokens:  CS-GEARV21-016  function exchangeRate() public view override returns (uint256) {     uint256 supply = totalSupply();     if (supply == 0) return WAD;     return (aToken.balanceOf(address(this)) * WAD) / supply; }  In  WrappedAToken.deposit(),  the  exchange  rate  is  computed  after  the  contract  received  the aToken, so its balance has already been updated. This leads to a wrong computation of the distributed shares or WaToken.  function deposit(uint256 assets) external override returns (uint256 shares) {     aToken.transferFrom(msg.sender, address(this), assets);     shares = _deposit(assets); }  function _deposit(uint256 assets) internal returns (uint256 shares) {     shares = (assets * WAD) / exchangeRate();     _mint(msg.sender, shares);  Gearbox Protocol - Gearbox V2.1 -   22  CriticalHighCodeCorrectedMediumCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCorrectnessHighVersion1CodeCorrected          \f    emit Deposit(msg.sender, assets, shares); }  Example:  For simplicity, we assume that the exchange rate of the aToken is 1.  User A deposits 10 aToken, the computed shares are 10 / 1 = 10 since the total supply is 0. After this transaction, the contract has 10 aToken and the total supply is 10.  User  B  deposits  10  aToken,  the  computed  shares  are  10  /  (20  /  10)  =  5  because  the  contract already holds the new 10 aToken. After this transaction, the contract has 20 aToken and the total supply is 15.  If  user  A  or  B  wants  to  withdraw  at  that  point,  each  should  get  their  10  aToken  back.  But  if  user  B withdraws, the computed amount of aToken he will receive is 5 * (20 / 15) = 6.666..., which is clearly not the expected amount.    The updated code does not take the balances into account anymore for the computation of the exchange rate. Now, the exchange rate is computed as the ratio of the current Aave pool's normalized income and the normalized income at WaToken contract deployment.  function exchangeRate() public view override returns (uint256) {     return WAD * lendingPool.getReserveNormalizedIncome(address(underlying)) / _normalizedIncome; }  Doing so, the contract only sees the exchange rate grow, as long as Aave's interest rate is growing, and the shares cannot be maniputaled by users of the WaToken contract.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Compound Adapter's redeemUnderlying()",
        "body": " Not Executed  CS-GEARV21-014  the   In  and CompoundV2_CEtherAdapter._redeemUnderlying()  only  encode  the  call  to  the  target  contract, but _execute() is not called:  CompoundV2_CErc20Adapter._redeemUnderlying()   error = abi.decode(_encodeRedeemUnderlying(amount), (uint256));  This has no security implications for Gearbox, but users cannot use this function.    The code has been updated to execute the call:  error = abi.decode(_execute(_encodeRedeemUnderlying(amount)), (uint256));  Gearbox Protocol - Gearbox V2.1 -   23  DesignMediumVersion1CodeCorrected          \f6.3   Inheriting ACLTrait Includes Pause/Unpause  The  AbstractAdapter  (which  is  inherited  by  all  Adapters)  and  the  BlacklistHelper  inherit  ACLTrait.  This abstract contract implements pause functionality:  CS-GEARV21-012  ///@dev Pause contract function pause() external {     if (!_acl.isPausableAdmin(msg.sender))         revert CallerNotPausableAdminException();     _pause(); }  /// @dev Unpause contract function unpause() external {     if (!_acl.isUnpausableAdmin(msg.sender))         revert CallerNotUnPausableAdminException();      _unpause(); }  Hence  contracts  inheriting  from  ACLTrait  will  have  external  functions  pause  and  unpause  exposed. These  functions  may  make  it  look  like  the  contract  can  be  paused  -  despite  no  function  actually  being pausable.    The  inheritance  from  ACLTrait  has  been  removed  in  the  AbstractAdapter  and  kept  in BlacklistHelper. Gearbox Protocol responded:  Abstract adapter no longer inherits ACL trait (for adapters, it could have potentially caused problems if we introduced some pausable functions, because credit facade is, in fact, a pausable admin, so users would then be able to pause an adapter in the multicall; for blacklist helper there is no risk so no change)  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Inconsistent Test for Reward Token Wrapper",
        "body": "  To  check  whether  a  reward  token  is  wrapped,  a  call  to  the  booster()  function  of  the  contract  is performed. If the call succeeds, then the reward token is further unwrapped. However, the test whether the  second  reward  token  is  wrapped  or  not  in  the  constructor  of  ConvexV2_BaseRewardPool  is inconsistent. The check for is using _extraReward1 instead of _extraReward2.  CS-GEARV21-013    Now booster() is called on _extraReward2.  Gearbox Protocol - Gearbox V2.1 -   24  DesignMediumVersion1CodeCorrectedDesignLowVersion6CodeCorrected                \f6.5   Missing Event  CS-GEARV21-010  Events should be emitted whenever an important state change happens in a smart contract. Since setting isIncreaseDebtForbidden  in CreditFacade._closeLiquidatedAccount()  is  an  important  state  change,  an  event  may  be useful.  occurred   true   when   pool   loss   the   to   a     If the pool occurred a loss during liquidation, the IncurLossOnLiquidation event is emitted.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Query of Curve's Tricrypto Pool Virtual Price",
        "body": "  CS-GEARV21-011  In  CurveCryptoLPPriceFeed.latestRoundData(),  is  queried  with curvePool.get_virtual_price(),  but  on  the  reference  code  provided  by  Gearbox  Protocol (https://arbiscan.io/address/0x4e828A117Ddc3e4dd919b46c90D4E04678a05504#code#F3#L1)  and notably in the official curve.finance pricefeed template (https://github.com/curvefi/crypto_lp_pricing/blob/b the 6fea6943d5ddf8648f05d442daad284c1757c86/contracts/LPPrice_tricrypto_ethereum.vy#L41),  virtual price is queried from the storage variable with curvePool.virtual_price().  virtual  price   the     function  CurveCryptoLPPriceFeed.latestRoundData  has  been  updated   The  curvePool.virtual_price() instead of curvePool.get_virtual_price().  to  use  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   BlacklistHelper Claimable Balance Is 1 Wei",
        "body": " off  In CreditFacade._increaseClaimableBalance(), the parameter balanceBefore has 1 wei too many due to _isBlacklisted(). The claimable amount is computed as balance-balanceBefore and will lack 1 wei.  CS-GEARV21-015    The  been  helperBalance - helperBalanceBefore + 1;  claimable   amount   has   updated   to   be   computed   as  Gearbox Protocol - Gearbox V2.1 -   25  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \f6.8   UniswapConnectorChecker Missing Sanity Check  The constructor of UniswapConnectorChecker accepts an array of addresses as parameter, but the length of the array is never checked to be <=10. So the checker could be deployed with an array of 25 addresses, only the 10 first will be saved in storage, but numConnectors will be 25. This will also incur unnecessary gas cost when getConnectors() is called.  CS-GEARV21-009    The constructor has been updated to revert if more than 10 addresses are provided.  Gearbox Protocol - Gearbox V2.1 -   26  DesignLowVersion1CodeCorrected      \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Code Duplication",
        "body": "  The  function  CurveV1StETHPoolGateway.remove_liquidity_imbalance  transfers  token0  and token1 in the function's body, but the dedicated function _transferAllTokensOf can be used.  CS-GEARV21-003  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Code Inconsistencies",
        "body": "  CS-GEARV21-006  1. For gas optimizations, the system tries to always keep 1 wei in the balances and the standard way in  is  with  balance  <=  1,   however   across   to  BlacklistHelper.claim() the check is amount < 2.  codebase   check   the   it   2. The Lido gateway transfers the full balance instead of balance-1 as everywhere else in the system  (gas optimization).  3. In the adapters, _gearboxAdapterType is sometimes overridden as a constant, and some other times  as  a  function.  For  consistency  across  the  codebase,  one  of  the  two  solutions  should  be chosen.  Code partially corrected:  1. Changed to amount < 1.  2. Not addressed.  3. Not addressed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Gas Optimizations",
        "body": "  1. In UniswapV2Adapter._parseUniV2Path(), path.length could be loaded from memory to a local variable at the beginning of the function and read from the local variable to save a MLOAD.  CS-GEARV21-007  2. In  UniswapV2Adapter._parseUniV2Path(),   if path.length < 2, path.length > 4, or if one of the hops is not an allowed connector to save some gas.  function   return   could   early   the   3. In   CurveV1AdapterBase,  add/remove_liquidity_one_coin(uint256,uint256,uint256)  do  not  need   functions the  the   the   Gearbox Protocol - Gearbox V2.1 -   27  InformationalVersion1InformationalVersion1CodePartiallyCorrectedInformationalVersion1CodePartiallyCorrected              \fcreditFacadeOnly()  add/remove_liquidity_one_coin(uint256,int128,uint256) have it already.  modifier,   since  Code partially corrected:  1. The length of the array is loaded only once at the beginning of the function and stored in a local  variable.  2. The conditionnal structure has been optimized. However, the function could return early if len > 4  to save some gas in the case of a failure.  3. The   concerned   internal been  _add/remove_liquidity_one_coin(int128) which do not have the creditFacadeOnly() modifier.  functions   updated   have   call   the   to   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   Unused Constants",
        "body": "  Some of the defined constants are still declared and imported, but never used. A non-exhaustive list is:  CS-GEARV21-004   ALL0WANCE_THRESHOLD   EXACT_INPUT   EXACT_OUTPUT  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   Wrong Comments",
        "body": "  Some comments in the code are wrong, here is a non-exhaustive list:  1. WstETHGateway: the @notice comment is wrong, the contract does not allow to convert stETH  into WstETH, it allows to provide liquidity to Gearbox's WstETH in the form of sthETH.  2. ACLNonReentrantTrait:  the  comment  of  the  controllerOnly()  modifier  is  incomplete,  it  only covers the case where externalController is false.  CS-GEARV21-008  3. CreditConfigurator:   in   the   creditManager.upgradeCreditFacade  Connects creditFacade and priceOracle, but only the CreditFacade is connected.  comment   that   has   constructor,  a   the   call   to specifies  4. CurveCryptoLPPriceFeed:  the  @notice  of  the  latestRoundData  function  is  wrong,  the  specified formula is not the one implemented.  5. CreditFacade:   In  _liquidateExpiredCreditAccount   the  comment  \"Checks   if   the  liquidsation . . .\" contains a typo.  6. The  natspec  of  BalancerV2VaultAdapter.batchSwap()  specifies  that  the  assets  must  be ordered.  Nothing  is  enforcing  the  ordering  and  Balancer  V2  does  not  need  to  have  the  assets ordered.  Specifications partially corrected:  Gearbox Protocol - Gearbox V2.1 -   28  InformationalVersion1InformationalVersion1Speci\ufb01cationPartiallyChanged          \f1. Not addressed.  2. The comment has been updated to include the case where externalController is true.  3. Not addressed.  4. The formula in the specification has been updated to match the implementation.  5. The typo has been corrected.  6. The mention of the assets' ordering has been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.6   safeApprove Can Revert",
        "body": "  CS-GEARV21-005  Theoretically,  IERC20.safeApprove()  can  revert  in  WstETHGateway._checkAllowance()  and WaToken.depositUnderlying()  because  the  safeApprove()  function  requires  either  the  current allowance or the value to be 0.  In WstETHGateway, the allowance for the WstETH token is set to type(uint256).max at contract deployment, and is decreased each time WstETHGateway.addLiquidity() is called. Also, each time  WstETHGateway.addLiquidity()  is  called,  the  allowance  check  is  performed,  so  if  the allowance is strictly smaller than the amount. But the maximum allowance is such a big number that this will never happen in practice.  In  WstETHGateway.removeLiquidity()  and  WaToken.depositUnderlying()  set  the allowance for Gearbox's and Aave's lending pool to the exact amount that should be pulled from the contract. The pools are trusted to pull the exact specified amount and not less to set the allowance back  to  0.  If  one  of  the  pool  was  to  be  updated  and  pulls  less  than  the  specified  amount, WstETHGateway.removeLiquidity() and WaToken.depositUnderlying() would revert.  Gearbox Protocol - Gearbox V2.1 -   29  InformationalVersion1      \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   MetaPool With Underlying",
        "body": "  Note that there could be a Curve Metapool with a Metabpoolbase which contains an asset which has an underlying. The current CuveV1_Base implementation does not support interaction using the underlying of of one of the assets in the Metapoolbase. Gearbox Protocol stated they do not aim to support this. In practice the two most relevant base pools are 3CRV and crvFRAX, which both don't have underlyings for their assets. If such a metapool was to be added, the swap into an underlying would be supported by the router.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Multicall Reverts When Temporarily",
        "body": " Exceeding TokenLimit  Adapters  don't  disable  tokenIn  when  uncertain  whether  all  balance  was  spent.  Such  tokens  will  be disabled  at  the  end  of  the  multicall  when  the  full  check  is  executed.  There  is  a  corner  case  where  a sequence of multicalls may revert for one credit account (as the limit would be temporarily exceeded) but not for another (where the limit is not exceeded).  This  may  hinder  the  usage  of  predefined  multicall  sequences.  Note  that  the  problem  can  always  be rectified by adding a call to disableToken in between.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.3   WrappedAToken: depositUnderlying",
        "body": " Assumption  It's of uttermost importance that the expected amount of aToken is deposited into the wrapper contract when shares are minted.  As argument assets the user passes the amount of underlying to depositUnderlying(). There is an assumption that when depositing x amount of underlying into Aave, x amount of aTokens is received in exchange. This holds if Aave works correctly as specified.  function depositUnderlying(uint256 assets) external override returns (uint256 shares) {     underlying.safeTransferFrom(msg.sender, address(this), assets);     underlying.safeApprove(address(lendingPool), assets);     lendingPool.deposit(address(underlying), assets, address(this), 0);     shares = _deposit(assets); }  However, this makes the contract vulnerable if Aave doesn't behave as expected.  Gearbox Protocol - Gearbox V2.1 -   30  NoteVersion1NoteVersion1NoteVersion1          \fGearbox Protocol states:  Wrapped aTokens will probably be deployed only for known tokens like WETH or USDC, for which said assumption can be easily validated.  Gearbox Protocol - Gearbox V2.1 -   31  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Performance Updates Can Be Sandwiched",
        "body": "  The  performance  safeguard  validates  that  the  performance  based  on  a  unit  of  pool  token  does  not deviate  too  much  from  the  old  performance  after  a  swap.  Updating  the  performance  is  permissionless when  a  perfUpdateInterval  (within  0.5  to  1.5  days)  has  elapsed.  If  the  allowed  performance deviation is x%, one can bundle a performance update within two swaps to achieve around 2x% deviation, that  performance  can  at  most  change  x%  within  one which  breaks  perfUpdateInterval.  the  assumption   CS-SLSGP-008  Swaap Labs - SafeguardPool -   12  SecurityDesignCorrectnessCriticalHighMediumLowRiskAcceptedCorrectnessLowVersion1RiskAccepted             \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings   Reentrancy via Vault   -Severity Findings  Incorrect Rounding Directions   Incorrect Target Deviation Computation    Missing Sanity Checks at Pool Initialization   -Severity Findings   Balance Based Penalty Can Be Manipulated    Price Feed Data Validity Checks   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Reentrancy via Vault",
        "body": "  0  1  3  2  CS-SLSGP-012  The Balancer V2 Vault has a known vulnerability to read-only-reentrancy:  https://forum.balancer.fi/t/reentrancy-vulnerability-scope-expanded/4345.  The balances during onJoin/onExit are updated after new shares are minted/burned. And before balance update, the Vault performs a call to external address with the remaining ETH.  The following scenario is possible:   A large LP awaits the time when the updatePerformance() can be called.   LP exits in a balanced way(no updatePerformance triggered yet) and triggers the reentrancy from  the Vault.  In the reentrant call the pool.updatePerformance() is executed. The reentrancy guard on Pool won't be triggered, because it is the Vault that makes the reentrant call.   The   performance   but Vault.getPoolTokens() will return not yet updated balances. Thus the performance will be too high.  values.  PT  will   snapshots  wrong   burned,   already   be   This reentrancy is due to the way Vault contract deals with the ETH that is sent along with swap/join/exit call using _handleRemawiningEth function.  As  a  result,  wrong  performances  will  be  saved  for  a  given  performance  update  period.  This  will  cause DoS in case of exit (performances are too high), or disable the performance based checks for the whole period.  This applies to getPoolPerformance function as well.  Swaap Labs - SafeguardPool -   13  CriticalHighCodeCorrectedMediumCodeCorrectedCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedDesignHighVersion1CodeCorrected           \f  The reentrancy issue has been fixed in the Vault contract, where the update of the balances is now done before the token transfers.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Incorrect Rounding Directions",
        "body": "  Most computations in SafeguardPool are based on 18 decimals for higher precision. However, rounding errors  are  not  properly  handled  in  some  cases,  where  it  may  round  towards  the  advantage  of  users instead of the pool.  In  calcJoinSwapAmounts(),  the  swapAmountIn  is  computed  using  divDown.  Then  the  rOpt  is computed from this value:  CS-SLSGP-002  uint256 swapAmountIn = num.divDown(denom); uint256 swapAmountOut = swapAmountIn.divDown(quoteAmountInPerOut);  function calcJoinSwapROpt(uint256 excessTokenBalance, uint256 excessTokenAmountIn,     uint256 swapAmountIn ) internal pure returns (uint256) {     uint256 num   = excessTokenAmountIn.sub(swapAmountIn);     uint256 denom = excessTokenBalance.add(swapAmountIn);     return num.divDown(denom); }  However, the num will be computed as excessTokenAmountIn.sub(swapAmountIn), thus it will be effectively rounded up. This might result in minting more shares than intended.  A similar case exits in calcExitSwapAmounts() though it is unclear which rOpt is larger.  In addition, in _exitBPTInForExactTokensOut() the bptAmountOut is rounded down. This lowers the amount of shares the user needs to burn. As a result, the pool tokens can lose value with time due to exit conditions that do not favor remaining pool token holders.  uint256 bptAmountOut = totalSupply().mulDown(rOpt);  In  another  note,  _getOnChainAmountInPerOut()  and  calcBalanceDeviation  round  down  the computations. This may make the fairPricingSafeguard and balance based checks slightly weaker. However, in other places, it is unclear if the computation should round up or down (e.g. computation of currentPerformance in _updatePerformance()).    The  calcJoinSwapROpt()  now  subs  1  wei  from  numerator  and  adds  1  wei  to  denominator.  This effectively  lowers  the  number  of  tokens  minted  during  the  deposit  by  a  small  amount,  that  always guarantees that the balances per PT values won't decrease during balanced join.  The  calcExitSwapROpt()  now  adds  1  wei  to  numerator  and  subs  1  wei  from  denominator.  This effectively increases the number of tokens burned during the withdrawal by a small amount, that always guarantees that the balances per PT values won't decrease during balanced exit.  The  _exitBPTInForExactTokensOut()  has  been  fixed  to  use  mulUp  instead  of  mulDown  to compute the amount of pool tokens burned upon a withdrawal.  Swaap Labs - SafeguardPool -   14  SecurityMediumVersion1CodeCorrected        \fThe  rounding  in  calcBalanceDeviation  can  effectively  be  accounted  by  the  quote  generating front-end.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Incorrect Target Deviation Computation",
        "body": "  The  balance  safeguard  validates  that  the  HODL  balance  of  the  output  token  after  a  swap  does  not deviate  too  much  from  it  before  the  swap  (target  deviation).  This  is  computed  in  the  wrong  way  in _getPerfAndTargetDev(),  where  the  numerator  should  be  newBalanceOutPerPT  instead  of newBalanceOut. The target deviation should be in %, however, this wrongly computed value represents the amount of pool tokens.  CS-SLSGP-003    The  deviation  newBalancePerPTOut.divDown(hodlBalancePerPTOut).  target   now   is   correctly   computed   as  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Missing Sanity Checks at Pool Initialization",
        "body": "  There  is  no  sanity  check  on  the  user's  input  token  amounts  amountsIn  as  well  as  the  initial  HODL balance at the pool initialization.  In case a user initializes the pool with 0 amountsIn, the pool becomes useless irreversibly:  CS-SLSGP-004   Anyone can mint any amount of pool tokens by depositing 0 liquidity.   No swap is possible as there is no liquidity.  A user can also disable swaps by initializing the pool with a small amountsIn, where the HODL balance rounds down to 0. Assuming there is a pool of two tokens with 18 decimals, due to the following behavior of the _onInitializePool:   User initializes with amountsIn = [1 wei, 1 wei].   After scaleUp, amountsIn = [1 wei, 1 wei] because the tokens already have 18 decimals.  the HODL balance is computed as 1 * 10^18 / (100 * 10^18), which rounds down to 0.  If both hold balances are 0, the _updatePerformace and _getPerfAndTargetDev will revert due to the division by 0.    A  check  was  added  in  the  _onInitializePool()  function,  that  requires  both  amountsIn[0]  and amountsIn[1]  to  be  at  least  _MIN_INITIAL_BALANCE  =  1e8.  This  way,  issues  due  to  division  by zero will be avoided.  Swaap Labs - SafeguardPool -   15  CorrectnessMediumVersion1CodeCorrectedSecurityMediumVersion1CodeCorrected                   \f6.5   Balance Based Penalty Can Be Manipulated  In  case  the  current  pool  balance  is  less  than  the  pool  balance  at  the  quote  time,  a  penalty  will  be enforced on the quote price during a swap. However, the balance of the pool can be easily manipulated by Join or Exit.  In case there is a balance based penalty, a user can bypass it by Just In Time (JIT) liquidity provision:  CS-SLSGP-001   Join the pool to push the balance back to quote time.   Swap without balance based penalty.   Exit after the swap.  By having a valid quote and doing join-swap-exit bundle, users can bring the state of the pool balances in a  state,  where  other  \"pending\"  quotes  are  blocked  by  the  balance  based  penalty.  Thus,  using join-swap-exit bundle user can:   Bypass paying the balance based penalty fees   Avoid the maxDeviation check.  However, in join-swap-exit the user will only get fraction of the maxSwapAmount total swap value, due to the need to provide out token as an asset during join.  A swap can also be front-run by a liquidity provider's exit, which aggravates the balance based penalty. This way an exit-swap-join, (swap is sandwiched by malicious LP) can:   Revert the swap   Enforce the higher balance penalties on the swap.  This  can  be  seen  as  a  DoS  attack,  however  it  requires  significant  gas  with  no  clear  benefit  for  the attacker.    Swaap Labs responded:  The new balance based penalty also takes into consideration the balance change per PT as well as the balance change: penalty = max(balanceChange, balanceChangePerPT) * slippage  Since  joins  and  exits  do  not  change  the  balances  per  PT,  this  check  will  not  be  bypassable  by join-swap-exit bundle. Thus, swaps with quoted balances that differ too much from the onchain conditions will not be executable.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Price Feed Data Validity Checks",
        "body": "  SafeguardPool  uses  chainlink  oracle  to  retrieve  the  price  feed  for  tokens.  However  the  checks  in ChainlinkUtils.getLatestPrice are missing or not strong enough:  CS-SLSGP-005   _ORACLE_TIMEOUT  is  a  constant  of  1.5  days  which  could  be  too  large.  The  heartbeat  of  most datafeeds  smaller: https://docs.chain.link/data-feeds/price-feeds/addresses#Ethereum%20Mainnet. Any  round  that  is  older  than  the  Heartbeat  cannot  be  considered  fresh.  This  might  happen  due  to potential ChainLink failures.  much   is   Swaap Labs - SafeguardPool -   16  DesignLowVersion1CodeCorrectedSecurityLowVersion1CodeCorrected              \f ChainLink  getLatestRound  returns  roundId  and  answeredInRound.  However,  they  are  not inspected. In ChainLink OCR pricefeeds the roundId and answeredInRound are always equal. However, older versions of pricefeeds require validation, that the round data was not computed in an old  roundId): https://docs.chain.link/data-feeds/historical-data#getrounddata-return-values.  Please  be  aware  of this and check for each deployed pool what pricefeed version is used.  round(answeredInRound   should   than   less   not   be     Swaap Labs responded:  Each oracle in a pool has its own maximum timeout (=< 1.5 days) which is immutable and defined at deployment time. The roundId and answeredInRound are checked .  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Events Indexed Params",
        "body": "  The quoteIndex in ISignatureSafeguard is not indexed. It functions as a random-order nonce for quote signatures. Querying on-chain information about which quote is exhausted is easier if this field is indexed.  CS-SLSGP-013  event SwapSignatureValidated(bytes32 digest, uint256 quoteIndex); event AllowlistJoinSignatureValidated(bytes32 digest);  Similarly, digest params in both events can be indexed.    quoteIndex as well as digest of both events has been marked as indexed in the updated code.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   Outdated Dependency of Balancer Pool",
        "body": " Factory  CS-SLSGP-011  One of SafeguardPool's dependency Balancer's BasePoolFactory has been updated in March where create2()  found  here: https://github.com/balancer/balancer-v2-monorepo/pull/2362  instead  of  create().  The   request  can  be   full  merge   is  used     Balancer dependency is updated. CREATE2 opcode with an extra salt parameter is now used to deploy the pools.  Swaap Labs - SafeguardPool -   17  InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected              \f6.9   Performance Safeguard Sensitivity  The  HODL  balances  are  set  on  initializing  pool,  and  during  the  updates  they  are  multiplied  by performance.  This  effectively  fixes  during  the  initialization  the  proportion  of  assets  that  are  used  for performance  safeguard.  If  the  price  of  assets  changes  significantly  over  time,  the  difference  between balance0/balance1 and hodlBalance0/hodlBalance1 can cause significant sensitivity to price changes. In addition, this imbalance can be caused intentionally during the initialization.  CS-SLSGP-007  For example:  1. Pool initialized with 1 Eth and 100k USD as assets. The hodlBalanceETH = 1, hodlBalanceUSD = 100k.  Assume  that  BPT  is  always  1.  At  this  time  1  ETH  ==  1000  USD.  TLV  =  101000  USD  == holdTVL  2. Over time, with help of swap the balance of pool becomes: 50 ETH and 1000 USD, with 2000 USD as  ETH  price.  TLV  =  101000  USD.  old  hodlTVL  =  1100  Since  TVL  does  not  change,  the holdBalanes will not change as well.  3. Without any balance changes, if price of ETH becomes 1900 USD == 5% drop: TLV = 96k USD.  hodlTVL = 101900. newTVL/hodlTVL = 0.942 > 5% drop  Thus, due to the initial proportion of hold balances the hodl performance of the pool was affected more than the asset price. Also, note that the balances of tokens itself did not change between 2 and 3. Just the change of the oracle price can be enough to make swaps fail due to the performance safeguard.    Swaap  Labs  have  updated  the  code  that  the  performance  safeguard  will  be  bypassed  if  a  swap  is rebalancing the current pool towards the hodl balance ratio.  if (newBalancePerPTOut < hodlBalancePerPTOut || newBalancePerPTIn > hodlBalancePerPTIn) {    _srequire(          _getPerfFromBalancesPerPT(newBalancePerPTIn,newBalancePerPTOut,             hodlBalancePerPTIn,hodlBalancePerPTOut,onChainAmountInPerOut          ) >= _getMaxPerfDev(packedPoolParams),          SwaapV2Errors.LOW_PERFORMANCE    ); }  Swaap Labs stated:  The idea is to allow the rebalancing of assets even if we do not have good performance in order not to find the pool stuck with undesired asset ratios.  Swaap Labs - SafeguardPool -   18  InformationalVersion1CodeCorrected    \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Imbalanced Join Order",
        "body": "  User  can  call  _joinExactTokensInForBPTOut()  to  join  the  pool  in  an  imbalanced  way.  There  are two approaches to achieve the same imbalanced join:  1. excess tokens are swapped for limited tokens first, then a balanced join is executed.  2. a balanced join is executed first, then do a swap to achieve the same result.  SafeguardPool  takes  the  first  approach.  However,  as  the  pool  balance  at  swap  time  is  smaller  in approach  1  compared  to  approach  2,  it  could  induce  higher  balance  based  penalty  and  consequently prevent a transition that actually benefits the system.  CS-SLSGP-006  Acknowledged:  Swaap Labs responded:  We  chose  to  keep  this  approach  as  it  is  easier  to  produce  a  quote  for  this  kind  of  operation  &  it\u2019s more gas efficient and easier to check the post trade safeguards. In addition a user can separately swap and then join the pool even if we change the approach.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Invalidation of Quotes",
        "body": "  The  signed  quotes  remain  valid  until  they  are  either  executed  or  reach  their  deadline.  No  functionality allows  a  specific  quote  to  be  invalidated.  However,  changing  the  signer  will  invalidate  all  previously signed quotes. In case the signer role holder is changed from Alice to Bob and then back to Alice, all the un-expired  quotes  Alice  signed  before  will  become  valid  again.  These  facts  must  be  considered throughout the contract's lifespan.  CS-SLSGP-009  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Management Fees and Swap Safeguards",
        "body": " Relation  The  _claimManagementFees  is  called  before  any  swap  or  join,  but  not  during  the  swaps.  This  can affect the safeguard that rely on per PT values. E.g. if _claimManagementFees is called after a long period, the hodl balances per pt will drop, due to newly minted PT shares. Then, the safeguards can fail  CS-SLSGP-010  Swaap Labs - SafeguardPool -   19  InformationalVersion1AcknowledgedInformationalVersion1InformationalVersion1            \funtil next snapshot of the hodl balances. Due to the low rate of management yearly fees (5%), this should not be a problem.  Swaap Labs - SafeguardPool -   20  \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Consistency of Input Arguments Scale",
        "body": "  Most of the computations work with values of 18 decimals. Input amounts for tokens that have less than 18 decimals will be first scaled up by a scaling factor to reach 18 decimals. In SafeguardPool, some of the input argument amounts are expected to be already scaled up, while the others (mostly coming from Vault) are not.  Examples of such differences:  In _onInitializePool(), amountsIn in userData needs to be not upscaled.  In _joinExactTokensInForBPTOut(), joinAmounts in userData needs to be already scaled up.  In _exitBPTInForExactTokensOut(), exitAmounts in userData needs to be already scaled up.  onSwap(),   In  quote.maxSwapAmount needs to be upscaled.  SwapRequest.amount   needs   to   be   not   upscaled,   however  Scaling  the  value  off-chain  is  gas-efficient,  but  requires  the  correct  input  data  generation.  If  directly submitting a transaction to the contract, users should be aware of which parameters should be scaled up and which should not.  Swaap Labs - SafeguardPool -   21  NoteVersion1      \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Missing Event for poolCreator Update",
        "body": "  The functions that allow an update of the pool creator perform important state change without emitting an event.  Acknowledged:  MYSO  Finance  has  acknowledged  this  issue,  but  has  decided  to  keep  the  functions  as-is  due  to limitations on the code size.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Gas Optimizations",
        "body": "  1. State  variables  r1,  r2,  liquidityBnd1,  liquidityBnd2,  and  minLoan  are  set  in  the constructor and are read-only afterwards, thus they can be declared as immutable to save gas.  2. In function removeLiquidity, the SLOAD to access totalLiquidity when emitting the event  could be avoided if memory variables are used.  3. In function borrow, the storage field totalLpShares is passed to updateAggregations. Even if  it  is  a  hot  address,  accessing  it  again  costs  100  gas,  a  memory  variable  would  be  more  MYSO Finance - Core Protocol V1 -   12  DesignCorrectnessCriticalHighMediumLowAcknowledgedCodePartiallyCorrectedAcknowledgedCodePartiallyCorrectedRiskAcceptedRiskAcceptedAcknowledgedAcknowledgedDesignLowVersion3AcknowledgedDesignLowVersion2CodePartiallyCorrectedAcknowledged                        \fefficient as MLOAD costs 3 gas. It is also the case for loanIdx in the borrow function and in the rollOver function.  4. rollOver  function  computes  _sendAmount  -  getLoanCcyTransferFee(_sendAmount)  multiple times. Storing the result in a memory variable will save gas.  5. In  function  updateAggregations,  repaymentUpdate  is  always  computed  but  is  only  needed  when _isRepay is true.  6. In   ,  the  constant  variable  treasury  was  changed  into  a  state  variable  poolCreator  which could be declared as immutable.  7. In   , function borrow performs an unnecessary SLOAD to get the loan index when emitting  the event Borrow.  Code partially corrected:  3. The storage variables totalLpShares and loandIdx are stored in memory variables.  4. The logic has been moved in function checkAndGetSendAmountAfterFees and the result of the  subtraction is cached.  Acknowledged  MYSO Finance replied:  We acknowledge that certain variables could be made immutable and also within functions a few cases where storing a repeatedly used variable as a memory variable would also save gas, but we were running against byte code limits and stack too deep errors, and instead of significantly refactoring, we decided against implementing many of the optimizations.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   Force Other LPs to Sell Cheap Loans",
        "body": "  Liquidity providers have the guarantee that they receive a minimum interest (flat rate r2) from the repaid loans.  If  there  is  enough  demand  for  borrowing  from  a  pool,  the  interest  rate  goes  up  which  makes  it more attractive for LPs to provide liquidity into it. However, one can implicitly force LPs to lend tokens at a lower interest rate. To achieve that, an attacker needs to add liquidity into a pool and then borrow.  For example, if the available liquidity in a pool is between liquidityBnd1 and liquidityBnd2, the attacker  adds  enough  liquidity,  so  the  interest  rate  gets  lowered.  Taking  a  loan  immediately  after  this operation, the attacker consumes part of its liquidity and part of other LPs liquidity with a lower interest rate than the market rate. The attacker borrows enough tokens such that the interest rate is back to the one  before  the  attack  started.  This  way,  the  liquidity  added  by  the  attacker  is  not  exposed  to  lower interest rates, while other LPs effectively were forced to sell loans with low interest rates.  Code partially corrected:  MYSO Finance implemented two mitigation measures to reduce the likelihood of such attacks:  1. Smart contracts (or EOA) cannot add liquidity and borrow from the pool in the same transaction (or block), as functions addLiquidity and borrow track tx.origin. This complicates but Instead  of  using does  not  eliminate   the  attack  described  above.   risk  of   the   MYSO Finance - Core Protocol V1 -   13  Version2Version3DesignLowVersion1CodePartiallyCorrectedRiskAccepted          \fone single contract to atomically provide liquidity and borrow, an attacker would need to take the risk of carrying the attack non-atomically, or use flashbots, which require more work.  2. Increase  the  minimum  LP-ing  period  from  30sec  to  120sec  to  increase  the  exposure  of  the  attacker's liquidity to the same attack vector.  Risk accepted:  MYSO Finance is aware that the attack is inherent to the system's architecture and states that the two mitigation measures described above will reduce the likelihood of such attacks but not fully prevent them. Furthermore, the attack does not lower the interest rates below the flat rate of a pool (r2), hence LPs still earn a minimum yield.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.4   Optimizations at the Cost of Added",
        "body": " Complexity  The  function  updateLpArrays  considers  7  different  cases  when  an  LP  updates  its  position  and optimizes the storage usage by avoiding storing redundant data. This optimization of the storage comes with added complexity in the logic of the function updateLpArrays although the majority of cases (4 out of 7) are expected to happen rarely.  Risk accepted  The  client  accepts  the  risk  associated  with  the  code  complexity  to  optimize  storage  gas  costs  and  will consider refactoring the function in a future version of the codebase.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.5   Rollover Not Allowed in Certain Situations",
        "body": "  Function  rollOver  in  BasePool  reverts  if  a  borrower  renews  its  loan  and  the  new  loan  amount  is higher  than  the  repayment  of  the  previous  loan.  This  might  be  the  case  if  the  pool  has  more  available liquidity when rollover happens than when the loan was initially taken. The restriction is enforced in the following check:  if (loanAmount >= loanInfo.repayment) revert InvalidRollOver();  Acknowledged  MYSO Finance has decided to keep the code unchanged as this scenario is expected to happen rarely, and users still have an alternative to perform the same operation, as explained in their response:  For bytecode reasons we refrained from supporting this use case as it would require an additional if-else to distinguish between calling transferFrom (regular case where borrower pays to rollOver) and transfer (rare case where borrower receives a refund). The situation where a rollOver would lead to a refund is expected to occur - if at all - rather rarely, hence not supporting it isn\u2019t deemed a significant loss in functionality. Moreover, if necessary a borrower could also independently emulate a rollOver for this situation by atomically repaying and borrowing using a flashloan.  MYSO Finance - Core Protocol V1 -   14  DesignLowVersion1RiskAcceptedDesignLowVersion1Acknowledged                \f5.6   Unclaimed Tokens Remain Locked  Liquidity  providers  specify  the  loan  indices  for  their  claims  and  are  allowed  to  skip  loans  that  are  not sufficiently profitable. Once an LP skips a loan, it cannot claim it anymore. Hence, a pool continuously holds loan and collateral tokens amounts that cannot be claimed by LPs and are locked. The only way to recover  loan  token  funds  is  if  all  LPs  remove  their  liquidity  from  a  pool  (totalLpShares  ==  0)  and then  one  adds  liquidity  which  triggers  the  transfer  of  dust  to  the  treasury.  However,  there  is  no  way  to recover collateral amounts left in the pool from skipped claims.  Acknowledged  MYSO  Finance  acknowledges  the  issue  and  does  not  plan  on  adding  a  functionality  to  track  the unclaimed loans as it would increase significantly the gas costs. However, MYSO Finance will simplify the UI for claiming and promote aggregate claims to reduce the number of unclaimed loans.  MYSO Finance - Core Protocol V1 -   15  DesignLowVersion1Acknowledged          \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  0  0  4  10  -Severity Findings  -Severity Findings  -Severity Findings   Mismatch of Implementation With Specification    Missing Loan Owner Sanity Check When Borrowing    Protocol Fee Computation Can Overflow    Total LP Shares Are Capped in Pools   -Severity Findings   Emission of ApprovalUpdate Event Can Be Tricked    Deletion of Timestamps From Mapping    Redundant Events Emitted    Disabled Optimizer   Inaccessible TREASURY Account   Insufficient Check for Minimal Loan Given Total LP Shares   Inverted NewSubPool Event Token Fields    Misleading ApprovalUpdate Event    Missing Precision of Pool Parameters    Non-indexed Events   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Mismatch of Implementation With",
        "body": " Specification  The specifications of the borrow function state:  In this case the collateral is deducted from the 3rd party ``msg.sender`` address but the ``_onBehalfOf``  address receives the loan and is registered as the loan owner (including the ability to repay and reclaim the pledged collateral).  However,  the  function  takes  the  collateral  from  msg.sender  and  also  sends  the  loan  amount  to msg.sender in violation with the specifications:  IERC20Metadata(collCcyToken).safeTransferFrom(msg.sender, address(this), _sendAmount); ... IERC20Metadata(loanCcyToken).safeTransfer(msg.sender, loanAmount);  MYSO Finance - Core Protocol V1 -   16  CriticalHighMediumSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCorrectnessMediumVersion1Speci\ufb01cationChanged           \fSpecification changed  The specification in section 'Calling Functions on Behalf' of the gitbook has been revised to reflect the code behavior:  In this case the collateral is deducted from msg.sender and msg.sender also receives the loan but the_onBehalfOf address is registered as the loan owner (including the ability to repay and reclaim the pledged collateral). This allows wrapping and unwrapping of tokens through a peripheral contract.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Missing Loan Owner Sanity Check When",
        "body": " Borrowing  A borrower can take a loan on behalf of anyone without restriction and this can result in the loan never being repaid. If a borrower calls borrow with an _onBehalf address they do not control or is aware that it will be the owner of a loan, the loan will default since the borrower is not the loan owner and is probably not allowed to repay it. E.g., borrow is called with _onBehalf=address(0), then the loan will default for sure.  Code corrected  The function borrow has been updated to perform a sanity check that address _onBehalf is not set to addr(0)  by  mistake.  However,  the  caller  is  still  responsible  for  providing  a  correct  address  for _onBehalf which repays the loan if required.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Protocol Fee Computation Can Overflow",
        "body": "  The  protocol  fee  computation  in  loanTerms  can  overflow  if  the  protocolFee  is  non-zero.  The multiplication in _protocolFee = uint128((_inAmountAfterFees * protocolFee) / BASE) is carried in uint128 and might overflow. Example is with protocolFee = 5 * 10**5 which is also the maximum allowed fee and _inAmountAfterFees=uint128(uint256(2**128) / uint256(5 *10**15))+1=68056473384187692692675  which  may  seem  to  be  a  lot  but  could  be  a  realistic amount for collateral tokens with 18 decimals and low value.  Code corrected  In the second version of the codebase, the variable protocolFee was renamed creatorFee and its type  was  changed  to  uint256  to  avoid  possible  overflows  in  the  computation  highlighted  in  the  issue above.  MYSO Finance - Core Protocol V1 -   17  DesignMediumVersion1CodeCorrectedDesignMediumVersion1CodeCorrected                  \f6.4   Total LP Shares Are Capped in Pools  The  function  _addLiquidity  performs  two  checks  to  guarantee  that  an  LP  will  get  non-zero  token amounts from a small loan, both on repay and default. The checks are implemented as follows:  if (     ((minLoan * BASE) / totalLpShares) * newLpShares == 0 ||     (((10**COLL_TOKEN_DECIMALS * minLoan) / maxLoanPerColl) * BASE) /         totalLpShares == 0 ) revert PotentiallyZeroRoundedFutureClaims();  The  first  condition  evaluates  to  true  whenever  totalLpShares  >  minLoan  *  BASE.  Since  both minLoan and Base are fixed for a pool, the totalLpShares is capped for a pool.  Similarly, the second condition evaluates to true whenever totalLpShares > ((10**COLL_TOKEN_ DECIMALS  *  minLoan)  /  maxLoanPerColl)  *  BASE)  sets  another  restriction  on  the  maximum totalLpShares.  Capping  the  totalLpShares  prevents  adding  liquidity  to  pools  that  are  attractive  to  users  and  have high activity.  Specification changed  The  specifications  have  changed  and  the  checks  described  above  have  been  removed,  hence  the unintended capping on total LP shares is not present anymore.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Emission of ApprovalUpdate Event Can Be",
        "body": " Tricked  There is no restriction on the parameter _packedApprovals of function setApprovals. One could set the 6th bit to 1 even if no approval is updated and the event will be emitted. Moreover, if bits higher than the 6th are set, they will be shown in the emitted event.    The input parameter _packedApprovals has been sanitized to consider only the 5 least significant bits.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Deletion of Timestamps From Mapping",
        "body": "  The timestamp stored in lastAddOfTxOrigin are never deleted from the mapping although they are used  only  to  disallow  LPs  from  adding  liquidity  and  borrowing  in  the  same  block.  The  entries  of  this mapping can be deleted, e.g., when LP remove their liquidity, to get gas refunds.    MYSO Finance - Core Protocol V1 -   18  DesignMediumVersion1Speci\ufb01cationChangedDesignLowVersion3CodeCorrectedDesignLowVersion2CodeCorrected                      \fThe entry for an address in the mapping lastAddOfTxOrigin is deleted when liquidity is removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Redundant Events Emitted",
        "body": "  The function setApproval iterates through all approval types and emits an event independently if an approval  status  is  updated  or  not.  Therefore,  even  if  only  one  approval  type  is  changed  for  an _approvee, five events will be emitted.  Code corrected  Function setApproval has been updated to emit the event when at least one of the approvals changes state.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   Disabled Optimizer",
        "body": "  In  hardhat.config.js  the  optimizer  is  not  explicitly  enabled  and  the  default  value  for  hardhat  is enabled: false. Enabling the optimizer may help to reduce gas cost.  Code corrected  The optimizer has been enabled and the runs are set to 1000.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   Inaccessible TREASURY Account",
        "body": "  TREASURY   The  to declared  0x1234567890000000000000000000000000000001  which  is  not  in  the  control  of  the  developers, hence  all  protocol  fees  collected  by  the  system  will  be  locked  forever.  MYSO  Finance  is  aware  of  this issue and will use a multisig account for the treasury on deployment.  constant   address   and   set   as   is   Code corrected  The constant variable TREASURY is replaced with the state variable poolCreator which is assigned to msg.sender in constructor.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   Insufficient Check for Minimal Loan Given",
        "body": " Total LP Shares  The second condition in the following code is supposed to check that repayment amount for a loan is big enough that all LPs can claim non-zero amounts if the loan is repaid given their share:  MYSO Finance - Core Protocol V1 -   19  DesignLowVersion2CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1Speci\ufb01cationChanged                                \fif (     ... ||     ((repaymentAmount * BASE) / totalLpShares) == 0 ) revert ErroneousLoanTerms();  The  check  might  not  work  as  intended  for  loan  tokens  with  low  decimals,  e.g.,  USDC  (6  decimals),  as BASE  is  a  constant  with  value  10**18.  For  example,  if  repaymentAmount  is  10**7  (10  USDC)  and totalLpShares is 10**8 (2 LPs with 5 * 10**7 shares each) the check would still pass.  Specification changed  MYSO Finance has changed the specifications and decided to remove the check above as it effectively would increase the minimum loan amount over time as total LP shares increase.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.11   Inverted NewSubPool Event Token Fields",
        "body": "  The  NewSubPool  event  definition  in  IBasePool.sol  specifies  that  the  first  two  fields  are collCcyToken and loanCcyToken, but when the event is emitted in the constructor, the two fields are set to _loanCcyToken and _collCcyToken.  Code corrected  The definition of event NewSubPool in IBasePool is updated and the parameters are in line with the code that emits the event:  event NewSubPool(     address loanCcyToken,     address collCcyToken,     ... );  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.12   Misleading ApprovalUpdate Event",
        "body": "  The function setApprovals emits an event only when an approval type is set to true, even if it was previously the case, and nothing is emitted when an approval is unset. An example is: current approvals are  10101  and  the  updated  approvals  are  10100.  The  event  is  misleading  in  the  sense  that  it  will  be emitted for indices 0 and 2, which have not been updated, and no ApprovalUpdate event is emitted for the actual update of the index 4.  Code corrected  The event Approval is now emitted for every index with the status true or false and independently if it was changed from the previous state.  MYSO Finance - Core Protocol V1 -   20  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                  \f6.13   Missing Precision of Pool Parameters  The  documentations  and  inline  specifications  do  not  describe  the  precision  of  the  pool  parameters.  To improve  the  readability  of  the  code  and  avoid  possible  mistakes,  the  decimals  used  for  all  pool parameters such as r1, r2, liquidityBnd1 and liquidityBnd2 should be stated clearly.  Code corrected  Inline  code  comments  were  added  for  the  variables  mentioned  above,  which  specify  the  precision  of expected values:  uint256 r1; // denominated in BASE and w.r.t. tenor (i.e., not annualized) uint256 r2; // denominated in BASE and w.r.t. tenor (i.e., not annualized) uint256 liquidityBnd1; // denominated in loanCcy decimals uint256 liquidityBnd2; // denominated in loanCcy decimals  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.14   Non-indexed Events",
        "body": "  No  parameters  are  indexed  in  the  events  of  contracts  BasePool.  It  is  recommended  to  index  the relevant event parameters to allow integrators and dApps to quickly search for these and simplify UIs.  Code corrected  MYSO  Finance  has  evaluated  the  events  used  in  BasePool  and  has  indexed  parameters  that  they deem useful for future UI and dashboard integrations.  Several events such as NewSubPool and Approval have non-indexed parameters, however, the client intentionally kept them unchanged.  MYSO Finance - Core Protocol V1 -   21  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected              \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   LP Shares Dilute Over Time",
        "body": "  The shares of an LP dilute over time as more activity happens in a pool by users that borrow and LPs that add more liquidity. Therefore, LPs should monitor their proportion of LP shares to the total LP shares and  remove  their  liquidity  from  a  pool  when  their  share  to  loan  repayments  or  collateral  becomes insignificant.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   LPs Get Slightly Less Token for Their Shares",
        "body": "  The pool keeps a minimum of loan tokens and it does not allow LPs to fully empty a pool. When removing liquidity, LPs get slightly less tokens than their fair share to maintain the minimum liquidity in the pool. The relevant code is:  uint256 liquidityRemoved = (numShares *     (_totalLiquidity - MIN_LIQUIDITY)) / _totalLpShares;  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   LPs Should Be Careful When Claiming",
        "body": "  function  claim  or LPs  can  claim  repayments  and  collateral  claimFromAggregated.  It  is  important  to  note  that  LPs  are  responsible  for  claiming  loans  always  in order. Otherwise, any loan skipped during a claim is impossible to be claimed in the future.  their  share  of   tokens  via   Furthermore,  LPs  can  skip  all  loans  during  a  time  window  via  the  function  overrideSharePointer. Similarly,  if  an  LP  calls  this  function,  they  cannot  claim  anymore  the  repayments  and  collateral  for  all loans linked with the skipped shares.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   Limitations on Claiming Batch of Loans",
        "body": "  Both functions claim and claimFromAggregated allow LPs to claim loans in batches over a period during  which  the  LP  has  not  changed  its  shares  in  a  pool.  LPs  should  be  aware  that  modifying  their position in a pool by topping up or removing liquidity, will require them to perform multiple transactions for the claiming which increases gas costs and potentially prevents LPs from using aggregate claims.  MYSO Finance - Core Protocol V1 -   22  NoteVersion2NoteVersion1NoteVersion1NoteVersion1                \f7.5   Locked Tokens  ERC20 tokens could be accidentally/intentionally sent to the pool contracts. In that case the tokens will be  Incidents (https://coincentral.com/erc223-proposed-erc20-upgrade/) in the past showed this is a real issue as there always will be users sending tokens to the token contract.  recover   locked,   them.   with   way   no   to   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.6   Minimum Loan Amount Allowed",
        "body": "  The constructor of BasePool does not enforce any restriction on the minimum allowed amount for loans. Therefore, the pool deployer should carefully set this value depending on the specific token used as loan token.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.7   Positions in a Pool Are Non Transferrable",
        "body": "  All positions in pools held by liquidity providers or borrowers are tracked in the contract BasePool and they  are  non-transferable.  Users  can  approve  other  addresses  to  act  on  their  behalf,  but  there  is  no support for transferring ownership of positions.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.8   Possible to Overpay Loans",
        "body": "  Functions  repay  and  rollOver  check  that  the  user  always  pays  at  least  the  due  amount.  However, both  functions  allow  users  to  overpay  their  loans  by  1%  in  case  users  cannot  precisely  calculate  the sending amount for tokens with transfer fees.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.9   Profits of a Pool Are Not Equally Distributed",
        "body": "  The  profits  of  a  pool  from  loan  repayments  are  not  equally  distributed  among  liquidity  providers.  The system  is  designed  such  that  profits  for  an  LP  depend  on  loans  that  borrow  most  of  their  liquidity.  For example, if a pool starts with an interest i and over time the interest rate goes to 3 x i, initial LPs will earn payments from loans with interest i, while LPs joining later will have higher profits (as the interest rate tripled to 3 x i).  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.10   Transfer Fee for Upgradable Tokens",
        "body": "  function  getLoanCcyTransferFee   The  is hard-coded to return 0 as fee for the loan token, namely USDC. We would like to highlight that the pools would not work as expected if upgradable tokens were to introduce fees in new implementations.  in  contracts  PoolPaxgUsdc  and  PoolWethUsdc   MYSO Finance - Core Protocol V1 -   23  NoteVersion1NoteVersion2NoteVersion1NoteVersion1NoteVersion1NoteVersion1                      \f7.11   if Blocks Without Curly Braces  It  is  generally  good  practice  to  enclose  every  if/else  block  into  curly  braces.  It  increases  code readability  and  lowers  possibilities  for  bugs  like  the  famous  goto  fail;  bug  in  Apple  SSL  code https://blog.codecentric.de/en/2014/02/curly-braces/.  MYSO Finance - Core Protocol V1 -   24  NoteVersion1    \f8   Monitoring  A thorough code audit is just one important part of a comprehensive smart contract security framework.  Next  to  proper  documentation/specification,  extensive  testing  and  auditing  pre-deployment,  security monitoring  of  live  contracts  can  add  an  additional  layer  of  security.  Contracts  can  be  monitored  for suspicious  behaviors  or  system  states  and  trigger  alerts  to  warn  about  potential  ongoing  or  upcoming exploits.  Consider  setting  up  monitoring  of  contracts  post-deployment.  Some  examples  (non-exhaustive)  of common risks worth monitoring are:  1. Assumptions made during protocol design and development.  2. Protocol-specific invariants not addressed/mitigated at the code level.  3. The state of critical variables  4. Known risks that have been identified but are considered acceptable.  5. External  contracts,  including  assets  your  system  supports  or  relies  on,  that  may  change  without  your knowledge.  6. Downstream  and  upstream  risks  -  third-party  contracts  you  have  direct  exposure  to  (e.g.  a  third  party liquidity pool that gets exploited).  7. Privileged functionality that may be able to change a protocol in a significant way (e.g. upgrade the  protocol). This also applies to on-chain governance.  8. Protocols  relying  on  oracles  may  be  exposed  to  risks  associated  with  oracle  manipulation  or  staleness.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Project-specific monitoring opportunities",
        "body": " We have identified some areas in Core Protocol V1 that would be well suited for security monitoring.  We classify these into two categories: invariants and suspicious changes. If an invariant of the system doesn't  hold  anymore,  there  has  been  unexpected  behavior  requiring  immediate  investigation.  If  a change of a suspicious condition has been observed, something has happened which could change the behavior of the system and requires timely investigation to ensure the continued safety.  The following monitoring opportunities have been identified:  suspicious   Identified  and getLoanCcyTransferFee are hardcoded to return a transfer fee of 0 for tokens that currently do not have  such  fees.  However,  for  upgradable  tokens  such  as  USDC,  this  could  change  in  new implementations, hence this change can be monitored and trigger an alert if fees ever change.  getCollCcyTransferFee   functions   change:   The   Identified suspicious change: All pools have a finite number of cycles for borrowing and adding liquidity until a potential overflow on the total LP shares may happen. Therefore, the value of totalLpShares can be monitored and trigger an alert if it becomes large enough to overflow, e.g., larger than 2**240, so a new pool can be deployed.  MYSO Finance - Core Protocol V1 -   25  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Preferential Withdrawal",
        "body": "  0  0  1  1  When there are more withdrawal requests than can be serviced, all users receive the same percentage of their withdrawals. A user that wants to make a partial withdrawal could take advantage of this.  Consider an example where withdrawal requests are fulfilled at 50%. A user that wants to withdraw 100 shares could instead request to withdraw 200 shares (given he has enough shares). Their request would be fulfilled by half, giving them 100 shares. Now they can cancel the remaining withdrawal request.  In  this  way,  the  user  was  able  to  circumvent  the  withdrawal  limit  at  no  cost.  Other  users  were  able  to withdraw fewer shares than they would have otherwise.  Risk accepted:  Avantgarde Finance states:  This is the intended behavior. Also note that redeemers who request to redeem more than they actually would like to redeem are risking that their entire requested amount be redeemed in full if the cap is not met, the cap is updated by the manager, or other redeemers cancel their requests.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   BondBuyer: Claims Involving Ether Track",
        "body": " Wrong Asset  Avantgarde Finance - Sulu Extensions IX -   11  DesignCorrectnessCriticalHighMediumRiskAcceptedLowAcknowledgedDesignMediumVersion1RiskAcceptedCorrectnessLowVersion1Acknowledged                  \fClaiming a position involving Ether will result in the wrong asset being added to the tracked assets of the vault. Note that the vault actually supports receiving Ether (it immediately wraps it as WETH).  Consider the parser of the SolvV2BondBuyerPosition:  else if (_actionId == uint256(ISolvV2BondBuyerPosition.Actions.Claim)) {         (address voucher, uint256 tokenId, ) = __decodeClaimActionArgs(_encodedActionArgs);          ISolvV2BondVoucher voucherContract = ISolvV2BondVoucher(voucher);          uint256 slotId = voucherContract.voucherSlotMapping(tokenId);         ISolvV2BondPool.SlotDetail memory slotDetail = voucherContract.getSlotDetail(slotId);          assetsToReceive_ = new address[](2);         assetsToReceive_[0] = voucherContract.underlying();         assetsToReceive_[1] = slotDetail.fundCurrency;  For arbitrary vouchers, one of the assets may be Ether as Ether is technically supported by the Solv v2 smart contracts.  Solv v2 represents the Ether asset as \"0xEeeeeEeeeEeEeeEeEeEeeEEEeeeeEeeeeeeeEEeE\" which in this case will be added to assetsToReceive. Within Enzyme, however, the correct asset to track in this case would be the address of WETH.  This results in an unsupported asset being tracked by a vault which may have severe consequences. For example, it breaks calcGav().  Whether  such  vouchers  actually  exist  depends  on  the  market  configurations  administrated  by  Solv Protocol. These markets may change in the future. Since the external position may interact with any offer on the IVOMarket / any voucher, such an issue may arise.  The InitialVoucherOfferingMarket currently doesn't support to create offers with Ether as underlying since offer()  misses  the  payable  modifier.  Note  that  the  implementation  otherwise  supports  the  case  to handle Ether.  The currency of a voucher may be Ether. Contrary to offer() buy() features the payable modifier and hence such vouchers can be bought successfully. Note that one can't buy such a position in Ether via the external position since it doesn't support providing ERC20 tokens. This however doesn't prevent all  scenarios  where  claim()  may  return  Ether  as  such  an  NFT  may  be  transferred  directly  to  the external position.  Acknowledged:  Avantgarde Finance states:  While ETH can technically be the currency of the offer, Solv\u2019s refund logic depends on it being a stablecoin: https://github.com/solv-finance/solv-v2-ivo/blob/ ac12b7f91a7af67993a0501dc705687801eb3673/vouchers/bond-voucher/ contracts/BondPool.sol#L174  Avantgarde Finance - Sulu Extensions IX -   12    \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings  -Severity Findings  0  0  0  0  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Missing indexed in Event",
        "body": "  The event initialized emitted in GatedRedemptionQueueSharesWrapperLib.init() contains the address of the VaultProxy. This field is not indexed, hence one can't easily search such events for a certain VaultProxy. Given that the Factory doesn`t implement access control when deploying new shares wrappers it may be helpful to have this field indexed so that one can more easily search the events.    The parameter of the event has been indexed.  Avantgarde Finance - Sulu Extensions IX -   13  CriticalHighMediumLowInformationalVersion1CodeCorrected      \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Number of Assets",
        "body": "  By design, the external position framework adds all assets specified as incoming assets to the tracked assets of the vault, regardless whether the vault has a non-zero balance at the end of the operation.  Notably ISolvV2BondBuyerPosition.Actions.Claim adds two assets as both may be received. In a corner case scenario, despite actually receiving one asset only, adding two may exceed the position limit and hence the operation fails.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   OpenZeppelin ERC20 Hooks",
        "body": "  The  GatedRedemptionQueueSharesWrapperLib  overrides  transfer()/transferFrom()  in  order  to validate the transfer (__preProcessTransfer).  The OpenZeppelin ERC20 implementation provides a hook, (_beforeTokenTransfer) which could be used  for  this.  Note  that  this  hook  is  also  executed  upon  minting/burning.  For  more  information  please refer to documentation of OpenZeppelin:   https://docs.openzeppelin.com/contracts/3.x/extending-contracts#using-hooks  Avantgarde Finance - Sulu Extensions IX -   14  InformationalVersion1InformationalVersion1      \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Bond Buyer Requires Trusted Fund Manager",
        "body": "  Investors need to trust the fund manager to a certain degree.  fund  manager  can  always  drain   A  https://specs.enzyme.finance/topics/known-risks-and-mitigations#opportunistic-managers  through  bad   trades.  This   funds  e.g.   is  documented:  Note that this is amplified when a fund can use the SolvV2BondBuyer External Position: A malicious fund manager  may  create  an  IVO  offer  via  the  Solv  Protocol  with  a  very  high  lowestPrice  set  for  their collateral  asset.  Then  they  can  buy  this  offer  through  the  External  Position  and  never  pay  back  the principal to the Bond. This would leave the fund with a small amount of collateral, while the fund manager could keep all value that was in the fund.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Deployment of",
        "body": " GatedRedemptionQueueSharesWrapper  Anyone  may  deploy  a  GatedRedemptionQueueSharesWrapper  for  any  fund  through  the  factory.  This includes setting the initial configuration. For example, a deployer can set themselves as manager.  Users and fund owner should be aware and excercise extra caution. The owner of a fund has full control over any such GatedRedemptionQueueSharesWrapper and can reconfigure it.  Multiple SharesWrapper can be deployed for the same fund. Note that they all bear the same name and symbol.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.3   Kick Ignores Redemption Limit",
        "body": "  The kick function in the shares wrapper allows an admin to immediately force a user redemption. This ignores the redemption limit.  Note that the limit of other users' withdrawals is not reduced by this, so the maximum redeemed amount in that period can be the redemption limit, plus any kick actions in addition.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.4   Redemption Requests Not Always Possible",
        "body": "  Note  that  redemption  requests  to  the  shares  wrapper  can  only  be  made  outside  of  the  redemption window.  Avantgarde Finance - Sulu Extensions IX -   15  NoteVersion1NoteVersion1NoteVersion1NoteVersion1              \fThe comments in the code suggest that window frequency could be chosen every 2 weeks and duration 1 week:      struct RedemptionWindowConfig {     uint64 firstWindowStart; // e.g., Jan 1, 2022; as timestamp     uint32 frequency; // e.g., every 2 weeks; in seconds     uint32 duration; // e.g., 1 week long; in seconds     uint64 relativeSharesCap; // 100% is 1e18; e.g., 50% is 0.5e18 }  With these settings, users would only be able to make redemption requests half of the time. If a user is unlucky,  they  would  need  to  wait  for  an  entire  week  until  they  can  make  a  transaction  that  does  not revert.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.5   Vault May Track Unsupported Assets",
        "body": "  The external position framework relies on the parser of the external position to check the assets returned as _assetsToReceive. The code of the external position framework doesn't do any checks itself and simply  adds  any  asset  to  the  tracked  assets  of  the  vault.  Note  that  this  is  also  independent  of  the balance.  VaultLib.__callOnExternalPosition():  function __callOnExternalPosition(     address _externalPosition,     bytes memory _actionData,     address[] memory _assetsToTransfer,     uint256[] memory _amountsToTransfer,     address[] memory _assetsToReceive ) private {     require(         isActiveExternalPosition(_externalPosition),         \"__callOnExternalPosition: Not an active external position\"     );      for (uint256 i; i < _assetsToTransfer.length; i++) {         __withdrawAssetTo(_assetsToTransfer[i], _externalPosition, _amountsToTransfer[i]);     }      IExternalPosition(_externalPosition).receiveCallFromVault(_actionData);      for (uint256 i; i < _assetsToReceive.length; i++) {         __addTrackedAsset(_assetsToReceive[i]);     } }  ...2e42850b7bbc2237618c38fb01e767d14b606e00      function __addTrackedAsset(address _asset) private notShares(_asset) {     if (!isTrackedAsset(_asset)) {         __validatePositionsLimit();          assetToIsTracked[_asset] = true;         trackedAssets.push(_asset);          emit TrackedAssetAdded(_asset);     } }  Avantgarde Finance - Sulu Extensions IX -   16  NoteVersion1    \fThe SolvV2BondBuyerPositionParser doesn't check these assets sufficiently:  else if (_actionId == uint256(ISolvV2BondBuyerPosition.Actions.Claim)) {             (address voucher, uint256 tokenId, ) = __decodeClaimActionArgs(_encodedActionArgs);              ISolvV2BondVoucher voucherContract = ISolvV2BondVoucher(voucher);              uint256 slotId = voucherContract.voucherSlotMapping(tokenId);             ISolvV2BondPool.SlotDetail memory slotDetail = voucherContract.getSlotDetail(slotId);              assetsToReceive_ = new address[](2);             assetsToReceive_[0] = voucherContract.underlying();             assetsToReceive_[1] = slotDetail.fundCurrency;         }  A voucher's underlying and fundCurrency may be any asset the IVO market supports. There is no check that the fundCurrency is an asset supported by Enyzme. If the position was bought through the external position,  it's  likely  that  the  underlying  is  supported  (else  it  couldn't  have  been  bought.)  Note  that  Solv Bond  Voucher  NFT  positions  may  be  transferred  to  an  external  position  and  consequently  one  cannot rely on the underlying to be supported.  Even when no value is returned in the specific asset, the asset is still added as tracked asset.  Similarly this situation may arise in the SolvV2BondIssuerPosition: CreateOffer() only validates that the received currency is not the native token (Ether). There is no further check on this asset which will be incoming to the vault upon reconcile().  It's unclear if Enyzme supports all possible assets by default (e.g. also when new assets are added by Solv).  Unsupported  assets  tracked  by  a  vault  may  have  severe  consequnces  as  they  break  e.g. calcGav().  It's the fund manager's responsibility to be aware and to act appropriately.  Avantgarde Finance - Sulu Extensions IX -   17  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Funds Can Avoid Paying Protocol Fees",
        "body": "  Consider a fund that has not enabled autoProtocolFeeSharesBuyback and assume that over time the protocol fee reserve has accrued a sizeable amount of shares of this fund.  The fund, through its manager, can avoid paying protocol fees by employing the following vector:  1. Move  all  assets  of   the CompoundDebtPosition  available  as  an  external  position,  this  means  exchanging  all  of  the vaults holdings into a cToken and transferring it to the external position.  to  an  external  position.  Currently,  with  only   the  vault   2. Remove the external position. Note that, at this point, the GAV of the fund is close to 0.  3. Call buyBackProtocolFeeShares which calculates a really low price per share. This means that only a small amount of MLN tokens needs to be burnt to burn the protocol fee shares and, thus, pay back the fee.  4. Reactivate the external position and move the funds back.  Note that a similar vector can be used by the fund manager to avoid minting protocol fees while migrating or reconfiguration the fund.  The opportunistic behavior of the manager against the users of the fund is well documented. However, adversarial actions against the protocol are not mentioned.  Note that the underlying problem, a manipulated lower GAV due to hiding assets of the fund in a removed external position can also be abused by the fund manager to buy shares for a low price.  Acknowledged:  Avantgarde Finance - Enzyme Protocol v4 Sulu -   11  DesignCorrectnessCriticalHighMediumAcknowledgedLowCodePartiallyCorrectedAcknowledgedAcknowledgedDesignMediumVersion1Acknowledged          \fAvantgarde Finance responded:  As  the  audit  team  importantly  noted,  this  issue  only  potentially  affects  the  protocol  fee  amount ultimately burned, and does not impact end users of the protocol. Hence, rather than changing the core contracts for this release to protect against the reported deviant behavior, we have decided to combine the monitoring of blatant protocol fee violations with potential on- and off-chain penalties.  Deviant  behavior  can  monitored  off-chain  by  comparing  each  shares  buyback  event  with  the  last known share price.  If the Council assesses that there is a blatant attempt to evade protocol fees, it would be possible, for example,  to  restrict  buying  back  shares  by  upgrading  the  ProtocolFeeReserveProxy  contract  to disallow particular funds.  We  can  reevaluate  for  subsequent  releases  whether  or  not  to  prevent  this  behavior  at  the  core protocol level.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Untracked WETH",
        "body": "  A  fund  owner  can  withdraw  the  Ether  that  has  been  deposited  to  the  paymaster  account  by  calling GasRelayPaymasterLib.withdrawBalance. At this point Ether will be transferred to the vault and wrapped into WETH. However, there is no guarantee that WETH is a tracked asset for the fund.  Code Partially Corrected:  When  ComptrollerLib.shutdownGasRelayPaymaster  is  called,  WETH  is  added  to  the  tracked assets.  Avantgarde Finance responded:  It is highly unlikely that a fund using a paymaster would not have WETH as a tracked asset. Still, we have added a call to track WETH as a tracked asset when shutdownGasRelayPaymaster() is called from the ComptrollerProxy. It is more difficult - and best not - to attempt to validate whether WETH is a tracked asset when calling withdrawBalance() directly from the paymaster lib, since it can be called after a fund has migrated to a new release, at which point, the interface of its new VaultLib should not be assumed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   AddressListRegistry Gas Inefficiency",
        "body": "  AddressListRegistry  stores  ListInfo  using  the  mapping  itemToIsInList.  The  type  of  the mapping is mapping(address => bool). However, it would be more gas efficient to set its type to address => uint256 which omits the masking operation required to handle the boolean values.  Acknowledged:  Avantgarde Finance responded:  We  acknowledge  the  technical  efficiency,  but  in  practice  the  gas  savings  is  insignificant  within  the context of the protocol, and the use of bool is more intuitive.  Avantgarde Finance - Enzyme Protocol v4 Sulu -   12  CorrectnessLowVersion2CodePartiallyCorrectedDesignLowVersion2Acknowledged                  \f5.4   Redundant Check  In FundDeployer.__redeemSharesSetup, the following snippet exists:     } else if (postFeesRedeemerSharesBalance < preFeesRedeemerSharesBalance) {         ...         preFeesRedeemerSharesBalance.sub(postFeesRedeemerSharesBalance)     ); }  Note  case  postFeesRedeemerSharesBalance < preFeesRedeemerSharesBalance.  redundant   that   use   this   the   sub   of   in   is   since   it   holds:  Acknowledged:  Avantgarde Finance responded:  Currently,  we  generally  use  SafeMath  for  math  operations  rather  than  making  judgements  about where or where not to use it.  Avantgarde Finance - Enzyme Protocol v4 Sulu -   13  DesignLowVersion1Acknowledged        \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings   redeemSharesForSpecificAssets Fails For Derivatives   -Severity Findings  Incorrect redemptionWindowBuffer Check    Shadowed Constant    Missing Indexes in Events   0  0  1  3  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   redeemSharesForSpecificAssets Fails For",
        "body": " Derivatives  In Sulu, users are allowed to redeem specific assets. According to the documentation:  The redeemer specifies one or multiple of the VaultProxy's ERC20 holdings along with the relative values of each to receive (for a total of 100%).  However,  if  an  ERC20  token  which  represents  a  derivative  is  specified  as  a  payout  asset  then  the redemption will fail. The call in __payoutSpecifiedAssetPercentages fails for non primitive assets due  the the  valueInterpreter:  the  calcCanonicalAssetValue  of   require  statement  shown  below   to   in   payoutAmounts_[i] = IValueInterpreter(getValueInterpreter()).calcCanonicalAssetValue(     denominationAssetCopy,     _owedGav.mul(_payoutAssetPercentages[i]).div(ONE_HUNDRED_PERCENT),     _payoutAssets[i] );  function calcCanonicalAssetValue(     ...      require(         isSupportedPrimitiveAsset(_quoteAsset),         \"calcCanonicalAssetValue: Unsupported _quoteAsset\"     );      ...  Note that simply removing the requirement is not enough since the ValueInterpreter can only handle conversions to primitive assets due to the implicit requirement that the quote asset has a Chainlink price feed.  Avantgarde Finance - Enzyme Protocol v4 Sulu -   14  CriticalHighMediumCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCorrectnessMediumVersion1CodeCorrected         \fCode Corrected:  ValueInterpreter.calcCanonicalAssetValue  now  supports  the  conversion  from  a  primative asset  to  a  derivative  asset.  This  is  done  by  calculating  the  price  of  the  derivative  asset  against  the primative one and the inverting.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Incorrect redemptionWindowBuffer Check",
        "body": "  Certain  actions  through  adapters  e.g.  exchanging  Synths  through  the  Synthetix  adapter  may  block  the transfer of the asset for a period of time. The GuaranteedRedemptionPolicy ensures that a redemption blocking  adapter  is  not  used  during  the  redemption  window  nor  a  buffer  period  before  the  start  of  the guaranteed redemption window. This ensures redemption is possible during a guaranteed time window every day.  uint256 latestRedemptionWindowStart = calcLatestRedemptionWindowStart(         redemptionWindow.startTimestamp     );  // A fund can't trade during its redemption window, nor in the buffer beforehand. // The lower bound is only relevant when the startTimestamp is in the future, // so we check it last. if (     block.timestamp >= latestRedemptionWindowStart.add(redemptionWindow.duration) ||     block.timestamp <= latestRedemptionWindowStart.sub(redemptionWindowBuffer) ) {     return true; } return false;  The comment describing the code is not entirely accurate. Three cases have to be distinguished  I. A fund can't trade during its redemption window  II.a. A fund can't trade in the buffer before the next redemption window  II.b.  If  startTimestamp  is  in  the  future,  a  fund  can't  trade  in  the  buffer  before  the  first  redemption window  Note  that  calcLatestRedemptionWindowStart()  returns  either  the  start  timestamp  of  the  latest redemption window or, in case startTimestamp is still in the future, the startTimestamp.  The  current  code  checks  condition  (I)  and  (IIb)  but  does  not  check  (IIa).  Hence,  in  case  we  are  past startTimestamp and there exists a latestRedemptionWindowStart timestamp in the past, a trade in the buffer window before the start of the next guaranteed redemption period is not prevented and such a trade may prevent redemption in the guaranteed redemption timeframe.  Code Corrected:  In  the  current  implementation,  the  startTimestamp  is  required  to  be  in  the  past.  Moreover,  the redemptionWindowBuffer  is  now  subtracted  from  the  latestRedemptionWindowStart  with  the addition of one day.  Avantgarde Finance - Enzyme Protocol v4 Sulu -   15  CorrectnessLowVersion2CodeCorrected           \fif (     block.timestamp > latestRedemptionWindowStart.add(redemptionWindow.duration) &&     block.timestamp < latestRedemptionWindowStart.add(ONE_DAY).sub(redemptionWindowBuffer) ) {     return true; }  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Shadowed Constant",
        "body": "  UniswapV2PoolPriceFeed  inherits  UniswapV2PoolTokenValueCalculator.  Both  contracts  define  a constant uint256 private constant POOL_TOKEN_UNIT = 10**18;.  Code Corrected:  The shadowing variable has been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Missing Indexes in Events",
        "body": "  in  ComptrollerLib  could  use  The  PreRedeemSharesHookFailed  event  for address  of the  PreRedeemSharesHookFailed  and  BuyBackMaxProtocolFeeSharesFailed  could  be  indexed since it could facilitate queries for specific errors.  FailureReturnData   redeemer.   Moreover,   indexes   bytes   Code Corrected:  The missing indexes have been added.  Avantgarde Finance - Enzyme Protocol v4 Sulu -   16  DesignLowVersion2CodeCorrectedDesignLowVersion1CodeCorrected                \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Overestimation Of Fund's Value Under",
        "body": " Pending Liquidation  During  the  calculation  of  the  GAV  of  a  fund,  the  value  of  the  collateral  held  by  an  external  position  is taken into consideration. The calculation takes into account the fact that borrowed amount of an external position is to be returned and, thus, this amount is subtracted from the total collateral held. However, the calculation ignores a potential liquidation.  Assume  an  external  position  that  holds  100  cDAI  and  has  borrowed  75  dollars  worth  of  ETH  with  a collateral factor of 75%. Assume now that the value of ETH has increased so that the external owes 80 dollars.  When  the  GAV  is  calculated  the  external  position  will  be  evaluated  as  100  -  80  =  20  dollars. Since  the  position  is  undercollateralized,  a  liquidation  could  be  triggered.  Note  that  during  liquidations, users are incentivized to pay back the borrowed amount with an 8% discount for the collateral. When the liquidation takes place then the real value of the external position will be roughly 100 - 86.4 = 13.6. Users should be aware of that behavior which might lead to fluctuations in the GAV of the fund. Moreover, the front  end  of  Enzyme  should  indicate  potentially  undercollateralized  external  positions  to  users  prior  to investing.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Reverting Relayed Call Paid By The Fund",
        "body": "  According  to  the  GSN  protocol,  in  case  GasRelayPaymaster.preRelayedCall  fails  then  the execution is aborted. However, there might be the case where the preRelayedCall succeeds but the relayed  transaction  fails.  In  this  case,  the  fund  will  still  pay  for  the  gas.  An  interesting  case  is  the following.  The  preRelayCall  requires  the  original  _relayRequest.request.from  to  be  an authorised entity for the vault i.e., the owner or an asset manager or a migrator. However, some of the authorised calls allowed by the preRelayedCall further restrict the allowed entities. For example, a call to an integration is limited to only the owner and the asset manager. This means that in case the migrator tries  to  execute  this  function,  the  transaction  will  fail  but  paymaster  will  pay  for  the  gas.  We  assume, however, that the migrator is a trusted role who will not act against the system.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Sandwiching Authorized Actions",
        "body": "  An authorized user for a fund can use GSN to execute authorized actions. Is important to note that due to the fact that the relayer acts as an intermediary, it is easier for them to sandwich these transactions. For example,  a  relayer  can  sandwich  the  buyBackProtocolFeeShares  and  make  a  profit.  Notice  that when  buying  back  shares  the  value  of  the  shares  increases  since  the  shares  which  correspond  to  the protocol fee are burnt.  Avantgarde Finance - Enzyme Protocol v4 Sulu -   17  NoteVersion1NoteVersion1NoteVersion1          \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Unexpected Staking of Tokens",
        "body": "  Since  the  spent  assets  are  not  validated  against  the  Balancer  v2  pool's  underlying  assets, lendAndStake() could stake LP tokens from the vault along with the newly generated ones.  Consider the following scenario  1. Vault holds 1 Balancer LP  2. Manager  triggers  lendAndStake  where  the  underlyings  of  the  Balancer  LP's  pool  and  Balancer  LP are specified as spent assets.  3. 1 more Balancer LP is generated.  4. The full balance (2) of Balancer LPs is staked.  In contrast, all unused spent assets during the lending part, are returned to the vault proxy. Hence, the adapter may not behave as expected.  Risk accepted:  Avantgarde Finance replied:  This actually seems like an unintended convenience (batches the staking of held LP tokens with buying + staking new LP tokens). It is going to be the case for many/most adapters that if the manager inputs an incorrect value, there could be unintended consequences or value loss (e.g., slippage). Especially since there is no reported path that leads to value loss here, we will leave as- is.  Avantgarde Finance - Sulu Extensions VII -   11  DesignCorrectnessCriticalHighMediumRiskAcceptedRiskAcceptedLowCorrectnessMediumVersion1RiskAccepted          \f5.2   Unhandled Stake Slashing on Kiln  When computing the managed assets of an external position on Kiln, the system assumes the position holds  validatorCount  *  32  ETH  +  address(this).balance,  thus  not  considering  any  stake slashing that may have occurred. This could lead to an over-evaluation of the position if the stake gets slashed on a validator.  Risk accepted:  Avantgarde Finance replied:  Rewards and slashing are not included in the current position valuation, as this requires external oracle monitoring of the consensus layer. The actual position value will deviate by some percent from the ideal value, which will generally tend to be more and more undervalued if we assume consensus rewards outweigh slashing in most cases. For now, managers will need to be aware of this, and if they require more precision, we can integrate a simple oracle to monitor the delta.  Avantgarde Finance - Sulu Extensions VII -   12  DesignMediumVersion1RiskAccepted          \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings  lendAndStake() May Interact With Two Pools and Leave Tokens Behind   -Severity Findings   Event Emitted When Non-Existing Pool Is Removed    Missing Sanitization for _feeBps    Validation for Balancer Staking   0  0  1  3  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   lendAndStake() May Interact With Two",
        "body": " Pools and Leave Tokens Behind  lendAndStake() should mint LP tokens for a pool and stake them. However, it is possible that funds are deposited into one pool but another LP token is staked due to a potential mismatch between pool id and the staking token's LP token. Ultimately, the newly minted LP tokens are to be left in the adapter.  Consider the following scenario:  1. The vault holds LP token B.  2. A lend and stake action is started. The pool id is A, the staking token's underlying LP token is pool  with id B. The spent assets are the underlying tokens of pool id A and the LP token B.  3. Through the lending, LP token A is received.  4. If  the  adapter's  balance  of  LP  token  B  (spent  asset)  is  greater  than  its  balance  of  LP  token  A,  staking will be successful.  5. Only the spent assets are pushed back to the vault.  6. The minimum incoming checks can in the integration manager pass if the spent asset amount for  LP token B is greater than the minimum incoming amount.  Ultimately, funds can be lost.    pool   The  __parseAssetsForLendAndStake and __parseAssetsForUnstakeAndRedeem.  validated   against   staking   token's   now   the   is   underlying   BPT   in  Avantgarde Finance - Sulu Extensions VII -   13  CriticalHighMediumCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCorrectnessMediumVersion1CodeCorrected           \f6.2   Event Emitted When Non-Existing Pool Is Removed  Function  BalancerV2StablePoolPriceFeed.removePool  emits  a  PoolRemoved  event  even  if  a pool  function BalancerV2StablePoolPriceFeed.removePoolFactories  emits  events  only  if  a  previously added factory is removed.  contrast,   added.   never   was   In     The check isSupportedAsset(pool) has been added to only allow the deletion, and emission of the associated event, of an existing pool.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Missing Sanitization for _feeBps",
        "body": "  input   No  the ArbitraryTokenPhasedSharesWrapperLib.init.  One  could  deploy  with  feeBps  >  MAX_BPS intentionally or by mistake, which would block the redemption because local fees cannot be paid out.  sanitization   _feeBps   function   done   on   in   is     Input sanitization for the feeBps has been added. It must satisfy feeBps < MAX_BPS.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Validation for Balancer Staking",
        "body": "  Both,  the  Balancer  native  staking  and  the  Aura  staking,  perform  validity  checks  on  the  staking  token when  parsing  the  assets  for  staking  or  unstaking  actions.  The  validation  ensures  that  the  LP  token matches the staking token. That is typically implemented as follows:  __validateBptForStakingToken(stakingToken, __getBptForStakingToken(stakingToken));  However,  __getBptForStakingToken(stakingToken)==__getBptForStakingToken(stakingToken) which is always true. Hence, the validation is redundant and increases gas consumption.  perform   check   that   the   will   that    The redundant checks have been removed. However, no validation of the staking addresses for Balancer native staking tokens has been added.  Avantgarde Finance - Sulu Extensions VII -   14  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                      \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Unfair Distribution of Rebasing Tokens in",
        "body": " Shares Wrapper  In contrast to other system contracts, the shares wrapper for arbitrary deposit tokens does not support rebasing tokens.  For each deposit token wei deposited in the shares wrapper, one shares wrapper wei is minted to the depositor. If the deposit token is a rebasing token, that may lead to losses for early depositors in terms of rebase amounts.  Consider the following scenario:  1. Alice deposits 1 stETH and receives 1 stETH shares wrapper.  2. stETH rebases. The contract holds 2 stETH.  3. Bob deposits 1 stETH and receives 1 stETH shares wrapper.  4. Technically,  Alice  contributed  to  two  thirds  of  the  contracts  holdings  (2  stETH  out  of  3  stETH).  However, Bob and Alice both have claims to 50% of the contract's underlyings.  Ultimately, early-depositors could lose rebase amounts.  Avantgarde Finance - Sulu Extensions VII -   15  NoteVersion1  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Obsolete Storage Writes During Pool",
        "body": " Deployment  0  0  2  0  After the intermediate report, the following functions have been added to DMMPool:  function name() public override view returns (string memory) {     IERC20Metadata _token0 = IERC20Metadata(address(token0));     IERC20Metadata _token1 = IERC20Metadata(address(token1));     return string(abi.encodePacked(\"KyberDMM LP \", _token0.symbol(), \"-\", _token1.symbol())); }  function symbol() public override view returns (string memory) {     IERC20Metadata _token0 = IERC20Metadata(address(token0));     IERC20Metadata _token1 = IERC20Metadata(address(token1));     return string(abi.encodePacked(\"DMM-LP \", _token0.symbol(), \"-\", _token1.symbol())); }  The pool storage still contains the old name and symbol variables which are set during execution of the constructor.  Due  to  the  new  functions,  the  new  name  and  symbol  will  be  returned  while  the  storage variables are now obsolete.  constructor() public ERC20Permit(\"KyberDMM LP\", \"DMM-LP\", \"1\") VolumeTrendRecorder(0) {  These unnessesary storage writes makes the deployment of new pools more expensive than necessary. In  particular  100,000  gas  (roughly  20  USD  at  the  time  of  writing)  could  be  saved  during  each  pool deployment.  Kyber.Network - KyberSwap Classic - ChainSecurity  11  SecurityDesignCorrectnessCriticalHighMediumAcknowledgedLowDesignMediumVersion2           \f5.2   Actual Amplification Reduces After Unblanced Contribution  Users may add liquidity to a pool by directly invoking DmmPool.mint().  Normally,  liquidity  is  added  in  balanced  amounts  of  token0  and  token1  according  to  the  pool's inventory  as  the  amount  of  liquidity  tokens  minted  in  return  is  based  on  the  lower  contribution.  The surplus amount of the other token is kept by the pool.  After minting, the values of the virtual reserves are updated as follows:  liquidity = Math.min(     amount0.mul(_totalSupply) / data.reserve0,     amount1.mul(_totalSupply) / data.reserve1 ); uint256 b = liquidity.add(_totalSupply); _data.vReserve0 = Math.max(data.vReserve0.mul(b) / _totalSupply, _data.reserve0); _data.vReserve1 = Math.max(data.vReserve1.mul(b) / _totalSupply, _data.reserve1);  Unbalanced  contributions  reduce  the  factor  between  the  value  of  the  actual  reserve  and  the virtualReserve, hence the pool \"looses amplification\" figuratively speaking. In an extreme scenario of an unbalance contribution, which is rather costly for an attacker and has no clear benefit, the following scenario may arise:  Assume a pool has following state: reserve0 = 1000, reserve1 = 1000, vReserve0 = 2000 and vReserve1 = 2000.  1. A  user  adds  2000  token0  and  1  token1  to  the  pool.  The  values  for  vReserve0  and vReserve1 should now be 2002. However, as the pool received an additional amount of token0 the  value  of  reserve0  (3000)  is  now  higher  than  the  result  of  the  calculation  for  the  new vReserve0 amount, hence the value for vReserve0 is set to _data.reserve0.  2. This  step  may  be  repeated  for  the  other  token:  A  user  adds  3  tokens  to  reserve0  and  2998 tokens to reserve1. Then again the vReserve1 will get the value of reserve1.  3. Now it holds that reserve0 = vReserve0 and reserve1 = vReserve1.  After such a scenario an amplified pool is no longer amplified.  Note  that  a  similar  attack  vector  can  be  implemented  using  burn  for  tokens  that  accrue  rewards  on transfer.  unbalanced   The documentation provided does not describe the expected behavior when liquidity is added in case of an  section paper  Adding  liquidity  in  Ampfliciation  model  on  page  7  the  only  case  described  is  when  the contributions match the expected ratio.  Amplification   contribution.   Model,   the   In   in   Acknowledged:  Kyber is aware of this scenario and states:  Note that liquidity providers get benefits if this scenario happens and the attacker has no economic incentives to do this.  Kyber.Network - KyberSwap Classic - ChainSecurity  12  DesignMediumVersion1Acknowledged        \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings   Conflicting Statements About Contribution Ratio    Sandwich Attack on New Liquidity Providers   -Severity Findings   Outdated Compiler Version    Redundant Modulo Operation    Unused Library    Unused blockTimestampLast    Wrong Inequality    vReserve Wrong Naming   0  0  2  6  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Conflicting Statements About Contribution",
        "body": " Ratio  The document Dynamic AMM model design and rationals in section 2.3.3 Add Liquidity reads:  When users add liquidity to existing pools, they must add liquidity with the current ratio of token in the pool. The amount of mint token will be the min increase proportion of 2 tokens, the virtual balances will scale out with the mint token to assure that the price range of the pools is only bigger. Special case: the pool has reserve0=1000 and reserve1=1000 and vReserve0=2000 and vReserve1=2000. An user adds 2000 token0 and 1 token1 to the pool. The vReserve0 and vReserve1 should be 2002. But the reserve0 (3000) is higher than vReserve0. Therefore, we must vReserve0 = max(reserve0, vReserve0) to assure the assumption that vReserve0 >= reserve0  The first statement clearly states:  must add liquidity with the current ratio of token in the pool  while the next statement handles a special case where this does not hold - hence the two statements are contradicting.  The actual implementation does not enforce that adding liquidity must be done with the current ratio of the tokens in the pool.  Finally  the  rational  behind  setting  vReserve  to  reserve  in  case  the  new  value  for  vReserve  is  less than  reserve  is  not  clear.  It's  understood  that  vReserve  cannot  be  smaller  than  reserve  as  the  Kyber.Network - KyberSwap Classic - ChainSecurity  13  CriticalHighMediumSpeci\ufb01cationChangedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCorrectnessMediumVersion1Speci\ufb01cationChanged        \famplification factor must be >= 1, however it's questionable and not documented why setting the value equal to reserve is the correct action in this case.  Specification changed:  The specification has been updated and now describes the scenario of an unbalanced contribution more detailed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Sandwich Attack on New Liquidity Providers",
        "body": "  This attack works against new liquidity providers when they are adding liquidity. The overall idea of the attack  is  that  the  virtual  reserve  values  are  out  of  sync  with  the  reserve  values.  Hence,  the  slippage protection  of  addLiquidity()  can  be  circumvented.  The  reserve  values  are  brought  out  of  sync  by adding unbalanced liquidity. Adding unbalanced liquidity by itself is good for liquidity providers, but in this combination it can be used for an attack.  Prerequisites:   A pool with little liquidity, e.g. new pool   The pool is amplified   The attacker has the ability to perform a sandwich attack  Setup:   The pool has two token T0, T1   T0 is worth 100 USD   T1 is worth 1 USD   The pool is balanced, e.g. 1 T0 and 100 T1  Attacks Steps:  1. Attacker  adds  liquidity  regularly  through  the  router.  Hence,  the  pool  is  still  correctly  balanced.  In  particular the reserves and virtual reserves have the ratio 1:100.  2. The victim looks at the pool and decides to add liquidity   The  victim  uses  the  router  and  allows  for  no  slippage  or  a  tiny  amount  of  slippage  (hence,  following best practices)   The victim sets up amountADesired and amountBDesired in 1:100 ratio, also amountAMin and  amountBMin have 1:100 ratio  4. The attacker detect the victim transaction in the mempool and starts a sandwich attack  5. First attacker transaction:   The attacker swaps all of T0 out of the pool   The attacker adds unbalanced liquidity (as described in our report)   These two steps can be repeated   As a result the reserves are in a 1:100 ratio but the virtual reserves are in a different ratio, e.g.  1:210 in our example  6. The victim transaction is executed, all checks pass, the transaction is successfully completed  Kyber.Network - KyberSwap Classic - ChainSecurity  14  SecurityMediumVersion1CodeCorrected        \f7. Second attacker transaction:   Attacker removes all its liquidity from the pool, now only the victim's liquidity is in the pool   Attacker uses the incorrect ratio of the virtual reserves to execute a swap that is bad for the  victim  Effect and Analysis:   The  \"gifted\"  liquidity  through  unbalanced  minting  here  goes  back  to  the  attacker  as  they  are  the  only/primary liquidity provider  In  our  example  with  an  amplification  factor  of  100,  the  attacker  can  steal  12.69%  of  the  victim's funds. Hence, the more the victim deposits, the more can be stolen.   The attacker's funds can be smaller than the victim's funds. The percentage of stolen funds remains  the same.   This is independent of the price ratios between T0 and T1 (1:100 in this example). Different ratios  lead to the same outcome.   Other amplification factors lead to different results, but there are probably ways to make this attack  more effective  Example Numbers:  Pool after liquidity has been added:  [++] T0: 1.0 [++] T1: 100.0 [++] Value: 200.0 USD [+] Value of 1 LP Share: 20.00 USD [+] Virtual Reserves: 10.00, 1000.00  At this point all seems fine and the victim decides to add liqudity.  Pool after pre-manipulation:  [++] T0: 5.5249 [++] T1: 552.49 [++] Value: 1104.97 USD [+] Value of 1 LP Share: 110.50 USD [+] Virtual Reserves: 6.89, 1452.49  At this point the reserves are still in a 1:100 ratio, but the virtual reserves are not. There ratio is 1:210.  Pool before final swap to exploit incorrect ratios:  [++] T0: 100.0 [++] T1: 10000.0 [++] Value: 20000.0 USD [+] Value of 1 LP Share: 110.50 USD [+] Virtual Reserves: 124.68, 26290.01  At this point only the victim's liquidity is left. The ratio of the virtual reserves is still 1:210.    The router now features a slippage protection on the ratio of the virtual reserves. The function takes two new  arguments  where  users  can  specify  the  lower  and  upper  bound  for  the  ratio  between  the  virtual  Kyber.Network - KyberSwap Classic - ChainSecurity  15   \freserves. This mitigates the attack described above as the attacker can no longer arbitrarily unbalance the  virtual  reserves.  Note  that  the  protection  is  in  the  Router,  hence,  users  interacting  with  the  pool contract directly are not protected.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Outdated Compiler Version",
        "body": "  The project uses an outdated version of the Solidity compiler.  pragma solidity 0.6.6;  in  Known  https://github.com/ethereum/solidity/blob/develop/docs/bugs_by_version.json#L1378  version   bugs   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "0.6.6 ",
        "body": "  are:  More information about these bugs can be found here: https://docs.soliditylang.org/en/latest/bugs.html  At  the  time  of  writing  the  most  recent  Solidity  release  is  version  0.6.12.  For  version  0.6.x  the  most recent release is 0.6.12 which contains some bugfixes but no breaking changes.    After the intermediate report the compiler version has been updated to 0.6.12.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Redundant Modulo Operation",
        "body": "  DMMPool._update   In  operation uint32 blockTimestamp = uint32(block.timestamp % 2**32);. With optimizations enabled, for the  uint32(uint256(block.timestamp)) and uint32(uint256(block.timestamp)%2**32);.  redundant   generates   bytecode   compiler   identical   modulo   version   solidity   almost   there   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "0.6.6 ",
        "body": "  are:  More information about these bugs can be found here: https://docs.soliditylang.org/en/latest/bugs.html  At  the  time  of  writing  the  most  recent  Solidity  release  is  version  0.6.12.  For  version  0.6.x  the  most recent release is 0.6.12 which contains some bugfixes but no breaking changes.    After the intermediate report the compiler version has been updated to 0.6.12.  6.4   Redundant Modulo Operation  DMMPool._update   In  operation uint32 blockTimestamp = uint32(block.timestamp % 2**32);. With optimizations enabled, for the  uint32(uint256(block.timestamp)) and uint32(uint256(block.timestamp)%2**32);.  redundant   generates   bytecode   compiler   identical   modulo   version   solidity   almost   there   0.6.6   use   of   is   a   This code no longer exists in the updated implementation.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Unused Library",
        "body": "  Library UQ112x112 is present in the repository but never used.    The unused library has been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Unused blockTimestampLast",
        "body": "  Kyber.Network - KyberSwap Classic - ChainSecurity  16  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                                \fVariable blockTimestampLast in DMMPool is regularly updated but never used. The purpose of the variable is not documented.    The unused variable has been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Wrong Inequality",
        "body": "  DMMLibrary.getAmount  ensures  reserveOut  >=  amountOut.  However,  if  the  equality  holds  the transaction  requires amount0Out < data.reserve0 && amount1Out < data.reserve1.  swap   since   later   later   call   will   fail   in   a     The equality check has been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   vReserve Wrong Naming",
        "body": "  In  DMMLibrary.getReserves(),  the  return  values  of  DMMPool.getReserves  are  assigned  to vReserve variables while the values returned by the function correspond to the unamplified reserves.  (uint256 vReserve0, uint256 vReserve1, ) = IDMMPool(pool).getReserves();  IDMMPool(pool).getReserves() :  function getReserves()         external         override         view         returns (         uint112 _reserve0,         uint112 _reserve1,         uint32 _blockTimestampLast         ) {         _reserve0 = reserve0;         _reserve1 = reserve1;         _blockTimestampLast = blockTimestampLast; }    The naming of the variables in the code has been corrected.  Kyber.Network - KyberSwap Classic - ChainSecurity  17  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Amplification Increases Risk for Liquidity",
        "body": " Providers  A higher amplification coefficient increases the risk for the liquidity providers. Due to a large amplification factor,  larger  trade  volumes  are  required  in  order  for  the  current  price  to  be  reached.  Moreover,  the smaller spread may be exploited by arbitrage bots balancing liquidity accross markets.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Tokens With Multiple Entrypoints",
        "body": "  This is more a theoretical issue but has applied to tokens in the past. Nowadays this is a less common issue.  Some  (very  few)  tokens  have  multiple  addresses  as  entry  points,  e.g.  a  proxy  not  using delegatecall and the actual implementation contract. TrueUSD is such an example.  In the DMM system, this may has following consequences.   The check in DMMFactory.create() to prevent the creation of a pool where tokenA and tokenB  are equal can be bypassed.   A second unamplified pool may exist for the same token pair.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Volume Increase",
        "body": "  By swapping large amounts of funds of a pool with the receiver being the pool itself anyone may execute a trade with a large volume. The requirement is that some additional tokens are transferred to the pool during the callback in order to cover the fees so that the transaction can succeed.  As any swap, such a trade gets recorded in the VolumeTrendRecorder. The volume observed by the VolumeTrendRecorder may be increased by anyone willing to spend the fee in order to do so.  Kyber.Network - KyberSwap Classic - ChainSecurity  18  NoteVersion1NoteVersion1NoteVersion1          \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Calls That Sweep All ETH in EVC Can Fail",
        "body": " Silently  Calls and batch items in the EthereumVaultConnector can transfer the whole balance of the EVC by setting  the  value  to  type(uint256).max.  This  can  carry  unintended  consequences  when  calls  are nested, even in the presence of trusted systems only:  Let's consider the following setup, where the user performs a batch call with three actions: A, B, and C.  EULEVC-001   A withdraws some ether into the EVC   B performs some arbitrary operation on trusted vaults   C deposits the ether somewhere, using type(uint256).max as the value.  If B is to perform some action on the EVC that uses its ether balance, then C would fail to deposits the whole amount received in A, but the failure will in general not result in a revert.  This can be of course problematic if B triggers malicious code (the EVC documentation addresses this in the security paragraph), but it can also fail when the action performed by B is correct but also performs an EVC calls with type(uint256).max value. In the latter case, the nested EVC call performed in B would unintentionally use the whole ether amount from A.  The problem is not present when using a specified ETH value in C, because the C action would cause a revert.  The  use  of  type(uint256).max  as  value  is  therefore  safe  only  when  no  intermediate  action exists that transfers ETH to the EVC.  Risk accepted:  Euler - Ethereum Vault Connector -   12  SecurityCorrectnessCriticalHighMediumLowRiskAcceptedRiskAcceptedRiskAcceptedCorrectnessLowVersion1RiskAccepted          \fEuler accepts the risk with the following statement:  We  acknowledge  this  issue.  Considering  that  oftentimes  users  might  not  know  exactly  how  much value the EVC has received as a result of an operation, the EVC provides users with a convenient method  to  sweep  all  the  available  value  by  passing  a  special  parameter  of  type(uint256).max.  We consider this feature to outweigh potential risks associated.  As per \u201cEVC Contract Privileges\u201d section of the EVC white paper, it is not advisable for the EVC to hold  any  native  currency.  The  documentation  emphasizes  potential  risks  regarding  untrusted  code execution, but we agree it does not mention any side effects that may arise from multiple operations using special type(uint256).max and an input parameter for the EVC. The EVC white paper has been refined to sufficiently describe this behavior.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Execution of Arbitrary Code Can Cause Denial",
        "body": " of Service  The execution of arbitrary code when checks are deferred can be exploited to cause denial of service of the  EVC.  If  a  user  initiates  a  call  through  the  EVC  which  triggers  the  execution  of  malicious  code,  the whole EVC execution can be forced to revert by introducing an account or vault status checks that fails.  Arbitrary non malicious code can also introduce EVC failures by including a number of vault or account status checks that exceeds the maximum of 10 (SET_MAX_ELEMENTS).  EULEVC-003  Risk Accepted:  Euler accepts the risk with the following statement:  We acknowledge this issue. The EVC has been designed to function as a glorified multi-call contract allowing the user to execute calls into any other addresses, including contracts containing malicious code.  As  with  any  other  system  of  such  a  type,  it  is  the  user's  responsibility  to  carefully  select contracts  they  interact  with.  If  not  careful,  it  is  true  that  malicious  contracts  can  cause  denial  of service attacks. However, such attacks should never pose a greater security threat to the system as a whole and with user\u2019s care, can easily be avoided. The white paper has been refined to sufficiently describe this behavior.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   Simulations Can Be Tricked by Malicious",
        "body": " Systems  A  user  can  simulate  the  effects  of  a  batch  by  using  batchSimulation()  or  batchRevert(). However, during a simulated batch, the execution context of the EVC is updated to indicate that it is in simulation mode, by setting the SimulationInProgress flag. This flag can be checked by any vault or external system that the EVC interacts with. Therefore, malicious vaults or external systems could use this information to act differently during simulation mode, in order to trick the user into thinking that the vault/external  system  is  not  malicious.  Simulations  should  not  be  used  as  a  security  measure  to determine the effects of a batch if the systems with which the batch interacts are untrusted.  EULEVC-004  Euler - Ethereum Vault Connector -   13  SecurityLowVersion1RiskAcceptedSecurityLowVersion1RiskAccepted                \fRisk Accepted:  Euler accepts the risk with the following statement:  this   The   issue.   acknowledge   We  as operatorAuthenticated  flag,  has  been  introduced  in  the  system  on  purpose.  None  of  them  is used  internally  by  the  EVC,  they  both  have  been  introduced  so  that  they  can  be  observed  by  the external smart contracts the user interacts with through the EVC. Although, as noticed in the issue description,  those  flags  allow  the  contracts  called  to  modify  the  behavior  and  execution  path,  their existence  may  increase  the  UX  and  hence  we  consider  this  feature  to  outweigh  potential  risks associated.  simulationInProgress   same   flag,   For example, the simulationInProgress flag can be used by a vault so that the user is able to determine the outcome of the operation even if they do not currently hold tokens required to carry out such an operation, i.e. deposit into a vault.  As  with  any  other  EVC  feature,  users  should  only  use  the  EVC  simulation  with  trusted  and recognized smart contracts that do not aim to trick or harm them in any way. Considering the EVC simulation features are mostly meant to be used by the UI applications, we believe this is the natural place where user protection should be applied. If the user aims to faithfully evaluate the outcome of the simulation to assess the security of the to be executed transaction, they should resort to other methods  and  available  commercial  solutions.  The  white  paper  has  been  refined  to  sufficiently describe this behavior.  Euler - Ethereum Vault Connector -   14    \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings  -Severity Findings  Informational Findings   Gas Optimizations    setAccountOwnerInternal() Naming Is Not Accurate    Unused Variable   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Gas Optimizations",
        "body": "  0  0  0  0  3  EULEVC-005  the  EthereumVaultConnector  contract,  public   functions  requireAccountStatusCheck, In  requireVaultStatusCheck, and requireAccountAndVaultStatusCheck are decorated with the nonReentrantChecks modifier. However, the functions perform different actions depending if checks are  deferred  or  not.  Since  areChecksDeferred()  and  areChecksInProgress()  are  mutually exclusive (except transiently in the body of these functions), the reentrancy check can be moved to the internal version of the functions which is called if checks are not deferred. This saves 3 storage accesses every time one of these functions is called.  Several  gas  optimizations  can  be  implemented  in  the  Set  library,  all  pertaining  to  writing  values  into structs that share a storage slot. If a and b share a storage slot, writing a new value into a requires first loading b from storage, so that the new [a,b] value can be then written in storage. If a and b are written together, the SLOAD is prevented. The gas optimizations in question are:   At   the   end   94 (setStorage.numElements = uint8(numElements + 1)), a storage load can be prevented by also setting setStorage.firstElement, which is known, and setStorage.stamp, which is always DUMMY_STAMP in the setStorage struct.  function   insert,   around   line   of   In  function  insert  when  inserting  at  the  end  of  the  array,  line  91,  the  stamp  value  can  also  be written,  therefore  saving  a  storage  read.  To  know  which  value  to  set  for  stamp,  the element-searching  loop  that  is  performed  just  before  (lines  85-87)  can  also  be  used  to  query  the stamp values of the array. They will either all be set (for transient sets), or all unset (for persistent sets), so when setting stamp at index i, the value of stamp at index i - 1 can be used (i >= 1). If the second element is being inserted (i == 0), then the extra SLOAD can't be avoided, since the old value of stamp must be retrieved.  In  function  remove,  when  replacing  the  removed  element  with  the  last  element,  at  line  143,  the stamp value can also be written to prevent an SLOAD. The stamp value to write can be known at no extra storage load costs.  Euler - Ethereum Vault Connector -   15  CriticalHighMediumLowCodeCorrectedCodeCorrectedCodeCorrectedInformationalVersion1CodeCorrected        \fIn  function  reorder,  if  index1  ==  0,  setStorage.numElements  and  setStorage.stamp can be set to their known values to prevent an extra SLOAD.  functions  forEachAndClear  and  forEachAndClearWithResult,  when  clearing In  setStorage.numElements and setStorage.firstElement, setStorage.stamp can be set to DUMMY_STAMP to prevent an extra SLOAD.  Because some functions are only used on transient sets (forEachandClear), and some others only on persistent sets (reorder), extra optimizations are available if we accept tighter coupling between the Set implementation and the EthereumVaultConnector:  can    When  clearing  the  array  elements  in  forEachandClear  (and  forEachAndClearWithResult), we  since forEachAndClear() is only used on transient sets which are known to have every stamp set to DUMMY_STAMP.  also  write  setStorage.elements[i].stamp  =  DUMMY_STAMP,    reorder()  is  only  used  on  persistent  sets  of  accountCollaterals,  which  are  known  to  have stamp value 0 for entries of the elements array. Therefore, the stamp value can be set to 0 when writing the value of entries, saving extra SLOADs    After evaluation by Euler, some of the optimizations were implemented while others were considered to slightly complicate the logic of the contract or increase the gas consumption.  The following optimizations were implemented:  two  additional  internal  functions,  requireAccountStatusCheckInternalNonReentrant  and requireVaultStatusCheckInternalNonReentrant,  wrap requireVaultStatusCheckInternal requireAccountStatusCheckInternal  in accordingly,  have  been  added  requireAccountStatusCheck,  and requireAccountAndVaultStatusCheck functions.  the  EthereumVaultConnector  and  used   requireVaultStatusCheck   and   that   to   forEachAndClear and forEachAndClearWithResult have been modified.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Unused Variable",
        "body": "  The variable STAMP_MASK of ExecutionContext is currently unused.  EULEVC-008    This variable has been removed  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   setAccountOwnerInternal() Naming Is Not",
        "body": " Accurate  EULEVC-009  Euler - Ethereum Vault Connector -   16  InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected                \fsetAccountOwnerInternal() seems to indicate that the function is setting the account owner for a single  account.  However,  the  function  is  setting  the  owner  of  all  256  accounts  (for  the  whole  address prefix), and not just a single account.    This function has been inlined and removed.  Euler - Ethereum Vault Connector -   17  \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Account Check Can Fail When Enabling",
        "body": " Collateral  enableCollateral() will always requireAccountStatusCheck(). This can be problematic in the case  a  position  is  below  the  LTV  and  above  the  liquidation  threshold.  In  this  case,  it  will  prevent  the account from improving the position by enabling a new collateral if the amount of enabled collateral is too small to improve the position above the LTV. The same issue can arise in reorderCollateral().  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Differences Between Call to Collateral and ",
        "body": " controlCollateral  EULEVC-002  controlCollateral()  enables  the  controller  of  an  account  to  act  on  the  account's  collateral  while impersonating  the  account.  This  is  expected  to  be  used  for  example  in  liquidations,  and  the  controller should be able to use the collateral at their discretion. However, since controlCollateral() sets the setControlCollateralInProgress flag, a controller has more restrictions when interacting with a collateral than the owner, because the EVC can't be re-entered.  The  implementation  of  complex  collateral  vaults  is  therefore  restricted  to  not  interact  with  other  EVC vaults  in  methods  used  in  liquidations,  and  controller  vaults  are  restricted  to  use  methods  of  collateral vaults that are known not to interact with the EVC. This imposes design restrictions on how the liquidating vault (controller) interacts with the collateral. When asked about it, Euler stated that operations performed as part of the liquidation flow will most likely involve share transfers or asset withdrawals, and should not contain any complex logic requiring them to perform additional EVC calls.  If a vault implementation performs EVC calls when transferring shares (callThroughEVC), in case the liquidation flow includes asset withdrawal from a vault, the withdrawn asset cannot be a share token of another  vault  (vaults  nesting).  This  restriction  is  however  unlikely  to  cause  problems  because  nested vaults make a poor choice of collateral from a risk management perspective.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Inefficient ETH Transfer in ",
        "body": " callThroughEVC()  In callThroughEVC() a substantial amount of gas is spent if the message value is positive because the ether is sent to the EVC and back to the Vault resulting in the ether being moved three times instead of  once.  Every  call  that  transfers  ether  costs  at  least  6800  gas,  so  at  least  an  additional  13600  gas  is spent.  Euler - Ethereum Vault Connector -   18  NoteVersion1NoteVersion1NoteVersion1            \f7.4   Inter-dependencies in Checks  Checks  on  accounts  and  vaults  are  performed  in  the  order  they  were  added  to  the  set.  These  checks might read and modify the state of third-party smart contracts such that subsequent checks will behave differently due to the modified state. Therefore, the order in which the checks are performed can matter.  While this is not a problem for the EVC itself, it should be considered by any vault implementation that relies  on  the  EVC.  Vault  should  not  depend  on  the  order  of  checks  execution  as  it  is  not  guaranteed, since different call nesting can influence it.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   Nonces Are Shared by Addresses With",
        "body": " Colliding Prefix  While extremely unlikely, two different addresses may share the same address prefix. In this case, the first address to be authenticated with the EVC will be the owner of the address prefix preventing the other address from authenticating on behalf of the address prefix. However, the second address can still sign permit  messages  using  nonces  for  the  address  prefix.  Therefore,  the  second  address  can  invalidate nonces used by the owner's address by signing a permit message with the same nonce and front running the call to permit by the owner's address.  EULEVC-007  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.6   Vault Composability Is Limited by the",
        "body": " Maximum Amount of Deferred Checks  The amount of vaults and accounts that can be checked during the check phase is limited by the size of the  respective  sets.  Therefore,  any  nested  operation  that  results  in  more  than  10  deferred  vault  or account checks will fail.  Therefore, vaults containing other vaults could stop working with the EVC if the contained vaults change their  behavior  by  requesting  additional  checks,  which  would  lead  to  the  above-mentioned  limit  being exceeded. This is a limitation of the EVC that vault developers should be aware of.  Euler - Ethereum Vault Connector -   19  NoteVersion1NoteVersion1NoteVersion1          \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Sandwich Attack on updateState",
        "body": "  StructuredAssetVault.updateState() allows the manager to add interest payments to the vault or  default  loans  on-chain.  The  frequency  of  such  updates  is  entirely  up  to  the  manager.  Thus,  it  is possible that such updates occur rarely and add a large amount of interest at once.  If  deposits  are  allowed  during  the  Live  state  of  the  vault,  this  is  problematic  as  users  depositing  right before an update receive the same amount of interest as users that deposited earlier.  If  withdrawals  are  also  allowed  during  the  Live  state  of  the  vault,  this  behavior  becomes  exploitable. Consider the following example:  CS-TFFlourine-001   A given vault accrues 0% fees.   Each tranche accrues 0% interest (for demonstration purposes).   Each tranche holds a value of 100 tokens.   The manager disburses 150 tokens, setting outstandingAssets to 150.   After 1 year, the manager updates the outstandingAssets to 200.   An attacker frontruns the call to updateState() with a deposit of 100 tokens to the equity tranche.   After the updateState() call has been processed, the attacker can withdraw their received shares  for an instant profit of 25 tokens.  Risk accepted:  The client accepts the risk with the following statement:  Manager  should  disable  withdrawal  and  deposits  if  there  will  be  a  big  change  of  value  in  update state.  TrueFi - Fluorine -   12  SecurityDesignCorrectnessCriticalHighMediumRiskAcceptedLowSecurityMediumVersion1RiskAccepted           \fTrueFi - Fluorine -   13    \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings   Wrong Distribution of Unpaid Fees in Repay()   -Severity Findings   Disburse to 0-Address   0  0  1  1  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Wrong Distribution of Unpaid Fees in Repay()",
        "body": "  StructuredAssetVault._calculateWaterfall()  first  calculates  the  waterfall  without  fees,  then subtracts the fees from each waterfall value:  CS-TFFlourine-003  uint256[] memory waterfall = _calculateWaterfallWithoutFees(assetsLeft); uint256[] memory fees = new uint256[](tranches.length); for (uint256 i = 0; i < waterfall.length; i++) {     uint256 waterfallValue = waterfall[i];     uint256 pendingFees = tranches[i].totalPendingFeesForAssets(waterfallValue);     waterfall[i] = _saturatingSub(waterfallValue, pendingFees);     fees[i] = pendingFees; }  If all value of a vault has been disbursed before and there are unpaid fees in the tranches, a repay() will repay the unpaid fees of the tranches first and then start to add value to the senior tranche. However, due  to  the  aforementioned  calculation  of  the  waterfall,  the  unpaid  fees  of  the  lower  tranches  are  not removed from the value that is added to the senior tranche's checkpoint.totalAssets. Consider the following example:   Each tranche has 0 value, 5 tokens in unpaid fees and a deficit of 95 tokens.   A repayment of 20 tokens occurs.   Each tranche now has 0 tokens in unpaid fees.   The senior tranche now has a value of 15 tokens in its checkpoint and a deficit of 85 tokens.  Since  only  5  tokens  are  in  the  end  kept  in  the  vault's  virtualTokenBalance,  another  call  to updateCheckpoints()  updates  the  senior  tranches  checkpoint  to  just  5  tokens  and  a  deficit  of  95 tokens.  However,  since  TrancheVault.deposit()  does  not  update  its  own  deficit  before  processing  a deposit,  any  deposit  (e.g.,  1  wei)  can  cause  this  wrong  deficit  to  become  persistent  because  the checkpoint  is  updated  with  the  actual  waterfall  value  (going  from  15  tokens  to  5  tokens  +  1  wei)  and  TrueFi - Fluorine -   14  CriticalHighMediumCodeCorrectedLowCodeCorrectedCorrectnessMediumVersion1CodeCorrected        \fsubsequent  calls  to  updateCheckpoints()  can  only  calculate  the  deficit  with  the  currently  stored values.    Deficits are now stored in the TrancheVault checkpoints instead of StructuredAssetVault and are calculated  on  every  checkpoint  update  in  the  tranches.  Additionally,  TrancheVault._payFee  now limits the fees to the waterfall value of the tranche so that unpaid fees in empty tranches are no longer paid out.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Disburse to 0-Address",
        "body": "  StructuredAssetVault.disburse() allows the transfer of tokens to the 0-address. This could be problematic, for example, if a bug in the frontend the manager uses passes an uninitialized parameter to the function call.  CS-TFFlourine-004    Disbursals to the 0-address are no longer possible.  TrueFi - Fluorine -   15  DesignLowVersion1CodeCorrected        \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Event Emitted When Nothing Has Changed",
        "body": "  CS-TFFlourine-002  StructuredAssetVaultFactory.setAllowedBorrower()  event AllowedBorrowersChanged every time a borrower is added or removed. If a borrower is added that has  already  been  added  or  if  a  borrower  is  removed  that  has  already  been  removed,  the  event  is  still emitted because the return values of the EnumerableSet (the type of the _allowedBorrowers state variable) functions add() and remove() are never checked.  emits   the   TrueFi - Fluorine -   16  InformationalVersion1  \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Asset Report Identifiers Not Unique",
        "body": "  Each time the manager changes the state of the vault (regarding loans) a string identifier is added to the contract that is linked to a JSON report. However, there is no guarantee, that the manager reuses a string they have used before (except if the same string was used in the last call).  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Relevant Concerns of TrueFi Carbon Smart",
        "body": " Contract Audit Report  This audit report covers Fluorine which is dependent on some logic of another product of TrueFi: Carbon. Since both projects share similarities, the following points, which have been covered in the Carbon audit report, are also valid for Fluorine.  The report can be found at https://chainsecurity.com/wp-content/uploads/2023/07/TrueFi_Carbon_-Smar t-Contract-Audit-_-ChainSecurity.pdf (snapshot).   5.2 DoS for Start   5.3 Loan Default Frontrunning   5.4 Fee Transfer DoS   7.1 Ambiguous Deficit Data in Closed State   7.2 Compounding Interest Computed in Arbitrary Intervals   7.3 Fee Accrual in Closed State   7.4 Fee Accrual on Yield   7.5 Manager Fee Accrual   7.7 Skewed Interest Distribution   7.8 Use of Non-standard ERC20 Tokens  Please  note,  StructuredPortfolio.  that   the  Carbon   equivalent   to   StructuredAssetVault   is   called  Please  also  note,  that  a  \"loan  default\"  in  some  of  these  issues  is  equivalent  to  a  call  to StructuredAssetVault.updateState() with a value that decreases the outstanding assets of the vault.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.3   updateState in Closed State",
        "body": "  TrueFi - Fluorine -   17  NoteVersion1NoteVersion1NoteVersion1          \fThe  manager  is  able  to  call  updateState()  in  Closed  state.  Users  should  be  aware  that  it  is  still possible to receive interest payments that were not accounted for when the vault has been closed.  TrueFi - Fluorine -   18  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   DssProxy Constructor Does Not Emit",
        "body": " SetOwner Event  The constructor of DssProxy does not emit a SetOwner event. Consider emitting an event here to reflect this important storage change.  constructor(address owner_) {     owner = owner_; }    The constructor now emits the setOwner event.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Optimization of delegatecall Success",
        "body": " Check  The success check in the execute function of the DssProxy contract is as follows:  assembly {     let succeeded := delegatecall(/*...*/)     /*...*/     switch iszero(succeeded)  MakerDAO - Dss Proxy -   10  CriticalHighMediumLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \f    case 1 {         revert(add(response, 0x20), size)     } }  However, as delegatecall can only return 0 or 1, the iszero is unnecessary. Instead, one can simply check for case 0. With optimization enabled, this change saves 9 gas and 4 bytes of bytecode.    The optimization has been implemented.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Possible Failure of create2",
        "body": "  It is possible for the create2 operation to fail, in which case the returned address will be 0. This failure is not checked, which would result in isProxy[0] being set to 1. Additionally, the owner's seed would be incremented despite not having deployed a contract.  assembly {     proxy := create2(/*...*/) } proxies[owner_] = proxy; isProxy[proxy] = 1;    The code now ensures that the DssProxy has been successfully created:  require(proxy != address(0), \"DssProxyRegistry/creation-failed\");  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Possible Optimization in Proxy Check of",
        "body": " Registry  In the claim function of the DssProxyRegistry, the following check is made:  require(isProxy[proxy] == 1, \"DssProxyRegistry/not-proxy-from-this-registry\");  The  isProxy  mapping  only  contains  the  values  0  or  1.  Hence,  checking  the  condition  ==  1  is functionally  equivalent  to  checking  the  condition  !=  0.  The  latter  check  is  more  efficiently  compiled,  it saves 6 gas and reduces bytecode by 3 bytes.    MakerDAO - Dss Proxy -   11  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \fThe optimization has been implemented.  MakerDAO - Dss Proxy -   12  \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   No Event on execute",
        "body": "  Integrations must be aware that compared to the DSProxy it replaces, DssProxy no longer emits a event on execute().  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   isProxy Might Point to Addresses Without",
        "body": " Code  When creating a proxy with the build function, an entry is created in isProxy, which maps the address of the new proxy to 1 :  function build(address owner_) external returns (address payable proxy) {     /*...*/     isProxy[proxy] = 1; }  This  entry  cannot  be  modified.  Hence,  a  proxy  that  has  been  selfdestructed  would  still  appear  in isProxy like a valid proxy.  A selfdestructed proxy in the isProxy mapping would have prevented creation of a new proxy for the owner  using  DssProxyRegistry.build():  Retrieving  the  owner  would  have  reverted.  The implementation of DssProxyRegistry.build() has been changed to handle this case.  MakerDAO - Dss Proxy -   13  NoteVersion1NoteVersion1      \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Double Counting During Maple Migration",
        "body": "  During the migration of Maple positions, double counting of Maple LP tokens is possible as there are no restrictions enforced on lend().  Consider the following scenario:  1. The position holds 10 v1 LP tokens.  2. The snapshot is taken and snapshots are frozen.  3. The  airdrop  of  v2  LP  tokens  happens  and  the  position  receives  10  v2  LP  tokens.  Note  that getManagedAssets() does not consider v2 LP tokens since the v2 pool is not tracked. Hence, the valuation is 10 v1 LP tokens.  4. The  manager   tokens.  Now, getManagedAssets() considers both v1 and v2 LP tokens since lending will start tracking the v2 pool. Hence, the valuation is 10 v1 LP tokens and 20 v2 LP tokens.  to  Maple  v2  and  creates  10  v2  LP   tokens   lends   Thus, funds could be overvalued between airdop and migration execution.    Lending is now only allowed if the position has been migrated.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Incorrect Comment",
        "body": "  On  AddOnlyAddressListOwnerConsumerMixin there is the following comment:  __validateAndAddListItemIfUnregistered   the   function   of  Avantgarde Finance - Sulu Extensions VIII -   13  CriticalHighCodeCorrectedMediumLowSpeci\ufb01cationChangedCodeCorrectedCorrectnessHighVersion1CodeCorrectedCorrectnessLowVersion1Speci\ufb01cationChanged                 \f/// @dev Helper to lookup an item's existence and then attempt to add it. /// AddOnlyAddressListOwnerBase.addToList() performs validation on the item.  The  addToList  function  does  not  actually  perform  the  validation.  The  __validateItems  function does.  Specification changed:  The comment now specifies that the function addValidatedItemsToList() is used.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Unused Import",
        "body": "  MapleV1ToV2PoolMapper  which is unused.  imports  \"@openzeppelin/contracts/token/ERC20/ERC20.sol\"    The import has been removed.  Avantgarde Finance - Sulu Extensions VIII -   14  DesignLowVersion1CodeCorrected        \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Lido Rebasing",
        "body": "  Lido  has  epochs  for  rebasing.  It  could  be  possible  to  sandwich  oracle  updates  with  buying  and  selling shares.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Maple V2 Migrations Can Start Before",
        "body": " Snapshots  allowMigration() is a governance function that should be called after all snapshots. Note that there is no sanity check that all snapshots have been made. Governance should not call this function too early.  Further,  note  that  the  function  should  only  be  called  after  snapshots  have  been  disallowed  with freezeSnapshots().  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Pool Address",
        "body": "  Note  that  for  the  Aave  v2  and  Aave  v3  adapters,  the  lending  pool's  address  is  stored  and  not  queried from Aave's registry. Managers should be aware that the (lending) pool address used could be outdated.  Avantgarde  Finance  plans  to  upgrade  the  library  contract  in  the  case  that  the  lending  pool  address changes.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   Potential Maple V2 Rollback",
        "body": "  Note  that  Maple  V2  could  rollback  their  migration  process.  Avantgarde  Finance  should  be  aware  and quick to react.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   Redeemable Amount",
        "body": "  The action RedeemV2 tries to redeem the input amount poolTokenAmount. However, note that Maple's WithdrawalManager contains the following code  Avantgarde Finance - Sulu Extensions VIII -   15  NoteVersion1NoteVersion1NoteVersion1NoteVersion1NoteVersion1                  \frequire(requestedShares_ == lockedShares_, \"WM:PE:INVALID_SHARES\");  Hence, managers should be aware that RedeemV2 will only succeed if poolTokenAmount is equal to its locked shares.  Avantgarde Finance prefers this in case future implementations of Maple change this logic.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.6   Reverts on Batching Maple Migration",
        "body": "  The Maple mapper contract implements a batched function for migrating to v2. If a position has already been migrated, the batched function may revert.  Avantgarde Finance replied:  Pretty unlikely to occur and nicer to be able to easily preview a tx failure by not skipping reverting items.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.7   Theoretical Out-Of-Gas During Maple V2",
        "body": " Migrations  snapshotPoolTokenV1BalanceValues()  and  migratePoolsV1ToV2()  load  all  used  pools  from storage.  Theoretically,  these  functions  could  result  in  an  out-of-gas  problem  that  cannot  be  resolved without a contract upgrade.  In contrast, if too many pools are added for getManagedAssets(), this can be resolved by a manager.  Avantgarde Finance - Sulu Extensions VIII -   16  NoteVersion1NoteVersion1        \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Floating Pragma",
        "body": "  The  contract  HTX  uses  the  floating  pragma  ^0.8.0.  Although  this  contract  has  been  compiled  with Tron's  Solidity  version  0.8.20  and  is  already  deployed,  we  would  like  to  note  that  contracts  should always  be  deployed  with  the  compiler  version  and  flags  that  were  used  during  testing  and  auditing. Locking  the  pragma  helps  to  ensure  that  contracts  are  not  accidentally  deployed  using  a  different compiler version and help ensure a reproducible deployment.  CS-HTX-001  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Optimizations",
        "body": "  CS-HTX-002  The codebase could be more efficient in terms of energy usage. Reducing the energy costs may improve user experience. Below is a list of potential inefficiencies:  1. The  contract  HTX  uses  Solidity  version  0.8.x  which,  by  default,  implements  overflow  and  underflow checks. Therefore, the use of library SafeMath is redundant and could be avoided.  2. Furthermore, the functions mul(), div() and mod() of the library SafeMath remain unused.  3. The internal functions _burn() and _burnFrom() are unused in the codebase.  4. The storage variable _decimals could be immutable as it is only set in the constructor. This would  reduce the number of storage operations made when decimals() gets called.  5. The  functions  increaseAllowance()  and  decreaseAllowance()  perform  a  redundant  SLOAD operation when emitting the Approval event.  HTX DAO - HTX -   10  InformationalVersion1InformationalVersion1      \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Locked Assets",
        "body": "  Tokens (TRX, TRC-20 or similar) could be accidentally/intentionally sent to the HTX contract. In that case the tokens will be locked, with no way to recover them. Incidents in the past showed this is a real issue as there always will be users sending tokens to the token contract.  Note that TRX and tokens can be forced into any contract and get locked if there is no \"recover\" function.  HTX DAO - HTX -   11  NoteVersion1  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Mismatches With Documentation and Lack",
        "body": " Thereof  Documentation  plays  a  crucial  part  for  understanding  a  codebase  and  integrating  it  into  a  live  system. However,  the  code  lacks  project  specific  documentation  and  is  only  described  in  a  generic  way  in  the MakerDAO Oracle documentation.  Moreover, the interfaces of the CurveLPOracle mismatch the interface specified:   The  documentation  specifies  step()  to  take  a  uint16  as  an  input  parameter  while  the  code defines  step(uint256)  which  checks  that  a  provided  argument  does  not  exceed  the  maximum uint16.   Documented  function  change()  is  missing.  However,  link()  is  undocumented  but  implements  the specified functionality of change().   According to documentation, stop() should only set the stopped flag while void() should set the flag but also reset nxt, cur and zph. In contrast, void() is missing while stop() implements the semantics of void().  Similarly StETHPrice deviates from the MakerDAO medianizer documentation.  Acknowledged:  MakerDAO acknowledges this.  MakerDAO - Curve LP & stETH oracle -   10  DesignCorrectnessCriticalHighMediumLowAcknowledgedCorrectnessLowVersion1Acknowledged            \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings  -Severity Findings   Curve Registry    Outdated Compiler Version    Potential Inconsistency   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Curve Registry",
        "body": "  0  0  0  3  According to the Curve Documentation of their registry contracts, the central source of truth in the Curve system  is  the  address  provider.  That  contract  allows  changing  the  registry  through  set_address() when the id parameter is set to zero. Currently, the oracle stores the registry as an immutable. Hence, in case the registry changes, the oracle will utilize a wrong registry.    The registry is now queried from the address provider.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Outdated Compiler Version",
        "body": "  The  solc  version  is  fixed  to  version  0.8.9.  The  introduced  changes  in  versions  0.8.10  and  0.8.11 could reduce gas consumption of the inline-assembly code of poke().    Compiler version 0.8.11 was chosen.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Potential Inconsistency",
        "body": "  step() sets a new value to hop which specifies the minimum time between calls to poke(). Function zzz() should return the time of the last poke().  MakerDAO - Curve LP & stETH oracle -   11  CriticalHighMediumLowCodeCorrectedCodeCorrectedCodeCorrectedCorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \fConsider now the following scenario where hop is 1 hour and the zph is set to the current time + 1 hour. Assume that a call to step() sets hop to 10 minutes. Now, zzz() returns current time + 50 minutes which is in the future. Moreover, the next poke requires waiting for one hour instead of only 10 minutes.  Ultimately, that could lead to temporary inconsistencies.    zph (Time of last price update plus hop, the minimum time between price updates) is now updated on step() using the new value of hop. The update of zph is skipped when it hasn't been set yet but hop is updated.  MakerDAO - Curve LP & stETH oracle -   12  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   zkAllocation May Not Behave as Expected",
        "body": "  CS-STUAGG-004  The  zkAllocation  function  is  assumed  to  only  be  called  with  a  lender  allocation  that  increases  the total APR of the aggregator.  However, the possible allocations depend on the state of the blockchain at execution time, which is likely impossible  to  know  at  proof  generation  time.  In  particular,  the  aggregator.update_debt  function gives no guarantees on how much it will withdraw or deposit when it is called with a certain target debt. It may deposit/withdraw more or less than expected, depending on the current state.  In general, the aggregator will try to get \"as close as possible\" to the target debt, but will not revert even if far away from the target. For example, a call that tries to reduce debt by 100, but due to tokens being locked in the strategy, only reduces debt by 1, will not revert. However, there will be a revert if there is a call that would deposit or withdraw a zero amount.  Consider the following illustrative example:  1. There  are  two  lenders,  A  and  B.  Both  have  a  debt  of  100.  The  minimum_total_idle  of  the  aggregator is set to 10. There are 210 tokens in the aggregator in total.  2. The interest rates change such that A now has a slightly lower interest rate than B.  3. A zk proof is generated, that claims that a better allocation of tokens would be 90 tokens in A, and  110 tokens in B. This is true at proof generation time.  4. Someone withdraws 5 tokens from the aggregator.  5. The zkVerifier verifies the proof, and calls zkAllocation().  6. update_debt(A,90)  is  called.  It  was  expected  at  proof  generation  time  that  this  withdraws  10 tokens. However, since then, assume the internal balances of A have changed, and only 7 tokens are withdrawable. 7 tokens are added to the total_ idle.  Sturdy - Sturdy Aggregator -   9  DesignCorrectnessCriticalHighMediumRiskAcceptedLowAcknowledgedDesignMediumVersion1RiskAccepted          \f7. update_debt(B,110)  is  called.  It  was  expected  at  proof  generation  time  that  this  deposits  10 tokens. However, now the total_idle of the aggregator is only 12 and the minimum is 10, so only 2 tokens are deposited to B.  8. zkAllocation()  successfully  returns.  Now  the  balances  are  A:  93  and  B:  102.  This  has  a lower APR than if there had been no change and the balances had stayed A: 100 and B: 100.  There  can  be  many  lender-specific  conditions  that  limit  how  much  can  be  added/withdrawn.  These conditions  can  be  dependent  on  the  current  state  of  the  blockchain,  with  no  way  to  know  the  limits  in advance.  As  the  allocation  zk  proofs  must  be  generated  ahead  of  execution  time,  it  does  not  seem possible  that  they  can  take  all  of  these  limits  into  account.  This  may  lead  to  cases  where  a  zk  proof verifies,  but  the  resulting  APR  is  lower.  A  malicious  actor  may  even  be  able  to  frontrun  the zkAllocation call to change the state such that the allocation becomes worse.  Zk  proof  generation  should  also  consider  the  effects  of  process_report,  which  can  change current_debt,  otherwise  update_debt  may  lead  to  more  tokens  deposited  to  that  lender  than expected.  The severity of this issue depends on what exactly is proven in the zk proofs, which is out of the scope of this audit and is treated as a black box.  Risk accepted:  Sturdy understands and accepts the risk.  Sturdy responded:  The time period between proof generation and execution time will be quite small, so changes are unlikely. Given that there is no risk of lost funds (only suboptimal yield), we're accepting this risk for the time being and will consider lender-specific limits in the future.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   borrowAsset() Slippage Protection",
        "body": "  Silo.borrowAsset()  returns  the  amount  of  shares  debited  when  borrowing.  However,  this  value  is ignored  by  SiloGateway.borrowAsset().  The  received  amount  of  shares  may  be  smaller  than expected.  CS-STUAGG-010  Acknowledged:  Sturdy acknowledges and understands the issue. Sturdy states:  The value to be compared depends on the external silo's logic (ex: Fraxlend, Aave V3, Compound V3). Slippage protection will be added where needed.  Sturdy - Sturdy Aggregator -   10  DesignLowVersion1Acknowledged          \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings   Sorting of the Lenders Is Incorrect   Idle Assets Not Used for requestLiquidity    Utilization Limit Does Not Take Into Account JIT Liquidity    Utilization Limit Only Enforced on Requesting Lender    utilizationLimit Is Not Always Enforced   -Severity Findings  Incorrect Code Comment    Reentrancy Guards Applied Inconsistently   Informational Findings   Gas Optimizations    Missing Input Sanitization    Misleading Error Names   0  0  5  2  3  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Sorting of the Lenders Is Incorrect",
        "body": "  The sortLenderWithAPR function was updated in   .  The  algorithm  that  sorts  the  lenders  by  APR  only  swaps  the  lenders'  addresses  in  the  array,  but  the positions in the new APRs array are not swapped. This leads to the list of APRs being out of sync with the list of lenders, which leads to incorrect sorting comparisons.  CS-STUAGG-013  Example result of the implemented algorithm:  lenders = [A, B, C, D]   aprs = [0, 1, 0, 0]   result of the sorting: [A, D, B, C]   correct result should have B at the end of the array    Sturdy - Sturdy Aggregator -   11  CriticalHighMediumCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedLowSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCorrectnessMediumVersion2CodeCorrectedVersion2           \fThe  codebase  has  been  updated  so  that  the  array  of  APRs  is  also  updated  along  with  the  array  of lenders, fixing the issue.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Idle Assets Not Used for requestLiquidity",
        "body": "  CS-STUAGG-001  In DebtManager, requestLiquidity() has the following check:  if (requiredAmount > totalIdle) {         unchecked {             requiredAmount -= totalIdle;         }     }  This will use idle liquidity to partially fulfill a request, but only if the requiredAmount is more than the idle amount.  If there are enough idle assets to cover the entire requiredAmount, they will not be used at all.    The  code  has  been  updated  such  that  if  the  totalIdle  amount  is  greater  or  equal  to  the requiredAmount, the idle assets will be used and nothing will be pulled from other lenders.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Utilization Limit Does Not Take Into Account",
        "body": " JIT Liquidity  When borrowing from a silo, even if JIT liquidity can be performed, there is a limit on the utilization of the silo before the liquidity transfer. The utilization of the silo, before JIT liquidity is taken into account, cannot exceed 100%.  CS-STUAGG-002  Example:  1. Silo A has 100k, silo B has 900k.  2. A user wants to borrow 300k from silo A, but this will revert since the computed utilization rate will  be 3 * PREC_UTIL (300%).    The utilization limit check before JIT liquidity is taken into account has been removed.  Sturdy - Sturdy Aggregator -   12  DesignMediumVersion1CodeCorrectedDesignMediumVersion1CodeCorrected                  \f6.4   Utilization Limit Only Enforced on Requesting Lender  When calling borrowAsset(), the utilization limit is only enforced on the requesting silo, but not on the other lenders, which can be fully utilized if JIT liquidity is used.  There could be situations where all the silos are fully utilized but one.  CS-STUAGG-014    The utilization limit can now be set per lender in DebtManager and is enforced in borrowAsset in the requesting lender, but also in the lenders from which the liquidity is being pulled.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   utilizationLimit Is Not Always Enforced",
        "body": "  In borrowAsset(), requestLiquidity() is called with the _amount that should be deposited to the Silo such that the utilizationLimit is respected. However, requestLiquidity() can deposit a smaller amount than what is expected.  The amounts that are withdrawn from other lenders by the aggregator are calculated as follows:  CS-STUAGG-003  newDebt = aggregator.update_debt(lenders[i], newDebt);         unchecked {             withdrawAmount = lenderData.current_debt - newDebt;         }  This does not always correctly calculate the withdrawAmount. When withdrawing from a lender, there can be an unexpected loss. In this case, the withdrawn amount will be smaller than the change in debt.  Consider the following excerpt from VaultV3, which is the implementation of aggregator:  # making sure we are changing idle according to the real result no matter what. # We pull funds with {redeem} so there can be losses or rounding differences. withdrawn: uint256 = min(post_balance - pre_balance, current_debt)  # If we got too much make sure not to increase PPS. if withdrawn > assets_to_withdraw:     assets_to_withdraw = withdrawn  # Update storage. self.total_idle += withdrawn # actual amount we got. # Amount we tried to withdraw in case of losses self.total_debt -= assets_to_withdraw  new_debt = current_debt - assets_to_withdraw  The  withdrawAmount  value  that  should  be  calculated  in  requestLiquidity()  is  actually withdrawn, the change in total_idle.  Sturdy - Sturdy Aggregator -   13  DesignMediumVersion1CodeCorrectedCorrectnessMediumVersion1CodeCorrected              \fIf there is a loss while withdrawing from the lender, an insufficient amount of totalIdle will be available when  depositing  than utilizationLimit, but in cases where losses are large or utilizationLimit is configured to be close  to  100%,  the  Silo.borrowAsset()  call  at  the  end  of  SiloGateway.borrowAsset()  will revert, as there will not be enough funds in the Silo.  to  a  higher  utilization   In  most  cases   the  Silo.   this  will   lead   to   :  The  code  now  uses  an  accurate  amount  of  tokens  to  reduce  requiredAmount.  However,  two conditions have been added in the DebtManager.requestLiquidity() logic.  One early-return check in the for loop:  if (requiredAmount < minIdle) break;  And one require check after the for loop:  require(requiredAmount <= minIdle, Errors.AG_INSUFFICIENT_ASSETS);  Recall that requiredAmount = amount + minIdle. If requiredAmount is greater than 0, it means that  the  current  idle  amount  is  smaller  than  amount  +  minIdle.  When  updating  the  debt  of  the requesting  lender,  the  aggregator  will  still  keep  minIdle  and  the  amount  sent  to  the  lender  can  be smaller than amount. This would lead to the requesting lender exceeding its utilizationLimit.    The  codebase  has  been  updated  so  that  DebtManager.requestLiquidity()  compares  the aggregator's totalIdle before and after the call to update_debt() to know exactly how many tokens have been withdrawn from the lender.  The early-return check has been removed and the require check corrected to  require(requiredAmount == 0, Errors.AG_INSUFFICIENT_ASSETS);  which ensures that enough assets have been retrieved.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Incorrect Code Comment",
        "body": "  On the manualAllocation function, there is the following comment:  CS-STUAGG-005  @dev Manual update the allocations. Calculate the newAPR, curAPR and if newAPR < curAPR then it would be failed.  However, there is no check in the code that makes the call fail if newAPR < curAPR. The admin could input any manual allocation, no matter the resulting APR.  Spec changed:  The comment has been removed.  Sturdy - Sturdy Aggregator -   14  Version2CorrectnessLowVersion1Speci\ufb01cationChanged          \f6.7   Reentrancy Guards Applied Inconsistently  The SiloGateway has a reentrancy guard on its borrowAsset function, but DebtManager does not have a reentrancy guard on requestLiquidity().  Note  that  there  can  be  multiple  SiloGateway  for  each  DebtManager,  so  it  could  technically  be possible to reenter requestLiquidity().  CS-STUAGG-012    A reentrancy guard has been added to requestLiquidity() in DebtManager.  It  has  also  been  clarified  that  the  system  is  not  intended  to  be  used  with  reentrant  tokens  such  as ERC-777.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   Gas Optimizations",
        "body": "  CS-STUAGG-006  1. The  functions  DebtManager.removeLender  and  SiloGateway.borrowAsset  could  be  payable to save gas.  2. In the function DebtManager.requestLiquidity the condition for continue could be moved  at the beginning of the for loop. This avoids unnecessarily loading from storage.  3. The function DebtManager.requestLiquidity could avoid the big for loop if the totalIdle  amount is enough to cover requiredAmount.  4. The  function  DebtManager.sortLendersWithAPR  makes  a  lot  of  calls  to  the  APR  oracle.  These calls could be cached to avoid querying the same value multiple times.    1. No change. Sturdy states:  Since anyone can call DebtManager.removeLender and SiloGateway.borrowAsset, they should not be payable in order to prevent the user from potentially sending ether and losing funds.  2. The condition has been moved at the beginning of the loop.  3. If the total idle assets are enough to cover the required amount, the loop is completely skipped.  4. The APR is queried once for every lender in an independent loop before sorting.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   Misleading Error Names",
        "body": "   The  error  returned  by  DebtManager._manualAllocation()  when  the  new  debt  exceeds  the  lender's max debt should be AG_HIGHER_DEBT  CS-STUAGG-007  Sturdy - Sturdy Aggregator -   15  DesignLowVersion1CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected                  \f The error returned by DebtManager.requestLiquidity() when the requiredAmount is not  equal to zero should be AG_INSUFFICIENT_ASSET   The errors returned when the lender's address is not active should be AG_INVALID_LENDER    The error names have been changed to more accurately reflect the error.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   Missing Input Sanitization",
        "body": "  The  SiloGateway  utilizationLimit_. It could accidentally be set to more than 100%.  constructor  and  setUtilizationLimit   CS-STUAGG-008  function  do  not   sanitize    The logic related to the utilization limits has been moved to the DebtManager, where input sanitization is properly done. The limits are enforced to be strictly smaller than UTIL_PREC.  Sturdy - Sturdy Aggregator -   16  InformationalVersion1CodeCorrected      \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   manualAllocation Can Ignore Unrealized",
        "body": " Losses  In manualAllocation(), there is the following check:  if (lenderData.current_debt == position.debt) continue;  CS-STUAGG-011  This is intended to skip a lender if there should be no change to its debt.  the  current_debt  However,  assess_share_of_unrealised_losses().  value  may  be  outdated,  as   there   is  no   call   to  As a result, the debt of the position when including unrealized losses may be different than expected.  Acknowledged:  Sturdy responded:  Unrealised losses will be very rare; in the event they do occur, process_report() will be called before manualAllocation() to prevent a discrepancy.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   zkAllocation Could Contain Duplicates",
        "body": "  In  _manualAllocation(),  there  is  no  check  that  unique  lenders  are  included  in  the  input. zkAllocation() has a length check on the new positions array, but there may be duplicate entries.  The admin may call _manualAllocation() with any values.  Additionally,  the  existence  check  for  positions  happens  after  continue.  As  a  result,  a  non-existent position could be included in the array if the new position.debt is 0.  CS-STUAGG-009  Acknowledged:  Sturdy responded:  To reduce gas costs, we don't check duplicate entries. This is a permissioned function, so the admin and zkVerifier will avoid duplicated lenders.  Sturdy - Sturdy Aggregator -   17  InformationalVersion1AcknowledgedInformationalVersion1Acknowledged          \fAdditionally,  the  existence  check  for  positions  has  been  moved  to  before  the  continue  in  the _manualAllocation loop.  Sturdy - Sturdy Aggregator -   18  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Exchange Rate Rounding Errors",
        "body": "  BaseConicPool.deposit() allows users to add funds to the protocol while no shares are minted. On a  new  pool,  a  user  can  donate  some  tokens  to  the  contract  before  calling  deposit()  with  an underlyingAmount of 0. The donated tokens are then added to the contract holdings while no shares are minted for the user. After that, the user can deposit 1 wei of tokens, minting them exactly 1 wei of shares.  CS-CCP-006  The exchange rate is skewed:  totalUnderlying_.divDown(lpSupply);  Since the amount of deposited tokens by other users is divided by this exchange rate to determine the amount  of  minted  shares,  the  results  can  include  large  rounding  errors.  Users  that  are  not  depositing multiples of the initially deposited amount will incur slippage (up to 100%) which results in either Denial of Service or, if they choose a loose slippage parameter, loss of funds.  For  example,  a  donation  of  10,000  USDC  and  a  subsequent  deposit  of  another  user  of  15,000  USDC would result in the second user getting only 1 wei of LP tokens, thus losing 2,500 USDC to the first user.  It is also possible to burn LP tokens without decreasing the underlying in withdraw().  Conic - Conic Protocol -   15  SecurityDesignCorrectnessCriticalHighMediumRiskAcceptedRiskAcceptedLowRiskAcceptedCodePartiallyCorrectedRiskAcceptedRiskAcceptedRiskAcceptedDesignMediumVersion1RiskAccepted              \fRisk accepted:  Conic accepts the risk claiming that all pools will be atomically seeded by the team on deployment. In that case, the mentioned attack is not possible.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   No Governance Default Delay",
        "body": "  Conic governance decisions are computed off-chain. Based on the results, a multi-sig address with the GOVERNANCE_ROLE  on  the  GovernanceProxy  can  then  request  changes  and  execute  them. Depending  on  the  function  signatures  these  changes  are  going  to  call,  a  delay  is  invoked  so  that  a separate multi-sig address (VETO_ROLE) that belong to different entities can veto the change.  However,  no  default  delay  is  enforced  which  means  that  the  GOVERNANCE_ROLE  can  perform  any actions that have not explicitly been marked directly, evading any possible vetos.  CS-CCP-008  Risk accepted:  Conic accepts the risk with the following statement:  We do not want a delay for all the functions. The community and veto multisig can easily check which functions have a delay and which does not.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   Instant Rewards",
        "body": "  RewardManager performs reward calculations and actual reward claiming in separate steps. Only when certain conditions are met, rewards are actually claimed. This approach is, however, flawed for Convex' extra rewards as the reward calculation is only performed during the claim step here. If claiming has not occurred for a longer period, the accrued extra rewards are added to the earned rewards of all users in bulk the next time they are claimed.  CS-CCP-018  that   User  call RewardManager.claimPoolEarningsAndSellRewardTokens() directly after staking and instantly receive some CNC rewards in this case.  LpTokenStaker   deposited   tokens   have   can   the   LP   to   Risk accepted:  Conic accepts the risk with the following statement:  Very  few  pools  have  extra  rewards  (not  any  that  we  currently  support)  and  the  chances  of  these rewards becoming an important part of the APR is low enough for us to accept this risk.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.4   Missing Checks",
        "body": "  The protocol is missing some checks that could potentially lead to a problematic state:  CS-CCP-021  Conic - Conic Protocol -   16  SecurityMediumVersion1RiskAcceptedDesignLowVersion1RiskAcceptedCorrectnessLowVersion1CodePartiallyCorrectedRiskAccepted                          \f RewardManager.addExtraReward() checks that the added reward token is not an LP token of one of the Curve pools of the associated LP tokens. If, however, a Curve pool is added to the Conic pool at a later stage, its LP token might have already been added.   RewardManager.addExtraReward()  does  not  check  whether  there  is  a  valid  SushiSwap  or  Curve pool for a given reward token.   Neither   nor _swapRewardTokenForWeth() check whether a given Curve pool actually holds the asset that is going to be swapped on it.  RewardManager.setExtraRewardsCurvePool()    RewardManager.removeExtaReward()  does  not  check   that   the  specified  argument   is  successfully removed from the extra rewards list.   Bonding.startBonding()  does  not  check  whether  an  epochPriceIncreaseFactor  is  set.  Since there exists a minimum for the factor, it should be set before starting the bonding period.  Code partially corrected:  Bonding.startBonding() now checks if the epochPriceIncreaseFactor has already been set.  Risk accepted:  Conic accepts the risk for all other missing checks with the following statement:  We accept the risk for the extra rewards.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.5   No Reward Checkpoint When Unstaking",
        "body": "  LpTokenStaker.unstakeFor() does not call RewardManager.accountCheckpoint() when the staker is shut down. Users unstaking on such a shut down staking contract will lose their rewards since the last checkpoint but users that call accountCheckpoint() before unstaking will keep their rewards.  CS-CCP-022  Risk accpted:  Conic accepts the risk with the following statement:  This is an extremely rare event, in which case we will inform our users beforehand so that they claim their rewards.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.6   Stale Oracle Price Means Token Is Not",
        "body": " Supported  ChainlinkOracle.isTokenSupported()  calls  getUSDPrice()  to  determine  whether  a  token  is supported by the oracle. If the price is stale (older than the heartbeat), the function erroneously returns false.  CS-CCP-024  Conic - Conic Protocol -   17  DesignLowVersion1RiskAcceptedCorrectnessLowVersion1RiskAccepted                \fRisk accepted:  Conic accepts the risk with the following statement:  We only use isTokenSupported in two places:  1. When adding a new curve pool to the registry. If it fails here, we can retry later.  2. When  claiming  extra  token  rewards.  In  the  unlikely  event  that  it  fails  here,  we  accept  the  slippage risk when swapping extra rewards.  Conic - Conic Protocol -   18    \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings   Endless Rebalancing    Execution of Wrong Governance Change   -Severity Findings   Depeg Due to Oracle Manipulation    Wrong Accounting in Bonding   -Severity Findings   Bonding lastCncPrice Manipulation With Leftover Dust    Extra Reward Tokens Not Sent to RewardManager    Higher Imbalance Tolerance in Metapools   Incomplete Pool Balance Check    Oracle Price Manipulation    Reward Double Counting    Slippage Losses Are Socialized    Weight Update Rounding Errors    Wrong Denomination of Deviation Delta   -Severity Findings   Possible Zeroed Pool Weight Increase    Reward Factor Override    Boost After Shutdown    CNCLockerV3 Lock Squatting    Claimable Rewards Potentially Wrong    Enabled Fee Not Reset    Endless Loop    Lock Spam DoS    Minimum Tainted Transfer Amount Can Be Circumvented    Rebalancing Reward After Depeg    Unreachable Imbalance Buffers    Wrong TVL Factor    Wrong Time to Full Boost   Informational Findings  Conic - Conic Protocol -   2  2  9  13  9  19  CriticalCodeCorrectedCodeCorrectedHighCodeCorrectedCodeCorrectedMediumCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrected \f removeDuplicates Not Working With 0 Elements    Fees Without Locked CNC    Exchange Rate Race Condition   Interface Differences    Ambiguous Naming    Typographical Errors    Rebalancing Reward Formula Mismatch    Missing Events    Shadowed Variables   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Endless Rebalancing",
        "body": "  CS-CCP-001  As detailed in Depeg due to oracle manipulation, Curve pools can be depegged wilfully at any time. On new Conic pools, or pools with very low TVL, this is even more problematic because an infinite amount of rebalancing rewards can be claimed.  This is possible by donation of Curve LP tokens to the Conic pool. When the attacker is the only liquidity provider on a Conic pool, or if they hold most of the LP tokens, all donated value is given straight back to them. Therefore, the donations are free (or almost free), enabling this attack:  1. The attacker deposits to an empty Conic pool.  2. The attacker depegs one of the underlying Curve pools, enabling rebalancing rewards.  3. The  attacker  rebalances  the  Conic  pool  to  almost  the  maxDeviation  threshold,  so  that  the  rebalancing rewards are still active.  4. The attacker adds liquidity directly to the Curve pool, sends these tokens to the Conic pool.  5. The attacker repeats step 3 and step 4 as often as possible.  6. The attacker withdraws their LP tokens from the Conic pool (in the next block).  As long as the attacker gains more CNC rewards per iteration than they lose to other Conic LPs (only relevant if they are not the only LP), the attack is profitable and can be performed indefinitely, allowing them  to  mint  CNC  up  to  the  _MAX_REBALANCING_REWARDS.  The  only  cost  is  the  amount  of  tokens needed to increase the LP token price of a given Curve pool by the depeg threshold. Therefore, small Curve pools are more vulnerable.    A  new  (off-chain)  threshold  for  a  pool's  TVL  is  introduced  which  has  to  be  passed  before  rebalancing rewards  are  activated.  In  practice,  this  is  done  via  governance  change  that  calls  the  function BaseConicPool.setRebalancingRewardsEnabled(). Additionally, rebalancing rewards now start from  0  after  a  pool  has  been  marked  as  depegged.  This  ensures  that  the  attack  does  not  become instantly  profitable.  With  a  reward  factor  of  10,  the  attacker  has  to  wait  1.4  days  to  achieve  the  same result as before.  Conic - Conic Protocol -   20  CodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedDesignCriticalVersion1CodeCorrected           \f6.2   Execution of Wrong Governance Change  GovernanceProxy.executeChange() gets a storage pointer to the change corresponding to a given ID, deletes the change from storage and then tries to execute the change.  The change is deleted in the following way:  CS-CCP-002  pendingChanges[index] = pendingChanges[pendingChanges.length - 1]; pendingChanges.pop();  If the change is the last one in the pendingChanges array, then nothing is executed at all. If the change is any other change, the last change in pendingChanges will be executed instead of the correct one.    A given pending change is now deleted after all calls have been performed. To ensure that the change cannot re-execute itself, a new state Executing has been introduced that is set over the duration of the calls. Only Pending changes can be executed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Depeg Due to Oracle Manipulation",
        "body": "  CS-CCP-003  Deposit and withdraw functions of ETH pools are protected against reentrancy from Curve pools which disables the ability of attackers to manipulate the totalSupply() function of Curve and therefore the manipulation  of  the  CurveLPOracle.  Furthermore,  the  oracle  checks  that  a  given  Curve  pool  is balanced by comparing the Chainlink oracle prices of the underlying tokens with the actual price of the tokens on the Curve pool (using get_dy()). This ensures that an attacker cannot perform large trades on the pool before calling Conic, which would also skew the LP token price.  There  exists,  however,  another  possibility:  Fee  accrual  on  the  Curve  pool  that  results  in  the  LP  token price  becoming  (permanently)  inflated.  While  this  is  not  a  problem  for  deposits  and  withdrawals,  the mechanism can be used to call BaseConicPool.handleDepeggedCurvePool() and set the weight of the pool to 0. This automatically enables rebalancing rewards. An attacker can then rebalance the pool and gain the rebalancing rewards. The fees can be accrued with a single, large, bi-directional trade.  Since handleDepeggedCurvePool() does not set the timestamp for pool weight updates, the reward for  rebalancing  is  instantly  available.  If  a  pool  is  depegged  right  before  a  weight  update  (which  is estimated  to  happen  around  every  14  days),  the  reward  can  be  as  high  as  280  CNC  per  10.000  USD value rebalanced.  Consider the following example:  1. A Conic pool exists that contains two Curve pools with 3 assets holding 100k tokens each. Weights  are [0.5, 0.5].  2. An attacker (iteratively) adds 900k tokens liquidity per asset to the first Curve pool (by adding the Conic pool's underlying via Conic and the rest via Curve). The attacker also has to add liquidity to the  other  Curve  pool  to  ensure  that  everything  keeps  balanced.  These  tokens  can  be  withdrawn again later.  3. The first Curve pool's value is now roughly 3M. With the aforementioned fee donation attack, the  attacker increases the value of the pool to 3.09M.  Conic - Conic Protocol -   21  CorrectnessCriticalVersion1CodeCorrectedCorrectnessHighVersion1CodeCorrected              \f4. The  attacker  now  depegs  the  first  Curve  pool  and  rebalances  900k  on  Conic,  netting  them  ~25k  CNC tokens.  5. The  attacker  withdraws  liquidity  from  Conic  and  Curve.  They  get  back  up  to  90%  of  the  donated 90k fees to Curve (depending on the Curve pool setup) as they hold 90% of the liquidity of the pool.  6. Depending on the amount of fees the attacker gets back, and the current market value of CNC, this  attack becomes profitable.  The  attack  can  be  scaled  infinitely  with  sufficient  holdings  and  also  becomes  more  profitable. Rebalancing and liquidity provision to Curve can be done with flash loans while the liquidity provision to Conic requires capital as a deposit cannot be withdrawn in the same block.    Depegs are now identified by comparing Chainlink prices of all underlying tokens to their cached price. As there are no longer any LP token prices involved, there is no possibility for manipulation (except broad market manipulation).  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Wrong Accounting in Bonding",
        "body": "  Bonding._checkpointAccount()  calculates  the  already  accrued  stream  of  LP  tokens  that  can  be unstaked by multiplying the user's rewards boost with the difference of the total integral and the user's integral since the last checkpoint:  CS-CCP-004  uint256 accountBoostedBalance = cncLocker.totalRewardsBoost(account); perAccountStreamAccrued[account] += accountBoostedBalance.mulDown(     streamIntegral - perAccountStreamIntegral[account] ); perAccountStreamIntegral[account] = streamIntegral;  The streamIntegral is computed with CNCLockerV3.totalBoosted() amount which is the total of the  locked  CNC  times  the  boosts  of  each  user.  The  accrued  stream  of  users  is  computed  with totalRewardsBoost() which also contains balances of the old CNCLockerV2 contract and does not contain CNC of locks that have already expired:  function totalRewardsBoost(address account) public view override returns (uint256) {     return         lockedBoosted[account] -         unlockableBalanceBoosted(account) +         ICNCVoteLocker(V2_LOCKER).balanceOf(account); }  Since totalBoosted() is smaller than the sum of totalRewardsBoost() for all users, there can be more claims than could be satisfied. Consider the following scenario:  1. User 1 has a totalRewardsBoost() of 1000 tokens.  2. User 2 has a totalRewardsBoost() of 0.  3. totalBoosted() is 0.  4. User 2 calls bondCncCrvUsd() with an amount of 1000 LP tokens and gets a bonding price of 1.  Conic - Conic Protocol -   22  CorrectnessHighVersion1CodeCorrected        \f5. After 2 epochs, user 1 calls checkpointAccount(). streamIntegral is set to 1. Since user 1 has a balance of 1000 tokens in totalRewardsBoost() but their account integral has not been set yet, perAccountStreamAccrued for user 1 is updated to 1000 tokens.  6. User 1 calls claimStreamed() and receives 1000 LP tokens.  7. User  2  can  still  accrue  1000   in  perAccountStreamAccrued  by  calling checkpointAccount().  But  they  cannot  claim  the  stream  anymore,  since  the  1000  LP  tokens have already been unstaked.  tokens   Additionally,  it  is  problematic  that  the  integral  calculation  with  totalBoosted()  does  not  consider unlockable CNC as the calculation might result in an integral smaller than it should be.    now   Bonding  of totalRewardsBooost() to calculate the integral of individual accounts. This function only returns the locked boost of a user which matches the calculation for the total integral.  CNCLockerV3.totalStreamBoost()   function   instead   uses   the   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Bonding lastCncPrice Manipulation With",
        "body": " Leftover Dust  During every bonding epoch, there will likely be some CNC dust left-over since it is hard to estimate the exact amount of LP tokens to bond in order to acquire all the CNC up to the last decimal. Some of this CNC  dust  can  however  be  acquired  just  before  the  epoch  ends  for  the  purpose  of  manipulating lastCncPrice to be MIN_CNC_START_PRICE, even if the actual bonding happened at a much higher price.  CS-CCP-005    A minBondingAmount has been added that can be set to up to 1,000 LP tokens. This ensures (if set to a sensible value) that leftover dust cannot be acquired.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Extra Reward Tokens Not Sent to",
        "body": " RewardManager  RewardManager._swapRewardTokenForWeth() assumes the extra rewards reside on the contract. This  is  not  true  as  all  tokens  are  sent  to  the  corresponding  Conic  pool  and  are  never  sent  to  the RewardManager. No approvals from Conic pools to their reward managers exist for these extra tokens.  CS-CCP-007    BaseConicPool  now  has  a  function  updateRewardSpendingApproval()  that  allows  to  set approvals of arbitrary tokens to the RewardManager. It is called each time a new reward token is added.  Conic - Conic Protocol -   23  SecurityMediumVersion1CodeCorrectedCorrectnessMediumVersion1CodeCorrected                \f_sellRewardTokens() now transfers tokens from the respective Conic pool to the RewardManager before they are swapped.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Higher Imbalance Tolerance in Metapools",
        "body": "  In CurveLPOracle.getUSDPrice(), the pool balancing for Metapools is checked twice, once for the wrapping  Metapool,  and  once  for  the  base  pool.  This  allows  both  pools  to  be  unbalanced  up  to  the maximum threshold, which is twice the imbalance threshold that would apply to a single pool.  CS-CCP-044    A  new  customInternalImbalanceBuffers  storage  mapping  has  been  added  that  allows  to  set custom imbalance buffers for LP tokens of a base pool. If these parameters are set in the right way, the threat can be mitigated.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   Incomplete Pool Balance Check",
        "body": "  CurvePoolUtils.ensurePoolBalanced()  compares  Chainlink  prices  to  the  prices  returned  by  a Curve  pool's  get_dy()  function.  The  checks  are  always  performed  from  the  first  asset  to  all  other assets. In pools with more than 2 assets, this can become problematic.  CS-CCP-045  Consider the following scenario:  1. A Curve pool with 3 assets holds exactly 1000 tokens per asset (perfectly balanced).  2. The Curve pool accrues 0 fees (for simplicity) and has an A parameter of 2000.  3. An attacker trades 900 tokens from asset 1 to asset 2.  4. The attacker also trades 800 tokens from asset 1 to asset 0.  5. get_dy(0, 1) returns ~1.04.  6. get_dy(0, 2) returns ~0.96.  7. get_dy(1, 2) returns ~0.92.  With an imbalance buffer of 4% (simply for demonstration purposes, in production this would be smaller), the pool would still be considered balanced while there is an imbalance of 8% between asset 1 and 2.    The function now checks all combinations of tokens in a given pool.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   Oracle Price Manipulation",
        "body": "  Conic - Conic Protocol -   24  CS-CCP-009  DesignMediumVersion1CodeCorrectedDesignMediumVersion1CodeCorrectedSecurityMediumVersion1CodeCorrected                        \fDeposit and withdraw functions in Conic ETH pools are protected against reentrancy from a Curve pool that can potentially manipulate LP token prices. This is, however, not true for some other functions.  InflationManager.updatePoolWeights() can be called by reentering from a Curve pool resulting in  skewed  pool  weights  as  the  calculation  relies  on  prices  of  the  CurveLpOracle  which  can  be manipulated by removing liquidity from a Curve pool that holds ETH and then reentering to the function in the callback.  BaseConicPool.handleInvalidConvexPid()  the totalDeviationAfterWeightUpdate storage variable which is, however, not used anywhere in the code.  manipulate   allows   to   Furthermore,  onlyOwner  functions  that  are  called  from  the  GovernanceProxy  (if  they  have  a  delay) are  also  principally  open  to  this  manipulation  as  the  changes  can  be  executed  by  any  user. Controller.updateWeights()  and  updateAllWeights()  can  be  tricked  into  writing  wrong  LP token prices into the _cachedPrices of BaseConicPool, which can then be used to set the weight of a Curve pool to 0 with handleDepeggedCurvePool().    All  mentioned  functions  are  now  executing  reentrancy  checks  similarly  to  the  deposit  and  withdraw functions.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   Reward Double Counting",
        "body": "  RewardManager.poolCheckpoint()  accrues  rewards  by  storing  a  total  integral  and  holdings  since the last checkpoint per reward token:  CS-CCP-010  function _updateEarned(     bytes32 key,     uint256 holdings,     uint256 earned,     uint256 _totalSupply ) internal {     _rewardsMeta[key].earnedIntegral += earned.divDown(_totalSupply);     _rewardsMeta[key].lastHoldings = holdings; }  After  claiming  the  regular  rewards,  _claimPoolEarningsAndSellRewardTokens()  claims  extra rewards on Convex and swaps them for CNC. These additional CNC rewards are then added to the total integral. The last holdings, however, are not updated accordingly.  if (_totalStaked > 0)     _rewardsMeta[_CNC_KEY].earnedIntegral += receivedCnc_.divDown(_totalStaked);  As the CNC holdings of the contract increase, but the last holdings do not, the next checkpoint will count these tokens as new rewards again and add them to the integral again:  cncHoldings = CNC.balanceOf(conicPool); ... uint256 cncEarned = cncHoldings - _rewardsMeta[_CNC_KEY].lastHoldings;  Conic - Conic Protocol -   25  CorrectnessMediumVersion1CodeCorrected        \f... _updateEarned(_CNC_KEY, cncHoldings, cncEarned, _totalStaked);    _claimPoolEarningsAndSellRewardTokens()  now  correctly  sets  the  lastHoldings  for  CNC after  selling  reward  tokens.  Additionally,  if  rewards  have  to  be  claimed  in  claimEarnings(),  the account  share  of  the  calling  user  is  updated  again  after  the  rewards  tokens  have  been  swapped  to ensure that the user receives the extra reward in the same call.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.11   Slippage Losses Are Socialized",
        "body": "  BaseConicPool.depositFor()  calculates  the  amount  of  LP  tokens  a  user  receives  based  on  the value  of  the  whole  pool.  When  slippage  is  incurred,  this  is  problematic  as  the  depositor  might  receive more LP tokens than they should, resulting in a loss for all other liquidity providers. Consider the following example with simplified numbers:  1. A Conic pool contains one Curve pool with two tokens, 1000/1000 liquidity, 2000 LP total supply,  token prices of 1 and an LP price of 1.  2. The Conic pool holds 1000 of the LP tokens and the Conic LP token has a total supply of 1000.  CS-CCP-040  3. A user deposits 1000 token 0 to Conic.  4. Conic receives 900 LP tokens from Curve (slippage of 10%).  5. The Curve pool now holds 3000 USD value and has 2900 LP tokens total supply. Conic owns 1900  of these LP tokens.  6. Due to the slippage, the LP price of the Curve pool according to Conic now increased to 1.0345.  7. underlyingBalanceAfter therefore is now 1965, so the delta is 965.  8. The user now receives 965 Conic LP tokens for their deposit of 1000 tokens.  9. The Conic pool holds a total of 1900 Curve LP tokens which means the user's share of the Curve LP  tokens  now  is  933  while  the  Conic  pool  only  received  900  Curve  LP  tokens  for  the  user's deposit.    If the price of a Curve pool's LP token increases during a deposit, the price before the deposit is used to calculate the amount of LP tokens the user receives.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.12   Weight Update Rounding Errors",
        "body": "  BaseConicPool._setWeightToZero() sets the weight of a given pool to 0 and scales the weights of all other pools accordingly to reach at a total weight of 1. This is done by computing a scale factor which involves  a  division.  This  division  can  result  in  rounding  errors  which  will  be  passed  to  the  upscaled  CS-CCP-011  Conic - Conic Protocol -   26  DesignMediumVersion1CodeCorrectedCorrectnessMediumVersion1CodeCorrected                \fweights.  Therefore,  it  is  possible  that  the  total  weight  after  the  operation  is  slightly  smaller  than  1, breaking the invariant that the sum of all weights must equal exactly 1.  In turn, this can become problematic when rebalancing rewards are active (which is the case after the function has been called) as deposit / withdrawal maximums are now calculated without maxDeviation gaps.  Consider the following example:  1. A   Conic   pool   has   two   Curve   pools   with   weights  [666666666666666667, 333333333333333333].  2. The first pool is depegged, resulting in the following weights: [999999999999999999].  3. A user deposits 101 tokens with 18 decimals. _getDepositPool() returns a maximum amount of  100.999999999999999899  tokens  that  can  be  deposited  to  the  Curve  pool.  Including  the  1e2 constant in _depositToCurve(), the user's deposit can not completely be satisfied and the call results in a revert after a second iteration of getDepositPool().    _setWeightToZero() now adds the remaining weight to the last element that is not equal to the pool being set to 0-weight instead of multiplying its weight with the scaling factor. This ensures that all weights , if the last pool had already 0-weight, it will incorrectly receive always sum up to 1. However, in  the remaining weight, setting the pool weight to a non-zero value as explained in Possible zeroed pool weight increase.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.13   Wrong Denomination of Deviation Delta",
        "body": "  CNCMintingRebalancingRewardsHandler.computeRebalancingRewards()  rebalancing rewards with the following formula:  CS-CCP-012  computes  (elapsedSinceUpdate * cncRebalancingRewardPerDollarPerSecond).mulDown(     deviationDelta.convertScale(decimals, 18) );  The cncRebalancingRewardPerDollarPerSecond factor is per Dollar. It is therefore assumed that deviationDelta  should  be  in  USD  denomination.  This  is,  however,  not  the  case  as  the  value  is  in underlying.  For example, rebalanced deviation of 10.000 USDC would net ~0.833 CNC per hour, while a rebalanced deviation if 5 ETH (roughly the same value as the 10.000 USDC) would only net ~0.0004166 CNC.    The formula has been corrected by multiplying the amount with the current price of the underlying token.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.14   Possible Zeroed Pool Weight Increase",
        "body": "  Conic - Conic Protocol -   27  CS-CCP-041  Version2CorrectnessMediumVersion1CodeCorrectedCorrectnessLowVersion2CodeCorrected                \fBaseConicPool._setWeightToZero()  sets  the  weight  of  the  last  pool  that  is  not  the  pool  whose weight is set to 0 to the leftover weight so that the total weights equal to exactly 1.  If this pool has already been set to 0 weight previously, the weight might increase again by some dust.    The function now filters out all pools with 0 weight before performing the scaling.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.15   Reward Factor Override",
        "body": "  In  BaseConicPool.handleDepeggedCurvePool,  the  rebalancingRewardsFactor  is  set  even when rebalancing rewards are not activated. If rebalancing rewards have been activated before due to a weight update and the function is called on an empty pool, the reward factor is set regardless.  CS-CCP-042    The reward factor is now only set when rebalancing rewards are activated.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.16   Boost After Shutdown",
        "body": "  LpTokenStaker.unstakeFrom()  calculates  _stakerCheckpoint()  even  after  the  contract  has been shut down, further increasing the boost of the users.  CS-CCP-013    unstakeFrom()  now  if  _stakerCheckpoint() (and RewardManager.accountCheckpoint()).  contract  has  been   checks   the   shut  down  before   calling  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.17   CNCLockerV3 Lock Squatting",
        "body": "  Similarly to issue Lock spam DoS, a user who wants to avoid having its lock ever kicked (for example to use an airdropped boost indefinitely) can create a very big amount of 1 wei locks before and after the lock they wish to protect. Unlocking those locks will be very gas expensive for other users, and the cost will surpass  the  gas  cost  of  running _getLockIndexById() will exceed the block gas limit.  the  kicking  reward.  Kicking  will  not  be  possible  since   CS-CCP-014    Conic - Conic Protocol -   28  CorrectnessLowVersion2CodeCorrectedCorrectnessLowVersion1CodeCorrectedSecurityLowVersion1CodeCorrected                        \fA _MIN_LOCK_AMOUNT of 10 CNC has been introduced. Additionally, _MAX_LOCKS restricts the amount of locks a single account can hold to 10. It is now impossible to create enough locks for an account to be able to squat a certain lock.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.18   Claimable Rewards Potentially Wrong",
        "body": "  RewardManager.claimableRewards()  returns  0  if  the  balance  of  a  Conic  pool  is  0  in  the LpTokenStaker. This is not correct if the pool already accrued some rewards and later all tokens are unstaked (for example after shutdown).  CS-CCP-015    claimableRewards() now does not return early if the balance of a Conic pool is 0 and instead returns the correct value.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.19   Enabled Fee Not Reset",
        "body": "  RewardManager.setFeePercentage() does not reset feesEnabled to false when the fee is set back to 0.  CS-CCP-016    feesEnabled is now set to false when the fee is set to 0.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.20   Endless Loop",
        "body": "  RewardManager.poolCheckpoint()  claims  rewards  from  Convex  and  the  LpTokenStaker  if certain  conditions  are  met  (either  if  there  are  not  enough  funds  to  cover  fees  or  if  the  Convex  cliff  is approaching). If one of the conditions is met, and additionally the current _INFLATION_RATE_PERIOD has  ended  in  the  InflationManager,  then  the  function  executes  an  endless  loop  that  calls  back  to itself (because the conditions are still met at the time of the callback) until the transaction runs out of gas. The callpath is as follows:  CS-CCP-017  1. RewardManager.poolCheckpoint().  2. RewardManager._claimPoolEarningsForCliff() (optional).  3. RewardManager._claimPoolEarningsAndSellRewardTokens().  4. RewardManager._claimPoolEarnings().  5. LpTokenStaker.claimCNCRewardsForPool().  6. LpTokenStaker._claimCNCRewardsForPool().  7. InflationManager.executeInflationRateUpdate().  Conic - Conic Protocol -   29  CorrectnessLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                        \f8. InflationManager._executeInflationRateUpdate().  9. InflationManager.updatePoolWeights().  10. RewardManager.poolCheckpoint().  It  is  also  worth  to  note  that  the  subsequent  calls  of  LpTokenStaker.claimCNCRewardsForPool() increase  the  amount  of  CNC  minted  every  time  since  the  poolShares  are  only  reset  after  the  call  to InflationManager.executeInflationRateUpdate() while the shares are minted before. A fix of the issue should take this into consideration.    LpTokenStaker._claimCNCRewardsForPool()  InflationManager.executeInflationRateUpdate() so there is no loop anymore.  longer   no   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.21   Lock Spam DoS",
        "body": "  calls  CS-CCP-019  CNCLockerV3.lockFor() allows anyone to create a lock for a given account. An attacker can create a big amount of 1 wei locks on a victim account, such that if a legitimate lock is then created unlocking it becomes impossible as the cost of running _getLockIndexById() exceeds the block gas limit.  This  attack  allows  an  actor  to  effectively  freeze  any  CNC  that  is  to  be  locked  by  a  specific  user.  It  is extremely costly though (Around $27k in gas fees at gas price 45 Gwei and ETH value $2000).    A _MIN_LOCK_AMOUNT of 10 CNC has been introduced. Additionally, _MAX_LOCKS restricts the amount of locks a single account can hold to 10. It is now impossible to create enough locks for an account to be able DoS it. However, as described in note Locking in CNCLockerV3 can potentially fail if too many locks exist , some annoyance could be caused by an attacker willing to spend 100 CNC to create 10 locks for another user.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.22   Minimum Tainted Transfer Amount Can Be",
        "body": " Circumvented  LpToken  sets  a  flag  on  accounts  that  mint()  or  burn()  that  disables  them  from  minting  or  burning again in the same block. Since LP tokens can be transferred, the flag also has to be set on all addresses that the tokens are sent to.  To  prevent  cheap  DoS  attacks  on  arbitrary  accounts  that  deposit  or  withdraw  on  a  Conic  pool,  there exists a minimum threshold. Minting / burning of less than this amount will not set the flag.  The  tainting  mechanism  is  not  in  use  when  users  stake  their  minted  tokens  directly  in  the LpTokenStaker.  Only  when  the  tokens  are  withdrawn  again,  the  flag  is  set.  This  can  be  abused  to circumvent the minimum tainted transfer amount in the following way:  CS-CCP-020  Conic - Conic Protocol -   30  DesignLowVersion1CodeCorrectedSecurityLowVersion1CodeCorrected                \f1. Call BaseConicPool.deposit() with at least the minimum tainted transfer amount to a Conic  Pool and set the stake argument to true.  2. Call lpTokenStaker.unstakeFor() with an amount of 1 wei and the address you want to DoS.  3. In the next block, withdraw the rest if the deposited amount.    transferred  amount   function  called  by The  lpTokenStaker.unstakeFor()  to  taint  a  transfer)  and  the  function  checks  for  the  minimum  taint amount.  to  LpToken.taint()   is  now  passed   the   (   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.23   Rebalancing Reward After Depeg",
        "body": "  CS-CCP-023  BaseConicPool.handleDepeggedCurvePool() automatically enables rebalancing rewards. This is, however,  not  necessary  the _MAX_USD_VALUE_FOR_REMOVING_POOL threshold.  is  already  below   the  allocation  of   the  given  pool   if     handleDepeggedCurvePool()  now  checks  if  the  value  of  a  Curve  pool  is  below  the  threshold  and does not start rebalancing rewards in that case.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.24   Unreachable Imbalance Buffers",
        "body": "  CS-CCP-025  CurvePoolUtils.ensurePoolBalanced()  compares  prices  of  token  pairs  on  Curve  with  their respective  Chainlink  prices  using  an  imbalance  buffer  as  threshold.  The  imbalance  buffers  are  set  for individual tokens. A pair of two tokens will only ever be compared to the imbalance buffer of input token. Depending  on  the  Curve  pool  configuration,  this  can  result  in  the  inability  to  set  a  buffer  for  a  certain token.  For example, in an ETH/rETH Curve pool that contains WETH as the 0-token, it is not possible to use the imbalance buffer of rETH:  for (uint256 i = 0; i < poolMeta.numberOfCoins - 1; i++) {     ...     for (uint256 j = i + 1; j < poolMeta.numberOfCoins; j++) {         ...         toActual = ICurvePoolV2(poolMeta.pool).get_dy(i, j, fromBalance);         ...         require(             _isWithinThreshold(toExpected, toActual, poolFee, poolMeta.imbalanceBuffers[i]),             \"pool is not balanced\"         );     } }  Conic - Conic Protocol -   31  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \f  The function now uses the minumum of the imbalance buffers of each token pair.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.25   Wrong TVL Factor",
        "body": "  Conic stated that the TVL_FACTOR in LpTokenStaker is supposed to work in a way that gives the full boost to a user that holds 20% of the total staked amount using the following calculation:  CS-CCP-027  uint256 stakeBoost = ScaledMath.ONE +     userStakedUSD.divDown(totalStakedUSD).mulDown(TVL_FACTOR);  With  the  given  TVL_FACTOR  of  50,  the  full  boost  of  10  is  already  achieved  with  a  share  of  18%.  The correct TVL_FACTOR for 20% would be 45.    The TVL_FACTOR has been changed to 45.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.26   Wrong Time to Full Boost",
        "body": "  LpTokenStaker.getTimeToFullBoost()  returns  the  time  for  a  given  user  until  their  full  boost  is active:  CS-CCP-028  function getTimeToFullBoost(address user) external view returns (uint256) {     uint256 fullBoostAt_ = boosts[user].lastUpdated + INCREASE_PERIOD;     if (fullBoostAt_ <= block.timestamp) return 0;     return fullBoostAt_ - block.timestamp; }  This calculation is not correct. For example, the function returns the full INCREASE_PERIOD for a user that just reached their full boost amount in the current block, while it should return 0. lastUpdated is the point in time when a user's boost has been updated the last time. The function is therefore only correct for users that have just created a new position.    The function getTimeToFullBoost() has been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.27   Ambiguous Naming",
        "body": "  Conic - Conic Protocol -   32  CorrectnessLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrectedInformationalVersion1CodeCorrected                      \fThe following code parts contain symbols that are not precise and could be misunderstood:   ChainlinkOracle._getPrice() defines a boolean argument shouldRevert. Contrary to the  name of the argument, the function can still revert when it is set to true.   InflationManager.hasPoolRebalancingRewardHandlers()  allows  handler address while the function name contains the word \"handlers\" in plural.  to  check  a  single   LpTokenStaker.unstakeFor() allows a user to unstake their own tokens to a specific address.  It does not, as opposed to the naming, allow a user to unstake for another address.  CS-CCP-029    All aforementioned function names have been changed except for the function unstakeFor() because it is a public interface that has already been in use before.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.28   Exchange Rate Race Condition",
        "body": "  BaseConicPool.deposit() allows to instantly stake the freshly minted LP tokens with the following flow:  CS-CCP-032  1. Mint tokens.  2. Stake tokens on the LpTokenStaker.  3. Update the _cachedTotalUnderlying.  LpTokenStaker.stakeFor()  calls  BaseConicPool.usdExchangeRate()  implemented in the following way:  in  step  2.   It   is  function usdExchangeRate() external view virtual override returns (uint256) {     uint256 underlyingPrice = controller.priceOracle().getUSDPrice(address(underlying));     return _exchangeRate(cachedTotalUnderlying()).mulDown(underlyingPrice); }  function _exchangeRate(uint256 totalUnderlying_) internal view returns (uint256) {     uint256 lpSupply = lpToken.totalSupply();     if (lpSupply == 0 || totalUnderlying_ == 0) return ScaledMath.ONE;      return totalUnderlying_.divDown(lpSupply); }  As can be seen, the exchange rate is calculated by dividing the cached total underlying (which is not yet updated  in  the  call)  by  the  total  supply  of  the  LP  token  (which  has  already  been  increased  due  to  the minting in step 1). The exchange rate is therefore erroneously deflated.  However, this exchange rate is used in a way that completely factors it out in this call which makes this call safe after all.    _cachedTotalUnderlying  LpTokenStaker.stakeFor().  is  now  updated  before   the  calls   to  LpToken.mint()  and  Conic - Conic Protocol -   33  InformationalVersion1CodeCorrected      \f6.29   Fees Without Locked CNC  CS-CCP-033  RewardManager.setFeePercentage()  the CNCLockerV3.totalBoosted() > 0. Once the fee is set, fees are however still accrued even if the amount of locked CNC goes down back to 0.  allows   only   fee   set   to   a   if   Specifiaction changed:  setFeePercentage() now no longer requires CNCLockerV3.totalBoosted() > 0.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.30   Interface Differences",
        "body": "  The following parts of the code have non-uniform interfaces:   BaseConicPool.depositFor() allows the minted LP tokens to be instantly staked by setting a boolean  parameter.  withdraw()  does  not  expose  such  a  boolean  parameter  for  unstaking  LP tokens.  Instead,  a  separate  function  unstakeAndWithdraw()  must  be  used.  This  interface  is non-uniform.   RewardManager contains a function accountCheckpoint() while Bonding contains a function  checkpointAccount().  CS-CCP-035    Bonding.checkpointAccount()  has  been  renamed  to  Bonding.accountCheckpoint().  The withdraw function names are kept as-is for backwards compatibility.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.31   Missing Events",
        "body": "  The following state-changing functions are not emitting events (the list is non-exhaustive):  CS-CCP-036   RewardManager.poolCheckpoint().   All functions in SimpleAccessControl.   ChainlinkOracle.setHeartbeat().    Events have been added to most functions where it makes sense.  Conic - Conic Protocol -   34  InformationalVersion1Speci\ufb01cationChangedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected                    \f6.32   Rebalancing Reward Formula Mismatch  The  CNCMintingRebalancingRewardsHandler.computeRebalancingRewards()  following formula:  comments   doc   CS-CCP-037  describe   of the  CNC = t * CNC/s * (1 - (Ddeviation / initialDeviation))  This is different to the actual implementation:  (elapsedSinceUpdate * cncRebalancingRewardPerDollarPerSecond).mulDown(     deviationDelta.convertScale(decimals, 18) );  The formula in the comments is also likely wrong as it would imply lower rewards the higher the deviation delta is.  Specification changed:  The formula has been updated.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.33   Shadowed Variables",
        "body": "  The  LpToken  constructor's  arguments  name  and  symbol  shadow  the  storage  variables  of  the  ERC20 contract.  CS-CCP-038    The variable names have been changed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.34   Typographical Errors",
        "body": "  CS-CCP-039  Typographical errors have been identified in the following parts of the code:  1. BaseConicPool.depositFor()  and  shutdownPool()  define  an  error  message  that  contain  the word \"shutdown\" as a verb.  2. Doc comments of BaseConicPool.handleInvalidConvexPid() contain the word \"shutdown\"  as a verb.  3. Doc comments of BaseConicPool.handleInvalidConvexPid() contain the word \"outcomu\".  4. Doc comments of BaseConicPool.handleInvalidConvexPid() contain the word \"unilkely\".  5. Doc comments of ETH_FACTORY_POOL_CODE_HASH_1 in CurveHandler contain the phrase \"a  optimization\".  Conic - Conic Protocol -   35  InformationalVersion1Speci\ufb01cationChangedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected                \f6. Error   pool  BaseConicPool.handleInvalidConvexPid() is inconsistent with the check performed.  shutdown\"   \"convex   string   pid   is   in    All errors have been fixed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.35   removeDuplicates Not Working With 0",
        "body": " Elements  ArrayExtensions.removeDuplicates() does not work correctly if the array passed as arguments contains the 0-address. It will be filtered out.  CS-CCP-043    The function now correctly checks for 0 elements.  Conic - Conic Protocol -   36  InformationalVersion1CodeCorrected      \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Code Copies",
        "body": "  The  project  contains  multiple  functions  that  share  a  similar  or  even  identical  codebase.  The  common functionality should be refactored into separate functions to minimize the risks of future changes resulting in different functions behaving differently when they should behave the same way.  CS-CCP-030  Examples are:   BaseConicPool._withdrawFromCurve() and _depositToCurve().   LpTokenStaker.poolCheckpoint() and claimableCnc().   Multiple functions in CNCLockerV3.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Events Emitted on No Change",
        "body": "  Some functions emit events even when no change in storage has occurred. Here are some examples:  CS-CCP-031  1. BaseConicPool.updateDepegThreshold().  2. Controller.setCurveHandler().  3. RewardManager.addExtraReward().  4. RewardManager.removeExtraReward().    Most of the functions have been corrected to only emit events when the state changes.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Gas Optimizations",
        "body": "  Some code parts can be optimized for better gas efficiency.  1. Redundant calls. For example:  CS-CCP-034   BaseConicPool.depositFor()  calls  the  price  oracle  for  the  underlying  price.  The  same  call is then performed in _exchangeRate() and potentially _isBalanced().  CurveHandler._version_0_remove_liquidity_one_coin(),   In  CurveRegistryCache.coins() is executed in each loop iteration.  the   call  Conic - Conic Protocol -   37  InformationalVersion1InformationalVersion1CodePartiallyCorrectedInformationalVersion1             \f RewardManager.poolCheckpoint()  could  send  fees  directly  from  a  Conic  pool  to  the  CNCLockerV3.   CurveAdapter._stakedCurveLpBalance()   calls IConvexHandler(controller.convexHandler()).getRewardPool()  which  in  turn calls CurveRegistryCache.getRewardPool(). This function could be called directly.   The  call  to  CurveRegistryCache.nCoins()  in  CurveLpOracle.getUSDPrice()  can  be omitted as the number of coins is already available.   GenericOracle.getUSDPrice()   calls   which  ChainlinkOracle.getUSDPrice().  calls   ChainlinkOracle.getUsdPrice().   ChainlinkOracle.isTokenSupported() call  proceeds   then   to   It   2. Redundant storage reads. For example:   BaseConicPool._getDepositPool()  loads  all  pools  and  weights  in  each  iteration  of  _depositToCurve().   BaseConicPool._depositToCurve() loads the pool address from storage when it could  have just been passed back by _getDepositPool().   CNCLockerV3._feeCheckpoint()   loads   accruedFeesIntegralCrv   and  accruedFeesIntegralCvx multiple times from storage.   LpTokenStaker._claimCNCRewardsForPool() loads poolShares from storage instead  of using the return value of checkpoint().  3. Redundant storage writes. For example:   GovernanceProxy._endChange()  writes  data  to  the  pending  change  in  storage  before  deleting it from storage.  4. Unnecessary computation. For example:   The  loop  in  BaseConicPool._getDepositPool()  does  not  continue  if  the  weight  of  a  given pool is 0.   The  computation  of  _isEthIndexFirst()  in  CurveHandler.isReentrantCall()  is  irrelevant.   RewardManager.poolCheckpoint()  does  not  set  the  rewardsClaimed  flag  when rewards  are  claimed  due  to  being  within  the  threshold  of  the  Convex  cliff.  This  results  in claimPoolEarningsAndSellRewardTokens()  potentially  executing  the  claiming functionality two times.   RewardManager.poolCheckpoint() does not return early if no rewards have accrued.  5. Unoptimized structs in storage. For example:   The size of the endedAt field in the Change struct of IGovernanceProxy could be reduced  to fit the Status enum into the same word.   The Boost struct in LpTokenStaker could be optimized to only occupy 1 word.  6. _chainlinkOracle and _curveLpOracle in GenericOracle can be immutable.  Conic - Conic Protocol -   38  \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Extra Rewards Might Have 100% Slippage",
        "body": "  RewardManager swaps all extra rewards of a Convex pool to CNC on either SushiSwap or Curve. If the respective token is not supported by the GenericOracle, no slippage protection is set for these swaps. It is likely that these swaps will be arbitraged by bots.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Locking in CNCLockerV3 Can Potentially Fail",
        "body": " if Too Many Locks Exist  No more than _MAX_LOCKS can exist in CNCLockerV3 for every user. If a user has created more, or if an attacker targets a user, they could be prevented from creating new locks according to their intentions. New locks can always be created by using the relock option of lockFor(), however that requires the duration to be longer than any of the existing locks.  If it is not possible to create new locks for an address, an alternative address will have to be used. If an airdrop  cannot  be  used  because  of  having  reached  _MAX_LOCKS,  the  airdrop  can  still  be  used  on another address through lockFor().  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.3   RewardManager Can Become Temporarily",
        "body": " Insolvent  RewardManager  handles  CVX  rewards  by  calculating  the  current  amount  of  earnings  for  the  current Convex cliff period. If the end of the cliff period approaches, earnings are finally claimed. It is, however, possible that there are no interactions with the contract for a longer period which would result in this claim being missed before the period ends. In that case, the amount of CVX rewards in the contract are inflated as the actual claimable reward is lower than the reward that has been calculated before. It is therefore possible  that  not  all  claims  can  be  served  until  the  new  incoming  CVX  reward  reach  the  previously calculated amount of CVX rewards that should be in the contract.  Users that stake after this incident also do not accrue CVX rewards in favor of older stakers.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.4   Rewards of Rebalance Function",
        "body": "  CNCMintingRebalancingRewardsHandler.rebalance() allows users to easily rebalance a Conic pool and earn rewards. This includes rewards for withdraw() which are not granted if the function is called directly.  Conic - Conic Protocol -   39  NoteVersion1NoteVersion1NoteVersion1NoteVersion1              \fThe  setup  allows  for  additional  reward  handlers  to  be  added  to  a  Conic  Pool.  These  reward  handlers, however, will only grant rewards for deposits even when the rebalance() function is used.  Conic - Conic Protocol -   40  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Ineffective Try Catch Statement",
        "body": "  Try  catch  statements  should  handle  critical  code  parts  that  might  fail  and  their  respective  exertions correctly.  The  used  try  catch  statement  in  authorizationDecrease  simple  fails  silently  if  not successful. Resulting in potential incorrect authorization decrease.  Risk accepted :  Network   Threshold  event AuthorizationInvoluntaryDecreased has been added to track involuntary decreases, it contains a field to indicate whether the call to the application succeeded or not.  decrease   accepts   silently.   fails   The   that   a   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Missing Sanity Checks",
        "body": "  For  security  reasons  stakers  use  different  roles  to  manage  the  stake.  If  different  roles  exist,  it  seems consistent  to  enforce  the  use  of  different  keys.  stake  and  stakeNu  do  not  check  if  the  addresses (operator,  beneficiary,  owner,  authorizer)  are  the  same.  In  a  more  limited  way  this  is  also  the  case  for stakeKeep.  Acknowledged :  Threshold  Network  does  not  consider  that  roles  having  different  addresses  must  be  enforced.  In  their modelling, they always assumed that some stakers will reuse addresses for different roles.  Threshold Network - Threshold Network -   9  DesignCriticalHighMediumRiskAcceptedLowAcknowledgedRiskAcceptedDesignMediumVersion1RiskAcceptedDesignLowVersion1Acknowledged                    \f5.3   Possibly Uninitialized Penalties  function   initializes   The  constructor  the  staking  contract.  However, important  variables  takeDiscrepancyPenalty  and  stakeDiscrepancyRewardMultiplier  are  not  initialized  and need  to  be  set  separately  in  setStakeDiscrepancyPenalty.  The  onlyGovernance  modifier ensures  that  only  the  community  controlled  governance  contract  can  call  this  function.  Calls  from community  driven  governance  contracts  usually  have  a  long  reaction  time  due  to  voting  and  other collective decisions that need to be taken before. Hence, the variables might be uninitialized and result in no penalties for misbehaving.  for   Risk accepted :  These parameters need to be set by governance, Threshold Network believes that in the interim, zero penalty is an acceptable behavior.  Threshold Network - Threshold Network -   10  DesignLowVersion1RiskAccepted        \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings   Unauthorized Top Ups   -Severity Findings   Compiler Version Not Fixed and Outdated   Inefficient Struct Packing   Inefficient processSlashing Loop   Interface File Name Convention    Misleading Variable count    Specifications Mismatch   0  0  1  6  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Unauthorized Top Ups",
        "body": "  With the current design, anybody can call topUp on any operator (in Kepp, Nu and T). This could lead to KEEP  or  NU  staked  in  legacy  contract,  that  the  owner  may  not  want  to  be  staked  on  the  new  staking contract, ending staked on the new contract.  On Nu this might lead to trolling by calling topUpNu after a user send an unstakeNu transaction and blocking the Nu withdraw through:  1. X calls unstakeNu  2. Y calls topUpNu on X  3. X tries to withdraw from NU legacy staking contract, but it fails because there is still an amount  of NU accounted in the new staking contract  With Keep the issue is more severe as non-malicious behavior could be slashed with a sandwich attack like follows:  1. Someone wants to unstake keep and calls \"unstakeKeep\"  2. The user sends the tx for the Keep legacy contract to \"undelegate\"  3. This tx lands in the men pool and someone front runs it by calling \"topUpKeep\"  4. The undelegate is mined after the top up  5. The attacker calls the notify keep discrepancy function to slash  Threshold Network - Threshold Network -   11  CriticalHighMediumCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedDesignMediumVersion1CodeCorrected           \fCode corrected :  A modifier has been added to all three top up functions to restrict the access only to owner and operator.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Compiler Version Not Fixed and Outdated",
        "body": "  The  solidity  compiler  is  not  fixed  in  the  Checkpoints.sol.  The  version,  however,  is  defined  in  the hardhat.config.js to be 0.8.4.  In the code the following pragma directives are used:  pragma solidity ^0.8.0;  Known bugs in version 0.8.4 are:  https://github.com/ethereum/solidity/blob/develop/docs/bugs_by_version.json#L1562  More information about these bugs can be found here:  https://docs.soliditylang.org/en/latest/bugs.html  At the time of writing the most recent Solidity release is version 0.8.9 which contains some bugfixes.  Code corrected :  Compiler version is now 0.8.9 and fixed all files.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Inefficient Struct Packing",
        "body": "  The variable order inside structs is not optimized by the compiler. Hence, tight variable packing needs to be done manually. The struct OperatorInfo could be packed differently, to save two storage slots.  Code corrected :  Struct has been optimized.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Inefficient processSlashing Loop",
        "body": "  State operations are expensive. Additionally, Threshold Network told that the processSlashing is gas critical.  The  function  processSlashing  reads  and  writes  the  state  variable  slashingQueueIndex multiple times. The loop even does operations in each iteration.  Additionally,  a  sanity  check  for  count  parameter  in  processSlashing  instead  of  a  check  at  every iteration of the for loop could save gas.  Code corrected :  Threshold Network - Threshold Network -   12  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \fslashingQueueIndex is now updated only once after the for loop with an internal counter in memory.  The  stopping  condition  of  the  for  loop  has  been  optimized,  maxIndex  is  now  capped  at  max  queue's length and an event is emitted with the effective number of slashes.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Interface File Name Convention",
        "body": "  The file StakingProviders.sol is an interface definition. To be consistent with the naming, the file should be renamed with a leading I.  Code corrected :  Filename updated.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Misleading Variable count",
        "body": "  One of the stop conditions of the for loop in processSlashing allows the function to process one more intended.  slashingQueueIndex  <=  maxIndex  should  be pending  slash  slashingQueueIndex  <  maxIndex  if  it  should  match  the  passed  in  count  argument.  One  more unintended iteration also would cost the processor more gas than they may have wanted to spend in the first place.  initially   than   Code corrected :  Loop's stopping condition has been updated.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Specifications Mismatch",
        "body": "  Specs  of  processSlashing  say  that  processor  can  get  either  4%  or  5%  of  the  slashed  amount, depending on the type of call the application did, but in practice processor always gets 5%, no matter the application called seize or slash.   getStartTStakingTimestamp specs say that result is zero when operator has no stake or  when they was topped-up, but top up functions do not update the staking timestamp  Specification partially changed :  For both mentioned issues the specifications were updated accordingly.  Threshold Network - Threshold Network -   13  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1Speci\ufb01cationChangedVersion3                        \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Applications Share the Same Stake",
        "body": "  Threshold Network informed that the same stake can be used in different applications. Sharing the same stake  practically  means  that  if  one  application  slashes  or  seizes  all  stake,  all  other  applications  that shared the stake will have no stake left to seize or slash.  Threshold Network - Threshold Network -   14  NoteVersion1  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Inconsistent Decimals of LP Token",
        "body": "  The  function  ERC20RootVault.deposit  performs  the  following  checks  when  new  LP  tokens  are minted to a user:  require(lpAmount + balanceOf[msg.sender] <= params.tokenLimitPerAddress, ExceptionsLibrary.LIMIT_OVERFLOW); require(lpAmount + totalSupply <= params.tokenLimit, ExceptionsLibrary.LIMIT_OVERFLOW);  The LP tokens distributed by root vaults do not have pre-defined number of decimals but depend on the token amounts of the first deposit, hence making difficult to set the params tokenLimitPerAddress and tokenLimit in advance.  Acknowledged:  Mellow Finance - Mellow Vaults -   13  SecurityDesignCorrectnessCriticalHighMediumLowAcknowledgedAcknowledgedCodePartiallyCorrectedAcknowledgedAcknowledgedAcknowledgedAcknowledgedAcknowledgedAcknowledgedCodePartiallyCorrectedAcknowledgedAcknowledgedCorrectnessLowVersion5Acknowledged            \fMellow Finance acknowledges the issue and will take care to set the proper limits after initial LP shares are minted and the respective decimals are known:  We don\u2019t intend to stand limits in advance of the launch of the system, we rather want to stand them as MaxUint256 initially and then have a possibility to set meaningful values based on the supply of lp tokens during the work of the system.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Performance Fee in Specific Setups",
        "body": "  The  performance  fee  is  charged  in  ERC20RootVault  only  if  the  price  of  LP  tokens  has  increased  in value, which is calculated in the statement:  uint256 lpPriceD18 = FullMath.mulDiv(tvlToken0, CommonLibrary.D18, baseSupply);  However, in specific setups where the token0 is of high value but has low decimals, while the token1 is of low value but with many decimals, the variable baseSupply would inherit the decimals of token1. Therefore, in such setups it is possible that the statement above returns lpPriceD18 equal to zero.  Acknowledged:  Mellow  Finance  has  decided  to  keep  the  code  unchanged  as  they  only  will  use  only  verified  token combinations that this issue does not occur. The response:  We decided that this situation would not be possible when calculating the performance fee, since we agreed to use only verified tokens, for which the difference between decimals would be less than 18.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   Possible Optimization in AggregateVault",
        "body": "  The function AggregateVault._push performs the following actions:  1. Approves allowance with safeIncreaseAllowance for each token to destVault.  2. Calls destVault.transferAndPush, which transfers tokenAmounts to the ERC20Vault.  3. Resets approval to destVault for all tokens to 0.  Given that the _push function moves tokens to the ERC20Vault and allowance in the end should be 0, the  function  can  be  revised  to  be  more  efficient.  For  instance,  safeIncreaseAllowance  performs additional  operations  and  is  useful  when  the  existing  allowance  is  not  zero  and  should  be  considered. Also,  the  function  consumes  in  step  2  the  allowance  given  earlier,  hence  the  last  for-loop  might  be omitted.  Code partially correct:  The  function  AggregateVault._push  is  made  more  efficient  by  performing  the  external  calls safeIncreaseAllowance  and  safeApprove  only  for  tokens  that  non-zero  amounts  are  being  Mellow Finance - Mellow Vaults -   14  DesignLowVersion5AcknowledgedDesignLowVersion5CodePartiallyCorrected                \ftransferred (tokenAmounts[i] > 0). However, for the other tokens two external calls are performed for updating the allowance.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.4   Possible Optimization on Deposits and",
        "body": " Withdrawals  The function ERC20RootVault.deposit can be optimized to be more gas efficient by transferring the tokens directly from the user to the ERC20Vault. Currently, the tokens are first transferred from the user to the root vault:  for (uint256 i = 0; i < tokens.length; ++i) {     ...     IERC20(tokens[i]).safeTransferFrom(msg.sender, address(this), normalizedAmounts[i]); }  and then, in AggregateVault._push tokens are transferred again:  for (uint256 i = 0; i < _vaultTokens.length; i++) {     IERC20(_vaultTokens[i]).safeIncreaseAllowance(address(destVault), tokenAmounts[i]); }  Similarly,  the  function  ERC20RootVault.withdraw  can  be  made  more  efficient  if  the  tokens  are transferred directly from the sub-vaults to the user instead of transferring to the root vault first and then to the user.  Acknowledged:  Client acknowledges the optimization possibility but prefers to keep the code unchanged:  The main idea behind this behavior is for the root vault to be responsible for pushing tokens onto different vaults. We consider the current design to be clearer with pushing with the ```AggregateVault._push``` method.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.5   Redundant Calculation of LP Amounts",
        "body": "  The  function  ERC20RootVault.deposit  calculates  the  LP  amount  that  is  rewarded  to  the  user  two times:  {     ...     (preLpAmount, isSignificantTvl) = _getLpAmount(maxTvl, tokenAmounts, supply);     for (uint256 i = 0; i < tokens.length; ++i) {         normalizedAmounts[i] = _getNormalizedAmount(...);         ...     } } actualTokenAmounts = _push(normalizedAmounts, vaultOptions); (uint256 lpAmount, ) = _getLpAmount(maxTvl, actualTokenAmounts, supply);  Mellow Finance - Mellow Vaults -   15  DesignLowVersion5AcknowledgedDesignLowVersion5Acknowledged                \fInitially,  preLpAmount  is  calculated  based  on  the  tokenAmounts,  then  normalizedAmounts  are returned computed.  Considering  actualTokenAmounts  is redundant.  to  normalizedAmounts.  Hence,  recomputing  lpAmount   that  _push  moves   the  ERC20Vault,   is  equal   tokens   the   to   Acknowledged:  Client acknowledges the redundant calculation of LP amount but prefers to keep the code unchanged as in the future the behavior of ERC20Vault might change, i.e., the returned actualTokenAmounts might not be equal to normalizedAmounts.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.6   Broad Access Control for Functions",
        "body": "  functions  addDepositorsToAllowlist  and  removeDepositorsFromAllowlist   in The  ERC20RootVault  restrict  the  access  control  with  function  _requireAtLeastStrategy.  However, neither MStrategy nor LStrategy call these functions. Similarly, multiple functions in VaultGovernance use the same access control, although they are not called by the strategies.  Acknowledged:  Mellow  Finance  is  aware  that  these  functions  are  not  called  by  smart  contracts  implementing  the strategies, but they can be called by an EOA in case it manages the vault system. Client replied:  The vault system can be managed not by strategy, but by some account. In such a case this account should have the possibility to edit `depositorsAllowList`. These 2 functions exist for this reason.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.7   Redundant Check for baseSupply",
        "body": "  The  function  ERC20RootVault._chargePerformanceFees  performs  a  check  of  baseSupply  is equal to 0, and returns if this is the case:  if ((performanceFee == 0) || (baseSupply == 0)) {     return; }  However, this check is redundant because _chargeFees performs the same check and returns before calling _chargePerformanceFees.  Acknowledged:  Client acknowledged the redundant check but has decided to keep it as it enhances the readability of the code.  Mellow Finance - Mellow Vaults -   16  DesignLowVersion4AcknowledgedDesignLowVersion4Acknowledged                  \f5.8   Redundant Check for deltaSupply  The function _getBaseParamsForFees performs the following check on withdrawals:  baseSupply = 0; if (supply > deltaSupply) {     baseSupply = supply - deltaSupply; }  The deltaSupply corresponds to the LP shares that a user is burning, which is less than or equal to the balance of that user. Hence, it is always less or equal to the totalSupply.  Acknowledged:  Client acknowledged the redundant check but has decided to keep it as it enhances the readability of the code.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.9   Redundant Checks on Push Function",
        "body": "  The  function  IntegrationVault.push  performs  the  following  checks  that  are  always  true  when  a vault is linked to a root vault:  uint256 nft_ = _nft; require(nft_ != 0, ExceptionsLibrary.INIT); IVaultRegistry vaultRegistry = _vaultGovernance.internalParams().registry; IVault ownerVault = IVault(vaultRegistry.ownerOf(nft_)); // Also checks that the token exists uint256 ownerNft = vaultRegistry.nftForVault(address(ownerVault)); require(ownerNft != 0, ExceptionsLibrary.NOT_FOUND);  Acknowledged:  Mellow  Finance  has  decided  to  keep  the  checks  to  prevent  from  pushing  and  pulling  on  uninitialized vaults.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.10   State Updates After Reentrancy Possibility",
        "body": "  When creating a vault, _mint is called to mint the NFT. This calls the receiver and gives an opportunity to reenter the system.  _safeMint(owner, nft); _vaultIndex[nft] = vault; _nftIndex[vault] = nft; _vaults.push(vault); _topNft += 1; emit VaultRegistered(tx.origin, msg.sender, nft, vault, owner);  Mellow Finance - Mellow Vaults -   17  DesignLowVersion4AcknowledgedDesignLowVersion4AcknowledgedDesignLowVersion4CodePartiallyCorrected                      \fState  updates  and  events  are  emitted  after  the  possible  reentrancy  in  this  function  and  the  calling functions. Coding guidelines suggest following the check-effects-interaction pattern to mitigate reentrancy vulnerabilities.  Code partially corrected:  The  minting  statement  _safeMint  has  been  moved  to  the  end  of  the  function  registerVault. However, state is still updated afterwards in functions createVault of vault governance contracts.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.11   Missing Slippage Protection in _mintNewNft",
        "body": "  The function _mintNewNft in LStrategy sets the parameters amount0Min and amount1Min of the MintParams to zero, hence disabling any slippage protection. However, the risk exposure in this case is limited as a new position in Uniswap should be open with small amounts minTokenXForOpening. The exact amount depends on admin who sets the otherParams.  Acknowledged:   to check if the variables minTokenXForOpening are smaller Sanity checks were introduced in  than 10**9. This adds another layer of protection to ensure that the number of tokens is relatively low. Still, the number of tokens does not guarantee that the value is small.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.12   UniV3Vault Pulls More Tokens Than",
        "body": " Requested  UniV3Vault._pullUniV3Nft first calculates the amount of tokens to pull, then decreases the liquidity inside  the  Uniswap  position  and  then  collects  the  tokens.  When  the  earnings  have  not  been  collected before, the last step additionally collects the earnings, returning more tokens than intended.  The function should take the tokens owed into consideration when calculating the amount to pull.  Acknowledged  Mellow  Finance  acknowledged  the  issue  and  replied  that  the  strategy  maintainer  can  call  the collectEarnings function to collect all the fees.  Mellow Finance - Mellow Vaults -   18  SecurityLowVersion1AcknowledgedVersion3CorrectnessLowVersion1Acknowledged                  \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  5  14  17  -Severity Findings   Mismatch of Specification With Uniswap V3 Oracle    Chainlink Oracle Returns Empty Prices   Incorrect LP Token Calculation in ERC20RootVault    Missing Access Control in UniV3Oracle    UniV3Oracle Returns Reverse Prices for Token Pairs   -Severity Findings  Incorrect TVL Conversion    Adding up Total Value Locked on Different Tokens    Calling _liquidityDelta Incorrectly    Calling _liquidityDelta With Incorrect Inputs   Incorrect Observation Index in _getAverageTick   Incorrect Parameters on externalCall   Insufficient Testing    Opposite Vaults Are Swapped    Possibility to Exit Positions of Any Address    Possible DOS From First Depositor    Setting Wrong State Variable    Wrong Formula in _rebalanceUniV3Liquidity    Wrong TVL Calculation in ERC20RootVault   liquidity Gets Overwritten in the Loop   -Severity Findings   Wrong State Variable Updated   Inconsistent Access Control for Rebalance in LStrategy   Inconsistent Sanity Check on First Deposit's Amounts    Safety Level of Returned Prices Can Silently Downgrade    Unfair Distribution of LP Shares in ERC20RootVault    Conflicting Specifications for MStrategy   Implementation Differs From Specification on _targetTokenRatioD   Incorrect Access of Addresses in EnumerableSet    Missing Checks for Dust Amounts When Rebalancing Pools    Missing Delay Restriction in BaseValidator   Mellow Finance - Mellow Vaults -   19  CriticalCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedHighCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedMediumCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrected          \f Missing Sanity Checks in signOrder    No Slippage Protection in Multiple Contracts    Possible Underflow in UniV3Oracle.price    Rebalance in LStrategy Can Leave Tokens in the Vault to Be Closed    Subvault Tokens Are Not Checked in AggregateVault    Transferring Tokens Only to lowerVault    Use of Libraries   -Severity Findings   Missing Sanity Checks for intervalWidthInTicks    Possible Attack by First Depositor    Possible Optimization on _chargePerformanceFees    Possible Violation of the Minimum Token Amounts After the First Deposit    Misleading Function Name and Natspec    Mismatch of Specifications for StrategyParams    Missing Sanity Check for maxSlippageD in MStrategy   41   Missing Sanity Checks for oracleSafetyMask    Possible Struct Optimization in Strategies    Redundant Comparisons    Redundant Storage Read in ERC20Vault._pull    Variables Can Be Declared as Constant   Incorrect Specification for reclaimTokens    Missing Natspec Description for minDeviation    Casting of maxTickDeviation    Check Requirements First    Duplicate Code _permissionIdsToMask    Duplicate Storage Read in Deposit   Inconsistent Specifications   Inefficient Array Shrinking   Inefficient State Variable Packing    Misleading Naming of Variables in UniV3Oracle    Missing Sanity Check in MStrategy.createStrategy    Missing Sanity Checks for Params    Misspelled Variable Names    Possible Struct Optimization    Rebalance in MStrategy Is Inconsistent    Specification for minDeviation Not Enforced    Storing Redundant Data in Storage    Unnecessary Approval to Vault Registry   Mellow Finance - Mellow Vaults -   20  CodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedLowCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrected    \f Unused Constant in ERC20Validator    Unused Event DeployedVault    Unused Function LStrategy._priceX96FromTick    Unused Imports    Wrong Check of Minimum Token Amounts in ERC20RootVault.withdraw    Wrong Specification for YearnVault.tvl    ContractRegistry DOS    ERC20Vault._pull Forces Push of Wrong Amount of Tokens   IntegrationVault._root Does Not Check the NFT of the Root Vault    VaultGovernance.commitInternalParams Does Not Delete Staged Parameters    registry.ownerOf Is Called Twice in IntegrationVault.pull   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Mismatch of Specification With Uniswap V3",
        "body": " Oracle  The specifications of the function price for oracles are in the interface IOracle as following:  /// @dev The price is token1 / token0 i.e. how many weis of token1 /// required for 1 wei of token0.  function price(     address token0,     address token1,     uint256 safetyIndicesSet ) external view returns (uint256[] memory, uint256[] memory);  According  to  the  specification,  priceA_B  =  price(tokenA,  tokenB)  should  be  the  inverse  of priceB_A  =  price(tokenB,  tokenA),  meaning  relation  should  hold: priceA_B = 1 / priceB_A.  following   the   The  function  UniV3Oracle.price  in    returns  the  same  price  for  a  pair  of  tokens  without differentiating in which denomination token the price should be. Namely, the function returns the same prices  when  calling  price(tokenA,  tokenB)  or  price(tokenB,  tokenA).  This  behavior  is enforced in the first if statement of the function:  if (token0 > token1) {     (token0, token1) = (token1, token0); }    The  Uniswap  V3  Oracle  has  been  revised,  the  Uniswap's  OracleLibrary  is  now  used  and  a  flag isSwapped is added to track the correct denomination of the returned price.  Mellow Finance - Mellow Vaults -   21  CodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCorrectnessCriticalVersion2CodeCorrectedVersion2           \f6.2   Chainlink Oracle Returns Empty Prices  ChainlinkOracle maintains the mapping oraclesIndex which stores addresses of chainlink oracles for each token. The mapping is populated by the admin through the function _addChainlinkOracles:  function _addChainlinkOracles(address[] memory tokens, address[] memory oracles) internal {     ...     oraclesIndex[token] = oracle;     ... }  The  function  price(token0,token1,safetyIndicesSet)  checks  if  the  mapping  oraclesIndex has the addresses for the respective Chainlink oracles:  if ((address(chainlinkOracle0) != address(0)) || (address(chainlinkOracle1) != address(0))) {         return (pricesX96, safetyIndices); // returns empty values }  The condition above is incorrect as it returns empty values if the Chainlink oracles exist in the mapping. This  makes  the  Chainlink  oracle  -  assumed  to  be  the  safest  by  the  specifications  and  the  code  - unusable.    The above check in function price has been revised to return empty prices only if there is no entry for at least one of the tokens in mapping oraclesIndex:   if ((address(chainlinkOracle0) == address(0)) || (address(chainlinkOracle1) == address(0))) {     return (pricesX96, safetyIndices); }  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Incorrect LP Token Calculation in ",
        "body": " ERC20RootVault  ERC20RootVault._getLpAmount  incorrectly  calculates  the  minimum  of  given  token  amounts.  An attacker can issue more LP tokens than he is entitled to and can then exchange them back for additional tokens.  The following code incorrectly resets the MIN calculation for as many iterations as tokenLpAmount is equal to 0:  for (uint256 i = 0; i < tvlsLength; ++i) {    if ((amounts[i] == 0) || (tvl_[i] == 0)) {       continue;    }     uint256 tokenLpAmount = FullMath.mulDiv(amounts[i], supply, tvl_[i]);    if ((tokenLpAmount < lpAmount) || (lpAmount == 0)) {       lpAmount = tokenLpAmount;  Mellow Finance - Mellow Vaults -   22  CorrectnessCriticalVersion1CodeCorrectedCorrectnessCriticalVersion1CodeCorrected              \f   } }  If tokenLpAmount == 0 in the first iteration, lpAmount will be set to 0. If tokenLpAmount > 0 in the next iteration, lpAmount will be set to tokenLpAmount although it is larger than the already set value.  In a later step, ERC20RootVault._getNormalizedAmount normalizes the sent token amounts to the calculated lpAmount. This function however does not increase the normalized amount to a value greater than the sent one. An attacker can therefore exploit this by calling deposit with all token amounts but the last one being set to 0 and then calling withdraw with the LP tokens that have just been minted to obtain his initial investment plus an amount of all other tokens in the Vault equal to the current ratio of tokens.    The  function  _getLpAmount  has  been  refactored  to  set  the  lpAmount  to  the  minimum  of tokenLpAmount calculated on each iteration of the for loop. The flag isLpAmountUpdated is set to true on the first iteration that a non-zero value is assigned to lpAmount.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Missing Access Control in UniV3Oracle",
        "body": "  The function addUniV3Pools populates the mapping poolsIndex with the address of a Uniswap pool for  a  pair  of  tokens.  The  function  should  be  accessible  only  to  trusted  accounts,  however,  it  does  not implement  any  access  restriction.  As  the  function  is  external  anyone  can  set  arbitrary  addresses  as Uniswap pools, hence freely manipulate the oracle prices.    The updated code resolves the issue by restricting the access to the function addUniV3Pools only to the admin, hence preventing malicious users from setting arbitrary addresses as Uniswap pools:  function addUniV3Pools(IUniswapV3Pool[] memory pools) external {     _requireAdmin();     _addUniV3Pools(pools); }  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   UniV3Oracle Returns Reverse Prices for",
        "body": " Token Pairs  The UniV3Oracle computes the price for two tokens using the Uniswap V3 observations. As the tokens in  Uniswap  are  always  sorted  by  their  address  (Token0  <  Token1),  the  function  price  uses  a  flag revTokens to distinguish if the price from Uniswap corresponds to the order of function parameters, or if it should be reversed. The respective code is:  Mellow Finance - Mellow Vaults -   23  SecurityCriticalVersion1CodeCorrectedCorrectnessCriticalVersion1CodeCorrected                \ffunction price(address token0,address token1,uint256 safetyIndicesSet)     external view returns (uint256[] memory pricesX96, uint256[] memory safetyIndices) {    ...     bool revTokens = token1 > token0;      for (uint256 i = 0; i < len; i++) {         if (revTokens) {             pricesX96[i] = FullMath.mulDiv(CommonLibrary.Q96, CommonLibrary.Q96, pricesX96[i]);         }         pricesX96[i] = FullMath.mulDiv(pricesX96[i], pricesX96[i], CommonLibrary.Q96);     } }  The flag revToken is set to true if the tokens in the function parameters are ordered as in Uniswap, hence incorrectly reverses the computed price.    The  contract  UniV3Oracle  has  been  refactored  due  to  the  bug  presented  above  and  other  issues reported for this contract. The code above that mistakenly reversed the prices is not present anymore in  , however, another issue has been introduced on the fix.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Incorrect TVL Conversion",
        "body": "  The function _getTvlToken0 incorrectly converts the TVL amount of a given token i into token 0. The oracle returns a price in x96 format. This price is directly used as if it would be a correctly formatted price to  convert  the  amounts.  As  the  TVL  in  most  cases  will  be  lower  than  the  price  in  x96  format  the calculation will return 0.  tvl0 = tvls[0]; for (uint256 i = 1; i < tvls.length; i++) {     (uint256[] memory prices, ) = oracle.price(tokens[0], tokens[i], 0x28);     require(prices.length > 0, ExceptionsLibrary.VALUE_ZERO);     uint256 price = 0;     for (uint256 j = 0; j < prices.length; j++) {         price += prices[j];     }     price /= prices.length;     tvl0 += tvls[i] / price;  Additionally,  the  calculation  would  be  more  precise  if  the  price  would  be  multiplied  to  convert  the amounts.    The  issue  about  the  conversion  of  TVLs  in  function  _getTvlToken0  has  been  addressed.  The  last statement of the for-loop has been changed:  tvl0 += FullMath.mulDiv(tvls[i], CommonLibrary.Q96, priceX96);  Mellow Finance - Mellow Vaults -   24  Version2CorrectnessHighVersion3CodeCorrected          \f6.7   Adding up Total Value Locked on Different Tokens  function  postPreOrder  calls   The  tvl[0] + tvl[1] (see the issue reported in Calling _liquidityDelta incorrectly).  the   function  _liquidityDelta  with  tvl[0]  and  Additionally, the calculations are performed on tvl with different underlying tokens. Namely, tvl[0] is in the denomination of token0, while tvl[1] in the denomination of token1.    , the first argument tvl[0] is converted into the domination The issue is resolved in code base  of  token1  before  passed  to  _liquidityDelta,  while  the  second  parameter  tvl[1]  remains  in  the denomination of token1.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   Calling _liquidityDelta Incorrectly",
        "body": "  The function postPreOrder in Lstrategy calls _liquidityDelta as follows:  (uint256 tokenDelta, bool isNegative) = _liquidityDelta(     tvl[0],     tvl[0] + tvl[1],     ratioParams.erc20TokenRatioD,     ratioParams.minErc20TokenRatioDeviationD );  As  already  pointed  out  in  the  issue  Calling  _liquidityDelta  with  incorrect  inputs,  the  function _liquidityDelta also performs the addition, hence computing incorrectly the result.    The parameters passed to the function _liquidityDelta have been corrected, namely the addition of tvl[0] + tvl[1] is removed and only tvl[1] is passed as the second argument of the function call.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   Calling _liquidityDelta With Incorrect",
        "body": " Inputs  The function rebalanceERC20UniV3Vaults in LStrategy calls _liquidityDelta as follows:  (capitalDelta, isNegativeCapitalDelta) = _liquidityDelta(     erc20VaultCapital,     erc20VaultCapital + lowerVaultCapital + upperVaultCapital,     ratioParams.erc20UniV3CapitalRatioD,  Mellow Finance - Mellow Vaults -   25  CorrectnessHighVersion1CodeCorrectedVersion2CorrectnessHighVersion1CodeCorrectedCorrectnessHighVersion1CodeCorrected                      \f    ratioParams.minErc20UniV3CapitalRatioDeviationD );  Note  that,  the  first  parameter  is  included  in  the  sum  used  as  the  second  parameter.  However,  the function  _liquidityDelta  also  performs  the  addition  on  the  code  below,  hence  computing targetLowerLiquidity incorrectly:  uint256 targetLowerLiquidity = FullMath.mulDiv(     targetLiquidityRatioD,     lowerLiquidity + upperLiquidity,     DENOMINATOR );    In rebalanceERC20UniV3Vaults the calculation does not add erc20VaultCapital anymore.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   Incorrect Observation Index in ",
        "body": " _getAverageTick  Function _getAverageTick computes the averageTick and the tickDeviation based on the most recent observation and a previous observation referred as observationIndexLast. The latter index is computed as follows:  uint16 observationIndexLast = observationIndex >= oracleObservationDelta     ? observationIndex - oracleObservationDelta     : observationIndex + (type(uint16).max - oracleObservationDelta + 1);  If oracleObservationDelta is larger than observationIndex (e.g., by 1), the code above returns a  value  that  is  close  (or  equal)  to  type(uint16).max.  It  is  very  likely  that  the  Uniswap  pool  has  a smaller  cardinality  of  observations  than  the  computed  observationIndexLast,  hence  0s  would  be returned for this observation.    formula   The  when oracleObservationDelta  >  observationIndex  has  been  revised,  type(uint16).max  has been replaced with observationCardinality.  observationIndexLast   compute   to   obsIdx = 20 delta = 30 card = 50 --- 20 + 50 -30 = 40  obsIdx = 30 delta = 30 card = 50 --- 0  obsIdx = 30 delta = 31 card = 50 --- 30 + 50 -31 = 49  obsIdx = 30 delta = 49 card = 50 --- 30 + 50 - 49 = 31  generalized: obsIdx + card - delta % card  Mellow Finance - Mellow Vaults -   26  CorrectnessHighVersion1CodeCorrected          \f6.11   Incorrect Parameters on externalCall  The function signOrder in LStrategy performs few externalCall s, and for one of them sets the wrong parameters as input:  bytes memory setPresignatureData = abi.encode(SET_PRESIGNATURE_SELECTOR, uuid, signed); erc20Vault.externalCall(cowswap, SET_PRESIGNATURE_SELECTOR, setPresignatureData);  Note  that  the  function  selector  is  part  of  the  abi.encode  and  then  is  set  as  the  second  parameter  in externalCall, which also appends the selector when executing the call, hence causing the external function to always fail:  (bool res, bytes memory returndata) = to.call{value: msg.value}(abi.encodePacked(selector, data));    The  external  call  in  LStrategy.signOrder  does  not  encode  the  SET_PRESIGNATURE_SELECTOR twice anymore.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.12   Insufficient Testing",
        "body": "  We found an unusual high number of issues that would have been easily detected with proper tests. The current unit and integration tests are insufficient.    The tests have been extended significantly on the latest iterations of the review process to cover more functions and call paths.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.13   Opposite Vaults Are Swapped",
        "body": "  The  function  _swapVaults  in  LStrategy  should  close  the  position  with  no  liquidity  and  open  a  new one given the price move in positiveTickGrowth. The decision on which vault to close is done in the following if condition:  /// @param positiveTickGrowth `true` if price tick increased ... if (!positiveTickGrowth) {     (fromVault, toVault) = (lowerVault, upperVault); } else {     (fromVault, toVault) = (upperVault, lowerVault); }  The  function  closes  the  fromVault  and  creates  the  new  vault  according  to  the  current  position  of toVault.  However,  the  code  above  assigns  fromVault  wrongly  to  lowerVault  if  the  tick  is  Mellow Finance - Mellow Vaults -   27  CorrectnessHighVersion1CodeCorrectedSecurityHighVersion1CodeCorrectedCorrectnessHighVersion1CodeCorrected                      \fdecreasing,  and  vice-versa  if  the  tick  is  increasing.  Given  this  error  and  the  following  requirement,  the function would fail always (as fromVault has all liquidity):  require(fromLiquidity == 0, ExceptionsLibrary.INVARIANT);    The vaults were switched like:  if (!positiveTickGrowth) {         (fromVault, toVault) = (upperVault, lowerVault);     } else {         (fromVault, toVault) = (lowerVault, upperVault);     }  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.14   Possibility to Exit Positions of Any Address",
        "body": "  In  ERC20RootVault.withdraw,  LP  tokens  are  burned  in  a  call  to  _burn  from  the  address  that  is specified  in  the  to  parameter.  Neither  _burn  nor  any  other  statement  in  withdraw  performs  access control checks to verify if the msg.sender is allowed to burn the tokens of the given address. Thus, any user can burn LP tokens of a given address and transfer the underlying tokens to that address.  Finally, an incorrect event is emitted with msg.sender.    . The function withdraw now burns only The issues have been resolved in the updated code  the LP tokens of the msg.sender, while transfers the underlying tokens to the address to specified by the caller.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.15   Possible DOS From First Depositor",
        "body": "  The first user that calls deposit in ERC20RootVault can choose freely any amount (including zero) for each  vault  token,  while  the  LP  shares  are  set  to  the  largest  amount  by  the  following  loop  in _getLpAmount:  for (uint256 i = 0; i < tvl_.length; ++i) {     if (amounts[i] > lpAmount) {         lpAmount = amounts[i];     } }  However, if the first user (on initialization or whenever totalSupply is zero) chooses to deposit only one token (e.g., token[0]) it makes impossible for other users to deposit other tokens (e.g., token[1]) as the totalSupply is not zero anymore, and _getNormalizedAmount considers the existing TVL:  Mellow Finance - Mellow Vaults -   28  SecurityHighVersion1CodeCorrectedVersion2SecurityHighVersion1CodeCorrected                \f// normalize amount uint256 res = FullMath.mulDiv(tvl_, lpAmount, supply); // if tvl_ == 0, res = 0  The intended use of the function might be that the first deposit is done by a trusted account, but this is not enforced.    A new constant FIRST_DEPOSIT_LIMIT is introduced and a require checks that each token amount is above this limit with tokenAmounts[i] > FIRST_DEPOSIT_LIMIT.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.16   Setting Wrong State Variable",
        "body": "  The function _setOperatorParams in VaultGovernance, as the name suggests, should update the state variable _operatorParams, instead it overwrites the variable _protocolParams:  function _setOperatorParams(bytes memory params) internal {     _requireAtLeastOperator();     _protocolParams = params; }  This mistake has severe consequences: operator gets admin privileges to set _protocolParams or can set  a  vault  state  to  incorrect  parameters.  Finally,  the  functionality  to  initialize  or  update  the _operatorParams is missing.    The  issue  is  resolved  and  now  the  function  _setOperatorParams  sets  the  operator  params  as intended. The natspec description has been updated accordingly also.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.17   Wrong Formula in ",
        "body": " _rebalanceUniV3Liquidity  The  function  _rebalanceUniV3Liquidity  in  LStrategy  updates  the  value  of  liquidity  as follows:  liquidity = uint128(     FullMath.mulDiv(         availableBalances[i],         shouldDepositTokenAmountsD[i] - shouldWithdrawTokenAmountsD[i],         DENOMINATOR     ) );  The  formula  above  is  wrong,  it  multiplies  two  amounts  in  token[i],  then  divides  the  result  with DENOMINATOR.  Mellow Finance - Mellow Vaults -   29  CorrectnessHighVersion1CodeCorrectedCorrectnessHighVersion1CodeCorrected                \f  The formula now multiplies with DENOMINATOR and divides by the token amount.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.18   Wrong TVL Calculation in ERC20RootVault",
        "body": "  ERC20RootVault._getTvlToken0  calculates  the  TVL  of  the  Vault  denominated  in  the  token  at position 0 of an array of tokens. It iterates over all the tokens in the array, but only ever compares token with index 0 to token with index 1. It should, however, compare token with index 0 to the token with the current iteration's index. The function is only used in _calculatePerformanceFees.  for (uint256 i = 1; i < tvls.length; i++) {         (uint256[] memory prices, ) = oracle.price(tokens[0], tokens[1], 0x28);    The issue has been resolved as the correct index is now used when querying the price of tokens inside the loop.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.19   liquidity Gets Overwritten in the Loop",
        "body": "  The following loop in LStrategy._rebalanceUniV3Liquidity updates the liquidity for vault tokens in a loop:  for (uint256 i = 0; i < 2; i++) {     ...     liquidity = uint128(         FullMath.mulDiv(             availableBalances[i],             shouldDepositTokenAmountsD[i] - shouldWithdrawTokenAmountsD[i],             DENOMINATOR         )     ); }  The  final  value  of  liquidity  after  the  loop  exists  should  be  the  minimum  value  calculated  in  each iteration, however, the loop above overwrites the liquidity on each iteration without performing any check.    In  with liquidity, hence liquidity can only decrease in the loop:    the  potentialLiquidity  is  computed  on  each  iteration  of  the  loop  and  it  is  compared  Mellow Finance - Mellow Vaults -   30  CorrectnessHighVersion1CodeCorrectedCorrectnessHighVersion1CodeCorrectedVersion2                \fliquidity = potentialLiquidity < liquidity ? potentialLiquidity : liquidity;  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.20   Wrong State Variable Updated",
        "body": "  The function LStrategy.rebalanceUniV3Vaults updates the wrong state variable when storing the timestamp of the ongoing rebalance:  require(     block.timestamp >= lastRebalanceUniV3VaultsTimestamp + otherParams.secondsBetweenRebalances,     ExceptionsLibrary.TIMESTAMP ); lastRebalanceERC20UniV3VaultsTimestamp = block.timestamp;  Due to this error the throttling mechanism does not work as expected for the function rebalancing the two function uniswap  vaults.  Furthermore,  rebalanceERC20UniV3Vaults.  throttling  mechanism  of   this  also  affects   the   the     The issue has been fixed and the correct state variable is updated in rebalanceUniV3Vaults:  lastRebalanceUniV3VaultsTimestamp = block.timestamp;  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.21   Inconsistent Access Control for Rebalance in",
        "body": " LStrategy  The  function  LStrategy.rebalanceERC20UniV3Vaults  restricts  the  access  to  only  accounts  with operator or admin roles. However, functions deposit and withdraw in the ERC20RootVault do not have  any  access  restriction  (unless  the  vault  is  private).  The  root  vault  has  the  operator  role  in LStrategy  and  for  any  deposit  or  withdraw  operation,  the  vault  triggers  the  rebalance  function  in LStrategy, hence circumventing the access control of the rebalance function.  Specification changed:  Mellow Finance has decided to remove the callback feature that triggered the rebalance in LStrategy. Now, the rebalance functions rebalanceERC20UniV3Vaults and rebalanceUniV3Vaults can be called only by whitelisted addresses with either admin or operator role. Note that, the callback feature is still present in ERC20RootVault in case future strategies will support the callback feature.  Mellow Finance - Mellow Vaults -   31  DesignMediumVersion8CodeCorrectedDesignMediumVersion4Speci\ufb01cationChanged                  \f6.22   Inconsistent Sanity Check on First Deposit's Amounts  The  function  ERC20RootVault.deposit  runs  the  following  loop  for  the  first  deposit  (whenever totalSupply  is  0)  to  check  that  all  amounts  are  above  a  threshold  FIRST_DEPOSIT_LIMIT (hard-coded to 10000):  if (totalSupply == 0) {     for (uint256 i = 0; i < tokens.length; ++i) {         require(tokenAmounts[i] > FIRST_DEPOSIT_LIMIT, ExceptionsLibrary.LIMIT_UNDERFLOW);     } }  The  contract  uses  another  set  of  thresholds  per  token  _pullExistentials  which  are  initialized  as: 10**(token.decimals() / 2). Hence for tokens with more than 8 decimals, there is a gap between the two thresholds FIRST_DEPOSIT_LIMIT and _pullExistentials. If the first deposit includes an amount for a token in this gap, the contract does not allow new deposits for the token from other users as the respective TVL will be always below the threshold _pullExistentials. This behavior is enforced in _getLpAmount:  for (uint256 i = 0; i < tvlsLength; ++i) {     if (tvl_[i] < pullExistentials[i]) {         continue;     }     ... }  and in the function _getNormalizedAmount:  if (tvl_ < existentialsAmount) {     // use zero-normalization when all tvls are dust-like     return 0; }    Mellow Finance now requires that the amount in the first deposit is 10 times the _pullExistentials.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.23   Safety Level of Returned Prices Can Silently",
        "body": " Downgrade  The  function  UniV3Oracle.price  returns  more  than  one  price  depending  on  the  value  of safetyIndicesSet. UniV3Oracle supports 4 safety levels:   Safety level 1: spot price.   Safety level 2: average price based on observations from last 2.5 minutes.  Mellow Finance - Mellow Vaults -   32  DesignMediumVersion4CodeCorrectedSecurityMediumVersion4Speci\ufb01cationChanged              \f Safety level 3: average price based on observations from last 7.5 minutes.   Safety level 4: average price based on observations from last 30 minutes.  If  a  Uniswap  pool  does  not  have  enough  observations  required  for  a  safety  level,  the  oracle  skips  the prices for such safety levels and returns only prices with lower safety levels. The respective code:  for (uint256 i = 2; i < 5; i++) {     ...     (int24 tickAverage, , bool withFail) = OracleLibrary.consult(address(pool), observationTimeDelta);     if (withFail) {         break;     }     ... }  Specifications changed:  The  natspec  description  of  IOracle.priceX96  has  been  updated  to  be  more  explicit  about  this behavior:  /// @notice It is possible that not all indices will have their respective prices returned.  Also, more detailed description has been added in UniV3Oracle.priceX96:  /// If there is no initialized pool for the passed tokens, empty arrays will be     returned. /// Depending on safetyIndicesSet if the 1st bit in safetyIndicesSet is non-zero, then     the response will contain the spot price. /// If there is a non-zero 2nd bit in the safetyIndicesSet and the corresponding     position in the pool was created no later than |l|_OBS_DELTA seconds ago, /// then the average price for the last |l|_OBS_DELTA seconds will be returned. The     same logic exists for the 3rd and MID_OBS_DELTA, and 4th index and |hl|_OBS_DELTA.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.24   Unfair Distribution of LP Shares in",
        "body": " ERC20RootVault  The  ERC20RootVault  charges  the  management,  protocol  and  performance  fees  by  minting  new  LP shares, hence inflating the total supply. The function _chargeFees is triggered on every deposit (and withdraw) action, hence the total supply of LP shares after a deposit increases more than the amount of LP shares awarded to the depositor. In this way, a second deposit of the same token amounts after the fees have been charged, receives more LP shares than the first one.  For  example,  assume  that  the  ERC20RootVault  has  been  initialized  and  a  first  user  deposits  10 TokenA and 10 TokenB (assuming 0 decimals for simplicity) and receives 10 LP shares. As the fees will be charged on deposit, let's suppose another 1 LP share will be minted, hence in total there are 11 LP shares  minted  after  the  deposit.  If  a  second  user  deposits  the  same  amounts  10  TokenA  and  10 TokenB, the function _getLpAmount will award 11 LP shares to the user although the same amounts were deposited.    Mellow Finance - Mellow Vaults -   33  DesignMediumVersion3CodeCorrected        \fThe  issue  has  been  addressed  by  modifying  the  functions  deposit  to  charge  fees  first  and  then compute the LP shares awarded to the user according to the new LP supply.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.25   Conflicting Specifications for MStrategy",
        "body": "  The specifications of MStrategy have conflicting instructions. The section \"TickMin and TickMax update\" states:  tickMin and tickMax are initially set to some ad-hoc params. As soon as the current price \u2014 tick is greater than tickMax - tickNeiborhood or less than tickMin + tickNeiborhood  the boundaries of the interval is expanded by tickIncrease amount.  In the rebalance steps, tickNeiborhood is used instead of tickIncrease:  - tick is greater than tickMax - tickNeiborhood then new     boundaries are [tickMin, tickMax + tickNeiborhood]  - tick is less than tickMin + tickNeiborhood then new     boundaries are [tickMin - tickNeiborhood, tickMax]  Specification changed:  The specification was changed accordingly.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.26   Implementation Differs From Specification",
        "body": " on _targetTokenRatioD  The specifications use the following formula to compute the portions of tokens in a Uniswap v3 pool: | wx = tick \u2212 tickMax tickMin \u2212 tickMax  However, the implementation uses the following code:  return (uint256(uint24(tick - tickMin)) * DENOMINATOR) / uint256(uint24(tickMax - tickMin));  which corresponds to the following formula: |  wx = tick \u2212 tickMin  tickMax \u2212 tickMin    The  implementation  of  MStrategy._targetTokenRatioD  has  been  updated  to  comply  to  the specification.  Mellow Finance - Mellow Vaults -   34  CorrectnessMediumVersion1Speci\ufb01cationChangedCorrectnessMediumVersion1CodeCorrected                    \f6.27   Incorrect Access of Addresses in  EnumerableSet  Function  commitAllValidatorsSurpassedDelay  in  the  protocol  governance  contract  has  a  for loop that iterates through _stagedValidatorsAddresses and commits the ones for which the delay period has passed. The respective code is:  for (uint256 i; i != length; i++) {     address stagedAddress = _stagedValidatorsAddresses.at(0);     if (block.timestamp >= stagedValidatorsTimestamps[stagedAddress]) {         ...     } }  The variable stagedAddress inside the loop points always to the hard-coded index 0, hence if there is at least one address in staged validators for which the deadline has not passed, the loop will just run until it reaches i==length.    The 0 was replaced by the index variable i. The loop exit conditions were changed to:  uint256 length = _stagedValidatorsAddresses.length(); ... uint256 addressesCommittedLength; for (uint256 i; i != length;) {         address stagedAddress = _stagedValidatorsAddresses.at(i);             ...             addressesCommitted[addressesCommittedLength] = stagedAddress;             ++addressesCommittedLength;             --length;             ...         } else {             ++i;         }  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.28   Missing Checks for Dust Amounts When",
        "body": " Rebalancing Pools  The  function  _rebalancePools  in  MStrategy  rebalances  the  erc20Vault  and  moneyVault  to comply  to  the  specified  ratio  erc20MoneyRatioD.  The  rebalancing  is  performed  always  when  a non-zero amount should be moved from one vault to the other, i.e., even for dust amounts. Considering that pull is relatively costly, the strategy would be more efficient if it performs the rebalancing of the two pools only if a minimum threshold of tokens should be moved.  Mellow Finance - Mellow Vaults -   35  CorrectnessMediumVersion1CodeCorrectedDesignMediumVersion1CodeCorrected                \f  The updated code does not perform the token transfers if only dust amounts should be moved:  if ((absoluteTokenAmounts[0] < minDeviation) && (absoluteTokenAmounts[1] < minDeviation)) {     return tokenAmounts; }  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.29   Missing Delay Restriction in BaseValidator",
        "body": "  Setting the new params in BaseValidator follows the pattern stage-wait-commit. On staging the new parameters, the respective timestamp is updated:  _stagedValidatorParamsTimestamp = block.timestamp + governance.governanceDelay;  However,  the  admin  of  the  governance  can  commit  the  staged  parameters  at  any  time,  e.g., immediately after staging them, by calling commitValidatorParams as the function does not check if the delay period has passed.    The  block.timestamp >= _stagedValidatorParamsTimestamp.  function   checks   delay   now   the   with   a   require   validating  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.30   Missing Sanity Checks in signOrder",
        "body": "  The function signOrder in LStrategy performs some sanity checks if the submitted order is in line with the values of the posted preOrder. However, the check for order.receiver is missing, therefore the caller can set any arbitrary address and receive the buyToken.    The  code  doing  the  sanity  checks  for  order  in  signOrder  has  been  moved  to  the  separate  function LStrategyOrderHelper.checkOrder  which  the erc20Vault.  the  receiver   the  check   includes   that   is   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.31   No Slippage Protection in Multiple Contracts",
        "body": "  push and pull functions in UniV3Vault take options arguments that contain the minimum amount of tokens for slippage protection.  Mellow Finance - Mellow Vaults -   36  CorrectnessMediumVersion1CodeCorrectedSecurityMediumVersion1CodeCorrectedSecurityMediumVersion1CodeCorrected                        \fpush and pull functions in MellowVault take an options argument that contains the minimum amount of LP tokens for slippage protection.  In the following cases, these options are not used:  call    ERC20RootVault.deposit calls AggregateVault._push without options, which could result in described a  of  Vault``s  without  slippage  protection  if  the  first  ``subVault  of  the ERC20RootVault  is  one  of  the  described  Vault  s.  With  the  current  contract  setup,  this  is  not possible though.  _push   one   the   to   of    ERC20RootVault.withdraw calls AggregateVault._pull without options, which could result  in a call to _pull of one of the described ``Vault``s without slippage protection.   MStrategy.manualPull calls pull of an arbitrary Vault without options, which could result in a  call to _pull of one of the described ``Vault``s without slippage protection.   MStrategy._rebalancePools  calls  pull  of  an  arbitrary  Vault  without  options,  which  could  result in a call to _pull of one of the described ``Vault``s without slippage protection.   MStrategy._swapToTarget calls pull of an arbitrary Vault without options, which could result  in a call to _pull of one of the described ``Vault``s without slippage protection.    A new parameter with option for slippage protection was introduced.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.32   Possible Underflow in UniV3Oracle.price",
        "body": "  The UniV3Oracle computes the price of two tokens based on two observations obs1 and obs0 from the Uniswap. The respective code is:  uint256 obs1 = (uint256(observationIndex) + uint256(observationCardinality) - 1) %                 uint256(observationCardinality); uint256 obs0 = (uint256(observationIndex) + uint256(observationCardinality) - bfAvg) %                 uint256(observationCardinality); int256 tickAverage; {     (uint32 timestamp0, int56 tick0, , ) = IUniswapV3Pool(pool).observations(obs0);     (uint32 timestamp1, int56 tick1, , ) = IUniswapV3Pool(pool).observations(obs1);     uint256 timespan = timestamp1 - timestamp0; // reverts     ... }  The  obj1  points  to  the  previous  observation  (the  one  before  the  most  recent  observation),  while  the obj0 should point to bfAvg observations before obj1. However, in case:  bfAvg == observationCardinality  obj0 would point to the most recent observation, which would have a more recent timestamp than obj1, hence the statement to compute timespan would cause an underflow which reverts.    Mellow Finance - Mellow Vaults -   37  CorrectnessMediumVersion1CodeCorrected        \fThe  possibility  of  the  underflow  as  described  above  has  been  mitigated  in  the  updated  code  as  the bfAvg cannot be equal to obersvationCardinality:  if (observationCardinality <= bfAvg) {     continue; }  Note  that,  the  oracle  does  not  return  a  price  if  for  some  pool  bfAvg  is  equal  to  the  observations cardinality.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.33   Rebalance in LStrategy Can Leave Tokens in",
        "body": " the Vault to Be Closed  The  internal  function  _rebalanceUniV3Liquidity  should  move  the  desiredLiquidity  from  one vault to the other depending on the price trend. If the price moves outside the range covered by a vault, all liquidity should be moved to the other vault and a new position should be open. However, given that lowerVault and upperVault operate on different price ranges, it means that they have different token ratios.  Hence,  when  moving  tokens  from  one  vault  to  the  other,  the  function  caps  the  liquidity  being transferred to the available balance in the cash position that can fill the token difference of two positions (the relevant code is shown below). However, if the cash position has insufficient balance to cover the difference for the whole liquidity being transferred, fromVault will have some remaining liquidity, hence it cannot be closed. As a consequence, a new Uniswap position cannot be created to cover the price as intended.  uint128 potentialLiquidity = uint128(     FullMath.mulDiv(         availableBalances[i],         DENOMINATOR,         shouldDepositTokenAmountsD[i] - shouldWithdrawTokenAmountsD[i]     ) ); liquidity = potentialLiquidity < liquidity ? potentialLiquidity : liquidity;    The  function  LStrategy._rebalanceUniV3Liquidity  has  been  modified  in    to  withdraw everything from a vault when desiredLiquidity is set to maximum value of uint128, which is the case when a vault is to be closed. The relevant code is:  uint256[] memory withdrawTokenAmounts = fromVault.liquidityToTokenAmounts(     desiredLiquidity == type(uint128).max ? desiredLiquidity : liquidity ); pulledAmounts = fromVault.pull(     address(erc20Vault),     tokens,     withdrawTokenAmounts,     _makeUniswapVaultOptions(minWithdrawTokens, deadline) );  Mellow Finance - Mellow Vaults -   38  DesignMediumVersion1CodeCorrectedVersion3        \fThe array withdrawTokenAmounts will have huge amounts when the desiredLiquidity is set to max uint128, but the pull operation is capped to the existing balance of the fromVault.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.34   Subvault Tokens Are Not Checked in ",
        "body": " AggregateVault  AggregateVault  requires  the  _vaultTokens  state  array  to  be  initialized  with  the  same  tokens  and the  same  ordering  all  the  subvaults  have  been  initialized  with.  However,  this  is  not  enforced  upon initialization.    When initializing, the vault of the nft is queried in AggregateVault.initialize. The vault's tokens are  queried  afterwards  with  the  call  IIntegrationVault(vault).vaultTokens().  A  loop  checks for each token in the vault if it matches the tokens from the initialization arguments.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.35   Transferring Tokens Only to lowerVault",
        "body": "  The  following  code  should  transfer  tokens  from  erc20Vault  to  the  two  Uniswap  vaults  with  the respective amounts:  if (!isNegativeCapitalDelta) {     totalPulledAmounts = erc20Vault.pull(         address(lowerVault),         tokens,         lowerTokenAmounts,         _makeUniswapVaultOptions(minLowerVaultTokens, deadline)     );     pulledAmounts = erc20Vault.pull(         address(lowerVault),         tokens,         upperTokenAmounts,         _makeUniswapVaultOptions(minUpperVaultTokens, deadline)     );     for (uint256 i = 0; i < 2; i++) {         totalPulledAmounts[i] += pulledAmounts[i];     } }  Both transfers above are from the erc20Vault to the lowerVault, hence no tokens are transferred to the upperVault.    The  bug  has  been  fixed,  the  code  now  transfers  the  respective  amounts  to  the  lowerVault  and upperVault.  Mellow Finance - Mellow Vaults -   39  CorrectnessMediumVersion1CodeCorrectedCorrectnessMediumVersion1CodeCorrected                \f6.36   Use of Libraries  Mellow Finance often uses own custom code for which battle proof libraries exist. We highly recommend using libraries instead of custom implementations. Especially, when dealing with complex DeFi projects like Uniswap V3.  Code Corrected:  The  code  part  were  most  issues  were  found  was  the  Uniswap  oracle.  In  switched to the libraries provided by uniswap to interact with the oracle.    Mellow  Finance  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.37   Missing Sanity Checks for ",
        "body": " intervalWidthInTicks  function  LStrategy.updateOtherParams  does  not  perform  any  sanity  check  on  The  the intervalWidthInTicks. However, this parameter should be carefully updated as it affects directly the tick ranges covered by the two Uniswap vaults. For example, if the new width in ticks is the half of the existing one, the range of the new position would be fully covered by the existing vault (created with old width).    In  the  updated  version  of  the  codebase,  the  parameter  intervalWidthInTicks  is  declared  as  an immutable state variable, hence it set in the constructor and cannot be updated later.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.38   Possible Attack by First Depositor",
        "body": "  The decimals of the LP shares distributed by root vaults are implicitly determined by the token amounts deposited  by  the  first  user.  If  the  totalSupply  ever  goes  to  zero,  or  all  TVLs  are  not  significant,  the next  user  that  performs  a  deposit  would  affect  the  decimals  of  LP  shares.  This  setup  allows  the  first depositor  to  front-run  and  potentially  exploit  the  next  user  depositing  into  the  root  vault.  Consider  the following example.  1. First  Depositors  deposits  10  WBTC  (8  decimals,  so  10**9  wei)  and  10**-9  DAI  (18  decimals,  so  10**9 wei)   Receives 10**9 LP Tokens (= max(10**9, 10**9))  2. Second Depositor also sends a transaction to deposit 10 WBTC and 10**-9 DAI   Expects to receive also 10**9 LP Tokens, hence sets minLpTokens = 10**9  3. First depositor front-runs the transaction and performs these actions:  Mellow Finance - Mellow Vaults -   40  DesignMediumVersion1CodeCorrectedVersion3DesignLowVersion5CodeCorrectedSecurityLowVersion5Speci\ufb01cationChanged                        \f withdraw() => withdraws everything, no fees charged   deposit() => deposit 10**5 WBTC wei and 10**10 DAI wei => Receives 10**10 LP tokens   withdraw() => withdraws ~ 9 * 10**9 LP => TVLs = [10**4 - 1 WBTC wei, 10**9 - 1 USDC  wei]   First depositor still has ~ 10**9 LP  4. Transaction of second depositor is executed   _getLpAmount -> isSignificantTvl == False   Receives 10**9 LP tokens => slippage protection passes   Deposits 10 WBTC and 10**-9 DAI  5. First  depositor  withdraws  their  ~  10**9  LP  and  receives  ~  5  WBTC  (after  depositing  only  0.0001  WBTC)  Specifications changed:  The updated code mitigates the attack presented above by enforcing the first deposit into a root vault to mint  LP  shares  to  address(0).  To  prevent  from  accidentally  depositing  large  amounts  in  the  first deposit  (and  effectively  burning  LP  shares),  the  function  checks  that  all  amounts  being  deposited  are between 10 * _pullExistentials[i] and a full token. Nevertheless, one full token might still have significant value for some tokens, e.g., WBTC or ETH.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.39   Possible Optimization on",
        "body": " _chargePerformanceFees  The  function  _chargePerformanceFees  in  ERC20RootVault  mints  LP  tokens  to  the  treasury address as follows:  uint256 toMint; if (hwmsD18 > 0) {     toMint = FullMath.mulDiv(baseSupply, lpPriceD18 - hwmsD18, hwmsD18);     toMint = FullMath.mulDiv(toMint, performanceFee, CommonLibrary.DENOMINATOR); } lpPriceHighWaterMarkD18 = lpPriceD18; _mint(treasury, toMint);  The function would be more gas efficient if the minting is executed only for non-zero values, hence only minting when the if-condition is satisfied.    In  the  updated  code,  the  statement  _mint(...)  is  moved  inside  the  if-block,  hence  minting  only non-zero amounts.  Mellow Finance - Mellow Vaults -   41  DesignLowVersion5CodeCorrected          \f6.40   Possible Violation of the Minimum Token Amounts After the First Deposit  The function ERC20RootVault.deposit checks on the first deposit that all token amounts are larger than  a  minimum  value  10  *  _pullExistentials[i].  If  the  TVL  for  a  token  goes  below  the threshold,  users  cannot  make  deposits  for  that  token.  However,  the  first  depositor  can  circumvent  the restriction for the minimum token amounts by performing an withdrawal after the deposit.    The issue presented above is not present anymore in the updated code base as the first deposit always mints LP shares to address(0).  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.41   Misleading Function Name and Natspec",
        "body": "  The function LStrategy.targetPrice returns the price in x96 format. Neither the function name, nor the natspec description clarify the format of the return value. We have reported another issue in a calling function which assumed the price to be returned in a different format.    The codebase has been updated to make more explicit in the function name and natspec description of getTargetPriceX96 that the returned price is in x96 format. Similarly, other functions that return the price in x96 format are renamed accordingly.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.42   Mismatch of Specifications for",
        "body": " StrategyParams  The natspec description for the struct StrategyParams states that the params are changed with a delay:  /// @notice Params that could be changed by Strategy or Protocol Governance     with Protocol Governance delay.  while  the  natspec  description  of  the  function  setStrategyParams  states  that  they  are  changed immediately, which is in line with the implementation:  // @notice Set Strategy params, i.e. Params that could be changed by Strategy or Protocol Governance immediately.  Core corrected  The natspec was corrected and does not mention the governance delay.  Mellow Finance - Mellow Vaults -   42  DesignLowVersion5CodeCorrectedCorrectnessLowVersion4CodeCorrectedCorrectnessLowVersion4CodeCorrected                      \f6.43   Missing Sanity Check for maxSlippageD in MStrategy  The function MStrategy.setOracleParams does not check that maxSlippageD is greater than zero, but if it is accidentally set to zero, the following code will revert always: .. code::solidity  require(absoluteDeviation < oracleParams.maxTickDeviation, ExceptionsLibrary.INVARIANT);    The function setOracleParams is updated to include a check that the new maxSlippageD parameter is not zero:  require((params.maxSlippageD > 0) && (params.maxSlippageD <= DENOMINATOR), ExceptionsLibrary.INVARIANT);  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.44   Missing Sanity Checks for oracleSafetyMask",
        "body": "  The  function  LStrategy.updateTradingParams  performs  sanity  checks  on  the  maxSlippageD, orderDeadline and oracle, but no checks are performed for oracleSafetyMask. This parameter should be non-zero for functions that query the oracle to work properly. Additionally, the function could check that at least one oracle with high safety index is included always.    An  additional  check  is  added  when  new  trading  params  are  set  by  the  admin.  The  check  fort  the  new oracle safety mask is: newTradingParams.oracleSafetyMask > 3.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.45   Possible Struct Optimization in Strategies",
        "body": "  Mellow Finance might want to consider to optimize some structs in the code base. E.g., in:  struct TradingParams {     uint32 maxSlippageD;     uint32 orderDeadline;     uint256 oracleSafetyMask;     IOracle oracle;     ...  struct PreOrder {     address tokenIn;     address tokenOut;     uint256 amountIn;  Mellow Finance - Mellow Vaults -   43  DesignLowVersion4CodeCorrectedDesignLowVersion4CodeCorrectedDesignLowVersion4CodeCorrected                        \f    uint256 minAmountOut;     uint256 deadline; }  struct RatioParams {     int24 tickMin;     int24 tickMax;     uint256 erc20MoneyRatioD;     int24 minTickRebalanceThreshold;     int24 tickNeighborhood;     int24 tickIncrease;     uint256 minErc20MoneyRatioDeviation0D;     uint256 minErc20MoneyRatioDeviation1D; }  Some  of  the  variables  will  not  take  up  a  whole  word  and  could  be  reordered  to  be  packed  tightly  if needed.    The variables in the structs listed above are reordered to be more efficient when stored in storage in the updated code.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.46   Redundant Comparisons",
        "body": "  The function Univ3Vault._getMinMaxPrice implements the following code:  minPriceX96 = prices[0]; maxPriceX96 = prices[0]; for (uint32 i = 0; i < prices.length; ++i) {     if (prices[i] < minPriceX96) {         ...  Note that minPriceX96 and maxPriceX96 are assigned to prices[0] before the for-loop, so the first iteration of the loop is redundant.    The for-loop has been updated to start from i = 1 which avoids the redundant checks.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.47   Redundant Storage Read in ",
        "body": " ERC20Vault._pull  _vaultTokens  is  a  state  variable  that  is  read  multiple  times  in  the  _pull  function  even  though  it  is stored in memory at the beginning of the function in tokens.  Mellow Finance - Mellow Vaults -   44  DesignLowVersion4CodeCorrectedDesignLowVersion4CodeCorrected                \f  The  function  has  been  revised  to  avoid  storage  reads  for  _vaultTokens,  instead  the  value  stored  in memory tokens is now used.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.48   Variables Can Be Declared as Constant",
        "body": "  The variable MAX_ESTIMATED_AAVE_APY in AaveVaultGovernance is declared as immutable and assigned  to  a  constant  in  constructor.  Similarly,  MAX_PROTOCOL_FEE,  MAX_MANAGEMENT_FEE  and MAX_PERFORMANCE_FEE in ERC20RootVaultGovernance can be declared as constants.    All immutable variables listed above are converted to constants.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.49   Incorrect Specification for reclaimTokens",
        "body": "  The following statement in IntegrationVault regarding the function reclaimTokens is incorrect:  /// `reclaimTokens` for mistakenly transfered tokens (not included into vaultTokens) /// additionally can be withdrawn by the protocol admin  Specification changed:  The statement in IntegrationVault has been changed as:  /// `reclaimTokens` for claiming rewards given by an underlying protocol to erc20Vault      in order to sell them there  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.50   Missing Natspec Description for ",
        "body": " minDeviation  The  parameter  minDeviation  in  the  function  LStrategy._liquidityDelta  has  no  natspec description.  Code Corrected:  The description for minDeviation was added.  Mellow Finance - Mellow Vaults -   45  DesignLowVersion4CodeCorrectedCorrectnessLowVersion3Speci\ufb01cationChangedCorrectnessLowVersion2CodeCorrected                        \f6.51   Casting of maxTickDeviation  maxTickDeviation  _getAverageTickChecked, the variable is casted as int24:  is  declared  as  uint24   in   the  struct  OracleParams.   In   function  int24 maxDeviation = int24(oracleParams.maxTickDeviation);  For large values of maxTickDeviation, an overflow can happen when casting as int24.    The  deviation  is  now  converted  to  an  absolute  value  and  directly  compared  to  the  maxDeviation without casting it to an int24.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.52   Check Requirements First",
        "body": "  Multiple functions can be more efficient by checking all requirements first (fail early), before performing expensive operations, such as external calls. We list below some examples (not an exhaustive list):   UniV2Validator: in validate both branches of the if condition require the msg.sender to be the  address  to.  The  function  can  be  optimized  by  checking  the  requirement  first,  and  then performing the call to _verifyPath function.   UniV2Validator:  the  function  _verifyPath  can  be  optimized  by  checking  the  following  requirement first, before making external calls in the loop:  require(vault.isVaultToken(path[path.length - 1]), ExceptionsLibrary.INVALID_TOKEN);   UniV3Validator:  the  function  _verifyMultiCall  can  be  optimized  by  checking  the  following  requirement first, before iterating through path and making external calls:  require(recipient == address(vault), ExceptionsLibrary.INVALID_TARGET);    The  updated  code  expensive for the cases listed above.    performs  the  checks  first  before  executing  other  operations  that  might  be  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.53   Duplicate Code _permissionIdsToMask",
        "body": "  The  function  revokePermissions  in  the  ProtocolGovernance  contract  implements  the  following loop:  Mellow Finance - Mellow Vaults -   46  SecurityLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedVersion3DesignLowVersion1CodeCorrected                        \fuint256 diff; for (uint256 i = 0; i < permissionIds.length; ++i) {         diff |= 1 << permissionIds[i]; }  which is a duplicate of the _permissionIdsToMask function.    The code part was replaced by a call to the _permissionIdsToMask function.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.54   Duplicate Storage Read in Deposit",
        "body": "  In ERC20RootVault.deposit the variable totalSupply is read for the check if it is 0 and later again to be loaded into memory.    The redundant storage read is eliminated in the updated code and the value stored in memory supply is used instead.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.55   Inconsistent Specifications",
        "body": "  In the specifications of struct IProtocolGovernance.Params:   permissionless is described but it's not a member of the struct.   maxTokensPerVault  has  the  description  that  it  stores  the  maximum  tokens  managed  by  the  protocol, not a vault as the name suggests.   protocolTreasury is not described.  In the specifications of unitPrices, the comment staged for commit is wrong.  Specifications changed:  The specifications have been updated in    to address the issues reported above.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.56   Inefficient Array Shrinking",
        "body": "  ProtocolGovernance.addressesByPermission  and ProtocolGovernance.commitAllPermissionGrantsSurpassedDelay  arrays  with extended length and copy the values to a newly generated array with the correct size. This can be more efficiently done with mstore assembly, which is also used in various other places in the code.  create   Mellow Finance - Mellow Vaults -   47  DesignLowVersion1CodeCorrectedCorrectnessLowVersion1Speci\ufb01cationChangedVersion2DesignLowVersion1CodeCorrected                        \f  The array is now cut to length via mstore as in other parts of the code.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.57   Inefficient State Variable Packing",
        "body": "  lastFeeCharge  and  totalWithdrawnAmountsTimestamp  in  ERC20RootVault  are  declared  as uint256.  Both  are  timestamps;  hence,  it  might  be  more  efficient  to  pack  them  as  uint64.  This  only makes sense if they are used and loaded together, which would be possible in the current code base. Similarly, other structs in other contracts can be more storage-efficient by packing variables together.    Both  variables  lastFeeCharge  and  totalWithdrawnAmountsTimestamp  have  been  declared  as uint64 in the updated code.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.58   Misleading Naming of Variables in ",
        "body": " UniV3Oracle  The  function  price  uses  variable  names  that  are  inconsistent  with  the  variable  names  of  Uniswap. Namely,  the  variables  tick0  and  tick1  refer  to  tickCumulative  variables  of  Uniswap  and  not normal ticks.  Similarly,  the  array  pricesX96  temporarily  stores  prices  in  square  root  format  which  are  typically referred to as sqrtPriceX96. These inconsistencies make the reading of the code harder.  Code Corrected:  The variables were renamed accordingly.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.59   Missing Sanity Check in ",
        "body": " MStrategy.createStrategy  In MStrategy.createStrategy any token array could be passed in, but the strategy can only handle two tokens. There is no sanity check to limit the number of tokens. The fee parameter is also not checked even though it could only take a limited range of values.    Mellow Finance - Mellow Vaults -   48  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \fThe sanity check on the tokens array is added in the initialize function which is called when a new strategy  is  created.  The  sanity  check  for  the  fee  parameter  is  performed  when  the  pool  address  is queried:  pool = IUniswapV3Pool(factory.getPool(tokens[0], tokens[1], fee_)); require(address(pool) != address(0), ExceptionsLibrary.ADDRESS_ZERO);  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.60   Missing Sanity Checks for Params",
        "body": "  LStrategy.updateRatioParams  and  LStrategy.updateOtherParams  do  not  perform  sanity checks on all the params.  Code Corrected:  Both functions now perform basic sanity checks for the arguments.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.61   Misspelled Variable Names",
        "body": "  Function  deposit  delayedStaretgyParams.  in  ERC20RootVault  declares  a   variable  with  misspelled  name:  Struct ratioParams in MStrategy declares a variable with misspelled name: tickNeiborhood.    Both variable names have been corrected in the updated code.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.62   Possible Struct Optimization",
        "body": "  Mellow Finance might want to consider to optimize some structs in the code base. E.g., in:  struct TradingParams {     uint256 maxSlippageD;     uint256 minRebalanceWaitTime;      ...  struct RatioParams {     uint256 erc20UniV3CapitalRatioD;     uint256 erc20TokenRatioD;     uint256 minErc20UniV3CapitalRatioDeviationD;     uint256 minErc20TokenRatioDeviationD;     uint256 minUniV3LiquidityRatioDeviationD  Mellow Finance - Mellow Vaults -   49  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \fSome of the variables will not take up a whole word and could be packed if needed.    The examples above and some other structs were changed. We assume that Mellow Finance evaluated all structs if an optimization is suitable and shall be applied.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.63   Rebalance in MStrategy Is Inconsistent",
        "body": "  MStrategy provides only one function for rebalancing (rebalance) which calls _rebalancePools to enforce  the  predetermined  ratio  for  the  pools  (erc20Vault  and  moneyVault)  and  then  calls _rebalanceTokens to enforce the token ratio for the erc20Vault. The latter calls _swapToTarget which, in specific cases, pulls tokens from the moneyVault to the erc20Vault:  if (amountIn > erc20Tvl[tokenInIndex]) {     ...     moneyVault_.pull(address(erc20Vault_), tokens_, tokenAmounts, \"\");     ... }  This  transfer  of  tokens  from  moneyVault  to  the  erc20Vault  would  break  the  balance  set  in  the function _rebalancePools called in the beginning of the rebalance process.    The function rebalance has been updated to perform first the rebalance of tokens in the erc20Vault, which includes any potential swap. Afterwards, the function calls _rebalancePools which enforces the predetermined ratio of TVLs for the erc20Vault and moneyVault.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.64   Specification for minDeviation Not",
        "body": " Enforced  The function rebalanceERC20UniV3Vaults in LStrategy calls the function _liquidityDelta and provides the minimum required deviation for a rebalance to be performed. _liquidityDelta checks the  current  deviation  and  if  it  is  lower  than  the  required  minimum,  it  returns  0.  However,  the  calling function  does  not  check  the  return  value,  hence  continues  the  execution  of  the  function  although  no tokens will be moved.    The  check  below  for  the  return  value  of  the  function  _liquidityDelta  has  been  added.  Now  the function returns immediately if capitalDelta is equal to 0 due to current deviation being smaller than the minimum required deviation:  Mellow Finance - Mellow Vaults -   50  CorrectnessLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                \f(capitalDelta, isNegativeCapitalDelta) = _liquidityDelta(...); if (capitalDelta == 0) {     return (pulledAmounts, false); }  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.65   Storing Redundant Data in Storage",
        "body": "  The function _addUniV3Pools stores two entities in the mapping for each pair of tokens:  poolsIndex[token0][token1] = pool; poolsIndex[token1][token0] = pool;  Given that there is only one Uniswap pool for a pair of tokens and a fee, the tokens can be sorted and stored only once in the mapping: tokenA -> tokenB -> pool, assuming tokenA < tokenB.    The  mapping  poolsIndex  token0 -> token1 -> pool.  now   stores   only   one   entry   for   a   pair   of   tokens  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.66   Unnecessary Approval to Vault Registry",
        "body": "  Function _initialize in Vault has the following line which gives approval to the vault registry, but it is unnecessary as VaultRegistry is the implementation contract of the NFT token:  registry.setApprovalForAll(address(registry), true);    The statement giving the approval has been removed from the function in   .  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.67   Unused Constant in ERC20Validator",
        "body": "  ERC20Validator declares the following constant, but it is not used:  bytes4 public constant EXCHANGE_SELECTOR = 0x3df02124;    Mellow Finance - Mellow Vaults -   51  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedVersion2DesignLowVersion1CodeCorrected                        \fThe constant was removed from the contract.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.68   Unused Event DeployedVault",
        "body": "  The  contract  VaultGovernance  defines  the  event  DeployedVault  but  it  is  not  used  in  the  current code base.    The updated code emits the event DeployedVault when a new vault is created.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.69   Unused Function ",
        "body": " LStrategy._priceX96FromTick  The internal function LStrategy._priceX96FromTick is not used in the LStrategy.    The function was removed from the L Strategy.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.70   Unused Imports",
        "body": "  Throughout the code base we found many unused imports. Due to the number of unused imports, the following list is non-exhaustive and list only examples:  -MellowOracle  import \"@openzeppelin/contracts/utils/structs/EnumerableSet.sol\"  import \"../libraries/CommonLibrary.sol\";   UniV2Oracle  import \"../libraries/ExceptionsLibrary.sol\"   UniV3Oracle  import \"../libraries/ExceptionsLibrary.sol\"   LStrategy  import \"../interfaces/IVaultRegistry.sol\"  import \"../interfaces/utils/IContractMeta.sol\"   MStrategy  import \"@openzeppelin/contracts/token/ERC20/utils/SafeERC20.sol\";   CowswapValidator  Mellow Finance - Mellow Vaults -   52  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \fimport \"../libraries/CommonLibrary.sol\"  import \"../libraries/PermissionIdsLibrary.sol\"   CurveValidator  import \"../libraries/CommonLibrary.sol\"  import \"@openzeppelin/contracts/utils/structs/EnumerableSet.sol\"  import \"../interfaces/validators/IValidator.sol\";   ERC20Validator  import \"../libraries/CommonLibrary.sol\"   UniV2Validator and UniV3Validator  import \"../interfaces/validators/IValidator.sol\";  import \"../libraries/CommonLibrary.sol\"  import \"@openzeppelin/contracts/utils/structs/EnumerableSet.sol\"   AaveVault  import \"../interfaces/vaults/IVault.sol\"   AggregateVault  import \"../interfaces/vaults/IAggregateVault.sol\";  import \"../libraries/PermissionIdsLibrary.sol\"   ERC20RootVault  import \"../interfaces/utils/IContractMeta.sol\"  Code partially corrected:  The  unused  imports  have  been  removed  from  the  respective  contracts  for  all  examples  listed  above, except for the SafeERC20 import in the MStrategy.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.71   Wrong Check of Minimum Token Amounts in ",
        "body": " ERC20RootVault.withdraw  ERC20RootVault.withdraw  compares  the  token  amounts  a  user  wants  to  receive  at  minimum  with the  calculated  token  amounts,  but  not  the  token  amounts  that  are  actually  returned  after  pulling  from underlying Vault s. This could potentially result in the user receiving less tokens than anticipated.    The actual token amounts pulled from vaults are now validated against the minimum amounts provided by the user: `` require(actualTokenAmounts[i] >= minTokenAmounts[i],...);``  Mellow Finance - Mellow Vaults -   53  CorrectnessLowVersion1CodeCorrected          \f6.72   Wrong Specification for YearnVault.tvl  The specification in YearnVault mentions that YearnVault.tvl returns a cached value when in fact it does not.  Specification changed:  The  specification  has  been  updated  in  removed.    and  the  statement  about  the  cached  value  has  been  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.73   ContractRegistry DOS",
        "body": "  ContractRegistry.registerContract  checks  that  the  version  of  a  registered  contract  is  always increasing in:  require(newContractVersion > _latestVersion(newContractName), ExceptionsLibrary.INVARIANT);  If a contract is deployed with a version set to max uint, this would be the last contract possible to add to the system. No contracts could be added afterwards.    Mellow  Finance  introduced  major  and  minor  contract  version.  The  16  right  most  bytes  are  the  minor version and the remaining bytes to the right the major version. A require ensures that with each call to registerContract  with newContractVersionMajor - latestContractVersionMajor <= 1.  increase   version   major   only   can   the   by   1   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.74   ERC20Vault._pull Forces Push of Wrong",
        "body": " Amount of Tokens  In ERC20Vault._pull, if tokens are not pulled to the ERC20RootVault, the receiving Vault is forced to push the received tokens. The token amounts to be pushed are set in actualTokenAmounts, but this variable is never used. Instead tokenAmounts is used.    The  code  has  been  corrected  to  push  into  the  integration  vault  the  amounts  as  stored  in actualTokenAmounts.  Mellow Finance - Mellow Vaults -   54  CorrectnessLowVersion1Speci\ufb01cationChangedVersion3SecurityLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                        \f6.75   IntegrationVault._root Does Not Check the NFT of the Root Vault  IntegrationVault._root  tries  to  verify  the  initialization  of  a  given  Vault  and  its  corresponding ERC20RootVault with the following code:  require(thisNft + thisOwnerNft != 0, ExceptionsLibrary.INIT);  If thisNft is set (greater than 0) and thisOwnerNft equals 0, no revert will happen. _root is called in pull  only.  pull  already  checks  that  the  argument  thisNft  given  to  _root  is  not  equal  to  0  which renders the require useless.    The  statement  was  changed  and  checks  each  variable  separately  (thisNft != 0) && (thisOwnerNft != 0).  if   it   is  zero   in  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.76   VaultGovernance.commitInternalParams",
        "body": "  Does Not Delete Staged Parameters  VaultGovernance.commitInternalParams  does  not  delete  the  _stagedInternalParams  state variable.    The state variable _stagedInternalParams is now deleted after it is applied.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.77   registry.ownerOf Is Called Twice in",
        "body": " IntegrationVault.pull  registry.ownerOf  is  called  twice  with  the  same  value  in  IntegrationVault.pull,  inducing unnecessary additional gas costs.    The obvious redundant call to registry.ownerOf was removed. Still, there would be another call in _isApprovedOrOwner.  Mellow Finance - Mellow Vaults -   55  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                      \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Approximated TVL for Aave Vaults",
        "body": "  The function AaveVault.tvl() computes an approximate total value locked (TVL) based on the time passed  since  the  parameter the  estimatedAaveAPY:  function  updateTvls  was  called  and   time   last   the   uint256 apy = IAaveVaultGovernance(address(_vaultGovernance)).delayedProtocolParams().estimatedAaveAPY; factor = CommonLibrary.DENOMINATOR + FullMath.mulDiv(apy, timeElapsed, CommonLibrary.YEAR);  Note  that  the  parameter  estimatedAaveAPY  is  set  by  the  protocol  admin  for  all  tokens  of  the  vault, hence the function tvl might return incorrect values if updateTvls is not called frequently.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Balances Are Drained Faster in Vaults With",
        "body": " Lower Index  AggregateVault._pull pulls funds out of the underlying Vault's by pulling the maximum amount out of  each  Vault  sequentially.  This  drains  funds  faster  from  Vault's  depending  on  their  index  in  the _subvaultNfts state variable.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Deposits Can Be Blocked by Updating",
        "body": " StrategyParams  The function ERC20RootVaultGovernance.setStrategyParams does not perform any sanity check for the new parameters being set, hence if tokenLimitPerAddress or tokenLimit is set to zero, the functionality to deposit is blocked. The sanity checks are not enforced intentionally as the admin might use these parameters to block deposits into a root vault by updating these parameters.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   Deprecated Function _setupRole",
        "body": "  DefaultAccessControl  and  DefaultAccessControlLateInit  use  the  function  _setupRole, which according to its specification is deprecated:  /**  * NOTE: This function is deprecated in favor of {_grantRole}.  */  Mellow Finance - Mellow Vaults -   56  NoteVersion4NoteVersion1NoteVersion1NoteVersion1              \f7.5   Duplicate Declaration of DENOMINATOR  Both MStrategy and LStrategy import CommonLibrary which declares the constant DENOMINATOR, however, they also declare the constant as well.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.6   Dust LP Shares Are Burned",
        "body": "  If a user decides to redeem its LP shares in a root vault by calling the function withdraw, and if at the time of this action the amount of remaining LP shares represents less than the threshold existentials in underlying tokens, the whole user's LP balance is burned. Put shortly, the function prevents users from leaving dust amounts in LP shares when withdrawing.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.7   External Functions in ContractMeta",
        "body": "  ContractMeta  implements  external  pure  functions,  and  currently  they  are  called  only  by registerContract  in  ContractRegistry.  The  calls  are  performed  as  three  external  calls,  which increase gas costs, as there is no function in ContractMeta returning all values in a single external call.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.8   LP Tokens of the First Deposit Are Burned",
        "body": "  In  to address(0), practically burning them.   of the code base, the LP tokens of the first user depositing into a root vault are always send  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.9   Locked Token or ETH",
        "body": "  ERC20 tokens could be accidentally/intentionally sent to any contract. In such cases the tokens will be locked. Only externalCall for intergration vaults offers some functionality to recover funds.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.10   No Checks for Address to on ERC20Token",
        "body": " Transfer  The functions transfer and transferFrom in ERC20Token do not perform any sanity check for the address to, hence making it possible to burn tokens by sending them to address 0x0.  Mellow Finance - Mellow Vaults -   57  NoteVersion1NoteVersion6NoteVersion1NoteVersion6Version6NoteVersion1NoteVersion1                          \f7.11   Non Canonical Signatures  function   IntegrationVault.isValidSignature   The  function CommonLibrary.recoverSigner to validate signatures if the strategy is an externally owned account. Note  that,  the  function  recoverSigner  does  not  perform  any  sanity  check  on  values  r,  s  and  v  to ensure  that  only  unique  signatures  validate  successfully.  Therefore,  callers  of  this  function  should  be aware of possible attacks (https://swcregistry.io/docs/SWC-117).  library   uses   the   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.12   Non-indexed Event Topics",
        "body": "  Some  events  have  already  hit  in UnitPricesGovernance have not and do not index the token address. Given that the unit price update could be important to users, making the token address indexed, makes it easier to filter the events for specific tokens.  topics.  But   the  events   limit  of   indexed   three   the   There are some other events like DeployedVault in VaultGovernance, ReclaimTokens and Pull in  IntegrationVault  and  RebalancedUniV3  in  LStrategy  where  one  more  index  could  be  set. Additionally,  some  events  could  emit  the  nft  which  might  be  worth  indexing  (it  e.g.,  is  done  in SetStrategyParams). This is just noted and up to Mellow Finance to decide.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.13   OracleParams in MStrategy",
        "body": "  Te  admin  of  MStrategy  should  carefully  set  the  OracleParams.  The  admin  should  ensure  that  the Uniswap used for the oracle has enough observations to cover oracleObservationDelta, otherwise the  function  _getAverageTickChecked  called  in  _rebalanceTokens  will  only  use  the  spot  price, hence  making  the  rebalance  function  vulnerable  to  sandwich  attacks.  Additionally,  the  parameter maxTickDeviation should be carefully chosen to enforce proper slippage protection for the rebalance.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.14   Performance Fee Capped",
        "body": "  ERC20RootVault._chargePerformanceFees only charges performance fees for the strategy if the price of LP tokens has reached a new high score. When prices have fallen, the fees are still not charged even when prices climb again until this all-time high has been reached again.  Additionally, if all liquidity providers withdraw their funds and the totalSupply is zero, or all token TVLs are  less  than  _pullExistentials,  the  previous  high  score  lpPriceHighWaterMarkD18  is  not reset, hence performance fees might not be collected as expected.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.15   Rebalance of Uniswap Vaults in LStrategy",
        "body": "  The  function  rebalanceUniV3Vaults  maintains  a  ratio  of  tokens  in  the  two  Uniswap  positions depending  on  the  move  of  the  current  price.  If  the  price  goes  up,  more  tokens  are  transferred  into  the upperVault from the lowerVault, and vice-versa. The function is designed in a way that it tries to add  Mellow Finance - Mellow Vaults -   58  NoteVersion4NoteVersion1NoteVersion5NoteVersion5NoteVersion4                  \fthe same liquidity amount into the destination vault that is removed from the other vault. However, since the two vaults operate in different price ranges, the same liquidity amount translates into different token amounts.  The  token  in  the  cash  position  (erc20Vault)  are  used  to  cover  for  the  difference. Consequently  the  ratio  between  the  cash  position  (erc20Vault)  and  the  money  vaults  (lowerVault and upperVault) is affected.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.16   Rollback Individual Validators Not Possible",
        "body": "  ProtocolGovernance  implements  a  function  to  rollback  all  staged  validators,  but  there  is  no functionality to rollback individual staged validators.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.17   Special Behavior in ERC20Token",
        "body": "  The function transferFrom has a special behavior when allowance==type(uint256).max, as the allowance  is  never  reduced  when  these  transfers  occur.  This  special  behavior  should  be  properly documented as users should be aware of it.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.18   Trust Setup",
        "body": "  The  system  has  multiple  trusted  roles  and  heavily  relies  on  admin  operations  to  work.  E.g.,  setting oracles and the admin needs to maintain enough funds to open new Uniswap positions.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.19   Uneven Gas Distribution on deposit and",
        "body": " withdraw  Fees are not calculated on every transaction. Therefore, some users are burdened with more gas costs than others depending on the time they are performing their withdraw and deposit actions.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.20   Unit Prices Amounts",
        "body": "  The admin in UnitPricesGovernance can set the amounts of a given token that match the value of 1 USD. The prices are set with a delay of 14 days, hence the prices are not supposed to reflect the market price. Note that, for valuable tokens with few decimals, it might be impossible to store the correct token amount that matches 1 USD.  Mellow Finance - Mellow Vaults -   59  NoteVersion1NoteVersion1NoteVersion1NoteVersion1NoteVersion5                      \f7.21   Unnecessary Creation of Pair  In  UniV3Vault._push  and  UniV3Vault._pullUniV3Nft,  a  Pair  is  created  and  not  used  as  a Pair afterwards. Instead, the particular values are extracted from the Pair, rendering the creation of the Pair useless.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.22   ContractRegistry Functions Truncate",
        "body": " name  Functions  versions,  versionAddress  and  latestVersion  in  ContractRegistry  truncate  the input parameter name_ to 32 bytes:  bytes32 name = bytes32(bytes(name_));  If these functions are called with name_ longer than 32 bytes, the return value would be based on the truncated input parameter name_, which is inconsistent behavior.  Furthermore,  the  function  latestVersion  parses  the  input  parameter  name_  differently  from  other functions:  bytes32 name = bytes32(abi.encodePacked(name_));  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.23   LStrategy Needs Tokens to Create Uniswap",
        "body": " Positions  The  function  _mintNewNft  assumes  that  the  strategy  contract  has  enough  balance  to  open  new Uniswap positions as needed, otherwise new Uniswap NFTs cannot be minted:  IERC20(tokens[0]).safeApprove(address(positionManager), minToken0ForOpening); IERC20(tokens[1]).safeApprove(address(positionManager), minToken1ForOpening); (newNft, , , ) = positionManager.mint(     INonfungiblePositionManager.MintParams({         token0: tokens[0],         token1: tokens[1],         fee: poolFee,         tickLower: lowerTick,         tickUpper: upperTick,         amount0Desired: minToken0ForOpening, // required balance         amount1Desired: minToken1ForOpening, // required balance         amount0Min: 0,         amount1Min: 0,         recipient: address(this),         deadline: deadline     }) );  Mellow Finance - Mellow Vaults -   60  NoteVersion1NoteVersion1NoteVersion1          \fMellow  Finance  is  aware  of  this  requirement  and  states  they  will  take  care  that  enough  funds  are available at any point in time. Additionally, a check was added to ensure that the amount of token needed in the contract is very low (less than 10**9) to mitigate that money is lost because of the deactivated slippage protection in the function above.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.24   _pullExistentials Are Unevenly",
        "body": " Distributed in Terms of Value  _pullExistentials  in  AggregateVault  are  set  to  10**(token.decimals()  /  2)  for  each token. This is an uneven distribution considering that tokens may have different value. The existential for USDT for example has a much lower value than the existential for WBTC.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.25   addressesByPermission Does Not",
        "body": " Consider Forced Permissions  The  function  addressesByPermission  in  the  protocol  governance  contract  returns  only  addresses that  explicitly  have  the  permissionId  in  the  mapping  permissionMasks.  However,  if  the permissionId  is  enforced  by  forceAllowMask,  then  all  addresses  are  assumed  to  have  the permission.  Mellow Finance - Mellow Vaults -   61  NoteVersion1NoteVersion1        \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Effects of Snapshotting at Every Block",
        "body": "  The HoprToken performs a state snapshot at every block. That has the following effects:  1. Significant extra gas costs for a token transfer compared to regular token implementations. Even if none  of  the  callbacks  are  executed,  there  is  an  expected  overhead  of  69,400  gas  compared  to  a regular ERC-20 token and 62,600 compared to a regular ERC-777 token.  Some addresses, e.g. HoprDistributor or exchange addresses will amass a considerable number of snapshots. This has two additional effects:  2. The overall contracts state size will be rather big. In case that ETH2.0 transitions to stateless clients,  state proofs will be relatively large for all Hopr balances.  3. The  gas  cost  of  calling  balanceOfAt  for  these  contracts  with  many  snapshots  will  continue  to grow.  However,  as  it  only  grows  logarithmically  it  will  foreseeably  not  reach  a  critical  level.  The impact  of  this  is  also  determined  by  whether  balanceOfAt  is  primarily  intended  for  on-chain  or off-chain use.  Risk accepted:  Hoprnet replied:  Due to our approach with our upcoming DAO contract, we require a snapshot on every block.  Hoprnet - Hoprnet Token -   7  SecurityDesignCorrectnessCriticalHighMediumLowRiskAcceptedDesignLowVersion1RiskAccepted             \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings   Burn Function of HoprToken Can Cause Inconsistent Snapshot    Wrong Check in the HoprDistributor claim Function   -Severity Findings   Miners Can Claim With Schedule Violation   -Severity Findings   Multiple Storage Writes    Redundant Condition Check in _valueAt    Snapshot Inefficiency    Superfluous Call to _beforeTokenTransfer    Timestamp Conversion Has Redundant Operation   0  2  1  5  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Burn Function of HoprToken Can Cause",
        "body": " Inconsistent Snapshot  interface   The  ERC777  has  a  _beforeTokenTransfer  hook  that  is  called  in  the  burn,  transfer  and  mint functions. Also it introduced _callTokensToSend and _callTokensReceived functions that can call the  registry.  ERC777Snapshot  utilizes _beforeTokenTransfer  to  track  the  snapshots  after  each  balance  change.  Due  to  the  order  of _beforeTokenTransfer  and  _callTokensReceived  functions  in  the  _burn  function,  there  is  a possibility of reentrancy, that can cause the snapshots to be in an inconsistent state.  implementations   in  ERC1820   registered   function _burn(     address from,     uint256 amount,     bytes memory data,     bytes memory operatorData )     internal virtual {     require(from != address(0), \"ERC777: burn from the zero address\");      address operator = _msgSender();      _beforeTokenTransfer(operator, from, address(0), amount);  Hoprnet - Hoprnet Token -   8  CriticalHighCodeCorrectedCodeCorrectedMediumCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCorrectnessHighVersion1CodeCorrected        \f    _callTokensToSend(operator, from, address(0), amount, data, operatorData);      // Update state variables     _balances[from] = _balances[from].sub(amount, \"ERC777: burn amount exceeds balance\");     _totalSupply = _totalSupply.sub(amount);      emit Burned(operator, from, amount, data, operatorData);     emit Transfer(from, address(0), amount); }  function _beforeTokenTransfer(address operator, address from, address to, uint256 amount) internal virtual override {     super._beforeTokenTransfer(operator, from, to, amount);      if (from == address(0)) {         // mint         updateValueAtNow(accountSnapshots[to], balanceOf(to).add(amount));         updateValueAtNow(totalSupplySnapshots, totalSupply().add(amount));     } else if (to == address(0)) {         // burn         updateValueAtNow(accountSnapshots[from], balanceOf(from).sub(amount));         updateValueAtNow(totalSupplySnapshots, totalSupply().sub(amount));     } else if (from != to) {         // transfer         updateValueAtNow(accountSnapshots[from], balanceOf(from).sub(amount));         updateValueAtNow(accountSnapshots[to], balanceOf(to).add(amount));     } }  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1.1   Attack scenario",
        "body": " Attacker  can  register  a  IERC777Sender  smart  contract  in  the  ERC1820  registry  that  will  transfer  Hopr Tokens  to  the  attacker.  When  this  transfer  happens  in  the  _callTokensToSend  from  ERC1820 registered implementation, the snapshot will be overwritten again, using balanceOf value, that has not been yet updated.  In a trace example above, with green color marked balance updates and with yellow - snapshot updates. Due to dependency of snapshot updates depend on balance updates, the reentrancy issue arise. In the other  ERC777  functions,  such  as  the  transfer  function,  where  the  _callTokensToSend  goes  before any state updates, such a problem does not arise. To avoid the issue, the newly released OpenZeppelin contracts should be used.    Hoprnet - Hoprnet Token -   9  \fThe  HoprToken  now  uses  an  OpenZeppelin  ERC777  implementation  that  does  not  have  a  reentrancy vulnerability in its burn function. The snapshot is now updated after the external call.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Wrong Check in the HoprDistributor claim",
        "body": " Function  The  claim  function  of  the  HoprDistributor  calls  internal  _claim  function  that  contains  following code:  uint128 newClaimed = _addUint128(allocation.claimed, claimable); // Trying to claim more than allocated assert(claimable <= newClaimed);  This  assertion  can  only  be  violated  if  the  _addUint128  operation  overflows.  But  check  of  overflow  is already  present  the newClaimed  <=  allocation.amount.  The  comment  above  the  assertion  also  describes  the intention.  the  _addUint128.   there  are  no   In  addition,   checks   for   in     The assertion was rewritten. The new assertion checks that the value of newClaimed does not exceed the total allocated amount.  assert(newClaimed <= allocation.amount);  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Miners Can Claim With Schedule Violation",
        "body": "  The  claim  function  calls  the  _getClaimable  function  to  determine  the  amount  users  can  claim depending on the elapsed periods.  for (uint256 i = 0; i < schedule.durations.length; i++) {     uint128 scheduleDeadline = _addUint128(startTime, schedule.durations[i]);      // schedule deadline not passed, exiting     if (scheduleDeadline > _currentBlockTimestamp()) break;     // already claimed during this period, skipping     if (allocation.lastClaim > scheduleDeadline) continue;      claimable = _addUint128(claimable, _divUint128(_mulUint128(allocation.amount, schedule.percents[i]), MULTIPLIER)); }  At the end of claim execution, the allocation.lastClaim is reassigned, to disable repetitive claims for the same period of the schedule.  allocation.lastClaim = _currentBlockTimestamp();  But  if  multiple  claims  will  be  send  with  block.timestamp  equal  to  scheduleDeadline  of  some schedule  period,  multiple  repetitive  claims  of  this  blocks  will  be  possible.  This  will  effectively  allow  the hackers to ignore the schedule. While this operation is hard to time right using regular transaction, miners can craft such transactions.  Hoprnet - Hoprnet Token -   10  SecurityHighVersion1CodeCorrectedSecurityMediumVersion1CodeCorrected                \fCombined with nonexistent allocation.amount <= newClaimed check in claim function, this bug also allows to claim more than the allocated amount.    The condition in the loop was rewritten. Now the equality case will be skipped and repetitive claims for the same periods of the schedule are not possible.  if (allocation.lastClaim >= scheduleDeadline) continue;  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Multiple Storage Writes",
        "body": "  The  addAllocations  function  repeatedly  writes  to  and  reads  from  the  totalToBeMinted  storage variable. This incurs additional gas costs. Note, however, that the additional gas costs will be significantly lowered by the upcoming EIP-2929.    A new variable _totalToBeMinted was introduced. All repetitive operations are performed on it. Thus, gas is saved.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Redundant Condition Check in _valueAt",
        "body": "  The  functions  balanceOfAt  and  totalSupplyAt  of  the  HoprToken  have  following  branching conditions:  if (     (accountSnapshots[_owner].length == 0) ||     (accountSnapshots[_owner][0].fromBlock > _blockNumber) ) {  if (     (totalSupplySnapshots.length == 0) ||     (totalSupplySnapshots[0].fromBlock > _blockNumber) ) {  In addition, both of these public functions rely on internal _valueAt function. Meanwhile the _valueAt has following branching conditions:  if (snapshots.length == 0) return 0;  if (_block < snapshots[0].fromBlock) {  Those conditions are redundant and will never be triggered.  Hoprnet - Hoprnet Token -   11  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \f  The checks are now performed only inside the _valueAt function.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Snapshot Inefficiency",
        "body": "  Hoprnet implemented the following binary search:  // Binary search of the value in the array     uint256 min = 0;     uint256 max = snapshots.length - 1;     while (max > min) {         uint256 mid = (max + min + 1) / 2;         if (snapshots[mid].fromBlock <= _block) {             min = mid;         } else {             max = mid - 1;         }     }     return snapshots[min].value;  In  case  the  _block  number  matches  the  block  number  of  one  of  the  snapshots,  the  implementation could be optimized. The equality case:  snapshots[mid].fromBlock == _block  is not handled explicitly. Given that in this case, the result has already been found, there is no need for further unnecessary iterations.  Code Corrected:  The code was adjusted and now explicitly checks for equality:  uint256 midSnapshotFrom = snapshots[mid].fromBlock; if (midSnapshotFrom == _block) {     return snapshots[mid].value;  Hence, the inefficiency is gone.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Superfluous Call to _beforeTokenTransfer",
        "body": "  When  overriding  the  empty  parent  function  _beforeTokenTransfer  from  the  ERC777  template, super._beforeTokenTransfer  gets  called.  This  call  has  no  effect  as  the  parent  is  empty.  Due  to current  state  of  Solidity  compiler,  this  call  will  create  unnecessary  operations  with  no  effects.  Small amount of gas (+-30) will be wasted.    Hoprnet - Hoprnet Token -   12  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \fThe superfluous call to the super class was removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   Timestamp Conversion Has Redundant",
        "body": " Operation  Function  _currentBlockTimestamp  has  a  modulo  operation  that  can  be  dropped.  The  default behavior of solidity uint128(X) conversion achieves the same result and uses less gas.  function _currentBlockTimestamp() internal view returns (uint128) {     // solhint-disable-next-line     return uint128(block.timestamp % 2 ** 128); }    The superfluous modulo operation was removed.  Hoprnet - Hoprnet Token -   13  DesignLowVersion1CodeCorrected        \f7   Notes  We leverage this section to highlight potential pitfalls which are fairly common when working Distributed Ledger Technologies. As such technologies are still rather novel not all developers might yet be aware of these  pitfalls.  Hence,  the  mentioned  topics  serve  to  clarify  or  support  the  report,  but  do  not  require  a modification  inside  the  project.  Instead,  they  should  raise  awareness  in  order  to  improve  the  overall understanding for users and developers.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   ERC-20 Approve Race Condition",
        "body": "  The ERC-20 standard has a well-known race condition for the approve function if both the new and the implementations  add  increaseApproval  and old  approval  are  non-zero.  Hence,  a  decreaseApproval  functions  which  do  not  have  this  issue.  The  Hopr  Token  does  not  have  such functions. Hence, it is up to users and using smart contracts to avoid the issue.  lot   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Floating Pragma",
        "body": "  The solc version is fixed in the hardhat configuration to version 0.6.6. However, the files have a floating pragma.  Furthermore, please note the chosen compiler version 0.6.6 has five known bugs.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Ownership Cannot Be Atomically Transferred",
        "body": "  The specification says:  allow admin to transfer or revoke their ownership  There is no classical role transfer function inside the contract. The admin can add a new admin and later revoke itself, but not perform an atomic role transfer.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   Schedules Are Specified Using UTF-8 Strings",
        "body": "  The distribution schedules are addressed using UTF-8 strings. UTF-8 strings have well-known security implications, such as characters that look identical to humans, but have a different byte representation or inverse character order. Hence, calls like addAllocations could theoretically be referencing a different schedule than expected.  However, as all of the functions setting up allocations can only be executed by the administrators, there is fairly low risk.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   Theoretical Overflow in Binary Search",
        "body": "  Hoprnet - Hoprnet Token -   14  NoteVersion1NoteVersion1NoteVersion1NoteVersion1NoteVersion1                  \fIn theory the binary search can overflow. This would affect the following computation:  uint mid = (max + min + 1) / 2;  This  could  occur  as  soon  as  snapshots.length  would  be  larger  than  2**255.  As  this  implies  that 2**255 snapshots have been taken, which implies that 2**255 blocks have passed, it is irrelevant in practice.  Hoprnet - Hoprnet Token -   15  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Redundant While-loop",
        "body": "  curveLiquidityAdapter.__parseSpendAssetsForLendingCalls  aims  to  detect  the  spent assets  and  the  amounts  of  them  so  that  they  can  be  post-processed  by  the  Integration  Manager.  It includes the following while-loop which should always terminate after one iteration.  while (spendAssetsIndex < spendAssetsCount) {     for (uint256 i; i < _orderedOutgoingAssetAmounts.length; i++) {         if (_orderedOutgoingAssetAmounts[i] > 0) {             spendAssets_[spendAssetsIndex] = __castWrappedIfNativeAsset(                 canonicalPoolAssets[i]             );             spendAssetAmounts_[spendAssetsIndex] = _orderedOutgoingAssetAmounts[i];             spendAssetsIndex++;         }     } }  Notice  that  spendAssetsIndex  increases  to  the  maximum  value  of  spendAssetCount  inside  the for-loop.    The  while-loop  been  spendAssetsIndex == spendAssetsCount was added.  removed  while   has   an   early   exit   of   the   for-loop  when  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Unstaking sOHM Leaves Dust",
        "body": "  Avantgarde Finance - Sulu Extensions -   11  CriticalHighMediumLowCodeCorrectedCodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \fsOHM is a rebasing token, meaning that the number of tokens a vault has increases after each epoch. Sulu currently allows managers to define the number of sOHM tokens they want to unstake. Consider the following case:   A fund manager M wants to unstake all the sOHM the fund holds   The fund manager submits a transaction where they unstake the total amount of the tokens   A rebase happens and the number of sOHM increases   The transaction is mined.  This will lead to the fund holding a dusty amount of sOHM together with the unstaked OHM tokens.    The code has been adapted to support unstaking the maximum amount when uint.max is specified as the unstake amount.  Avantgarde Finance - Sulu Extensions -   12  \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Rewards in Different Gauge Version",
        "body": "  CurveLiquidityAdapter is implemented in such a way so that it is compatible with version 2, 3 and 4 of  the  gauge  tokens.  When  claim_rewards  for  the  gauge  tokens  v2  and  v3,  rewards  are  accrued. However,  this  is  not  true  for  v4  where  users  should  pass  a  specific  argument  for  the  rewards  to  be accrued.  Avantgarde Finance - Sulu Extensions -   13  NoteVersion1  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Compound Rate normalizeAmount",
        "body": "  The normalizeAmount returns values that are greater or equal to target * decimals / rate, but still denormalizes to the same target value. For example, target 3, rate 123 and decimals 1000 yields 25. The true value, if computed in the domain of real numbers, would be 24.39. Thus, it can be expressed, for  some  cases.  Also, that  normalizeAmount(300)  deposits  of normalizeAmount(3)  ==  25.  This  has  that  depend  on CoumpoundRateKeeper.  is  few  effects  on   the  normalizeAmount  performs   than  the  systems,   rounding  up  of   the  smaller   2440  which   result   100   ==    Saving  _checkBalance  function  calls  can  fail  and  system  will  be  rendered  unusable.  This  can happen during the normal operation of the system. Saving contract users won't be able to deposit and withdraw funds from the contract. The rounding can effectively cause Denial of Service failure on this contract.   QVault _checkBalanceInvariant can fail for the same reason and render contract DoSed.   Saving contract can have not enough tokens to cover the deposits. Since all deposits are stored as normalized values and rounded up, all users get more tokens than they can claim from the system.   Saving contract rewards users with smaller deposits   BorrowingCore penalized the users, by rounding up their debt.   The BorrowingCore will collect more fees but users also will get less liquidation coins if fee is high  enough to cover both.  In addition, the update is done via a loop, that is not executed more than once, while according to fuzzing tests it never runs more than once for the domain of numbers that contract should work with.  Code partially corrected:  Q Blockchain - System contracts -   10  SecurityDesignCorrectnessTrustCriticalHighMediumLowCodePartiallyCorrectedDesignLowVersion1CodePartiallyCorrected            \fThe  ineffective  loop  was  removed  in  favor  of  simple  if  condition.  On  repetitive  deposit  to  the  same address  on  the  QVault  the  user  balance  loses  some  small  values  due  to  division  with  truncation  in denormalization  function.  This  loss  should  in  most  cases  compensate  the  gain  from  the  rounding  up. Overall all mentioned problems can be mitigated by some extra funds deposits. BorrowingCore behavior also while penalizing certain parties by tiny amounts, rewards the system health.  Q Blockchain - System contracts -   11    \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  0  3  6  16  -Severity Findings  -Severity Findings  Inconsistent extendLocking Allows Multiple Votes    Multiple Votes by Delegation    Owner Not Initialized   -Severity Findings   Expired Slashing Proposals Are Not Purged    FxPriceFeed setExchangeRate Timestamp    Gas Heavy Operation on Foreign Chain   Inconsistent Liquidation Full Debt Due to Payback    Price Decimals and Token Decimals May Differ    ValidationRewardPools _updateCompoundRate   -Severity Findings   ASlashingEscrow Decision Reordering    Compiler Version Not Fixed and Outdated    ContractRegistry Erasing Key    Corruptible AddressStorageStakesSorted    FxPriceFeed Can Have No Maintainers    GSN Version String   Inconsistent Liquidation Full Debt Due to Outdated Debt   Inconsistent System Debt Auction Start Condition   Inefficient Code    Long pendingSlashingProposals Attack    QVault updateCompoundRate Precision Loss    Solc Pragma    Specification Mismatch    SystemSurplusAuction Bid Reentrancy    ValidationRewardProxy Allocate Potential Overflow    Validators Can Alter Delegator Share   Q Blockchain - System contracts -   12  CriticalHighCodeCorrectedCodeCorrectedCodeCorrectedMediumCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrected       \f6.1   Inconsistent extendLocking Allows Multiple Votes  VotingWeightProxy.extendLocking only assigns _lockNeededUntil to lockedUntil[_who]. To  be  consistent,  it  should  be  the  max  between  the  new  and  the  old  value.  Otherwise  the  user  can manipulate the unlock times by voting on a proposal with smaller end time. In addition, the manipulation with unlock times enables user to transfer out the funds earlier and perform the attacks similar to on in Multiple Votes by Delegation, where users tokens can be reused to contribute to the same vote multiple times.    VotingWeightProxy.extendLocking now yields the max value between _lockNeededUntil and lockedUntil[_who].  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Multiple Votes by Delegation",
        "body": "  Upon  VotingWeightproxy.announceUnlock  and  VotingWeightproxy.unlock,  no  check  is done to verify that the voting agent is not currently locking the delegated amount. This enables an attack where it is possible to vote multiple times with the same Q.  Here is the attack scenario: A    and V   i  i   are accounts controlled by attacker.   : QVault.lock(X)  1. A  i 2. A   3. V  i 4. A   (no lock)    :  VWP.announceNewVotingAgent(V1)  and  VWP.setNewVotingAgent,  can  do  it  in  one  go i  because getLockeduntil will return 0 since A    did not vote  i   : vote on proposal, gets a lock on its own lockInfo   : QVault.announceUnlock(X) and QVault.unlock(X), can do it in one go since A  i   did not vote  i  5. A  i   : Qvault.transfer(A   , X)  i+1  6. goto 1. with i = i+1  Code corrected :  Lock time is now tracked only once per user, previously it was once per locking contract and per user. Now both announceUnlock and unlock now take into account the max time between user's own time lock and its voting agent's time lock, this mitigates the attack described above.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Owner Not Initialized",
        "body": "  Some  contracts  inherit  Ownable  and  Initializable,  but  do  not  assign  the  owner  in  the  initialize function. If such contracts are deployed as a proxy, the owner field will be uninitialized (stays address 0) and owner functionality would be unusable.  Q Blockchain - System contracts -   13  CorrectnessHighVersion2CodeCorrectedDesignHighVersion1CodeCorrectedDesignHighVersion1CodeCorrected                      \f GSNPaymaster  inherits  Initializable  and  BasePaymaster.  BasePaymaster  inherits  Ownable. Function initialize of the GSNPaymaster only assigns value to stc field. The relayHub field can only be set by owner.   ForeignChainTokenBridgeAdminProxy does not set owner in initialize.   TokenBridgeAdminProxy  is  Initializable  and  Ownable.  Owner  is  not  initialized.  Also,  the  Ownable  functionality is not used anywhere.   ExpertsMembership does not initialize owner. Also, the Ownable functionality is not used anywhere.    Q Blockchain has done following fixes for the issues:   Function  initialize  was  removed  from  GSNPaymaster.  The  logic  from  it  was  moved  to  the  constructor.   Now the contract extends OwnableUpgradeable contract of openzeppelin library. The initialize  functions calls _Ownable_init, that sets the owner.   Now the contract extends OwnableUpgradeable contract of openzeppelin library. The initialize  functions calls _Ownable_init, that sets the owner.   Now the contract extends OwnableUpgradeable contract of openzeppelin library. The initialize  functions calls _Ownable_init, that sets the owner.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Expired Slashing Proposals Are Not Purged",
        "body": "  When  purgePendingSlashings  is  called  (Validators  and  Roots),  only  proposals  with  state REJECTED  or  EXECUTED  are  deleted.  The  proposals  with  state  EXPIRED  are  kept  the pendingSlashingProposals  list  and  their  slashing  amount  is  always  kept  into  account  when calculating the pending slashing amount. Thus, preventing the Roots and Validators to withdraw this amount that they should be able to withdraw, locking it forever.  in   Code corrected :  RootNodesSlashingVoting  and  ValidatorsSlashingVoting  now  define  slashingAffectsWithdrawal functions. The slashingAffectsWithdrawal function includes a check that slashing proposal is not in EXPIRED state.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   FxPriceFeed setExchangeRate Timestamp",
        "body": "  The  exchange  rate  on  FxPriceFeed  is  set  by  setExchangeRate  function  and  recorded  timestamp  is taken from the block. Since the transactions can be delayed and reordered or put to the chain earlier than needed,  the  rate  can  be  outdated  by  the  time  the  block  is  mined.  The  recorded  timestamp  can  give unreliable information about the rate status. Some approaches, like Maker price oracles, ensure that new price  values  propagated  from  the  Oracles  are  not  taken  up  by  the  system  until  a  specified  delay  has passed.  Q Blockchain - System contracts -   14  DesignMediumVersion1CodeCorrectedDesignMediumVersion1CodeCorrected                \f  Field pricingTime was added to the FxPriceFeed contract.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Gas Heavy Operation on Foreign Chain",
        "body": "  ForeignChainTokenBridgeAdminProxy is supposed to be deployed on the Ethereum mainnet, thus its  gas  consumption  is  critical.  The  current  complexity  of  the  updateTokenbridgeValidators  is actually O(m*n), where m is length of old list and n is length of new list. Complexity can be reduced to O(m+n)  if  all  old  values  in  list  were  replaced  by  new  list  values.  Also,  the  number  of  calls  to  other contracts should be minimized. Currently, a lot of calls to bridgeValidators contract are done.  Specification corrected:  Q  Blockchain  wants  to  use  IBridgeValidators  interface  implementation  as  it  is  without  any modifications,  since  it  allows  them  easier  integration  with  existing  tokenbridge  code.  With  this requirement, current solution is sufficient. In addition, the O(m*n) complexity loop is done to lower the number  of  calls  between  ForeignChainTokenBridgeAdminProxy  and  IBridgeValidators contracts. According to Q Blockchain tests, this lowers the overall gas consumption.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Inconsistent Liquidation Full Debt Due to",
        "body": " Payback  Owner  of  the  Vault  that  is  being  liquidated  can  call  payBackStc  and  repay  STC  after  the  liquidation process has started. This can lead to potential problematic scenario:  Collateralization ratio = 150% Liquidation ratio = 125% Liquidation fee = 2%  1. Vault owner has for 150 worth of collateral and 100 worth of STC.  2. Collateral value drops to 120, liquidation is opened with liquidationFullDebt = 100. At that  point the fee should be 2. Highest bid is 105.  3. Vault  owner  pays  back  some  its  debt  over  liquidation  ratio,  so  now  the  vault  has  for  120  worth  of collateral  and  88  worth  of  STC.  Vault  owner  cannot  call  liquidate  because  the  liquidation  ratio does not allow this.  4. Liquidation  is  executed,  liquidationFullDebt  is  still  100  but  should  be  88  by  now.  After liquidation, liquidator got his 120 worth of collateral token, system had its fee of 2 and user only got 105 - (100 + 2) = 3. So, in the end vault owner has lost more STC than what he should have with the liquidation.  System  would  also  burn  more  STC  the liquidationFullDebt that should have changed due to payback.  than  needed,  compensating   token   Code corrected :  A modifier has been added to prohibit debt payback when vault is being liquidated.  Q Blockchain - System contracts -   15  DesignMediumVersion1Speci\ufb01cationChangedCorrectnessMediumVersion1CodeCorrected                  \f6.8   Price Decimals and Token Decimals May Differ  When computing the collateralization ratio in BorrowingCore the formula uses the price from the oracle along with the decimals of the collateral. It is an issue because there is no guarantee that the oracle price will  have  the  same  decimals  as  the  associated  collateral.  The  decimalPlaces  of  the  FxPriceFeed should be used instead.    Instead  of  using  getDecimals,  Q  Blockchain  uses  decimalPlaces  in  BorrowingCore  in  functions _getColRatio and getVaultStats.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   ValidationRewardPools ",
        "body": " _updateCompoundRate  In attempt to improve the precision, the _updateCompoundRate tries to update the compound rate of rate  keeper  with  balance  -  reservedForClaim  -  1  tokens.  Then, the  validator  denormalize(newRate,  stake)  -  denormalize(oldRate,  stake)  +  1  tokens  are  be  used to increase the reservedForClaim variable.  Assume  following  starting  point  of  the  system:  oldRate  ==  1  stake  ==  200  balance  ==  400 reservedForClaim == 0  to   integer  division   The  _updateCompoundRate  will  update  the  compound  rate  keeper  with  400-0-1  ==  399  amount. Due  for reservedForClaim will be 400-200+1==201. But the stakers would be able to get only 200 tokens out from this update. This 1 token difference will not be claimable by anyone and such discrepancies will be slowly accumulating the ValidationRewardPools system.  the  newRate  will  be  2.  New  value   truncation  of   the  result,   If compound rate was updated with balance - reservedForClaim == 400 tokens, newRate would be  3  and  denormalize(newRate,  stake)  -  denormalize(oldRate,  stake)==400  could have been distributed. reservedForClaim would have become 400 too.  If balance where == 200, the balance - reservedForClaim - 1 would be 199, that is not enough to increase the rate. Meanwhile the solution without the -1 would have increased the rate by 1.  To  conclude,  the  balance  -  reservedForClaim  -  1  _updateCompoundRate  algorithm  slowly accumulates  the  errors  and  delays  in  some  cases  the  distribution  of  the  tokens.  With  time  the accumulated errors can drive the denormalized stake and reservedForClaim values more apart and can prevent the payout of the rewards, since the reservedForClaim values will be greater than they should have been, if computation were done in the domain of real numbers.    sub(1)   add(1)   method The  reserveAdditionalFunds(address  _validator)  that  increases  the  validators  balance  and reservedForClaims  fields  by  the  transferred  value  was  added.  It  allows  to  compensate  for  rounding  up errors if they occur. Since the accumulation error speed is not higher then number of delegators * number of updates 1 extra Q token with 18 decimals should compensate error for quite awhile.  approach   dropped.   Payable   was   Q Blockchain - System contracts -   16  DesignMediumVersion1CodeCorrectedDesignMediumVersion1CodeCorrected              \f6.10   ASlashingEscrow Decision Reordering  The  proposeDecision  and  recallProposedDecision  can  be  called  numerous  times  on ASlashingEscrow.  Roots  that  want  to  confirmDecision  cannot  be  sure  what  decision  they  are confirming  and condition  recallProposedDecision/proposeDecision.  Since  the  order  of  those  transactions  can  vary, pending decision might be changed by the time confirmation arrives.  confirmDecision   between   race   due   the   to     The  confirmDecision  function  takes  extra  decision  hash  argument,  that  solves  the  problem  with reordering.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.11   Compiler Version Not Fixed and Outdated",
        "body": "  The  solidity  compiler  truffle-config.js to be 0.7.6.  is  not   fixed   in   the  code.  The  version,  however,   is  defined   in   the  In the code the following pragma directives are used:  pragma solidity ^0.7.0;  Known bugs in version 0.7.6 are:  https://github.com/ethereum/solidity/blob/develop/docs/bugs_by_version.json#L1509  More information about these bugs can be found here:  https://docs.soliditylang.org/en/latest/bugs.html  At the time of writing the most recent Solidity release is version 0.8.7 which contains some bugfixes.  Code correct :  Solidity compiler version has been fixed to 0.7.6 in every file, this this the last version before breaking changes of version 0.8.0.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.12   ContractRegistry Erasing Key",
        "body": "  Any given string key for address cannot be purged from ContractRegistry. Function contains always checks that address != 0. But _setAddress function does not allow address to be 0. Thus, unused key address  will  always  be  contained  by  this  contract.  There  is  no  dedicated  function  for  purging  the addresses. In addition, keys are pushed to the storage keys array, but never can be deleted.    Q Blockchain - System contracts -   17  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \fFunctions removeKey and removeKeys were added.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.13   Corruptible AddressStorageStakesSorted",
        "body": "  AddressStorageStakesSorted contract uses linked list to manage the sorted stakes of addresses. Linked list implementation relies on HEAD==address(0) and TAIL==address(1) constants It is possible to inject  HEAD  or  TAIL  wherever  in  the  linked  list,  allowing  the  owner  to  manipulate  the  order  of  the elements.  The  issue  severity  is  limited,  because  only  the  Validators.sol  contract  is  using  the AddressStorageStakesSorted and only message senders can add themselves to this list. However, if the contract is used in another way than the Validators.sol contract does, the corruption of the sorted linked list could lead to severe issues.  Code correct :  A check that prohibits HEAD or TAIL to be added in the list has been added.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.14   FxPriceFeed Can Have No Maintainers",
        "body": "  Function  leaveMaintainers  in  FxPriceFeed  contract  does  not  check  that  there  are  left  maintainers after the execution of this function. ContractRegistry performs such check in the same function.    Check was added similar to ContractRegistry, that prevents the last maintainer from leaving.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.15   GSN Version String",
        "body": "  Versions  of  contracts  that  enable  the  GSN  functionality  should  reference  the  GSN  version  used  2.2.2. Currently  the  returned  version  strings  are  not  correct.  While  there  are  no  consequences  on  smart contract level (versions are not checked), the font end libs can have problems with compatibility.   StableCoin.versionRecipient returns \"0.0.1\"   GSNPaymaster.versionPaymaster returns \"0.0.1\"  Code corrected :  The  GSNPaymaster.versionPaymaster is 2.2.0 now.  returned   version   by   StableCoin.versionRecipient   and  Q Blockchain - System contracts -   18  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                          \f6.16   Inconsistent Liquidation Full Debt Due to Outdated Debt  BorrowingCore vault liquidationFullDebt value is updated every time the liquidated function is called.  This  function  can  be  called  by  anyone  and  LiquidationAuction  calls  is  once  during  the startAuction. Nothing prevents the liquidated, as long as the vault is still undercollateralized. But there  is  no  incentive  to  do  so  for  anyone.  In  addition,  the  liquidationFullDebt  saved  in  the beginning of the liquidation will be smaller than the up-to-date value of debt. The collateral interest rate grows  constantly  and  actual  debt  at  than liquidationFullDebt. The difference depends on duration of liquidation auction and interest rate on collateral. All values that depend on liquidationFullDebt will be affected by this discrepancy. For example, the liquidation fee that is defined as a percent of liquidationFullDebt will be smaller than needed and thus, the generated surplus of the system will be smaller than defined %.  the  end  of  Auction  execution  will  be  higher     The liquidate function cannot be called when liquidated. Thus, the liquidationFullDebt cannot be  updated,  once  it  is  set.  The  collateral  interest  rate  growth  won't  affect  the  debt  and  according  to  Q Blockchain, it is intended behavior.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.17   Inconsistent System Debt Auction Start",
        "body": " Condition  From SystemBalance.getBalanceDetails, auction can begin if  systemBalance.getDebt() >= _params.getUint(stc.debtThreshold())  In SystemDebtAuction.startAuction, auction can begin if  _systemBalance.getDebt() > _params.getUint(stc.debtThreshold())  Note >= vs > difference.  Code corrected :  Both conditions are now strict inequality >.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.18   Inefficient Code",
        "body": "  Some code has no effect, is redundant, or simply inefficient. Removing or changing it can increase code readability and save some gas as well.  Examples  Q Blockchain - System contracts -   19  CorrectnessLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                      \f AddressStorage.mustRemove/mustAdd  :AddressStorage.remove/add  already  has  the  onlyOwner modifier   AddressStorage.size()  :  array.length  has  already  type  uint256,  further  casting  to  uint256 has no effect   AddressStorageStakesStore.updateStake(): addrStake[_addr] = _stake; should be moved after the if(_stake==0){} block, otherwise on a 0 stake contract will write 0 in the slot, then delete the entry.   EmergencyUpdateVoting._vote() : the first two require statements check the same property  and have different error messages   QVault.withdrawTo() : the check for user balance is already done in _subFromBalance   QVault._subFromBalance() : upon _targetBalance computation, the SafeMath library not  needed, the check for _amount <= balanceOf(_owner) has already been done   QVault._subFromBalance() : balanceOf is called 3 times, while the result can be queried only  once and later stored in memory variable.   ValidationRewardProxy.PayInformation : this struct contains bool ok, which is assigned  once but never used or returned   ASlashingEscrow.Decision,   SystemSurplusAuction.AuctionInfo,  SystemBalance.SystemBalanceDetails : those structs can be optimized for tight packing   Validators   if   currentWithdrawal.amount   is   0,   the   entry  validatorsInfos[msg.sender].withdrawal is first deleted and then reinitialized again.   RootsVoting._equals() : function is never used   SystemSurplus.bid()   :   _auction   is   already   in   storage,   rewriting   it   to  auctions[_auctionId] is not needed and gas heavy   SystemBalance.getBalanceDetails()  :  a  condition  evaluation  can  be  saved  on  average  by  writing this block in a if - else if - else style, with the most validated condition first   SystemDebtAuction.execute() : call to _checkBalances has no effect since auction status is  now CLOSED   TokenBridgeAdminProxy : is Ownable but the functionality is never used   VotingWeightProxy.extendLocking()  :  the  loop  may  update  lockInfo.lockedUntil  for each  tokenLockSource  every  time  it  is  called.  So,  every  source  will  have  the  same  value  for  their lockInfo.lockedUntil, a unique lockedUntil per user would be more gas efficient   FxPriceFeed can have fields defined as immutable.   CompoundRateKeeperFactory and AddressStorageFactory can deploy minimal proxies for  implementations and not the complete contract.     The redundant check is removed from AddressStorage.mustRemove/mustAdd   Redundant casting removed   The _stake == 0 is handled properly now.   The redundant check was removed.   The redundant check was removed.   The redundant calls were removed.   The ok field was removed from struct.  Q Blockchain - System contracts -   20  \f The field definitions were rearranged, to profit from tight packing.   The deletion was removed.   RootsVoting._equals() is removed.   The redundant rewrite was removed.   The conditions were rewritten in more optimal way.   _checkBalances was moved to the beginning of SystemDebtAuction.execute() function.   _checkBalances was moved to the beginning of SystemDebtAuction.execute() function.   fallback function is onlyOwner now.   The loop was removed.   State variables that could be immutable are now immutable   Proxies are used for the implementations.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.19   Long pendingSlashingProposals Attack",
        "body": "  Malicious root can create numerous proposals on ValidatorsSlashingVoting or RootNodesSlashingVoting and  make  pendingSlashingProposals  entries  on  Validators  or  Roots  too  long  for  gas  limit  to  be executed. This will brake withdrawal functionality on those contracts for a given Root/Validator. Since the root is trusted role, the chance of such attack is considered low.  Code corrected :  Check  RootNodesSlashingVoting and ValidatorsSlashingVoting upon createProposal.  for  already  pending  slashing  proposal  pair   (victim,  proposer)  has  been  added   in  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.20   QVault updateCompoundRate Precision",
        "body": " Loss  Following computations are performed in the updateCompoundRate function of the QVault:  uint256 _accruedReward = aggregatedNormalizedBalance.mul(_newRate.sub(_oldRate)).div(getDecimal()); IQHolderRewardPool(registry.mustGetAddress(\"tokeneconomics.qHolderRewardPool\")).requestRewardTransfer(     _accruedReward );  The resulted _accruedReward variable will have more error, then the difference of two denormalized values, calculated with different rates. The requested reward will be smaller due to the integer division truncation  error.  With  time,  the  error  can  accumulate  and  break  invariant  of  the  contract.  In  addition, _checkBalanceInvariant is not performed after the updateCompoundRate.  Code corrected :  The Q Blockchain provided following fixes:   call _checkBalanceInvariant at the end of updateCompoundRate  Q Blockchain - System contracts -   21  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \f change calculation of _accruedReward to our standard pattern:   denormalize aggregated balance with old rate   update compound rate   denormalize aggregated balance with new rate   _accruedReward must be the diff between the two  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.21   Solc Pragma",
        "body": "  pragma   contract   Current  compiler: pragma solidity ^0.7.0; Contracts should be deployed with the same compiler version and flags that  they  have  been  tested  the  most  with.  Locking  the  pragma  helps  ensure  that  contracts  do  not accidentally  get  deployed  using,  for  example,  the  latest  compiler  which  may  have  higher  risks  of undiscovered bugs.  quite  many   directive   versions   permits   the   of     Solidity  pragma  is  set  to  fixed  0.7.6  for  all  Smart  Contracts.  This  is  the  latest  version  of  Solidity  0.7 major version compiler.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.22   Specification Mismatch",
        "body": "  Code does not match with the specification.  Examples:  1. AddressStorageStakes.add()  address  _addr   :  stake   spec  be   @param  @param _stake amount of decreasing but it should be increase instead of decrease  decreased   whose   will   says and  2. AddressStorageStakes.sub()  :  data.stake  >=  _stake  check  does  not  match  with  the  error message  3. FxPriceFeed : @title Root nodes voting is wrong  4. BorrowingCore.withdrawCol()   : userVaults[msg.sender][_vaultId].colAsset > _amount check does not match with the error message  5. QHolderRewardPool.requestRewardTransfer() : return specs to not match with code, there is no _unsatisfyableClaims and if the amount is too big, call just reverts and does not return 0.  6. SystemBalance.increaseDebt() : PDF documentation says only liquidation auction and saving should  be  allowed  to  increase  debt.  Eligible  contracts  are  not  fixed,  could  be  more  contracts  than those two  7. ConstitutionVoting.shouldExist()   says @dev  Internally  counts  the  vetos  percentage  but  modifier  only  checks  for  proposal existence  spec   :   8. VotingWeightProxy.announceUnlock()  :  spec  says  function  should  throw  error  028002  if  _amount = 0 but no check is done  Q Blockchain - System contracts -   22  DesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                \f9. VotingWeightProxy.unlock()  :  spec  says  we  can  only  unlock  previously  announced  amount  via announceUnlock, but it is possible to unlock more than announced  Code corrected :  1. specs updated  2. error message updated  3. specs updated  4. error message updated  5. specs updated  6. new modifier has been added to check for LiquidationAuction and Saving  7. specs updated  8. specs updated  9. specs updated  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.23   SystemSurplusAuction Bid Reentrancy",
        "body": "  Function  bid  in  SystemSurplusAuction  calls  PushPaymaster.safeTransferTo  to  bidder  address. After  the  call  some  _auction  storage  variable  is  reassigned.  While  PushPaymaster  call  has  a  limited 30000 gas, this can be still enough for reentrancy. Reordering of call and storage assignments can close this potential vulnerability.    The  order  of  operations  was  PushPaymaster.safeTransferTo call.  changed.  No   storage   reads/writes  happen  after   the  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.24   ValidationRewardProxy Allocate Potential",
        "body": " Overflow  The allocate function has following computations:  p.delegatorReward = p.balance.mul(shortList[i].amount).mul(p.qsv).div(p.totalStake).div(decimal); p.validatorReward = p.balance.mul(shortList[i].amount).mul(decimal.sub(p.qsv)).div(p.totalStake).div(decimal);  The max value for uint256 is close to 10^77. Balance has 18 decimals, amount 18 decimals as well. The qsv or decimal-qsv is a value of 10^27 magnitude. Overall it makes 10^63 just for decimals calculations. Keeping in mind the potential big values for shortList amounts and distributed p.balance, the overflow can occur and block all Validator reward payouts from execution.  Code corrected :  Q Blockchain - System contracts -   23  SecurityLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \fComputation that are prone to intermediate overflows are now done using the function mulDiv of library FullMath from Uniswap V3.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.25   Validators Can Alter Delegator Share",
        "body": "  The setDelegatorsShare function of ValidationRewardPools allows validators to set a percent, that will go to delegators from the rewards that validator can get. This action can be done without any time constraints and prior announcement. Validator can even sandwich the call to rewards distribution function between  two  setDelegatorsShare  calls  that  will  result  in  harder  to  notice  of  lowering  the  profits  of delegators.  Code corrected :  Q Blockchain added event DelegatorsShareChanged that allows users to easily identify misbehaving validators. The own stake of validator is much higher than the potential profit from reward distribution and since the own stake can be slashed for misbehavior, the issue is considered as resolved.  Q Blockchain - System contracts -   24  TrustLowVersion1CodeCorrected        \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Constructor and Initializer",
        "body": "  Some  contracts,  e.g.  AddressStorage  defines  both  constructor  and  function  initialize.  Quite  often developers  duplicate  the  logics  of  initialize  inside  constructor  and  define  constructor  itself  with initializer  modifier.  In  your  case  you  don't  do  it,  but  the  creation  and  initialization  of  such  contracts  is consistent and done in a safe way. We wanted to let you know that the current pattern can easily lead to issues, if contract will be used directly without proxy and without proper initialization. The contracts that will serve as implementations for Factories also should be properly initialized, to prevent the undesired state modifications on it.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   DefaultAllocationProxy Allocate",
        "body": "  The design of allocate function in DefaultAllocationProxy contract has aspect that is worth mentioning: The  failure  of  any  beneficiary  fallback  logic  will  force  the  entire  allocation  procedure  to  fail.  In  current implementation version only the QHolderRewardProxy has any logic in its receive function.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Plain Strings as Keys",
        "body": "  The use of plain strings as access keys for the registry across the code base is error prone. It could lead to mistyping one of the keys, can make a contract unusable. A less error prone solution would be to store those string keys as globally available constants.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   Proxy Tests",
        "body": "  The  truffle  tests  concerning  proxies  should  be  extended.  In  the  current  state,  the  proxies  are  just deployed,  but  never  used.  Tests  should  be  done  with  real  proxies,  issues  like  the  one  concerning  the ownership could have been detected then.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   Roots Function _addStake Check",
        "body": "  The check needs to check the _amount value. In current implementation this causes no problems, but can lead to bug if functionality changes.  require(msg.value > 0, \"[QEC-002012]-Additional stake must not be zero.\");  Q Blockchain - System contracts -   25  NoteVersion1NoteVersion1NoteVersion1NoteVersion1NoteVersion1                  \f7.6   SlashingEscrow PENDING After appealEndTime  The  ASlashingEscrow's  state  machine  can  stays  PENDING  on  an  arbitration  decision  if  not  enough RootNodes  confirm  the  decision.  If  a  decision  on  a  casted  objection  does  not  receive  enough confirmations,  it  stays  on  PENDING  state,  event  after  the  appealEndTime.  So  as  long  as  not  enough RootNodes have confirmed the decision, the slashed amount is kept in the slashing escrow, that could mean pure loss for the validator, the slashing proposer and the system reserve if the arbitration is never decided.  The  Q  Blockchain  team  confirmed,  that  root  nodes  are  incentivized  to  vote.  Thus  every  vote  on SlashingEscrow should eventually be decided.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.7   System Compatibility With External Tokens",
        "body": "  While  systems  contracts  operate  properly  with  good  behaving  ERC20  tokens,  some  odd  tokens  can cause  potential  problems  in  the  system.  For  example,  the  BorrowingCore  getting  collateral  with collateral.transferFrom(msg.sender,  address(this),  _amount)  and  _amount  is retained  for  accounting.  This  behavior  does  not  tolerate  tokens  with  fees.  If  a  collateral  is  a  token  that allows fees upon transfer, the real amount received by the BorrowingCore will be less than _amount and the system could end up undercollateralized without noticing it. Similarly, the rounding errors in QVault transfers can lead to smaller received values on the BorrowingCore side. Thus, QVault cannot be used as  a  collateral  inside  BorrowingCore  without  code  adjustments.  In  addition,  on  Ethereum  some  tokens don't always return values on transfer/transferFrom or approvals. Some tokens have unusual number of decimals  (too  big  or  too  small).  Allowing  the  system  to  manipulate  any  external  token  should  be  done with a great care.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.8   Total Q Supply Assumption Source",
        "body": "  the   amount, Upon  (block.number.mul(15)).add(10000000000).mul(1  ether)  is  copy-pasted  as-is  four  times. Having  system  parameters  defined  in  different  sources  is  error  prone  and  can  complicate  the upgradability of the system contracts.  computation   circulating   total   of   Q   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.9   Unchecked Function Return Values",
        "body": "  Some of the calls to known functions are not checked, mainly calls to AddressStorage.  Examples :   QVault.delegateStake : return value of _newDelegations.add(_delegationAddr); is not  checked  Q Blockchain - System contracts -   26  NoteVersion1NoteVersion1NoteVersion1NoteVersion1                \f AExertsMembership.add/remove/swapMember : return values of the interactions with the list  of experts are not checked   QVault _addToBalance and _subFromBalance functions return bool that are never used  While this might be intended, this uses more gas.  Q Blockchain - System contracts -   27  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Conversion Errors When Computing",
        "body": " Underlying Graph Token Value  Each delegation contains two values relevant for the totally managed assets per indexer: the delegated amount denominated in shares and the locked amount denominated in The Graph tokens. To compute the  value  in  The  Graph  tokens  assigned  currently  to  an  indexer  pool,  getDelegationGrtValue() implements the following logic:  (uint256 delegationShares, uint256 tokensLocked, ) = GRAPH_STAKING_CONTRACT.getDelegation(     _indexer,     address(this) ); (, , , , uint256 poolShares, uint256 poolTokens) = GRAPH_STAKING_CONTRACT.delegationPools(     _indexer ); if (delegationShares > 0) {     return delegationShares.mul(poolTokens).div(poolShares).add(tokensLocked); } return tokensLocked;  Note, however, that the view function delegationPools returns the following struct:  struct DelegationPool {     uint32 cooldownBlocks; // Blocks to wait before updating parameters     uint32 indexingRewardCut; // in PPM     uint32 queryFeeCut; // in PPM  Avantgarde Finance - Sulu Extensions IV -   15  CriticalHighCodeCorrectedMediumCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCorrectnessHighVersion1CodeCorrected         \f    uint256 updatedAtBlock; // Block when the pool was last updated     uint256 tokens; // Total tokens as pool reserves     uint256 shares; // Total shares minted in the pool     mapping(address => Delegation) delegators; // Mapping of delegator => Delegation }  The poolShares return value corresponds to the tokens value in the struct (similar for poolTokens). Hence, the return values are not used correctly when delegationShares > 0 holds since the shares' value in GRT will be computed with the inverse of the actual exchange rate.  The  tests  leave  this  issue  undiscovered  since  for  the  delegation  pool  used  in  the  test  case  tokens equals shares which hides the issue.  Ultimately, getManagedAssets() will incorrectly estimate the position.    The  poolTokens  and  poolShares  values  are  now  delegationPools.  retrieved   in   the  correct  order   from  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Incorrect Argument Order for lowerHint and",
        "body": " upperHint  In  LiquityDebtPositionLib.sol,  the  order  in  which  the  lowerHint  and  upperHint  arguments are passed is incorrect in several locations.  This includes private calls (from receiveCallFromVault to the action in question), external calls (from the action to ILiquityBorrowerOperations). Furthermore, there are mix-ups in the tests as well.  Passing the hints in the wrong order generally does not result in the call to Liquity to fail. However, as the hint is unusable, the execution spends more gas to find the right location.  Below  is  a  summary  of  whether  these  function  calls  are  made  with  a  correct  argument  order  for  each action within the smart contract:   __openTrove:   Private call: Incorrect   External call: Incorrect   __addCollateral:   Private call: Correct   External call: Incorrect   __removeCollateral:   Private call: Correct   External call: Incorrect   __borrow:   Private call: Incorrect   External call: Correct  Avantgarde Finance - Sulu Extensions IV -   16  CorrectnessMediumVersion1CodeCorrected        \f __repayBorrow:   Private call: Incorrect   External call: Correct  The  convention  that  Liquity  seems  to  follow  is  to  pass  upperHint  before  lowerHint.  In  Liquity's SortedTroves.sol, a different naming (_prevId and __nextID) is used. Since troves are sorted in descending order, _prevId actually corresponds to upperHint. This is inconsistent with how hints are interpreted/named  in  LiquityDebtPosition.test.ts.  In  some  test  cases  hints  are  in  switched  as well.  One example is the implementation and the test case for repayBorrow: The arguments are switched in the smart contract code and in the corresponding test. Two wrongs make a right and the hints are passed correctly.  When an uneven number of such mistakes are made, the hints are useless and the gas consumption of the call increases.  After  switching  all  the  hints  arguments  in  the  tests,  the  gas  consumption  of  the  above  actions  is  as follows:   __openTrove: Higher (761598 vs. 748240)   __addCollateral: Higher (516155 vs. 417178)   __removeCollateral: Lower (549037 vs. 562395)   __borrow: Lower (1181526 vs. 1194884)   __repayBorrow: Higher (490531 vs. 391554)  Overall, the arguments upperHint and lowerHint should be rechecked and corrected everywhere to ensure useful hints are passed to Liquity and gas used is minimized.    Hints  are  now  always  passed  in  the  same  order,  i.e.,  upperHint,  lowerHint.  The  code  was  also improved to more explicitly identify these two arguments. Furthermore, the tests were updated to use a collateralization  ratio  that  will  avoid  placing  the  trove  at  an  extremity  of  the  sorted  list  to  validate  the correct passing of hints.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Liquity: Lack of Support for ",
        "body": " claimCollateral()  The technical documentation of Liquity writes the following:  claimCollateral(address _user): when a borrower\u2019s Trove has been fully redeemed from and closed, or liquidated in Recovery Mode with a collateralization ratio above 110%, this function allows the borrower to claim their ETH collateral surplus that remains in the system (collateral - debt upon redemption; collateral - 110% of the debt upon liquidation).  However,  the  Liquity  position  library  does  not  support  such  an  action.  Hence,  it  could  be  possible  that funds could become stuck in some situations (e.g. liquidations in recovery mode).  Avantgarde Finance - Sulu Extensions IV -   17  DesignMediumVersion1CodeCorrected        \f  The  issue  has  been  resolved  by  adding  a  ClaimCollateral  action  and  including  the  unclaimed collateral in the valuation.  Note:  Note that this issue has been inadvertently included in another report previously.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Lending Pools Array Read Twice From",
        "body": " Storage in getManagedAssets  In  MapleLiquidityPositionLib.getManagedAssets()  the  length  of  the  used  lending  pools  is queried by copying the full array from storage into memory. Next, the for loop iterates over the array and reads  the  elements  from  storage.  Hence,  gas  consumption  could  be  reduced  by  caching  the  array  in memory.    The pools are now cached into memory and no longer read from storage repeatedly.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Pool Owner Could Change",
        "body": "  To  prevent  the  manipulation  of  a  pool,  reentrancy  is  checked  through  the  withdraw_admin_fees function of the pool owner contract. However, the pool owner address could change and hence such calls on the pool could fail not due to reentrancy but due to access control. The price feed stores the address as  an  immutable  and,  thus,  could  become  unusable  in  the  aforementioned  scenario  of  changing ownerships.    The pool owner address is not immutable anymore. Now, it can be changed by governance.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   LendAndStake Stakes the Full Balance",
        "body": "  LendAndStake  is  an  action  wrapping  the  lending  and  the  staking  action.  First,  it  lends  an  amount  of liquidity  assets  to  the  Maple  pool.  Next,  it  stakes  LP  tokens  to  the  rewards  contract  to  get  some  extra rewards:  function __lendAndStakeAction(bytes memory _actionArgs) private {     (         address pool,         address rewardsContract,         uint256 liquidityAssetAmount     ) = __decodeLendAndStakeActionArgs(_actionArgs);  Avantgarde Finance - Sulu Extensions IV -   18  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \f    __lend(IMaplePool(pool).liquidityAsset(), pool, liquidityAssetAmount);     __stake(rewardsContract, pool, ERC20(pool).balanceOf(address(this))); }  The argument passed to the internal __stake function is the full balance of the pool token. Note that it is also possible to lend the underlying without staking. Consider now the following scenario:  1. 100 tokens are lent into the pool. 100 LP tokens are received.  2. Later, lend and stake is used with 100 underlying tokens.  3. The full balance, namely 200 LP tokens, will be staked.  Such behavior could be unexpected for fund managers.    The code of __lendAndStakeAction() has been changed and now only stakes the amount of tokens received.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   __curveGaugeV2GetRewardsTokensWithCrv",
        "body": "  Is Unused  The internal function __curveGaugeV2GetRewardsTokensWithCrv is unused and could be removed to reduce deployment cost.    The function has been removed.  Avantgarde Finance - Sulu Extensions IV -   19  DesignLowVersion1CodeCorrected        \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Derived Contracts Could By-Pass the",
        "body": " Invariant on the Sum of Shares  The  TreasurySplitterMixin  is  an  abstract  contract  that  allows  splitting  funds  at  constant  ratios  (which should  sum  up  to  100%)  among  users.  The  only  possibility  to  modify  the  split  ratio  in  a  more  derived contract is through the internal function __setSplitRatio.  function __setSplitRatio(address[] memory _users, uint256[] memory _splitPercentages)     internal {     uint256 totalSplitPercentage;     for (uint256 i; i < _users.length; i++) {         // ... duplicate and non-zero validation         userToSplitPercentage[_users[i]] = _splitPercentages[i];         totalSplitPercentage = totalSplitPercentage.add(_splitPercentages[i]);         emit SplitPercentageSet(_users[i], _splitPercentages[i]);     }     require(totalSplitPercentage == ONE_HUNDRED_PERCENT, \"__setSplitRatio: Split not 100%\"); }  This function is agnostic to the current storage of the contract. Hence, the following scenario could occur:  1. A  more  derived  contract  sets  the  split  ratio  with  __setSplitRatio  to  100%  for  user  A.  Hence,  userToSplitPercentage for A will be 100% while no invariants are violated.  2. In another step, the more derived contract tries to add user B to the sharing mechanism. It passes  only user B and 50% to the function.  3. Now, the userToSplitPercentage is set to 50% for B.  4. The sum of all user split percentages is 150% which violates the invariant.  Hence, the current implementation is only suited for one-time setting of split ratios.  With the current usage, this is not an issue as the shares splitter contract will set the ratio only once upon creation.  However,  future  contracts  inheriting  from  the  TreasurySplitterMixin  could  require  some additional logic to prevent the invariant violations described above.  Avantgarde Finance - Sulu Extensions IV -   20  NoteVersion1  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Incorrect Description of Dog.bark()",
        "body": "  After  the  intermediate  report  the  main  functions  of  Liquidations  2.0  have  been  annotated  with  their expected behavior taken from MIP45.  The description above Dog.bark() as well as the corresponding part in MIP45 are outdated: In order to address an other issue (Liquidation of Dusty Vaults), the behavior has been slightly altered.  Notably, the statement  // There is a precondition about `room` that needs // to be satisfied in order to create an auction: // room > 0 && room >= ilk.dust // otherwise the transaction fails  no longer applies in the updated code.  Specification changed:  The  code  comments  have  been  changed  and  now  explain  the  new  liquidation  behaviour  including  the preconditions.  Maker Foundation - Liquidations 2.0 - ChainSecurity  12  CriticalHighMediumSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedLowSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCorrectnessMediumVersion2Speci\ufb01cationChanged           \f7.2   Dirt Remains After Bad Auction  As  described  in  MIP45c4,  the  Hole/  ilk.hole  values  define  a  global  /  per-collateral  limit  of  the  total amount  of  DAI  needed  to  cover  the  summed  debt  and  liquidation  penalty  associated  with  all  active auctions.  The current debt is tracked by the global Dirt and the per collateral ilk.dirt variables.  Upon  auction  initiation,  the  tab,  the  new  debt  of  the  system  is  added  to  the  corresponding  variables. Upon  buying  from  an  auction,  the  owe  amount,  the  amount  of  debt  paid,  is  removed  from  the corresponding variables.  The expected behavior is only loosely covered in MIP45c8:  Lastly, various values are updated to record the changed state of the auction: the DAI needed to cover debt and fees for outstanding auctions, and outstanding auctions of the given collateral type, are reduced (via a callback to the liquidator contract) is reduced by owe, and the tab (DAI collection target) and lot (collateral for sale) of the auction are adjusted as well. If all collateral has been drained from an auction, all its data is cleared and it is removed from the active auctions list. If collateral remains, but the DAI collection target has been reached, the same is done and excess collateral is returned to the liquidated Vault.  As described in the specification above, the code only removes the received amount of DAI (owe) from the debt. This works as expected when the auction managed to cover the tab. In this case all debt added to the dirt during liquidation is removed. During exceptional circumstances however, the situation that an auction is unable to collect enough DAI to cover the tab despite selling all collateral may arise. In this scenario the auction terminates but the unrecovered debt amount remains in the dirt variables.  The expected behaviour in this scenario should be documented.  After such an auction, the value of Dirt will exceed the summed debt of all active auctions and it is no longer possible for the summed debt of all auctions to reach the limit defined by Hole.  If  this  happens  repeatedly,  e.g.  during  a  rapid  market  crash  the  accumulated  unaccounted  dirt  may severely  restricts  the  amount  of  active  auctions  possible.  Most  notably  this  will  impact  less  liquid collateral types with a comparatively low amount set for ilk.hole.    The code has been updated and now handles this case correctly: When an auction has sold all collateral (lot reduced to 0) the remaining tab is removed in addition to owe which is the aumount of DAI just collected:  // Removes Dai out for liquidation from accumulator dog_.digs(ilk, lot == 0 ? tab + owe : owe);  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Potential Reentrancy During Emergency",
        "body": " Shutdown  Maker Foundation - Liquidations 2.0 - ChainSecurity  13  CorrectnessMediumVersion1CodeCorrectedSecurityMediumVersion1CodeCorrected              \fOnce the emergency shutdown mode has been entered, a reentrancy attack is possible. The reentrancy attack works as follows:  1. The attacker identifies an open auction to attack and the corresponding ilk. Note that this attack  can be repeated for different auctions.  2. The attacker ensures that the ilk has been caged inside the End contract. If not, the attacker can  enforce this by calling the cage function for the ilk in question.  3. The attacker calls take on the corresponding Clipper for the identified auction so that the auction  will be closed at the end.  4. The attacker specifies its contract as who for the callback.  5. The take function sends collateral to who.  6. As part of the callback the attacker calls the snip function of the End contract, which will call the  yank function of the Clipper.  7. The  snip  function  returns  the  collateral  and  the  debt  to  the  corresponding  vault  .  Hence,  the  collateral has been sent away twice at this point.  8. The  yank  function  signals  to  the  dog  that  the  auction  is  closed.  The  yank  function  deletes  the  auction and removes it from the active list.  9. After the return of the callback, the take function also signals to the dog that the auction is closed, also  deletes  it  and  finally  tries  to  remove  it  from  the  active  list.  At  this  point  it  removes  another auction from the active list.  The consequences are:   There are more active auctions than listed inside the active array.   Not  all  remaining  auctions  can  be  closed.  The  _remove  function  will  eventually  revert  once  the  active array is empty.   The  Dirt  values  of  the  Dog  is  incorrect.  Hence,  even  auctions  for  other  collaterals  could  revert  during yank or take as the corresponding calls to dog.digs will revert.   The Clipper does not hold sufficient collateral to serve all ongoing auctions.  Note that the exact consequences increase if the attack is performed multiple times.    The issue was addressed by adding the lock modifier to yank which prevents the reentrancy.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   Specification Mismatches",
        "body": "  There are multiple errors of different severity in the MIP45 specification. For each item we list the relevant part of the specification and the explanation of the error:   c7:  \"all  liquidations  disabled(2):  This  means  no  new  liquidations  (Clipper.kick),  no  takes  (Clipper.take), and no redos (Clipper.redo)\"  Reason:  While  this  is  correctly  implemented,  the  code  comment  is  a  bit  unclear  as  it  does  not specify that no kick invocations are allowed on level 2:  // Levels for circuit breaker // 0: no breaker // 1: no new kick()  Maker Foundation - Liquidations 2.0 - ChainSecurity  14  CorrectnessMediumVersion1Speci\ufb01cationChanged        \f// 2: no new redo() or take()   c8: \"If the auction reached the tail value, ... then the Clipper.take would revert if called\"  Reason:  This  description  of  the  tail  value  mismatches  with  its  description  in  c1:  \"Time  elapsed before auction reset\". Note that the source code follows c1:  function status(uint96 tic, uint256 top) internal view returns (bool done, uint256 price) {     price = calc.price(top, sub(block.timestamp, tic));     done  = (sub(block.timestamp, tic) > tail || rdiv(price, top) < cusp); }   c8: \"If the auction ... fell by cusp percent of top, then Clipper.take would revert if called, ...\"  Reason:  Discrepancy  with  c1  \"cusp  =  0.6  *  RAY  (60%  of  the  starting  price),  then  the  auction  will need to be reset when reaching just below the price of 720.\" c1 implies that the auction needs to be restarted once it falls by at least cusp percent, while c8 implies that it needs to be restarted when it falls by more than cusp percent.   c8: \"If the caller provided a bytestring with greater than zero length, an external call is made to the who  address,  assuming  it  exposes  a  function,  follow  Solidity  conventions,  with  the  following signature.\"  Reason: This is not entirely correct, as no call will be made if who is the Dog contract or the Vat contract.   c13: \"treats price at the current time as a function of the initial price of an auction and the time at  which it was initiated\".  Reason: The price is a function of the initial price and the duration since last redo.   c14: \"This process will repeat until all collateral has been sold or the whole debt has been collected\"  Reason: This is not true as the auction might also be completed through a call to the snip function.   c15:  \"The  Clipper.take  call  can  send  any  remaining  collateral  or  DAI  beyond  owe  to  a  cold  wallet  address inaccessible to the keeper.\"  Reason: This statement is slightly imprecise as the remaining collateral or DAI would be moved by the clipperCallee.   c16:  \"A  mutex  check  to  ensure  the  Clipper.take  function  is  not  already  being  invoked  from  clipperCallee.\"  Reason:.  The  mutex  check  prevents  reentrancy  into  Clipper.take/redo()  irregardless  of  the clipperCallee.   c17: \"calls dog.digs in order to increment its Hole and ilk.hole values by the remaining auction tab.\"  Reason: It is not Hole/hole that are modified but Dirt/dirt.   c18: \"function file(bytes32 what, uint256 data) external\"  Reason: data should be of the type address.   c18: function active() external view returns (uint256[]);  Reason: The automatically created getter active will requires numeric index as a parameter and returns a single uint256.   c26: \"urn.art * ilk.rate * ilk.chop ||\"  Reason: Missing operator for comparison.   c26:   In  equations   into  account  e.g., urn.art * ilk.rate * ilk.chop > room. However, this choice is not explicitly stated which creates mismatch with the implementation.  the  units  are  not   it  seems   taken   that   Maker Foundation - Liquidations 2.0 - ChainSecurity  15  \f c26: \"vault.art * ilk.rate <= room\"  Reason: Missing chop.   c27: \"if amt < lot && tab - (amt * abacus.price) < ilk.dust\"  Reason: Mismatch with code. The code says amt < lot && owe < tab.  Specification corrected:  The  specification  has  been  corrected  and  matches  the  code  behavior  apart  from  minor  diversions  that are irrelevant to general usage, e.g., internal restrictions on callback targets.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   Specification Mismatches Due to Final",
        "body": " Changes  The documentation still lists the function getId inside the Clipper contract. However this function was  of the code. Note that no functionality was removed as the active function can be removed in  used instead.  The  updust  function  was  newly  added  to  the  code  in    to  allow  a  caching  of  the  dust  value inside  the  Clipper,  see  Dust  Retrieval  Is  Relatively  Expensive  for  more  information.  The  updust function is not yet documented.  Specification changed:  The specification was adjusted accordingly to reflect the removal of the getId function and the addition of the updust function.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.6   Dust Retrieval Is Relatively Expensive",
        "body": "  Multiple clever gas optimizations have been performed by the developers. However, we note that a rather trivial looking line still contains major gas costs:  (,,,, uint256 dust) = vat.ilks(ilk);  This line retrieves the dust amount for the specific ilk. It occurs inside the Clipper functions take and redo. Inside the vat the following struct will be loaded:  struct Ilk {     uint256 Art;   // Total Normalised Debt     [wad]     uint256 rate;  // Accumulated Rates         [ray]     uint256 spot;  // Price with Safety Margin  [ray]     uint256 line;  // Debt Ceiling              [rad]     uint256 dust;  // Urn Debt Floor            [rad] }  Maker Foundation - Liquidations 2.0 - ChainSecurity  16  CorrectnessLowVersion3Speci\ufb01cationChangedVersion3Version3DesignLowVersion2CodeCorrected                \fHence, 5 SLOAD operations are necessary. After the activation of the upcoming Berlin hardfork this will cost 5 * 2,100 = 10,500 gas. However, in the current architecture there is no way to retrieve the dust value separately. Mirroring it inside the Clipper contract would reduce the costs significantly, but would introduce potential inconsistencies between the two values.    The code has been corrected. The dust value is cached inside the Clipper and can be kept consistent through a permissionless call to updust.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.7   Duplicate Functions in Clipper",
        "body": "  The  two  functions  getId  and  the  active  inside  the  Clipper  have  the  same  functionality.  Both functions take a list index as input and return the element of the active list at that index.  function getId(uint256 id) external view returns (uint256) {     return active[id];  Hence, it seems that the code size is unnecessarily increased.    The getId function was removed from the Clipper contract.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.8   Gas Inefficiency During Auction Removal",
        "body": "  When an auction is being removed from the Clipper, because it is finished or has been yanked, then the auction id will be removed from the active list. As part of this removal, the auction id is exchanged with the last auction id in the active list and the appropriate changes are made:  function _remove(uint256 id) internal {     uint256 _index   = sales[id].pos;     uint256 _move    = active[active.length - 1];     active[_index]   = _move;     sales[_move].pos = _index;  In case that the removed auction was already last in the list, which is not unlikely given that there is such a list for each collateral, two SSTORE and one SLOAD operation could have been skipped.  Code Corrected:  The code has been changed as follows:  function _remove(uint256 id) internal {     uint256 _move    = active[active.length - 1];     if (id != _move) {  Maker Foundation - Liquidations 2.0 - ChainSecurity  17  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \f        uint256 _index   = sales[id].pos;         active[_index]   = _move;         sales[_move].pos = _index;     }     active.pop();     delete sales[id]; }  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.9   Liquidation of Dusty Vaults",
        "body": "  According to the protocol, the initiation of an auction will be reverted if the available room is less than the dust for the corresponding ilk. However, there might be the corner case where a dusty vault exists, e.g., after the dust amount for a particular ilk has been increased.  Dusty vaults can be blocked from liquidation even though there would be room for them. This is because of following check:  require(room > 0 && room >= dust, \"Dog/liquidation-limit-hit\");  Even  though  there  wouldn't  be  enough  room  for  dust,  there  would  still  be  enough  room  for  a  dusty auction. This state is temporary. Later, once even more room becomes available again, the dusty vault can be liquidated again.    Dusty vaults can now be liquidated. If there is room to liquidate the total art of the vault there are no further restrictions related to the dust to start the auction.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.10   room > 0 Check Can Be Omitted",
        "body": "  In dog.bark there is a check on whether the available room is positive. This check takes place in the following require statement:  require(room > 0 && room >= dust, \"Dog/liquidation-limit-hit\");  This check is only useful in the case where dust == 0 and room == 0, otherwise it holds trivially. In the  previously  mentioned  case,  however,  dart  ==  0  (since  dart  =  min(art,  0))  and (art - dart)*rate >= dust (since dust == 0).  Hence, dink = mul(ink, dart)/art == 0 and the following require statement reverts:  require(dink > 0, \"Dog/null-auction\");  Hence, the room > 0 sub-condition can be safely removed, which saves a small amount of gas during every execution.  Maker Foundation - Liquidations 2.0 - ChainSecurity  18  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \fCode Corrected:  In  the  updated  implementation  the  logic  determining  whether  a  full  or  partial  liquidation  happens  has been changed in order to address another issue. The require statement listed above no longer exists and neither does an unnecessary > 0 check. Hence the issue has been resolved.  Maker Foundation - Liquidations 2.0 - ChainSecurity  19  \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  contracts  in scope for this review are part of the Maker system which consists of many interacting contracts. Hence, the mentioned topics serve to clarify or support the report, but do not require a modification inside the project. Instead, they should raise awareness in order to improve the overall understanding for users and developers.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Blocked Calls From Clipper",
        "body": "  During the take function of the Clipper, an external call is executed. Certain call targets are blocked:  if (data.length > 0 && who != address(vat) && who != address(dog_)) {     ClipperCallee(who).clipperCall(msg.sender, owe, slice, data); }  As the Clipper has special privileges inside the vat and dog_ contracts, these contracts are blocked. However, additionally targets need to be blocked where the funds controlled by the Clipper could be moved  in  an  unauthorized  way.  A  good  example  is  the  GemJoin.exit  function.  This  function  could remove the stored collateral from the Clipper and send it to an attacker. Please note that this attack currently does not work as there is no collision between the signature hashes of   clipperCall(address,uint256,uint256,bytes) and   exit(address,uint256).  However, we note that for all future contracts added to the system it needs to be ensured that no such collisions exist or the call targets need to be blocked.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Creation of Many Small Auctions",
        "body": "  As  discussed  in  the  MIP45,  incentive  farming  needs  to  be  avoided.  Besides  the  scenarios  that  are already described in the MIP45, another scenario is possible. This scenario comes into effect if either the capacity  for  one  collateral  or  the  overall  capacity  has  almost  reached  its  limit.  In  technical  terms  this means that the dirt is almost as large as the hole.  If, in this scenario, a large vault becomes unsafe, an attacker could create many small auctions out of it. The attacker would perform the following steps within a single transaction:  1. Create a small auction that fills up the capacity limit and receive the keeper incentive  2. Take a small amount (ideally dust) from another auction (note that given that the limit is reached,  there is likely a good auction available)  The  only  downside  for  the  attacker  compared  to  creating  a  big  auction  are  higher  gas  costs.  Note, however, that after EIP-2929 (in combination with EIP-2200) will come into effect the additional costs of performing step 2 multiple times will be significantly reduced, while the costs of repeated executions of step 1 will also be reduced.  Maker Foundation - Liquidations 2.0 - ChainSecurity  20  NoteVersion2NoteVersion1        \f8.3   Debt Queue Not Updated Automatically  The Vow contract manages a system debt queue called sin, not to be confused with the sin mapping inside the Vat contract. It is noteworthy that the debt queue is fully not synchronized with the liquidation system. In particular, the liquidation system makes new entries, but never resolves them.  This can have two possible effects:  1. The debt inside the system debt queue is released too quickly. In particular that means that auctions might still be ongoing for the released debt and hence some of the debt might still get covered. This can  occur  if  the  wait  value  inside  the  Vow  is  too  low  in  comparison  to  auction  durations.  As  a consequence it might be possible to trigger a debt auction even though there is no need for it.  2. The debt inside the system debt queue is released too slowly. In particular that means that auctions might have long finished and that the debt has already been repaid. This can occur if the wait value inside the Vow is too large in comparison with auction durations. As a consequence surplus auctions could be unnecessarily delayed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.4   Ethereum Is a Dark Forest",
        "body": "  Ethereum  is  a  Dark  Forest  describes  the  phenomena  of  bots  inspecting  the  pool  of  unmined transactions  and  front-running  profitable  transactions  with  their  own.  Although  the  exact  capabilities  of these bots are unknown, these bots are sophisticated.  Liquidations 2.0 relies on keepers to initiate liquidations of undercollateralized vaults. There is a certain cost overhead (e.g. running a software monitoring the blockchain) for keepers to detect undercollaterlized vaults.  Only  after  undercollateralized  vaults  have  been  identified,  they  can  be  liquidated  by  calling Dog.bark(). For their efforts, keepers are rewarded on-chain if tip and/or chip are set to non-zero values.  While  it  doesn't  matter  for  the  liquidation  system  when  bots  copy  and  front-run  these  transactions,  the honest  keepers  will  not  only  lose  their  anticipated  reward  for  the  liquidation,  but  also  lose  the  gas  fee paid. If this happens repeatedly, keepers may stop to identify & liquidate undercollateralize vaults as they can't make a profit. Once no keeper identifies and crafts transactions to liquidate vaults bots can't copy these transactions anymore - and hence in an extreme scenario no more liquidations happen.  Clipper.redo() is affected in a similar way, Clipper.take() may be affected partially, e.g. when there are flash-loans involved.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.5   Incentive Farming Might Be Possible Due to",
        "body": " Misconfiguration  As  mentioned  in  MIP45c19,  Incentive  Farming  is  a  risk  in  the  system.  However,  it  could  also  occur without  a  change  in  the  dust  value.  Note  that  there  is  no  mechanism  inside  the  smart  contracts  that prevents that a keeper's reward for kicking off an auction is bigger than the liquidation penalty which the system achieves. Hence, the governance needs to chose the corresponding parameters: chip, tip and chop very carefully as a misconfiguration allows a way to drain the system.  Maker Foundation - Liquidations 2.0 - ChainSecurity  21  NoteVersion1NoteVersion1NoteVersion1            \f8.6   Initialization and Deployment Requires Extra Care  As  with  any  smart  contract  care  needs  to  be  taken  during  deployment  and  initialization.  However,  for these contracts it is especially important as they:   will be integrated into an existing system   are not fully initialized during deployment  In particular the following steps need to be performed correctly:   Authorizations between the contracts need to be granted   All parameters need to be chosen. Not that some functionality will already be available with partially initialized  contracts,  e.g.  the  Clipper  contract  will  be  fully  functional  if  no  Vow  contract  has  been registered. However, all collected DAI will flow to the Zero address.  Initially given deployment authorizations need to be revoked   Authorizations for replaced contracts need to be revoked  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.7   Monotonicity of Price Functions",
        "body": "  The auction system is designed as \"Dutch style auction system, where auction prices generally start high and  drop  over  time\".  Note,  however  that  there  is  no  guarantee  in  the  system  that  prices  will  be monotonically decreasing. Apart from a redo which can trigger a price increase, the prices can also rise due to changed parameters of the corresponding Abacus contract.  As  an  example,  if  the  variable  tau  which  contains  the  \"Seconds  after  auction  start  when  the  price reaches zero\" is increased, ongoing auctions will see a price increase. Note, that users of the system can protect  themselves.  Auction  takers  can  specify  a  max  price  which  they  are  willing  to  pay  for  collateral. Then, they only stand to lose gas costs.  We  aim  to  educate  users  to  properly  use  the  max  value  even  though  there  is  a  seemingly  decreasing price.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.8   No Stability Fee During Auctions",
        "body": "  As  debt  accumulates  no  stability  fee  during  auctions,  it  needs  to  be  ensured  that  debt  doesn't  reside inside an auction for too long. In case the stability fee would be very high, the liquidation penalty would be  really  low,  and  the  auction  would  be  running  for  a  very  long  time,  the  stability  fee  lost  during  the auction time would exceed the liquidation penalty earned. In this hypothetical scenario a liquidation would be \"beneficial\" for a vault owner.  Note, however, that we deem this as highly unlikely as there is a general incentive to keep auctions short, which is also discussed in the MIP45. Even for the collateral with the currently highest stability fee (50%), the auction would have to take roughly 110 days to offset a regular liquidation penalty of 13%.  Maker Foundation - Liquidations 2.0 - ChainSecurity  22  NoteVersion1NoteVersion1NoteVersion1             \f8.9   Vat Debt Tracking Not Automatically Synchronized  At the beginning of an auction dog.bark() calls vat.grab() to reassign the collateral to the auction contract  and  the  debt  from  the  vault  to  the  system.  Hence,  both  vat.sin[vow]  and  vat.vice  are increased by dart times the collateral's rate. The sin mapping and vice are used to track the bad debt of the system inside the Vat contract.  However, these values are not updated after a successful auction. This is due to how the Maker system works: After a purchase in an auction, the DAI amount received is transferred to the vow. When the vow contract  has  a  surplus  amount  of  DAI,  anyone  may  call  vow.heal()  to  settle  the  debt  accrued  in vat.sin[vow]. Further functionality allows to handle debt or surplus auctions. Please note that the Vow and Vat contracts are not in scope of this review and are expected to work correctly.  Maker Foundation - Liquidations 2.0 - ChainSecurity  23  NoteVersion1  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   No Sanity Check on _start_time",
        "body": "  There is no sanity check on _start_time in FeeDistributor.__init__.  Acknowledged  StakeDAO acknowledged the issue.  StakeDAO - StakeDAO-Frax-veSDT -   14  DesignCorrectnessCriticalHighMediumLowAcknowledgedAcknowledgedAcknowledgedAcknowledgedAcknowledgedAcknowledgedCodePartiallyCorrectedCodePartiallyCorrectedAcknowledgedAcknowledgedCodePartiallyCorrectedCodePartiallyCorrectedAcknowledgedAcknowledgedAcknowledgedDesignLowVersion4Acknowledged              \f5.2   Broad Function Visibility: approveWallet  The visibility of the function SmartWalletWhitelist.approveWallet is public, however it is not called  internally.  For  functions  that  are  expected  to  be  called  from  other  contracts  only,  the  function visibility can be restricted to external instead of public. This allows to save gas costs, as public functions copy array function arguments to memory which can be expensive.  Acknowledged  StakeDAO acknowledged the issue.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   Inconsistent Checks When Depositing in ",
        "body": " veSDT  The function increase_amount requires that the msg.sender is either an externally owned contract or a whitelisted contract:  self.assert_not_contract(msg.sender)  However, the function deposit_for performs the same operation if addr is msg.sender and does not have the above restriction.  Acknowledged  StakeDAO acknowledged the issue. It is connected to a vyper bug which also affects another issue. The bug was resolved in version 0.3.1. More information: Fix allocation of unused storage slots  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.4   Inconsistent Procedure for Updating admin",
        "body": "  Multiple  contracts  have  an  admin  role  that  is  privileged  and  can  call  sensitive  functions.  However,  the procedure  to  update  such  privileged  roles  is  not  consistent  among  different  contracts.  Namely, SmartWalletWhiteList  uses  commit/apply  approach,  meaning  the  current  admin  initially  calls commitAdmin and then should call applyAdmin to set the new admin. While, LiquidityGaugeV4, FeeDistributor,  veBoostProxy  use  commit/accept  approach.  Differently  from  the  previous contracts, veSDT provides both procedures commit/accept and commit/apply to update the admin.  Acknowledged  StakeDAO acknowledged the issue.  StakeDAO - StakeDAO-Frax-veSDT -   15  DesignLowVersion3AcknowledgedCorrectnessLowVersion3AcknowledgedDesignLowVersion3Acknowledged                        \f5.5   Mismatch of Specification With the Function Modifier in AngleLocker  The  specification  of  the  AngleLocker's  function  createLock  states  that  it  can  only  be  called  by governance or proxy, however, the modifier onlyGovernance is used and the mentioned proxy is not declared anywhere.  Acknowledged  StakeDAO acknowledged the issue and replied:  The specification comment is wrong because it mentioned a proxy where it is not declared at the end.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.6   Missing Documentation for Parameter",
        "body": "  The function GaugeController.__init__ has no NatSpec description for the parameter admin.  Acknowledged  The NatSpec has not been updated.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.7   Missing Events for Sensitive Operations",
        "body": "  Multiple  contracts  do  not  emit  events  when  sensitive  operations  are  performed,  e.g.,  the  update  of  the admin for a contract.  We provide below some examples:   SmartWalletWhitelist.sol: applyAdmin and applySetChecker.   ClaimRewards.sol: setGovernance.   SdtDistributor.sol: initializeMasterchef, setDistribution and setTimePeriod.   LiquidityGaugeV4.vy: add_reward, set_reward_distributor and set_claimer.  Code partially corrected  StakeDAO added a new event for the function setGovernance of ClaimRewards.sol.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.8   Missing Sanity Checks",
        "body": "  Several setter functions in multiple contracts do not perform sanity checks for the new values that are set. We provide examples of such cases below:  StakeDAO - StakeDAO-Frax-veSDT -   16  CorrectnessLowVersion3AcknowledgedDesignLowVersion3AcknowledgedDesignLowVersion3CodePartiallyCorrectedDesignLowVersion3CodePartiallyCorrected                              \f SdtDistributor.sol:  _masterchef  parameter   in  initialize  and  _delegateGauge   in  setDelegateGauge.   LiquidityGaugeV4.vy: _distributor in add_reward.   veSDT.vy: token_addr in initialize and addr in commit_smart_wallet_checker.   FeeDistributor.vy: _start_time in the constructor.  Code partially corrected  StakeDAO added some checks but the following values still lack sanity checks:   SdtDistributor.sol: _delegateGauge in setDelegateGauge.   LiquidityGaugeV4.vy: _distributor in add_reward.   veSDT.vy: addr in commit_smart_wallet_checker.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.9   Missing Sanity Checks: AngleLocker",
        "body": "  The  setter  functions  take  an  address  as  a  parameter  and  assign  it  to  a  state  variable.  Given  the sensitivity  of  such  functions,  basic  sanity  checks  on  the  input  parameter  help  to  eliminate  the  risk  of setting address(0) to the state variable of the contract by accident (e.g. UI bugs).  Acknowledged  StakeDAO  decided  to  keep  the  function  as  it  is  and  explained  that  its  parameters  will  be  reviewed carefully and that it won't be managed through a user interface.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.10   Non-indexed Events",
        "body": "  Events  can  be  indexed  to  easily  filter  and  search  for  the  indexed  arguments.  This  is  used  in  most contracts.  Without  full  specification  about  what  needs  indexing  we  simply  highlight  that  the  following occasions are not indexed and the need of indexing should be revised by StakeDAO.   Completely no indexed events in BaseAccumulator   Completely no indexed events in ClaimRewards   Completely no indexed events in GaugeController   Multiple not indexed events in LiquidityGaugeV4   Multiple not indexed events in veBoostProxy   No indexed events in CommitAdmin and ApplyAdmin in FeeDistributor  Acknowledged  StakeDAO replied:  StakeDAO - StakeDAO-Frax-veSDT -   17  DesignLowVersion3AcknowledgedDesignLowVersion3Acknowledged                \fWe decided to not include indexed parameters within the events definition because they will increase the gas a little bit and also, we could fetch externally the same info using theGraph.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.11   Possible Gas Optimization in Mappings",
        "body": "  Multiple contracts of the system use mappings in the format: mapping(key_type => bool). Solidity uses a word (256 bits) for each stored value and performs some additional operations when operating bool values (due to masking). Therefore, using uint256 instead of bool is slightly more efficient.  We provide below the list of mappings that can be optimized:   SmartWalletWhitelist.sol: wallets.   ClaimRewards.sol: gauges.   SdtDistributor.sol: killedGauges, isInterfaceKnown and isGaugePaid.  Code partially corrected  StakeDAO changed the mapping gauges in ClaimRewards.sol from mapping(key_type => bool) to mapping(key_type => uint256) and modified all the functions using it accordingly.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.12   Unused Events",
        "body": "  Several contracts declare events that remain unused in the existing code base. The StakeDAO should assess if such events should be removed or emit them accordingly. We provide a list of unused events:   ClaimRewards.sol:   DepositorDisabled,   RewardClaimedAndLocked   and  RewardClaimedAndSent.   SdtDistributorEvents.sol:   UpdateMiningParameters.   GaugeController.vy: KilledGauge.  DistributionsToggled,   RateUpdated,  Code partially corrected  StakeDAO  deleted  the  unused  events  in  ClaimRewards  but  not  in  SdtDitributorEvents  and GaugeController as they were already deployed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.13   Missing Sanity Checks: FraxLocker",
        "body": "  The  setter  functions  take  an  address  as  a  parameter  and  assign  it  to  a  state  variable.  Given  the sensitivity  of  such  functions,  basic  sanity  checks  on  the  input  parameter  help  to  eliminate  the  risk  of setting address(0) to the state variable of the contract by accident (e.g. UI bugs).  Acknowledged  StakeDAO - StakeDAO-Frax-veSDT -   18  DesignLowVersion3CodePartiallyCorrectedDesignLowVersion3CodePartiallyCorrectedDesignLowVersion1Acknowledged                        \fDue to efficiency reasons, StakeDAO decided to keep the function as it is.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.14   Missing Sanity Checks: FxsDepositor",
        "body": "  The  setter  functions  that  take  an  address  as  a  parameter  and  assign  it  to  a  state  variable  lack  basic sanity  checks  on  the  input  parameter.  Such  checks  would  help  to  eliminate  the  risk  of  setting address(0) to the state variable of the contract by accident (e.g. UI bugs).  Acknowledged  Due to efficiency reasons, StakeDAO decided to keep the function as it is.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.15   Missing Sanity Checks: sdFXSToken",
        "body": "  The  function  setOperator  takes  an  address  as  a  parameter  and  assigns  it  to  the  state  variable operator. Given the sensitivity of this function, basic sanity checks on the parameter _operator help to eliminate the risk of setting address(0) as the operator of the contract by accident (e.g. UI bugs).  Acknowledged  Due to efficiency reasons, StakeDAO decided to keep the function as it is.  StakeDAO - StakeDAO-Frax-veSDT -   19  DesignLowVersion1AcknowledgedDesignLowVersion1Acknowledged                  \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  0  1  3  12  -Severity Findings  -Severity Findings  Incorrect Index Used to Access depositorsIndex   -Severity Findings   Possible to Lock Users' Funds Into veSDT   Inconsistent Access Control    Update of unlockTime   -Severity Findings  Inconsistent Specification: deposit_for_from   Inconsistent Specification: initialize    Possible to Optimize the Check on Distributor of tokenReward    Broad Function Visibility    Commented Code    Mismatch of Specification With the Function Modifier    Revert Message on Modifier    Unused Event Voted    Unused Imports: FxsDepositor    Unused Imports: FxsLocker    Unused Imports: sdFXSToken    createLock Access Control   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Incorrect Index Used to Access ",
        "body": " depositorsIndex  In  the  function  addDepositor  of  ClaimRewards  ,  values  of  depositorsIndex  are  set  using depositor addresses as indexes.  depositorsIndex[_depositor] = depositorsCount;  In claimAndLock this array is accessed twice using token addresses as indexes.  if (depositor != address(0) && lockStatus.locked[depositorsIndex[token]]) {         IERC20(token).approve(depositor, balance);  StakeDAO - StakeDAO-Frax-veSDT -   20  CriticalHighCodeCorrectedMediumCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCorrectnessHighVersion3CodeCorrected            \f        if (lockStatus.staked[depositorsIndex[token]]) {                 IDepositor(depositor).deposit(balance, false, true, msg.sender);         } else {                 IDepositor(depositor).deposit(balance, false, false, msg.sender); }  Given  that  there  are  no  contract  defining  both  a  token  and  a  depositor  in  the  codebase,  it  would  most likely  lead  depositorsIndex[token]  to  always  evaluate  to  0  and  hence  use  the  first  element  of lockStatus.staked and lockStatus.locked as decisions for each token.  Code corrected  The variable depositor is now used to address depositorsIndex in claimAndLock.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Possible to Lock Users' Funds Into veSDT",
        "body": "  Users that lock their tokens into the voting escrow contract need to approve an allowance to veSDT and then call deposit_for or deposit_for_from to transfer the tokens. However, if a user approves to the veSDT an amount that is larger than the intended amount of tokens to be locked, or max uint for simplicity, the user's tokens are exposed to arbitrary locking. In such cases the function deposit_for allows anyone to lock more of user's tokens into the contract without their clear consent. This is possible because  the  function  deposit_for  calls  the  internal  function  _deposit_for  without  passing  the msg.sender as a parameter:  def deposit_for(_addr: address, _value: uint256):     ...     self._deposit_for(_addr, _value, 0, self.locked[_addr], DEPOSIT_FOR_TYPE)  The internal function transfers the tokens from _addr if enough allowance exists, while the caller only pays the gas costs:  def _deposit_for(_addr: address, _value: uint256, unlock_time: uint256, locked_balance: LockedBalance, type: int128):     ...     if _value != 0:         assert ERC20(self.token).transferFrom(_addr, self, _value)  Code corrected  StakeDAO  corrected  the  issue  by  adding  the  new  parameter  _from  to  _deposit_from  and  using  it instead of _addr for the ERC20 transfer. Whenever _deposit_from is called, msg.sender is passed as  an  argument  so  that  _from  is  always  equal  to  it.  Anyone  is  still  able  to  call  deposit_for  or deposit_for_from for someone else, but it is now the caller's tokens that are deposited.  def _deposit_for(_addr: address, _value: uint256, unlock_time: uint256, locked_balance: LockedBalance, type: int128, _from: address):     ...     if _value != 0:         assert ERC20(self.token).transferFrom(_from, self, _value)  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Inconsistent Access Control",
        "body": "  StakeDAO - StakeDAO-Frax-veSDT -   21  DesignMediumVersion3CodeCorrectedDesignMediumVersion1CodeCorrected                \fto   allows   The  access  control  for  FraxLocker.execute  is  onlyGovernanceOrDepositor.  The  function basically  function FraxLocker.claimFXSRewards  has  the  following  access  control  onlyGovernanceOrAcc.  As execute can replicate the behavior of claimFXSRewards the access control is inconsistent because claimFXSRewards can be replicated by execute. Ultimately, giving the Depositor the same power as Acc in this case.  function.   arbitrary   contract   The   and   any   call   This is only a theoretical problem in the current implementation due to another issue.  Code corrected  The  updated  code  protects  the  function  execute  with  the  modifier  onlyGovernance,  which  restricts the access to only the governance address.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Update of unlockTime",
        "body": "  We  do  not  have  sufficient  specification  about  the  intended  behavior,  but  the  following  seems  to  be  an issue. The internal function _lockFXS updates the unlockTime if the following condition is satisfied:  if (unlockInWeeks.sub(unlockTime) > 1) {         ILocker(locker).increaseUnlockTime(unlockAt);         unlockTime = unlockInWeeks; }  Given that both unlockInWeeks and unlockTime store the number of seconds passed until a given week, the comparison with 2 (sec) seems incorrect.  Specification changed  The  current  code  will  always  evaluate  the  if  condition  as  true  if  the  comparison  is  bigger  than  1. StakeDAO changed the specification from two weeks to one week. Additionally, the 2 was changed to 1 (which has no effect but makes it more explicit). The code works but we need to highlight, that this only works for one week check.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Inconsistent Specification: ",
        "body": " deposit_for_from  The functions deposit_for and deposit_for_from have a similar behavior, however their NatSpec specification is inconsistent. The comment for deposit_for:  @dev Anyone (even a smart contract) can deposit for someone else, but      cannot extend their locktime and deposit for a brand new user  while the respective description for deposit_for_from is:  @dev Anyone (even a smart contract) can deposit for someone else from their account  StakeDAO - StakeDAO-Frax-veSDT -   22  DesignMediumVersion1Speci\ufb01cationChangedCorrectnessLowVersion3CodeCorrected                \fCode corrected  The NatSpec specification of deposit_for_from has been modified to reflect the function's behavior.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Inconsistent Specification: initialize",
        "body": "  The NatSpec description of veSDT's initialize function describe token_addr as being the address of the ERC20ANGLE contract while the contract is a voting escrow for the SDT token.  Code corrected  StakeDAO corrected the NatSpec description by replacing ERC20ANGLE by ERC20SDT.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Possible to Optimize the Check on Distributor",
        "body": " of tokenReward  The  function  BaseAccumulator._notifyReward  checks  if  the  distributor  of  _tokenReward  is  not address(0), then it performs the two external calls as shown below:  if (ILiquidityGauge(gauge).reward_data(_tokenReward).distributor != address(0)) {                     IERC20(_tokenReward).approve(gauge, _amount);                     ILiquidityGauge(gauge).deposit_reward_token(_tokenReward, _amount);         ...             }  The  function  call  deposit_reward_token  succeeds  only  if  the  accumulator  is  the  distributor  for  the _tokenReward, otherwise it reverts. Hence, the function could be optimized by directly checking if the distributor of the _tokenReward is the accumulator.  Code corrected  The condition checks immediately if the address is the accumulator.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   Broad Function Visibility",
        "body": "  The  function  depositFor  in  FxsDepositor  is  declared  as  public  but  it  is  never  called  internally. Following  the  best  practices,  functions  expected  to  be  called  only  externally  should  be  declared  as external.  Code corrected  StakeDAO - StakeDAO-Frax-veSDT -   23  CorrectnessLowVersion3CodeCorrectedDesignLowVersion3CodeCorrectedDesignLowVersion1CodeCorrected                        \fThe function depositFor has been removed from the contract.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   Commented Code",
        "body": "  The contract FraxLocker includes a function vote which is commented out. Please elaborate on the cause and if this functionality should be implemented or the code removed completely.  Code corrected  The commented function was removed from the code base.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   Mismatch of Specification With the Function",
        "body": " Modifier  The specification of the function createLock states that it can only be called by governance or proxy, however,  the  modifier  onlyGovernanceOrDepositor  is  used,  which  checks  if  the  msg.sender  is either the governance or fxsDepositor address. Additionally, the fxsDepositor contract does not implement any functionality which calls createLock currently.  Code corrected  The updated spec state that createLock can be called only by the governance. The respective modifier onlyGovernance is now used.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.11   Revert Message on Modifier",
        "body": "  The  modifier  onlyGovernanceOrDepositor  checks  if  the  msg.sender  is  either  governance  or fxsDepositor address as shown:  modifier onlyGovernanceOrDepositor() {         require(                 msg.sender == governance || msg.sender == fxsDepositor,                 \"!(gov||proxy||fxsDepositor)\"         );         _; }  The error message claims that msg.sender is not proxy address, which is not declared in the contract.  Code corrected  The error message has been updated accordingly.  StakeDAO - StakeDAO-Frax-veSDT -   24  DesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                        \f6.12   Unused Event Voted  The contract FraxLocker declares the event Voted, however, it is not used in the current codebase.  Code corrected  The unused event Voted has been removed from the code.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.13   Unused Imports: FxsDepositor",
        "body": "  The file FxsDepositor.sol (   Depositor contract) has the following unused import:  import \"@openzeppelin/contracts/token/ERC20/ERC20.sol\"; import \"@openzeppelin/contracts/utils/Address.sol\"; import \"@openzeppelin/contracts/utils/Context.sol\";  Code corrected  The unused libraries listed above have been removed from the updated code.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.14   Unused Imports: FxsLocker",
        "body": "  The contract FxsLocker has the following unused imports:  import \"@openzeppelin/contracts/math/SafeMath.sol\"; import \"@openzeppelin/contracts/utils/Address.sol\";  Code corrected  The unused libraries have been removed from the updated code.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.15   Unused Imports: sdFXSToken",
        "body": "  The file sdFXSToken.sol (   sdToken) has the following unused imports:  import \"@openzeppelin/contracts/token/ERC20/IERC20.sol\"; import \"@openzeppelin/contracts/utils/Address.sol\";  StakeDAO - StakeDAO-Frax-veSDT -   25  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedVersion2DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedVersion2                                \fimport \"@openzeppelin/contracts/token/ERC20/SafeERC20.sol\"; import \"@openzeppelin/contracts/utils/Context.sol\";  Code corrected  The unused libraries listed above have been removed from the updated code.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.16   createLock Access Control",
        "body": "  functions   The  modifier onlyGovernanceOrDepositor,  but  the  contract  FxsDepositor  never  calls  these  functions. Specifications covering use cases when these functions are called by the depositor are missing.  createLock,   execute   release   have   and   the   Code corrected  The modifier for the functions listed above has been updated to onlyGovernance.  StakeDAO - StakeDAO-Frax-veSDT -   26  DesignLowVersion1CodeCorrected        \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Admin's Weight on a Gauge Can Be",
        "body": " Overwritten  The function change_gauge_weight in GaugeController allows the admin to set the weight of any gauge to an arbitrary value. This value can be altered by voters of the gauge. If users vote for the gauge, its weight is increased to a higher value than set by the admin. Furthermore, if users that previously voted the gauge (before the admin called change_gauge_weight) remove their votes, the weight of the gauge is decreased to a lower value than set by the admin.  StakeDAO replied:  The weight, for a gauge already included into the GaugeController won't likely change, if it would happen, we will take care of managing it.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   All Gauges Should Be Trusted",
        "body": "  The gauges are added into the system by the admin of the GaugeController and they are considered to be non-malicious. If an untrusted gauge is added, then it can exploit a reentrancy vulnerability in the function SdtDistributor._distributeReward which can drain all rewards:  ILiquidityGauge(gaugeAddr).deposit_reward_token(address(rewardToken), sdtDistributed);  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Dust Amounts Not Accounted in veSDT",
        "body": "  function  veSDT._checkpoint   The  MAXTIME = 4 * 365 * 86400:  ignores   locked   tokens  with  an  amount  smaller   than  def _checkpoint(addr: address, old_locked: LockedBalance, new_locked: LockedBalance):     ...     u_old.slope = old_locked.amount / MAXTIME     ...     u_new.slope = new_locked.amount / MAXTIME     ...  If old_locked.amount or new_locked.amount is less than MAXTIME, the respective slope is set to 0.  StakeDAO - StakeDAO-Frax-veSDT -   27  NoteVersion3NoteVersion3NoteVersion3          \f7.4   Event Can Be Emitted Multiple Times  Several contracts follow the approach commit/accept to set a new admin for the contract. For such updates,  an  event  CommitOwnership/  CommitAdmin  is  emitted  on  the  commit  operation,  and ApplyOwnership / ApplyAdmin event is emitted when the new admin accepts the transfer. However, the accepting functions can be called multiple times, hence the respective events would be emitted for every call. We provide a list of such contracts here:   GaugeController   veSDT   FeeDistributor   LiquidityGaugeV4   veBoostProxy  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   Outdated Compiler Version",
        "body": "  The  compiler  version:  0.8.7  is  outdated  (https://swcregistry.io/docs/SWC-102).  The  compiler  version has the following known bugs.  This is just a note as we do not see any severe issue using this compiler with the current code. At the time of writing the most recent Solidity release is version 0.8.13.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.6   Possible Reentrancy in lockToken for Special",
        "body": " Tokens  The  function  Depositor.lockToken  performs  a  mint  operation  and  afterwards  emits  an  event  and updates the state variable incentiveToken:  if (incentiveToken > 0) {     ITokenMinter(minter).mint(msg.sender, incentiveToken);     emit IncentiveReceived(msg.sender, incentiveToken);     incentiveToken = 0; }  In the current code base, minter token is always the sdToken which extends the ERC20 standard and does  not  provide  any  callback  functionality  to  the  receiver,  hence  the  code  above  is  not  vulnerable  to reentrancy  attacks.  However,  if  in  the  future  versions  of  the  code  the  minter  token  is  supposed  to support callbacks, e.g., implement ERC777 standard and the mint operation provides an opportunity for reentrancy, the above function would be exploitable.  StakeDAO - StakeDAO-Frax-veSDT -   28  NoteVersion3NoteVersion1NoteVersion3              \f7.7   Reward Distribution Should Be Called Periodically for All Gauges  The  function  SdtDistributor.distributeMulti  works  correctly  only  if  it  is  called  periodically  (at least once a day) for all the gauges, otherwise the following two issues arise:  1. Failing to call distributeMulti for a gauge on a given day means that the gauge does not receive  its  share  of  rewards  for  the  respective  day  and  the  funds  are  locked  in  the  contract. Only the governance can recover these funds via recoverERC20 function.  2. On the time period that overlaps with the weekly event of updating votes for gauges, there is a time window for a malicious user to manipulate the rewards distributed to gauges. For example, if a gauge receives a higher weight for the following week, it is profitable for a malicious user to call  the  function  distributeMulti  when  the  new  weight  is  applied,  and  vice-versa.  This makes  the  accounting  of  rewards  in  SdtDistributor  incorrect  and  potentially  can  prevent legit gauges from receives any reward.  As  stated  in  the  System  Overview,  StakeDAO  should  run  a  bot  that  guarantees  the  function  is  called periodically and correctly for all gauges to prevent the issues above.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.8   Tautology in if Condition",
        "body": "  The function setFees in contracts Depositor and FxsDepositor verifies that _lockIncentive is greater than or equal to zero, however, as it is a unsigned integer, this condition will always hold.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.9   ClaimRewards Functions Should Be Called",
        "body": " Only With Enabled Gauges  The functions claimRewards and claimAndLock take a list of gauges as a parameter and check that each of them is enabled. If one of the gauges in _gauges is disabled by the governance, the functions revert.  Hence,  the  caller  should  always  guarantee  that  that  all  gauges  passed  into  the  functions  are enabled.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.10   safeApprove Usage",
        "body": "  The  contract  FxsDepositor  (Depositor  in  given to the gauge. As explained in the specifications of the function, safeApprove is deprecated.  )  uses  safeApprove  to  update  the  allowance  /**  * @dev Deprecated. This function has issues similar to the ones found in  * {IERC20-approve}, and its usage is discouraged.  *  * Whenever possible, use {safeIncreaseAllowance} and  StakeDAO - StakeDAO-Frax-veSDT -   29  NoteVersion3NoteVersion1NoteVersion3NoteVersion1Version2              \f * {safeDecreaseAllowance} instead.  */  StakeDAO - StakeDAO-Frax-veSDT -   30  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Redemption Blocked When No Rate Entry at",
        "body": " Maturity Exists  After  the  shutdown  of  the  ClaimFee  contract,  users  may  exchange  their  claim  balance  for  DAI  using cashClaim(),  if  it  has  a  maturity  after  the  closure  timestamp.  However,  this  requires  a  valid  entry  in ratio[ilk][maturity] which must be set manually for each ilk and maturity by the governance.  Since the function slice allows users to split their claim fee, many arbitrary maturity timestamps may exist.  If  the  user  still  holds  all  segments  up  to  the  maturity,  they  may  be  able  to  merge  them  using function merge(). However, these segments may not be available anymore: Individual segments may have  been  redeemed  already,  or  be  unavailable  to  the  user  as  they  have  been  transferred  using  the function moveClaim.  Overall, users may be blocked and unable to redeem their claim fee.  Risk accepted:  Deco accepts the risk that rate entries might be missing for maturity timestamps. They pledge to provide appropriate support to ensure all maturities have a valid ratio set in case of emergency shutdown.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Gate1 Withdraw Timestamp",
        "body": "  MakerDAO - Claim Fee Maker -   10  DesignCorrectnessCriticalHighMediumRiskAcceptedLowAcknowledgedRiskAcceptedRiskAcceptedDesignMediumVersion1RiskAcceptedDesignLowVersion1Acknowledged                  \fIn the Gate1 constructor, the withdrawAfter timestamp is set. The only check made using this value is to see if it is in the past. Thus, not setting the value at all would save gas and yield the same results.  Acknowledged:  The additional storage write is a one-time cost during deployment.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   Leftover Claims",
        "body": "  ClaimFee.collect()  reimburses  the  stability  fee  accrued  between  the  issuance  and  collect timestamp. If the collect timestamp is not equal to the maturity, a new claim fee is issued from the collect timestamp to the maturity.  In  general,  it's  very  unlikely  that  a  valid  rate  is  stored  for  the  maturity  timestamp:  Apart  from  values manually inserted by the governance, rates stored through function snapshot() can only exist for valid block timestamps. The maturity of a claim fee could have been set months in advance upon issuance or the claim fee could have been sliced in various ways. Hence, most of the time, it's not possible to collect up to the maturity timestamp. This design will result in minting many small \"leftover\" claims.  Risk accepted:  There  will  be  standardized  maturity  timestamps,  e.g.the  first  day  of  the  month  at  12:00:00  UTC. Additionally, it is planned to run bots that regularly take snapshots to ensure that any leftover claims are sufficiently small to be negligible. Lastly, users will be warned against using functionality which creates non-standard maturity timestamps.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.4   Slice at Timestamp With No Rate",
        "body": "  The function slice allows users to split their claim at a certain timestamp. However, it is possible that the  timestamp  at  which  they  split  their  claim  does  not  have  a  valid  rate.  Unless  they  later  merge  their claims again, or the governance adds a valid rate for the split timestamp, it may not be possible for the user to redeem the full value of the claims.  Risk accepted:  As stated previously, it is intended to have standardized maturity timestamps so that users can know in advance  which  timestamps  will  have  valid  rates.  Using  such  timestamps,  users  are  able  to  split  their claims  without  incurring  any  losses.  Should  the  need  arise  there  are  two  pathways  to  mitigate  the situation: Governance may insert snapshots at timestamp or users can use activate() to activate a claim  fee  balance  at  a  timestamp  with  a  rate  set.  Note  that  yield  earned  between  issuance  and  the activation timestamp becomes uncollectable and is permanently lost.  MakerDAO - Claim Fee Maker -   11  DesignLowVersion1RiskAcceptedDesignLowVersion1RiskAccepted                  \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  Increasing VAT Debt After Shutdown, After thaw()   -Severity Findings   Comments Regarding vow.heal()    Governance Can Burn From Users    Gate1.heal()   totalSupply Mapping Not Updated   -Severity Findings   Address of VOW    Duplicate Check    Maturity in the Past    Unused Constants and Function    Various Event Issues   this Keyword in initializeIlk   0  1  4  6  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Increasing VAT Debt After Shutdown, After ",
        "body": " thaw()  ClaimFee generates the required DAI by calling vat.suck() through the Gate1 contract which acts as a safeguard to enforce a limit on the maximum amount of DAI that can be generated by adding bad debt to the system.  vat.suck() is independent of the system status, notably whether the VAT is live or not. Hence, the call to  vat.suck()  will  add  more  bad  debt  and  generate  DAI  when  the  VAT  is  in  shutdown.  This  occurs even  after  end.thaw()  has  been  called  in  step  6  of  the  shutdown,  which  fixes  the  total  outstanding supply of DAI.  The Gate1 contract's purpose is to limit access of the ClaimFee contract in the core maker system: In order to draw bad debt using vat.suck() one needs to be a ward in the VAT to be able to pass the auth modifier. To avoid giving full privileges to the external ClaimFee contract, an intermediary contract Gate1 is introduced, which will be given the privileged role in the VAT. The code of the Gate1 contract enforces limitations in order to limit the risk for the core system. In its current state, the Gate1 contract is missing restrictions to prevent drawing more debt when the VAT is in shutdown.  For further reference:  MakerDAO - Claim Fee Maker -   12  CriticalHighCodeCorrectedMediumSpeci\ufb01cationChangedSpeci\ufb01cationChangedRiskAcceptedCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedAcknowledgedCodeCorrectedDesignHighVersion1CodeCorrected               \fhttps://github.com/makerdao/dss/blob/master/src/end.sol#L410 https://docs.makerdao.com/smart-contract-modules/shutdown/end-detailed-documentation#6.-thaw https://github.com/makerdao/dss/blob/master/src/vat.sol#L230    A check for the condition VatAbstract(vat).live() == 1 was added to the accessSuck function in the ClaimFee contract. This prevents the debt from increasing after the VAT is in shutdown.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Comments Regarding vow.heal()",
        "body": "  One of the annotations of the Gate1 contract reads:   does  not  execute  vow.heal  to  ensure  the  dai  draw  amount  from  vat.suck  is  lower  than  the  surplus buffer currently held in vow  There is the following comment in Gate1.accessSuck():  // call suck to transfer dai from vat to this gate contract try VatAbstract(vat).suck(address(vow), address(this), amount_) {     // optional: can call vow.heal(amount_) here to ensure     // surplus buffer has sufficient dai balance      // accessSuck success- successful vat.suck execution for requested amount     return true; } catch {   vow.heal() uses surplus DAI of the VOW (= surplus buffer) to repay bad debt of the VOW at the  VAT   vat.suck() generates DAI by creating bad debt assigned to the VOW  Vat.suck() simply adds bad debt, there is nothing ensuring the amount of DAI drawn is lower than the surplus buffer.  Specification changed:  The annotation and comments were removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Governance Can Burn From Users",
        "body": "  The function ClaimFee.withdraw() allows the privileged ward role (the governance) to burn a claim of any user. However, the function's annotation contradicts this as it states the following:  /// Withdraws claim balance held by governance before maturity /// @dev Governance is allowed to burn the balance it owns  MakerDAO - Claim Fee Maker -   13  CorrectnessMediumVersion1Speci\ufb01cationChangedCorrectnessMediumVersion1Speci\ufb01cationChangedRiskAccepted                  \fFurthermore, this function can also withdraw/burn a claim balance upon/after maturity.  Risk accepted:  The annotation was changed to reflect the functionality. The risk of allowing the governance to burn any user's  balance  is  accepted,  as  they  plan  to  add  additional  contracts  with  functionalities  that  require burning claim fee balances.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Gate1.heal()",
        "body": "  Gate1.heal() is annotated with:  // Access to vat.heal() can be used appropriately by an integration  It simply calls vat.heal():  function heal(uint rad) external {     VatAbstract(vat).heal(rad); }  Vat.heal() heals bad debt of msg.sender()  function heal(uint rad) external {     address u = msg.sender;     sin[u] = sub(sin[u], rad);     dai[u] = sub(dai[u], rad);     vice   = sub(vice,   rad);     debt   = sub(debt,   rad); }   The Gate1 contract however doesn't accrue bad debt when generating DAI: Gate1 only draws bad debt using vat.suck(address(vow), address(this), amount_). The bad debt is assigned to the VOW, only the generated DAI is assigned to the Gate1 contract:  function suck(address u, address v, uint rad) external auth {     sin[u] = add(sin[u], rad);     dai[v] = add(dai[v], rad);     vice   = add(vice,   rad);     debt   = add(debt,   rad); }  If  the  Gate1  contract  doesn't  accrue  bad  debt  outside  of  its  own  functionality,  the  function  has  no purpose.  Furthermore,  if  Gate1  does  indeed  accrue  bad  debt,  the  intended  backup  DAI  balance  may  be compromised by the fact that anyone could call heal() and use some of this DAI balance to heal the bad debt.  MakerDAO - Claim Fee Maker -   14  DesignMediumVersion1CodeCorrected        \f  The heal() function of the Gate1 contract was removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   totalSupply Mapping Not Updated",
        "body": "  The ClaimFee contract has a totalSupply mapping which should track the total supply of claims per ilk. However, neither the mintClaim nor burnClaim functions update the mapping.    The totalSupply mapping is now updated accordingly in the mintClaim and burnClaim functions.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Address of VOW",
        "body": "  In the Gate1 Contract, both the VOW and the VAT addresses are stored as immutables. In contrast, the ClaimFee  contract  stores  both  addresses  in  storage  without  implementing  functionality  to  update  the address.  As  reading  from  storage  is  expensive,  variables  set  only  during  deployment  may  be  changed  to immutables. During the deployment, all immutable values are inserted into the bytecode of the deployed contract code. Hence, they can be accessed during execution without the need for an expensive SLOAD operation.  that   there  are  ongoing  discussions   Note  to  use  a  proxy: https://github.com/makerdao/dss/pull/241  As  such,  it  may  be  necessary  to  have  a  mutable  storage variable for its address.  to  change   the  VOW     The VAT address was made immutable in the ClaimFee contract, and the VOW address was removed. Instead, the VOW address is dynamically queried from the Gate1 contract when necessary.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Duplicate Check",
        "body": "  The function issue checks the following condition:  require(initializedIlks[ilk] == true, \"ilk/not-initialized\");  However,  the  mintClaim  function  checks  the  very  same  condition  and  hence  the  check  in  issue  is unnecessary.    The duplicate check was removed.  MakerDAO - Claim Fee Maker -   15  CorrectnessMediumVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \f6.8   Maturity in the Past  The function issue places the following requirement on the maturity timestamp:  require(         issuance <= latestRateTimestamp[ilk] && latestRateTimestamp[ilk] <= maturity,         \"timestamp/invalid\"     );  However,  there  is  no  guarantee  that  the  value  latestRateTimestamp[ilk]  is  recent.  As  it  makes little  sense  to  issue  a  claim  with  a  maturity  in  the  past,  one  could  instead  check  that  the  maturity  is later than the current block timestamp.    The issue function now ensures the condition block.timestamp <= maturity.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   Unused Constants and Function",
        "body": "  There are a few constants and a function that are unused or could otherwise be omitted.  1. The  MAX_UINT   constant   could  be   replaced  with   the  built-in  Solidity   constant:  type(uint256).max.  2. The constant RAD is never used.  3. The function wmul is never used.    The MAX_UINT constant was replaced as suggested; RAD and wmul were removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   Various Event Issues",
        "body": "  There are a few functions in which events should be emitted or the event parameters should be indexed.  1. In  the  ClaimFee  constructor,  no  Rely  event  is  emitted  when  the  message  sender  is  added  as  a  ward.  2. No event is emitted by the close function. This is an important change regarding the functionality  of the contract and hence should emit an event.  3. No event is emitted by the calculate function. Again, this is an important storage change which allows  users  to  cash  out.  Indexing  the  events  would  allow  users  to  search  for  specific  ilks  and maturities.  4. The Kiss and Diss events in the Gate1 contract are not indexed.  5. The NewApprovedTotal and Draw events in the Gate1 contract could have indexed amounts.  MakerDAO - Claim Fee Maker -   16  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedAcknowledged                          \f  1. A Rely event emission was added to the ClaimFee constructor.  2. A Closed event was added and is now emitted by the close function.  3. A NewRatio event was added and is now emitted by the calculate function.  4. The address parameter in the Kiss and Diss events in the Gate1 contract are now indexed.  Acknowledged:  5. The  NewApprovedTotal  event  was   indexed accessSuckStatus parameter, but the amount parameter is not indexed as Deco did not see the need for it.  removed.  The  Draw  event  now  has  an   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.11   this Keyword in initializeIlk",
        "body": "  The initializeIlk function makes the following call to the snapshot function:  function initializeIlk(bytes32 ilk) public auth {     // ...     this.snapshot(ilk); // take a snapshot }  Calling  a  function  in  this  way  incurs  an  extra  cross-contract  call.  In  order  to  make  an  internal  call,  the snapshot  function  would  have  to  be  declared  public  instead  of  external  and  the  this  keyword removed.    In  initializeIlk() has been updated accordingly.  the  snapshot   functions  visibility  has  been  changed   to  public,   the  call   in  MakerDAO - Claim Fee Maker -   17  DesignLowVersion1CodeCorrectedVersion3          \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Circumvent withdrawAfter Restriction",
        "body": "  Gate1  features  a  restriction  for  function  withdrawDai().  The  privileged  role  able  to  pass  the  auth modifier can only call withdrawDai() successfully when the withdrawal condition is satisfied:  bool withdrawalAllowed = (block.timestamp >= withdrawAfter);  The  privileged  role  able  to  pass  the  auth  modifier  can  always  add  any  address  as  a  bud  using  the function  kiss().  Such  an  account  can  then  pass  the  toll  modifier  and  successfully  call  suck()  / draw()  and  draw  DAI.  If  the  call  to  vat.suck()  is  unsuccessful  (e.g.  if  the  limit  has  already  been reached) this allows to withdraw the backup DAI balance of the contract.  Code partially corrected:  While  it  is  no  longer  possible  to  add  a  bud  when  the  withdrawal  condition  is  not  satisfied,  an  already existing bud would still be able to circumvent the restriction. For example, after the contract is created, a bud  could  be  added,  and  only  then  withdrawAfter  would  be  set  to  a  timestamp  in  the  future. Alternatively,  one  could  wait  for  withdrawAfter  to  be  in  the  past,  then  add  a  bud  and  set withdrawAfter  to  a  future  timestamp.  Therefore,  a  ward  is  still  able  to  withdraw  the  backup  DAI balance of the contract.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Discrepancy Between Reimbursed Amount",
        "body": " and Actual Stability Fee  The  stability  fee  paid  in  in  the  Maker  system  is  based  on  the  rate  increase  between  when  taking  and repaying the debt.  ClaimFee reimburses the stability fee based on stored snapshots of the rate.  There are corner cases where the rate stored may not match the actual rate debt was taken/repaid for at this  timestamp  and  hence  the  reimbursed  amount  of  DAI  is  not  the  amount  of  stability  fee  paid  by  the user.  Storing  the  current  rate  in  ClaimFee  does  not  trigger  the  update  of  the  rate  in  the  Maker  system (jug.drip()).  A  later  transaction  in  the  very  same  block  may  trigger  jug.drip()  and  further transactions modifiying a debt position of this ilk use the new rate.  Consider the following scenarios which must happen within the same block:  1.   ClaimFee.snapshot() is executed and rate A is stored   Jug.drip() is executed -> The rate is udpated to A+x   The user repays debt in the Maker system at rate A+x  MakerDAO - Claim Fee Maker -   18  NoteVersion1CodePartiallyCorrectedNoteVersion1RiskAccepted          \fWhen the user calls collect() on his claim fee balance he is reimbursed based on the \"old\" rate stored and receives less DAI than actual stability fee paid.  2.   User takes debt in the Maker system at rate A   Jug.drip() is executed -> rate is udpated to A+x   ClaimFee.snapshot() is executed and rate A+x is stored  Similarly,  the  user  may  not  be  compensated  for  the  full  stability  fee  in  this  scenario.  Note  that normally, with the stability fee based on the rate/time, the user has an incentive to increase the rate first using jug.drip() before taking on debt. However, unaware users with the impression that claim fee covers their stability fee may not do this.  We assume that jug.drip() is executed frequently and the resulting rate increase is small enough so the discrepancies arising in scenarios as described above can be neglected.  Risk accepted:  The risk is accepted based on the assumption that the rate increases are small enough to be negligible.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   No Connection Between ClaimFee and Actual",
        "body": " Debt  There  is  no  connection  between  an  issued  claim  fee  and  debt  in  the  VAT.  ClaimFee  reimburses  the stability fee its amount (art) would have accrued.  Note that the amount of claim fees issued per ilk should not exceed the amount of actual debt per ilk otherwise more stability fee is reimbursed than is actually accrued by the system.  Deco responded:  \u2013 Our goal is to help the Maker protocol find users who want to hold a vault open for the entire term of the claim fee so that the protocol can derive the benefits of a sticky user and collect the fixed-rate revenue upfront without having to make any re-imbursements later to these users from the revenue generated by variable-rate vaults held by others. We want to ensure claim fee supply stays matched to the vaults who signed up for fixed-rate debt at the issuance date.  \u2013 ClaimFee has a transfer function which already allows a vault owner who has claim fee balance and no longer wants to use it to transfer it to another regular vault owner. This would keep claim fee balance less than ilk debt and not trigger the excess reimbursement issue.  \u2013  We  originally  planned  to  avoid  reimbursements  that  exceed  stability  fee  accrual  to  the  system  when debt level drops directly at the urn that was supposed to use the claim fee balance, by combining both the urn and claim fee balance and routing all its usage through a CDP Manager style contract which can create and manage a fixed-rate vault. This CDP Manager can have the required state transitions to keep both debt and claim fee balance of the vault in sync over its lifetime.  \u2013  We  now  plan  to  design  and  deploy  a  much  simpler  and  standalone  \u201cLiquidation  Penalty\u201d  contract instead  of  the  modified  CDP  Manager.  Liquidity  Penalty  contract  can  withdraw  an  amount  of  claim-fee balance  (burn  it)  held  by  a  user  address  to  match  any  reduction  in  debt  on  a  regular  vault  the  same address  holds.  We  don\u2019t  want  addresses  holding  claim  fee  balances  standalone  without  also  holding vaults of the collateral type between the issuance and maturity timestamps of the claim fee balance. This liquidation  penalty  contract  could  re-imburse  the  claim  fee  balance  after  taking  a  haircut  on  its  current  MakerDAO - Claim Fee Maker -   19  NoteVersion1    \fvalue(let\u2019s say 75%, make it attractive for fixed-rate vault owners to abandon their claim fee balance, but not  set  it  too  high  at  like  100%  to  ensure  no  reimbursement  but  force  claim  fee  holders  to  find  buyers among other vault owners to avoid loss of value) to ensure claim fee in circulation stays below the debt held in urn at all times, thereby also solving the issue at the ilk level.  MakerDAO - Claim Fee Maker -   20  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Curve Price Oracle Manipulation",
        "body": "  When estimating the value of a Curve LP token, get_virtual_price() is queried which describes the value increase through fees since the pool was created. The function may return a manipulated value for some  pools  where  transfers  have  callbacks  or  other  callbacks  to  users  are  made  (e.g.  ETH,  ERC677, ERC223, ERC777, ...) as the state of the pool may be inconsistent during the callback.  Due to the limiter of the Pricefeed which enforces that the price remains within a certain bound, Gearbox is largely protected hence the low severity rating. Nevertheless, the manipulated state of the Curve pool could be detected (at this point the pool's reentrancy lock is set) by the pricefeed.  Curve  is  aware  of  this  issue  and  new  pools  are  no  longer  affected.  Existing  pools  however  remain vulnerable. This issue is currently being addressed and affects various integrations. As of today not all have  been  fixed  hence  please  treat  this  issue  confidential  for  the  time  being.  Full  public  disclosure  is expected to be released soon.  Gearbox Protocol responded as follows:  Due to the LP price limiters, the attacker cannot practically inflate the asset value more than 2% of its real value. This discrepancy can be included in the asset's LT - the LT represents the maximal asset price drop during the liquidation period, but is not dependent on whether this price drop comes from actual market conditions, or price manipulation within a bound known in advance.  Gearbox Protocol - Gearbox V2 -   13  SecurityDesignCorrectnessCriticalHighMediumLowAcknowledgedCodePartiallyCorrectedSecurityLowVersion1Acknowledged             \f6.2   Enable Supported Token on Any CreditAccount  CreditFacade.addCollateral() allows anyone to deposit funds on behalf of another credit account owner. Using this function has a different effect compared to simply transferring the funds to the credit account directly: It additionally enables the token for this credit account.  This may be a risk factor: If there is ever a bad token supported by a CreditManager, this immediately affects  all  CreditAccounts  of  this  CreditManager.  Users  are  not  safe  when  they  don't  hold  the  affected token.  Code partially corrected:  CreditFacade.addCollateral()  is  now  only  allowed  for  users  for  which  are  authorized  in  the transferAllowed mapping.  Gearbox Protocol notes:  This change should address an attacker sending a bad token to other users in order to break health factor calculation. However, there still remains a narrow vector whereas a token that was already on Credit Account is broken and reverts on balanceOf() (for example, stETH and SNX use proxies, and can be potentially changed to a broken implementation contract).  Currently,  this  is  not  addressed,  however,  should  this  transpire,  CreditFacade  could  be  quickly updated  to  ignore  this  token  (or  error-handle)  in  calcTotalValue(),  which  would  allow  to  liquidate affected positions.  Gearbox Protocol - Gearbox V2 -   14  SecurityLowVersion1CodePartiallyCorrected        \f7   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  0  0  3  22  -Severity Findings  -Severity Findings  -Severity Findings   Multicall Actions During Pauses    Pricefeed of Oracle May Be Updated    Unable to Handle Missing Return Value   -Severity Findings   CumulativeDrop Calculation Rounding   twvUSD Contains Value in Underlying    Free Flashloan upon Open/Close    Adapters Ignore User Input    Add Token Without Liquidation Threshold    Checking for Valid Token Indices for Curve Pools Is Too Loose    Credit Accounts Give Very High Approval to Contract    CreditAccount Calls approve() on Unsupported Token    Curve Registry    CurveV1 Adapters: TokenOut Might Not Be Enabled at CreditAccount    Duplicate Error Code Used   Incorrect Comment After Refactoring   Incorrect Descriptions    Outdated Function Description    PriceOracle: Unused Timestamp    Read-only Reentrancy    Redundant Event Emission    Redundant Initialization    Reentrancy Into CreditFacade    Sanity Check of New Pricefeed    Unused allowedContractsSet    YearnV2Adapter: Different Behavior of Functions   Gearbox Protocol - Gearbox V2 -   15  CriticalHighMediumCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedAcknowledgedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrected       \f7.1   Multicall Actions During Pauses  During  a  liquidation,  the  liquidator  can  call  CreditFacade._multicall.  When  this  happens,  the ownership  of  the  credit  account  is  temporarily  passed  to  the  CreditFacade  to  allow  it  to  properly interact with the adapters. By using this feature, liquidators can swap tokens of the credit account to the underlying and, thus, they don't have to supply the underlying by themselves. This is a useful feature for any  liquidator,  even  for  the  emergency  ones.  During  pauses,  however,  the  functionality  of  the  credit manager is limited. One of the limitations is that CreditManager.transferAccountOwnership fails. This means that the liquidators cannot make any calls to the adapters.    The CreditManager now allows multiple calls to be made while the system is paused as long as the call is related to an emergency liquidation (whenNotPausedOrEmergency).  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Pricefeed of Oracle May Be Updated",
        "body": "  PriceOracle._addPriceFeed() is annotated with  /// @dev Sets price feed if it doesn't exist. If price feed is already set, it changes nothing /// This logic is done to protect Gearbox from priceOracle attack /// when potential attacker can get access to price oracle, change them to fraud ones /// and then liquidate all funds  The function does not enforce this, a second call to this function allows to update the pricefeed for the token.  Specification changed:  The description was erroneous and it was intended for the function to update the existing price feed. The description was updated to reflect that.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Unable to Handle Missing Return Value",
        "body": "  to  Gearbox  V1  safeApprove()  has  been  replaced  by  approve()  function Compared  CreditAccount.approveToken. The interface inherited expects a boolean return value as defined in the ERC-20 specification. However, there are tokens such as USDT or OMG which do not adhere to this specification and have no return value on approve() and transfer.  in   Calling CreditAccount.approveToken() with these tokens will revert as the function call does not return the expected return value. Hence it's not possible for the new credit accounts to give approval on such tokens.    Gearbox Protocol - Gearbox V2 -   16  DesignMediumVersion1CodeCorrectedCorrectnessMediumVersion1Speci\ufb01cationChangedDesignMediumVersion1CodeCorrected                      \fThe  new  CreditAccount  implementation  no  longer  features  an  approveToken  function.  Approvals through  CreditManager.approveCreditAccount()  now  use  the  execute  function  of  the CreditAccount  which  allows  arbitrary  calls.  This  works  for  both,  the  new  implementation  and  the  old already deployed credit accounts.  If present, the returned boolean is checked. In case the approval is unsuccessful the code attempts to reset the approval to 0 before attempting the to approve the intended amount. This accounts for some token implementations enforcing this.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   CumulativeDrop Calculation Rounding",
        "body": "  The new fast collateral check is described as follows:  The fast check now ensures that the HF has not decreased significantly, rather than pure collateral value. The decrease is also tracked cumulatively across multiple swaps (hence the sum) - as soon as liquidationFee of cumulative loss is occurred, a full collateral check is performed and the cumulative sum is reset.  The computation is done as follows:  // compute cumulative price drop in PERCENTAGE FORMAT uint256 cumulativeDrop = PERCENTAGE_FACTOR -     ((amountOutCollateral * PERCENTAGE_FACTOR) / amountInCollateral) +     cumulativeDropAtFastCheck[creditAccount]; // F:[CM-36]  ...  if (cumulativeDrop <= slot0.feeLiquidation) {     cumulativeDropAtFastCheck[creditAccount] = cumulativeDrop; // F:[CM-36]     return; }  PERCENTAGE_FACTOR is 10`000. This allows precision up to 2 decimals. Resulting rounding errors per division might be up to 0.009999% Drops up to 0.009999...% per fast check are not detected nor added to cumulativeDropAtFastCheck. This may be done repeatedly.  Hence the requirement  The decrease is also tracked cumulatively across multiple swaps (hence the sum) - as soon as liquidationFee of cumulative loss is occured, a full collateral check is performed  strictly  speaking  does  not  hold.  Other  protocols,  e.g.  Maker  work  with  significant  higher  precision internally.  Is the resulting precision sufficient / can the potential loss be tolerated?  The new fast check compares cumulativeDrop and feeLiquidation. While both are percentages, they are different: The feeLiquidation will be taken from the actual total value while the cumulative drop has  been  calculated  taking  into  account  the  liquidation  thresholds.  Given  the  liquidation  thresholds  are strictly lower than 100% there is a safety margin before the system takes a loss.    The precision of the calculation was increased in RAY. The relevant code snippet now looks like this:  Gearbox Protocol - Gearbox V2 -   17  CorrectnessLowVersion3CodeCorrected        \f// compute cumulative price drop in WAD FORMAT        uint256 cumulativeDropRAY = RAY -            ((amountOutCollateral * RAY) / amountInCollateral) +            cumulativeDropAtFastCheckRAY[creditAccount]; // F:[CM-36]         // if it drops less that feeLiquiodation - we just save it till next check        // otherwise new fullCollateral check is required        if (            cumulativeDropRAY <=            (slot0.feeLiquidation * RAY) / PERCENTAGE_FACTOR        ) {            cumulativeDropAtFastCheckRAY[creditAccount] = cumulativeDropRAY; // F:[CM-36]            return;        }  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   twvUSD Contains Value in Underlying",
        "body": "  The  public  function  CreditFacade.calcCreditAccountHealthFactor()  calculates  the  health factor in percent:  function calcCreditAccountHealthFactor(address creditAccount)     public     view     override     returns (uint256 hf) {     (, uint256 twvUSD) = calcTotalValue(creditAccount); // F:[FA-42]     (, uint256 borrowAmountWithInterest) = creditManager     .calcCreditAccountAccruedInterest(creditAccount); // F:[FA-42]     hf = (twvUSD * PERCENTAGE_FACTOR) / borrowAmountWithInterest; // F:[FA-42] }  The  naming  of  the  variable  twvUSD  is  misleading  since  the  total  weighted  value  returned  by calcTotalValue()  is  in  the  underlying.  Note  that  it  has  to  be  in  the  underlying  for  the  calculation hf = (twvUSD * PERCENTAGE_FACTOR) / borrowAmountWithInterest to be correct.    twvUSD was renamed into twv.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.6   Free Flashloan upon Open/Close",
        "body": "   introduced a protection which prevents free flashloans by increasing/decreasing debt within the same multicall. A variable within _multicall() tracks whether debt has already been increased in this call and if true prevents reducing debt.  This prevention however is not effective in a corner case:   When  a  new  credit  account  has  just  been  opened  through  openCreditAccountMulticall()  debt can be reduced within the multicall (free flashloan).  Gearbox Protocol - Gearbox V2 -   18  CorrectnessLowVersion3CodeCorrectedDesignLowVersion2CodeCorrectedVersion2                \f  The  internal  variable  tracking  whether  debt  has  already  been  increased  is  now  an  additional  input parameter for _multicall(). This allows the calling function openCreditAccountMulticall() to pass the information that debt has already been increased and hence the prevention also works in this corner case described in the issue above.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.7   Adapters Ignore User Input",
        "body": "  The design of the Adapters is that they implement the same interface as the contract they connect to.  Illustrated  with  the  following  examples  taken  from  the  YearnV2  adapter  this  issue  highlights  that  user inputs are sometimes silently ignored:  /// @dev Deposit credit account tokens to Yearn /// @param amount in tokens function deposit(uint256 amount, address)     external     override     nonReentrant     returns (uint256) {     address creditAccount = creditManager.getCreditAccountOrRevert(         msg.sender     ); // F:[AYV2-4]      return _deposit(creditAccount, amount); // F:[AYV2-7,12] }  deposit() allows the user to specify the address of the recipient of the yVault shares. Obviously, this is not allowed as the funds must remain with the CreditAccount. The implementation uses \"safe defaults\", and ignores the user input. This behavior should be documented.  A more critical example is function withdraw and parameter maxLoss. The user may intend to set the acceptable maxLoss to a lower value. The implementation of the adapter however ignores this value and proceeds with the default. The result may be unexpected for the user.  function withdraw(     uint256 maxShares,     address,     uint256 maxLoss ) public override nonReentrant returns (uint256 shares) {     address creditAccount = creditManager.getCreditAccountOrRevert(         msg.sender     ); // F:[AYV2-4]      return _withdraw(creditAccount, maxShares); // F:[AYV2-9,14] }  Gearbox Protocol - Gearbox V2 -   19  DesignLowVersion1CodeCorrected        \f  There  is  now  a  withdraw()  override  that  correctly  passes  maxLoss  to  the  corresponding withdraw(uint256,address,uint256)  internal function  _withdrawMaxLoss function.  the  Yearn  vault,  using  an   in   Note: There are other adapter functions where the inputs are ignored - this happens in 2 cases:   The  adapter  passes  unmodified  msg.data  to  the  target  contract,  and  doesn\u2019t  need  some  of  the  inputs for adapter-specific operations;   The  input  is  the  recipient  address,  which  is  always  replaced  by  the  credit  account  address  (same  cases as the deposit(uint256,address) function described in the original issue).  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.8   Add Token Without Liquidation Threshold",
        "body": "  Configurators may add a token to a credit manager using the function addTokenAllowedList. Initially, this token has a liquidation threshold of zero, the configurator must set a liquidation threshold using the function setLiquidationThreshold.  When no liquidation threshold is set for a token, the balance of this token that the credit accounts hold doesn't count towards the weighted value.    The  function  in  question  is  now  called  CreditConfigurator.addCollateralToken().  It  now accepts  uint16  liquidationThreshold  as  input  and  calls  _setLiquidationThreshold() immediately after adding the token. _setLiquidationThreshold() checks that the passed LT value is larger than 0.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.9   Checking for Valid Token Indices for Curve",
        "body": " Pools Is Too Loose  When translating the token index required in Curve pools to the token as known to Gearbox, the following require is executed:  function _get_token(int128 i) internal view returns (address) {     require(i <= int128(uint128(N_COINS)), \"Incorrect index\");     return (i == 0) ? token0 : token1; }  This  check  passes  for  invalid  values  like  negative  indices  and  exactly  one  index  too  high,  e.g.  i  =  2 passes for pools with N_COINS = 2 like in this example, although only i = 0 and i = 1 should pass. While  in  our  understanding  Curve  will  fail  when  called  with  invalid  tokens,  it  is  safer  to  ensure  that  no wrong token indices can be passed to not have to rely on Curve preventing execution with those indices.    Gearbox Protocol - Gearbox V2 -   20  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \fThe code has been refactored, the __getToken() function in CurveV1AdapterBase is strict and reverts for invalid indices.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.10   Credit Accounts Give Very High Approval to",
        "body": " Contract  Credit accounts give very high (25% of uint96.max) approval to the contracts adapters connect to. This approval remains even when the credit account is returned to the factory or being assigned to the next user.  Giving  excess  approvals  introduces  a  risk:  The  third  party  system  must  be  fully  trusted  and reviewed  that  these  approvals  cannot  be  accessed  when  not  called  by  the  holder  of  the  funds.  If  this does not hold, e.g. due to a bug, the funds of credit accounts are at risk.  One  https://medium.com/gelato-network/sorbet-finance-vulnerability-post-mortem-6f8fba78f109  example   where   such   loss   bug   led   to   a   of   funds:  Gearbox uses a trust-minimized approach by validating effects of adapters for token transfers instead of relying on correct execution. The recently discovered UniswapV3 bug would also have been prevented in case targeted allowances are given. Infinite approvals can undermine this approach. Approving only the necessary  funds  each  time  also  saves  gas  as  the  increased  allowance  is  reset  to  the  original  value, resulting in a refund which is significantly larger than the overhead cost of calling into a \"hot\" contract.    Gearbox Protocol responded:  For more fine-grained security configuration, there are now 2 allowance models:  1. Max allowance For highly-trusted protocols (such as Curve or Uniswap) approvals are always set to  type(uint256).max.  For  swap-like  operations  the AbstractAdapter._executeMaxAllowanceFastCheck()  function.  After  each  operation,  the system  returns  allowance  to  the  maximal  possible  value.  This  significantly  improves  UX  for WalletConnect usage, since users wouldn\u2019t have  is  encapsulated   logic   this   in   to approve tokens in the Uniswap/Curve interface after each transaction.  2.  Limited  allowance  For  other  protocols,  approvals  are  set  to  the  available  balance  on  the  Credit Account  before  the  operation,  and  then  reset  to  1  in  the  end.  This  would  prevent  an  attacker  from withdrawing assets from Credit Accounts, if they manage to compromise the target contracts.  and   safe   fastCheck  Maximal  AbstractAdapter._executeMaxAllowanceFastCheck()  AbstractAdapter._safeExecuteFastCheck(),  fullCollateralCheck operations have to be done manually within adapter functions.  respectively.   allowances   operations   for   are   set   Allowances   in and for  This mitigation still allowed to be circumvented in the following way:  The limited allowance approach for semi-trusted third-party contracts might be circumvented: Using CreditFacade.approve() the current owner of a credit contract may approve a supported token for any supported target contract. Such an approval remains when the credit account is returned to the factory and still exists when the credit account is assigned to the next user.  Gearbox Protocol further improved the security in the following way:  In order to improve the security of the CreditFacade.approve() function, upgradeableContracts was added  to  the  Credit  Facade.  This  is  a  list  of  contracts  with  practices  potentially  detrimental  to  Gearbox Protocol - Gearbox V2 -   21  SecurityLowVersion1CodeCorrected        \fsecurity.  This  includes  upgradeable  contracts,  contracts  that  can  make  arbitrary  calls  (even  with admin-only access), etc.  approve  now  reverts  when  called  on  a  contract  in  upgradeableContracts.  Currently,  the  Gearbox team  intends  to  include  only  Lido  into  the  list,  as  no  other  supported  contracts  appear  to  be upgradeable, or able to call transferFrom on CA assets.  To additionally secure assets accounts that don't belong to the attacker but have allowances (e.g., some non-zero allowances may remain after previous use), the first iteration of the Universal Adapter was implemented, which allows users to revoke all allowances on a newly-opened account.  Note:  CreditFacade.approve  is  mainly  used  to  support  WalletConnect  with  dApp  frontends.  Most frontends require non-zero allowance of a token to the contract, and do not allow any further action before  approve  is  called.  Thus,  a  function  to  set  allowance  separately  from  adapter  actions  is required.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.11   CreditAccount Calls approve() on",
        "body": " Unsupported Token  CreditManager.approveCreditAccount() approves token transfers on behalf of a credit account. The function calls the CreditAccount which then executes a call to the given tokens approve() function.  The function is annotated with:  /// @dev Approve tokens for credit account. Restricted for adapters only  Note that the comment is incorrect as it can also be called by the CreditFacade.  While  CreditFacade.approve()  does  check  whether  the  token  to  be  approved  is  supported,  the adapters  generally  do  not  check  this.  CreditManager.approveCreditAccount()  itself  does  not perform such a check on the given token address.  The lack of token validation may be used in an exploit.  Note the following should also be taken into account:   CreditAccounts  may  receive  other  tokens  e.g.  as  an  airdrop.  How  should  users  be  able  to  access/trade them?   A token may have been \"forbidden\". Does this only apply to a new incoming asset or does this also  block usage as an outgoing asset?    Token being supported is now checked in CreditManager.approveCreditAccount(). This means that the token will be verified regardless of whether the call comes from the CreditFacade or an adapter.  On additional notes:  CreditFacade  now  has  an  enableToken()  function  which  allows  the  Credit  Account  owner  to  enable any  token  and  include  it  in  the  collateral  computation,  as  long  as  this  token  is  supported  by  the  Credit Manager and is not forbidden. This can be used to handle airdropped tokens.  Whether  the  token  is  forbidden  is  only  checked  when  a  new  token  comes  in  and  is  being  enabled  (in CreditManager.checkAndEnableToken()). Whether an outgoing token is forbidden is not checked. This is  Gearbox Protocol - Gearbox V2 -   22  SecurityLowVersion1CodeCorrected        \fdeliberately done in order to allow positions in a forbidden token to be unwound after it was forbidden, by selling the token on Uniswap, closing/liquidating the account, etc.  outdated: annotation  The  /// @dev Approve tokens for credit account. Restricted for adapters only. The CreditFacade is also eligible to call this function.  function   is   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.12   Curve Registry",
        "body": "  The factory contract CurveLPFactory which deploys the curve price feeds has the address of the Curve registry hardcoded. Similarly, CurveV1_Base uses the hardcoded address.  According to the Curve Documentation of their registry contracts, the central source of truth in the Curve system  is  the  address  provider.  That  contract  allows  changing  the  registry  through  set_address() when the id parameter is set to zero. Currently, the oracle stores the registry as an immutable. Hence, in case the registry changes, the contract will utilize a wrong registry.    The Curve Registry is no longer used either by the price feeds or CurveV1_Base and hence this issue no longer applies.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.13   CurveV1 Adapters: TokenOut Might Not Be",
        "body": " Enabled at CreditAccount  The  implementation  of  the  CurveV1_2/3/4  adapters  bears  the  risk  that  after  a  successful  action,  the incoming tokens might not be enabled at the CreditAccount.  Consider the following function:  function remove_liquidity(     uint256 amount,     uint256[N_COINS] memory min_amounts ) external virtual nonReentrant {     address creditAccount = creditManager.getCreditAccountOrRevert(         msg.sender     ); // F:[ACV1_2-3]      _enable_tokens(creditAccount, min_amounts);     _executeFullCheck(creditAccount, msg.data); //F:[ACV1_2-5,6] }  Parameter  min_amounts  serves  as  slippage  protection.  The  adapter  uses  it  to  enable  the  incoming tokens using the internal _enable_tokens function:  function _enable_tokens(     address creditAccount,     uint256[N_COINS] memory amounts ) internal {  Gearbox Protocol - Gearbox V2 -   23  CorrectnessLowVersion1CodeCorrectedSecurityLowVersion1CodeCorrected                \f    if (amounts[0] > 1) {         creditManager.checkAndEnableToken(creditAccount, token0); //F:[ACV1_2-5,6]     }      if (amounts[1] > 1) {         creditManager.checkAndEnableToken(creditAccount, token1); //F:[ACV1_2-5,6]     } }  If  the  user  didn't  set  the  slippage  protection  (which  shouldn't  be  done  as  it  makes  the  transaction vulnerable to being sandwiched, resulting in worse exchange rates) the token might not be enabled in the credit account. This may remain undetected when the remaining assets at the credit account suffice to reach  a  health  factor  >  1.  Closing  such  a  credit  account  likely  leaves  those  tokens  behind  and  a  later borrower who realizes this could collect them. Also, if such a credit account becomes unhealthy and is liquidated, a liquidator could collect the tokens.    The function now enables all tokens of the pool, regardless of the min_amounts array. This is correct, since remove_liquidity() transfers tokens based on the current inventory of the pool, so there are only two scenarios in which it can return less than 2 tokens:  the user burns a very small amount of the LP token;  the pool is 100% unbalanced, which should not be practically achievable in Curve.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.14   Duplicate Error Code Used",
        "body": "  The library Errors contains error messages encoded as short strings to save on deployment cost and two  distinct  errors, contract  CC_INCORRECT_TOKEN_CONTRACT  and  CM_TOKEN_IS_ALREADY_ADDED,  which  prevents  users  from exactly determining the cause of the error.  size.  One  of   the  error   is  used   \"CFH\",   codes,   for     Text errors are being replaced with explicit Exceptions that are now being thrown on errors or constraint with in  violations.  IErrors.IncorrectTokenContractException  and ICreditManagerV2Exceptions.TokenAlreadyAddedException.  particular,   replaced   question   errors   were   In   In  the  current  version  of  the  code  the  library  Errors.sol  is  still  imported  and  used  by  several  system contracts, the duplicate error described above however has been corrected.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.15   Incorrect Comment After Refactoring",
        "body": "  in  CreditManager.manageDebt  mentions   function  sometimes  shifts A  comment  newBorrowedAmount. This comment refers to a previous version of the code and isn't describing the current system.  that   the   Gearbox Protocol - Gearbox V2 -   24  DesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                  \f  The comment has been removed  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.16   Incorrect Descriptions",
        "body": "  PriceOracle:   The  function  description  of  addPriceFeed  in  both  the  contract  and  the  interface  definition  incorrectly mentions Eth  /// @param priceFeed Address of chainlink price feed token => Eth  In GearboxV2 the Chainlink pricefeed used is supposed to return a value in USD.  the return value in convertedToUSD() is incorrectly described as:  /// @return Amount converted to tokenTo asset  the  description  for  parameter  token  should  read  to  instead  of  from  in  the  convertFromUSD()` function   The description of fastCheck() is incorrect.   Not all functions in the interface are annotated.  CreditFacade:   The  description  of  both  functions  closeCreditAccount  and  liquidateCreditAccount  mention the outdated sendAllAssets.  CreditManager:   fastCollateralCheck still mentions WETH instead of USD   closeCreditAccount description mentions if sendAllAssets is true, this no longer exists.  Specification changed:  The aforementioned description issues have been rectified.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.17   Outdated Function Description",
        "body": "  There are frequent cases in which comments refer to previous functionality in the code which now has been  changed.  As  an  example,  the  description  of  function  closeCreditAccount  in  both  contracts, CreditFacade  and  CreditManager  describe  sendAllAssets  which  no  longer  exists.  Similarly  this applies  to  the  function  liquidateCreditAccount  of  the  CreditFacade  in  which  skipTokenMask allows this behavior now. .  Gearbox Protocol - Gearbox V2 -   25  CorrectnessLowVersion1Speci\ufb01cationChangedCorrectnessLowVersion1Speci\ufb01cationChanged                  \fSpecification changed:  Function annotations have been brought up-to-date.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.18   PriceOracle: Unused Timestamp",
        "body": "  function _getPrice(address token) internal view returns (uint256) {     require(         priceFeeds[token] != address(0),         Errors.PO_PRICE_FEED_DOESNT_EXIST     );      (         ,         //uint80 roundID,         int256 price, //uint startedAt, , //uint80 answeredInRound         ,         uint256 timeStamp,      ) = AggregatorV3Interface(priceFeeds[token]).latestRoundData();      return uint256(price); }  }  latestRoundData()  returns  several  values,  all  unused  values  except  timesTamp  are  dropped.  The value for timeStamp is handled but remains unused.    PriceOracle.getPrice()  now  uses  roundId,  answer,  updatedAt  and  answereInRound  to perform sanity checks on round data. The unused startedAt value is dropped.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.19   Read-only Reentrancy",
        "body": "  When  integrating  with  Gearbox,  developers  should  be  aware  of  read-only  reentrancy  opportunities. Assume a credit account (CA) which is controlled by a protocol (P) integrating with Gearbox and holds WETH, and a malicious user (E). Assume now that at some point the account becomes liquidatable:   E liquidates the account by calling CreditFacade.liquidateCreditAccount where the to  address is a smart contract controlled by E and convertWETH is true.   During  closure,  CreditManager.closeCreditAccount  is  called,  which  converts  WETH  to  ETH and sends it to to as seen in the following snippet:  Gearbox Protocol - Gearbox V2 -   26  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \f_transferAssetsTo(creditAccount, to, convertWETH, enabledTokensMask);   At this point, the control of the execution flow is passed to the smart contract of to address.   The smart contract makes a call to P which queries the state of CA. CA will seem like it holds less value than it actually used to at the beginning of the transaction. The reason is that its state hasn't been fully updated but part of its holdings has been sent to another address.   Based  on  this  intermediate  state  of  the  CA,  P  might  proceed  incorrectly  and  end  up  in  an  unexpected state.    The line ` delete creditAccounts[borrower]; // F:[CM-9] ` was moved to the beginning of the function, right after the Credit Account for the borrower is first retrieved. This will make any calls to CreditManager.getCreditAccountOrRevert() in the middle of closeCreditAccount execution fail, since the record no longer exists in the mapping.  While  third-party  protocols  that  directly  query  the  state  through  a  saved  CA  address  may  still  be vulnerable, we will advise all integrators to use CreditManager.getCreditAccountOrRevert() to retrieve the address dynamically, as a security best practice.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.20   Redundant Event Emission",
        "body": "  When CreditFacade._disableToken is called, a TokenDisabled event is emitted even if the token was already disabled.    CreditManager.disableToken()  now  returns  whether  the  token  was  actually  disabled.  This  is  used  in CreditFacade._disableToken() to emit the event conditionally.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.21   Redundant Initialization",
        "body": "  In CreditConfigurator.constructor the following line can be found:  creditManager.upgradePriceOracle(address(creditManager.priceOracle())); // F:[CC-1]  This line upgrades the price oracle of the CreditManager with the same price oracle. Hence, this call is redundant.    The line has been deleted.  Gearbox Protocol - Gearbox V2 -   27  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                  \f7.22   Reentrancy Into CreditFacade  The new CreditFacade featuring the new multicall functionality allows executing multiple actions including calls  to  the  adapters.  A  health  check  of  the  credit  account  is  only  done  once  after  all  calls  have  been executed,  not  in  between  calls.  In  between  calls  credit  accounts  may  be  in  an  unhealthy  state.  The internal  multicall  function  of  CreditFacade  itself  is  not  protected  against  reentrancy,  nor  are  some functions  of  the  CreditFacade  using  this  multicall  functionality.  Reentrancy  protection  is  present  in  the called  adapter  and  during  the  execution  of  certain  functions  of  the  CreditManager.  Note  that  the reentrancy  protection  used  works  per  contract:  Reentrancy  into  the  specific  contract  is  locked  at  the beginning of the function and the lock is released when the function call completes.  Aside  from  certain  functions  of  the  CreditFacade  itself  (which  are  handled  differently),  multicall  allows calling any function on external contracts which are valid adapters.  Furthermore, note that attacks are limited as credit account cannot be returned in the very same block it has been borrowed.  Nevertheless, extra care should be taken especially as untrusted code can be reached via the adapters. It might be more cautious to prevent reentrancy into the CreditFacade as this is not intended to be done.  Code corrected and Acknowledged:  All  remaining  non-restricted  CreditFacade  functions  have  been  covered  with  a  nonReentrant  modifier. This ensures that:   At most one multicall can be performed within a single transaction (internal _multicall() can only be  called from non-reentrant functions);   Only one of debt-managing functions (addCollateral, increaseDebt and decreaseDebt) can be called externally  within  a  single  transaction  (internal  counterparts  can  be  called  multiple  times  within  a multicall, barring flash loan protections).  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.23   Sanity Check of New Pricefeed",
        "body": "  PriceOracle._addPriceFeed() contains the following sanity check:  require(     AggregatorV3Interface(priceFeed).decimals() == 8,     Errors.PO_AGGREGATOR_DECIMALS_SHOULD_BE_8 ); // F:[PO-2]  This check helps to ensure that the intended kind of pricefeeds returning a price with 8 decimal is passed, which USD-denominated Chainlink pricefeeds do.  The  sanity  check  could  be  enhanced  to  check  if  the  pricefeed  actually  implements  the  required functionality of the AggregatorV3Interface, notably whether function latestRoundData is implemented which is the function called by the PriceOracle to query the price.    _addPriceFeed() now performs extensive sanity checks on the newly added feed and token:  Gearbox Protocol - Gearbox V2 -   28  SecurityLowVersion1AcknowledgedCodeCorrectedDesignLowVersion1CodeCorrected                \fChecks that neither feed nor token are zero addresses; Checks that the token is a contract; Checks that the  price  feed  is  a  contract;  Checks  that  the  token  implements  decimals();  Checks  that  the  feed implements decimals() and it is equal to 8; Checks that the feed implements dependsOnAddress(); Checks  implements latestRoundData() (and performs sanity checks on the answer if skipPriceCheck() == false);  implements  skipPriceCheck();  Checks   feed   feed   that   that   the   the   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.24   Unused allowedContractsSet",
        "body": "  EnumerableSet.AddressSet  private  allowedContractsSet;  defined  in  the  CreditFacade  is unused. The very same variable exists in the CreditConfigurator where it actually is used.    Removed unused variable and corresponding getters.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.25   YearnV2Adapter: Different Behavior of",
        "body": " Functions  Functions  transfer  and  transferFrom  approve() however behaves differently simply returns true.  revert  with  Errors.NOT_IMPLEMENTED.  Function    approve(),  transfer()  and  transferFrom()  of  the  YearnV2Adapter  now  return  false  without doing anything.  Gearbox Protocol - Gearbox V2 -   29  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Airdrops",
        "body": "  CreditAccounts may be eligible for airdrops, e.g. as they may have held a certain token when a snapshot was taken or as they may have interacted with a DeFi system a certain amount of times.  Users of a credit account must be aware that they lose participation in the airdrop when they return the credit account (close/liquidation).  At the moment when the information about an airdrop becomes public, this credit account may be in use or in the queue at the factory.  Depending on the value of the airdrop users may attempt to retrieve this credit account. The governance has the option to take out such accounts directly. Generally, airdrops can only be claimed by the credit account if this process can be triggered by a third party. Airdrops requiring the credit account to call a specific function generally won't work as no adapter supporting this exists.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Free Flashloans",
        "body": "  Gearbox prevents users from increasing and decreasing their debt during a multicall and thus taking a free  flashloan.  However,  a  user  could  still  create  a  contract  that  executes  two  separate  multicalls,  one that  includes  a  debt  increase  and  one  that  includes  a  debt  decrease.  This  way,  a  free  loan  is  still possible.  It  is  important  to  note  that  the  amount  to  be  borrowed  during  the  loan  is  still  limited  by  the checks performed when an amount is borrowed from the pool.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.3   Renouncing Ownership",
        "body": "  In  Gearbox,  transfers  of  ownership  take  place  in  two  steps.  First,  the  previous  owner  defines  the  new owner  (pendingOwner)  and  the  new  owner  claims  the  ownership.  The  Claimable  contract  extends Ownable  meaning  that  the  old  owner  can  renounce  ownership.  Users  should  note  that  ownership renounce is ignored if a pending owner has been already defined since Claimable.claimOwnership does not check if the ownership has been renounced before.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.4   _safeTokenTransfer - Call to External",
        "body": " Address  When the boolean parameter convertToETH is set to true, WETH is unwrapped into Ether. This Ether is transferred  to  the  recipient  using  a  call,  the  gas  amount  passed  is  not  restricted.  At  this  point,  the execution may reach untrusted code.  Gearbox Protocol - Gearbox V2 -   30  NoteVersion1NoteVersion1NoteVersion1NoteVersion1              \fThe function name \"safeTokenTransfer\" is due to the usage of OpenZeppelins SafeERC20 library. One must be careful to not misinterpret the function name and assume using this function is \"safe\" under all circumstances.  Gearbox Protocol - Gearbox V2 -   31  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Broken Integration With Special ERC20",
        "body": " Tokens  OFT  does  not  integrate  well  with  ERC20  tokens  that  have  special  behavior,  such  as  transferring  less tokens  than  the  specified  amount.  One  concrete  example  of  such  tokens  is  cUSDCv3.  This  token transfers  the  current  balance  of  a  user  when  type(uint256).max  is  passed  as  amount,  instead  of reverting. Since cUSDCv3 also uses 6 decimals (same as default shared decimals), there is a possibility of exploiting an OFT if deployed for this token.  CS-LZOFT-001  An attacker could perform the following steps:  1. Ensure a non-zero balance of cUSDCv3 in the source chain.  tries   2. Trigger a call to OFTCore.send() with amountToSendLD set to the maximum uint256. Function _debit()  from  attacker,  however  because  of amountToSendLD = type(uint256).max, the token will transfer only the existing balance of attacker. Given that cUSDCv3 uses 6 decimals, no dust is removed, and the shared amount send to the destination chain is max uint64.  input  amount   to  pull   the   3. On the destination chain, the OFT mints the maximum amount to the attacker.  Acknowledged:  LayerZero acknowledged the issue, and has added new comments to warn developers about these risks:  LayerZero - OFT/OApp -   11  SecurityDesignCorrectnessCriticalHighMediumAcknowledgedLowAcknowledgedAcknowledgedAcknowledgedSecurityMediumVersion1Acknowledged           \f@dev WARNING: The default OFTAdapter implementation assumes LOSSLESS transfers, ie. 1 token in, 1 token out. IF the 'innerToken' applies something like a transfer fee, the default will NOT work... a pre/post balance check will need to be done to calculate the amountToCreditLD/amountReceived.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Missing Event for New Delegatee",
        "body": "  The new function EndpointV2.setDelegate in  emitted in the OAppCore constructor when endpoint.setDelegate() is initially called.   does not emit an event. Similarly, no event is  It is recommended to emit events for important state updates and index the relevant parameters to allow integrators and dApps to quickly search for these and simplify UIs.  CS-LZOFT-010  Acknowledged:  LayerZero is aware about the missing event but has decided to keep the code unchanged.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   Unsafe Casting in _toSD",
        "body": "  The function OFTCore._toSD casts unsafely a uint256 into uint64:  function _toSD(uint256 _amountLD) internal view virtual returns (uint64 amountSD) {     return uint64(_amountLD / decimalConversionRate); }  If  the  result  of  _amountLD  /  decimalConversionRate  is  equal  or  larger  than  2**64,  the  most significant bits are lost.  CS-LZOFT-005  Acknowledged:  LayerZero  has  acknowledged  the  issue  but  has  decided  to  keep  the  unsafe  casting  unchanged.  The following description has been added for function OFTCore.sharedDecimals:  @dev Sets an implicit cap on the amount of tokens, over uint64.max() will need some sort of outbound cap / totalSupply cap Lowest common decimal denominator between chains. Defaults to 6 decimal places to provide up to 18,446,744,073,709.551615 units (max uint64). For tokens exceeding this totalSupply(), they will need to override the sharedDecimals function with something smaller. ie. 4 sharedDecimals would be 1,844,674,407,370,955.1615  Developers should be aware that the maximum total supply should be limited by uint64 for OFT tokens (or  the  inner  token  of  an  OFTAdaptor).  However,  it  is  important  to  notice  that  if  this  constrain  is  not  LayerZero - OFT/OApp -   12  DesignLowVersion2AcknowledgedVersion2DesignLowVersion1Acknowledged                \frespected by the developers, this unsafe casting can lead to funds being burned (or locked) in the source chain without an equivalent amount being minted on the destination chain.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.4   Update of lzToken",
        "body": "  Users  specify  the  amount  _lzTokenFee  they  pay  when  sending  a  transaction.  However,  if  owner  of EndpointV2 calls setLzToken to update the lzToken before the transaction is executed, users would pay the same amount in the new token (assuming the allowance is provided).  CS-LZOFT-011  Acknowledged:  LayerZero  has  acknowledged  the  issue,  and  has  decided  to  keep  the  code  unchanged  in  . LayerZero stated that in future versions a timelock will be used to inform users ahead of time in case of a token switch.  LayerZero - OFT/OApp -   13  SecurityLowVersion1AcknowledgedVersion2          \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings   Limited Documentation and Specifications   -Severity Findings   Commented Code and Remaining ToDos    OFT Does Not Refund Excess Fees    Type Check for User Provided Options   Informational Findings  Inconsistent Solidity Compiler Version in IOAppReceiver   0  0  1  3  1  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Limited Documentation and Specifications",
        "body": "  The  codebase  lacks  proper  documentation  and  inline  code  specifications  that  clearly  explain  pre/post conditions  of  functions  and  their  expected  behavior.  Complete  documentation  and  specifications  are important  for  OFT  and  OApp  contracts  because  other  developers  will  extend  them  and  the documentation/specifications  are  essential  to  reduce  the  likelihood  of  introducing  vulnerabilities  in  the derived contracts.  CS-LZOFT-002    LayerZero has extended significantly inline specifications for the contracts in scope of this review.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Commented Code and Remaining ToDos",
        "body": "  Commented out code is present in the contract OAppPreCrimeSimulator. Also, several ToDo notes are present in the codebase. Removing commented code and addressing remaining notes help improve the quality and readability of the code.  CS-LZOFT-003    LayerZero - OFT/OApp -   14  CriticalHighMediumCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCorrectnessMediumVersion1CodeCorrectedDesignLowVersion1CodeCorrected                 \fLayerZero has removed commented-out code and ToDos in   .  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   OFT Does Not Refund Excess Fees",
        "body": "  Users  call  the  function  OFTCore.send  to  trigger  an  omnichain  operation.  The  function  send()  is payable  and  users  are  expected  to  send  enough  Ether  to  cover  for  the  native  fee.  The  function _payNative  caps  the  msg.value  to  the  amount  of  native  fee,  hence  the  diff  amount  between msg.value and _fee.nativeFee is not forwarded to the endpoint:  function _payNative(uint _nativeFee) internal virtual returns (uint256 nativeFee) {     if (msg.value < _nativeFee) revert NotEnoughNative(msg.value);     return _nativeFee; }  CS-LZOFT-004  The returned value is then forwarded to the endpoint:  uint256 messageValue = _payNative(_fee.nativeFee); ...  return     endpoint.send{ value: messageValue }(...);  However, if the user sends more Ether than nativeFee, the excess amount is locked.  Note that, if the nativeFee is higher than actual fee charged by the endpoint, the excess amount will be refunded.    LayerZero  has  changed  the  function  OAppSender._payNative  such  that  it  checks  that  msg.value  is exactly equal to _fee._nativeFee:  function _payNative(uint256 _nativeFee) internal virtual returns (uint256 nativeFee) {     if (msg.value != _nativeFee) revert NotEnoughNative(msg.value);     return _nativeFee; }  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Type Check for User Provided Options",
        "body": "  The  function  OAppOptionsType3.setEnforcedOptions  validates  that  options  provided  by  the owner are of type 3:  CS-LZOFT-014  uint16 optionsType = uint16(bytes2(_enforcedOptions[i].options[0:2])); // enforced not supported for options type 1 and 2 if (optionsType != OPTION_TYPE_3) revert OptionsTypeInvalid(optionsType);  LayerZero - OFT/OApp -   15  Version2CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \fHowever,  when  combining  owner-provided  options  with  user-provided  options,  function OAppOptionsType3.combineOptions does not check that the user-provided options (_extraData) are of type 3. As a consequence, options of different types may be combined.  the     The  function  OAppOptionsType3.combineOptions  has  been  revised  to  check  the  type  of _extraOptions which are provided by the user when they are combined with enforced options. User options could be of legacy type (type 1 or 2) if there are no enforced options:  // No enforced options, pass whatever the caller supplied, even if it's empty or     legacy type 1/2 options. if (enforced.length == 0) return _extraOptions;  ...  // @dev If caller provided _extraOptions, must be type 3 as its the ONLY type that can be combined. if (_extraOptions.length >= 2) {     _assertOptionsType3(_extraOptions);     .... }  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Inconsistent Solidity Compiler Version in",
        "body": " IOAppReceiver  In  IOAppReceiver still presents the previous compiler version (^0.8.22).  , the Solidity compiler version for all files in scope was set to ^0.8.20. However, the contract  CS-LZOFT-012    LayerZero has changed the compiler version pragma in IOAppReceiver to ^0.8.20.  LayerZero - OFT/OApp -   16  InformationalVersion3CodeCorrectedVersion3      \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Floating Pragma for Dependencies",
        "body": "  OFT/OApp uses the floating pragma ^4.8.1 || ^5.0.0 for OpenZeppelin contracts. The constructor of Ownable in versions 4.8.x does not take any argument and owner role is set to the deployer of the contract. However, in version 5.0.0 the implementation has changed and an address should be passed in the constructor. Therefore, developers extending OFT contracts are responsible to use the constructors correctly.  Contracts should be deployed with the dependencies version that were used during testing and auditing. Locking  the  pragma  helps  to  ensure  that  contracts  are  not  accidentally  deployed  using  a  different dependency version and help ensure a reproducible deployment.  CS-LZOFT-006  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Gas Optimizations",
        "body": "  The codebase could be more efficient in terms of gas usage. Reducing the gas costs may improve user experience. Below is an incomplete list of potential gas inefficiencies:  1. The function OAppCore.callEndpoint could be marked as external.  2. The function OFTCore.quoteSend is not called internally, hence potentially could be marked as  CS-LZOFT-007  external.  3. SetConfigParam is imported in file IOAppCore.sol but is not used.  4. The function OAppCore.setDelegate could be marked as external.  Code partially corrected:  The optimizations 1 to 3 in the list above have been applied in   .  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Magic Numbers in Codebase",
        "body": "  Some magic values are used in the codebase mainly for the version of contracts that could be declared as  constant.  For  instance,  function  OFT.oftVersion  returns  the  following  values  (1,  1).  Similarly, OFTAdapter.oftVersion()  returns  magic  values.  Such  values  can  be  replaced  with  constant variables to improve code readability.  CS-LZOFT-008  LayerZero - OFT/OApp -   17  InformationalVersion1InformationalVersion1CodePartiallyCorrectedVersion2InformationalVersion1Acknowledged              \fAcknowledged:  LayerZero has acknowledged the issue and has decided to keep the code unchanged in   .  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   Possible Incorrect Return Value",
        "body": "  The function OAppReceiver.allowInitializePath performs the following check:  function allowInitializePath(Origin calldata origin) public view virtual returns     (bool) {     return peers[origin.srcEid] == origin.sender; }  Note that if origin.sender is 0 (default value) and there is no entry in peers for srcEid, the function returns incorrectly true.  CS-LZOFT-013  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   Solidity Compiler Version",
        "body": "  The  solidity  compiler  is  fixed  to  0.8.22  in  the  config  file  foundry.toml  which  has  been  released recently.  The  new  opcode  PUSH0  has  been  added  since  compiler  version  0.8.20  but  it  is  not  widely supported by other EVM-compatible chains.  Deployers of OFTs are responsible to compile the smart contracts with the correct options for a target chain.  CS-LZOFT-009  LayerZero - OFT/OApp -   18  Version2InformationalVersion2InformationalVersion1        \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Custom OFT Implementation",
        "body": "  Developers can extend the OFT contract and implement custom logic for new functionalities or different behaviors.  The  inline  comment  in  function  OFTAdapter._debitSender()  suggests  that  OFT implementations could also charge fees:  // @dev amountDebited could be 100, with a 10% fee, the credited amount is 90, // so technically the amountToCredit would be locked as outboundAmount  We would like to highlight that contracts extending OFT with new functions or new behaviors should be assessed  carefully.  For  instance,  charging  a  fee  for  OFTs  requires  developers  to  implement  additional functions that transfer such fees outside of the contract.  Furthermore, OFTAdapter does not work with innerToken that have special behaviors, e.g., fees on transfer. Developers should be aware of such behaviors and customize the OFTAdapter to integrate well with such tokens. For instance, function _debitSender() should be overridden if the underlying token charges fees on transfer, as the following comment suggests:  // @dev will need to override this and do balanceBefore, and balanceAfter IF the     innerToken has fees on transfers  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Delegatee Could Be Different From Owner",
        "body": "   to set the delegatee in the local endpoint. The The contract OAppCore added functionality in  delegatee  is  initially  set  to  the  owner  in  the  constructor.  However,  the  codebase  does  not  enforce  that both delegatee and owner are the same address. For instance, transferring ownership of OApp to a new address, does not automatically update the delegatee in endpoint.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.3   Enforcement of Next Nonce",
        "body": "  The contract OAppReceiver declares a virtual function nextNonce that by default returns 0, however derived contracts can override it and implement a custom policy for nonces. Developers of OApps that implement  a  specific  policy  for  nonces  should  enforce  the  policy  by  validating  the  correct  nonce  when messages are received, for example in function _lzReceive.  Note that enforcing a specific policy for nonces increases the possibility of griefing attacks as one can send a transaction that will fail in the destination chain, hence owner of the OApp should skip/clear such transactions.  LayerZero - OFT/OApp -   19  NoteVersion1NoteVersion2Version2NoteVersion1            \f8.4   Failing Transactions on the Destination Chain  The OApp is responsible for implementing the receiving logic such that the incoming transactions do not revert,  however  there  are  cases  when  the  transaction  could  revert  even  if  the  OApp  does  not contemplate  this  possibility.  Whenever  this  happens,  funds  might  be  permanently  locked  in  the  source chain.  A  reason  for  reverting  might  be  in  the  underlying  token,  for  example  implementing  blocklists,  being paused,  or  rejecting  specific  transfer  amount  such  as  0.  For  instance,  if  USDC  is  an  inner  token  of  a OFTAdapter  and  the  recipient  of  a  USDC  transfer  is  in  the  blocklist  on  the  destination  chain,  the transaction will revert.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.5   Limitation on Shared Decimals",
        "body": "  As suggested in the Natspec of the function OFTCore.sharedDecimals, the shared decimals across all chains are capped by the lowest decimals of OFT deployments. For instance, if an OFT is deployed in 3 chains and they use 2, 8, and 18 decimals respectively, the shared decimals is capped at 2. Therefore, messages passed between OFTs with high decimals (8 and 18) use also a precision of 2 decimals.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.6   Precision Loss in Amounts Passed Between",
        "body": " Chains  The amounts shared between chains use type uint64 and limit the precision of values transferred to 6 decimals by default. If a user passes an amount that requires more decimals to be correctly represented, the function _debitView truncates it such that it fits the shared decimals. The rest is considered dust by the system.  For instance, if a user intends to transfer an amount 1.23456789 tokens into another chain, the actual amount transferred will be 1.23456 assuming the default 6 decimals, while the remaining 0.00000789 is considered dust. This dust is accumulated in the contracts OFT, or OFTAdapter, when users transfer tokens  directly  to  the  contract  and  the  respective  function  _debitThis  is  triggered.  The  dust accumulated  in  these  contracts  can  be  transferred  to  another  chain  and  claimed  by  anyone  by  calling OFTCore.send specifying sendParam.amountToSendLD = 0.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.7   Reentrancy Possibility When Sending",
        "body": "  The function OFTCore.send triggers a call in _lzSend() which calls EndpointV2.send(). In case the  user  specifies  a  higher  native  fee  than  the  one  that  will  be  charged  by  the  endpoint,  the  latter refunds the excess amount to the user. This poses a reentrancy possibility as the execution is passed to the _refundAddress specified by the user.  Developers that extend OFT contracts should be aware of this behavior and take measures to address the reentrancy.  LayerZero - OFT/OApp -   20  NoteVersion1NoteVersion1NoteVersion1NoteVersion1              \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   ERC165 Partially Implemented",
        "body": "  0  0  0  1  CS-POLTOKEN-001  contract   AccessControlEnumerable   The  contract PolygonEcosystemToken  that  inherits  AccessControlEnumerable  in  the  codebase  does  not extend  the  implementation  of  ERC165.  ERC165  should  either  return  true  for  all  the  interfaces  the contract implements or be completely disabled.  implements   ERC165   the   but   Acknowledged:  Polygon answered that:  PolygonEcosystemToken is planned to only support AccessControlEnumerable interface and ERC20 Permit but it isn't industry practice for it to extend ERC165 so far.  Polygon - Polygon Token (POL) -   10  DesignCriticalHighMediumLowAcknowledgedDesignLowVersion1Acknowledged           \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings  -Severity Findings   Missing Input Sanitization   Interfaces Are Missing Functions   0  0  0  2  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Missing Input Sanitization",
        "body": "  The respective arguments of the constructors of PolygonMigration and DefaultEmissionManager are not ensured to be non-zero.  CS-POLTOKEN-008    The constructors have been updated to check that the addresses are non-zero.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Interfaces Are Missing Functions",
        "body": "  CS-POLTOKEN-002  Some  of  the  interfaces  are  missing  functions  from  their  implementations  that  could  be  useful  for integrators. Here is a non-exhaustive list:  1. IPolygonEcosystemToken is missing updatePermit2Allowance() and the getter functions  for the storage variables  2. IPolygonMigration  is  missing  getVersion(),  burn(),  and  the  getter  functions  for  the  storage variables  3. IDefaultEmissionManager  is  missing  getVersion(),  inflatedSupplyAfter(),  and  the  getter functions for the storage variables    The interfaces have been updated to expose all relevant functions.  Polygon - Polygon Token (POL) -   11  CriticalHighMediumLowCodeCorrectedCodeCorrectedDesignLowVersion2CodeCorrectedDesignLowVersion1CodeCorrected                   \f6.3   Storage Gap Inconsistency  , the upgradable contracts __gap variables were updated with the intention that exactly 50 In  storage slots are used by each contract. In PolygonMigration, __gap was set to be 48 slots long as the contract contains two storage variables. However, as the storage variables are packed into one slot by the compiler, to have exactly 50 storage slots, __gap should have size 49.  CS-POLTOKEN-009    __gap was updated to have size 49.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Gas Optimizations",
        "body": "  1. In the contract DefaultEmissionManager, the storage variables migration, stakeManager, and  treasury  can  be  set  at  deployment  and  thus  be  immutable.  The  initialization  would  only need to set token. This would allow to reduce the number of SLOAD performed upon minting.  2. In the function DefaultEmissionManager.mint(), the storage variable token can be loaded  in memory to avoid multiple SLOAD.  3. In the contract PolygonMigration, the storage variable matic can be set at deployment and be  immutable, thus saving storage reads.  CS-POLTOKEN-004    All optimizations have been applied.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Inconsistent Event Emission",
        "body": "  In  the  codebase,  events  are  mostly  emitted  before  a  state  change.  However,  the  functions PolygonEcosystemToken._updatePermit2Allowance  and PolygonMigration.updateUnmigrationLock are not following that pattern.  CS-POLTOKEN-005    The two functions have been updated to emit events before performing state changes.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Initializable Is Inherited Twice",
        "body": "  Polygon - Polygon Token (POL) -   12  CS-POLTOKEN-007  InformationalVersion3CodeCorrectedVersion3InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected                      \fThe  contract  DefaultEmissionManager  Ownable2StepUpgradeable. Direct inheritance is not necessary.  inherits  Initializable  directly  and  also   from    The DefaultEmissionManager now only inherits Initializable once.  Polygon - Polygon Token (POL) -   13  \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Emission Manager Owner Has No Purpose",
        "body": "  Although the contract DefaultEmissionManager is ownable and an owner must be given when calling initialize, the owner has no specific permissions and the role is never used in the contract.  CS-POLTOKEN-003  Acknowledged:  Polygon is aware of this and explained that they want to proactively keep Ownable for now.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Planned Emissions Conflict With Supply Cap",
        "body": "  In  the  DefaultEmissionsManager,  the  planned  supply  increase  is  2%  of  the  supply  per  year, compounding.  The  PolygonEcosystemToken  contract  enforces  that  no  more  than  10  tokens  per second can be emitted. After about 22 years and 41 days, the manager will try to mint more tokens than what the cap allows, and the transaction will revert. To resume emissions, admin action will be needed to increase the cap.  CS-POLTOKEN-006  Acknowledged:  Polygon acknowledged and stated:  According to the current plan, it is expected that emissions will stop after 10 years (and hence all fuzz tests are done with a 10-year bound).  Polygon - Polygon Token (POL) -   14  InformationalVersion1AcknowledgedInformationalVersion1Acknowledged          \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Approval Events Do Not Reflect Permit2",
        "body": " Allowance  The  implicit  infinite  allowance  granted  to  the  Permit2  contract  is  invisible  to  applications  that  rely  on Approval() events to track token allowances. Furthermore, when it is enabled or disabled, they will not be notified either since this action raises a different event.  Nothing  can  be  done  on-chain  about  this  since  the  ERC-20  interface  is  not  designed  to  support allowances on behalf of all users.  Polygon - Polygon Token (POL) -   15  NoteVersion1  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   EIP-170 Mix Up / Unlimited Contract Size",
        "body": "  EIP-170 has been introduced into the Ethereum mainnet with the Spurious Dragon hardfork in order to limit the maximum codesize of a contract.  The short specification of the EIP reads:  ... if contract creation initialization returns data with length of more than 0x6000 (2**14 + 2**13) bytes, contract creation fails with an out of gas error.  The data returned by the contract creation initialization is the code of the newly deployed smart contract that will be stored as the code of the smart contract. This is valid regardless wether the contract has been deployed  directly  from  a  transaction  or  a  during  code  execution  of  a  CREATE  /  CREATE2  opcode.  For more details please refer to chapter 7 of the Ethereum Yellowpaper.  The  TxPermissionBased  contract  _deployerInputLengthLimit. There is an annotated function for the owner to set this variable:  the  POSDAO  system  attempts   to  enforce  a  in   /// @dev Sets the limit of `input` transaction field length in bytes /// for contract deployment transaction made by the specified deployer. /// @param _deployer The address of a contract deployer.  POA Network - POSDAO -   15  DesignCorrectnessCriticalHighRiskAcceptedMediumRiskAcceptedAcknowledgedRiskAcceptedAcknowledgedLowAcknowledgedRiskAcceptedAcknowledgedAcknowledgedCorrectnessHighVersion1RiskAccepted            \f/// @param _limit The maximum number of bytes in `input` field of deployment transaction. /// Set it to zero to reset to default 24Kb limit defined by EIP 170.  And inside the _allowedTxTypes function which is annotated with:  /// @dev Defines the allowed transaction types which may be initiated by the specified sender with /// the specified gas price and data. Used by node's engine each time a transaction is about to be /// included into a block.  there is:  if (_to == address(0) && _data.length > deployerInputLengthLimit(_sender)) {     // Don't let to deploy too big contracts     return (NONE, false); }  There is a mixup here: What the TxPermission contract actually limits with this parameter is the lenght of  the  data  field  of  the  transaction,  not  the  limit  of  a  contract's  code  size.  This  has  nothing  to  do  with EIP-170. Hence if the limit is only \"enforced\" by the TxPermission contract and there is no further limit set in the chain specification anyone may deploy a contract of arbitrary size, limited only by the gas limit. EIP-170 is not activated in the template/spec.json chain sepcification file available in the repository.  Note that the Ethereum mainnet has no excplicit limit on the data field of a transaction (called input in the function description in POSDAO). This is only limited by the gas limit of a block.  Ethereum Yellowpaper: https://ethereum.github.io/yellowpaper/paper.pdf EIP-170 Specification: https://github.com/ethereum/EIPs/blob/master/EIPS/eip-170.md  Risk Accepted:  POA Network accepts this risk and states: Some popular projects on xDai require the abi lity to deploy contracts with size greater than 24 Kb. The limit on transacti on size is intended as an easy protection against script kiddies.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Changing Mining and Staking Addresses",
        "body": " While Banned  ValidatorSetAuRa  allows  to  change  the  mining  and  staking  address  while  a  pool  is  banned.  This updates the state, including:  idByStakingAddress[oldStakingAddress] = 0; idByStakingAddress[_newStakingAddress] = poolId;  or  idByMiningAddress[_oldMiningAddress] = 0; idByMiningAddress[_newMiningAddress] = _poolId;  The available specification does not cover this scenario and it remains unclear if this should be possible or not.  POA Network - POSDAO -   16  DesignMediumVersion1RiskAccepted        \fIn case of a change of the mining address while a pool is banned, the return value of following functions may be unexpected for the caller:  /// @dev Returns the block number when the ban will be lifted for the specified mining address. /// @param _miningAddress The mining address of the pool. function bannedUntil(address _miningAddress) public view returns(uint256) {     return _bannedUntil[idByMiningAddress[_miningAddress]]; }  bannedUntil() will return 0 if the mining address of the banned pool has been changed even though the pool is banned.  function isValidatorBanned(address _miningAddress) public view returns(bool) {     uint256 bn = bannedUntil(_miningAddress);     if (bn == 0) {         // Avoid returning `true` for the genesis block         return false;     }     return _getCurrentBlockNumber() <= bn; }  This holds similarly for this function which notably is querried by BlockRewardAuRaBase.reward().  Within the system one such address can only be used once for an unique purpose, e.g. an address that has been a mining or staking address once cannot be reused anymore.  This is tracked by following mappings:  mapping(address => uint256) public hasEverBeenMiningAddress; mapping(address => bool) public hasEverBeenStakingAddress;  The information to which pool the mining address once belonged to is availabe in this mapping.  Risk accepted:  POA Network states this is expected behavior in order to allow pools to change their staking or mining address if they are compromised during the ban period.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Incoherent Event ChangedMiningAddress",
        "body": " Emitted  To change a mining address, changeMiningAddress is called from the participants staking address. If the  participant  is  a  current  validator,  the  change  is  not  done  immediately.  This  emits  the InitiateChange.  Additionally,  the  function  will  always  emit  the  ChangedMiningAddress  event. Given the name of the event and that it is also emitted when the mining address is changed immediately because the participant is not part of the current validator set, this seems incoherent. As the event name suggests, the event should be emitted only when the mining address is changed or maybe renamed.  Acknowledged:  POA  Network  is  aware  that  the  ChangeMiningAddress  event  only  corresponds  to  the  immediate change of the mining address when a pool is not a validator. Unfortunately no events can be emitted at  POA Network - POSDAO -   17  DesignMediumVersion1Acknowledged        \fthe moment of the real change for the delayed case inside the system's finalizeChange function as events cannot be emitted during execution of this system operation.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Limitations of the TxPermissions Contract",
        "body": "  The  _allowedTxTypes  function  of  the  TxPermissions  contract  is  applied  to  all  transactions  to  be include into a block. However this means all checks are only done on external transactions created from externally  owned  accounts,  internal  transactions  (calls  within  transactions)  are  not  subject  to  these checks.  Some of these checks including e.g.  if (validatorSetContract.isValidator(_to)) {     // Validator's mining address can't receive any coins     return (NONE, false); }  can  be  circumvented  by  internal  transaction.  Internal  transactions  are  calls  from  within  bytecode execution, e.g. during execution of a smart contract.  Risk Accepted:  POA  Network  is  aware  that  the  rules  defined  by  the  TxPermissions  contracts  are  only  applied  to transactions of EOAs.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Role Switch Needed",
        "body": "  The  TokenMinter  contract  calls  permissioned  functions.  These  are  mint, setBridgeContract, transferOwnership. To successfully call these functions, the TokenMinter contract needs to be the owner of the ERC677MultiBridgeToken contract.  token  contract   Regarding the setBridgeContract we have opened a separate issue because this call will always fail. But the ERC677MultiBridgeToken contract also implements other functions that are permissioned to be called only by the owner. Given the TokenMinter contract is the owner these functions could not be are:  addBridge,  removeBridge,  setBlockRewardContract, called.  These  setStakingcontract.  functions   To call this functions, the ownership needs to be transferred from the minter contract to an other contract and then back. This seems undesirable.  Acknowledged:  POA Network explains that the TokenMinter contract is used as an intermediate owner contract for the PermittableToken contract wich represents the STAKE token. To clarify this, comments where added to the TokenMinter contract.  POA Network - POSDAO -   18  DesignMediumVersion1RiskAcceptedDesignMediumVersion1Acknowledged                  \f6.6   Gas Inefficiency During Removal From Array  The staking contract keeps track of the pools using multiple arrays. When an entry has to be removed, this is done as in the following example:  uint256 indexToDelete = poolToBeRemovedIndex[_poolId];     if (_poolsToBeRemoved.length > indexToDelete && _poolsToBeRemoved[indexToDelete] == _poolId) {         uint256 lastPool = _poolsToBeRemoved[_poolsToBeRemoved.length - 1];         _poolsToBeRemoved[indexToDelete] = lastPool;         poolToBeRemovedIndex[lastPool] = indexToDelete;         poolToBeRemovedIndex[_poolId] = 0;         _poolsToBeRemoved.length--;     }  In case that the removed entry was already last in the list two SSTORE and one SLOAD operation could have been skipped.  Acknowledged:  Client states that this operation is quiet rare and, hence, will not change the implementation.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Inconsistent Use of Safemath",
        "body": "  The code has multiple calculations including multiplications and divisions without safemath. Even though we  could  not  find  a  place  where  we  think  calculation  would  over  or  underflow,  the  consistent  use  of safemath would ensure this.  Risk accepted:  Safe math was not used intentionally in critical functions to not cause reverts and risk a network break down. Hence, POA network accepted the risk.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   Potentially Compromised Key Needed to",
        "body": " Change Key  To change a potentially compromised staking key, the staking key is needed. Even though, the mining key is not used for tasks like key changes, in this case it might make sense from a security perspective. One reason to change a key is that it might be corrupted. In this case, it might be safer to use an other already existing key to change it.  Acknowledged:  POA network wants to keep the strong separation regarding the key usage.  POA Network - POSDAO -   19  DesignLowVersion1AcknowledgedDesignLowVersion1RiskAcceptedDesignLowVersion1Acknowledged                        \f6.9   Superfluous Call of  _finalizeNewValidators  changeMiningAddress sets _finalizeValidators.list to the unedited _pendingValidators. In  finalizeChange  triggers _finalizeNewValidators.  _finalizeNewValidators  first  removes  all  validators  and  then  adds the same. This seems unnecessary. Additionally, the comment suggest another use case for the else if.  true  and   the  else   condition   to  be   causes   this   if   Acknowledged:  POA network acknowledged the issue but decided to leave the code unchanged.  POA Network - POSDAO -   20  DesignLowVersion1Acknowledged        \f7   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  0  0  3  7  -Severity Findings  -Severity Findings  -Severity Findings   Failing Function Call    No Canonical Definition of Calldata for onTokenTransfer    claimOrderedWithdraw Not Always Successful   -Severity Findings  Incorrect Comment in finalizeChange   Incorrect Description    Make onTokenTransfer() External    Multiplication After Division    No Indexed Fields for ReportedMalicious    Unchecked Return Value of Transfer    certify Missing Sanity Check   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Failing Function Call",
        "body": "  The  TokenMinter  contract  implements  the  function  setBridgeContract  which  should  call tokenContract.setBridgeContract.  The  setBridgeContract  function  does  not  exists  in  the ERC677MultiBridgeToken contract. Hence, the function call would fail and the interface definition at the beginning is incorrect.  Specification changed:  POA Network explains that the TokenMinter contract is used as an intermediate owner contract for the PermittableToken contract wich represents the STAKE token. To clarify this, comments where added to the TokenMinter contract.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   No Canonical Definition of Calldata for ",
        "body": " onTokenTransfer  POA Network - POSDAO -   21  CriticalHighMediumSpeci\ufb01cationChangedSpeci\ufb01cationChangedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedDesignMediumVersion1Speci\ufb01cationChangedCorrectnessMediumVersion1Speci\ufb01cationChanged                  \fThe function onTokenTransfer uses inline assembly to read the receiver and calldata from the calldata arguments.  The  assembly  strongly  relies  on  some  assumptions  about  the  argument  encoding  of  the Solidity.  One  of  them  is  that  there  are  no  \"garbage  bits\"  between  the  byte  offset  of  the bytes  calldata  _data  variable  and  the  length  field  of  the  bytes  calldata  _data  argument. This  assumption  will  hold  true  in  most  cases,  but  is  not  guaranteed  to  hold.  This  assumption  can  be eliminated  letting  the  compiler  copy  the  _data  into  the  memory  and  dealing  with  it  there.  Full expectations  about  the  expected  information  in  the  _data  argument  must  be  properly  documented,  to avoid the misinterpretation of the interface.  function onTokenTransfer(     address _from,     uint256 _value,     bytes calldata _data ) external returns (bool) {  A similar situation can be found in the TxPermissions contract.  Specification Changed:  The code has been commented as follows:  // It is assumed that the `_data` field contains the `length` field in its first 32 bytes. // There are data bytes right after the `length` field (without \"garbage bits\" between them).  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   claimOrderedWithdraw Not Always",
        "body": " Successful  After  using  the  StakingAuRa.orderWithdraw()  function  the  validator  can  complete  the  withdrawal starting from the next epoch using claimOrderedWithdraw().  To prevent abuse, this function queries _isWithdrawAllowed once more in order to determined if the validator  may  have  been  banned  in  the  meantime.  However  _isWithdrawAllowed  also  includes  a check whether staking or withdrawals are currently allowed using areStakeAndWithdrawAllowed().  Normally such actions are not allowed near the end of a staking epoch in order to not interfere with the validator selection process. Note that claiming a previously ordered withdrawal has no influence on this and hence shouldn't be subject to this restriction. If a party happens to claim their withdrawal at the end of an epoch their withdrawal fails without apparent reason.    The _isWithdrawAllowed function has been refactored and parts of it's functionality has been moved into a new _isPoolBanned() function. This function is now querried in claimOrderedWithdraw() which resolves problem with the blocked withdrawals at the end of an epoch as described above.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   Incorrect Comment in finalizeChange",
        "body": "  POA Network - POSDAO -   22  DesignMediumVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                \fThe  comment  in  the  else  if  branch  suggest,  it  is  only  been  executed  in  case  of  malicious  validator reporting.  But the code is also executed in case of mining address changes.    The code comments were corrected and elaborated.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   Incorrect Description",
        "body": "  In StakingAuRaBase the function description of _stake(address, address, uint256) is  // @dev The internal function used by the `_stake` and `moveStake` functions.  But function is also used in initialValidatorStake, _addPool.    The code comments were corrected and elaborated.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.6   Make onTokenTransfer() External",
        "body": "  Function StakingAuraTokens.onTokenTransfer() has visibility public. This means the function can be called externally and internally from within the contract.  Inside this function the calldata is read. This is the data passed alongside the call to the contract and remains unchanged if another function within the contract executes another contract as on a bytecode level  this  is  only  a  JUMP.  Function  onTokenTransfer  is  currently  only  called  from  externally  and  not internally  from  within  the  StakingAuraTokens  contract.  Hence,  the  calldata  consists  of  the  function arguments  as  expected.  Due  to  the  dependency  on  calldata  the  functions  visibility  may  be  external instead of public to avoid the function being called from within the contract accidentally during future code changes.    The function visibility as well as the reads from memory were changed accordingly.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.7   Multiplication After Division",
        "body": "  In ValidatorSetAuRa.reportMaliciousCallable() a multiplication is performed after a division:  POA Network - POSDAO -   23  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \faverageReportsNumber = (reportsTotalNumber - reportsNumber) / (validatorsNumber - 1) [...] reportsNumber > validatorsNumber * 50 && reportsNumber > averageReportsNumber * 10  Due to possible precision loss, this should be avoided.    The multiplication is now done before division.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.8   No Indexed Fields for ReportedMalicious",
        "body": "  The  ReportedMalicious  event  has  multiple  fields  that  might  be  worth  indexing.  No  field  is  indexed. POA Network might re-evaluate if this is desired.    The event has now indexed fields.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.9   Unchecked Return Value of Transfer",
        "body": "  BlockRewardAuRaTokens.transferReward()  In  and StakingAuRaTokens._sendWithdrawnStakeAmount()  the  boolean  return  value  of  the  call  to erc677TokenContract.transfer() is ignored.  While  most  ERC-20  Tokens  (ERC-677  implements  the  ERC-20  Standard)  and  the  ERC677  token implementation  available  in  the  repository  revert  upon  failure,  the  standard  does  not  require  this  and returning false instead of reverting is valid according to the standard. As the POSDAO system is highly customizable the situation may arises where a token contract not reverting on failure is used.  Similarly  return  TokenMinter.mintReward() is also ignored.  value   the   of   the   call   to   tokenContract.mint()   inside    The transfer functions are wrapped into a require. The mint function remained as it is since it is called by the BlockReward.reward function which is critically sensible for reverting according to POA network.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.10   certify Missing Sanity Check",
        "body": "  The Certifier implements certify. The function allows certifying the same address multiple times. The Confirmed event would be emitted misleadingly multiple times.  POA Network - POSDAO -   24  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \f  An appropriate sanity check was added.  POA Network - POSDAO -   25  \f8   Notes  We leverage this section to highlight potential pitfalls which are fairly common when working Distributed Ledger Technologies. As such technologies are still rather novel not all developers might yet be aware of these  pitfalls.  Hence,  the  mentioned  topics  serve  to  clarify  or  support  the  report,  but  do  not  require  a modification  inside  the  project.  Instead,  they  should  raise  awareness  in  order  to  improve  the  overall understanding for users and developers.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Avoiding Function Identifier Clashes",
        "body": "  The current proxy scheme is vulnerable to duplicated 4-byte function identifiers which could result in a function  identifer  clash.  POA  Network  prevents  this  by  using  an  off-chain  script  to  check  for  clashes. There are also on-chain solutions like the upgradable transparent proxy solution by OpenZeppelin which might be worth considering.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   ERC677 Standard Is a DRAFT",
        "body": "  The ERC677 standard is based on a eip having draft status since it's creation in 2017. Such standards are subject to changes before the eip's status is finalized.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.3   Most of the RedBlackTree Library Functions",
        "body": " Unused  Following function of the RedBlockTree Library are unused and hence dead code.  BokkyPooBahsRedBlackTreeLibrary.first() BokkyPooBahsRedBlackTreeLibrary.getEmpty() BokkyPooBahsRedBlackTreeLibrary.getNode() BokkyPooBahsRedBlackTreeLibrary.isEmpty(uint256) BokkyPooBahsRedBlackTreeLibrary.next() BokkyPooBahsRedBlackTreeLibrary.treeMinimum()  Note as the functions are not used within the POSDAO system these were not reviewed as part of this audit.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.4   Pragma Experimental ABIEncoderV2",
        "body": "  Contract  TxPriority  uses  pragma  experimental  ABIEncoderV2.  In  the  compiler  version choosen the new ABI encoder is still considered to be experimental.  POA Network - POSDAO -   26  NoteVersion1NoteVersion1NoteVersion1NoteVersion1                \f8.5   UTF-8 Charset  The validator and the staking contract allow names to be set for pools. The charset for string is UTF-8. UTF-8  has  some  similar  looking  characters,  which  for  a  human  reader  some  of  these  letters  are indistinguishable.  This allows so called visual spoofing of names. Users and front-end developper should excercise extra caution.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.6   Unreliable Event Emission When Mining",
        "body": " Address Is Changed  When reporting a malicious validator, the mining address is used and the following event emitted.  The  _maliciousMiningAddress  might  change  between  multiple  reportings.  Hence,  the  mining address is no reliable information to process from across multiple events.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.7   Unused Code _removeMaliciousValidator",
        "body": "  The  ValidatorSetAuRa  contract  implements  the  function  _removeMaliciousValidator.  This function is not called at all. The only function it appears is in _removeMaliciousValidators. But it is commented  out  there.  Furthermore,  the  function  _removeMaliciousValidators  does  not  do anything  except  for  setting  lastChangeBlock.  Hence,  also  removeMaliciousValidators  is basically only setting this variable.  This also affects parts of reportMalicious. We were verbally informed that client is aware of this and this will be fixed for the final review. Else, this would turn into an issue.  POA Network - POSDAO -   27  NoteVersion1NoteVersion1NoteVersion1          \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Accrued Interest Is Not Accounted in ",
        "body": " trancheValue  CS-XENA-002  The interest that is owed to LPs by an open leveraged position is only accounted for when that position is updated (increased or reduced), in _calcPositionFee().  If a position is opened, but then no longer updated for a long time, a significant amount of interest may accrue.  This  pending  interest  will  not  be  calculated  in  _getTrancheValue(),  leading  to  an undervaluation of LP shares.  Consider the following situation:  There are 2 LPs, both with an equal amount of liquidity. A trader opens a position. The position is open for 1 year and is paying 50% APR in interest. After a year, one of the LPs leaves. One minute later, the trader closes their position. Now, the trader will pay the full interest amount to the remaining LP, even though the risk of the position was shared equally among both LPs.  Xena Finance - Xena -   14  DesignCorrectnessCriticalHighMediumRiskAcceptedRiskAcceptedAcknowledgedRiskAcceptedLowRiskAcceptedRiskAcceptedRiskAcceptedCodePartiallyCorrectedRiskAcceptedAcknowledgedAcknowledgedDesignMediumVersion1RiskAccepted           \fA third LP could even front-run the transaction which closes the position, depositing an equal amount as the remaining LP to the pool. The trader will now pay half of their accrued interest to the third LP, even though  they  did  not  take  any  risk.  The  third  LP  could  immediately  withdraw  their  liquidity  afterward, receiving a risk-free profit.  The  effect  of  this  will  be  larger,  the  longer  positions  remain  open  without  being  updated.  If  positions typically  do  not  stay  open  for  a  long  time,  the  accrued  interest  will  likely  be  small  enough  that  the undervaluation of LP shares is negligible.  Risk accepted:  Xena Finance understands and accepts the risk posed by this issue, but has decided not to make a code change.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Hardcoded Stablecoin Price",
        "body": "  CS-XENA-004  In _getCollateralPrice(), if the collateral asset is marked as a stablecoin, the value is hardcoded to 1 USD. The configured oracle is not queried.  In case a stablecoin loses peg, this price will not match the oracle price.  The PnL (against USD) of shorts is always paid out as if the stablecoin was worth 1 USD, no matter the actual value. The collateral is valued consistenly between increasing and decreasing a position.  However,  in  _getTrancheValue()  of  LiquidityCalculator,  the  stablecoins  are  valued  at  their oracle price. The PnL of shorts is calculated in USD, independently of the current stablecoin price.  Consider the following illustrative situation:  1. A pool has one tranche and no opening and trading fee, with 2000 USDC liquidity. A trader has an open short position with 100 USDC collateral. They currently have a positive PnL of 100 USD. The tranche  has  reserved  1000  USDC  of  collateralToken  from  LPs.  The  oracle  price  of  USDC  is 1 USD. The trancheValue will be calculated as (2000 - 1000) * 1 - 100 = 900.  2. The oracle price of USDC collapses to zero.  3. Now, the trancheValue will be calculated as (2000 - 1000) * 0 - 100 = -100.  4. The trader closes their short. They will be paid out their collateral and 100 USDC (worth 0 USD).  5. Now, the trancheValue will be calculated as (1900 * 0) = 0.  In this extreme (and unlikely) example, the system invariant that AUM (trancheValue) must always be positive,  can  be  broken.  This  would  lead  to  _getTrancheValue  always  reverting  when  casting toUint256(), which will make it impossible to add or remove liquidity from that tranche.  // aum MUST not be negative. If it is, please debug     return aum.toUint256();  A  price  collapse  of  the  stablecoin  to  zero  is  the  most  extreme  case,  but  the  same  effect  on trancheValue  happens  in  a  smaller  way  as  soon  as  the  oracle  price  of  the  stablecoin  is  not  exactly 1 USD.  The  incorrect  trancheValue  will  lead  to  LP  shares  being  over-  or  undervalued,  which  can  lead  to losses for LPs.  Xena Finance - Xena -   15  CorrectnessMediumVersion1RiskAccepted        \fRisk accepted:  Xena Finance understands and accepts the risk posed by this issue, but has decided not to make a code change.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   LP Fee Distribution Is Unfair",
        "body": "  CS-XENA-018  Upon  position  increase/decrease/liquidation,  the  LP  fee  is  scaled  and  distributed  according  to  the  risk factor, and not according to the distribution of the reserve amount across the tranches. In the case where the system has three tranches (junior, mezzanine, and senior) and the junior tranche is full, the risk for newly  opened  positions  will  only  be  distributed  across  the  mezzanine  and  senior  tranches.  But  in  this case, the junior tranche will still receive a share of the LP fee, although it does not participate in the risk, and the mezzanine and senior tranches will not get rewarded according to the new risk.  Consider the following situation:  1. There is a pool with two tranches. Tranche A has 2/3 of the total riskFactor, tranche B has 1/3.  Tranche A has only one LP, Alice.  2. Each  time  a  trader  wants  to  take  leverage,  Alice  front-runs  the  increasePosition  call  of  the  executor with removeLiquidity, removing her entire balance.  3. When  increasePosition  is  executed,  there  is  no  unreserved  liquidity  in  tranche  A,  so  the  full  amount is reserved in tranche B.  4. Alice deposits her balance again.  5. When the trader closes their leveraged position, Alice receives 2/3 of the positionFee, as well  as the borrowFee (interest), even though she did not provide any leverage to the trader.  Upon a swap, the LP fee is similarly scaled and distributed according to the risk factor, and not according to the distribution of the amountOut. So, the LP fee does not reflect the liquidity utilization.  Acknowledged:  Xena Finance acknowledged the issue with the following response:  This is intended behavior  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.4   Missing Documentation",
        "body": "  The codebase is poorly documented and almost no natspec has been written.  Xena Finance did not supply any code-external documentation. Only a reference to a third-party project's documentation website with similar functionality was given.  A well-documented codebase helps integrators and improves the overall security by allowing readers to better understand the role of a piece of code, as well as any assumptions that are made.  CS-XENA-005  Xena Finance - Xena -   16  DesignMediumVersion1AcknowledgedDesignMediumVersion1RiskAccepted                \fRisk accepted:  Xena  Finance  understands  and  accepts  the  risk  posed  by  this  issue,  but  has  decided  not  to  make  a change.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.5   Contracts Not Implementing Their Interface",
        "body": "  Some contracts do not implement their interface, which could lead to problems when integrated.  CS-XENA-008   Pool should implement IPoolWithStorage   LPToken should implement ILPToken   Oracle should implement IPriceFeed   OrderManager should implement IOrderManagerWithStorage  Risk accepted:  Xena Finance understands and accepts the risk posed by this issue, but has decided not to make a code change.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.6   Free Leverage Within Accrual Interval",
        "body": "  The interest for leveraged positions accrues once per accrualInterval.  As a result, a trader could avoid paying any interest by creating a leveraged position after interest has been  accrued,  then  closing  the  position  again  before  the  next  accrual.  The  positionFee  will  still  be paid.  CS-XENA-009  Risk accepted:  Xena Finance understands and acknowledges this issue, but has decided not to make a code change.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.7   Incorrect Fee Calculation When Oracles",
        "body": " Disagree  In  LiquidityCalculator,  _calcFeeRate()  calculates  the  fees  for  a  swap  based  on  if  the  swap moves the pool towards the targetWeight or away from it. For this, the value of the token is calculated based on tokenPrice. The targetWeight is calculated based on the Pool.virtualPoolValue.  In the normal case, these values are correct. However, in special conditions, the Oracle does not return the Keeper's posted price, but instead gives a price that is more favorable to the protocol. For example, the tokenPrice of tokenIn for a swap will be undervalued.  CS-XENA-011  Xena Finance - Xena -   17  DesignLowVersion1RiskAcceptedDesignLowVersion1RiskAcceptedCorrectnessLowVersion1RiskAccepted                        \fThe Pool.virtualPoolValue is calculated as an average of undervaluing and overvaluing all tokens. This means that in virtualPoolValue, the tokenIn will not be undervalued in the same way.  MathUtils.average(liquidityCalculator.getPoolValue(true), liquidityCalculator.getPoolValue(false));  As  a  result,  the  weights  are  computed  incorrectly,  as  values  that  have  different  \"rounding\"  applied  to them are compared as if they were rounded the same.  Ultimately, this will lead to the fee calculated by calcFeeRate() to be either too high or too low.  Risk accepted:  Xena Finance understands and accepts the risk posed by this issue, but has decided not to make a code change.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.8   Missing Reentrancy Protection",
        "body": "  CS-XENA-014  functions Although  no  attack  vector  Pool.liquidatePosition  and  view  function  virtualPoolValue  should  implement  reentrancy protection to avoid any potential issue.  for  reentrancy  or  read-only  reentrancy  was   found,   the   Code partially corrected:  A reentrancy guard has been added to Pool.liquidatePosition.  virtualPoolValue() has not been changed, so integrators must be careful when calling this function.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.9   No Slippage Protection on poolSwap",
        "body": "  The _poolSwap function in OrderManager has a _minAmountOut argument, which can be used for slippage protection.  CS-XENA-015  However,  when  _poolSwap()  functionality is not used, always passing a _minAmountOut of 0.  is  called   from  _executeLeveragePositionRequest(),   this  Risk accepted:  Xena Finance understands and accepts the risk posed by this issue, but has decided not to make a code change.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.10   OrderLens Marks Inexistent Swap Orders as",
        "body": " Executable  Xena Finance - Xena -   18  DesignLowVersion1CodePartiallyCorrectedDesignLowVersion1RiskAcceptedCorrectnessLowVersion1Acknowledged                        \fThe  default  status  of  an  order  is  OPEN  and  the  values  of  an  uninitialized  order's  amountIn  and function  OrderLens.canExecuteSwapOrders  will  mark minAmountOut  will  be  0.  So,  non-existent orders as non-rejected, but they will fail if submitted to the OrderManager.  the   CS-XENA-019  Acknowledged:  Xena Finance answered:  We are aware of this. Contracts don't use this function so we keep that for convenience.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.11   OrderLens Missing Checks for Executable",
        "body": " Leverage Orders  The  function  OrderLens.canExecuteLeverageOrders  does  not  do  any  check  for  INCREASE requests  and  only  does  minimal  checks  for  DECREASE  requests,  e.g.,  the  fee  is  not  fully  computed. Therefore, it may happen that an order marked as executable by the function will fail if submitted to the OrderManager.  CS-XENA-017  Acknowledged:  Xena  Finance  acknowledged  this  issue  and  has  decided  not  to  make  a  code  change.  Xena  Finance states:  Contracts don't use this function. We keep it for compatibility with backend/frontend logic.  Xena Finance - Xena -   19  DesignLowVersion1Acknowledged          \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings   Wrong Accounting upon Margin Account Top up   -Severity Findings   Hardcoded Contract Addresses    PriceReporter Will Not Execute Every Second Swap Order   -Severity Findings   CEI Pattern Not Applied   Incorrect Comments   Interest Rate Is Not Constrained    Missing Events   IPool Is Missing Signature for liquidatePosition()   0  1  2  5  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Wrong Accounting upon Margin Account Top",
        "body": " up  CS-XENA-001  When  collateral  is  added  to  a  long  position  without  changing  the  position's  size,  the  function _reservePoolAsset distributes the collateral in the tranches' poolAmount and guaranteedValue. The distribution is done according to the risk factor and current utilization of each tranche, calculated in _calcReduceTranchesPoolAmount().  Note  that  the  amount  of  collateral  that  can  be  added  to  a  tranche  is  limited  to  the  unreserved  amount available  in  that  tranche.  In  an  extreme  case  where  all  tranches  have  a  high  utilization,  it  will  be impossible  large  amount  of  collateral  while  keeping  position  size  equal,  as _calcReduceTranchesPoolAmount() will revert if the amount of collateral to add is higher than the total unreserved amount in all tranches.  to  add  a   When releasing the asset, the distribution is done according to the ratio of reserved amounts across the tranches.  In  the  case  of  a  collateral  top-up,  collateral  will  be  distributed  among  the  tranches,  but  no additional amount is reserved. This means the distribution of the collateral and reserved amount may not match. This may lead to a wrong accounting, incorrect pricing of LP shares, and reverting transactions.  Consider the following example:  There are 2 tranches, each with the same risk factor for a given asset. When a long position is opened, tranche 0 is at full utilization, so the entire collateralAmount and reserveAmount will be given to tranche 1. Time passes and now the trader wants to increase their collateral, while keeping the size the same. At this  point  in  time,  tranche  1  has  full  utilization,  so  all  the  extra  collateral  will  be  given  to  tranche  0.  No  Xena Finance - Xena -   20  CriticalHighSpeci\ufb01cationChangedMediumCodeCorrectedCodeCorrectedLowCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCorrectnessHighVersion1Speci\ufb01cationChanged           \fadditional  amount  is  reserved.  Now,  the  trader  closes  their  position.  The  full  amount  of  collateral  (that they deposited over 2 transactions) will be withdrawn from tranche 1's poolAmount, as only the ratio of reserveAmount is taken into account when closing a position. This is incorrect, as a part of the collateral was actually attributed to tranche 0. Tranche 1 will have fewer funds than it should, while tranche 0 will have more.  The guaranteedValue for the tranches will also be incorrect.  Specification changed:  Xena Finance acknowledged the issue and changed the spec to use only one tranche, which resolves the issue. Xena Finance stated:  We will use 1 tranche model for this version.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Hardcoded Contract Addresses",
        "body": "  In LiquidityRouter, the address of the wrapped ether contract is hardcoded.  IWETH public constant weth = IWETH(0x82aF49447D8a07e3bd95BD0d56f35241523fBab1);  CS-XENA-003  The same is true in OrderLens:  address constant WETH = 0x82aF49447D8a07e3bd95BD0d56f35241523fBab1;  While this would be correct on Arbitrum One, this project is intended to deploy on Base Mainnet. On Base Mainnet, this address does not contain a deployment of WETH. As a result, the router will not work with WETH since the call to deposit() will fail and make the transaction revert.  Similarly, in Oracle, an address for a sequencer uptime feed is hardcoded.  /// @notice arbitrum sequence uptime feed AggregatorV3Interface public constant sequencerUptimeFeed =     AggregatorV3Interface(0xFdB631F5EE196F0ed6FAa767959853A9F217697D);  This feed is specific to Arbitrum One and does not function on Base Mainnet.  If  the  codebase  is  deployed  with  the  current  hardcoded  addresses,  no  funds  will  be  at  risk  since  the system will not work at all.  Furthermore, in OrderManager an address for EthUnwrapper is hardcoded.  address public constant ETH_UNWRAPPER = 0x1730CdEe8f86272eBae2eFD83f94dd9D5D855EeD;  A contract exists at this address on Base Goerli. Since no contract has been deployed at this address on Base Mainnet, we cannot determine whether it is correct.    Xena Finance - Xena -   21  CorrectnessMediumVersion1CodeCorrected        \fThe addresses are now given as an argument in the constructor, or in initialize() for contracts that will be used behind a proxy.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   PriceReporter Will Not Execute Every Second",
        "body": " Swap Order  CS-XENA-006  In postPriceAndExecuteOrders(), when looping over swap orders, i is incremented twice. Once in the post-loop expression, and once in the loop body.  As a result, half the orders will be skipped.  for (uint256 i = 0; i < swapOrders.length; i++) {     try orderManager.executeSwapOrder(swapOrders[i], payable(msg.sender)) {} catch {}     unchecked {         ++i;     } }    i is now only incremented once per loop.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   CEI Pattern Not Applied",
        "body": "  The  checks-effects-interactions  pattern  that  prevents  reentrancy  attacks  is  not  followed  in  the  function executeLeverageOrder().  The  status  of  the  order  is  set  to  FILLED  only  after  the  call  to _executeLeveragePositionRequest(), which may send ETH to the owner with full gas().  We  do  not  see  a  direct  attack  vector  through  this  reentrancy,  but  we  recommend  fixing  this  as  a preventative measure.  CS-XENA-007    The  code  has  been  updated  to  first  mark  the  order  as  FILLED,  and  then  make  the  call  to _executeLeveragePositionRequest().  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Incorrect Comments",
        "body": "  1. The comment above the function OrderManager._createIncreasePositionOrder specifies the  construction  of  the  _data  field.  It  mentions  a  uint256  collateral,  but  no  such  field  is decoded from the _data.  CS-XENA-010  Xena Finance - Xena -   22  CorrectnessMediumVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1Speci\ufb01cationChanged                        \f2. In  the  struct  DataTypes.Position,  the  comment  on  the  member  reserveAmount  says  the  amount is in indexToken, but the amount is denominated in collateralToken.  3. In   PoolV1.md,   the   formula   for   long-side   ManagedValue   it   should   reads read  4. Some of the comments describing the constants in Oracle.sol do not represent the correct units.  For example:  MAX_CHAINLINK_TIMEOUT = 1 days; // 10%  Specification changed:  All mentioned comments have been corrected.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Interest Rate Is Not Constrained",
        "body": "  In Constants, an upper bound for the interest rate is provided:  uint256 public constant MAX_INTEREST_RATE = 1e7; // 0.1%  However, this value is not used anywhere. In particular, in InterestRateModel, there is no constraint on the interest rate parameter.  CS-XENA-012    The  interest  rate  in  SimpleInterestRateModel  is  now  constrained  to  be  strictly  smaller  than MAX_INTEREST_RATE in the constructor.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Missing Events",
        "body": "  1. When the OrderManager is initialized, the oracle is also set but no related event is emitted. This is  not consistent with the setOracle() function, which emits an event.  2. When the PriceReporter adds and removes reporters, no event is emitted. This is not consistent  with the similar functionality in Oracle, which emits events.  CS-XENA-013    1. The OracleChanged event is emitted at the end of initialize.  2. The  events  ReporterAdded  and  ReporterRemoved  are  emitted  when  a  reporter   is  added/removed.  Xena Finance - Xena -   23  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                    \f6.8   IPool Is Missing Signature for liquidatePosition()  The interface of the Pool, IPool, contains the events and errors relative to a liquidation, but is missing the signature of the function liquidatePosition.  CS-XENA-016    The missing function was added to the interface.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   Duplicate Code",
        "body": "  LiquidityCalculator._calcDaoFee() is never called and is a copy of Pool._calcDaoFee().  CS-XENA-020    The function LiquidityCalculator._calcDaoFee() has been removed from the codebase.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   Oracle Reporter Address Consistency",
        "body": "  The  function  Oracle.addReporter  allows  the  owner  to  add  the  address(0)  as  a  reporter,  but  the function Oracle.removeReporter does not allow to remove the address(0). This is not consistent with  the  behavior  of  the  same  functionality  in  PriceReporter,  which  does  not  allow  adding address(0).  CS-XENA-025    Oracle.addReporter no longer allows the address(0) to be added as a reporter.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.11   Use of assert()",
        "body": "  The function Pool.setTargetWeight() is using assert(isAsset[item.token]); to ensure that a token is in the mapping of assets.  The Solidity documentation states the following:  CS-XENA-028  Xena Finance - Xena -   24  DesignLowVersion1CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected                        \fAssert should only be used to test for internal errors, and to check invariants. Properly functioning code should never create a Panic, not even on invalid external input.  Moreover,  failing  assertions  will  consume  all  the  remaining  gas.  This  is  why  a  require()  statement should be used instead.    The assert has been replaced by a require statement;  Xena Finance - Xena -   25  \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   EVM Version",
        "body": "  When  deploying  on  non-Ethereum  chains,  compatibility  with  the  different  EVM  versions  should  be considered. It must be checked that the target chain supports the used Solidity version. For example, not every  chain  supports  the  PUSH0  opcode,  introduced  in  Solidity  0.8.20.  If  the  Solidity  version  used  is changed  to  something  other  than  0.8.18  in  the  future,  these  differences  between  chains  should  be considered.  CS-XENA-021  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Gas Optimizations",
        "body": "  CS-XENA-022  The following is an incomplete list of possible gas optimizations:  1. Duplicated  slippage  protection:  OrderManager.executeSwapOrder()  implements  slippage  protection, but Pool.swap() already has the same functionality.  2. The  field  SwapOrder.price  is  assigned  in  OrderManager.placeSwapOrder()  but  never  used.  3. The  mappings  userLeverageOrderCount  and  userSwapOrderCount  are  redundant,  as  a getter  returning  the  length  of  the  userLeverageOrders  and  userSwapOrders  arrays  would accomplish the same thing with higher gas efficiency.  4. The storage slot SimpleInterestRateModel.interestRate can be immutable.  5. The parameters _minAmountOut and receiver of the function OrderManager._poolSwap are always 0 and address(this). They could be replaced by their fixed value to decrease the length of the calldata.  6. The  check  done  in  OrderManager._requireControllerOrOwner  could  be  transformed following  De  Morgan's  law  to  be  more  gas  efficient  and  leverage  the  lazy  evaluation  of  the parameters.  7. The function OrderManager.cancelSwapOrder could load only the specific fields of order that are needed into memory, instead of the whole struct, since not all the fields will be read. The same applies for request in OrderManager._expiresOrder().  8. In OrderLens.getOpenLeverageOrders(), an array of constant size is first filled, then another array is created which contains the same elements, except that empty items are removed. Instead, only  non-empty  could  be  added  to  a  dynamic  size  array  using  array.push().  This  could  avoid needing the second array. The same applies for OrderLens.getOpenSwapOrders().  9. In  most  for()  loops,  incrementing  the  counter  can  be  marked  as  unchecked  to  avoid  an  unnecessary overflow check. This is done in some places, but not systematically.  10. In certain callpaths, the oracle is queried multiple times for the same price. Caching certain prices could save gas. An example is the addLiquidity callpath, where the oracle is queried once for  Xena Finance - Xena -   26  InformationalVersion1AcknowledgedInformationalVersion1Acknowledged          \feach  refreshVirtualPoolValue().  supported   token   from   calcAddLiquidity(),   then   twice  more   from  11. Most  uint256  storage  slots  in  PoolStorage  have  a  known  maximum  size.  For  example,  fee values  or  the  accrual  interval.  These  values  could  use  smaller  data  types,  which  would  allow packing them with other values to save gas.  12. The SwapOrder and LeverageOrder structs could be optimized by choosing a smaller data type  for some of the fields, e.g., submissionBlock, submissionTimestamp, or expiresAt.  13. Upon interest accrual, it could save gas to check whether the interest has already been accrued for  the current interval and return early if it has, avoiding the interest rate computation.  Acknowledged:  Xena Finance acknowledged this issue and has decided not to make a code change.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Hardcoded Contract Address",
        "body": "  In OrderManager, an address for EthUnwrapper is hardcoded.  address public constant ETH_UNWRAPPER = 0x1730CdEe8f86272eBae2eFD83f94dd9D5D855EeD;  A contract exists at this address on Base Goerli. Since no contract has been deployed at this address on Base Mainnet, we cannot determine whether it is correct.  CS-XENA-023  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   Misleading onlyController Name",
        "body": "  The onlyController/_onlyController modifier/function's name is misleading, as they will accept the owner address as well, not only the controller.  CS-XENA-024  Acknowledged:  Xena Finance understands and acknowledges the issue.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   Tokens With Low Decimals",
        "body": "  All  computations  that  split  token  amounts  into  different  ratios  are  rounded  down,  which  is  safer  for  the system.  While  it  is  not  a  problem  for  tokens  with  enough  decimals,  it  could  impact  tokens  with  low decimals (e.g., GUSD has 2 decimals) or relatively low decimals compared to its value (e.g., WBTC has 8 decimals). Such rounding could result in value being locked in the contract.  Tokens used must be carefully chosen so the value lost in precision errors is not too high.  CS-XENA-026  Xena Finance - Xena -   27  InformationalVersion1InformationalVersion1AcknowledgedInformationalVersion1Acknowledged                \fAcknowledged:  Xena Finance understands and acknowledges the issue.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.6   Tokens With Many Decimals",
        "body": "  As the normalized price in Oracle is stored as a 30 decimal USD value, tokens used must be carefully chosen so their price will have enough precision.  For example, a token with a number of decimals close to 30 will have a low price precision.  CS-XENA-027  Acknowledged:  Xena Finance understands and acknowledges the issue.  Xena Finance - Xena -   28  InformationalVersion1Acknowledged      \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Add Then Remove Liquidity May Be Cheaper",
        "body": " Than Swap  Adding or removing liquidity, as well as swapping, has a fee. These fees are separately configured.  For a swap, the fees for in and out token are calculated and the higher fee is used. For liquidity, there is a fee on add as well as on remove.  If the fees for liquidity adding/removing are sufficiently low, it may be cheaper to emulate a swap by first adding and then removing liquidity in another token, than it is to do a direct swap. In particular, there is a minimum fee that is enforced on swaps, but this minimum is not enforced on add/remove liquidity.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   LPs Are Not Always Able to Remove Liquidity",
        "body": "  removal   Liquidity  i.e. poolAmount  -  reservedAmount,  so  if  the  tranche  is  fully  reserved  or  the  LP  has  a  position  in  a tranche greater than the unreserved amount, removal of liquidity will be limited to that amount.  the  unreserved  amount,   is  only  possible  within   from  a   tranche   LPs do not have a way to force the closure of open positions, so they may be unable to withdraw for a long time in this situation. However, they will also be earning a high interest rate.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.3   Market Manipulation of Listed Assets Must",
        "body": " Not Be Profitable  Xena relies fully on an external oracle to determine the prices it offers to traders. This is what enables the zero-price-impact trading feature.  However,  it  also  comes  with  significant  risks.  Unlike  spot  markets,  large  positions  can  be  opened  and closed without affecting the market price. This means that it is important that the price on the market from which the external oracle gets its prices must not be manipulatable by an attacker.  If an attacker is able to move the external market price by an amount larger than the fee paid to swap or open  and  then  close  a  position  in  Xena  combined  with  the  cost  of  the  manipulation,  this  could  be  a profitable attack. The loss from such an attack would be taken by LPs. The profit for the attacker is limited by the percentage they manipulate the market and the maximum size of a position (or swap) the attacker can create.  If the attacker keeps their position open for less than accrualInterval, they may not need to pay any interest. See Free Leverage Within Accrual Interval.  Xena Finance - Xena -   29  NoteVersion1NoteVersion1NoteVersion1          \fTo mitigate this attack vector, Xena has 2 features: A maxLiquidity, which limits the size of longs and swaps, and a maxGlobalShortSize, which limits the size of shorts. Each of these can be configured per token.  These  values  must  be  configured  carefully,  in  such  a  way  that  the  cost  of  manipulating  the  external market is always larger than the profit that can be made from exploiting projects relying on that market's price. Only assets with highly liquid markets should be listed on Xena. The less liquid the external market is, the lower the maxLiquidity and maxGlobalShortSize must be. If an asset becomes less liquid over time, it should be delisted, or the limits should be lowered. Additionally, the limits should be lowered if there is another project (for example another deployment of Xena) that also relies on the same asset's price.  In  this  case,  the  limits  must  be  coordinated  such  that  the  total  profit  among  all  projects  from manipulating the price is still smaller than the cost of manipulation.  A historical example of such an attack on another zero-price-impact DEX (GMX) can be found here: http s://web.archive.org/web/20221015123657/https://twitter.com/joshua_j_lim/status/1571554171395923968  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.4   Outdated Virtual Pool Value",
        "body": "  If liquidity is not added or removed frequently, the virtual pool value may be outdated. Integrators relying on the virtual pool value should call refreshVirtualPoolValue before using the value.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.5   Pay Token and Returned Token May Differ",
        "body": "  When using ETH or WETH, users must be aware of the following behaviors:  If  the  tokenIn  of  a  swap  order  was  ETH,  then  WETH  will  be  transferred  back  to  the  owner  if  the order is cancelled.  If the payToken of a leveraged order was WETH, then ETH will be transferred back to the owner if the order is cancelled.  If the payToken of a leveraged order was WETH, then ETH will be transferred back to the owner if the order expires.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.6   Public Execution of Leverage Orders Does",
        "body": " Not Work if Keeper Is Down  The  publicExecution  flag  should  allow  order  owners  to  execute  their  own  orders,  even  when  the executor is inactive.  However, public execution of leverage orders will not work if the Keeper does not post prices anymore. Leverage orders can only be executed if a price update happened after it was placed.  Xena Finance - Xena -   30  NoteVersion1NoteVersion1NoteVersion1                 \f8.7   Senior Tranche Assumes Full Risk in Extreme Situations  Different  tranches  have  different  risk  exposures,  which  are  dependent  on  the  riskFactor  of  the tranche.  In normal circumstances, a tranche will only assume a percentage of risk of each trade according to their riskFactor.  However,  in  extreme  scenarios  where  the  other  tranches  are  already  fully  utilized,  the senior  tranche  can  be  exposed  to  100%  of  the  risk  of  a  trade.  These  extreme  situations  likely  have  a higher  risk  to  the  LP  compared  to  \"normal  conditions\".  This  leads  to  senior  tranches  having  lower  risk exposure  (and  lower  fee  revenue)  during  \"normal  conditions\"  and  full  risk  exposure  during  \"extreme conditions\".  This  may  lead  to  the  overall  risk/reward  ratio  for  senior  tranches  to  be  worse  than  for junior tranches.  Users should take this into account when deciding which tranche they want to participate in.  Xena Finance affirmed that they are aware of this and that it is the intended behavior.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.8   Swaps on Pool Should Be Done Atomically",
        "body": "  When users are directly using the swap function of the Pool, it must be done within one transaction. The swap function expects the user's funds to already have been transferred to the contract before the call. If users were to first send the funds and then call swap() in two separate transactions, they will likely be front-run and lose their funds.  The OrderManager and LiquidityRouter provide helper functions to transfer and swap in the same transaction.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.9   System Is Paused if Chainlink Is Down",
        "body": "  The system relies on Chainlink prices for every user action. Users must be aware that the system will not work if one of the following conditions is met:  the Chainlink price has not been updated for some time and is stale (every token has a configurable timeout)   The chain's (initially Base) sequencer is down according to the Chainlink sequencer uptime feed   The chain's sequencer restarted less than 1 hour ago according to the Chainlink sequencer uptime  feed  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.10   Transaction Ordering MEV",
        "body": "  Transaction ordering in Xena is very important. Similarly to other markets, the execution of a transaction depends on the transactions before it. For example, the fees charged for a swap are dependent on the current token ratios in the pool. This is also known in the context of Ethereum as MEV.  Xena Finance - Xena -   31  NoteVersion1NoteVersion1NoteVersion1NoteVersion1               \fIn Xena, any user can make a swap at any time. However, other order types can only be executed by the executor  role  while  publicExecution  is  disabled.  The  smart  contracts  do  not  enforce  any transaction  order,  so  the  executor  is  free  to  decide  in  which  order  they  execute  orders.  It  can  also decide to censor some orders, never executing them. This is comparable to the role of block builders in Ethereum.  The executor has the potential to use its privileged position to extract some of this MEV-comparable value that is present for itself. Additionally, it seems to be intended that the executor role is held by the PriceReporter,  which  also  has  the  powerful  role  of  providing  asset  prices  to  the  Oracle.  Using postPriceAndExecuteOrders,  the  PriceReporter  can  update  the  oracle  price  and  then immediately  execute  orders.  In  particular,  it  can  execute  swap  orders  immediately,  before  other addresses have a chance to swap using the updated prices.  Users  must  ensure  that  the  executor  and  PriceReporter  are  behaving  as  expected  and  are  not using their privileged position to extract value for themselves, for example by taking payments for quicker execution, censorship, or by executing their own transactions first.  The  executor  should  publish  its  transaction  ordering  methodology,  so  that  users  can  hold  it accountable if it does not behave accordingly. It would also be possible to enforce some ordering rules on the smart contract level.  Xena Finance - Xena -   32  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Push3 Used Where Push2 Would Be Sufficient",
        "body": "  The ring buffer size (8191 in  two bytes, a PUSH2 would also be sufficient. This would result in a minor size reduction of the bytecode.  ), is pushed to the stack using PUSH3, however, as it only occupies  CS-EIP4788-010  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Merge Failure Cases for Gas Savings",
        "body": "  Generally,  we  expect  the  most  common  get  execution  case  to  be  the  one,  where  the  get  call  will succeed.  Hence,  we  try  to  optimize  the  gas  cost  for  this  case.  In  the  current  implementation,  the successful get contains two executions of JUMPI that branch off to the corresponding revert statements. If  the  two  conditions  were  combined  using  an  OR  operation,  only  a  single  JUMPI  would  be  needed. Thereby execution gas costs could be lowered in the successful get execution.  CS-EIP4788-002  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   Negate Failure Conditions to Save Gas",
        "body": "  The contract has two conditions that can revert the execution:  CS-EIP4788-003  Ethereum Foundation - EIP-4788 Contract -   9  DesignCorrectnessCriticalHighMediumLowAcknowledgedAcknowledgedAcknowledgedAcknowledgedDesignLowVersion2Version2DesignLowVersion1AcknowledgedDesignLowVersion1Acknowledged                        \f1. calldatasize == 32  2. sload(calldataload(0) % HISTORY_BUFFER_LENGTH) == calldataload(0)  Usually,  we  expect  the  good  case  where  both  conditions  will  evaluate  to  true  to  be  the  most  common one.  However,  on  EVM-level  the  conditions  are  currently  implemented  so  that  in  the  good  case  the JUMPI  performs  a  jump.  As  a  result,  in  the  good  case  two  JUMPDEST  operations  are  executed,  which consume one gas each. If the conditions would be negated on EVM level by using SUB instead of EQ, the gas consumed by the JUMPDEST operations could be saved.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.4   Reorder Operations to Save Gas",
        "body": "  The contract's source code contains a swap1 operation, which swaps out elements of the stack. Through a  different  order  for  the  preceding  operations,  the  swap1  instruction  can  be  omitted.  This  results  in  a lower execution gas cost and smaller contract size.  CS-EIP4788-004  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.5   Replace Push Command With Msize for Gas",
        "body": " Savings  Towards the end of the get() function there is the following instruction:  push1 32  It is supposed to push the current memory size (32 bytes) onto the stack, so that this can be used as size input  for  the  return  statement.  Instead  the  msize  instruction  could  be  used,  which  achieves  the  same and reduces execution gas costs as well as contract deployment costs.  CS-EIP4788-005  Ethereum Foundation - EIP-4788 Contract -   10  DesignLowVersion1AcknowledgedDesignLowVersion1Acknowledged                  \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings   Zero-Timestamp Can Be Queried Successfully   -Severity Findings  -Severity Findings  Implications of Ring Buffer Size   Informational Findings  Inconsistent Comment   0  1  0  1  1  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Zero-Timestamp Can Be Queried Successfully",
        "body": "  The get() function can be queried with the Zero-Timestamp even though no value has ever been set for the Zero-Timestamp. This violates the important property that all returned values must have previously been  set.  This  happens  because  the  EVM  storage  is  initialized  with  zeroes  which  allow  the  timestamp check to pass.  Note that this remains possible until the corresponding storage slot is first used.  With  0  as  an  argument  for  get(),  The  returned  beacon  root  would  be  zero.  This  leads  to  integrators being tricked into accepting the Zero-Hash as a valid beacon root which might allow exploits depending on the protocol.  CS-EIP4788-001    An explicit check has been added to make sure that the get() function reverts when a Zero-Timestamp is provided as calldata.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Implications of Ring Buffer Size",
        "body": "  The EIP-4788 states:  The ring buffer data structures are sized to hold 8192 roots from the consensus layer at current slot timings.  CS-EIP4788-008  Ethereum Foundation - EIP-4788 Contract -   11  CriticalHighCodeCorrectedMediumLowCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCorrectnessHighVersion1CodeCorrectedDesignLowVersion1CodeCorrectedSpeci\ufb01cationChanged                      \fIn  at a current SECONDS_PER_SLOT = 12 on the mainnet.   the code implements the circular buffer, however out of 98304 slots, only 8192 will be utilized  Effectively  the  ring  buffer  behaves  as  a  ring  of  integers  modulo  n,  where  n  is  its  size.  The ( current_timestamp + X * SECONDS_PER_SLOT ) mod 98304 function will produce a cyclic subgroup  of  order  8192  the SECONDS_PER_SLOT would change to 16, the cyclic subgroup will have order 6144, which is less than 8192.  Furthermore,  many  old  entries  from  the  12-second  interval  would  uselessly  remain  in  the  ring buffer.  if  SECONDS_PER_SLOT   is  12.  However,   future,   the   if,   in   Thus, the requirement of the EIP-4788 to have 8192 roots available in the ring buffer will not be satisfied if the SECONDS_PER_SLOT changes to 16 seconds. If the SECONDS_PER_SLOT changes to 13 seconds, the cyclic subgroup will have order 98304, thus increasing the storage requirements for the ring buffer by 12 times.  To summarize, the 98304 as a group order for the ring buffer is not an ideal choice, as it is not a prime number.  Potential  changes  to  the  SECONDS_PER_SLOT  will  drastically  change  the  behavior  of  the  ring buffer.  If the ( current_timestamp + X * SECONDS_PER_SLOT ) mod 8209 function is used instead, the cyclic subgroup will always have order 8209, since it is a prime number. That would have two key advantages:   The  ring  buffer  could  always  hold  the  most  recent  8209  beacon  roots  independent  of  SECONDS_PER_SLOT   The storage consumption would remain constant even when SECONDS_PER_SLOT changes  If the primary objective is to make sure that the ring buffer can hold all beacon roots of the past 24 hours, then  a  prime  ring  buffer  size  still  makes  sense,  but  a  bigger  one  has  to  be  chosen,  according  to  the lowest value SECONDS_PER_SLOT might have in the future.  Please note that the changes discussed here would require a change in the specification.    The  specification  has  been  changed  to  make  the  ring  buffer  size  8191,  which  is  a  prime  number.  The code has been changed accordingly. Hence, the new implementation benefits from the positive effects described above.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Inconsistent Comment",
        "body": "  In the code comments inside src/main.etk for the get() function, the same loaded calldata is once referred to as time and once as input. To avoid confusion a consistent label could be used for it in both places.  CS-EIP4788-009    The comments have been updated and are more consistent.  Ethereum Foundation - EIP-4788 Contract -   12  Version1InformationalVersion1CodeCorrected      \f7   Informational  We utilize this section to point out informational findings that are technically not issues. As the EIP served as a specification, we primarily check whether the code correctly and securely implements the EIP. Here, however,  we  also  point  out  possible  improvements  to  the  EIP.  Furthermore,  an  inconsistency  in  the comments of the source code.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Changes in Block Interval",
        "body": "  As  long  as  the  block  interval  (SECONDS_PER_SLOT)  remains  at  its  current  value  of  12  seconds  two properties will hold:  1. A successfully written beacon root can only be overwritten after 8191 blocks have passed.  2. All successfully written beacon roots from past 24 hours are available in the contract.  CS-EIP4788-011  However, different changes in the block interval are possible:  Different, Fixed Block Interval  If,  at  a  block  X,  the  block  interval  changes  to  a  different  value,  e.g.,  8  seconds,  the  following  holds regarding the properties mentioned above:  1. This  property  is  temporarily  violated.  A  beacon  root  written  in  the  blocks  [X  -  8190,  X]  might  be  overwritten sooner due to the change in the interval.  2. This  property  is  temporarily  violated  for  the  beacon  roots  written  in  the  24  hours  before  X. Furthermore, if the new block interval is smaller than 11 seconds, the property will no longer hold as more than 8191 beacon roots are produced in 24 hours.  Variable Block Interval  If  the  block  interval  becomes  variable,  e.g.  there  are  10  seconds  between  blocks  X  and  X+1,  but  9 seconds  between  blocks  X+1  and  X+2,  then  the  following  holds  regarding  the  properties  mentioned above:  1. This property is permanently violated.  2. This property is permanently violated.  However, in all cases mentioned above, the following property always holds:  A  successfully  written  beacon  root  can  only  be  overwritten  after  8191  seconds  have  passed.  Hence, even during network changes, each beacon root will be available for more than two hours.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Gas Savings in Ring Buffer Layout",
        "body": "  Currently, the two ring buffer storage location segments are laid out as follows:  1. Timestamps: [0 , HISTORY_BUFFER_LENGTH - 1]  2. Beacon Roots: [HISTORY_BUFFER_LENGTH , 2 * HISTORY_BUFFER_LENGTH - 1]  Hence, to compute the beacon root storage slot based on the timestamp storage slot, the code currently adds HISTORY_BUFFER_LENGTH. However, a more efficient approach would be to use the EVM's NOT  CS-EIP4788-007  Ethereum Foundation - EIP-4788 Contract -   13  InformationalVersion2InformationalVersion1      \fopcode on timestamp slot for the beacon root storage slot computation. By doing this, both the execution gas cost and the overall contract size could be reduced.  Please note that this would require a change in the specification.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Minor Inconsistencies in Specification",
        "body": "  A few documentation parts are outdated in   :   The subsection Size of ring buffers in the EIP-4788 contains an outdated ring buffer size.   The  bytecode  in  the  README.md  of  the  code  repository  is  incorrect  based  on  the  command  presented above it.   The  cfg.png  showing  the  control-flow  graph  in  the  code  repository  is  outdated  as  it  does  not  contain the latest code.  CS-EIP4788-012  Ethereum Foundation - EIP-4788 Contract -   14  InformationalVersion2Version2    \f8   Notes  We leverage this section to highlight issues that could potentially arise when interacting with this contract. First  from  the  perspective  of  smart  contract  developers  and  then  from  the  perspective  of  execution clients.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Integration Guidelines for Developers",
        "body": "  Smart  contract  developers  who  aim  to  interact  with  the  beacon  roots  contract  should  be  aware  of  the following pitfalls:  1. Unless  most  smart  contracts,  this  contract  has  no  4-byte  abi  calldata  signature  to  select  the function.  As  you  are  not  calling  from  the  SYSTEM_ADDRESS  your  call  is  automatically  calling  the get function.  2. The  calldata  has  to  be  exactly  32  bytes  and  should  only  contain  the  timestamp,  in  big-endian  format, which is the EVM default.  3. Due to the points above, smart contract developers might perform a low-level call in the respective smart contract language. That low-level call generally does not perform checks, such as sufficient return  data.  Hence,  smart  contracts  performing  such  a  low-level  call  should  check  that  the RETURNDATASIZE == 32 using the features of the respective language.  4. Beacon roots are only available for a limited time. This is because a ring buffer is used where old values  are  overwritten.  In  particular  this  also  implies  that  a  timestamp  which  was  queried successfully in one block might not be available in the next block.  5. The   ring  buffer  might  contain  outdated  entries.  At   the HISTORY_BUFFER_LENGTH  will  be  chosen  so  that  roughly  one  day  of  beacon  roots  is  available. However, developers cannot assume that successfully queried beacon roots are from the past day. They might be as old as the FORK_TIMESTAMP.  time  of  writing   the   6. There  is  a  beacon  root  available  for  the  current  timestamp,  but  it  is  not  the  beacon  root  of  the  current block. It is the beacon root of the preceding block.  7. There might be no beacon root for current timestamp - 12 or more generally: there might be no beacon root for the timestamp of a particular slot that occurred recently. This is because slots can be missed. Then no blocks will be produced and no beacon root will be inserted.  8. To get the beacon root from time X do not query X. Instead the timestamp of the succeeding block must  be  used.  That  timestamp  is  generally  unknown  it  could  be  X+12,  X+24,  or  something completely different once the block interval changes.  9. Do not send ETH to the contract. The ETH will be lost. A STATICCALL can be used, as it does not  allow the transfer of ETH.  Please note that we have only covered pitfalls related to the get function as this is the only one smart contract developers should be able to call.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Note for Execution Clients",
        "body": "  Execution clients need to perform the set operation as part of block construction. They should be aware that:  Ethereum Foundation - EIP-4788 Contract -   15  NoteVersion1NoteVersion1      \fset never reverts. Hence, a non-reverting execution of the set function does not imply a correct call. In particular set would not revert if called with no calldata or with too much calldata. If less than 32 bytes of calldata are provided, the calldataload operation will pad the missing bytes with zeros.  Ethereum Foundation - EIP-4788 Contract -   16  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Use of Atomic Transactions Only",
        "body": "  The  router  performs  critical  actions,  of  which  many  should  not  be  done  separately  in  multiple transactions. All critical operations must be done in one atomic transaction.  Yearn - Yearn ERC4626 Router -   10  NoteVersion1  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   StakingRewards rewardsDistribution",
        "body": " Ownership Inconsistency  StakingRewardsInit.init() is called by the deployer after StakingRewardsDeploy.deploy() to  p.owner,  which  should  be  Maker's  PauseProxy. has  been  called,  setting  StakingRewardsInit.init() is therefore not called by the owner (as the Foundry script cannot be run by a governance Spell) and will revert. If p.owner is the deployer, then the ownership is not correctly transferred to the PauseProxy anywhere in the script.  its  owner   CS-EGTKD-001  Specification changed:  MakerDAO informed us that the audited deployment script is currently meant for testing purposes. The deployer  will  therefore  be  an  EOA.  This  will  change  later  in  Phase  0  of  the  Endgame  Plan,  where  the contracts are initialized via governance Spell setting the owner of the contracts to the PauseProxy. The deployment scripts will be used as templates for the final Spell.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Vest Minting Not Possible",
        "body": "  MakerDAO - Endgame Toolkit -   12  CS-EGTKD-002  CriticalHighSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedMediumLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCorrectnessHighVersion1Speci\ufb01cationChangedCorrectnessHighVersion1CodeCorrected                \fDssVestMintable.pay()  calls  the  NGT  token's  mint()  function  to  generate  tokens  for  the  vesting. The  functions  is  guarded  and  can  only  be  accessed  by  a  ward.  The  DssVestMintable  contract  is never set as a ward of the NGT contract.    The initialization script now performs the following call, setting the ward of the NGT contract:  RelyLike(ngt).rely(vest);  This call is only possible if the deployer is an EOA that has been set as ward in the NGT contract. Since the script is currently only deploying contracts for testing purposes, the supplied NGT contract will have the correct rights in the given environment.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Vest Ownership Not Transferred at",
        "body": " Deployment  StakingRewardsDeploy deploys DssVestMintable, whose ward has unlimited token minting ability for the vested token by creating arbitrary new vests. The ward of DssVestMintable is not transferred to Maker's PauseProxy after deployment. It remains at the address of the deployer.  CS-EGTKD-003    The owner of DssVestMintable is now transferred to the given admin address of the deployment script. Since  the  deployment  script  is,  in  a  first  step,  run  by  an  EOA  and  only  used  for  testing  purposes,  the ownership  will  not  be  transferred  to  the  PauseProxy.  This  will  be  different  later  in  Phase  0  of  the Endgame plan.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Missing Checks",
        "body": "  CS-EGTKD-007  Phase0StakingRewardsInitScript  does  not  check  the  correct  state  of  some  of  the  deployed contracts. In particular, the following checks are missing:   stakingToken in StakingRewards is not checked to be the actual NST contract.   dssVest and stakingRewards in VestedRewardsDistribution are not checked to be equal  to the actual DssVestMintable and StakingRewards contracts.  It  is  not  checked  that  the  rewardRate  in  StakingRewards  has  already  been  updated  (e.g.,  by checking  that  lastUpdateTime  is  0).  This  is  possible  if  the  deployer  adds  their  own  rewards distribution contract and calls notifyRewardAmount with it.    MakerDAO - Endgame Toolkit -   13  SecurityHighVersion1CodeCorrectedSecurityLowVersion2CodeCorrected                 \fWhile originally the scripts related to the deployment and initialization of the farming module (including Phase0StakingRewardsInitScript.sol of the issue above) have been intended for testing/demo   these  scripts  have  been  adapted  to  be  used  for  the  actual  deployment  in purposes  only,  in  phase 0. The missing checks have been added to the code.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   SubProxy rely() to MCD End Instead of MCD",
        "body": " ESM During Initialization  In the SubProxyInit library, the init() function sets MCD End as a ward of the SubProxy. MCD End has no  ability  to  administrate  arbitrary  contracts,  such  as  the  SubProxy  in  question.  The  purpose  of  the rely() is therefore unclear.  CS-EGTKD-006    MCD  End  has  been  replaced  with  MCD  ESM  (Emergency  Shutdown  Module)  which  will  be  able  to remove the PauseProxy from the wards of the contract.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Vest Should Not Have a Cliff Period",
        "body": "  VestedRewardsDistribution  requires  the  configured  vest  to  not  have  a  cliff  period  past  the  beginning. StakingRewardsDeploy however supports a non-zero value for vestEta.  CS-EGTKD-004    The vestEta option has been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Redundant Imports",
        "body": "  VestInit.sol  imports  dss-test/ScriptTools.sol  that  is  redundant.  It  is  never  used  in  this library, in addition, it is built on top of the forge standard library that can only be used for off-chain testing.  CS-EGTKD-005    The redundant import has been removed.  MakerDAO - Endgame Toolkit -   14  Version3CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedInformationalVersion3CodeCorrected                      \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Deployment Verification",
        "body": "  Note: This is only relevant for the deployment in Phase 0/1 of the Endgame plan.  Since deployment of the contracts is not performed by the governance directly, special care has to be taken  that  all  contracts  have  been  deployed  correctly.  While  some  variables  can  be  checked  upon initialization through the PauseProxy, some things have to be checked beforehand.  We therefore assume that all mappings in the deployed contracts are checked for any unwanted entries (by  verifying  the  bytecode  of  the  contract  and  then  looking  at  the  emitted  events).  This  is  especially crucial for wards mappings.  In the case of DssVestMintable, special care also has to be taken to make sure that no extra awards have been added by the deployer. During initialization, the PauseProxy adds the contract as a ward to the NGT contract. After this, if the deployer added any awards with a controlled address as usr, they are able to mint tokens to themselves.  MakerDAO - Endgame Toolkit -   15  NoteVersion1  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Bypassing Antisnipping Protection",
        "body": "  The  AntisnippingManager  implements  logic  to  protect  against  so-called  liquidity-snipping  (Just-in-Time Liquidity)  attacks  to  prevent  attackers  from  adding  much  liquidity  before  a  swap  and  removing  it  right afterwards to collect most of the fees while not being exposed to LP risks.  Kyber Network removes the economic incentive of such an attack by locking fees for vestingPeriod which means an immediate withdrawal of liquidity should set the collected fees to zero.  Note,  that  AntiSnipAttack  protection  only  comes  in  play  if  feeGrowthInsideLast  of  the  position manager and the feeGrowthInsideLast of the position are not equal:  if (feeGrowthInsideLast != pos.feeGrowthInsideLast) {     ....     (additionalRTokenOwed, feesBurnable) = AntiSnipAttack.update(  Kyber Network - KyberSwap Elastic -   12  CriticalHighCodeCorrectedCodeCorrectedCodeCorrectedMediumCodeCorrectedCodeCorrectedLowCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedSpeci\ufb01cationChangedSecurityHighVersion1CodeCorrected         \f    ... }  Also, feesBurnable can only be non-zero if liquidity is removed:  if (isAddLiquidity) {     .... } else if (_self.feesLocked > 0) {     feesBurnable = (_self.feesLocked * liquidityDelta) / uint256(currentLiquidity);     _self.feesLocked -= feesBurnable; }  Thus, the following attack is possible:  1. Attacker sees a huge swap and mints an enormous position  2. Swap occurs.  3. An attacker adds a small amount of liquidity. The position's feeGrowthInsideLast is updated.  However, rTokens are now locked.  4. An attacker removes all his liquidity which does not enter the AntiSnipAttack code since there was  no fee growth. Liquidity is withdrawn and rTokens remain locked.  5. After vestingPeriod has passed the attacker can withdraw the newly generated fees.  Even  though  the  attacker  does  not  immediately  withdraw  the  fees,  his  liquidity  came  and  went immediately while generating a temporarily locked profit for the attacker.    In version 3 of the code, the Antisnipping protection logic is triggered on every call of removeLiquidity function.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Function Pool.burnRTokens Return Values",
        "body": "  Function burnRTokens of Pool contract has following definition:  /// @return qty0 token0 quantity sent to the caller for burnt reinvestment tokens /// @return qty1 token1 quantity sent to the caller for burnt reinvestment tokens function burnRTokens(uint256 qty, bool isLogicalBurn)   external   returns (uint256 qty0, uint256 qty1);  However the qty0 and qty1 value are not assigned in the implementation of this function. Thus 0 values will be returned instead.  The position managers rely on these return values as they implement slippage protection as follows:  (amount0, amount1) = pool.burnRTokens(rTokenQty, false); require(amount0 >= params.amount0Min && amount1 >= params.amount1Min, 'Low return amounts');  Ultimately, the transaction will revert if amount0Min > 0 && amount1Min >0 holds.  Kyber Network - KyberSwap Elastic -   13  CorrectnessHighVersion1CodeCorrected        \f  The values are now properly assigned to the return variables.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Locked Funds Remain Locked After ",
        "body": " vestingPeriod Update  The AntiSnipAttackPositionManager prevents profitable snipping attacks by locking rewards for a certain in amount  of  stored  AntiSnipAttackPositionManager:antiSnipAttack[tokenId].feesLocked.  However,  if vestingPeriod is set to zero, feesLocked remains locked.  in  a  position  with  tokenId  are   time.  The   locked   fees   Assume the following scenario:  1. vestingPeriod = 1 day  2. User mints a position.  3. After 12 hours, the User adds liquidity to a position. Assume that 1 rToken in fees has been earned  totally while half of it is locked.  4. vestingPeriod set to 0.  5. Whenever the user performs a position-modifying action, the following code gets executed.  if (vestingPeriod == 0) return (feesSinceLastAction, 0);  6. Only the newly accumulated fees become claimable while the locked fees remain locked. Hence,  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "0.5 rTokens will be unclaimable.",
        "body": "  Thus,  changes  to  the  vestingPeriod  can  potentially  allow  users  withdrawal  of  more  fees,  than  it  was intended.  Current  AntiSnipAttackPositionManager  and  AntiSnipAttack  library  rely  on  constant vestingPeriod. To conclude, the AntiSnipAttack library should be aware that the vesting period for fees could change.    If  vestingPeriod  is  zero  and  fees  are  still  locked,  feesLocked  is  added  to  the  claimable  fees  and feesLocked is set to 0.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Broken/Partial ERC165 Support",
        "body": "  The  ERC-721  specifies  that  the  ERC-165  interface  must  be  implemented  which  defines  a  standard method to publish and detect what interfaces a smart contract implements.  function supportsInterface(bytes4 interfaceID) external view returns (bool);  The more derived ERC-721 contracts of Kyber Network do not overwrite this function. Hence, querying the  support  of  the  additionally  implemented  interfaces  through  supportsInterface()  will  return false.  Kyber Network - KyberSwap Elastic -   14  CorrectnessHighVersion1CodeCorrectedDesignMediumVersion1CodeCorrected                \f  The  issue  has  been  addressed.  Function  supportsInterface  will  return  true  for  the  following interfaces.   ERC721Enumerable  IERC721Permit  Thus, they are considered as supported by the contract according to ERC-165.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Function Pool.unlockPool Reentrancy",
        "body": "  Pools  are  created  in  a  locked  state  and  need  to  be  unlocked  first.  The  unlockPool  function  first removes  the  lock  and  then  perform  the  mintCallback.  The  _initPoolStorage  is  called  after  the callback.  This  is  an  important  function  that  finalizes  the  setup  of  storage  for  the  pool.  This mintCallback after unlock and before _initPoolStorage can be misused by the malicious parties, since  all  pool  functions  will  be  available  during  the  call.  Attacker  can  potentially  misconfigure  or  abuse intermediate state inconsistency for its own profit. In addition, the mintCallback is usually performed to whitelisted position managers, while in this case any contract can be called.    The callback has been removed for unlocking pools. Now, funds have to be transferred to the pool before unlocking the pool.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Function ERC721Permit.permit Payable",
        "body": "  The  function  permit  has  a  payable  modifier  while  abstract  class  ERC721Permit  does  not  have  any other functions that can withdraw funds. The BasePositionManager that inherits this class has a separate receive function for ether transfers. Hence, the payable modifier could be removed from permit.    The payable modifier was removed from the permit function.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Function Pool.burnRTokens Natspec",
        "body": "  The  burnRTokens  does  not  describe  the  bool  isLogicalBurn  argument  with  a  @param  tag.  This argument greatly influences the result of burn and thus should be described.  Specification changed:  Kyber Network - KyberSwap Elastic -   15  SecurityMediumVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1Speci\ufb01cationChanged                         \fisLogicalBurn is now documented.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   Function Pool.burnRTokens Potential",
        "body": " Reentrancy  Certain  ERC20  tokens  perform  callback  on  token  transfers.  For  example,  ERC777.  Performing  _burn after  transfers  is  then  can  be  recognized  as  a  reentrancy  pattern.  While  the  burnRTokens  and  other Pool contract functions have reentrancy lock protection, there is possibility, that external contracts called during  the  transfer  callback,  might  misinterpret  the  State  of  the  Pool  contract.  For  example,  the reinvestL / totalSupply ratio will be off during this callback.  if (tokenQty > 0) token0.safeTransfer(msg.sender, tokenQty); tokenQty = QtyDeltaMath.getQty1FromBurnRTokens(sqrtP, deltaL); if (tokenQty > 0) token1.safeTransfer(msg.sender, tokenQty);  _burn(msg.sender, _qty);    The transfers have been moved to the very end of the function.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   Function SwapMath.calcFinalPrice",
        "body": " Rounding Down  The  calcFinalPrice  calculates  the  final  price  for  swaps,  when  the  used  amount  hits  the  specified amount limit. Depending on the starting price and direction of price movement during the swap, the price needs to be rounded either up or down. If isToken0 == false && isExactInput == true, sqrtP increases and thus price needs to be rounded down, in order not to 'overshoot' the target price.  But the tmp component of the final price is computed with rounding up division operator:  uint256 tmp = FullMath.mulDivCeiling(absDelta, C.TWO_POW_96, currentSqrtP); return FullMath.mulDivFloor(liquidity + tmp, currentSqrtP, liquidity + deltaL);  Thus the returned value with certain chance will be more than intended.    The code has been adjusted such that now division is rounding down.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   Gas Inefficiency in insert()",
        "body": "  Kyber Network - KyberSwap Elastic -   16  DesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \fInsertions  into  the  linked  list  through  LinkedList:insert()  occur  only  in  internal  function PoolTicksState:_updateTickList. In insert() the following storage read occurs:  However,  that  value  corresponds  to  the  last  nextTick  in  _updateTickList.  Thus,  storage  reads could be reduced by passing an additional argument to insert.    insert now takes nextTick as an additional argument, reducing the number of storage reads.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.11   Pool swap Max Tick Distance",
        "body": "  In the main loop of the swap function, to ensure that the tickOutside value is interpreted correctly the currentTick variable needs to be adjusted if the swap moves the price down:  swapData.currentTick = willUpTick ? tempNextTick : tempNextTick - 1;  the  next   On  MAX_TICK_DISTANCE == 487:  iteration  of   the   loop,   the  new   target   tick  distance  should  not  exceed   the  int24 tempNextTick = swapData.nextTick; if (willUpTick && tempNextTick > C.MAX_TICK_DISTANCE + swapData.currentTick) {     tempNextTick = swapData.currentTick + C.MAX_TICK_DISTANCE; } else if (!willUpTick && tempNextTick < swapData.currentTick - C.MAX_TICK_DISTANCE) {     tempNextTick = swapData.currentTick - C.MAX_TICK_DISTANCE; }  If willUpTick == false and tempNextTick - 1, then the tempNextTick will have at most 488 ticks between the matching tick for sqrtP. Thus, desired Dx*fee / x < 0.0005 ratio can be violated.   The MAX_TICK_DISTANCE was changed to 480. This way the desired Dx*fee / x < 0.0005 ratio will be preserved.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.12   Position Manager Storage Access",
        "body": "  AntiSnipAttackPositionManager  and  BasePositionManager  often  read  same  fields  inside  pos  storage variable  multiple  times  during  the  function  execution.  Since  this  struct  type  variable  is  defined  as  a storage  one,  this  will  lead  to  repeated  reads  from  the  same  work.  More  efficient  approach  would  be utilization of in memory variables.  Position storage pos = _positions[params.tokenId];    Kyber Network - KyberSwap Elastic -   17  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \fIn  version  3  of  the  code  the  gas  is  saved  by  utilizing  memory  variable  for  data  access  during  the execution.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.13   Solidity Compiler Pragma",
        "body": "  The smart contracts inside the repository utilize different compiler pragmas:   pragma solidity >=0.5.0;   pragma solidity >=0.8.0;   pragma solidity ^0.8.0;   pragma solidity >=0.8.0 <0.9.0;   pragma solidity 0.8.9;  Contracts should be deployed with the same compiler version and flags that they have been tested with thoroughly. Locking the pragma helps to ensure that contracts do not accidentally get deployed using, for example,  an  outdated  compiler  version  that  might  introduce  bugs  that  affect  the  contract  system negatively.  In  addition,  fixed  pragma  ensures  that  the  testing  and  deployment  performed  on  code  that was compiled by the same compiler version.    Core and periphery contracts use now pragma solidity 0.8.9 while libraries use >=0.8.0.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.14   Specification Mismatches in SwapMath",
        "body": "  Some mismatches between the specifications and code occur in the SwapMath library. Some examples are:   The  Core  Library  Swap  Math  documentation  of  calcReachAmount()  distinguishes  four  cases. However, case 1 & 4 and case 2 & 3 are identical. That mismatches the technical documentation of the swap and the implementation.   The technical documentation does not specify that the absolute value of usedAmount (delta x tmp)  is to be used for the calculation of deltaL.   The technical documentation differs in the mathematical formula for calculating returnedAmount.  Specification changed:  The specification now better reflects the implementation.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.15   flash() Sends Fees to feeTo",
        "body": "  The natspec documentation of flash() in IPoolActions specifies the following:  Kyber Network - KyberSwap Elastic -   18  DesignLowVersion1CodeCorrectedCorrectnessLowVersion1Speci\ufb01cationChangedCorrectnessLowVersion1Speci\ufb01cationChanged                        \f/// @dev Fees collected are distributed to all rToken holders /// since no rTokens are minted from it  However, the fees are transferred to the feeTo address stored in the Factory contract.  Specification changed:  The natspec specification has changed to specify that feeTo receives the fees from the flash loan.  Kyber Network - KyberSwap Elastic -   19  \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Pools for Tokens With Multiple Addresses",
        "body": "  The factory creates pools for two token address. It reverts if either the two addresses are identical or the pool has been already initialized for the token pair and the fee. However, some tokens (e.g. TUSD) have two addresses for the token. That allows for the creation of TUSD / TUSD pools, and multiple TUSD / other token pools with the same fee.  Kyber Network - KyberSwap Elastic -   20  NoteVersion1  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Missing Sanity Checks",
        "body": "  0  0  0  3  Multiple  setter  functions  are  missing  sanity  checks.  The  setters  functions  are  permissioned  and  we assume  the  caller  to  be  trusted.  Still,  mistakes  can  happen  and  would  be  irreversible  in  the  following cases:   StrategyProxy.setGovernance   BalancerYBALVoter.setGovernance  In other cases it might be helpful to prevent setting an address accidentally to address(0) but it is easy to override the value because the role setting the new address is not changed and could reverse their mistake. E.g., in StrategyProxy.setFeeToken it is possible to accidentally set it to address(0) but it could be immediately corrected by governance. Still, this might cause side effects as transactions could be executed with incorrectly set values before the mistake is reversed.  In  BalancerYBALVoter,  neither  the  initializing  function  nor  the  setters  do  verify  that  their  address inputs  are  different  than  the  zero  address.  Using  sanity  checks  prevents  unfortunate  errors  that  could potentially brick the contract.  In the zapper contract the _recipient is not checked and might be address(0) through a UI problem or incorrect user call.  Code partially corrected  A sanity check was added in the zap function to prevent the _recipient from being address(0). All other sanity checks were acknowledged by client but remained unchanged.  Yearn - yBAL -   10  DesignCorrectnessCriticalHighMediumLowCodePartiallyCorrectedCodePartiallyCorrectedRiskAcceptedCorrectnessLowVersion1CodePartiallyCorrected            \f5.2   No Event Emitted for State Modifying Code  Events indicate major state changes. Hence, it might be useful for users to listen to certain events. But events do increase the gas costs slightly. Yearn might consider the option to add events in the following cases:   BalancerYBALVoter  smart  contract  allows  for  modification  of  the  governance  and  the  strategy variables, but does not emit any event along with such modifications.   Some of the StrategyStYBAL setters like setProxy might issue events  Code partially corrected  An event was added that indicated a change of the governance variable in BalancerYBALVoter. In all other cases Yearn decided to keep the code as it is.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   Vault Withdrawal Could Fail in the Zapper",
        "body": "  Vaults  such  as  StYBAL  mint  some  shares  when  users  deposit  some  underlying  into  the  contract.  To withdraw underlying tokens from such vaults, user specify an amount of shares and the smart contract computes  the  underlying  value  by  using  an  exchange  rate  that  depends  on  total  funds  available  and profit/loss.  Note that in the zapper, there exists the following assertion after withdrawing _amount_in shares from a vault:  assert amount >= _amount_in # dev: fail on partial withdrawal  This code snipped could make a zapping transaction revert for two reasons:  1. A small rounding down can happen when computing the underlying value, which would make  amount a little bit smaller than _amount_in.  2. Some loss could have occured in the strategies, which could make 1 share of the vault worth  less than 1 underlying.  Risk accepted  Yearn is aware of the issue and accepts the risk as they rate the probability of the issue very low.  Yearn - yBAL -   11  DesignLowVersion1CodePartiallyCorrectedDesignLowVersion1RiskAccepted                \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings  -Severity Findings   Missing Parameter in JoinPool Struct    Outdated Comments Left   0  0  0  2  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Missing Parameter in JoinPool Struct",
        "body": "  The  userData  field  in  Balancer's  JoinPool  struct  depends  on  the  type  of  join,  in  the  case  of  an EXACT_TOKENS_IN_FOR_BPT_OUT  join  type,  the  field  must  be  organised  encoded  in  this  way: [EXACT_TOKENS_IN_FOR_BPT_OUT, amountsIn, minimumBPT].  In  the  zapper's  _lp_balweth()  function,  only  the  join  type  and  the  amounts  are  encoded  into  the userData:  user_data: Bytes[160] = _abi_encode(      convert(1, uint8), # EXACT_TOKENS_IN_FOR_BPT_OUT      _amounts,  )  Meaning that in the final encoding form, the length of the amounts will be accounted for as minimumBPT.  Code corrected  User data encoding was changed and convert(0, uint256) was added as minimumBPT amount.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Outdated Comments Left",
        "body": "  Some curve-related comments are left in the code:  1. StrategyStYBAL line 171  2. StrategyProxy line 60, 96  Code corrected  Yearn - yBAL -   12  CriticalHighMediumLowCodeCorrectedCodeCorrectedCorrectnessLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                \fCode comments were removed or changed accordingly.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Missing Capital Letter",
        "body": "  The  setdisableClaim()  function  in  the  StrategyStYBAL  contract  does  not  respect  the  camel casing. It should be setDisableClaim().  Code corrected  The function was renamed correctly.  Yearn - yBAL -   13  InformationalVersion1CodeCorrected      \f7   Open Questions  Here,  we  list  open  questions  that  came  up  during  the  assessment  and  that  we  would  like  to  clarify  to ensure that no important information is missing.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Inconsistent Call Behavior",
        "body": "  The  StrategyProxy  contract  calls  the  voter  (confusingly  referred  as  proxy  in  the  code)  to  execute various operations. The voter contract has a function to execute arbitrary calls. In most execution this is used.  E.g.,  vote_for_gauge_weights,  withdraw,  transfer,  approve,  deposit  and  mint.  But for increaseAmount a special function is defined in the voter contract. Why is this design chosen?  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   State Inconsistency for Safe Tokens",
        "body": "  The  functions  approveRewardToken  and  approveExtraTokenRecipient  check  if  a  token  is  safe by calling _isSafeToken. This guarantees that the tokens are considered safe at this moment in time (t0) when calling the functions. The check relies on the state of two other contracts to check if a token is safe. When operations with the tokens are performed later in time (t0 + x), the check is not repeated.  Hence,  it  implicitly  assumes  that  the  state  of  the  two  contracts  does  not  change  after  a  token  was checked in _isSafeToken. Please provide a brief explanation why this assumption will always hold.  Yearn - yBAL -   14  OpenQuestionVersion1OpenQuestionVersion1      \f8   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   No Error Strings Returned in the Zapper",
        "body": "  Meaningful  error  messages  help  users  to  understand  why  a  traansaction  failed.  No  error  strings  are returned  for  assertions  in  the  Zapper  contract.  Some  might  be  helpful  for  the  users  to  be  able  to understand the reason for the failed transaction, especially in the case of slippage protection.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Variables Could Be Immutable",
        "body": "  Setting variables that are only set in the constructor and cannot be changed later to immutable will save gas as the value is hardcoded into the contract and no SLOAD is required. Such variables could be:   The name and the sweep_recipient variables of the Zap contract   The variables escrow, token and name of the Voter contract   The name, symbol and decimals variables of the yBAL smart contract  Core partially corrected  The sweep recipient variable was made immutable. Yearn left all other variables as they are because the contracts are already deployed.  Yearn - yBAL -   15  InformationalVersion1InformationalVersion1CodePartiallyCorrected        \f9   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "9.1   Balancer LP Tokens Cannot Be Claimed as",
        "body": " Extra Token Rewards  The  StrategyProxy  's  _isSafeToken()  function  makes  sure  a  token  isn't  a  gauge  or  a  Balancer liquidity  token.  Because  of  that,  no  Balancer  liquidity  token  can  be  claimed  as  extra  rewards  in  the StrategyProxy. However, such extra rewards could potentially exist to claim (via a bribe for example), and would be lost in this case.  Yearn - yBAL -   16  NoteVersion1  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Offer/Listing Signature Valid for Any Loan",
        "body": " Contract  The current system requires the Offer or the ListingTerms struct to be signed. However, no information about for which contract address this struct is intended to be used. Thus, it allows the accepting party publishing a loan on-chain to decide whether the loan will be pro-rated or fixed (or other loan types in the future).  Assume the following scenario:  NFTfi - NFTfi Marketplace -   10  CriticalHighCodeCorrectedMediumCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedSecurityHighVersion1CodeCorrected        \f1. Alice talks off-chain to Bob and makes her the offer to lend 100 DAI for her ERC-721 collateral token as a fixed loan where the maximum repayment amount is 200 DAI. Bob sets the loan interest rate to 0 since it is not needed for the loan.  2. Bob sends the signed offer to Alice.  3. Alice  now  calls  acceptOffer  on  the  pro-rated  contract.  Loan  terms  get  prepared  for  later  calculations. _acceptOffer is called internally.  4. Now lender signatures are verified for the offer. Since nothing changed, the call succeeds.  5. Alice can pay back the loan cheaper than Bob agreed to.  In this scenario, Bob would need to have had the pro-rated contract approved for some DAI (e.g. Bob could be an active lender).  Furthermore, the signature could be used on multiple contracts. However, this requires the NFT to be a ERC-1155 token. In such a scenario, Alice could receive a pro-rated and a fixed loan while having only one signature of Bob.  Similar  issues  may  arise  in  the  case  of  signing  listings  where  the  lender  could  for  example  make  a pro-rated  loan  a  fixed  loan.  Since  the  borrower  could  be  an  active  user  of  the  platform,  making  both lending contracts an operator is a plausible assumption. Again, double-loans can be created if the NFT is an  ERC-1155  token  (assuming  the  contracts  are  operators  of  the  user's  NFTs).  Especially,  this  is dangerous, since the documentation describes giving default NFT approvals for NFTfi contracts.  In conclusion, the system is unaware for which contract a signature is intended to be used. Nonces can be reused since they are not stored globally but per lending contract. Hence, replay attacks are possible.    Now,  the  contract  address  is  signed  by  the  party  signing.  Thus,  a  loan  can  be  only  created  on  the intended contract.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Broken/Partial ERC165 Support",
        "body": "  Through inheritance the contracts in the composable directory inherit from ERC165 which implements EIP-165 that defines a standard method for publishing and detecting supported interfaces.  function supportsInterface(bytes4 interfaceID) external view returns (bool);  Not all of the aforementioned contracts do overwrite this function to extend its extended functionality.   ERC9981155Extension  additionally   implements   the   IERC998ERC1155TopDown  and   the  IERC1155Receiver interface.   NftfiBundler implements the INftiBundler functions while it does not explicitly implement the interface  (however, the naming suggests otherwise).  ImmutableBundle further implements the IERC721Receiver interface.  Hence, supportsInterface() will not return true for some of the interfaceId it supports.    The supportsInterface return true for interfaceId of all the implemented interfaces.  NFTfi - NFTfi Marketplace -   11  DesignMediumVersion1CodeCorrected         \f6.3   No Sanity Check on Revenue Share  fee.  The  percentage  can  be  set  with Partners  can  earn  a  share  of  PermittedPartners.setPartnerRevenueShare(). However, this method does not check whether the share exceeds 100%.  the  administrator   Assume a loan starts where that is the case. Then, this percentage would be stored in the loan extras of a  loan  which  cannot  be  renegotiated  nor  modified  in  any  way  for  the  loan.  Paying  back  the  loan  will ultimately  revert  since  an  underflow  would  occur  when  computing  the  fee  left  for  the  administrator. Hence, the borrower cannot retrieve his collateral back and liquidation is the only possibility to exit the loan.    100% cannot be exceeded anymore.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Renegotiation Replays Possible",
        "body": "  Renegotiation is a feature that allows the lender to give the borrower an alternative offer after the loan has been created. However, replay attacks may be possible here.  As  more  loan  types  will  appear,  more  loan  coordinator  contracts  could  be  deployed.  Following  could occur:  1. Borrower A has a loan connected to Coordinator A. Borrower B has a loan connected to Coordinator  B. The lender is in both cases the same.  2. Borrower A and the lender renegotiate the lending terms.  3. Borrower B replays the signature while the signature is not expired yet.  4. The lender has renegotiated two positions instead of only one.  This attack works as long as the data provided to renegotiation functions is the same.    Now, the contract address is signed. Thus, the signature can only be used on the valid contract.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   SmartNFTs May Not Be Composable With",
        "body": " Other Protocols  When a loan is accepted, two SmartNFT tokens are issued: A promissory note NFT to the lender, and an obligation note NFT to the borrower. The NFT collateral is stored in the NFTfi loan contract until either the borrower  repays  the  loan,  or  the  loan  is  liquidated.  However,  when  either  of  these  events  happen,  the SmartNFT tokens are transparently destroyed, and the addresses owning the respective NFTs receive the collateral and payback. That makes the SmartNFTS untraceable by smart contracts. That could be  NFTfi - NFTfi Marketplace -   12  CorrectnessMediumVersion1CodeCorrectedSecurityMediumVersion1CodeCorrectedDesignMediumVersion1CodeCorrected                        \fhazardous since the documentation specifies that a possible use-case of these NFTS could be trading them (e.g. selling the loan).  Assume the following scenario:  1. Lender and borrower agree on a loan, create it, and receive the SmartNFTs.  2. As  time  passes,  the  lender  decides  to  sell  the  promissory  note  on  a  platform  as  a  fixed-income  debt-bearing asset. The promissory note is deposited into a smart contract.  3. Now, the borrower pays back the loan. Both SmartNFTs are burned. The collateral is transferred to  the borrower. The payback is transferred to the NFT trade platform.  Ultimately,  the  auction  of  the  promissory  note  cannot  be  ended.  Hence,  funds  could  get  locked  in  the other contract while the lender does not receive anything.  Similarly, if the SmartNFTs are whitelisted in the PermittedList, funds could get lost in the NFTfi system since SmartNFTs could disappear at any time while a loan contract owning them would be clueless. Also, in such a way ImmutableBundles could lose funds.  To conclude, the immediate burning of SmartNFTs could be hazardous for NFTfi and other platforms as they could disappear at any point in time.    Now,  only  whitelisted  contracts  or  EOAs  can  hold  SmartNFTs.  Thus,  governance  must  ensure  that whitelisted contracts hold SmartNFTs that handle the scenarios above correctly.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Undeployable SmartNFTs",
        "body": "  SmartNFTs  are  used  for  the  promissory  note  and  obligation  receipt.  This  contract  inherits  from OpenZeppelin's access control contract. The deployment of the contract may fail.  _setupRole(DEFAULT_ADMIN_ROLE, _admin); grantRole(LOAN_COORDINATOR_ROLE, _loanCoordinator);  It sets _admin as the default administrator for all roles. If _admin is not msg.sender, then grantRole will fail.    _setupRole() is now used instead of grantRole in the constructor.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Anyone Can Liquidate",
        "body": "  The  renegotiation  feature  allows  to  renegotiate  even  if  the  loan  has  expired.  However,  anyone  can liquidate a loan. Thus, it could be possible that the result is not what the users desired. Moreover, fees that could have been earned will not be received.    Now, only the lender can liquidate.  NFTfi - NFTfi Marketplace -   13  CorrectnessMediumVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \f6.8   Double Getters  For  each  public  variable,  a  getter  is  automatically  generated.  However,  several  contracts  implement additional getter functions for public variables which leads to more code and, hence, higher deployment cost.  Some examples of double getters are:   partnerRevenueShare and getPartnerPermit in PermittedPartners.sol   nftPermits and getNFTPermit in PermittedNFTs.sol   erc20Permits and getERC20Permit in PermittedNFTs.sol  Similar  examples  can  be  also  found  in  other  contracts  such  as  DirectLoanCoordinator,  NftfiHub  and others. Removing double getters may reduce deployment cost.    The double getters have been removed by setting the public variables to private.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   Event Issues",
        "body": "  Many  events  are  emitted  in  the  system  helping  users  and  front-ends.  However,  some  event  could  be indexed to improve the experience. For example:   The permitted list contracts could index the address of the permitted contract.   Registry and loan contracts could have also indexed events  Furthermore, some important state changes do not emit events (e.g. updateMaximumLoanDuration or updateMaximumNumberOfActiveLoans). Note that also the renegotiation lacks events.  Emitting more events and indexing some of their parameters could improve the user-experience.    The events are now indexed and more events are emitted.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   Gas Inefficiencies",
        "body": "  Structs are passed to the loan functions as arguments. These structs are passed compactly since they use  for  example  uint32.  However,  some  state  variables  could  follow  this  principle.  For  example, adminFeeInBasisPoints will never be greater than 10000 but is a uint256. The structs store this as a  uint32.  However,  a  smaller  data  type  could  also  be  sufficient.  Similar  gas  optimizations  could  be made.  NFTfi - NFTfi Marketplace -   14  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \fFurthermore,  since  the  hub  should  not  change,  it  could  be  made  immutable  in  all  contracts.  For example, DirectLoanCoordinator stores it as an immutable while DirectLoanBase does not. Similar gas savings could be achieved.  Also, some state variable may be redundant. For example, the loan status stored in the loan coordinator. It  is  only  used  for  checking  something  when  burning  the  receipt  NFTs.  However,  burning  requires  the NFT owner to not be zero. Thus, the burn requirements are equivalent to the status checks.  Several  retrieved  values  from  storage  and  from  other  contracts  could  be  cached  in  memory  instead  of reading it multiple times. For example:   The NFT wrapper is retrieved in loanSanityChecks and when setting up the loan terms.   loanIdToLoan[id]  is  read  from  storage  into  memory  in  payBackChecks  and  then  in  payBackLoan.  Further redundant storage reads can be found.  Moreover, DirectLoanFixed._payoffAndFee is computed as follows:  uint256 interestDue = _loanTerms.maximumRepaymentAmount - _loanTerms.loanPrincipalAmount; uint256 adminFee = _computeAdminFee(interestDue, uint256(_loanTerms.loanAdminFeeInBasisPoints)); uint256 payoffAmount = ((_loanTerms.loanPrincipalAmount) + interestDue) - adminFee;  However, the addition could be removed since its result should be the maximum repayment amount.  Overall, gas consumption could be reduced by storing data more compactly, by reducing the number of storage reads and writes, and by removing redundant calculations.    Gas consumption has been reduced.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.11   Gas Inefficiencies in SmartNFTs ",
        "body": " supportsInterface()  NFTs must implement EIP-165's proposed method supportsInterface(). SmartNFT implement this method. Gas could be saved there by calling only the super method which would, in this case, evaluate all the implementations of the parent classes and cover all implemented interfaces.  Moreover,  deployment  cost  could  be  reduced  by  reducing  the  code  size  by  using  the  methods  and modifiers inherited from AccessControl. Thus, duplicated code could be removed.    The gas consumption of the code has been optimized.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.12   Maximum Number of Loans May Be Violated",
        "body": "  The  administrator  is  allowed  to  specify  a  maximum  number  of  loans  allowed.  The  following  invariant should always hold:  NFTfi - NFTfi Marketplace -   15  DesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                \ftotalActiveLoans <= maximumNumberOfActiveLoans  However,  that  could  be  violated.  Assume  that  these  are  equal.  Then,  the  administrator  calls updateMaximumNumberOfActiveLoan  to  reduce  the  maximum  number  of  active  loans.  Ultimately, the invariant could be violated.    An additional check was added to ensure that the invariant does not break.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.13   Maximum Repayment Amount",
        "body": "  The maximum repayment amount is specified by the lender. For both existing loan types this is value is relevant for accepting an offer while unused for accepting listings. The maximum repayment amount is calculated as the sum of the principal loan amount and the interest rate. However, that could be irritating for lenders as they could expect the maximum repayment amount specified by them to be used as the maximum.  Furthermore,  in  the  pro-rated  contract,  renegotiation  could  lead  to  a  scenario  where  the  interest  could grow even after time has elapsed since the interest rate is not modified.    The maximum repayment amount specified by the lender is now always used. Also, the interest rate is now updated for the pro-rated loan.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.14   Not Using safeTransfer for ERC-20",
        "body": " Transfers  Since  not  all  ERC-20  tokens  adhere  to  the  standard,  it  is  recommended  to  use  safeTransferFrom such  that  interactions  with  a  broader  range  of  tokens  are  possible.  However,  the  transfer  of  the renegotiation fee does not use the safe operation.    safeTransferFrom is now used.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.15   Renegotiation on Wrong Contract Possible",
        "body": "  Renegotiation is a feature that allows the lender to give the borrower an alternative offer after the loan has been created. However, it could be possible to renegotiate a loan on the wrong contract.  NFTfi - NFTfi Marketplace -   16  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \fThis becomes possible if the maximum loan duration is greater than the current block timestamp and no renegotiation fee is charged.  1. Lender and borrower agree on a direct fixed loan.  2. Lender signs the renegotiation with a high new loan duration for the pro-rated contract.  3. The borrower calls renegotiate on the pro-rated loan contract.  4. The correct SmartNFT ID is fetched from the shared coordinator while the loan data is empty as it is  stored per lending contract.  5. Thus,  if  the  maximum  loan  duration  and  the  new  loan  duration  are  sufficiently  high  and  the  renegotiation fee is 0 (no ERC-20 transfer occurs), all checks pass.  However,  as  the  NFT  wrappers  are  not  initialized,  this  leads  to  unnecessary  state  modifications  while funds cannot be transferred.    Now, the loan contract is compared to the stored contract in the loan coordinator disallowing such wrong renegotiations.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.16   Repetitive Validation on Batch Child Transfer",
        "body": "  safeBatchTransferChild()  allows  children  of  a  token  to  be  batch  transferred.  msg.sender  is validated in each loop iteration to be the root owner of tokenId. However, since only the children of one token id can be batch transferred at once, it is sufficient to validate only once. Ultimately, storage reads and, hence, gas consumption could be reduced.    The method has been optimized.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.17   Specification Mismatch",
        "body": "  The code has several occurrences of specification mismatch. Some examples are:   DirectLoanProRated._setupLoanTermsListing documents that it is a fixed loan.   ERC998TopDown.childExists  specifies  that  it  returns  true  if  a  child  exists.  However,  in  the  extended classes this will return false for ERC-1155 tokens.   ERC998TopDown.ownerOfChild  specifies  that  parameter  tokenId  while  it  has  only  parameter  childTokenId.  Specification changed:  The specification has been updated.  NFTfi - NFTfi Marketplace -   17  DesignLowVersion1CodeCorrectedCorrectnessLowVersion1Speci\ufb01cationChanged                \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Fee Avoidance",
        "body": "  The liquidation allows the administration fees to be avoided as follows:  1. The borrower transfers his receipt to a contract. As long as the lender has transferred his receipt to  the contract, the borrower can withdraw his receipt.  2. The lender signs a renegotiation and approves the cheating contract.  3. The  lender  calls  the  cheating  contract  method  that  takes  the  renegotiation  and  the  renegotiation  parameters as arguments (and checks whether the parameters are fair).  4. The contract, having the obligatory note, calls renegotiate.  5. The contract pulls the promissory note from the lender.  6. The loan gets liquidated and the contract holds the NFT collateral.  7. The  cheating  contract  implements  a  payback  function  that  is  cheaper  for  the  borrower  and  more profitable  for  the  lender  (splitting  the  admin  fee).  Moreover,  as  a  safeguard  for  the  lender  it implements a liquidation function.  Ultimately, no fees are distributed to the administration while the lender and borrower could profit.  This  behaviour  cannot  occur  anymore.  Since  only  EOA  addresses  could  hold  a  SmartNFT  in  such  a case, the lender would need to trust the borrower.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Front-running Offers",
        "body": "  Alice may receive an Offer of Bob for an ERC-1155 token. Charlie could call acceptOffer() with Bob's signature which would initiate a loan between Bob and Charlie for the same ERC-1155 token. However, Bob's  intend  could  have  been  to  only  allow  Alice  to  take  a  loan  from  him.  From  the  discussions  with NFTfi,  it  was  clarified  that  the  ERC-1155  tokens  to  be  supported  are  the  ones  that  have  at  most  one token per ID.  Hence, governance needs to be careful when whitelisting ERC-1155 contracts.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Outdated Compiler Version",
        "body": "  The solc version is fixed in the hardhat configuration to version 0.8.4. At the time of writing the most recent Solidity release is version 0.8.7.  NFTfi - NFTfi Marketplace -   18  NoteVersion1NoteVersion1NoteVersion1            \f7.4   Possible Inconsistencies After Registry Changes  Many values are stored such that the loan can be resolved, no matter the changes made to the system (e.g. whitelisting ERC-20 tokens). However, the loan registry is global for the whole system. That could introduce several issues:   Assume contract A is stored in the loan registry for loans of type B and Loans are still active. Now, administration  changes  the  contract  for  loan  type  of  B  to  contract  C.  That  could  lock  the  funds  in contract A and make the loans unresolvable or introduce other issues related to that.   The loan coordinator could change in the hub. Thus, loans could become all invalid since changing  the new loan coordinator could also change the smart NFT token contract address.   Loans could become unresolvable if the loan coordinator loses access to a Smart NFT contract.  These and similar issues could occur.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   Supported Tokens",
        "body": "  The  protocol  supports  ERC-20  tokens  as  lending  capital.  However,  whitelisting  for  example  ERC-777 tokens (backward-compatible with EIP-20) may lead to unwanted behaviour. For example, paybacks of loan could be blocked by reverting on token reception.  Also,  borrowers  may  receive  less  than  expected  if  the  ERC-20  tokens  collect  transfer  fees  while  the paybacks could fail.  Furthermore,  some  NFTs  could  be  added  that  could  be  burnable  externally  or  have  other  unexpected non-standard behaviour.  In general, governance has to be careful with whitelisting tokens.  NFTfi - NFTfi Marketplace -   19  NoteVersion1NoteVersion1      \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Floating Dependencies Versions",
        "body": "  The versions of the contract libraries imported as git submodules by the foundry are not fixed. With new versions  being  pushed  to  the  dependency  repositories,  the  imported  code  can  change  (e.g.,  via forge update) and lead to unexpected behavior by the smart contracts of the project.  The version of the foundry dependency can be specified as described here.  Acknowledged:  Circle acknowledged this issue and decided to keep the code unchanged due to the following reason:  The dependencies in repository are pinned git submodules, which won't be changed without explicitly committing a new version to master, so no change is needed.  We would like to highlight that the pinned version of OpenZeppelin dependency is 4.3.1 which includes a vulnerability in signature handling, however the reviewed code is not affected.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Gas Optimizations",
        "body": "  Circle - Circle EVM Bridge -   13  SecurityDesignCorrectnessCriticalHighMediumLowAcknowledgedAcknowledgedCodePartiallyCorrectedCodePartiallyCorrectedAcknowledgedDesignLowVersion1AcknowledgedDesignLowVersion1Acknowledged                    \f1. The  MessageTransmitter  contract  uses  a  mapping  of  boolean  values  to  keep  track  of  used nonces,  which  is  inefficient,  due  to  the  Solidity  compiler  automatically  padding  bool  values  with zeroes  when  writing  them  to  storage.  It  is  more  efficient  to  use  a  mapping  of  a  type  such  as uint256 that takes up an entire storage slot as the bool values anyway cannot be packed in this case.  2. Functions sendMessage and sendMessageWithCaller declare a return variable _nonce but it  remains unused as the variable _nonceReserved is returned in both cases.  3. Attestable  contract  has  a  constant  value  of  65  assigned   to   immutable  variable  signatureLength. Changing its type to constant reduces slightly the gas consumption.  4. At the sending end, MessageTransmitter keeps track of available nonces for each destination domain.  The  contract  could  be  made  more  efficient  in  terms  of  storage  used  if  a  single  global nonce is used for all remote domains.  5. Function  _recoverAttesterSignature  computes  a  hash  of  _message  and  then  calls recover from ECDSA library to get the address of the signer. This function is only called inside the for-loop  redundant computation of the hash for the same message.  function  _verifyAttestationSignatures,   therefore  causing   in   6. The  function  disableAttester  performs  two  calls  to  getNumEnabledAttesters  which performs  an  SLOAD  operation.  Although  the  second  SLOAD  costs  less  (100  gas)  due  to  storage being warm at that point, the function could be optimized by storing the value in memory.  7. Similarly,  the  function  addLocalTokenMessenger  performs  an  unnecessary  SLOAD  when  emitting the event.  8. The location of the following arguments can be changed from memory to calldata to make them and  MessageTransmitter.sendMessage;   messageBody  more  newMessageBody in MessageTransmitter.replaceMessage.  gas-efficient:   in   9. The function encodeHex in the library TypedMemView always checks if the iterator is not on the  16th byte:  for (uint8 i = 31; i > 15; i -= 1) {     uint8 _byte = uint8(_b >> (i * 8));     first |= byteHex(_byte);     if (i != 16) {         first <<= 16;     } }  As an improvement, the loop can iterate in the range i > 16 so the if statement inside the loop can be removed. The same optimization is possible for the next loop which iterates over the lower 16 bytes. By doing so, gas consumption would be decreased.  Acknowledged:  Circle has applied most of the optimizations listed above. More specifically, optimizations 1-6 and 8 were implemented in the updated codebase. Optimizations 7 and 9 were acknowledged but not addressed in code. We detail the fixes:  1. usedNonces is changed to be a mapping of bytes32 to uint256.  2. Circle has corrected both sendMessage and sendMessageWithCaller.  3. signatureLength is changed to be a constant.  4. MessageTransmitter  keeps  track  of  the  next  available  nonce  via  keeping  a  scalar  variable,  namely nextAvailableNonce.  Circle - Circle EVM Bridge -   14  \f5. In  _verifyAttestationSignatures  the  digest  of  the  message  is  firstly  calculated  and  sent  down to each call of _recoverAttesterSignature.  6. disableAttester  fetches  length  of  the  enabledAttesters  and  stores  it  in  a  memory  variable,  instead of accessing the storage twice.  7. Circle  has  acknowledged  this  optimization  but  has  decided  to  keep  the  code  unchanged  as  the  function addLocalTokenMessenger is not expected to be called often.  8. messageBody   originalMessage  MessageTransmitter.sendMessage,  newMessageBody in MessageTransmitter.replaceMessage are changed to calldata.  in   and  9. Circle has decided to keep the TypedMemView library as-is.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   Inconsistent Natspec Descriptions",
        "body": "  The natspec description of the following functions is not consistent with the implementation:  1. _sendMessage: @dev Increment nonce, ... is not aligned with the implementation.  2. _getLocalToken:  @dev  Reverts  if  unable  to  find  an  enabled  local  token...,  but the implementation does not revert.  3. onlyWithinBurnLimit: ... burn limit per-transaction for given 'burnToken'. The modifier only checks that the limit is not exceeded in a single function call, however, if multiple calls are executed within a transaction, the limit per-transaction is not enforced.  4. BurnMessage library: version field is declared as 4 bytes, but the type is set to uint8 instead of  uint32.  5. To fetch the 12 bytes containing loc, a variable of TypedMemView should be shifted 120 bits (3 empty + 12 len = 15 bytes) to the right and be masked. The comment inside the assembly block has wrongly stated 12 bytes of the loc instead of len.  Code partially corrected:  The reported inconsistencies 1-4 have been fixed in the updated codebase, while the last one remains unchanged.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.4   Missing Sanity Checks",
        "body": "  The following functions set important state variables or parameters, but do not perform any sanity check on input parameters:  1. MessageTransmitter.constructor.  2. TokenMessenger.constructor.  3. MessageTransmitter.setMaxMessageBodySize.  4. newMintRecipient in TokenMessenger.replaceDepositForBurn.  Code partially corrected:  Circle - Circle EVM Bridge -   15  CorrectnessLowVersion1CodePartiallyCorrectedDesignLowVersion1CodePartiallyCorrected                \fchecks   Sanity  and in  TokenMessenger.replaceDepositForBurn listed above, however no sanity checks were added for points 1 and 3.  TokenMessenger.constructor   added   were   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.5   Potential Event Reordering Due to Reentrancy",
        "body": " in MessageTransmitter  The function sendMessage does not have any access restriction, and the caller can pass any arbitrary value for recipient. On the other side of the bridge, the function receiveMessage gives execution to recipient and emits an event afterward. Therefore, a malicious recipient could reenter the contract causing events to be emitted in an inconsistent order:  require(     IMessageHandler(_m._recipientAddress()).handleReceiveMessage(         _sourceDomain,         _sender,         _messageBody     ),     \"handleReceiveMessage() failed\" );  // Emit MessageReceived event emit MessageReceived(     msg.sender,     _sourceDomain,     _nonce,     _sender,     _messageBody );  Acknowledged:  Circle acknowledged the issue but has decided to keep the code unchanged.  Circle - Circle EVM Bridge -   16  SecurityLowVersion1Acknowledged          \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings  -Severity Findings   Default Optimizer Configuration   Inconsistent Type Used for Nonce    Missing Event in Ownable   0  0  0  6   Unchecked Return Value for Functions From TypedMemView    Unrelevant Indexed Event Fields    Wrong Values Emitted in Event   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Default Optimizer Configuration",
        "body": "  The compiler optimizer is not enabled explicitly by the foundry configuration, hence the default optimizer enabled by the foundry with 200 runs is used:  [profile.default] src = 'src' out = 'out' libs = ['lib']  The  optimizer  uses  the  specified  number  of  runs  to  perform  a  trade-off  between  deployment  cost (bytecode  size)  versus  execution  costs.  A  high  number  of  runs  indicates  to  the  optimizer  that  the reduction of execution costs has a higher priority than deployment costs.    The configuration file foundry.toml has been updated to enable the optimizer with 10_000 runs.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Inconsistent Type Used for Nonce",
        "body": "  The  contract  MessageTransmitter  uses  type  uint64  for  storing  nonces,  however,  the  internal function _hashSourceAndNonce uses uint256 for the argument _nonce.  Circle - Circle EVM Bridge -   17  CriticalHighMediumLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                 \f  Type  of  _nonce  in  _hashSourceAndNonce  is  changed  to  uint64  and  is  consistent  throughout  the code.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Missing Event in Ownable",
        "body": "  The constructor of Ownable sets the deployer of the contract as owner, however, the respective event is not emitted.    The constructor of Ownable now calls the internal function _transferOwnership which sets the new _owner and emits the respective event.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Unchecked Return Value for Functions From",
        "body": " TypedMemView  The  functions  ref  and  slice  of  the  library  TypedMemView  return  a  memory  view  of  type  bytes29. However,  both  functions  can  return  NULL  which  represents  an  invalid  type  (ff_ffff_ffff)  if  the memory  is  malformed.  The  calling  functions  in  MessageTransmitter,  TokenMessenger  and Message do not check for the invalid type.    libraries   functions The  _validateMessageFormat and _validateBurnMessageFormat. These functions are now used to validate the return values from functions ref and slice from the library TypedMemView.  extended  with   BurnMessage   Message   been   have   and   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Unrelevant Indexed Event Fields",
        "body": "  Only relevant fields of the events should be indexed, the ones which it makes sense to search for. The following events index also uint values:  1. amount in TokenMessenger.DepositForBurn  2. amount in TokenMessenger.MintAndWithdraw  3. oldSignatureThreshold   and   newSignatureThreshold   in  Attestable.SignatureThresholdUpdated  4. burnLimitPerTransaction in TokenController.SetBurnLimitPerTransaction  5. newMaxMessageBodySize in MessageTransmitter.MaxMessageBodySizeUpdated  Circle - Circle EVM Bridge -   18  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \fOn the other hand, the event OwnershipTransferred does not index its argument. EVM opcodes for logging  events  with  more  indexed  arguments  consume  more  gas.  We  suggest  for  each  event  field reevaluate if indexing is necessary.    All events listed above were revised such that uint arguments are no longer indexed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Wrong Values Emitted in Event",
        "body": "  Function  updateAttesterManager  uses  the  same  variable  newAttesterManager  in  the  emitted event. The natspec of the event specifies that the first parameter is the address of the previous attester manager, while the second parameter is the new attester manager.  Code partially corrected:    to  pass  msg.sender  and The  function  updateAttesterManager  has  been  revised  in  newAttesterManager  as  parameters  to  the  event  AttesterManagerUpdated.  However,  the  first parameter  msg.sender  is  the  owner  of  the  contract,  and  not  necessarily  the  previous  manager  as described in the event definition.    In  attesterManager role:  ,  the  following  code  is  used  to  emit  the  previous  and  new  addresses  for  the  address _oldAttesterManager = _attesterManager; _setAttesterManager(newAttesterManager); emit AttesterManagerUpdated(_oldAttesterManager, newAttesterManager);  Circle - Circle EVM Bridge -   19  CorrectnessLowVersion1CodeCorrectedVersion2Version3        \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Compiler Version Not Fixed and Outdated",
        "body": "  The  solidity  compiler  is  fixed  only  in  contracts  Ownable,  Pausable  and  Rescuable,  while  other contracts use the following pragma directive:  pragma solidity ^0.7.6;  Although no later compiler version 0.7.x exist, it is a best practice to fix the compiler version in contracts or configuration file.  Known bugs in version 0.7.6 are listed here.  More information about these bugs can be found here: https://docs.soliditylang.org/en/latest/bugs.html  At the time of writing the most recent Solidity release is version 0.8.17 which contains some bugfixes. However, version 0.8 introduced breaking changes and would require heavy refactoring of the contracts.   changes: All contracts now use the following pragma directive:  pragma solidity 0.7.6;  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Non-canonical Conversion of Bytes to",
        "body": " Address  The  function  Message.bytes32ToAddress  implements  the  following  statement  to  perform  the  type conversion:  function bytes32ToAddress(bytes32 _buf) public pure returns (address) {     return address(uint160(uint256(_buf))); }  Note that due to downcasting, higher bits of _buf will be omitted. Thus, it is possible to have different input values _buf map to the same address.   changes: Circle has decided to emphasize this behavior in the code by appending the following  description to the function's natspec:  * @dev Warning: it is possible to have different input values _buf map to the same address. * For use cases where this is not acceptable, validate that the first 12 bytes of _buf are zero-padding.  Circle - Circle EVM Bridge -   20  NoteVersion1Version2NoteVersion1Version2      \f7.3   Overflow and Underflow Occurring in TypedMemView  The  function  TypedMemView.index  takes  as  the  third  argument  the  length  of  the  returned  value  in bytes _bytes, which is of type uint8. The length in bits is computed as follows:  uint8 bitLength = _bytes * 8;  If _bytes is 32, the multiplication above overflows as the result 256 cannot be stored in a variable of type  uint8,  hence  bitLength  stores  0.  Furthermore,  when  bitLength  is  passed  to  function leftMask an underflow occurs in the following assembly code:  assembly {     mask := sar(         sub(_len, 1),         ...     ) }  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   Potential Single Points of Failure",
        "body": "  Circle  EVM  Bridge  relies  on  a  centralized  attestation  service  (attesters)  to  guarantee  the  integrity  of messages  transmitted  between  chains.  The  protocol  assumes  that  an  adversary  cannot  compromise enough attesters (signatureThreshold) at the same time, otherwise, the bridge becomes vulnerable.  Besides  the  assumption  above,  we  would  like  to  highlight  below  the  accounts  that  are  potential  single points of failure for the security of the bridge.  Message  Transmitter:  Any  account  with  role  owner  or  attesterManager  should  be  carefully protected.  If  any  account  with  these  roles  gets  compromised,  it  can  freely  enable  new  attesters  and execute arbitrary cross-chain messages. Furthermore, the role pauser is critical to be protected in order to keep the bridge operational and avoid denial-of-service (DoS) attacks.  Token Messenger: The account with the role owner should be carefully protected, as if this account gets  compromised,  it  can  set  arbitrary  addresses  as  token  messengers  in  remote  domains  and  then process malicious messages.  Token Minter: The accounts with roles owner and tokenController should be carefully protected. If  any  of  these  accounts  get  compromised,  the  mapping  remoteTokensToLocalTokens  can  be manipulated, which can consequently create severe issues, e.g., an attacker can burn low value tokens in one chain but mint the same amount in high value tokens in the other chain.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   Return Value of Burn Function",
        "body": "  The  system  supports  tokens  that  implement  the  IMintBurnToken,  i.e.,  functions  transfer, transferFrom and mint return a boolean value. However, burn function is assumed to not return a  Circle - Circle EVM Bridge -   21  NoteVersion1NoteVersion1NoteVersion1            \fvalue  but  revert  if  unsuccessful.  This  behavior  is  in  line  with  the  implementations  of  USDC  and ERC20Burnable from OpenZeppelin.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.6   Signature Threshold Restrictions",
        "body": "  The documentation states that the threshold for the required signatures should not be below 2, however, this is not enforced by the codebase. On deployment, the constructor of Attestable contract takes only one attester address as an argument and sets signatureThreshold = 1.  Furthermore,  the  function  setSignatureThreshold  does  not  enforce  that  the  threshold  is  set  to  at least 2. Circle is aware of this behavior and does not intend to enforce the minimum threshold in code.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.7   Visibility Modifiers for Constructors",
        "body": "  Contracts  Attestable  and  Ownable  declare  the  visibility  of  constructors  as  public,  however,  such visibilities in compiler version 0.7.6 are obsolete. More information.   changes: The visibility for constructors has been removed in the updated codebase.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.8   Attestable._recoverAttesterSignature",
        "body": " Function Visibility Can Be Pure  The  modifier  of  the  function  _recoverAttesterSignature  can  be  changed  to  pure,  as  it  neither writes nor reads the storage of the contract.   changes: The visibility of the function above has been changed to pure.  Circle - Circle EVM Bridge -   22  NoteVersion1NoteVersion1Version2NoteVersion1Version2            \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Unprotected Escrow Funds",
        "body": "  L1DAIBridge.deposit() transfers DAI from a user-specified address from to the L1Escrow contract to lock DAI on layer one. However, a malicious user could specify from to be the L1Escrow contract that holds all of the locked funds. The call to DAI.transferFrom() will succeed since the escrow must have had approved the bridge contract. Ultimately, unbacked DAI could be minted on L2 and funds from the escrow could be stolen.  Consider the following scenario:  1. User calls deposit() with from being the escrow contract.  2. The   to  amount <= allowance[escrow][bridge].  self-transfer   from   and   escrow   succeeds   as   long   as  3. The ceiling check passes as long as balanceOf(escrow) <= ceiling since the balance does  not change.  4. Ultimately, a message to L2 is sent and unbacked DAI on L2 is minted.  5. Repeat the process.  6. Withdraw DAI from L2 to L1, such that the escrow is emptied.  MakerDAO - StarkNet-DAI-Bridge -   12  CriticalCodeCorrectedHighCodeCorrectedMediumCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSecurityCriticalVersion1CodeCorrected            \fThe README.md file in the repository states:  ### Initial configuration      ... Unlimited allowance on `L1Escrow` should be given to `L1DAIBridge`.  Hence an attacker may drain all DAI out of the escrow.  Furthermore, e.g. by frontrunning a deposit transaction or exploiting an unlimited approval given by the user to the bridge it is possible to steal L1 DAI from users. Consider the following scenario:  1. User  A  intends  to  deposit  DAI  to  L2  and  approves  the  bridge  contract.  He  either  gives  an  exact approval  for  the  amount  he  wants  to  deposit  or  may  give  an  unlimited  approval  as  he  trusts  the bridge contract and intends to use it in the future. Next he crafts a transaction to deposit.  2. User B calls deposit() and specifies the from address to be user A. The call succeeds and B receives funds on L2. Note that the DAI locked on L1 are from user A. This transaction frontruns the deposit call coming from user A.  3. User A's deposit is executed but fails due to lack of allowance.  Note that although they are known to be potentially dangerous it is quiet common that users give infinite approval to such systems they trust and intend to interact with frequently.    The  from  parameter  has  been  removed  from  function  deposit.  The  DAI  amount  is  now  transferred from msg.sender to the escrow. Hence the issue described above no longer exists.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   L2 DAI Allows Stealing",
        "body": "  The transfer function of the L2 DAI contract allows stealing tokens from other users. The attack works as follows:  1. Within the amount field of the transfer function the user specifies an invalid Uint256. Note that uint256_check  is  never  called.  To  steal  i  token  wei,  the  attacker  specifies  P-i  to  be amount.low  and  0  to  be  amount.high.  The  low  amount  could  be  interpreted  as  the  negative number -i.  2. The  uint256_le(amount,  sender_balance)  check  will  be  passed  as  it  will  ultimately  compute the following:  1 - is_nn(amount.low - (sender_balance.low+1))  If for example the sender's (attacker's balance) is 0, that check will pass.  3. The  uint256_sub(sender_balance,  amount)  computation  will  result  in  an  increased  sender_balance due to the specially crafted amount.  4. The  uint256_add(recipient_balance,  amount)  computation  will  result  in  a  decreased  recipient_balance due to the specially crafted amount.  Note that the decrease of the recipient_balance is also the increase of the sender_balance. In other words, the sender gains as many tokens as the recipient loses. Or more concisely, the sender can steal all of the tokens of the receiver. So, if i==1 then one token wei is stolen. If i==2 then two wei are stolen.  MakerDAO - StarkNet-DAI-Bridge -   13  SecurityHighVersion1CodeCorrected        \fThe  only  precondition  for  the  attack  is  that  the  uint256_le(amount,  sender_balance)  can  be passed  for  manipulated  amount  values.  Note  that  the  current  hints  prevent  a  proof  generation  for  this attack in uint256_add, but hints can freely be changed and the verifier will accept it.    amount  is  now  validated  in  the  internal  function  _transfer.  Thus,  neither  transfer()  nor transfer_from  can  perform  computations  with  invalid  integers.  Ultimately,  the  Uint256  library functions receive the expected inputs and, thus, perform the documented computations.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Frontrun cancelDeposit()",
        "body": "  L1->L2   After  L1DAIBridge.startDepositCancellation()  L1DAIBridge.cancelDeposit() can be used to complete the cancellation and retrieve the DAI.  initiated  has   cancellation   message   delay   been   time   and   has   the   using passed,  The caller of the function must provide the details to retrieve the message (the amount, the l2Recipient and the nonce) and as parameter l1Recipient any address to receive the funds on L1.  There is no access control, the first caller can retrieve the DAI to any address.    msg.sender  is  now  included  in  payload  of  deposit(),  startDepositCancellation()  and cancelDeposit(). Hence, a successful cancellation requires that the same msg.sender in all three calls of the process. Otherwise, the payload would be different.  payload[3] = uint256(uint160(msg.sender)); StarkNetLike(starkNet).cancelL1ToL2Message(l2DaiBridge, DEPOSIT, payload, nonce);  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   ForceWithdrawal Needs Prior Approval",
        "body": "  In  the  case  that  a  user  believes  they  are  censored,  the  user  can  initiate  the  withdrawal  using  the forceWithdraw function of the L1DAIBridge. When the L2 network works as expected, the withdrawal request is handled.  This however has some prerequisites:  1. The  user  needs  to  have  registered  his  L1  address  in  the  L2  registry  prior  to  initiating forceWithdraw(). Note that this may no longer be possible when the L2 network is censoring transactions hence this should be done by the users before receiving DAI on L2.  2. The  execution  of  finalize_force_withdrawal  on  L2  in  case  the  Layer2  network  complies requires  that  the  user  has  previously  given  allowance  to  the  l2_dai_bridge.  Again,  giving  the approval  at  this  point  in  time  may  no  longer  be  possible  in  case  the  L2  network  censors transactions.  MakerDAO - StarkNet-DAI-Bridge -   14  SecurityMediumVersion4CodeCorrectedCorrectnessMediumVersion1CodeCorrectedSpeci\ufb01cationChanged                  \f# check allowance let (contract_address) = get_contract_address() let (allowance : Uint256) = IDAI.allowance(dai, source, contract_address) let (allowance_check) = uint256_le(amount, allowance) if allowance_check == 0:     return () end  This  requirement  is  not  documented  and  may  come  as  a  surprise  for  the  user.  Note  that  for  normal withdrawals  from  L2  using  withdraw  no  such  allowance  is  needed.  Furthermore  without  the  check  in finalize_force_withdrawal  the l2_dai_bridge  is  a  ward  in  the  DAI  contract  and  has  the  privilege  to  burn  the  DAI  of  any  address without the need for an approval.  the  DAI  would  work  as   the  withdrawal   /  burning  of   The case that the L2 network may only censors transactions other than forced withdrawals (in order to avoid detection of the misbehavior) and its implication must be considered.  Overall the ForcedWithdrawal process and it's restrictions is not documented enough.  Code corrected and specification changed:  and   hence   Issue  1)  was  addressed  by  improving  the  documentation.  The  documentation  now  clearly  states  what actions  are  required  before  a  forced  withdrawal  can  be  executed.  The  enhanced  documentation  also resolves 2), note that in the updated code a ward of the DAI contract no longer has the privilege to burn understand  why needed.  DAI  finalize_force_withdrawal  must  check  whether  the  approval  exists:  Burning  without  the allowance would result in the transaction to revert. The prover can't prove failed executions, reverts are indistinguishable  from  censored  messages.  By  checking  the  allowance  and  gracefully  terminate  the transaction  when  no  sufficient  allowance  exist,  the  transaction  can  be  executed.  Hence  the  message from L1 can be processed which allows to clear the message in the StarkNet contract on Ethereum. This proves that the transaction must have been executed on L2.  important   approval   the   It's   to   is   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   L2 Address Sanity Checks",
        "body": "  In StarkNet users do not have addresses. Transactions sent to the network have the 0 address as caller. In  order  to  identify  accounts  via  addresses,  each  user  deploys  his  account  contract  and  interacts  with contracts such as the DAI token using his account-contract.   The deposit() function of the L1DAIBridge contract allows users to deposit with the to address set to 0. The execution of finalize_deposit initiated by the l1_handler on l2 however will fail as minting DAI for the zero address will revert. As a result the deposited DAIs on L1 will be locked in the escrow.  Furthermore, note that to will be received as a felt on L2. Hence, the true to address on L2 will be to  %  R.  Therefore,  it  could  be  possible  to  for  example  specify  address  R  on  L1  which  will  map  to zero-address (similarly R+1 will map to address 1). Users could be protected from errors by restricting the allowed address range on L1.   L2 DAI allows to give approvals specifying the 0 address as caller. All holders of L2 DAI must be aware  that  this  is  very  dangerous  and  means  that  anyone  crafting  an  external  transaction  to  the network can transfer their DAI using this approval.  MakerDAO - StarkNet-DAI-Bridge -   15  DesignMediumVersion1CodeCorrected        \f A user could specify the l2_dai contract as the recipient of the funds on deposit. Since the L1 call would succeed while the L2 call to the l1_handler would fail, the cross-layer message would remain unconsumed.    The code does the following checks now on L1:   to != 0 to ensure that the address is non-zero.   to != l2Dai to prevent a failing mint.   to < SN_PRIME to prevent a possible StarkNet overflow.   All functions related to approvals in the l2 DAI contract now forbid approving the zero-address.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Relay Parameter Mismatch",
        "body": "  The  L1GovernanceRelay  is  used  to  send  messages  to  the  L2  GovernanceRelay  to  execute  spells. However,  the  parameters  sent  by  the  L1  contract  and  the  parameters  the  L2  contract  receives  do  not match. Ultimately, governance spells cannot be relayed to L2.  More specifically, the L1GovernanceRelay sends a message to L2 as follows:  uint256[] memory payload = new uint256[](2); payload[0] = to; payload[1] = selector;  StarkNetLike(starkNet).sendMessageToL2(l2GovernanceRelay, RELAY_SELECTOR, payload);  However, the L2 side of the governance relay consumes the message as follows:  @l1_handler func relay{   syscall_ptr : felt*,   pedersen_ptr : HashBuiltin*,   range_check_ptr  }(    from_address : felt,    target : felt  ):    let (l1_governance_relay) = _l1_governance_relay.read()    assert l1_governance_relay = from_address    let (calldata : felt*) = alloc()    delegate_call(target, EXECUTE_SELECTOR, 0, calldata)    return ()  end  The  arguments  of  the  L1  handler  should  consist  of  the  from_address  and  payload.  However,  the payload created on L1 has two elements. That ultimately lets the execution of a governance spell fail.  MakerDAO - StarkNet-DAI-Bridge -   16  CorrectnessMediumVersion1CodeCorrected        \f  The unused selector was removed from the payload, the payload now contains the spell only.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Unlimited Approvals and the Range of Uint256",
        "body": "  DAI on L1 supports unlimited approvals using uint256(-1) as magic value. When an approval for this magic value is given, the spender can spend the funds of the token holder without the allowance being reduced.  Similarly  the  DAI  contract  in  cairo  supports  an  unlimited  approval  using  a  different  magic  number.  As Uint256 work differently in cairo, it's possible to define a magic value outside the actual range of Uint256. In cairo, a Uint256 is represented by a struct containing two felt members:  struct Uint256:     # The low 128 bits of the value.     member low : felt     # The high 128 bits of the value.     member high : felt end  However note that a felt can store more than 128 bits, so a Uint256 represented by such a struct may contain a value exceeding the max uint256 value.  The code of the DAI cairo contract, however, takes advantage of this special property of the Uint256 type and defines the magic number for the unlimited approval as:  const MAX_SPLIT = 2**128 let MAX = Uint256(low=MAX_SPLIT, high=MAX_SPLIT)  Note  that  the  common  library  for  Uint256  offers  a  function  uint256_check  which  checks  if  the  given Uint256 is actually valid. The code of the DAI cairo contract uses this function to check whether amounts regarding  balances  are  valid.  In  contrast,  the  code  is  generally  not  using  uint256_check()  when handling or checking approvals. That results in following potentially intended and/or strange behaviour:   Function approve can be used to give allowance for a valid amount, the magic number or an invalid  uint256 value.   Function  increase_allowance  does  not  work  on  such  allowances  due  to  the  carry  over. However,  increasing  with  bad  input  values  could  decrease  the  allowance  (in  a  similar  fashion  as described in L2 DAI allows stealing).   Function  decrease_allowance  works.  However,  note  that  decreasing  to  the  magic  number  results in unlimited approval so that allowance has been increased instead of decreased.  Concluding, the selection of the magic value outside the valid range for Uint256 could lead to unexpected and  undocumented  behaviour  due  to  an  implied  lack  of  Uint256  validity  checks.  Furthermore,  the deviation from L1-DAI's magic value may confuse users.    MAX_SPLIT has been renamed to ALL_ONES and redefined to 2**128-1. Also, uint256_check() is called  now  in  the  functions  approve,  increase_allowance  and  decrease_allowance.  Since  the inputs  are  always  validated  and  allowance  cannot  be  out  of  the  valid  Uint256  range,  the  unintended behaviour cannot occur anymore.  MakerDAO - StarkNet-DAI-Bridge -   17  DesignMediumVersion1CodeCorrected        \f6.8   ERC-20 Functions Have No Return Values  EIP-20  specifies  that  for  example  transfer  has  a  boolean  return  value.  However,  L2  DAI  does  not return anything.    Return values have been implemented for the ERC-20 functions.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   Inconsistent Version Pragma",
        "body": "  Different  to  the  L1Escrow  contract,  the  L1DAIBridge  and  the  L1GovernanceRelay  contract  feature following version pragma:  This allows the contracts to be compiled with any Solidity version >= 0.7.6 including more recent major version which may feature changes in the syntax.  The Solidity documentation states:  Source files can (and should) be annotated with a version pragma to reject compilation with future compiler versions that might introduce incompatible changes.  For  https://docs.soliditylang.org/en/develop/layout-of-source-files.html#version-pragma  information,   please   more   refer   to:    The pragmas have been changed to:  pragma solidity ^0.7.6;  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   Inefficiency in Reading Allowances",
        "body": "  In  function  burn  of  the  DAI  cairo  contract  the  allowance  is  always  read.  However,  it  is  only  used  if check_allowances  ==  1  is  true.  Thus,  the  efficiency  of  the  functionality  could  be  improved. Similarly, that is the case for transferFrom().    In the updated code wards no longer have special privileges in dai.burn(). Due to the changed code, the issue described above no longer applies.  MakerDAO - StarkNet-DAI-Bridge -   18  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                          \f6.11   Lack of L1-address Sanity Checks on L2  L1 addresses on L2 are of felt type. However, that could ultimately lead to bad user-input on L2 when passing L1 addresses since L1 addresses have 160 bits which is less than the number of bits the felt type is represented with.  For example, in function withdraw() of the L2 bridge contract a user passes an L1 address as felt which could to a bad address being passed to L1.    A check has been added to send_finalize_withdraw() with ensures that the destination is a valid L1 address. This function is used by both, withdraw and finalize_force_withdrawal.  In  the  initial  round  of  fixes  the  assert_l1_address  function  contained  unnecessary  declarations  of local syscall_ptr and local pedersen_ptr which now have been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.12   Unused Code",
        "body": "  The L1DAIBridge contract defines the struct SplitUint256. However, it remains unused.    The unused struct was removed.  MakerDAO - StarkNet-DAI-Bridge -   19  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected              \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Compiler Panicking for an Out of Range",
        "body": " Integer Node  For  exponentiation  of  unsigned  numbers,  the  following  IR  node  is  added  to  check  for  overflows  of  the computation:  CS-VYPER_JULY_2022-001  [\"lt\", x, upper_bound]  When a uint256 is raised to the power of 0 or 1, upper_bound is equal to MAX_UINT256+1, which is an output of calculate_largest_base. When trying to create a node for such value, the __init__ function of IRnode, will throw an exception as -(2 ** 255) <= self.value < 2 ** 256 is false.  @external def foo() -> uint256:     x: uint256 = 0     return x ** 1  Error compiling: Foo.vy vyper.exceptions.CompilerPanic: out of range  This is an unhandled internal compiler error. Please create an issue on Github to notify the developers. https://github.com/vyperlang/vyper/issues/new?template=bug.md  Vyper - Vyper Compiler -   9  CorrectnessCriticalHighMediumLowCorrectnessLowVersion1       \f5.2   Different Semantics for Raising to the Power of Negative Numbers  When  computing  the  power  of  0  or  1  by  a  negative  number,  if  the  compiler  knows  the  exponent  at compile time, it will output an exception. On the other side, if the compiler is only aware of the base, it will successfully compile and running the code will not revert. This behavior is due to the fact that the runtime checks  added  by  the  compiler  only  check  that  the  result  of  the  computation  is  in  bounds.  It  does  not check that the exponent is not negative to have the same semantic as the other case. The two examples below show the issue, compilation of foo will output the given exception while a call to bar will return 1.  CS-VYPER_JULY_2022-002  @external def foo() -> int16:     x: int16 = 1     return x ** (-2)  vyper.exceptions.InvalidOperation: Cannot calculate a negative power contract \"Foo.vy\", function \"foo\", line 4:17      3     x: int16 = 1 ---> 4     return x ** (-2) --------------------------^      5  @external def bar() -> int16:     x: int16 = -2     return 1 ** x  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   Exponentiation Lead to CompilerPanic",
        "body": " Exception  CS-VYPER_JULY_2022-003  In  arithmetic.safe_pow,  when  literal,  either  x  in  (0,1),  either calculate_largest_power  is  called.  In  calculate_largest_power  however,  CompilerPanic is  raised  when  the  absolute  value  of  the  base  is  either  0  or  1.  This  behavior  results  in  powers  of  -1 raising the exception as its absolute value is 1.  the  base  x   is  a   a = abs(a)  # No longer need to know if it's signed or not if a in (0, 1):         raise CompilerPanic(\"Exponential operation is useless!\")  The following code snippet produces this behavior:  Vyper - Vyper Compiler -   10  CorrectnessLowVersion1CorrectnessLowVersion1            \f@external def foo():         x: int256 = 4         y: int256 = (-1) ** x  In addition the compiler does not handle the exception that is produced by this snippet:  Error compiling: Foo.vy vyper.exceptions.CompilerPanic: Exponential operation is useless!  This is an unhandled internal compiler error. Please create an issue on Github to notify the developers. https://github.com/vyperlang/vyper/issues/new?template=bug.md  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.4   Folding Does Not Follow the Vyper Runtime",
        "body": " Semantics  AST  folding  is  performed  at  the  very  beginning  of  the  compilation  pipeline.  As  it  happens  before  the semantics validation, depending on the expression, it is possible that either the folding is too restrictive compared to the real semantics, or an expression that is not supposed to be valid is folded:  The following example shows the first case:  CS-VYPER_JULY_2022-004  @external def foo1() -> int8:     return 1 ** (-5)  @external def foo2() -> int8:     x: int8 = (-5)     return 1 ** x  Compiling foo1 outputs the following exception since folding does not allow exponents to be negative. On the other side, calling foo2 returns 1 as no folding is happening on the exponentiation.  Error compiling: Foo1.vy vyper.exceptions.InvalidOperation: Cannot calculate a negative power contract \"Foo1.vy\", function \"foo\", line 3:11      2 def foo1() -> int8: ---> 3     return 1 ** (-5) ------------------^      4  This example shows how some expression are folded even if they should not be valid:  @external def bar1() -> uint16:     return 1 - 2 + 2  Vyper - Vyper Compiler -   11  CorrectnessLowVersion1      \f@external def bar2() -> uint16:     x: uint16 = 2     return 1 - x + 2  In  this  example,  calling  bar1  returns  1  while  calling  bar2  reverts  since  no  folding  is  done  and  1-x results in an underflow.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.5   SafeMath Reverting on Valid Power",
        "body": "  When having the exponentiation of a signed number with the exponent y being a literal, safe_pow adds the following check to the intermediate representation:  CS-VYPER_JULY_2022-005  ok = [\"and\", [\"slt\", x, upper_bound], [\"sgt\", x, -upper_bound]]  Signed integers are represented using two's complement, one of the properties of this representation is that MIN_INT+1 == -MAX_INT.  For  values  of  y  for  which  there  exists  x'  such  that  x'**y==MAX_INT+1,  safe_pow  will  compute upper_bound=x',  which  is  result  of  calculate_largest_power.  If  the  event  that  the  base  of  the exponentiation  happens  to  be  x==-x',  although  there  is  no  overflow  as  x**y==MIN_INT,  the  check mentioned above will fail as [\"sgt\", x, -upper_bound] will return false since x==-upper_bound.  For instance, when the following code snippet is compiled and deployed, a call to foo will revert:  @external def foo() -> int16:         x: int16 = -8         y: int16 = x ** 5 return y  The produced IR check will be:  [seq, [assert, [and, [slt, x, 8], [sgt, x, -8]]], [exp, x, 5 <5>]]]]],  that   Note  upper_bound==MAX_INT+1 in this case:  the  same   issue  arises  when   trying   to  compute  MIN_INT**0  as  well  since  @external def foo() -> int16:         x: int16 = -32768         y: int16 = x ** 0 return y  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.6   SafeMath Reverting on Valid Power for ",
        "body": " int256  Vyper - Vyper Compiler -   12  CorrectnessLowVersion1CorrectnessLowVersion1            \fWhen  having  an  exponentiation  of  a  signed  number,  the  following  IR  node  is  added  to  check  for overflows and underflows of the computation:  CS-VYPER_JULY_2022-006  [\"and\", [\"slt\", x, upper_bound], [\"sgt\", x, -upper_bound]]  For int256, a similar issue as the one described in SafeMath Reverting on Valid Power can happen. For any exponentiation of a int256 by 0 or 1, upper_bound will be equal to MAX_INT256+1 and hence the left-hand side of the and will be the following node: N=[\"slt\", x, MAX_INT256+1]. This check will always evaluate to false as the EVM interprets MAX_INT256+1 as MIN_INT256. In the following code, a call to foo will always revert:  @external def foo() -> int256:     x: int256 = 2     return x ** 0  When  optimizations  are  enabled  an  _comparison_helper, the optimizer will check the following:  interesting  case  can  happen,  during   its  call   to  if is_strict and _int(args[1]) == never:     # e.g. gt x MAX_UINT256, slt x MIN_INT256     return (0, [])  As _int(MAX_INT256+1) evaluates to MIN_INT256, N will be replaced by the integer node 0.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.7   Wrong Overflow Exception",
        "body": "  CS-VYPER_JULY_2022-007  When  having  an  exponentiation,  to calculate_largest_base  will  raise  a  TypeCheckFailure  if  y  happens  to  be  greater  than  the number of bits the given type can store. While this is a correct behavior in most cases, for bases equal to 0 or 1, such computation would not overflow.  literal,  safe_pow's  call   the  exponent  y   is  a   if   In  practice,  an  OverflowException  is  raised  earlier  when  the  same  check  is  performed  against  the Vyper AST in validate_numeric_op.  @external def foo():         x: uint256 = 1         y: uint256 = x ** 257  Error compiling: Foo.vy vyper.exceptions.OverflowException: Power is too large, the calculation will always overflow contract \"test_opti/02.vy\", function \"foo\", line 4:22      3     x: uint256 = 1 ---> 4     y: uint256 = x ** 257 -----------------------------^      5  Vyper - Vyper Compiler -   13  CorrectnessLowVersion1      \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Calling permit on a Forbidden Token",
        "body": "  Tokens  can  be  set  to  forbidden  on  the  CreditFacade.  A  token  can  be  forbidden  for  various  reasons including security issues its logic. This means the allowed interaction with it should be as constrained as possible. To that end, many actions are not permitted while a credit account holds a forbidden token such as increasing the debt of an account. Note, however, calling addCollateralWithPermit with 0 amount is still  allowed  since  the  credit  account's  balance  will  not  be  increased.  During  this  call,  a  permit()  is executed on the token. In theory, this call can execute arbitrary logic which could be dangerous for both the  users  and  the  system.  Theoretically,  they  same  concern  holds  when  calling  transfer  and transferFrom on the problematic tokens.  CS-GEARV3CORE-001  Acknowledged:  Gearbox Protocol responded:  We do assume that tokens are not malicious because we allow users to decrease their exposure by withdrawing them or selling using adapters (both of which call transferFrom under the hood). And it's probably safe to assume that permit can't do more harm than transferFrom.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Missing Input Sanitization",
        "body": "  1. None  of  the  setMaxEnabledTokens()  functions  check  that  the  new  maxEnabledTokens  is  greater than zero. Setting zero as maxEnabledTokens would make the system unusable.  CS-GEARV3CORE-002  Gearbox Protocol - Gearbox V3 Core -   20  SecurityDesignCorrectnessCriticalHighMediumLowAcknowledgedCodePartiallyCorrectedSecurityLowVersion1AcknowledgedDesignLowVersion1CodePartiallyCorrected                   \f2. The to parameter in GearStaking._processPendingWithdrawals is unsanitized.  3. The constructor of AddressProviderV3 take the address _acl as parameter, but the address is not checked to be non-zero. There is no security issue as the contract would simply be unusable.  Code partially corrected:  1. The  function  CreditConfigurator.setMaxenabledTokens  has  been  updated  and  reverts  if  the new value for maxEnabledTokens is 0.  Gearbox Protocol - Gearbox V3 Core -   21  Version3  \f7   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings   Anyone Can Redistribute the Votes   -Severity Findings  -Severity Findings   Custom Health Factor Is Ignored    No Rate on New Quoted Tokens    Reserve Pricefeed Can Be Main Price Feed    Too Many Bots Can Block Liquidation   -Severity Findings   Debt Accrual on Quota Dust    Partial Liquidations When maxEnabledTokens Are Reduced    Arbitrary Bot Permissions    Debt Calculation Ignores Tokens With Fees on Transfer    Division By Zero    Global Quoted Tokens Mask Instead of Credit Account's Mask   Inconsistent Casting    Mint With Referral    Quota Increase Is Allowed for Forbidden Tokens    Updating Voter Contract May Lock GEAR   Informational Findings  Inconsistent Remaining Balance Check    Unused Code    Wrong Comments   Interest Accrued by Quota Dust    Code Duplication    Redundant and Missing Events Emission   Inconsistent Overflow Handling   1  0  4  10  7  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Anyone Can Redistribute the Votes",
        "body": "  Gearbox Protocol - Gearbox V3 Core -   22  CS-GEARV3CORE-021  CriticalCodeCorrectedHighMediumCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedDesignCriticalVersion2CodeCorrected            \fThe function GearStakingV3.deposit allows anyone to deposit GEAR tokens and execute a multivote for an arbitrary address to. The unrestricted call to _multivote in the name of to allows the caller to redistribute the votes of any to target address in the limits of totalStaked.    The to parameter of the deposit function has been removed. The deposit function can only make a deposit for msg.sender.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Custom Health Factor Is Ignored",
        "body": "  Note: This issue was discovered by Gearbox Protocol.  Users  have  the  option  to  perform  the  collateral  check  with  a  health  factor  (HF)  greater  than  1.  Let's assume  that  a  user  sets  HF  to  1.2.  A  multicall  should  fail  if  the  health  factor  ends  up  being  1.1. Nevertheless, this doesn't happen as the check compares the debt to the weighted collateral ignoring the min health factor. As a result, the account is still healthy from the system's perspective.  CS-GEARV3CORE-013  Code corrected*  The check has been updated as follows:  if (cdd.twvUSD < cdd.totalDebtUSD * minHealthFactor / PERCENTAGE_FACTOR) {     revert NotEnoughCollateralException(); // U:[CM-18B] }  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   No Rate on New Quoted Tokens",
        "body": "  When a new quoted token is added in the PoolQuotaKeeperV3, its rate is set to 0 by default and will keep its value until the minRate is set in the GaugeV3 and a new epoch has elapsed. This would allow an attacker to request a huge quota (up to the configured limit) without paying any interest to the protocol during the period where rate = 0.  CS-GEARV3CORE-015    The  function  PoolQuotaKeeperV3._updateQuota  has  been  updated  so  that  if  rate  ==  0  the quotaChange is zero as well, preventing users to increase their quota for a yet inactive quoted tokens.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   Reserve Pricefeed Can Be Main Price Feed",
        "body": "  CS-GEARV3CORE-024  Gearbox Protocol - Gearbox V3 Core -   23  CorrectnessMediumVersion1CodeCorrectedDesignMediumVersion1CodeCorrectedDesignMediumVersion1CodeCorrected                        \fIn  the  function  PriceOracleV3.setReservePriceFeed(),  nothing  prevents  the  reserve  price  feed to  be  the  same, LPPriceFeed.updateBounds() could be used during a read-only reentrancy to trick the system into believing the exchange rate of the LP token is way too high.  the  base  price   the  same  as   feeds  were   to  be   feed.   two   the   If     No changes related to the issue have been done in PriceOracleV3 as it may complicate operations, but a check that the two feeds must be different has been added in LPPriceFeed.updateBounds().  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   Too Many Bots Can Block Liquidation",
        "body": "  It  is  possible  to  block  a  liquidation  by  adding  enough  bots  so  that  erasing  all  the  bot's  permission  on liquidation would be bigger than the block gas limit, thus blocking the liquidation process.  If such a scenario happens, a new BotList can always be redeployed and re-linked to the system, but all the bot users will have to withdraw their funds from the old BotList and set all the permissions again.  CS-GEARV3CORE-027    A  global  limit  of  5  bots  per  credit  account  has  been  added.  More  specifically CreditFacade.setBotPermissions reverts if the number of remaining bots exceeds the global limit.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.6   Debt Accrual on Quota Dust",
        "body": "  The  function  QuotasLogic.calcAccruedQuotaInterest  returns  0  when  quoted  <=  1  and  thus does not account for the debt accrued on the quota dust. Previously, the interest accrued by 1wei left in the  quota  was  accounted  for  in  the  pool  quota  revenue  and  materialized  whenever  the  quota  was increased again in the CA. In the updated codebase, it is still accounted for in the pool quota revenue, but will  never  materialize  in  the  CA  debt.  This  will  create  a  small  discrepancy  that  will  increase  over  time between the expected pool quota revenue and the true pool quota revenue which will be lower, slightly over-evaluating the value of the LP shares.  CS-GEARV3CORE-019    The 1wei gas optimization when a quota is set back to 0 has been removed from the codebase, fixing this issue.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.7   Partial Liquidations When maxEnabledTokens",
        "body": " Are Reduced  CS-GEARV3CORE-026  Gearbox Protocol - Gearbox V3 Core -   24  DesignMediumVersion1CodeCorrectedDesignLowVersion6CodeCorrectedDesignLowVersion3CodeCorrected                        \fA (bot) multi-call cannot execute successfully if the enabled tokens at the end of the execution exceed the maxEnabledTokens. Consider the case where the CreditConfigurator sets the maxEnabledTokens to a value lower than the current one. This means users who have more tokens enabled should disable some of them in order to execute a (bot) multi-call. Since partial liquidations are executed by the special permissioned bot, these will be blocked as well. The specification of the partial liqudations delivered to us does not handle such a case.    The  codebase  (CreditManager._saveEnabledTokensMask())  has  been  updated  so  that  the underlying  token  is  excluded  from  the  maximum  enabled  tokens  count,  making  partial  liquidation  by  a swap to the underlying token always possible.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.8   Arbitrary Bot Permissions",
        "body": "  When  setting  permissions  to  a  bot,  the  permissions  are  not  sanitized,  and  it  is  thus  possible  to  set arbitrary permissions that could be meaningless in the Gearbox system.  CS-GEARV3CORE-018    A  check  has  been  added  to  CreditFacadeV3.setBotPermissions  to  enforce  that  only  valid permissions can be set.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.9   Debt Calculation Ignores Tokens With Fees on",
        "body": " Transfer  Note: This issue was discovered by Gearbox Protocol.  CS-GEARV3CORE-023  CreditManager.fullCollateralCheck()  calculates  the  system denominated  in  the  pool's  underlying.  If  the  underlying  has  fees  on  transfer,  a  small  amount  will  be deducted when the debt is repaid. Even though the system is aware of this potential fee, it doesn't take it into account when it calculates the full debt during the full collateral check. This means that the health factor  could  be  slightly  overestimated  allowing  an  account  to  become  liquidatable  slightly  later  than  it should.  total  debt  owed   the   to   Code corrected  The fees are now accounted for in the debt calculation as follows:  uint256 totalDebt = _amountWithFee(cdd.calcTotalDebt());  Gearbox Protocol - Gearbox V3 Core -   25  DesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                  \f7.10   Division By Zero  LinearInterestRateModelV3.availableToBorrow() calculates the U_WAD value by dividing with expectedLiquidity.  However,  the the  corner  case  exists  expectedLiquidity is 0.  for  an  empty  pool,  where   CS-GEARV3CORE-016    A check was added to take care of the case where expectedLiquidity is 0.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.11   Global Quoted Tokens Mask Instead of",
        "body": " Credit Account's Mask  The specification of CreditManagerV3._getQuotedTokensData() specifies that the returned value _quotedTokensMask should be the mask of the enabled quoted tokens of the Credit Account, but the actual returned value is the mask of all the quoted tokens in the Credit Manager.  CS-GEARV3CORE-014  Specification updated:  The nat spec has been updated to reflect the functionality of the code.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.12   Inconsistent Casting",
        "body": "  CS-GEARV3CORE-028  In  the  function  CreditConfiguratorV3._revertIfContractIncompatible(),  _contract  is the  call  creditManager(),  but  _contract  can  be casted  CreditFacadeV3, AdapterBase, or CreditConfiguratorV3 as they all implement this call.  into  CreditFacadeV3   for   Spec changed:  A comment has been added in CreditConfiguratorV3._revertIfContractIncompatible() to justify the casting clarifying that all contracts implementing this interface can be used.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.13   Mint With Referral",
        "body": "  In  the  PoolV3,  the  function  depositWithReferral  is  available  for  users,  but  there  is  no  such equivalent for mint.  CS-GEARV3CORE-020  Gearbox Protocol - Gearbox V3 Core -   26  DesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrectedDesignLowVersion1Speci\ufb01cationChangedDesignLowVersion1CodeCorrected                              \f  The function mintWithReferral has been added in the PoolV3.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.14   Quota Increase Is Allowed for Forbidden",
        "body": " Tokens  When a CA holds a forbidden enabled token, it is not allowed to increase its debt or the balance of such a token. However, the system allows the increase of the quota of an enabled forbidden token. While it does not increase the exposure of the system to the problematic token, it would make sense to disallow such quota updates for consistency.  CS-GEARV3CORE-029    CreditFacade._updateQuota reverts when a forbidden token is specified in callData.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.15   Updating Voter Contract May Lock GEAR",
        "body": "  Changing  the  voter  contract  of  a  Gauge  while  stakers  still  have  registered  votes  may  break  the  votes accounting and prevent stakers from withdrawing their funds from the voter contract.  CS-GEARV3CORE-022    The voter contract of a Gauge has been updated to be immutable.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.16   Code Duplication",
        "body": "  1. The computation of the value pctDiff in PolicyManagerV3._checkPolicy() is duplicated  2. The   computation   timestampRampStart   +   rampDuration   in  CreditLogic.getLiquidationThreshold() is duplicated  CS-GEARV3CORE-012    Code duplication has been removed.  Gearbox Protocol - Gearbox V3 Core -   27  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedInformationalVersion1CodeCorrected                        \f7.17   Inconsistent Overflow Handling  USDTFees.amountUSDTWithFee  handles  the  case  where  maximumFee  +  amount  overflows. However, there is no such a case when the amountWithBP is calculated. This is just an inconsistency issue as it is unlikely the amount value to be that big.  CS-GEARV3CORE-025    An operation which is less probable to overflow is currently used.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.18   Inconsistent Remaining Balance Check",
        "body": "  Different checks are implemented for checking if an amount is 0 or 1, amount < 2 or amount <= 1. It is recommended to always use the same way of checking for consistency and code maintainability.  CS-GEARV3CORE-008    All the checks mentioned above have been updated to be <= 1 in the codebase.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.19   Interest Accrued by Quota Dust",
        "body": "  For gas optimization reasons, the Credit Accounts quotas are reset to 1, and this 1 wei contributes to TokenQuotaParams.totalQuoted. This dusty wei has multiple effects:  CS-GEARV3CORE-011  this  1  wei  may  contribute  to  the  pool's  revenue  on  updateRates  because  it's  based  on TokenQuotaParams.totalQuoted, which sums up that dust.  if a CA was closed and leaves 1 wei of quoted tokenA in AccountQuota.quota, the next borrower that increases the quota for that tokenA on the same CA may have some interests due because the timeDelta * currentQuotedTokenRate combination may be enough so that calcAccruedQuotaInterest may return a non zero value, recall that the minimal period before one can reuse a CA is 3 days (259200 seconds).  if this quota is not reactivated for a long time, over multiple CA open and close cycles, the time delta between now and the last time the accountQuota.cumulativeIndexLU was updated can be significant.  Note, the above is a theoretical issue and mostly an inconsistency of the system and it is not expected to harm the users. It can happen that the pool revenue accounts for the 1 wei due to the reason above, but the computation in calcAccruedQuotaInterest yields 0.    Gearbox Protocol - Gearbox V3 Core -   28  InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected                   \fFrom Version 6 on, there is no 1 wei optimization so the issue is resolved.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.20   Redundant and Missing Events Emission",
        "body": "  There  are  multiple  instances  of  setter  functions  where  events  are  emitted  regardless  of  whether  they actually change the values. More specifically:  CS-GEARV3CORE-017  1. GaugeV3.setVoter  2. GaugeV3.changeQuotaTokenRateParams  3. GearStakingV3.setVotingContractStatus  Furthermore, an event is not emitted in PolicyManagerV3.setPolicy.    1. The function setVoter and event SetVoter have been removed.  2. The function GaugeV3._changeQuotaTokenRateParams has been updated to early return and  not emit any event if the updated values are the same as the old values.  3. The  function  GearStakingV3.setVotingContractStatus  has  been  updated  to  early  return  and not emit any event if the updated value is the same as the old value.  Events  PolicyManagerV3.disablePolicy(), and PolicyManagerV3.setGroup().  added   been   have   in   PolicyManagerV3.setPolicy(),  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.21   Unused Code",
        "body": "  1. The immutable GaugeV3.addressProvider is set but never used.  2. The functions externalCall and approveToken in the CreditManagerV3 are never called.  CS-GEARV3CORE-009    1. addressProvider has been removed.  Acknowledged:  2. Gearbox  Protocol  responded  that  these  functions  are  not  meant  to  be  used  within  the  current  codebase, but are prep work for the future.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.22   Wrong Comments",
        "body": "  CS-GEARV3CORE-010  Gearbox Protocol - Gearbox V3 Core -   29  InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected                  \f1. USDT_Transfer._amountUSDTMinusFee():  the  value  returned  by  the  function  is  what  the  recipient would receive if amount was sent, not how much to send to reach amount  2. USDTFees.amountUSDTMinusFee():  the  value  returned  by  the  function  is  what  the  recipient  would receive if amount was sent, not how much to send to reach amount  3. CreditFacadeV3._revertIfOutOfTotalDebtLimit(): =   totalDebtLimit  totalDebtLimit = totalDebt.totalDebtLimit  totalDebt.currentTotalDebt   should   be  4. CreditManagerV3.calcDebtAndCollateral():  Therefore,  it  is  prevented  from  being  called  internally  should  be Therefore, it is prevented from being called externally    Comments for 1. and 2. were fixed.  Gearbox Protocol - Gearbox V3 Core -   30  \f8   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Gas Optimizations",
        "body": "  1. The computations in GearStakingV3.getCurrentEpoch() can be unchecked.  2. The  computations  of  the  new  withdrawalsPerEpoch  in  GearStakingV3.withdraw  can  be  unchecked.  CS-GEARV3CORE-007  3. Disabling   in CollateralLogic.calcNonQuotedTokensCollateral() is redundant. There is no need to disable already disabled tokens.  outside   token   block   the   the   of   if   4. In  the  function  CreditLogic.calcDecrease,  the  condition  amountToRepay  >  quotaFees could  be  transformed  into  a  non-strict  inequality  to  save  a  bit  of  gas  since  SafeCast  will  not  be needed.  5. Assigning   branch amountToRepay  of CreditLogic.calcDecrease() has no effect since they will be reassigned later in the function.  newCumulativeIndex  +   in  the  quotaProfit   cumulativeQuotaInterest   newDebt   and   <   to   6. The  mapping  AccountFactoryV3._queuedAccounts  could  use  a  static  array  instead  of  a dynamic array. Its length is never read and there would not be the need for updating the length of a static array.  7. In CollateralLogic.calcCollateral(), one could use the first pass over the enabled token mask combined with the collateral hints on the quoted tokens, and use that information to optimize the  so CollateralLogic.calcNonQuotedTokensCollateral()  does  not  have  to  iterate  through the whole mask until it finds the last token.  unquoted   tokens   pass   the   on   8. The  function  PoolQuotaKeeperV3._updateQuota  does  not  implements  the  gas  optimization  trick of leaving 1 wei when the quota is manually reduced to 0.  9. The   function   has  signature.length==0, but signature is always assigned and never empty.  ControllerTimelockV3.executeTransaction   a   branch   if  Code partially corrected:  1. The computations have been moved in an unchecked block.  2. The  total  supply  of  GEAR  (10_000_000_000e18)  would  fit  in  type(uint96).max,  thus  an  overflow check is not needed.  3. The  line  tokensToCheckMask  =  tokensToCheckMask.disable(tokenMask);  could  be moved  into  the  preceding  if  block  to  save  gas.  If  done  outside  of  the  block,  this  line  will  be executed even for the tokenMask that are already disabled in the tokensToCheckMask.  4. The use of SafeCast has been removed from the else branch.  5. The redundant assignments have been removed.  6. The mapping has been updated to use a static array of size 2**32.  Gearbox Protocol - Gearbox V3 Core -   31  InformationalVersion1CodePartiallyCorrected    \f7. This issue does not arise with a well formatted collateralHints, Gearbox Protocol expects well  formatted collateralHints.  8. Gearbox Protocol specified that the optimization will be done at the UI level.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Missing Natspec",
        "body": "  Some of the natspec are missing or incomplete, here is a non-exhaustive list:  1. CreditFacadeV3.setDebtLimits():   natspec   for   parameter  _maxDebtPerBlockMultiplier is missing  2. CreditManagerV3.closeCreditAccount():  natspect  for  parameter  collateralDebtData  CS-GEARV3CORE-003  is missing  3. QuotasLogic.cumulativeIndexSince(),  QuotasLogic.calcAdditiveCumulativeIndex()  QuotasLogic.calcAccruedQuotaInterest(): natspec for the return value are missing  and  4. USDTFees: the library is missing natspec  5. BitMask: the library is missing natspec for return values and the calcIndex function  6. CollateralLogic.calcQuotedTokensCollateral():   natspec   for   parameters  quotedTokens and quotasPacked are missing  Gearbox Protocol said:  We're preparing a system-wide cleanup of NatSpec and comments.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.3   Out-of-sync Configurators During Migration",
        "body": "  CS-GEARV3CORE-004  When  deploying  a  new  configurator  to  replace  an  old  one  for  a  credit  manager,  the  state  of  the  old to-be-replaced  configurator  is  copied  i.e.,  the  allowed  adapters  and  the  emergency  liquidators.  For  the migration  the  old  configurator  should  be  executed to  (CreditConfigurator.upgradeCreditConfigurator()).  In  the  meantime,  the  state  of  the  old credit configurator could have been changed. Hence, old and new credit configurators are out of sync. The governance of the protocol should be aware of this behavior.  to  complete  another   transaction   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.4   Pricefeed Existence Consistency",
        "body": "  In  PriceOracleV3,  the  checks  for  the  existence  of  a  price  feed  differ.  Sometimes  the  check  is priceFeed != address(0), and sometimes decimals != 0.   getPriceRaw(), setReservePriceFeedStatus() are checking for pricefeed address  CS-GEARV3CORE-005  Gearbox Protocol - Gearbox V3 Core -   32  InformationalVersion1InformationalVersion1InformationalVersion1            \f priceFeedParams(), setReservePriceFeed() are checking for decimals  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.5   Timelock Delay Can Be Zero",
        "body": "  When  a  policy  is  set  in  PolicyManagerV3,  nothing  prevents  the  delay  to  be  0.  If  the  delay  is  0,  the policy admin can set the parameter and execute it in the same transaction, which would leave no change to  the  veto  admin  to  cancel  the  change  if  needed.  The  configurator  must  be  careful  when  setting  the delay for a critical policy.  CS-GEARV3CORE-006  Gearbox Protocol - Gearbox V3 Core -   33  InformationalVersion1    \f9   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "9.1   Circular Swap With Full Balance Will Disable",
        "body": " the Token  If  a  user  makes  a  swap  such  X->Y->X  with  the  total  balance  of  token  X  within  the  same  call  in  the multicall, token X will be marked as disabled and unless explicitly marked as enabled with a later call in the multicall.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "9.2   Fees Parameters",
        "body": "  It  is  important  that  the  fees  are  set  correctly  for  the  system  to  behave  as  expected.  If  fees  are misconfigured, it could happen that certain unexpected behaviors may take place, for example, holders of unhealthy Credit Accounts could be incentivized to close their positions instead of liquidating themselves.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "9.3   Quota Activation Can Make Credit Accounts",
        "body": " Unhealthy  The  activation  of  quota  for  a  previously  whitelisted  token  in  the  Credit  Manager  can  make  Credit Accounts using that token as active collateral liquidatable, since their quotas will be 0.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "9.4   Quotas Are Independant Of Collateral",
        "body": "  A  credit  account  can  increase  its  quotas  by  consuming  all  the  available  amount,  independently  of  its collateral.  This  could  make  the  credit  account  very  quickly  liquidatable  as  the  quota  interest  will  be significant.  Moreover,  a  user  can  occupy  the  whole  quota  capacity  and  thus  prevent  other  users  from using the quota.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "9.5   Quotas for Derivative Tokens",
        "body": "  Each pool imposes a total amount of quota per token that can be used by all credit accounts related to that pool. This is done to limit the exposure of the system to specific risky assets. It's important to note that a token can derive its value from another underlying token. When setting the quota limit for either  Gearbox Protocol - Gearbox V3 Core -   34  NoteVersion1NoteVersion1NoteVersion1NoteVersion1NoteVersion1                  \ftoken this dependence should be taken into account, as the exposure of the system to a risky token can end up being greater than expected.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "9.6   Supported Tokens",
        "body": "   The system only supports standard ERC20 tokens without special behaviors, especially tokens with callbacks  (ERC777)  which  would  allow  arbitrary  code  execution.  More  explicitly,  tokens  with  two entry  points  should  also  be  avoided.  It  is  important  to  stress,  especially  in  the  absence  of  a withdrawal manager, that a reentrant token could allow read-only reentrancy attacks since the state of the credit account is not properly finalized and the full collateral check hasn't been performed.   The LP token of the Pool should not be allowed as collateral in the system.   Added  tokens  should  be  reviewed  regarding  gas  consumption.  For  example,  the  function UnsafeERC20._unsafeCall allows the callee to return a memory pointer that, if far in memory, would incur a huge gas cost for memory allocation.  Gearbox Protocol - Gearbox V3 Core -   35  NoteVersion1    \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Burn Function Redundant Checks",
        "body": "  In Dai contract, some gas savings are possible.  The  safeMath  operator  _sub  can  be  removed  in  totalSupply  =  _sub(totalSupply,  value);, because of the check:  uint256 balance = balanceOf[from]; require(balance >= value, \"Dai/insufficient-balance\");    The  redundant  check  was  removed.  Similar  check  in  mint  function  was  found  and  removed  by MakerDAO team themselves.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Contract L2GovernanceRelay Unnecessary",
        "body": " Statefulness  The  L2GovernanceRelay  contract  defines  the  l1GovernanceRelay  field  and  inherits  from  the messenger field from OVM_CrossDomainEnabled.  Those 2 fields could be declared as immutable as they are never changed after the initial assignment. The  L1GovernanceRelay  address  can  be  precomputed  and  passed  to  L2GovernanceRelay  as  a constructor variable.    MakerDAO - Optimism DAI Bridge -   9  CriticalHighMediumLowCodeCorrectedCodeCorrectedCodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                 \fThe l1GovernanceRelay is an immutable field now. The messenger is still a storage field, because changing  it  will  require  a  change  in  the  Optimism  contracts  library,  that  are  out  of  scope  for  this assessment.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Init Function of L2GovernanceRelay",
        "body": "  The  function  init  for  L2GovernanceRelay  contract  is  needed  to  set  the  l1GovernanceRelay  field. This  function  is  not  protected  by  any  access  modifier  and  can  be  called  by  anyone.  The  attacker  can potentially call this function himself and ruin the deployment. Such attack will require the redeployment of L2GovernanceRelay contract and potentially of the L1GovernanceRelay. In addition the attacker can find a potential transaction that will revert the optimism history to such extend, where the L2GovernanceRelay deployment has happened, but init hasn't. This way attacker can init contract again himself, effectively getting a full control over the L2GovernanceRelay.    The L2GovernanceRelay now has only a constructor, where the immutable l1GovernanceRelay is set.  MakerDAO - Optimism DAI Bridge -   10  DesignLowVersion1CodeCorrected        \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Constructors Marked Public",
        "body": "  L2DAITokenBridge.sol and dai.sol contracts have constructor with public modifier. This visability modifier will be ingnored by the solidity compiler.  MakerDAO - Optimism DAI Bridge -   11  NoteVersion1  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Compromised Guardian Can Block the",
        "body": " Executor  The guardian role has the privilege to cancel queued actions sets before they are executed. Updating the guardian  address  can  only  be  done  through  an  action.  If  the  guardian  account  is  compromised,  it  can always cancel an actions set which tries to update the guardian role to a new address. Effectively, once the guardian address is compromised it can block the Executor indefinitely.  Risk accepted:  Aave replied:  The guardian address is designed to be a multisig or governance executor (never an EOA) so having a compromised guardian is unlikely to happen.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Dangerous Delegatecalls",
        "body": "  Actions  sets  may  include  actions  (calls)  to  be  executed  as  DELEGATECALL  in  the  context  of  the BridgeExecutor. While this allows to aggregate multiple calls governed by code which can adapt to on chain  state,  should  the  called  contract  write  to  storage,  this  would  write  to  the  storage  of  the BridgeExecutor.  Hence  variables  of  the  contract  may  be  overwritten.  This  can  result  in  the  internal  Aave - Bridge Executors -   11  SecurityDesignCriticalHighMediumLowRiskAcceptedRiskAcceptedRiskAcceptedRiskAcceptedSecurityLowVersion1RiskAcceptedDesignLowVersion1RiskAccepted                  \fvariables  being  changed  without  respecting  the  restrictions  enforced  in  their  setter  function,  e.g. updateGracePeriod() and the check for the minimum grace period.  Besides,  a  Delegatecall  is  also  able  to  modify/delete  existing  actions  sets,  insert  arbitrary  new  actions sets or manipulate entries in _queuedActions. The governance must be aware of this danger.  Untrusted code must never be called with DELEGATECALL.  Furthermore,  note  that  the  following  corner  case  exists:  An  action  consisting  of  a  call  to  the BridgeExecutor's executeDelegateCall function technically allows the governance to execute a call as a Delegatecall (with the risks mentioned above) despite the flag withDelegatecalls being set to false.  Risk accepted:  Aave replied:  The Executor contract assumes that any set of transactions that are queued by a successful proposal is legit. Thus, there are no bad actions that the contract can execute since the proposal passes multiple checks by the community, devs, white hats, auditors, etc.  The executeDelegateCall function is designed to be used for executing payload contracts, where a set of actions are described (instead of having multiple encoded calldatas). The governance should check that the delegate call execution does not update or alter any executor contract's state variable.  Apart from that, the correct way of doing a delegate call is through the action set and the execute function, instead of calling directly to executeDelegateCall. The community would detect and raise this concern if applicable.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Function Signature as String, Unicode",
        "body": " Charset  An action may contain the function signature as a string. This allows to display the function to be called in a  human  readable  way.  However,  this  can  be  dangerous  as  strings  support  the  unicode  charset  and many  lookalike  characters  of  different  alphabets  exist  in  this  charset.  Hence  users  might  be  tricked  to approve an action which seemingly contains the intended function call, but actually results in a different function  selector.  Given  a  function  selector  consists  of  4  bytes  only,  it  might  be  feasible  to  find  such  a collision.  For  characters,  into  https://util.unicode.org/UnicodeJsps/confusables.jsp?a=setReserveActive  lookalike   insights   more   please   refer   to:  Risk accepted:  Aave replied:  Governance should assess, test and simulate each proposal, checking the outcome of its changes without trusting string function signatures. Having the function signature human-readable is not a way of validating the legitimacy of proposals by any means.  Aave - Bridge Executors -   12  SecurityLowVersion1RiskAccepted          \f6.4   Potential Reentrancy on execute  The function execute is not protected against reentrancy. While the governance is trusted to not create actions sets which reenter into execute() and start executing another actions set, generally speaking an  action  may  reach  untrusted  third-party  code.  This  untrusted  code  may  reenter  the  BridgeExecutor. This would break the atomicity of sets of actions and may result in unexpected executions and states.  Risk accepted:  Aave replied:  The community and governance decide if an action set should execute any other action set of the same executor. The community should asses every governance proposal carefully.  Aave - Bridge Executors -   13  SecurityLowVersion1RiskAccepted      \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Execution Order of Queued Actions Sets",
        "body": "  Multiple  queued  actions  sets  which  are  ready  for  execution  may  be  executed  in  an  arbitrary  order.  All actions which depend on a particular execution order must be placed within the same actions set where the  order  of  execution  is  defined.  If  multiple  actions  sets  exist  at  the  same  time,  they  must  be independent of each other.  Moreover,  updating  critical  system  variables  in  one  actions  set  might  change  the  behavior  of  other actions sets. For example, assume _delay is set to one day at the beginning. Actions set A is queued in the BridgeExecutor, A updates _delay to one second. On L1, the governance decides on actions set B. Governance should be careful, depending on whether A is executed before/after actions set B is queued on L2, a different _delay is applied before B can be executed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Impact of Rollback, Finality of Actions",
        "body": "  Especially  regarding  finality,  L2  solutions  based  on  optimistic  rollups  behave  differently  than  L1 Ethereum.  Should a rollback happen due to the discovery of an incorrect tx, this tx and all subsequent tx have to be reexecuted. This impacts the timestamp of the transaction. Most of the times incorrect transaction results are detected immediately and the rollback happens immediately, however in a worst-case scenario the rollback might happen just before the end of the fault proof period. In such cases the timestamp of the transaction changes significantly.  The  BridgeExecutor  heavily  relies  on  the  timestamps,  e.g.  to  determine  whether  an  action  can  be executed or if it already expired. Similarly the execution time is calculated based on the timestamp when queue() is executed. After a rollback the timestamps may have shifted and e.g. a previously executed actions set can no longer be executed as it has expired.  Furthermore,  the  order  of  transactions  after  a  rollback  is  not  guaranteed,  there  may  be  a  change  of sequence between a transaction to execute() or cancel() a pending actions set.  Validating  all  transactions  may  help  to  detect  incorrect  transactions  early,  however  in  a  worst-case scenario  (e.g.  a  bug  in  the  validator  software)  may  not  detect  such  a  wrong  transaction  and  an unexpected fraud proof may be submitted resulting in a rollback.  The  governance  needs  to  be  careful  about  finality  on  L2.  Overall  L2  solutions  are  still  considered  as experimental, interactions must be done with care.  Note that at the time of this review Optimism has not yet implemented fraud proofs while in Arbitrum only whitelisted addresses can create a challenge.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Potentially Resurrected ActionsSet",
        "body": "  Aave - Bridge Executors -   14  NoteVersion1NoteVersion1NoteVersion1          \fAn  actions  set  expires  if  the  _gracePeriod  has  elapsed  since  the  executionTime.  However,  an expired  actions  set  may  resurrect  if  the  _gracePeriod  is  extended  by  the  governance  later  in  the future. Resulting an expired actions set might be executable again.  It  should  be  carefully  thought  about  if  this  suspended  state  should  be  allowed,  especially  as  the guardian can only cancel queued actions set which have not yet expired.  Aave - Bridge Executors -   15  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Recent Stakers Get Unfair Yield",
        "body": "  0  0  1  1  CS-SQDC-001  In  the  DistributedRewardDistribution  contract,  the  rewards  being  committed  to  and  approved include the time range [fromBlock, toBlock] they were computed for. However, when the proposal is  executed  calls Staking.distribute(),  which  gives  out  yield  to  the  current  stakers  of  the  specified  worker, regardless of whether they were already staking during the relevant timeframe.  last  approve()  arrives),   the  distribute()   function   (when   the   This means that a staker joining after the period for which the rewards are computed, but before the last approve()  arrives  for  that  proposal,  gets  an  unfair  share  of  those  rewards.  Symmetrically,  a  staker leaving in the same window will lose their fair share of the rewards.  Code partially corrected:  Users are forced to stake for more epochs determined by epochsLockedAfterStake. This value is set by the admin.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Gateway Operator Can Add 0 SQD to His",
        "body": " Stake  The function GatewayRegistry.addStake() does not revert if called with amount = 0; instead, it extends  the  lock  period  by  one  \"segment\",  starting  from  the  next  epoch.  This  behaviour  is  harmless per-se (it is roughly equivalent to enabling auto-extension), but it is undocumented.  CS-SQDC-002  Subsquid - Subsquid -   13  DesignCorrectnessCriticalHighMediumCodePartiallyCorrectedLowAcknowledgedDesignMediumVersion1CodePartiallyCorrectedDesignLowVersion1Acknowledged                  \fAcknowledged:  It is not an intended behaviour, but since there\u2019s no harm in that, we will keep that and add a comment.  Subsquid - Subsquid -   14    \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings   Reward Distribution Can Run Out of Gas   -Severity Findings   Distribution With Multiple Commitments    Supporting the Same Worker in Subequal Strategies    Claiming Can Run Out of Gas    Delegation Limit Redundant With Soft Cap    Distributor Index    Gateway Operator Can Stake 0 SQD    Gateway Staking for Less Than an Epoch, With Autoextension    Missing Check When Removing Distributor    Retiring a Small Worker Can DOS the Reward Distribution    Stake Duration Is Not Sanity-Checked    Transferring the Ownership of Vesting   Informational Findings   Redundant Grant of Admin Role    Redundant Role-Granting Function    Event Rewarded Can Be Emitted With 0 Reward    Two Different Implementations of effectiveTVL()   0  0  1  11  4  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Reward Distribution Can Run Out of Gas",
        "body": "  The  reward  distribution  system  implicitly  requires  reward  proposals  to  cover  all  active  workers  for  their time  window:  this  is  because  proposals  have  to  cover  consecutive  timeframes  (enforced  through lastBlockRewarded),  therefore  one  cannot,  at  a  later  time,  \"go  back\"  and  integrate  an  old  proposal with worker rewards it did not include. If the system grows too big, the reward distribution would break because the one transaction to reward all workers would hit the block gas limit.  CS-SQDC-016    Subsquid - Subsquid -   15  CriticalHighMediumCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedDesignMediumVersion1CodeCorrected        \fThe number of delegates is capped by maxDelegations which is settable by the admin.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Distribution With Multiple Commitments",
        "body": "  CS-SQDC-017  2,   the   version   call In  DistributedRewardDistribution.commit()  for  the  same  block  range.  Other  distributors  can approve  this  commitment  for  this  range  only  once.  However,  if  a  second  commitment  takes  place  the approvals  are  reset.  Moreover,  the  distributors  already  have  approved  this  commitment  they  are  not allowed to reapprove it.  distributors   multiple   system   allows   to     A second commitment doesn't reset the number of approvals.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Supporting the Same Worker in Subequal",
        "body": " Strategies  Using the subequal strategy, gateway operators can choose to delegate their queries to a specific subset of workers by calling SubequalStrategy.supportWorkers(). Each time a worker is supported, the count  of  workers  increases.  However,  there's  no  check  that  a  worker  has  already  been  supported. Therefore, the worker count might be greater than the actually supported workers. The same issue exists for SubequalStrategy.unsupportWorkers(). Note that this issue could also lead to division by 0 when SubequalStrategy.computationUnitsPerEpoch() is called.  CS-SQDC-005    A check for worker duplication was implemented.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Claiming Can Run Out of Gas",
        "body": "  The function Staking.claim() iterates through all the workers this staker has staked into. There is no bound on the number of workers one can stake into: if it grows too large, the claiming transaction might hit the block gas limit, making it altogether impossible to claim yield without temporarily unstaking from some workers.  CS-SQDC-009    Subsquid - Subsquid -   16  DesignLowVersion2CodeCorrectedCorrectnessLowVersion2CodeCorrectedDesignLowVersion1CodeCorrected                           \fThe  contract  now  enforces  a  hard  limit  of  100  delegations  per  staker.  Note  that  the  number  of  max delegations can be changed by the admin.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Delegation Limit Redundant With Soft Cap",
        "body": "  The Staking.deposit() function enforces a hard cap on the total amount of SQD staked in favour of any  single  worker.  This  is  redundant  with  the  soft  cap  induced  by  the  law  of  diminishing  returns implemented in SoftCap.  CS-SQDC-015    The hard cap was removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Distributor Index",
        "body": "  CS-SQDC-014  The  DistributedRewardDistribution.distributorIndex() which implements the following logic:  distributor   decides   system   current   who   the   by   is   calling  uint256 slotStart = block.number / 256 * 256; return uint256(blockhash(slotStart)) % distributors.length();  When the block.number is a multiple of 256, the slotStart equals to block.number. blockhash for the current block returns 0 instead. This means the distributor will always be the one with index 0 for the multiples of 256.    The distributor index is not determined by blockhash. It changes in a round-robin fashion as follows:  return (block.number / roundRobinBlocks) % distributors.length();  However, the distributor index might not change the way it's expected. For example, consider the case where roundRobinBlocks is a multiple of distributors.length() then the index is always going to be 0.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Gateway Operator Can Stake 0 SQD",
        "body": "  The function GatewayRegistry.stake() does not check that amount > 0, so a gateway operator can call it with amount set to 0 and have all his gateways be marked as active.  CS-SQDC-008  Subsquid - Subsquid -   17  DesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \f  The function now includes a check that the staked amount is greater than minStake which is initially set to 1. minStake can be changed by the admin.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   Gateway Staking for Less Than an Epoch,",
        "body": " With Autoextension  CS-SQDC-011  Gateway operators can set an \"autoextension\" option for their staking position, which is meant to prolong it indefinitely, in whole consecutive \"segments\" of the original duration, until the option is disabled. Yet, the  function  GatewayRegistry.computationUnitsAvailable()  does  not  play  well  with  this mechanism, if the stake duration is less than an epoch.  Say that the duration is one tenth of an epoch (and autoextension is enabled): then an epoch is \"tiled\" by 10 segments, so the available CUs in the epoch should be 10 times those afforded by a single segment (which is, instead, what the function returns). On the other hand, if it were actually implemented this way, one could spend all those CUs in less than an epoch, then \"prematurely\" disable the autoextension, and finally unstake, thus spending more CUs than what should be granted by the effective lock period.    Gateway locking cannot be shorter than one epoch. However, should the epoch duration be increased, for  stakers  who  have  staked  under  the  previous  configuration,  the  staking  duration  could  be  less  an epoch.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   Missing Check When Removing Distributor",
        "body": "  In  the  DistributedRewardDistribution  contract,  the  function  removeDistributor()  does  not check that the resulting distributors.length() is greater than or equal to requiredApproves, as is instead done in the setApprovesRequired() function.  CS-SQDC-006    The check was added to the function removeDistributor() as well.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   Retiring a Small Worker Can DOS the Reward",
        "body": " Distribution  The  function  Staking._distribute()  reverts  if  the  worker  in  question  has  no  SQD  staked  in  his favour. Therefore, a malicious actor can register a worker doing only a tiny amount of work (just enough to earn some rewards), and also stake some SQD in his favour (he needs to be the only staker for that  CS-SQDC-018  Subsquid - Subsquid -   18  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \fworker).  Then,  when  the  reward  proposal  arrives  to  DistributedRewardDistribution,  he  can unstake  everything  to  execute  because DistributedRewardDistribution.distribute() will revert, temporarily blocking the rewards for all other workers as well, until a new proposal is submitted to make up for it.  from  his  worker.  The  proposal  will   then   fail     The  function  Staking._distribute()  now  does  nothing,  instead  of  reverting,  if  the  worker's  total stake is 0.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.11   Stake Duration Is Not Sanity-Checked",
        "body": "  In  the  function  GatewayRegistry.stake(),  the  parameter  durationBlocks  is  not  checked  to  lie within  some  reasonable  bounds.  A  user  can  therefore  inadvertently  plug  in  a  disproportionately  high value (e.g. thinking it is meant to be a duration in seconds) and lock their tokens for too long.  CS-SQDC-013    The stake duration is now checked not to exceed 3 years.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.12   Transferring the Ownership of Vesting",
        "body": "  SubsquidVesting aims to limit the usage of $SQD only within the protocol. However, the ownership of SubsquidVesting  can  be  transferred  to  a  contract  which  could  issue  transferrable  shares  of SubsquidVesting and therefore create a derivative of $SQD that can be traded.  CS-SQDC-003    Ownership transferring was disallowed. We assume that the beneficiaries of the vesting accounts will not be contracts.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.13   Event Rewarded Can Be Emitted With 0",
        "body": " Reward  In the Staking contract, the Rewarded event is emitted by the functions updateCheckpoint() and claim(). However, while the former checks for the reward to be positive before emitting the event, the latter does not.  CS-SQDC-010  Subsquid - Subsquid -   19  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedInformationalVersion1CodeCorrected                      \f  The event is now only emitted for positive rewards.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.14   Redundant Grant of Admin Role",
        "body": "  CS-SQDC-004  the   DistributedRewardDistribution   In  DEFAULT_ADMIN_ROLE  AccessControlledPausable, which DistributedRewardDistribution inherits from.  the  redundant  with   the  deployer.  This   constructor   contract,   the   to   is   grants   the constructor  of    The redundant statement was removed  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.15   Redundant Role-Granting Function",
        "body": "  In  contract  TemporaryHoldingFactory,  the  function  allowTemporaryHoldingCreator()  is redundant with the public grantRole() function (in OpenZeppelin's AccessControl), inherited from AccessControlledPausable.  CS-SQDC-007    The redundant function was removed  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.16   Two Different Implementations of ",
        "body": " effectiveTVL()  CS-SQDC-012  function  effectiveTVL()   The  in WorkerRegistration: in the former calculates the soft capped sum of the total bonded amount, the latter simply estimates the total bonded amount of all the workers.  in  RewardCalculation  and   implemented  both   is     The function was removed from the WorkerRegistration contract.  Subsquid - Subsquid -   20  InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected                  \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Cliff Value",
        "body": "  During vesting, the cliff depends on the totalAllocation i.e., the current balance of the token in the contract  and  the  released  amount.  However,  it  ignores  the  depositedIntoProtocol  amount.  This means, the value of the cliff and he vested amount varies depending on the amount of assets deposited into the system.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Computation Units Are Not Split Between an",
        "body": " Operator's Gateways  The function GatewayRegistry.computationUnitsAvailable() calculates the CUs available to a gateway by applying some mathematical formulas to the stake of its operator, regardless of the presence of  other  gateways  belonging  to  the  same  operator.  Therefore,  the  CUs  earned  by  an  operator  are \"replicated\" across all its gateways. According to Subsquid, the cluster is considered as a single instance of a gateway, with different endpoints. Therefore workers would have to track each cluster as a whole and monitor CU usage.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Incentives for Gateway Operators",
        "body": "  Gateway operators can lock their $SQD tokens for a period of time to get CUs in return. The number of CUs depends on the many factors:  the staked amount  the locked duration  the mana factor i.e., CUs per $SQD per epoch  the boost factor a step function for the most part with the exception of durations between 60 and 180 days where it's linear.  If the duration is set to a value greater than an epoch length then its effect is ignored. Therefore the CUs per epoch follow behave according to the graph below.  Subsquid - Subsquid -   21  NoteVersion1NoteVersion1NoteVersion1              \fNote that the operators have no incentive to stake for longer than an epoch unless they want to stake for longer  than  60  days.  Then  they  don't  have  an  incentive  to  stake  for  longer  than  180  days  unless  they want  to  stake  for  360  days.  Moreover,  an  operator  can  use  the  autoextension  option  so  their  $SQD remains staked until they decide otherwise.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   Incorrect Behavior of Variable ",
        "body": " depositedIntoProtocol  The  function  Vesting._vestingSchedule()  is  the  sole  consumer  of  the  storage  variable depositedIntoProtocol  inherited  from  Executable.  It  is  meant  to  track  the  total  $SQD  that  are currently not in the Vesting wallet itself, but have been deposited elsewhere in the protocol and can be in later  withdrawn  at  a  _vestingSchedule()  to SQD.balanceOf(address(this))  OZ already-released  VestingWallet.vestedAmount()) does not include such deposited funds.  locking  $SQD  as  a  gateway  operator).  that   It  totalAllocation   is  used  (equal  see   (e.g.  compensate   time  to   funds,   plus   fact   the   the   However,  the  implemented  behaviour  for  this  variable,  defined  in  Executable,  does  not  match  the description.  Indeed,  if  after  a  call  into  the  protocol  (using  Vesting.execute())  some  $SQD  are returned  the  variable depositedIntoProtocol is simply reset to 0, instead of being decremented by the appropriate delta. This harms the user, in case they have multiple positions open in the protocol through the wallet, which will now be left unaccounted for in the vesting schedule  (e.g.  by  calling  GatewayRegistry.unstake()),   the  wallet   to   According  to  Subsquid,  this  is  not  considered  to  be  an  issue.  However,  users  should  be  aware  of  this particular behavior of SubsquidVesting contract.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   Malleability of msg.data",
        "body": "  In  the  DistributedRewardDistribution  contract,  the  functions  commit()  and  approve() calculate  a  commiment  hash  as  keccak256(msg.data[4:]),  whereas  the  function  canApprove() calculates it by explicitly using abi.encode(), namely as keccak256(abi.encode(fromBlock, t oBlock, recipients, workerRewards, _stakerRewards)). This is a slight discrepancy, since msg.data is malleable: a caller to commit() or approve() can construct msg.data in many different ways,  (see https://docs.soliditylang.org/en/v0.8.25/security-considerations.html#minor-details).  On  the  other  hand, abi.encode() always serialises the parameters in the same way, regardless of how they are encoded in msg.data.  parameters   encoding   logical   same   the   all   Besides  the  two  calculations  potentially  mismatching  (which  leads  to  a  potentially  wrong  answer  by canApprove()),  the  very  exposure  to  the  malleability  of  msg.data  in  the  commit()  function  is  an  Subsquid - Subsquid -   22  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "0.010.10.4112510601803607201500Duration in days (log)02468CUs1e6Available CUs as a function of duration(amount=1000, mana=10)NoteVersion1NoteVersion1 ",
        "body": "       \fissue. The current distributor can inadvertently call the function with a \"non-default\" encoding: if the other distributors then try to approve() using the \"default\" encoding, the call will revert. Moreover, the current distributor can reset the approval count to 1, by re-submitting the same commit with a different encoding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.6   Wrong Initialisation of Epoch Variables",
        "body": "  In  contract  NetworkController,  the  constructor  initialises  firstEpochBlock  as  nextEpoch(). However, the function nextEpoch() is not yet able to return the correct value at this early stage, since it itself relies on the value of firstEpochBlock being correct (and not 0).  This  leads  firstEpochBlock  to  take  a  value  lower  than  it  should  (although  still  in  the  future),  thus reducing the effective duration of epoch 0.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.7   addDistributor() and",
        "body": " removeDistributor() Change distributorIndex  the  DistributedRewardDistribution  contract,   functions  addDistributor()  and In  removeDistributor()  modify  distributors.length(),  thus  changing  the  return  value  of distributorIndex().  the   Subsquid - Subsquid -   23  NoteVersion1NoteVersion1        \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   WrappedAToken Does Not Implement Its",
        "body": " Interface  The interface IWAToken is defined in oracles-v3/contracts/interfaces/aave/IWAToken.sol and used to interact with WrappedAToken, but WrappedAToken does not implement fully this interface.  CS-GEARV3INTGRTNS-001  Acknowledged:  Gearbox Protocol responded:  The contract conforms to the interface, which is sufficient.(Note, however, that external interfaces in oracles are reduced to only have the functions necessary in price feeds).  Gearbox Protocol - Gearbox V3 Integrations -   13  SecurityDesignCorrectnessCriticalHighMediumLowAcknowledgedDesignLowVersion1Acknowledged             \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings   Back-running Redemption Approvals    Front-running the Redeem   -Severity Findings  -Severity Findings   Number of Underlying Tokens in Metapools   Informational Findings   Gas Optimizations   0  2  0  1  1  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Back-running Redemption Approvals",
        "body": "  When redeeming assets a user calls redeem to the relevant zapper. They should give approval to the zapper to be able to redeem the assets. An attacker who sees the approval can the front-run the actual redemption redeem the assets of the user.  The  issue  was  reported  by  the  client  during  the  review  after  an  independent  assessment  of  the codebase.  CS-GEARV3INTGRTNS-004    Only the msg.sender can use their approvals.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Front-running the Redeem",
        "body": "  When redeeming a token with permit, a user specifies the receiver of the redeemed assets and submits a signature which is verified as follows:  try IERC20Permit(tokenOut()).permit(owner, address(this), tokenOutAmount, deadline, v, r, s) {} catch {} // U:[ZB-5]  CS-GEARV3INTGRTNS-005  Note that the signature verified is not connected to the msg.sender. Thus, an attacker who observes the mempool can front-run and submit the same signature. Since the receiver is freely set, an attacker can redeem the assets of a user.  Gearbox Protocol - Gearbox V3 Integrations -   14  CriticalHighCodeCorrectedCodeCorrectedMediumLowCodeCorrectedCodeCorrectedSecurityHighVersion2CodeCorrectedSecurityHighVersion1CodeCorrected                \fThe  issue  was  reported  by  the  client  during  the  review  after  an  independent  assessment  of  the codebase.    In the current implementation, only a signature belonging to the msg.sender can be verified.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Number of Underlying Tokens in Metapools",
        "body": "  The current implementation of CurveV1AdapterBase assumes the metapool to be a tricrypto pool, or at least have 3 underlying tokens. If the metapool has less than 3 underlying tokens, then the constructor will revert.  CS-GEARV3INTGRTNS-003    The function _getCoin will not revert if CurvePool.coin() reverts.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Gas Optimizations",
        "body": "  In the constructor of CurveV1AdapterBase, when the underlying tokens are queried for lending pools, the loop can break in the case !success as the calls to underlying_coins in following iterations will fail as well.  CS-GEARV3INTGRTNS-002    The loop now breaks the first time success is false.  Gearbox Protocol - Gearbox V3 Integrations -   15  CorrectnessLowVersion1CodeCorrectedInformationalVersion1CodeCorrected              \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Zappers Do Not Support Tokens With Fees",
        "body": "  Even though the pools can handle tokens with fees (USDT for now), the zappers do not support tokens with fees. If the fees on USDT were to be activated, the Underlying[Deposit|Farming]Zapper will stop working and users will have to deposit and withdraw manually.  Gearbox Protocol - Gearbox V3 Integrations -   16  NoteVersion1  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Temporary DOS Through Donations",
        "body": "  In Notional, depositing collateral for others is possible. For example, depositUnderlyingToken can deposit  collateral  to  another  address  than  msg.sender.  Hence,  it  is  possible  to  donate  collateral  to  a position  in  such  a  way  that  it  becomes  tracked  within  the  Notional  system.  Since  the  external  position computes  the  managed  assets  based  on  what  Notional's  getAccount  returns,  such  donations  will become visible to the external position. Hence, it could be possible to temporarily DOS the position by donating to it an unsupported token.  Acknowledged:  Avantgarde Finance replied:  Preventative measures for this are challenging and add complexity, so since the worst case is that the position will have a reverting price, and since the owner can resolve this state by removing that collateral, we will provide a fix if this ever becomes an issue in practice.  Avantgarde Finance - Sulu Extensions VI -   11  SecurityDesignCorrectnessCriticalHighMediumLowAcknowledgedDesignLowVersion1Acknowledged             \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings   Balancer Price Feed Vulnerable to Read-Only Reentrancy   -Severity Findings   Borrowing From cTokens With Same Underlying Can Lead to Unreported Debt   -Severity Findings   Remaining BPT in Adapter    mulUp Incorrect Comment   0  1  1  2  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Balancer Price Feed Vulnerable to Read-Only",
        "body": " Reentrancy  Balancer's system is vulnerable to read-only reentrancy. During the removal of liquidity, an inconsistency between the total supply and a pool's balances can be created (using native ETH transfers). That can be leveraged to manipulate the price feed upwards - leading to an over-evaluation of the fund.    Now, a reentrancy protected call to setRelayerApproval() is made when the price is computed to ensure that Balancer is not reentered.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Borrowing From cTokens With Same",
        "body": " Underlying Can Lead to Unreported Debt  Some  cTokens  may  have  the  same  underlying  (e.g.  cWBTC  and  cWBTC2).  The  parser  validates  the cTokens to borrow from as follows:  // validate ctokens for (uint256 i; i < cTokens.length; i++) {     address cTokenStored = ICompoundDebtPosition(_externalPosition)         .getCTokenFromBorrowedAsset(assets[i]);      if (cTokenStored == address(0)) {  Avantgarde Finance - Sulu Extensions VI -   12  CriticalHighCodeCorrectedMediumCodeCorrectedLowCodeCorrectedSpeci\ufb01cationChangedSecurityHighVersion1CodeCorrectedCorrectnessMediumVersion1CodeCorrected                \f        require(             CompoundPriceFeed(getCompoundPriceFeed()).getTokenFromCToken(cTokens[i]) ==                 assets[i],             \"parseAssetsForAction: Bad token cToken pair\"         );     } else {         require(             cTokenStored == cTokens[i],             \"parseAssetsForAction: Assets can only be borrowed from one cToken\"         );     } }  Note that the validation aims to prohibit borrowing from two cTokens that have the same underlying. In most cases, this works correctly. However, borrowing from both cTokens (with the same underlying) for the first time in the same action will bypass the validation. Consider the following scenario:  1. Borrow for the first time from both cWBTC and cWBTC2.  2. In the first iteration of the loop, cTokenStored will be 0x0 due to WBTC never being borrowed.  3. In  the  second  iteration  of  the  loop,  cTokenStored  will  still  be  0x0  since  the  mapping  in  the external position has not been updated yet. The update will happen in __borrowAssets, after the parser returns.  This will allow the external position to borrow from both cTokens. Note that __borrowAssets will only keep track of the first cToken. Hence, debt of the second cToken will not be tracked. The total debt will be underreported in such a scenario.    The parser now solely validates against the price feed while the library now validates against the stored cToken.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Remaining BPT in Adapter",
        "body": "  Avantgarde Finance reported an issue when redeeming Balancer LP tokens. It was possible to redeem BPTs so that a maximum amount of burned LP tokens is specified along with exact received underlying amounts. If the maximum was not reached, the BPT remained in the adapter.    After redemption, any surplus BPT remaining in the contract is sent back to the vault proxy.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   mulUp Incorrect Comment",
        "body": "   function mulUp(uint256 _a, uint256 _b) internal pure returns (uint256 res_) {     uint256 product = _a * _b;     require(_a == 0 || product / _a == _b, \"mul overflow\");  Avantgarde Finance - Sulu Extensions VI -   13  CorrectnessLowVersion1CodeCorrectedCorrectnessLowVersion1Speci\ufb01cationChanged                \f    if (product == 0) {         return 0;     } else {         // The traditional divUp formula is:         // divUp(x, y) := (x + y - 1) / y         // To avoid intermediate overflow in the addition, we distribute the division and get:         // divUp(x, y) := (x - 1) / y + 1         // Note that this requires x != 0, which we already tested for.          return ((product - 1) / ONE) + 1;     } }  The  comment  in  the  mulUp()  function  of  BalancerV2FixedPoint  mentions  divUp.  It  was  likely  copied from  there  and  not  changed.  This  issue  is  also  present  in  the  Balancer  contract  that  mulUp()  was adopted from.  Specification changed:  The comments in the files were adapted to reflect that the comments are not reviewed.  Avantgarde Finance - Sulu Extensions VI -   14  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   No Asset Check in requestDeposit()",
        "body": "  0  0  0  1  CS-SUL10-001  requestDeposit   The  a _depositAsset  argument.  This  asset  should  match  up  with  one  of  the  deposit  assets  of  the corresponding  vault.  to  call __depositFromQueue for that asset.  in  GatedRedemptionQueueSharesWrapperLib   they  do  not  match,   the  manager   it  will  be   impossible   function   takes   for   If   As  there  is  no  check  on  _depositAsset,  a  user  may  accidentally  deposit  an  incorrect  asset.  A  user accidentally making such a request can get their funds back by calling cancelRequestDeposit.  Note that in Enzyme V4 each vault only has a single deposit asset, but this may change in the future.  Risk Accepted:  Avantgarde  Finance  acknowledges  that  this  can  happen  and  accepts  the  risk  that  a  user  could  waste gas.  Avantgarde Finance - Sulu Extensions X -   10  SecurityDesignCriticalHighMediumLowRiskAcceptedDesignLowVersion1RiskAccepted            \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  Incorrect depositFromQueue Can Lead to Loss of User Funds   -Severity Findings  -Severity Findings  0  1  0  0  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Incorrect depositFromQueue Can Lead to",
        "body": " Loss of User Funds  depositFromQueue() in GatedRedemptionShareWrapper takes an array of addresses and processes their  deposit,  removing  them  from  the  DepositQueue.  It  reads  the  user's  position  index  in  the  queue from storage. Afterwards, the Request at index is deleted.  CS-SUL10-002  However, there is no check if the address actually had a Request in the queue to begin with. If a user has no request, their storage mapping will point to a Request with the default index of zero. This will result  in  the  first  Request  in  the  queue  being  deleted.  The  user  who  had  the  deleted  request  will  not receive any wrapped shares and their funds will be lost.  As  __depositFromQueue()  is  protected  with  __onlyManagerOrOwner(),  only  the  managers  can call the function with a non-existing address, which would cause the issue.  This could happen on 2 occasions:  1. The manager accidentally passes an incorrect address.  2. The  manager's  depositFromQueue  call  gets  frontrun  by  one  of  the  users  in  the  DepositQueue calling  cancelRequestDeposit().  Now  the  canceled  Request  no  longer  exists,  leading  to  a loss  of  funds  for  another  user.  If  the  manager  passed  all  users  in  the  queue  as  argument,  the attacker  will  also  need  to  deposit  again  from  another  address  after  they  cancel,  otherwise  the queue will not have a sufficient length and will revert. Note that the attack is more likely to happen when there's no whitelisting in place i.e., when useDepositApprovals is set to false.  depositAllFromQueue() is not affected, as here incorrect addresses cannot be passed.    The internal __removeDepositRequest function now validates that a Request has an assetAmount that is greater than zero. This ensures that the Request must exist before removing it. If a non-existant Request is passed, the function now reverts.  Avantgarde Finance - Sulu Extensions X -   11  CriticalHighCodeCorrectedMediumLowSecurityHighVersion1CodeCorrected         \f6.2   No minIncomingAsset Check for ZeroEx  In ZeroExV4Adapter, the parseAssetsForAction function returns a minIncomingAssetAmounts_ array with only a zero value. This means there is no internal check on the trade price, as is done in other adapters.  As only single orders with a fixed price can be taken on ZeroEx, there can be no slippage.  However, a vault admin may accidentally take an order with a lower price than they intended.  CS-SUL10-003    The  parseAssetsForAction  function  now  sets  the  minIncomingAssetAmounts_  to  the  amount that is expected to be received given the price of the order and the taker amount.  Avantgarde Finance - Sulu Extensions X -   12  InformationalVersion1CodeCorrected      \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Cannot Pay ZeroEx Protocol Fee",
        "body": "  The ZeroEx protocol has a fee mechanism, where a fee in native ETH must be attached to fill limit orders. The ZeroExV4Adapter does not support sending ETH with the limit order call to pay this fee.  However, the fee is currently set to zero as of the time of this report and has been since September 29, 2021.  If the fee is set to a non-zero value again in the future, the adapter will no longer be able to make Limit Order trades.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Some ZeroEx Order Restrictions Not",
        "body": " Supported  ZeroEx  orders  have  taker  and  txorgin  fields,  which  restrict  who  can  take  a  particular  order.  These restrictions  cannot  be  used  to  specify  Enzyme  vaults  as  multiple  vaults  can  use  the  same ZeroExV4Adapter adapter.  If,  for  example,  the  taker  field  was  used  to  restrict  an  order,  it  would  be  set  to  the  address  of  the adapter. Any caller of the adapter would be able to take the order.  Avantgarde Finance - Sulu Extensions X -   13  NoteVersion1NoteVersion1      \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Locked Refunded Provision",
        "body": "  ISSUEIDPREFIX-007  When  a  maker  submits  an  order  to  the  Mangrove  orderbook,  they  need  to  provide  some  ETH,  also known as the provision, to compensate the takers in case the makerExecute hook reverts. A maker can update their offer by calling Forwarder.updateOffer. Note that at this point a maker can update most of the parameters of the order including gasreq, i.e. the gas required for the makerExecute hook to execute. A maker could reduce the gas requirements meaning that some provision will be refunded to them. Forwarder.updateOffer does not handle this refunding (the ownerData.weiBalance is not updated) and Mangrove system only sees MangroveOrder as a maker. This means that the refunded amount is essentially lost for the end-user of the MangroveOrder. Note that if the provision needs to be increased again, the end-user must provide extra ETH.  Code Corrected:  In the current implementation, the provision can only be increased therefore no funds are locked.  Mangrove Association (ADDMA) - MangroveOrder -   12  CriticalHighCodeCorrectedCodeCorrectedMediumCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedLowCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCorrectnessHighVersion1CodeCorrected            \f6.2   Wrong Calculation of Locked Provision  When a user updates their offer through Forwarder.updateOffer, MangroveOrder tries to calculate the new gas price by calling deriveGasprice. The gas price depends on the total provision available for  this  order.  That  is  the  sum  of  the  extra  provision  attached  which  is  stored  in  args.fund  and  the already locked provision. Currently, the locked amount is calculated with the following snippet:  vars.offerDetail.gasprice() * 10 ** 9 * args.gasreq + vars.local.offer_gasbase()  ISSUEIDPREFIX-011  This formula is wrong for two reasons:  1. It depends on args.gasreq which is the updated gas requirement of the order as passed by  the user.  2. There are parentheses missing around args.gasreq + vars.local.offer_gasbase(),  as this entire term should be multiplied by the gas price.  This miscalculation can have multiple consequences:  1. Can allow users to steal funds (see relevant issue).  2. An  order  can  be  submitted  with  smaller  gasprice  since  the  calculated  total  provision  is  too  small.  Code Corrected:  Forwarder.updateOffer has been updated. Currently, users can only increase the provision for an order.  Users  cannot  determine  args.gasreq  as  it  is  set  to  be  equal  to  the  offerGasreq().  It  is important  to  notice  that  offerGasreq()  is  not  constant  but  depends  on  the  configuration  of  the MangroveOrder and in particular the gas requirements of the router.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Expiration Date Cannot Be Updated",
        "body": "  A  user  can  update  most  of  the  offer  details  by  calling  Forwarder.updateOffer.  However,  the expiration date cannot be changed. In order to change the expiration date of an order, one must retract it and submit a new one.  ISSUEIDPREFIX-003  Code Corrected:  MangroveOrder.setExpiry has been added to allow users to update the expiration date of the order.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Underflow in postRestingOrder",
        "body": "  ISSUEIDPREFIX-009  Mangrove Association (ADDMA) - MangroveOrder -   13  CorrectnessHighVersion1CodeCorrectedDesignMediumVersion1CodeCorrectedCorrectnessMediumVersion1Speci\ufb01cationChanged                      \fOnce the market order part of GTC order has been filled as much as possible, the remaining amount the user  wants  to  trade  is  put  into  a  resting  order.  Note  that  if  fillWants  ==  true,  then  the  Mangrove engine will have stopped matching the order either when it is fully filled, there are no more orders on the books, or when the total average price of the order would fall below the threshold of the ratio between the order's initial wants and gives. Hence, if the matching stops before the order's wants are fully filled, we are  guaranteed  not  to  have  given  away  more  than  the  order  initially  had  (else  the  total  average  price would be below what we initially wanted).  However,  if  fillWants  ==  false,  this  condition  no  longer  holds.  The  order  can  receive  arbitrarily many tokens before giving away all the tokens it has to give away. As the price of a trade is defined by the  maker,  there  could  be  orders  on  the  books  which  give  away  arbitrarily  many  tokens  for  a  very  low price.  Hence,  the  user  can  receive  more  tokens  in  the  market  order  part  of  the  trade  than  they  were expecting to. As such, res.takerGot + res.fee can exceed tko.takerWants despite only having partially filled the order.  When we go to post a resting order, the following code is executed:  res.offerId = _newOffer(   OfferArgs({     outbound_tkn: outbound_tkn,     inbound_tkn: inbound_tkn,     wants: tko.makerWants - (res.takerGot + res.fee), // tko.makerWants is before slippage     gives: tko.makerGives - res.takerGave,     gasreq: offerGasreq() + additionalGasreq, // using default gasreq of the strat + potential admin defined increase     gasprice: 0, // ignored     pivotId: tko.pivotId,     fund: fund,     noRevert: true, // returns 0 when MGV reverts     owner: msg.sender   }) );  When  the  wants  for  the  resting  order  are  calculated,  an  underflow  can  occur  in  the  case  described above, as the market order part of the GTC order could have received arbitrarily many tokens. As Solidity ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "0.8.10  is  used,  this  will  simply  revert  the  transaction,  but  will  unnecessarily  prevent  the  user  from",
        "body": " completing their trade.  Specification Changed:  Currently,  the  order  is  posted  with  the  same  price  as  the  taker  originally  wanted.  Thus,  the  issue  has been mitigated.  Mangrove Association (ADDMA) replied:  this  problem  made  use  reevaluate  our  specification:  requiring  the  (instant)  market  order  and  the (asynchronous) maker order to respect a limit average price is not well defined. In some cases this would lead the maker order to be posted for a 0 price. We decided to change the specification and post the maker order at the price initially set by the taker for the market order (irrespectively of the obtained price).  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Users Can Steal Funds From MangroveOrder",
        "body": "  The core Mangrove system maintains the balanceOf mapping which stores how much ETH is available for each maker to be used as a provision for their orders. Importantly, the MangroveOrder contract is seen  as  one  single  maker  by  the  system,  even  though  there  might  be  many  end  users  creating  their orders through it. Let us assume that at some point the balance of MangroveOrder is positive and an attacker has already submitted an order. It is possible as we show in another issue that there might be  ISSUEIDPREFIX-013  Mangrove Association (ADDMA) - MangroveOrder -   14  SecurityMediumVersion1CodeCorrected        \fsome non-claimable balance since updateOrder does not handle refunds. An attacker can steal money from mangrove by employing any of the following two vectors:  1. Updating an order without sending funds:   The attacker calls Forwarder.updateOrder for their order with msg.value == 0 and  they increase the gas requirement of their order.   This means that args.fund == 0 so gas price will remain the same, however, the total  provision needed has been increased as the gas requirements have been increased!   At this point MGV.updateOffer is called with msg.value == 0.   Mangrove core does not perform any check if there are enough funds attached to the call  since it relies on the balanceOf mapping by calling debitWei.   Mangrove core uses the amount stored in balanceOf for the extra provision.   The  attacker  now  retracts  the  order  and  withdraws  the  provision  of  the  order  which  includes the stolen amount.  2. Updating an order by attaching funds:   The attacker calls Forwarder.updateOrder for their order with msg.value != 0 and  they increase the gas requirement of their order.   Since funds have been attached to the transaction, the gas price will be recalculated.   The  new  provision  at  this  point  is  calculated  wrongly  since  the  provision  parameter passed  to  derivePrice  depends  on  args.gasreq  which  represents  the  updated  gas that requirements  of  args.gasreq can be freely set by the users so arbitrarily large value could be passed. As a result, the new gas price is greater than it should be but the extra funds passed are not enough to cover for the extra provision needed by the offer.  the  offer  and  not  vars.offerDetail.gasreq().  Note    Mangrove core uses the amount stored in balanceOf for the extra provision.   The  attacker  now  retracts  the  order  and  withdraws  the  provision  of  the  order  which  includes the stolen amount.  A  similar  attack  can  be  performed  when  some  of  the  global  parameters  change,  which  could  result  in inaccurate accounting of provisions. If the gasbase of the token pair related to an order changes in the core mangrove system, calling updateOffer can result in an increased (or decreased) provision without providing any additional funds. This will credit (or debit) funds to the MangroveOrder contract which aren't attributed  to  any  user.  In  particular,  if  the  global  gas  price  is  increased,  calling  updateOffer  of Mangrove core with an unchanged gasprice which is lower than the new global gas price, the mangrove core system will set the gas price higher without receiving any funds. This again changes the balance of the  MangroveOrder  contract,  without  attributing  it  to  any  individual  user.  While  _newOffer  and _updateOffer in Forwarder have checks to make sure the offer's gas price is higher than the global gas price, __posthookSuccess__ in MangroveOffer does not. Hence, if the global gas price changes, then an order is partially filled and attempts to repost, its provision will be increased with no additional submitted funds. While the amounts of funds are small, it is conceivable that a malicious user could be able to exploit a change in the global gas price or the gasbase in order to steal funds.  It  is  important  to  note  that  this  issue  cannot  result  in  users  losing  funds  since  the  excessive  provision which can be stolen cannot be claimed by any specific user. In the normal case, no excessive provision should  be  available.  Therefore,  it  is  expected  the  amount  that  can  be  stolen  to  be  low.  Hence,  we consider the issue as medium severity.  Code partially corrected:  The issue has been addressed in multiple different ways:  Mangrove Association (ADDMA) - MangroveOrder -   15  \f1. In the current implementation there shouldn't be unallocated users' funds in Mangrove core.  2. Users can only increase the provision of an order using MangroveOrder.updateOrder, not decrease  it.  Hence,  they  must  provide  additional  provision  and  can  not  submit  orders  which could make use of funds that are already stored in the Mangrove core.  3. The __posthookSuccess__ uses Forwarder._updateOffer.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Interpretation of type(uint24).max Not",
        "body": " Up-To-Date  ISSUEIDPREFIX-006  Before  Forwarder contract, i.e., gasreq = offerGasreq. In  is  removed  MangroveOffer.getMissingProvision  which  will  return  an  gasreq >= type(uint24).max.  ,  the  value  type(uint24).max  or  more  had  a  special  meaning  for  gasreq  in  the , the meaning of that value has been function the  if  called  with  incorrect  value   Forwarder,   present   from   still   the   but   in     The  function  has  been  removed.  It  has  been  suggested  that  MgvReader.getProvision()  can  be used as an alternative.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Wrong Comment",
        "body": "  The NatSpec of __posthookSuccess__ specifies for example \"posthook/filled\" as return data. However, the return data has changed its format.  ISSUEIDPREFIX-014  Specification changed:  The specification has been adapted.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   Inaccurate Comment",
        "body": "  In MangroveOrder.checkCompleteness, the following is mentioned:  // when fillWants is true, the market order stops when takerWants units of outbound_tkn have been obtained;  However, this comment is inaccurate since part of the takerWants goes to cover the fees, so not the full takerWants amount can be obtained.  In AbstractRouter.push, the return value is described as follows:  ISSUEIDPREFIX-005  Mangrove Association (ADDMA) - MangroveOrder -   16  CorrectnessLowVersion4CodeCorrectedVersion4Version4CorrectnessLowVersion4Speci\ufb01cationChangedDesignLowVersion1CodeCorrected                        \f///@return pushed fraction of amount that was successfully pushed to reserve.  However,  for  tokens  with  fees,  provided  the  TransferLib  is  used,  the  whole  amount  will  always  be reported.  Code Corrected:  The comments have been updated.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   Missing Natspec",
        "body": "  The Natspec is missing in the following cases:   For AbstractRouter.bind, the maker parameter.   For AbstractRouter.unbind, the maker parameter.   For SimpleRouter.__pull__, the strict parameter.   For IOfferLogic.OfferArgs, the gasprice field.  Code Corrected:  The Natspec has been added to the respective functions.  ISSUEIDPREFIX-008  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   Redundant pragma abicoder v2",
        "body": "  Many contracts include the pragma abicoder v2 directive. However, for solidity 0.8 the abicode v2 is the default one, so the pragma is redundant.  ISSUEIDPREFIX-010  Code Corrected:  The pragma has been removed from most of the contracts.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.11   Setting Expiration Date",
        "body": "  A user can define the time-to-live of a resting order submitted through MangroveOrder by specifying the TakeOrder.timeToLiveForRestingOrder.  It  is  important  to  note  that  an  order  can  remain  in  the mempool  for  a  long  time  before  it's  executed.  Specifying  an  explicit  expiration  date  instead  of  the time-to-live might be more convenient for users since it's independent of the time it takes for a transaction to be included in a block.  ISSUEIDPREFIX-002  Mangrove Association (ADDMA) - MangroveOrder -   17  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \fCode Corrected:  The  expiration  date  is  now  absolute  and  no  longer  relative  to  the  time  the  transaction  is  added  to  the blockchain.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.12   Forwarder.provisionOf Calculation Is",
        "body": " Wrong  ISSUEIDPREFIX-012  As its natspec suggests Forwarder.provisionOf computes the amount of native tokens that can be redeemed  when  In MgvOfferMaking.retractOffer, the provision is calculated as follows:  offer.  However,   deprovisioning   given   true.   this   not   is   a   provision = 10 ** 9 * offerDetail.gasprice() //gasprice is 0 if offer was deprovisioned   * (offerDetail.gasreq() + offerDetail.offer_gasbase());  The important part to notice is that provision depends on offerDetail.offer_gasbase().  This is not the same for Forwarder.provisionOf where the provision is calculated as follows:  provision = offerDetail.gasprice() * 10 ** 9 * (local.offer_gasbase() + offerDetail.gasreq());  Here,  offerDetail.offer_gasbase().  provision   the   depends   on   local.offer_gasbase()   instead   of  Code Corrected:  The provision is now calculated using the offerDetail.offer_gasbase().  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.13   Array Length Mismatch",
        "body": "  The batched functions of the TransferLib can take arrays differently sized arrays. The desired execution in that case is unclear.  ISSUEIDPREFIX-001    The batched functions have been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.14   Explicit Variable Visibility",
        "body": "  Mangrove Association (ADDMA) - MangroveOrder -   18  ISSUEIDPREFIX-004  DesignLowVersion1CodeCorrectedInformationalVersion4CodeCorrectedInformationalVersion1CodeCorrected                    \fAccessControlled has now a state variable _admin. However, it does not have explicit visibility defined. Note that this does not lead to any double getters since its by default internal. However, specifying explicit visibility may make code clearer.  Note that this is the case also for boundMakerContracts in AbstractRouter.    The code has explicit variable visibility now.  Mangrove Association (ADDMA) - MangroveOrder -   19  \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Updating Approvals on Order Update",
        "body": "  A  user  can  update  their  orders  by  using  Forwarder.updateOffer.  It  is  important  for  users  to remember  that,  in  case  the  makerExecute  hook  to  their  order  fails,  they  will  have  to  reimburse  the taker. A reason for an order to fail is that there is not enough allowance given to the router to transfer funds from the maker's reserve to MangroveOrder contract. This is highly likely to happen after a user updates their offer by having it give more funds to the taker.  Mangrove Association (ADDMA) - MangroveOrder -   20  NoteVersion1  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Missing Min/Max Checks in ChainlinkOracle",
        "body": "  CS-EULPO-002  Chainlink aggregators have a minimum and maximum price defined. Any updates to the aggregators are rejected  if  these  thresholds  are  crossed.  In  most  cases,  this  is  not  problematic.  There  are,  however, certain  feeds  for  which  the  thresholds  are  defined  in  a  way  that  could  be  reached  in  certain  market events.  If the thresholds are crossed, the oracle prices won't update anymore. Since most Chainlink feeds are configured  with  rather  high  heartbeats  (e.g.,  24  hours),  it  takes  some  time  until  this  can  be  reliably detected by the ChainlinkOracle.  In the rare case this happens, it can have catastrophic effects on any protocol relying on the oracle, as stale prices will be reported.  Risk accepted:  Euler accepts the risk with the following statement:  We have decided not to include minAnswer and maxAnswer bounds to ChainlinkOracle. It is unclear  whether  we  can  expect  these  value  to  change  so  we  cannot  safely  store  them  as immutable variables. We expect ChainlinkOracle to be a very hot contract for markets and we believe the gas cost increase associated with runtime fetching of minAnswer and maxAnswer is not worth  it.  Ultimately  we  believe  these  values  are  chosen  responsibly  by  the  Chainlink  team.  This opinion is evidently shared by the largest users of Chainlink, which also do not have minAnswer and maxAnswer checks.  Euler - Price Oracles -   11  SecurityDesignCorrectnessCriticalHighMediumLowRiskAcceptedSecurityLowVersion1RiskAccepted             \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings   RedstoneCoreOracle Update With Stale Data   -Severity Findings   RedstoneCoreOracle DoS   Informational Findings   Typographical Error    RedstoneCoreOracle Forced Package Ordering    Missing Uniswap Oracle Documentation   0  0  1  1  3  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   RedstoneCoreOracle Update With Stale Data",
        "body": "  CS-EULPO-001  RedstoneCoreOracle  implements  the  PrimaryProdDataServiceConsumerBase  of  Redstone's SDK. This contract manages the validation of submitted calldata to the updatePrice() function. Such calldata contains a minimum of three different packages that each contain a price for the requested feed, as well as a timestamp (and the signature of the associated Redstone signer). Timestamps, after being extracted  from  calldata,  are  handled  in  the  function  validateTimestamp()  which  checks  their staleness. This is done individually for each submitted package.  RedstoneCoreOracle  overrides  the  validateTimestamp()  function  to  add  custom  staleness checks as well as a storage write of the given timestamp. To avoid redundant writes, the function returns early when a given timestamp is equal to the timestamp that has been previously written to storage:  function _validateTimestamp(uint256 timestampMillis) internal {     // The `updatePriceContext` guard effectively blocks external / direct calls to `validateTimestamp`.     Cache memory _cache = cache;     if (_cache.updatePriceContext != FLAG_UPDATE_PRICE_ENTERED) revert Errors.PriceOracle_InvalidAnswer();      uint256 timestamp = timestampMillis / 1000;     // Avoid redundant storage writes as `validateTimestamp` is called for every signer in the payload (3 times).     // The inherited Redstone consumer contract enforces that the timestamps are the same for all signers.     if (timestamp == _cache.priceTimestamp) return;      if (block.timestamp > timestamp) {         // Verify that the timestamp is not too stale.         uint256 priceStaleness = block.timestamp - timestamp;          if (priceStaleness > maxStaleness) {             revert Errors.PriceOracle_TooStale(priceStaleness, maxStaleness);         }  Euler - Price Oracles -   12  CriticalHighMediumCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCorrectnessMediumVersion1CodeCorrected        \f    } else if (timestamp - block.timestamp > RedstoneDefaultsLib.DEFAULT_MAX_DATA_TIMESTAMP_AHEAD_SECONDS) {         // Verify that the timestamp is not too long in the future (1 min). Redstone SDK explicitly allows this.         revert Errors.PriceOracle_InvalidAnswer();     }      // Enforce that cached price updates have a monotonically increasing timestamp.     if (timestamp < _cache.priceTimestamp) revert Errors.PriceOracle_InvalidAnswer();     cache.priceTimestamp = uint48(timestamp); }  This  is  done  under  the  assumption  that  the  timestamps  on  all  submitted  packages  are  equal. PrimaryProdDataServiceConsumerBase,  however,  never  enforces  this,  leading  to  the  issue depicted by the following example:  1. updatePrice() is called with three packages containing the prices [1, 1, 1] and timestamps [1, 1,  1].  2. The cached price is set to 1, as is the cached timestamp.  3. After  some  time,  the  price  of  the  respective  asset  has  changed  a  lot.  A  new  price  update  would  contain three packages with the prices [2, 2, 2] and timestamps [2,2, 2].  4. A malicious user crafts calldata that contains two of the old prices and timestamps ([1, 1, 2] and [1,  1, 2]) and calls updatePrice() with it.  5. validateTimestamp(),  for  the  first  two  packages,  returns  early  because  the  timestamps  are equal to the old timestamp in the cache. For the third package, it performs staleness checks and writes the new timestamp 2 into the cache.  6. updatePrice() writes the median of the received prices ([1, 1, 2] -> 1) into the cache. The oracle  now contains the price 1 with a timestamp of 2.  7. The  user  can  now  call  getQuote()  to  retrieve  the  price  without  revert  as  the  price  is  not  stale  (assuming that the price would be stale with timestamp 1).  The longer the oracle has not been updated, the more severe this problem becomes, as the price can always be kept at the price of the last update while the timestamp is reset to a current one. The fact that prices are aggregated by median value exacerbate this problem further.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   RedstoneCoreOracle DoS",
        "body": "  RedstoneCoreOracle.updatePrice()  enforces  monotonically  increasing  timestamps.  If  a  user updates the price with a timestamp that is lower than the one stored in the cache, the transaction reverts.  Since price signatures are published rapidly, it is possible that two users submit price updates at roughly the  same  time  but  with  different  timestamps.  If  the  transaction  of  the  user  with  the  lower  timestamp  is executed last, it will revert. Users should be aware that even if their price update transaction fails, there may still be a valid price to read afterwards.  Consider the following example:  CS-EULPO-008  1. User Alice submits a multicall transaction that updates the price and then reads it.  2. Alice is frontrun by someone else who updates the price to an even newer value.  3. The updatePrice() call reverts.  4. As  the  transaction  has  reverted,  the  rest  of  Alice's  transaction  will  also  revert  even  though  it  could have used the more up-to-date price.  Protocol developers should consider catching reverts in price updates when executing them as part of a multicall. Otherwise unnecessary reverts could result in Denial of Service.  Euler - Price Oracles -   13  DesignLowVersion1CodeCorrected        \f  RedstoneCoreOracle.updatePrice()  no  longer  reverts  when  a  price  update  with  an  outdated timestamp occurs. It is worth to note that this now means that users' transactions might now be executed with a different price than anticipated.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Missing Uniswap Oracle Documentation",
        "body": "  The  documentation  of  UniswapV3Oracle  contains  a  warning  detailing  in  which  circumstances  the oracle can be used (mostly) safely. Among other things, the cardinality of the observation buffer and the need for enough liquidity is mentioned. While this is correct, it could be further extended:  CS-EULPO-004  1. The  buffer  must  not  only  have  enough  cardinality,  but  there  also  must  have  been  enough  observations since it was extended to fully fill it.  2. Not only the liquidity at the current time is relevant, but also the liquidity while the buffer was  filled with data.  Specification changed:  UniswapV3Oracle  now  contains  appropriate  documentation  to  make  users  aware  of  the  additional requirements.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   RedstoneCoreOracle Forced Package",
        "body": " Ordering  CS-EULPO-005  RedstoneCoreOracle.validateTimestamp()   Since  increasing timestamps, packages with differing timestamps must be ordered in the calldata so that the call does not revert.  enforces  monotonically   This  is  different  to  the  regular  Redstone  SDK  implementation  and  may  lead  to  incompatibilities. Developers should be aware of this restriction.  RedstoneCoreOracle now requires timestamps of all data packages to be equal.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Typographical Error",
        "body": "  The comments of RedstoneCoreOracle.updatePrice() contain the following line which is missing a comma: \"During execution the context flag is set to `FLAG_UPDATE_PRICE_ENTERED`.\".  CS-EULPO-007  Euler - Price Oracles -   14  InformationalVersion1Speci\ufb01cationChangedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected                  \f  The comment has been removed as the respective functionality is no longer present.  Euler - Price Oracles -   15  \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   L2 Sequencer Considerations",
        "body": "  CS-EULPO-003  The contracts will initially be deployed to Ethereum mainnet only but should eventually work on any L2.  Before deploying to L2s, consider that the L2 sequencer can have extended downtime.  The Chainlink docs suggest using the SequencerUptimeFeed to detect this and not consume any prices until the sequencer is back up.  Also, the Uniswap TWAP will have a high weight for the price that was present during the downtime (as it persisted  for  a  long  time).  This  could  be  a  problem  if  the  price  was  an  outlier  or  if  the  price  when  the sequencer recovers is significantly different from when it went down.  Additionally,  block.timestamp  may  have  slightly  different  behavior  on  other  chains.  This  should  be considered before deploying.  Acknowledged:  Euler acknowledges the risk associated with the mentioned markets.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Redundant Chronicle Adapter",
        "body": "  The ChronicleOracle communicates with Chronicle price feeds using the function readWithAge(). Chronicle,  however,  also  exposes  the  function  latestRoundData()  that  is  equivalent  to  Chainlink's feed  interface.  Since  only  positive  prices  are  used,  the  ChainlinkOracle  should  therefore  be compatible with Chronicle as well.  CS-EULPO-006  Acknowledged:  Euler acknowledges that the contract is redundant.  Euler - Price Oracles -   16  InformationalVersion1AcknowledgedInformationalVersion1Acknowledged          \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Compounding Errors in CrossAdapter",
        "body": "  CrossAdapter  allows  chaining  oracle  calls  in  order  to  get  price  quotes  for  pairs  with  no  direct  feed available.  Users  should  be  aware  that  using  such  an  oracle  might  increase  the  margin  of  error  in comparison to using a single oracle. This is especially relevant for pull-based oracles that give users the ability to \"choose\" their price in a narrow margin, but also applies to push-based oracles.  Consider the following example:   A CrossAdapter chains two instances of PythOracle   Both  oracles  have  an  outdated  price  (that  is  not  stale  yet),  which  is  0.5%  different  from  the  newest price   Usually, a user would be able to choose between the old price and the new price, which gives  them a 0.5% choice.  In this case, the user can make this choice twice, so in the worst case, they may be able to use a price that is ~1% different from the current price.  Any errors in chained oracles will be accumulated when using CrossAdapter. The resulting wider error margin should be included in risk assessments by consumers.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Lido Oracle Staleness",
        "body": "  The  LidoOracle  converts  stETH  to  wstETH  and  vice  versa.  This  is  done  by  calling  the  functions getSharesByPooledEth() and getPooledEthByShares() respectively on the stETH contract.  The pooled ETH value in Lido is only updated periodically.  There are two main cases where the ETH per share will change:  1. Staking rewards accrue (small increase)  2. Validators are slashed (variable size decrease)  Both of these changes are possible to predict before they are reflected on-chain. Someone could frontrun the update and use the stale price, with knowledge of what the future price will be.  Protocols using the LidoOracle must take this into account and should especially consider the slashing case. A slashing event will only be reflected by LidoOracle long after it has happened.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.3   No Price Quote in Vault Tokens",
        "body": "  Euler - Price Oracles -   17  NoteVersion1NoteVersion1NoteVersion1           \fEulerRouter.resolveOracle()  allows  to  find  the  configured  oracle  for  a  given  asset  pair.  If  the base  token  is  the  token  of  an  ERC-4626  vault  and  the  vault  has  been  configured  in  the  router,  the corresponding oracle can be resolved by first converting the vault's token to the corresponding amount of the vault's asset and then solving for an oracle of the vault's asset.  Note that this is not supported for the quote token. Prices cannot be quoted in vault tokens even if the corresponding vault is be configured in the router.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.4   Oracle Consumers Must Handle Reverts",
        "body": "  Most  of  the  implemented  oracle  adapters  have  certain  conditions  that  can  cause  reverts.  One  reason could be a price becoming stale.  Oracle consumers must be aware of this and should mitigate the impact of a reverting oracle as much as possible. Depending on design, a revert in the oracle may cause an unnecessary denial of service to the whole system.  For example, it should be considered if it is possible to allow withdrawals even when an oracle is down.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.5   Oracle Manipulation on FIFO L2s",
        "body": "  Price oracles must be robust and manipulation-resistant. It must be expensive to manipulate the markets which are used as price sources.  Usually,  the  factor  that  makes  price  manipulation  expensive  is  arbitrage.  If  a  manipulator  pushes  the price of an asset too high or too low, arbitrageurs will see this and make a profit by moving the price back to the \"true price\". Any profit made by arbitrageurs will be a loss to the manipulator.  This \"arbitrage assumption\" breaks down in two cases:  1. All markets for the token are manipulated simultaneously, so it is difficult to determine the \"true  price\". There is no other market to arbitrage against.  2. Arbitrageurs  are  not  able  to  see  the  manipulated  price  quickly  enough,  so  they  cannot  take  advantage of it.  Attacks that target condition 2. are known as \"Multi-block MEV\" attacks. The idea is that a manipulator could control the order of transactions in a block, which allows the following:  In block n, the manipulator sends a transaction (through a private mempool like Flashbots) that manipulates the price of an asset.  In block n+1, the manipulator ensures that the first transaction in the block is one where they revert the price back to the original value.  As a result, arbitrageurs will have no chance of reacting to the manipulation, as it will already be over by the time they can get a transaction included in the block. However, if there is an Oracle that reads the price at the beginning of block n+1, it will see the manipulated price.  This  attack  is  well-known  on  Ethereum,  but  is  generally  deemed  expensive  to  execute,  as  it  requires being  or  having  an  agreement  with  the  ETH  staker  that  is  chosen  to  propose  block  n+1.  If  the  attack should  be  repeated  multiple  times,  it  requires  being  chosen  as  block  proposer  multiple  times  within  a short time frame, which requires a significant amount of ETH staked.  Euler - Price Oracles -   18  NoteVersion1NoteVersion1          \fHowever, on L2s, block production works differently. Instead of a different proposer being chosen in each block, there is typically a single sequencer that decides on a block ordering policy. One commonly used policy  used  by  chains  such  as  Arbitrum,  Optimism  and  Base  is  \"FIFO\"  (First  In,  First  Out),  where transactions are included in the order they were received.  In FIFO ordering, the order of transactions is determined by time, not by the price a user is willing to pay. This can be taken advantage of to fulfill condition 2. above, without needing to be a block producer.  The FIFO attack looks as follows:  1. The manipulator experiments to figure out their latency to the sequencer (and ideally minimizes  it).  2. The  manipulator  sends  a  manipulation  transaction  at  a  time  such  that  it  will  arrive  at  the  sequencer towards the end of the period in which it is building block n.  3. The manipulator sends a second transaction so that it reaches the sequencer at the beginning  of the period in which it is building block n+1.  Arbitrageurs are only able to see the manipulated price once block n is published by the sequencer. By that  time,  the  manipulator  has  already  sent  the  second  transaction  that  reverts  the  price  back  to  the original value. As time is the only relevant factor, it is impossible for a transaction that is created later to be included in the block first (unless the arbitrageur has significantly lower latency to the sequencer).  The only cost to the attacker is the trading fees paid. As the attack cannot use a flashloan, they must also have sufficient capital available to manipulate the price by the percentage they aim for. The attack can be repeated as many times as the attacker wants, although repeated attacks could be speculatively frontrun by  arbitrageurs  if  they  detect  a  pattern.  Repeated  attacks  can  be  used  to  circumvent  outlier-detection mechanisms and TWAPs.  A policy that modifies transaction ordering to be based on a payment in addition to timing would make the attack significantly more expensive. For example, \"Arbitrum time-boost\" has been proposed, but not yet implemented. See Time Boost Medium post.  Note  that  Multi-block  MEV  attacks  have  historically  been  considered  mostly  in  the  context  of  TWAP manipulation. However, if there is an off-chain oracle, such as ChainLink, that uses an on-chain market as a primary price source, the attack also applies there. In fact, the effect will be much larger, as off-chain oracles typically do not use a time-weighted average. Instead, they read the spot price at a single point in time.  As  a  result,  executing  the  attack  once  could  lead  to  a  heavily  manipulated  price.  Some  off-chain oracles  may  implement  outlier-detection  to  mitigate  this,  but  this  is  often  not  clearly  documented,  if  it exists at all. If outlier-detection exists, the attack could be executed multiple times.  In  summary,  Multi-block  MEV  attacks  are  likely  much  more  realistic  to  execute  on  FIFO  L2s  than  on Ethereum, as they are possible without needing to be a block producer. They can affect on-chain TWAPs as well as any off-chain oracles that use L2 on-chain markets as a primary price source. This must be considered when deciding which assets have an oracle that is robust enough to allow lending.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.6   Potentially Incorrect Default Decimals",
        "body": "  BaseAdapter (and therefore all oracle adapters in the version of the protocol at the time of this report) fetches decimals of the underlying base and quote assets by using the function _getDecimals():  function _getDecimals(address asset) internal view returns (uint8) {     (bool success, bytes memory data) = asset.staticcall(abi.encodeCall(IERC20.decimals, ()));     return success && data.length == 32 ? abi.decode(data, (uint8)) : 18; }  Euler - Price Oracles -   19  NoteVersion1    \fThe  function  attempts  to  fetch  the  decimals  of  a  given  token  by  calling  the  associated  decimals() function. If this call fails, it instead uses a default of 18 decimals.  This  behavior  is  meant  to  support,  among  others,  asset  types  that  are  not  smart  contracts  (e.g.,  the native  asset  address  0xEeeeeEeeeEeEeeEeEeEeeEEEeeeeEeeeeeeeEEeE).  There  is,  however,  a certain caveat that should be considered before deploying an oracle with such addresses:  Deployment  of  an  oracle  before  the  actual  ERC-20  asset  is  deployed  with  CREATE2  can  result  in wrong decimals.  Users should avoid using oracle adapters that are misconfigured in this fashion.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.7   Pyth Maximum Confidence",
        "body": "  The  PythOracle  allows  to  set  a  maxConfWidth  interval  that  defines  the  maximum  confidence  the oracle is allowed to have before reverting. Note that this interval should be initialized with a value that also  covers  possibly  wider  margins  than  can  be  usually  observed.  This  is  due  to  the  fact  that  the confidence  interval  naturally  widens  in  more  volatile  market  conditions,  which  are  exactly  the  market conditions  in  which  liquidations  should  occur  in  a  timely  manner.  If  the  threshold  prevents  swift liquidations in such a case, it could be counter-productive.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.8   RedstoneCoreOracle Hot-Swap",
        "body": "  RedstoneCoreOracle  contains  constant  signer  addresses.  Should  there  be  any  complications  with these signer addresses, the oracle has to be swapped for a new contract that contains an updated set of signers.  Since  the  contract  is  immutable  (i.e.,  not  deployed  behind  a  proxy)  it  is  important  that  any projects using it implement functionality that allows replacement of the oracle.  Euler - Price Oracles -   20  NoteVersion1NoteVersion1        \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Unkill Function Allows Claiming After Closing",
        "body": "  Function unKill(), only callable by the PlatformFactory contract owner, allows to reset isKilled to  false.  If  a  bribe  manager  calls  closeBribe()  while  the  Platform  is  killed,  and  the  platform  is  then unkilled, the bribe becomes claimable again, even though the left over funds have been transferred by closeBribe(). Users can claim their bribes and the funds will be taken from other bribes sharing the same tokens.  Risk accepted  StakeDao accepts the risk but already fixed the issue by removing the unkill function in the latest code version that was not included in the audit.  StakeDao - Bribe Platform -   9  SecurityDesignCorrectnessCriticalHighMediumRiskAcceptedRiskAcceptedRiskAcceptedRiskAcceptedLowAcknowledgedCodePartiallyCorrectedRiskAcceptedRiskAcceptedAcknowledgedAcknowledgedRiskAcceptedSecurityMediumVersion2RiskAccepted              \f5.2   Bribe Manager Can Deny Bribe by Decreasing maxRewardPerVote  The  bribe  manager  can  use  increaseBribeDuration()  to  queue  a  decrease  of maxRewardPerVote to close to 0 just before the start of a claiming period, to rug the expected bribe of users who have already voted.  Risk accepted  StakeDao states that they accept the risk.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   GaugeController Not Checkpointed Before",
        "body": " First Period Update  The GaugeController is not checkpointed in _updateRewardPerToken(). If no vote has been cast on the gauge before the first period, _getAdjustedBias() will return 0 instead of the actual value, or might  revert  if  blacklisted  users  cause  an  underflow  to  happen.  This  can  cause  the  reward  to  become unclaimable for some voters.  Risk accepted  StakeDao states:  While it would cause an issue for the first period with old vote users not being able to claim their rewards, it would be solved by the next period with the rolling over.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.4   Repeated Addresses in Bribe Blacklist Cause",
        "body": " Total Bias Under Estimation  in   the  blacklist,   Newly  created  bribes  can  have  repeated  addresses  in  the  blacklist.  If  an  address  is  present  multiple times  in _getAdjustedBias(),  and  the  function  might  return  a  value  smaller  than  the  cumulative  bias  of potential  claimers.  rewardPerToken  can  therefore  be  manipulated  upward  by  inserting  repeated addresses in the blacklist.  its  bias  will  be  deducted  multiple   total  bias   times   from   the   Risk accepted  StakeDao states that they accept the risk.  StakeDao - Bribe Platform -   10  SecurityMediumVersion1RiskAcceptedCorrectnessMediumVersion1RiskAcceptedSecurityMediumVersion1RiskAccepted                        \f5.5   Error Messages and Event Usage  1. In  PlatformFactory,  StakeDao  might  consider  adding  an  event  to  the  state  change  in  setFeeCollector.  2. In Platform, the error messages INVALID_GAUGE is not used.  Acknowldeged  StakeDao acknowledges the issue. No actions are taken.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.6   Gas Optimizations",
        "body": "  1. Double external call to vote_user_slopes in _claim(), at line 385 - 387  2. The  function  getActivePeriod  is  redundant  since  activePeriod  is  already  public  and  will  implicitly define an external getter  3. _updateRewardPerToken  calls  getCurrentPeriod  which  was  in  both  execution  flows  called  right before in the parent function  4. getPeriodsLeft and getActivePeriodPerBribe copy the entire Bribe struct from storage to memory, but only use 2 of the fields from the struct. This causes unnecessary SLOAD operations to be performed, at a cost that scales linearly with the size of the blacklist.  Code partially corrected  getCurrentPeriod() is now only called once. The two other potential optimizations were not applied.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.7   Incorrect User Bias Calculation",
        "body": "  The  internal  _getAddrBias()  function  returns  0  if  currentPeriod  +  _WEEK  >=  endLockTime. However, as long as endLockTime is bigger than currentPeriod the user has voting power. Indeed, in its time progression, a user bias will incorrectly go from slope * 3 * WEEK to slope * 2 * WEEK to 0 while skipping slope * 1 * WEEK.  Risk accepted  StakeDao is aware of the issue but decided to accept the risk and leave the code as it is.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.8   Missing Sanity Checks",
        "body": "  The following arguments are not checked or are insufficiently checked if they make sense:  StakeDao - Bribe Platform -   11  DesignLowVersion1AcknowledgedDesignLowVersion1CodePartiallyCorrectedCorrectnessLowVersion1RiskAcceptedDesignLowVersion1RiskAccepted                              \fIn  Platform.createBribe  the  variable  manager  (address  zero  check),  maxRewardPerVote (zero  check)  and  a  check  for  rewardPerPeriod  as  it  could  be  zero  after  the  division  with numberOfPeriods  In Platform.updateManager there is no sanity check for address zero  In Platform._claim() it is not checked that the bribe exists  In  PlatformFactory  setting  the  fee  collector  and  transferring  the  owner  are  not  checked  for address zero  Risk accepted  StakeDao states that they accept the risk.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.9   Naming Issues, NatSpec Missings, Incorrect",
        "body": " Comments, Typos  In Platform.sol:  1. line 104, missing @notice for Upgrade struct  2. line 126, incorrect grammar: Minimum duration a Bribe  3. line  158,  rewardPerToken  naming  is  ambiguous,  the  variable  value  is  better  understood  as  the  reward per vote not the reward per token.  4. line 254, Target bias for the gauge, incorrect NatSpec on parameter maxRewardPerVote  5. In createBribe() NatSpec, missing parameters upgradeable and manager.  6. line 503: comment says called once per Bribe, however the function is called multiple times  on the first period, but the condition is only true on first call.  7. line 640: _additionnalPeriods declaration contains a typo  8. getActivePeriod  and  getActivePeriodPerBribe  are  named  ambiguously,  they  do  very  different things but share almost the same name  Acknowldeged  StakeDao acknowledges the issue. No actions are taken.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.10   Unused Imports",
        "body": "  The contract PlatformFactory imports ERC20 but does not use it.  Acknowldeged  StakeDao acknowledges the issue. No actions are taken.  StakeDao - Bribe Platform -   12  DesignLowVersion1AcknowledgedDesignLowVersion1Acknowledged                    \f5.11   safeTransfer Functions Do Not Check Contract Existence  The safeTransfer and safeTransferFrom functions of solmate's safeTransferLib do not check that the token contract actually exists. If called with a token address that doesn't contain code, the calls will succeed  even  if  no  transfer  is  performed.  This  could  be  an  issue  when  a  token  will  be  deployed  at  a predictable address.  Risk accepted  StakeDao states that they accept the risk.  StakeDao - Bribe Platform -   13  SecurityLowVersion1RiskAccepted          \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings   Adjusted Bias Measured Possibly Too Late   -Severity Findings   Queued Upgrade Still Taken in Account After Closing Bribe   -Severity Findings   closeBribe Does Not Refund Tokens Added in Upgrade   -Severity Findings  1  1  1  0  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Adjusted Bias Measured Possibly Too Late",
        "body": "  The  amount  of  excluded  votes  belonging  to  the  users  in  the  blacklist  are  counted  by  the  internal function  _getAdjustedBias  for  the  recently  concluded  period  when  _updateBribePeriod()  is called. However, the period update only happens when users interact with the contract. Between the start of  the  new  voting  period  (timestamp  /  WEEK  *  WEEK)  and  the  time  _updateBribePeriod()  is called,  a  blacklist  user  can  cast  a  new  vote  on  the  gauge,  which  is  incorrectly  counted  by ``_getAdjustedBias() as belonging to the previous period.  rewardPerToken at period T is computed as  rewardPerToken(T) = rewardPerPeriod / (total_bias(T) - omitted_reward(T_blacklisted_last_vote))  So the periods of total_bias and omitted_reward might not match.  Since the bribe creator has full control on who to include in the blacklist and what gauge to set the bribe on, they can make rewardPerToken as high as they desire by making the denominator arbitrarily small that with  bribe.totalRewardAmount is not exceeded when distributing the reward, a dishonest bribe creator can use this bug to steal funds from other bribes.  control.  Since  _claim()   blacklisted   doesn't   check   user   they   that   a   Code corrected  A  check  has  been  added  so  that  subtracting  the  bias  of  a  blacklisted  user  is  only  performed  if  the blacklisted user has voted before the start of the period. Otherwise bias is not deducted and rewarded users get a bit less.  _lastVote = gaugeController.last_user_vote(_addressesBlacklisted[i], gauge); if (period > _lastVote) {     _bias = _getAddrBias(userSlope.slope, userSlope.end, period);     gaugeBias -= _bias; }  StakeDao - Bribe Platform -   14  CriticalCodeCorrectedHighCodeCorrectedMediumCodeCorrectedLowSecurityCriticalVersion1CodeCorrected        \fA  check  is  also  bribe.totalRewardAmount.  introduced  so   that   the  cumulative  bribe  payout  never  exceeds   the  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Queued Upgrade Still Taken in Account After",
        "body": " Closing Bribe  A queued upgrade for a bribe can still be taken in account after the manager has closed the bribe with closeBribe. If it is the case, then part of the following rewards distributed are stolen from other bribes.  Once  the  bribe  is  closed  by  the  manager,  claiming  again  will  update  the  bribe  and  reset  the endTimestamp in the future, without taking in account the totalRewardAmount - amountClaimed amount withdrew by the manager.  Using this attack to steal all the funds of the contract is possible with no risks, but would necessitate at least the same amount of tokens that the attacker wants to steal and being able to lock them for multiple weeks.  Code corrected  The upgrade is now deleted from the queue when closeBribe() is called.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   closeBribe Does Not Refund Tokens Added in",
        "body": " Upgrade  When a bribe is closed while an upgrade is queued, the unclaimed amount will be refunded to the bribe manager, but not the additional _increasedAmount added in the queued upgrade.  Code corrected  During  the  closing  of  a  bribe,  if  there  is  an  upgrade  in  the  queue,  instead  of  transferring  back total reward amount - amount claimed, the total amount after the upgrade is used.  StakeDao - Bribe Platform -   15  SecurityHighVersion1CodeCorrectedDesignMediumVersion1CodeCorrected                \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Interface Definitions",
        "body": "  To indicate a file is an interface, the naming convention is to prepend an I to the file name. The interface SmartWalletChecker and VeToken is for test purposes only. Interfaces used only for test purposes are usually separated into test folders.  The following interfaces are defined but not used:  GaugeController:  In  gauge_relative_weight_write,  get_total_weight, get_gauge_weight, add_type (only in tests), admin.  gauge_relative_weight,   add_gauge   tests),   (only   for   WEIGHT_VOTE_DELAY, gauge_relative_weight,  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   claimable() Might Return Incorrect Values",
        "body": "  Due  to  the  nature  of  view  functions  not  being  able  to  change  state,  the  claimable()  view  function doesn't  checkpoint  the  gauge  nor  it  updates  the  period,  so  the  value  it  returns  could  be  invalid.  This should be made clear in the natspec.  StakeDao - Bribe Platform -   16  NoteVersion1NoteVersion1      \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Computation of ynLSD.getTotalAssets() Is",
        "body": " Wrong  The computation of ynLSD.getTotalAssets() has two issues:  CS-YNPROTO-001  YieldNest - YieldNest Protocol -   15  CriticalHighCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedMediumCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCorrectnessHighVersion1CodeCorrected            \f1. The  index  used  in  the  inner  loop  to  get  the  asset  should  be  j  instead  of  i.  The  current implementation will either revert with an out-of-bound exception, or double count some assets, by adding the balance of token X as what should be the balance of token Y and ignore others.  2. The current implementation of LSDStakingNode does not allow it to use its own token balance, as it  will  always  pull  tokens  from  ynLSD  and  deposit  that  exact  same  amount  to  EigenLayer.  This means  that  outside  of  a  call  to  depositAssetsToEigenlayer()  the  tokens  in  each  of  the LSDStakingNodes  are  locked.  If  counting  them  to  the  totalAssets  is  correct  and  intended should be re-evaluated.  Put together, the two issues result in a wrong price calculation of the ynLSD shares.    1. The correct index j is now used in the loop.  2. The  function  LSDStakingNode.recoverAssets()  has  been  added.  The  function  sends  the token  balance  from  an  LSDStakingNode  to  ynLSD,  allowing  them  to  be  unlocked  from  the LSDStakingNodes and counted towards the totalAssets.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   First Depositor Gets More Shares",
        "body": "  In  ynETH  and  ynLSD,  the  first  depositor  sees  its  shares  minted  1:1  to  its  deposited  amount.  If exchangeAdjustmentRate  >  0,  the  following  depositors  will  have  their  shares  minted  at  a  lower ratio, basically gifting some of their deposited amount to the first depositor.  Please provide a detailed description of why would exchangeAdjustmentRate be needed and what was the intention.  CS-YNPROTO-002    The variable exchangeAdjustmentRate has been removed from the codebase.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Withdrawals That Are Not Self-Claimed Break",
        "body": " the Accounting  EigenLayer allows claiming withdrawals on behalf of arbitrary addresses. The current implementation of the  YieldNest  Protocol  does  not  take  this  into  account,  and  thus  any  withdrawn  amounts  that  are  not claimed through StakingNode.claimDelayedWithdrawals() are locked in the StakingNode.  The implementation of StakingNode can be updated, but the shares of ynETH would be underpriced until the accounting is corrected.  CS-YNPROTO-003    YieldNest - YieldNest Protocol -   16  CorrectnessHighVersion1CodeCorrectedDesignHighVersion1CodeCorrected                \fThe  function  StakingNode.claimDelayedWithdrawals  has  been  removed  from  the  codebase.  A new  function  StakingNode.processWithdrawals  has  been  added,  this  function  expects  that  the withdrawals are claimed by a third party and will simply send the balance of the StakingNode contract to the stakingNodesManager for further processing as before. This new function can only be called by the admin.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   ynLSD Is Vulnerable to Donation Attack",
        "body": "  It  is  possible  for  the  first  user  of  the  pool  to  steal  the  next  deposited  amount.  The  ynLSD  reads  the balances  of  its  supported  assets  to  compute  totalAssets  and  the  _convertToShares  function does  not  add  an  offset.  This  makes  the  contract  vulnerable  to  a  donation  attack,  where  the  first  user mints  1  share  and  front-runs  the  second  user  in  their  deposit  by  transferring  the  deposited  amount  to ynLSD in order to force a minting of 0 shares to the second user.  CS-YNPROTO-004  Example:  1. ynLSD  is  deployed  and  accepts  token  T.  The  oracle  is  assumed  to  return  the  following  price:  1 T = 1 ETH.  2. Alice  deposits  1  wei  of  T  and  receives  1  share  for  it.  Now  totalSupply  =  1  and  totalAssets = 1.  3. Bob sends a transaction to deposit a big amount X of T.  4. Alice  sees  the  transaction  in  the  mempool  and  front-runs  it  with  a  transfer  of  amount  X.  Now  totalSupply = 1 and totalAssets = 1 + X.  5. Bob's transaction gets executed and the number of shares he receives is   .  6. Alice has now 1 share valued at 1 + 2 * X, and Bob lost his deposit.  Note  that  if  exchangeAdjustmentRate  >  0,  this  attack  would  be  cheaper  to  conduct  as  the totalSupply() would be considered smaller than what it actually is. Then the amount needed to round down to zero the shares of the next deposit is also reduced.    Upon  deployment,  the  code  now  enforces  a  bootstrap  deposit  of  10  units  of  assets[0]  that  must  be worth  at  least  1  ether.  The  shares  of  this  initial  deposit  are  sent  to  a  trusted  address depositBootstrapper.  Moreover,  exchangeAdjustmentRate  has  been  removed  the codebase.  from   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   Incorrect Balance Transfers With Rebasing",
        "body": " Tokens  Rebasing  tokens  like  stETH  might  transfer  less  than  expected.  This  might  get  problematic  when  a contract  expects  to  receive  the  amount  specified  in  the  transfer.  E.g.,  in  ynLSD.deposit  the safeTransferFrom  might  transfer  one  or  two  wei  less  than  specified  in  amount.  But  before,  all calculations and the share distribution were done on the assumption that amount would be later an asset  CS-YNPROTO-005  YieldNest - YieldNest Protocol -   17  DesignHighVersion1CodeCorrectedCorrectnessMediumVersion1CodeCorrected                \fof the contract. In consequence, this might break the invariant between the amount of shares and assets such that there are shares but no assets.    ynLSD   YieldNest   of In  LSDStakingNode.depositAssetsToEigenlayer  the  issue  was  fixed  by  querying  the  pre-  and post-balance  of  the  contract  before  calling  depositIntoStrategy.  We  rate  this  issue  as  fixed  but created a note to document the behavior for ynLSD.  accepted   case   risk.   the   the   In   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.6   Partial Withdrawals Claims Will Fail",
        "body": "  CS-YNPROTO-006  function  StakingNode.claimDelayedWithdrawals  allows   the The  maxNumWithdrawals,  but  totalClaimable  will  always  be  computed  as  if  maxNumWithdrawals was set to type(uint256).max. If the caller does not want to claim all the claimable withdrawals, the condition totalClaimable > claimedAmount will be evaluated to true and the function will revert.  to  specify   the  caller     The  function  StakingNode.claimDelayedWithdrawals  has  been  removed  from  the  codebase.  A new  function  StakingNode.processWithdrawals  has  been  added,  this  function  expects  that  the withdrawals are claimed by a third party and will simply send the balance of the StakingNode contract to the stakingNodesManager for further processing as before. This new function can only be called by the admin.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.7   Processing of Withdrawals Can Be DOSed",
        "body": "  The  function  StakingNode.processWithdrawals()  expects  a  precise  amount  of  ETH  as  its balance, if it differs from this amount the call will revert. The contract assumes it can only receive ETH from  the  DelayedWithdrawalRouter,  but  it  is  possible  to  force  send  ETH  to  the  contract  with selfdestruct.  CS-YNPROTO-021    function  StakingNode.processWithdrawals()  has  been  updated  such   The  that  only expectedETHBalance is processed. The difference between the balance and expectedETHBalance can be processed in another transaction.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.8   Discrepancy in the Value Check for maxAge",
        "body": "  CS-YNPROTO-007  YieldNest - YieldNest Protocol -   18  DesignMediumVersion1CodeCorrectedSecurityLowVersion2CodeCorrectedDesignLowVersion1CodeCorrected                        \fIn YieldNestOracle, the value of maxAge is required to be > 0 in setAssetPriceFeed, but no such check is done in the constructor.    The value of maxAge is now checked during construction of YieldNestOracle and redundancies have been resolved by reusing the code that was present in setAssetPriceFeed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.9   Ignored Return Values",
        "body": "  The following calls ignore the returned value:   LSDStakingNode.depositAssetsToEigenlayer  does  not  check   the   return  value  by  asset.approve   ynLSD.retrieveAsset does not check the return value from IERC20(asset).transfer  CS-YNPROTO-008    OpenZeppelin   The  LSDStakingNode.depositAssetsToEigenlayer  ynLSD.retrieveAsset (safeTransfer).  SafeERC20   library   is   used   for   ERC20   (forceApprove)   interactions  and   in in  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.10   Initializer Not Disabled",
        "body": "  Proxy  implementation  contracts  inheriting  OpenZeppelin's  Initializable  contract  should  call _disableInitializers  in  their  constructor  to  prevent  initialization  and  re-initialization  of  the implementation contract.  CS-YNPROTO-009    All contracts inheriting OpenZeppelin's Initializable contract now call _disableInitializers in their constructor.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.11   Oracle Price Sanity Check",
        "body": "  In  YieldNestOracle.getLatestPrice  the  price  returned  by  the  oracle  is  not  further  checked  if  it might be, e.g., zero.  CS-YNPROTO-010    YieldNest - YieldNest Protocol -   19  DesignLowVersion1CodeCorrectedSecurityLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \fThe function has been updated such that the call reverts if price <= 0.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.12   Redundant Functionality",
        "body": "  The  functions  ynBase.pauseWhiteList  and  ynBase.isAddressWhitelisted  have  the  same logic.  CS-YNPROTO-011    The function isAddressWhitelisted was removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.13   Uninitialized Reentrancy Guard",
        "body": "  The  StakingNode  contract  __ReentrancyGuard_init() in initialize.  inherits  ReentrancyGuardUpgradeable.  But  does  not  call  CS-YNPROTO-012    The initialize function has been updated to call __ReentrancyGuard_init().  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.14   Unused Code",
        "body": "  CS-YNPROTO-013  Some parts of the codebase are never used. To ease the comprehension of the code, it is good practice to keep it in its minimal form. Here is a non-exhaustive list of unused code:  1. the   errors   MinimumStakeBoundNotSatisfied,   StakeBelowMinimumynETHAmount,  DepositAllocationUnbalanced in StakingNodesManager  2. the errors MinimumStakeBoundNotSatisfied, StakeBelowMinimumynETHAmount in ynETH  3. the  errors  error  InvalidConfiguration,  error  NotOracle  and  error  Paused  in  RewardsDistributor  4. the errors StrategyIndexMismatch and WithdrawalAmountTooLow in StakingNode  5. the   storage   variable  pendingWithdrawnValidatorPrincipal   and   the   constant  GWEI_TO_WEI in StakingNode  6. the storage variable allocatedETHForDeposits in ynETH  7. the storage variables maxBatchDepositSize, stakeAmount in StakingNodesManager  8. the constant BASIS_POINTS_DENOMINATOR in ynBase  9. the  event  FeeReceiverSet  in  the  interface  definition  of  RewardsDistributorEvents  in  RewardsDistributor.sol  YieldNest - YieldNest Protocol -   20  DesignLowVersion1CodeCorrectedSecurityLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \f10. the  events  WithdrawalStarted  and  RewardsProcessed  in  the  interface  definition  of  StakingNodeEvents in StakingNode.sol  11. the interfaces IOracle and IEigenLayerBeaconOracle  :  1. the error ValueOutOfBounds in ynETH    All the listed issues have been resolved.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.15   Complete Events",
        "body": "  We assume YieldNest checked when to emit events. Without clear specification on when events shall be emitted,  we  cannot  verify  if  the  events  are  emitted  correctly.  We  encourage  YieldNest  to  review  if  all relevant  state  changes  emit  events  as  intended  (e.g.,  RewardsDistributor.processRewards, ynBase._updatePauseWhitelist).  The  above  also  applies  to  indexing  events.  Most  events  index  relevant  fields  but  some  don't.  E.g., RewardsDistributorEvents.FeeReceiverSet.  CS-YNPROTO-014  Core corrected:  Events have been added throughout the codebase where important state changes are made.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.16   Incorrect Natspec",
        "body": "  The  natspec  of  StakingNodesManager.validateDepositDataAllocation  claims  the  function does:  /** * @notice Validates the allocation of deposit data across nodes to ensure the distribution does not increase the disparity in balances. * @dev This function checks if the proposed allocation of deposits (represented by `_depositData`) across the nodes would lead to a more * equitable distribution of validator stakes. It calculates the current and new average balances of nodes, and ensures that for each node, * the absolute difference between its balance and the average balance does not increase as a result of the new deposits * @param newValidators An array of `ValidatorData` structures representing the validator stakes to be allocated across the nodes. */  CS-YNPROTO-017  The implementation deviates from the description. The only check done is nodeId >= nodes.length for each node in newValidators.    The function name and natspec have been changed to reflect the implementation.  YieldNest - YieldNest Protocol -   21  Version2InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected              \f7.17   Missing Natspec Param Definition  The  natspec  definition  for  the  second  parameter  withdrawnValidatorPrincipal  of  the  function StakingNode.claimDelayedWithdrawals is missing.  CS-YNPROTO-018    The function StakingNode.claimDelayedWithdrawals was removed from the codebase.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.18   Overcomplicated Expression",
        "body": "  Expressions like assetDecimals < 18 || assetDecimals > 18 in ynLSD.convertToETH can be replaced by simpler variants, they add unnecessary complexity and should be avoided.  CS-YNPROTO-019    The expression has been simplified to assetDecimals != 18.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.19   Remaining Todos",
        "body": "  In  StakingNodesManager.isStakingNodesAdmin  we  // TODO: define specific admin.  CS-YNPROTO-020  found  a   left  over   to  do  comment    The todo was removed from the code.  YieldNest - YieldNest Protocol -   22  InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected                \f8   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Gas Optimizations",
        "body": "  We  highlight  gas  inefficiencies  when  we  see  them  but  highly  encourage  YieldNest  to  check  for  more inefficiencies as we did find quite a lot and expect more to be present. The following list are examples we found:  1. In the function LSDStakingNode.depositAssetsToEigenlayer, asset can be used in place  of assets[i].  CS-YNPROTO-015  2. In   the   function   LSDStakingNode.depositAssetsToEigenlayer,   the   address(strategy)  ==  address(0)  ynLSD.retrieveAsset().  is   redundant  with   the  one   3. The substration in the function ynETH.withdrawETH() can be unchecked.  implemented   check in  4. In the function ynETH.depositETH(), msg.value can be used in place of assets, as its gas  cost is only 2.  5. In   the   functions  StakingNodesManager.initializeStakingNode(),  call  node.getInitializedVersion() but the returned value is never used.  ynLSD.initializeLSDStakingNode()  a   is   made   and to  6. When   the   and StakingNodesManager.initializeStakingNode() are used, nodes.length is read twice, passing the nodeId as a function argument can save an SLOAD.  ynLSD.initializeLSDStakingNode()   functions   7. In   the   call function  ynETH.processWithdrawnETH()  if withdrawnValidatorPrincipal > 0, if partial withdrawals are expected to be more common than full withdrawals.  StakingNodesManager.processWithdrawnETH(),   done   only   can   the   be   8. In  the  function  RewardsReceiver.initialize(),  the  admin  of  the  WITHDRAWER  is  explicitly  set to be DEFAULT_ADMIN, but this is the case by default.  9. In  ynLSD.createLSDStakingNode  the  state  variable  nodes.length  is  read  multiple  times  including in initializeLSDStakingNode where it could be passed as argument.  10. StakingNodesManager.validateDepositDataAllocation   the   state   variable  nodes.length is read multiple times and could be cached.  11. When looping over assets, the asset array's length should be cached. When using the storage  variable as bounded in i < assets.length it will be read multiple times.  1. In  ynLSD.getTotalAssets()  the  state  variable  nodes.length  is  read  multiple  times  in  the  loop and could be cached to save SLOAD.  Code partially corrected:  YieldNest - YieldNest Protocol -   23  InformationalVersion1CodePartiallyCorrectedVersion3    \f1. Fixed.  2. Fixed.  3. No change.  4. The  cached  value  in  now  used  everywhere.  It  is  now  consistent  within  the  function,  but  not  gas-optimal.  5. Fixed. The value is used in the emitted event.  6. Fixed.  7. No change.  8. Fixed.  9. Fixed.  10. Fixed. Function name updated to StakingNodesManager.validateNodes.  11. Fixed.  1. Fixed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Incorrect Comments",
        "body": "  1. In  ynLSD._convertToShares  the  comment  was  copied  from  the  same  function  that  exists  in  ynETH and, hence, mentions deltaynETH instead of deltaynLSD.  CS-YNPROTO-016  2. In   ynLSD   states Retrieves a specified amount of an asset from the staking node. But actually, transfers the asset to the staking node (as @dev correctly describes).  retrieveAsset   explanation   incorrect.   the   of   is   It   Code partially corrected:  1. The comment has been corrected.  2. No change  YieldNest - YieldNest Protocol -   24  Version3InformationalVersion1CodePartiallyCorrected      \f9   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "9.1   Slightly Deviating Balance to Share in Case of",
        "body": " Rebasing Tokens  Rebasing  tokens  like  stETH  might  transfer  less  than  expected.  This  might  get  problematic  when  a contract  expects  to  receive  the  amount  specified  in  the  transfer.  E.g.,  in  ynLSD.deposit  the safeTransferFrom  might  transfer  one  or  two  wei  less  than  specified  in  amount.  But  before,  all calculations  and  the  share  distribution  were  done  on  the  assumptions  that  amount  would  be  later  an asset of the contract. In consequence, this might break the invariant between the amount of shares and assets such that there are shares but no assets.  The  issue  was  rated  more  severe  in  Incorrect  balance  transfers  with  rebasing  tokens  and  fixed  for LSDStakingNode.depositAssetsToEigenlayer.  However,  in ynLSD.deposit but not considered severe enough to cause further issues.  is  still  present   the  behavior   YieldNest - YieldNest Protocol -   25  NoteVersion1  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Event Parameters Not Indexed",
        "body": "  The event ReferredBalanceIncreased emits the address of partnerId, vault and depositer. All three information might be relevant to later query specific deposits. Hence, it might be useful to index these parameters.    The updated event now indexes the parameters: partnerId, vault and depositer.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Missing Code Comments and Function",
        "body": " Descriptions  Even though the code base is simple and well structured, code comments as well as function description with parameter descriptions are part of good coding practice to help understanding the code. The current implementation lacks documentation and code comments.    The updated code contains specifications that describe the functions and their parameters.  Yearn Finance - Partner Tracker -   9  CriticalHighMediumLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                  \f6.3   Missing Return Values  Both  external  functions  deposit  declare  a  return  value  of  type  uint256,  but  the  return  statement  is missing.    The  internal  function  _internalDeposit  is  modified  to  return  receivedShares,  which  is  then returned by both external functions deposit.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Unused Constant registry",
        "body": "  The constant registry is defined but not used in the current code base.    The unused constant has been removed from the updated code.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Unused Imports",
        "body": "  The Math and Address libraries and the registry interface are imported but not used.  import \"@openzeppelin/contracts/math/Math.sol\"; import \"@openzeppelin/contracts/utils/Address.sol\"; import \"../interfaces/IYearnRegistry.sol\";    The unused imports have been removed from the updated code.  Yearn Finance - Partner Tracker -   10  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                      \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Contract Tracks Also Malicious Vaults and",
        "body": " Tokens  The input arguments for the vault to be deposited in and the token are provided by the user. Both can be malicious  contracts.  We  could  not  see  a  way  to  exploit  the  contract,  but  the  mapping  will  record everything  including  the  invalid/malicious  vaults.  Hence,  when  reading  the  mapping  the  correct  vaults needs to be carefully selected and invalid records neglected.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Outdated Compiler Version",
        "body": "  The compiler version is outdated (https://swcregistry.io/docs/SWC-102) and implicitly fixed in the brownie config file to version: 0.6.12. The contract has a floating pragma for the compiler version, although practically  there  is  no  newer  version  without  breaking  changes  (https://swcregistry.io/docs/SWC-103). This version has the following known bugs: https://docs.soliditylang.org/en/v0.6.12/bugs.html  This is just a note as we do not see any severe issue using this compiler with the current code.  Yearn Finance - Partner Tracker -   11  NoteVersion1NoteVersion1      \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Reentrancy to Circumvent Liquidation",
        "body": " Protection  When  a  borrow  is  no  longer  sufficiently  collateralized,  it  can  be  liquidated.  During  a  liquidation,  the function liquidateBorrowAllowed of the Comptroller is called to determine if the position can be liquidated.  This  check  basically  evaluates  whether  the  values  of  all  held  cTokens  times  their collateralRatio exceed the value of all borrowed assets. The function liquidateBorrowAllowed also determines whether the repaid amount does not exceed the closeFactor.  However, the following reentrancy attack is possible to circumvent the liquidation protection. We assume that the victim account V has two borrowed tokens A and B. Also, V has collateral deposits C and D and has just become liquidatable, due to a tiny shortfall. We call the respective cTokens cA, cB, cC, and cD. Lastly, A is contract with a callback, e.g. ERC777.  1. The  attacker  calls  liquidateBorrow  on  cA  with  collateral  cC.  liquidateBorrowAllowed  is evaluated by the comptroller and determines a small shortfall. Hence, the liquidation is allowed.  2. The token transferFrom of A is triggered and hence, the callback to the attacker is executed.  Compound - cToken -   10  SecurityDesignCorrectnessCriticalHighMediumAcknowledgedLowAcknowledgedAcknowledgedAcknowledgedRiskAcceptedAcknowledgedAcknowledgedSecurityMediumVersion1Acknowledged           \f1. As  part  of  the  callback,  the  attacker  calls  liquidateBorrow  on  cB  with  collateral  cD. liquidateBorrowAllowed is evaluated by the comptroller and determines a small shortfall (as no state changes have yet been performed). Hence, the liquidation is allowed.  2. The biggest possible amount of B tokens is repaid and cD tokens are received as reward. The  position of V is now safe again.  3. Despite the position being safe, the original liquidation continues and the biggest possible amount  of A tokens is liquidated to received cC as reward.  Please note that the attack also works against a single collateral, so if C == D. It also works with more than two borrowed tokens. In such cases more \"parallel\" liquidations are possible.  Acknowledged:  Compound has acknowledged the issue.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Deprecation Insufficiently Documented",
        "body": "  The deprecation of a cToken and its effects are insufficiently documented. The documentation says:  A user who has negative account liquidity is subject to liquidation  However,  liquidation  can  also  occur  once  a  cToken  has  been  deprecated.  As  users  aim  to  avoid liquidation, they should be made aware of this.  Acknowledged:  The Compound team has acknowledged this issue.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   Extra Encoding and Decoding in",
        "body": " CErc20Delegator  The  CErc20Delegator  contract  will  be  used  as  a  proxy.  Hence,  it  generally  forwards  the  calls. However, it contains two ways of forwarding:  1. The generic forwarder using the fallback function  2. Explicit forwarders such as:  function borrow(uint borrowAmount) override external returns (uint) {     bytes memory data = delegateToImplementation(abi.encodeWithSignature(\"borrow(uint256)\", borrowAmount));     return abi.decode(data, (uint)); }  The explicit forwarders are less gas efficient as they perform extra decoding and encoding for inputs as well as decoding and encoding for outputs, which is not performed by the generic forwarder.  Acknowledged:  Compound - cToken -   11  CorrectnessLowVersion2AcknowledgedDesignLowVersion1Acknowledged                \fCompound  acknowledges  the  issue  but  claims  that  the  gas  savings  are  small  enough  to  not  be  worth fixing.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.4   Extra Storage Operations",
        "body": "  Inside the function _acceptAdmin there is the following code:  // Store admin with value pendingAdmin admin = pendingAdmin;  // Clear the pending value pendingAdmin = address(0);  emit NewAdmin(oldAdmin, admin); emit NewPendingAdmin(oldPendingAdmin, pendingAdmin);  To emit the events, admin and pendingAdmin will be queried from storage which is unnecessary here. Hence, there is a certain (even though small due to EIP-2929) gas overhead.  Acknowledged:  Compound  acknowledges  the  small  gas  savings  but  deems  the  readability  of  the  code  to  be  more important.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.5   No Dynamic Bounds on Liquidation Incentive",
        "body": "  It  is  important  that  the  liquidation  incentive  is  sufficiently  high  in  order  to  provide  a  safe  protocol. However, the product of liquidation incentive and collateral factor also should not exceed 1. Otherwise, the protocol is sure to lose funds on liquidations.  Risk accepted:  Compound accepts the risk of possibly misconfiguring a protocol.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.6   Reentrancy by Admin",
        "body": "  In  the  case  of  Compound,  the  admin  role  of  the  cTokens  is  held  by  the  governance.  Hence, admin-based  attacks  are  especially  unlikely.  However,  in  principle  the  admin  could  perform  certain reentrancy-based  or _setInterestModel. These functions do not have a reentrancy guard.  like  _setComptroller   functions   attacks   special   admin   using   In a general case, an admin could switch out the comptroller for the initial checks of a liquidation and then call _setComptroller while receiving a token-based callback. The corrected comptroller address would  satisfy  the  further  checks  during  seizing.  This  way  the  admin  of  one  market  could  attack  other markets.  Compound - cToken -   12  DesignLowVersion1AcknowledgedDesignLowVersion1RiskAcceptedSecurityLowVersion1Acknowledged                        \fAcknowledged:  This issue has been acknowledged.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.7   Unnecessary Memory Copies",
        "body": "  In  some  parts  of  the  code  there  are  unnecessary  copy  operations  to  and  from  memory.  Consider  the following example:  function balanceOfUnderlying(address owner) override external returns (uint) {     Exp memory exchangeRate = Exp({mantissa: exchangeRateCurrent()});     return mul_ScalarTruncate(exchangeRate, accountTokens[owner]); }  The  exchangeRate  is  stored  in  memory  and  then  directly  afterwards  copied  back  onto  the  stack. However, as the gas overhead of memory operations is tiny, this is minor.  Acknowledged:  Compound  has  acknowledged  the  issue  but  decided  not  to  fix  it  at  this  time,  as  it  is  only  a  small  gas saving.  Compound - cToken -   13  DesignLowVersion1Acknowledged          \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings   Anyone Can Disable TUSD Market   -Severity Findings  -Severity Findings  Incorrect Exchange Rates Due to Incorrect Accounting   Incorrect Return Value for mintFresh   -Severity Findings   Liquidation Incentive Has Imprecise Documentation   Ignored Return Values    Special Case Not Clearly Specified    Unclear Specification    Unnecessary Overflow Checks   1  0  2  5  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Anyone Can Disable TUSD Market",
        "body": "  The TrueUSD (TUSD) token has two addresses through which it can be called. Calling the transfer function on either address affects the balance of both addresses. Given that there is a Compound market for TUSD, it is important to note that anyone can disable this market by calling:  function sweepToken(EIP20NonStandardInterface token) override external {     require(address(token) != underlying, \"CErc20::sweepToken: can not sweep underlying token\");     uint256 balance = token.balanceOf(address(this));     token.transfer(admin, balance); }  Usually, this function is meant to collect stray tokens and send them back to the admin. However, in this case  anyone  can  call  this  with  the  second  address  of  TUSD  and  thereby  transfer  all  TUSD  inside  the market to the administrator.  The funds are not lost, as they reside with the administrator, but no more borrows or redemptions will be possible. However, this causes a sudden change in the exchange rate and the interest rate of the token, which are both calculated using the current balance of the contract.  The dropped exchange rate allows different attacks. Among other things, it allows:  liquidation of users who used cTUSD as collateral (if the collateral factor is bigger than 0)   borrowing TUSD, then executing the attack and paying back less TUSD   executing the attack, minting cTUSD, waiting for the exchange rate to be restored and redeeming  cTUSD for more TUSD than were used for minting  Compound - cToken -   14  CriticalCodeCorrectedHighMediumSpeci\ufb01cationChangedSpeci\ufb01cationChangedLowSpeci\ufb01cationChangedCodeCorrectedSpeci\ufb01cationChangedSpeci\ufb01cationChangedCodeCorrectedSecurityCriticalVersion1CodeCorrected            \f  The sweepToken function can now only be called by the admin.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Incorrect Exchange Rates Due to Incorrect",
        "body": " Accounting  Due  to  the  design  of  the  cToken  non-liquidatable  borrows  can  exist.  These  borrows  are  incorrectly accounted  leading  to  overly  high  exchange  rates,  which  can  have  different  consequences.  Please consider  the  following  example.  For  simplicity  of  the  calculation,  we  assume  rates  and  the  liquidation incentive to be zero. We also assume that the exchange rate is 1 cETH = 1 ETH.  1. User A deposits 1 ETH, to obtain 1 cETH. At this time 1 ETH is worth 2000 DAI.  2. User A borrows 1000 DAI.  3. The price of ETH drops a lot until it is 500 DAI. During this time user A is not liquidated (e.g., due to  high gas prices).  4. Now user B liquidates the DAI-borrow of user A.   User B pays 500 DAI.   The amount of seized collateral is computed as 1 cETH.   1 cETH is seized from user A.  5. As a result, user A now has the following status:   0 balance in cETH   500 borrowed DAI  6. Thereby,  user  A  has  a  non-liquidatable  borrow  as  any  liquidation  fails  in  the  following  line  of  seizeInternal due to an underflow:  accountTokens[borrower] = accountTokens[borrower] - seizeTokens;  7. This results in an incorrect exchange rate for cDAI. The 500 DAI borrowed by user A will never be repaid. However, they are still part of the totalBorrows of the accounting within cDAI. Hence, the calculated exchange rate is too large.  The  incorrect  exchange  rate  can  have  different  consequences.  One  example  (assuming  no  reserves) would be:   All borrowers (except for A) are repaying their loans.   All suppliers try to redeem their deposits. However, each supplier is receiving too much DAI for their  cDAI as the exchange rate is too large.  In the end the last supplier finds that there are 0 DAI inside the contract and still 500 DAI borrowed. As the last borrow is non-liquidatable and will never be paid back, the last supplier cannot redeem their cDAI.  Compound - cToken -   15  DesignMediumVersion2Speci\ufb01cationChanged         \fSpecification changed:  The Compound team will update the documentation to correctly reflect this behaviour.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Incorrect Return Value for mintFresh",
        "body": "  The  mintFresh  function  that  is  internally  responsible  of  minting  new  cTokens,  has  the  following specification regarding its return value:  * @return (uint) the actual mint amount.  At the end of the function, it says:  return actualMintAmount;  However, the actualMintAmount variable contains the amount of underlying tokens used for minting and not the amount of minted cTokens.  Specification changed:  The specification was changed to match the implementation.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Liquidation Incentive Has Imprecise",
        "body": " Documentation  The documentation for the liquidation incentive says:  The  additional  collateral  given  to  liquidators  as  an  incentive  to  perform  liquidation  of  underwater accounts.  For  example,  if  the  liquidation  incentive  is  1.1,  liquidators  receive  an  extra  10%  of  the borrowers collateral for every unit they close.  this   However,  function liquidateCalculateSeizeTokens will calculate this amount with the liquidation incentive included, but in the function seizeInternal the protocol's share is deducted:  not  match   functionality   code.   does   The   the   the   of   uint protocolSeizeTokens = mul_(seizeTokens, Exp({mantissa: protocolSeizeShareMantissa})); uint liquidatorSeizeTokens = seizeTokens - protocolSeizeTokens;  Hence, liquidators receive less than 10% extra.  Specification changed:  The Compound team will update the protocol documentation to describe this behaviour more precisely.  Compound - cToken -   16  CorrectnessMediumVersion1Speci\ufb01cationChangedCorrectnessLowVersion2Speci\ufb01cationChanged                  \f6.5   Ignored Return Values  The return values of \"Internal\" functions such as repayBorrowInternal or mintInternal are being ignored  in  all  of  their  calls.  Hence,  it  could  be  checked  if  a  return  value  is  really  necessary  for  these functions and if so, whether it should be checked by the callers.    The unused return values of the relevant functions were removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Special Case Not Clearly Specified",
        "body": "  functions   repayBorrowBehalf, The  repayBorrowBehalfInternal,  repayBorrowFresh,  and  repayBorrowInternal  generally specify the input variable as:  repayBorrow,   concerning   repaying,   such   as   * @param repayAmount The amount to repay  However, this variable has a special meaning if it is -1 as then, the full amount is repaid. This should be documented more clearly in the code.  Specification changed:  The specification was changed for the relevant functions.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Unclear Specification",
        "body": "  The transferTokens function is specified as follows:  /* ...  * @return Whether or not the transfer succeeded  */ function transferTokens(address spender, address src, address dst, uint tokens) internal returns (uint) {  However,  as  the  return  value  is  not  boolean  but  uint  it  would  be  beneficial  to  explicitly  state  which values indicate success and failure.  The exitMarket function in the comptroller has a similar specification:  /* ...  * @return Whether or not the account successfully exited the market  */ function exitMarket(address cTokenAddress) override external returns (uint) {  Again, it would be good to specify which return values indicate success and failure.  Compound - cToken -   17  DesignLowVersion1CodeCorrectedCorrectnessLowVersion1Speci\ufb01cationChangedCorrectnessLowVersion1Speci\ufb01cationChanged                      \fSpecification changed:  The specification was changed to indicate what happens in case of success and failure.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   Unnecessary Overflow Checks",
        "body": "  In the doTransferIn function of the CErc20 contract, the new balance is checked to be larger than the balance before the transfer.  require(balanceAfter >= balanceBefore, \"TOKEN_TRANSFER_IN_OVERF|l|\"); return balanceAfter - balanceBefore;   // underflow already checked above, just subtract  However, this check is now unnecessary because of the updated compiler version, which automatically checks for under- / overflows. Therefore, gas can be saved by omitting this check.  Additionally, in the _addReservesFresh function, there is still an overflow check.  totalReservesNew = totalReserves + actualAddAmount;  /* Revert on overflow */ require(totalReservesNew >= totalReserves, \"add reserves unexpected overflow\");  Because actualAddAmount is an unsigned integer, this condition can never occur, as any overflow will be caught by the automatic check by the solidity compiler.  Similarly, the _reduceReservesFresh function has an unnecessary check, since the subtraction would revert in case of an underflow.  totalReservesNew = totalReserves - reduceAmount; // We checked reduceAmount <= totalReserves above, so this should never revert. require(totalReservesNew <= totalReserves, \"reduce reserves unexpected underflow\");    The unnecessary checks have been removed.  Compound - cToken -   18  DesignLowVersion1CodeCorrected        \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics serve to clarify or support the report.  As  the  scope  of  this  report  was  limited  to  the  cToken,  we  also  list  issues  outside  of  the  scope  in  this section.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Compatibility With Different Tokens",
        "body": "  In the future, new tokens might be added. When markets for those are created, issues can appear. In this non-exhaustive list, we highlight some of those issues:   On-demand Balance Modification + Callback:  Different  token  types  (inflationary,  deflationary,  or  rebasing)  can  have  balances  which  change without a Transfer occurring. For some of these tokens there is a permissionless trigger to update everyone's balances. Tokens with such a permissionless trigger and a callback on transfer should not be added for the following reason. While receiving the callback of mint() the depositor could trigger  the  balance  adjustment  and  thereby  increase  the  ERC20  balance  of  the  market  without making a deposit.   Blacklist, Freezable, Seizable:  Tokens where some addresses can be blacklisted, certain funds can be frozen or some funds can be seized/burnt, need to be added with great consideration. A blacklisted market would stop working properly.  A  (partially)  frozen  market  would  not  function  correctly  (as  the  underlying  fungibility assumption is violated). Finally, seizing could lead to sudden drops in the exchange rate.   Transfer Fees:  In  principle  the  protocol  supports  tokens  with  transfer  fees.  However,  if  a  user  borrows  a  certain amount  of  tokens  with  transfer  fees,  it  will  be  almost  impossible  to  completely  repay  that  borrow. This is because the existing feature of providing -1 as the amount wouldn't work due to the transfer fees. Hence, a small borrow residue will most likely remain.  When  borrowing  tokens  with  transfer  fees,  the  requested  amount  will  not  be  received.  Similarly, when reducing the reserve of a token with transfer fees, there will be unexpected losses.   Tokens with potential for sudden increase in value:  If  a  token  whose  value  can  suddenly  increase  by  a  significant  amount,  can  be  borrowed,  then attacks  due  to  extremely  bad  positions  are  possible.  Such  tokens  include  UniswapV2  and  Curve pool  tokens,  but  also  DPI  tokens.  Extreme  care  has  to  be  taken,  when  adding  such  tokens  to  the protocol as they will most likely lead to an attack.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Hindering Liquidation",
        "body": "  Borrowers  can  do  different  things  to  make  their  own  liquidation  less  likely.  During  a  liquidation  the liquidator  receives  a  liquidation  reward,  determined  by  the  liquidationIncentiveMantissa variable. If X is the amount of borrowed tokens, the liquidator receives at most:  X * (liquidationIncentiveMantissa - 1) * closeFactorMantissa / 10**36  Example: If the liquidation incentive is 108% and the close factor is 50%, the maximum liquidation reward is 4% * X.  Compound - cToken -   19  NoteVersion1NoteVersion1      \fThe  liquidator  needs  to  pay  the  transaction  costs  which  will  vary  over  time.  At  the  time  of  writing  the transaction  costs  for  a  liquidation  are  around  80  USD.  Hence,  the  liquidation  incentive  only  provides  a sufficient incentive for borrows above 2,000 USD.  As this computation is performed per borrowed token a user might decide to borrow 2,000 USD worth of tokens  from  ten  different  tokens,  hence  borrowing  20,000  USD  but  making  liquidation  by  a  simple liquidator unlikely.  Note that due to partial liquidation, caused by the close factor, such small borrows can also be generated over time.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Impossible Event Orders",
        "body": "  In  case  that  one  of  the  underlying  tokens  has  a  callback  on  token  transfer,  the  doTransferIn  and doTransferOut  functions  can  lead  to  reentrancies.  This  can  lead  to  event  orders  that  would  not  be possible without reentrancies.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   Incomplete Compatibility Check",
        "body": "  When adding a new market, the Comptroller checks compatibility using:  cToken.isCToken(); // Sanity check to make sure its really a CToken  However, as isCToken returns true and to be consistent with the isComptroller checks, the return value should also be checked.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   Misplaced Comment",
        "body": "  The following comment can be found inside the seizeInternal function:  /* * We calculate the new borrower and liquidator token balances, failing on underflow/overflow: *  borrowerTokensNew = accountTokens[borrower] - seizeTokens *  liquidatorTokensNew = accountTokens[liquidator] + seizeTokens */  However,  this  comment  does  not  refer  to  the  code  where  it  is  located  but  to  the  code  further  down. Hence, it could be moved closer to the corresponding code.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.6   Reentrancy Checks Are Necessary",
        "body": "  of   part   Forum As  (https://www.comp.xyz/t/punitive-accounting-for-borrow-and-redeem/2247), it was proposed that punitive accounting may allow to remove the reentrancy checks.  the  Compound  Community   published   recently   post   on   a   Compound - cToken -   20  NoteVersion1NoteVersion1NoteVersion1NoteVersion1                \fWith  the  proposed  punitive  accounting  changes,  it  may  now  instead  be  possible  to  remove  the reentrancy  checks  altogether.  To  do  that,  the  community  should  prove  to  itself  that  the  protocol  is now safe to reentrancy attacks altogether. That can be done as an independent later step, after more thorough evaluation.  However, this would open up some reentrancy attacks. For example, the following sequence of actions could drain a CToken contract, assuming a token with a callback on transferFrom:  1. Provide collateral of some sort, then borrow some funds from the CToken.  2. Call  repayBorrow  to  pay  back  your  borrowed  funds.  Your  current  borrow  balance  is  stored  in  accountBorrowsPrev.  3. doTransferIn is called, which triggers the callback of transferFrom. In this callback function,  borrow more funds from the contract. This updates your borrow balance.  4. When   set  accountBorrowsPrev - actualRepayAmount, overwriting the updated borrow balance.  doTransferIn   balance   returns,   borrow   your   is   to  Therefore,  omitting  the  reentrancy  checks  could  lead  to  vulnerabilities  for  tokens  with  callbacks  on transferFrom.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.7   Underlying as Immutable Variable",
        "body": "  The CErc20 contracts have the following storage variable:  address public underlying;  As  it  is  not  expected  to  change,  it  could  become  an  immutable  variable  to  save  gas  costs  during execution.  Note  that  while  this  change  would  reduce  the  execution  costs  of  nearly  every  CErc20 invocation  by  roughly  2200  gas,  it  also  implies  that  the  storage  layout  would  be  modified  which  would require  close  inspection.  Furthermore,  it  would  mean  that  not  all  CErc20  proxies  could  reference  the same implementation contract, as the implementation contracts would contain the specific underlying address.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.8   Unused Comptroller Functions",
        "body": "  The  following  Comptroller  functions  are  no  longer  being  used  by  the  cTokens  and  could  hence  be removed to reduce the code size and thereby the deployment costs:   mintVerify   borrowVerify   repayBorrowVerify   liquidateBorrowVerify   seizeVerify   transferVerify  Compound - cToken -   21  NoteVersion1NoteVersion1          \f7.9   Vote Delegation  Token holders who deposit into a CToken have to be aware that, in the case of governance tokens, they are  also  giving  away  their  voting  rights.  On  tokens  such  as  COMP  or  UNI,  the  governance  can  pick  a delegatee for the voting power which is accumulated inside the CToken contract.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.10   closeFactor Bounds Not Checked",
        "body": "  The Comptroller contract has a minimum and maximum bound for the value of closeFactor.  // closeFactorMantissa must be strictly greater than this value uint internal constant closeFactorMinMantissa = 0.05e18; // 0.05  // closeFactorMantissa must not exceed this value uint internal constant closeFactorMaxMantissa = 0.9e18; // 0.9  However, these bounds are never used. In fact, the closeFactor can be set to anything, as its value is not checked at all before setting it.  /**   * @notice Sets the closeFactor used when liquidating borrows   * @dev Admin function to set closeFactor   * @param newCloseFactorMantissa New close factor, scaled by 1e18   * @return uint 0=success, otherwise a failure   */ function _setCloseFactor(uint newCloseFactorMantissa) external returns (uint) {     // Check caller is admin     require(msg.sender == admin, \"only admin can set close factor\");      uint oldCloseFactorMantissa = closeFactorMantissa;     closeFactorMantissa = newCloseFactorMantissa;     emit NewCloseFactor(oldCloseFactorMantissa, closeFactorMantissa);      return uint(Error.NO_ERROR); }  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.11   maxAssets Not Enforced",
        "body": "  According to the documentation, a user should only be able to participate in a limited number of markets, namely no more than maxAssets.  /**  * @notice Max number of assets a single account can participate in (borrow or use as collateral)  */ uint public maxAssets;  Compound - cToken -   22  NoteVersion1NoteVersion1NoteVersion1          \fHowever,  this  is  not  enforced.  In  fact,  the  value  of  maxAssets  is  never  set  or  used.  In  particular,  the function  addToMarketInternal  in  the  Comptroller  blindly  adds  a  user  to  a  new  market  without checking that the user does not exceed this bound.  /**  * @notice Add the market to the borrower's \"assets in\" for liquidity calculations  * @param cToken The market to enter  * @param borrower The address of the account to modify  * @return Success indicator for whether the market was entered  */ function addToMarketInternal(CToken cToken, address borrower) internal returns (Error) {     Market storage marketToJoin = markets[address(cToken)];      if (!marketToJoin.isListed) {         // market is not listed, cannot join         return Error.MARKET_NOT_LISTED;     }      if (marketToJoin.accountMembership[borrower] == true) {         // already joined         return Error.NO_ERROR;     }      // survived the gauntlet, add to list     // NOTE: we store these somewhat redundantly as a significant optimization     //  this avoids having to iterate through the list for the most common use cases     //  that is, only when we need to perform liquidity checks     //  and not whenever we want to check if an account is in a particular market     marketToJoin.accountMembership[borrower] = true;     accountAssets[borrower].push(cToken);      emit MarketEntered(cToken, borrower);      return Error.NO_ERROR; }  Compound - cToken -   23  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Missing Events",
        "body": "  The following methods of the PegKeeperRegulator do not emit any event.  CS-CRVPKV2-003  1. set_price_deviation()  2. set_debt_parameters()  3. set_killed()  4. set_emergency_admin()  Moreover, setting a new admin, price_deviation, debt_parameters or emergency_admin in the constructor of PegKeeperRegulator, does not emit an event.    The following events have been added:  1. set_price_deviation emits a PriceDeviation event.  2. set_debt_parameters emits a DebtParameters event.  3. set_killed emits a SetKilled event.  4. set_emergency_admin emits a SetEmergencyAdmin event.  Moreover, the constructor emits now all the respective events.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Missing Sanity Checks",
        "body": "  The following sanity checks could be applied:  CS-CRVPKV2-004  Curve - PegKeeperV2 -   12  CriticalHighMediumLowCodeCorrectedCodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \f1. PegKeeperV2.commit_new_admin() does not check that _new_admin is non-zero.  2. PegKeeperV2.set_new_regulator() does not check that _new_regulator is non-zero. Moreover, it is not guaranteed that the new regulator set will implement the interface required.  3. PegKeeperRegulator.add_peg_keeper() does not check if the new keepers to be added are  not  already  part  of  the  peg_keepers.  Moreover,  the  _peg_keepers  array  could  have duplicates.    1. _new_admin is checked to be non-zero.  2. _new_regulator is checked to be non-zero.  3. add_peg_keeper() checks if the peg keeper has already been added.  Curve - PegKeeperV2 -   13  \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Gas Optimizations",
        "body": "  The following gas optimizations could be applied:  CS-CRVPKV2-001  1. PegKeeperV2.apply_new_admin():  self.new_admin_deadline  is  read  twice  from  storage but it could be cached.  2. PegKeeperV2._withdraw(): the function reads self.debt twice from storage but it could  be cached.  3. PegKeeperRegulator.withdraw_allowed(): This function is expected to be called often. Therefore, it could make sense to be able to store the peg keepers in a map so that their info can be retrieved in :math:O(1) instead of :math:O(n).    The optimizations are implemented as follows:  1. self.new_admin_deadline is cached in new_admin_deadline.  2. self.debt is cached in debt.  3. peg_keeper_i is introduced to allow access to peg keeper info in constant time.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Redundant Events",
        "body": "  The  following  methods  of  the  PegKeeperV2  emit  a  redundant  event  should  the  same  parameters  are set.  CS-CRVPKV2-002  1. set_new_caller_share()  2. set_new_regulator()  3. commit_new_admin()  4. set_new_receiver()  The  method  set_admin()  of  the  PegKeeperRegulator  emits  a  redundant  event  should  the  same admin be set.  Curve - PegKeeperV2 -   14  InformationalVersion1InformationalVersion1      \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   TVL Manipulation",
        "body": "  While the new system prevents price manipulation with the use of oracles through the regulator, it might still be possible to manipulate the TVL of a pool to trick the PegKeeper into providing more crvUSD than it should. Such manipulation could look like the following:  1. Provide a large amount of both assets to the pool in a balanced way.  2. Call   the   PegKeeper   to   provide   crvUSD,   the   result   of  (balance_peg - balance_pegged) / 5 will be inflated.  3. Remove the previously provided assets from the pool.  Curve - PegKeeperV2 -   15  NoteVersion1  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Allowances Enable Management of Both Base",
        "body": " Tokens and Collateral Assets  Users can give privileges to other accounts through the approve and allow functions. Both functions use the isAllowed mapping to store this information. Accounts for which isAllowed is set to true have full control over both the base tokens and the collateral assets of the user.  This is problematic for the following reasons:  It may not be clear to users who call the approve function (which is part of the ERC-20 interface) that this not only gives the spender access to their base tokens but also to their collateral assets. The function description does not specify this.   There is no means of giving partial privileges (i.e., access only to base tokens or only to collaterals)  to another account. This may force users to give unnecessary permissions to other accounts.   Given prior experiences with ERC-20 tokens, users might expect the approve function to allow the spender to transfer at most balanceOf tokens. However, this is not true here as an approval also allows  the  spender  to  borrow  funds.  As  a  result,  balanceOf  can  essentially  become  negative, which might not match the expectations of users or integrators.  Compound - Comet -   10  SecurityDesignCorrectnessCriticalHighMediumRiskAcceptedRiskAcceptedRiskAcceptedRiskAcceptedLowRiskAcceptedRiskAcceptedRiskAcceptedCorrectnessMediumVersion1RiskAccepted             \fTo  avoid  integration  issues  and  the  compromise  of  user  funds,  these  unexpected  behaviors  should  be clearly documented.  Risk accepted:  Compound has added dev notes documenting the special behaviour.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Oracle Timestamps Not Checked",
        "body": "  The function getPrice does not verify that the round data received from Chainlink oracles is up-to-date. If there is any problem with the oracles that results in outdated pricing data being returned. As a result critical calculations for allowed borrowing and liquidations would become inaccurate. It might be possible to liquidate safe positions or take out under-collateralized borrows.  Risk accepted:  Compound  acknowledges  the  risk  and  notes  that  even  if  a  defense  against  a  lack  of  updates  was implemented,  the  ability  to  report  false  prices  make  the  price  oracles  a  primary  risk  vector  for  the protocol.  Moreover,  Compound  encourages  governance  to  invest  in  improvements  upon  the  oracle system, especially ones which can also reduce gas costs.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   approve Only Allows the Values 0 and MAX",
        "body": "  The  approve  function  only  allows  the  values  0  and  type(uint256).max  which  could  lead  to  the following complications:  1. All  approvals  are  infinite.  In  the  past,  infinite  approvals  given  to  buggy  contracts  have  been exploited (e.g., in the case of Multichain). The risk of this is increased when only infinite approvals can be given.  2. All  other  approvals  will  fail.  This  breaks  integration  with  existing  DeFi  protocols,  which  approve  exact values. Comet Tokens would be incompatible with such protocols.  Risk accepted:  Compound accepts the risk and refers to its documentation.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.4   baseBorrowMin Is Not Enforced for",
        "body": " Destination of Transfer  Borrows  have  a  minimum  threshold,  called  baseBorrowMin  to  ensure  that  it  remains  worthwhile  to liquidate them. However, this minimum threshold does not always hold.  If Base Tokens are transferred to another address using transferBase and the sender has to borrow tokens,  the  call  reverts  if  the  amount  of  borrowed  tokens  does  not  exceed  the  baseBorrowMin threshold. However, if a user receives tokens such that his balance is still negative but now violates the baseBorrowMin threshold, the call does not revert.  Compound - Comet -   11  SecurityMediumVersion1RiskAcceptedDesignMediumVersion1RiskAcceptedCorrectnessMediumVersion1RiskAccepted                        \fAs  a  consequence,  an  attacker  could  intentionally  set  up  many  accounts  with  borrows  below  the threshold in order to avoid liquidation. However, setting up such accounts would also consume a lot of gas and hence is unlikely to be financially beneficial.  Risk accepted:  Compound accepts the risk with the following statement:  The intention behind baseBorrowMin is to disallow initiating new borrows for which liquidation would likely not be worthwhile relative to gas costs. The destination of a transfer can only end up with 'dust' if a debt is partially repaid by another account almost fully. Both new positions would still need to be fully  collateralized  according  to  the  borrow  collateral  factor.  If  some  kind  of  griefing  attack  were attempted, governance could declare such tiny borrows as liquidatable at any point, and potentially seize or sell all the collateral immediately.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.5   Balances Can Be Overflowed",
        "body": "  The  functions  presentValueSupply  and  presentValueBorrow  in  CometCore  allow  an  overflow due to unsafe casting to uint104. Consider the following scenario:   A user supplies type(int104).max Base Tokens to the protocol.   After some time, the baseSupplyIndex is equal to or greater than 2.   The user calls any of the functions that update their balance with 0 amount.   totalSupplyBase as well as the user's principal will be overflowed to a value smaller than the  current value.  If the base token uses the maximum of 18 decimals allowed in the protocol, around 10 trillion in principal balance  and  an  index  value  of  at  least  2  (otherwise  the  safe  cast  in  presentValue  will  kick  in)  are needed. This is practically infeasible for base tokens pegged to the USD. However, other base tokens (or USD-based  tokens  after  a  period  of  extreme  inflation)  can  bring  this  problem  into  the  realm  of possibilities.  Risk accepted:  Compound accepts the risk and extended the documentation to describe it.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.6   Tracking Indices May Overflow on Large",
        "body": " Tracking Speed Values  The  state  variables  trackingSupplyIndex,  trackingBorrowIndex  as  well  as  each  user's baseTrackingIndex are of type uint64. The function accrueInternal updates these indices with the product of the passed seconds and baseTrackingSupplySpeed / baseTrackingBorrowSpeed divided  by  the  current  amount  of  totalSupplyBase  /  totalBorrowBase  (without  decimals). baseTrackingSupplySpeed / baseTrackingBorrowSpeed can be numbers with a decimal scale of up  to  15  which  will  result  in  an  overflow  after  a  non-negligible  time-frame  if  the  amount  of  supplied  / borrowed tokens is low and baseMinForRewards is set to a low value.  Compound - Comet -   12  CorrectnessLowVersion1RiskAcceptedCorrectnessLowVersion1RiskAccepted                \fSuppose trackingIndexScale, trackingSupplyIndex and trackingBorrowIndex are all set to 1e15  (e.g.  1  COMP  per  second).  The  safe  cast  to  uint64  in  accrueInternal  will  revert  after  only approximately 5 hours after the baseMinForRewards has been reached resulting in a denial-of-service for the whole contract. This time is multiplied by the amount of full tokens supplied.  Risk accepted:  Compound accepts this risk with the following statement:  The  overflow  behavior  depends  on  several  parameters  which  do  need  to  be  chosen  carefully  by governance.  However,  we  believe  these  values  can  be  chosen  safely  and  need  not  often,  if  ever, change. In the worst case, in which governance fails to set these safely, there would be a denial of service until resolved by governance. We believe this is an acceptable risk, given that the very worst case in which bad parameters are chosen still does not result in any loss of funds.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.7   targetReserves Limit in buyCollateral",
        "body": " Can Be Circumvented  The  targetReserves  value  describes  the  expected  value  of  the  protocol  reserves  expressed  in  the base  asset.  The  function  buyCollateral  reverts  if  the  current  protocol  reserves  are  higher  than targetReserves as it doesn't allow the purchase of Collateral assets in this case. However, if any of the  collateral  tokens  has  a  callback  as  part  of  transferFrom  (e.g.  ERC777),  then  this  check  can  be circumvented  with  a  reentrant  call  to  buyCollateral.  As  a  consequence,  more  collateral  can  be bought than intended by the protocol as the check is not correctly performed for the reentrant call.  Additionally,  even  without  a  reentrancy,  the  purchased  amount  might  far  exceed  the  value  of targetReserves. At the time of writing it was unclear whether this is intended in all cases.  Risk accepted:  Compound accepts the risk with the following statement:  The reserves target is a mechanism for governance to prevent the sale of collateral after a sufficient number  of  reserves  have  been  reached.  The  risk  that  collateral  assets  may  be  sold  and  increase reserves beyond the target amount, is not a risk to the protocol health, in fact generally the opposite, as  it  guarantees  a  larger  amount  of  reserves.  The  issue  is  that  it  could  prevent  the  protocol  from being as profitable as it might otherwise be in the event that assets are liquidated and sold and later become much more valuable (as has been the case previously for many crypto assets), but we are not concerned about that risk.  Compound - Comet -   13  SecurityLowVersion1RiskAccepted          \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings   Wrong Computation of Borrow Balance   -Severity Findings   No Handling of Ecrecover Return on Wrong Input    No Sanity Checks for liquidationFactor    CometInterface Not Implemented by the Contracts   -Severity Findings   Accrued Interest Not Accounted for in Balance Functions    Floating Pragma    Missing Constructor Sanity Checks    Missing Events    No Recovery of Accidental Token Transfers Possible    Possible Contract Size Reductions    Possible Gas Savings    Rounding Errors Between User Balances and Total Balances    Unused Custom Error   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Wrong Computation of Borrow Balance",
        "body": "  function  borrowBalanceOf   The  baseBorrowIndex to compute the borrow balance:  inside   the  CometExt  uses  baseSupplyIndex   0  1  3  9  instead  of  function borrowBalanceOf(address account) external view returns (uint256) {     int104 principal = userBasic[account].principal;     return principal < 0 ? presentValueBorrow(baseSupplyIndex, unsigned104(-principal)) : 0;  As a consequence, the result is incorrect.    The borrowBalanceOf function now uses the correct index (i.e., baseBorrowIndex). In addition, unit tests  were  updated  to  catch  this  issue  by  using  a  different  value  for  baseSupplyIndex  and baseBorrowIndex.  Compound - Comet -   14  CriticalHighCodeCorrectedMediumCodeCorrectedCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCorrectnessHighVersion1CodeCorrected        \f6.2   No Handling of Ecrecover Return on Wrong Input  ecrecover returns 0 on error. This error value is not checked correctly within the allowBySig function. As a result anyone can call allowBySig with owner == 0 and thereby set approvals in the name of the  0-address.  Since  transfers  to  the  0-address  are  possible  in  the  contract,  falsely  sent  funds  to  this address could be recovered by an attacker.    The allowBySig function now reverts if the value returned by ecrecover is the 0-address.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   No Sanity Checks for liquidationFactor",
        "body": "  The  liquidationFactor  determines  the  liquidation  penalty  a  user  suffers  based  on  the  collateral asset. When setting the liquidationFactor in the function _getPackedAsset, it should be checked against  the  value  of  storeFrontPriceFactor.  The  storeFrontPriceFactor  describes  the discount  If liquidationFactor  >  storeFrontPriceFactor,  then  the  protocol  is  expected  to  lose  funds  on liquidations. Any user noticing this, could perform the following attack:  liquidated   collateral.   someone   protocol   when   gives   buys   the   Sandwich significant price updates which decrease any of the collateral prices or increase the base asset price using:   Supply a collateral and borrow the maximum   Absorb the account and liquidate  This would drain funds from the protocol. Hence, it should be ensured that this setting never exists.    liquidationFactor is now assured to be smaller than or equal to storeFrontPriceFactor.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   CometInterface Not Implemented by the",
        "body": " Contracts  The contracts Comet and CometExt contracts do not extend the CometInterface. This can lead to errors  during  development  and  integration  by  third  parties  as  the  interface  does  not  match  up  with  the implementations. One such error is that the contracts do not implement an accrue function even though it is defined in the CometInterface:  abstract contract CometInterface is CometCore, ERC20 {     ...     function accrue() virtual external;  Compound - Comet -   15  SecurityMediumVersion1CodeCorrectedDesignMediumVersion1CodeCorrectedCorrectnessMediumVersion1CodeCorrected                        \f  CometInterface  was  split  into  CometMainInterface  and  CometExtInterface.  Comet  now implements CometMainInterface, and CometExt now implements CometExtInterface.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Accrued Interest Not Accounted for in",
        "body": " Balance Functions  The  functions  balanceOf,  borrowBalanceOf  and  baseBalanceOf  do  not  accrue  interest  before returning  the  respective  balances.  This  can  result  in  unexpected  behavior.  Consider  the  following example:  1. A contract queries its borrowBalanceOf of asset A. The function returns X.  2. The contract supplies X of asset A, expecting to have paid back all its borrows. However, unless accrueInternal  has  by  chance  been  called  within  the  same  block,  there  will  be  a  remaining borrow balance.  This behavior needs to be explicitly specified, currently the function descriptions do not indicate this in any way:  /**  * @notice Query the current negative base balance of an account or zero  * @param account The account whose balance to query  * @return The present day base balance magnitude of the account, if negative  */    balanceOf,  borrowBalanceOf  and  baseBalanceOf  now  calculate  baseSupplyIndex / baseBorrowIndex before converting them to present values.  the  current  values  of  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Floating Pragma",
        "body": "  Comet uses the floating pragma ^0.8.11. Contracts should be deployed with the compiler version and flags that were used during testing and auditing. Locking the pragma helps to ensure that contracts are not accidentally deployed using a different compiler version and help ensure a reproducible deployment.    Compiler version has been fixed to 0.8.13.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Missing Constructor Sanity Checks",
        "body": "  The following sanity checks could potentially be added to the constructor:   Base Token decimals should be at least 6 to prevent accrualDescaleFactor from becoming 0.  Compound - Comet -   16  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \f A  comment  for  baseMinForRewards  suggests  the  value  should  be  sufficiently  large  but  is  only  checked to be non-zero.   reserveRate  should  be  lower  or  equal  to  FACTOR_SCALE  to  prevent  reverting  on  underflow  in  getSupplyRate.   kink should be lower than or equal to FACTOR_SCALE.     Corrected: baseScale is assured to be greater than or equal to BASE_ACCRUAL_SCALE.   Risk accepted: Governance is trusted to choose the correct value for baseMinForRewards.   Corrected: kink is assured to be smaller than or equal to FACTOR_SCALE.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   Missing Events",
        "body": "  The following functions represent important state changes, for which an event might be helpful:   initializeStorage   pause   absorb   buyCollateral   withdrawReserves   allow   allowBySig  Additionally, if absorbing an account results in a loss of funds of reserves, because the collateral did not cover the borrow, an event could be emitted as well.    All  mentioned  functions  except  initializeStorage  and  buyCollateral  now  emit  events. Regarding the remaining events, Compound has issued the following statement:  Our view is that events should not be viewed as critical for tracking state changes, and that modern off-chain processors are capable of tracking all contract state transitions anyway.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   No Recovery of Accidental Token Transfers",
        "body": " Possible  In case an ERC-20 token other than the base tokens or collateral tokens is sent to the contract, then it cannot be recovered. Among other reasons, this might happen due to airdrops based on the base tokens or collateral tokens.    A new function approveThis has been introduced to allow the governance to approve any ERC20 token to any address.  Compound - Comet -   17  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                  \f6.10   Possible Contract Size Reductions  Instead  of  creating  an  empty  AssetConfig,  and  later  returning  (0,  0),  the  function _getPackedAsset could directly return (0, 0).   The  functions  isBorrowCollateralized,  getBorrowLiquidity,  isLiquidatable  and getLiquidationMargin share the same code with marginal modifications. The overlapping code could be factored out into new functions to save code size.   The baseScale variable is only needed internally and is derived from decimals and can thus be  defined as internal to reduce code size.   The   intialization  of  trackingSupplyIndex  and  trackingBorrowIndex   to  0   in   the  initializeStorage function can be omitted.     Corrected:  __getPackedAsset  now  directly  returns  (0,  0)  if  an  AssetConfig  element  is  empty.   Not  corrected:  Compound  claims  that  the  compiler  opimizations  already  account  for  a  sufficient getBorrowLiquidity,  isBorrowCollateralized,   size   in   contract  reduction  isLiquidatable and getLiquidationMargin.   Not corrected: Compound does not want to make an exception for one variable.   Corrected: trackingSupplyIndex and trackingBorrowIndex are no longer initialized to 0.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.11   Possible Gas Savings",
        "body": "   The  function  _getPackedAsset  calls  the  decimals  function  of  the  asset  ERC20  contract  and checks  if  it  equals  the  provided  decimals  variable  in  AssetConfig.  Since  the  external  call  to asset  is  done  anyways,  there  is  no  need  to  provide  the  decimals  in  the  config  and  perform  this check.   The  function  supplyCollateral  calls  getAddressInfoByAddress  and  updateAssetsIn  which calls getAddressInfoByAddress for the same address again.   The  function  absorbInternal  calls  isLiquidatable  and  then  proceeds  to  perform  a  very  similar computation (including the same calls to the price oracles) again.   The function isBorrowCollateralized is expected to be commonly called for contracts with a non-negative  base  balance,  e.g.,  for  address(this)  in  buyCollateral.  In  those  cases, isBorrowCollateralized can return true as soon as presentValue is non-negative. Then, the call to the price oracle can be skipped.     Not  corrected:  The  additional  decimals  value  in  the  supplied  config  is  used  as  sanity  check  to  determine if the caller actually knows the decimals of the asset being configured.   Corrected:  updateAssetsIn  now  takes  AssetInfo  as  argument  and  does  not  load  asset  infos  itself anymore.  Compound - Comet -   18  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected               \f Not corrected: Compound claims that the compiler already optimizes the functions.   Corrected: isBorrowCollateralized now checks if the user's present value is greater than or  equal to zero before performing any calculations.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.12   Rounding Errors Between User Balances and",
        "body": " Total Balances  Due  to  the  balance  calculation  with  indices  and  principal  values,  rounding  errors  can  introduce  an inconsistency between the user balances and the total balances. Consider the following scenario:   totalSupplyBase is 100.   baseSupplyIndex is 1.085 (without decimals).   A user now supplies 10 Base Tokens with the supply function.   totalSupplyBase gets updated to 108.   The user's principal gets updated to 9.  If the protocol holds no reserves, the last user to withdraw their balance from the contract might not be able to withdraw the full amount.    The calculation of totals was modified to address this issue: Indices are now no longer translated to their present values, updated and trasnlated back to their principal values. Instead, they are now updated with the delta of users' principal values.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.13   Unused Custom Error",
        "body": "  The Comet contract defines a BadAmount error that is never used.    Unused errors BadAmount in Comet and Unauthorized in CometExt have been removed.  Compound - Comet -   19  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Event Reordering Possible",
        "body": "  doTransferIn  and  doTransferOut  are  always  called  before  events  are  emitted.  If  the  respective ERC20  tokens  that  are  called  implement  callbacks  to  the  sender  or  receiver,  events  could  possibly  be reordered due to reentrancy. While this is not problematic for the contract itself, this can introduce errors in third-party applications that make certain assumptions about the emitted events.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Magic Numbers",
        "body": "  The  functions  _getPackedAsset  and  getAssetInfo  use  the  same  magic  numbers  for  packing  as well as descale and rescale factors:  uint256 word_a = (uint160(asset) << 0 |                   uint256(borrowCollateralFactor) << 160 |                   uint256(liquidateCollateralFactor) << 176 |                   uint256(liquidationFactor) << 192);  These numbers should be defined as constants to avoid errors during development.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Potential Incentive to Withdraw Supply",
        "body": "  In certain circumstances, users might have an incentive to actually withdraw parts of their supplied base tokens. Consider the following scenario:   kink is set to 80%.   interestRateSlopeLow is set to 10%.   interestRateSlopeHigh is set to 300%.   interestRateBase is set to 5%   For simplification, reserveRate is set to 0.   User A has supplied 100 base tokens to the contract.   User B has borrowed 80 of those base tokens, resulting in 80% utilization.   User A currently receives 10.4 base tokens interest per year.   User A now withdraws 20 base tokens such that utilization becomes 100%   User  A  now  receives  58.4  base  tokens  interest  per  year,  even  though  they  have  reduced  their  balance.  Compound - Comet -   20  NoteVersion1NoteVersion1NoteVersion1          \fIf User A holds a significant stake in supplied base tokens, they might be incentivized to withdraw some of their supply for as long as the utilization is high enough so that they earn more than 10.4 base tokens per year. However, obviously such a scenario incentivizes others to supply liquidity or repay borrows, so that it is unlikely to last.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   Regular Use Expected",
        "body": "  For  the  sake  of  security,  the  protocol  assumes  that  each  contract  is  used  somewhat  regularly.  This  is required so that the function accrueInternal is called regularly. If there is no regular usage, e.g., if the contract is not called for a year, the following issue arises:  Collateral  that  normally  would  be  liquidatable  can  still  be  transferred  /  withdrawn.  This  is  because  the interest needs to be explicitly accrued to update the indexes. Transfers and withdrawals of collateral are allowed  without  explicit  accrual  and  hence  rely  on  recent  actions.  Theoretically,  this  can  lead  to under-collateralized  accounts,  but  given  typical  configurations,  this  would  take  years  of  inactivity.  The authors are aware of this requirement and added the following comment:  // Note: no accrue interest, BorrowCF < LiquidationCF covers small changes  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   Supported Tokens",
        "body": "  Not  all  ERC20  tokens  can  act  as  base  and  collateral  tokens  for  Comet  contracts.  In  particular,  the following tokens are not supported:   Tokens with more than 18 decimals   Tokens with less than 6 decimals, e.g., GUSD   Tokens with transfer fees   Tokens where the balance can change without a transfer, these include:  Interest bearing tokens that increase balances   Deflationary tokens that decrease balances   Rebasing tokens   Tokens with a missing return value on transfer or transferFrom (e.g., USDT)   Tokens that require certain receiver functions to be implemented in contracts, e.g., ERC223   Tokens with rapidly increasing/positively manipulatable prices (cannot be used as base token)   Tokens with rapidly decreasing/negatively manipulatable prices (cannot be used as collateral token)   Tokens  with  multiple  entry  points  for  which  more  than  one  entry  point  has  been  added  to  the  contract's collateral assets.  Additionally the following tokens can break the protocol depending on their use:   Tokens with blacklisting in case a Comet contract is blacklisted   Pausable tokens when paused   Upgradable tokens that later introduce one of the problematic features  Compound - Comet -   21  NoteVersion1NoteVersion1           \f7.6   The Fallback Function Is Payable  The fallback function of Comet is payable even though none of the functions of CometExt are payable. Hence, there is no reason for the fallback function to be payable.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.7   Transfers to 0-Address Allowed",
        "body": "  The  functions  transferInternal  and  withdrawInternal  do  not  revert  on  transfers  to  the 0-address. As a consequence, the base asset and the collateral assets might accidentally be transferred to the 0-address.  Compound - Comet -   22  NoteVersion1NoteVersion1      \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Incorrect Order of Evaluation of Arguments of",
        "body": " Builtin Function  The order of evaluation of the arguments of the builtin functions uint256_addmod, uint256_mulmod, ecadd and ecmul is incorrect.   For uint256_addmod(a,b,c) and uint256_mulmod(a,b,c), the order is c,a,b.   For ecadd(a,b) and ecmul(a,b), the order is b,a.  In the following contract, a call to foo() returns 1 while we would expect it to return 0.  CS-VYPER_MAY_2023-001  a:uint256  @internal def bar() -> uint256:     self.a = 1     return 8  @external def foo()->uint256:     return uint256_addmod(self.a, 0, self.bar()) # returns 1  In the following contract, a call to loo() returns False while we would expect it to return True.  x: uint256[2]  @internal def bar() -> uint256[2]:     self.x = ecadd([1, 2], [1, 2])     return [1,2]  @external def loo() -> bool:     self.x = [1, 2]      a:uint256[2] = ecadd([1, 2], [1, 2])     b:uint256[2] = ecadd(self.x, self.bar())      return a[0] == b[0] and a[1] == b[1] # returns false  Vyper - Vyper Compiler -   11  CorrectnessMediumVersion1       \f5.2   Make_setter Is Incorrect for Complex Types When the RHS References the LHS With a Function Call  Issue 2418 described a bug where, during an assignment, if the right-hand side refers to the left-hand side, part of the data to be copied may get overwritten before being copied.  Although PR 3410 fixed the issue in most of the cases, it can still happen with function calls as shown in the  example  below.  A  call  to  foo  returns  [2,2]  where  if  the  function  bar  would  be  inlined,  it  would return [2,1]  CS-VYPER_MAY_2023-002  a:DynArray[uint256,2]  @external def foo() -> DynArray[uint256,2]:     # Initial value     self.a = [1,2]     self.a = [self.bar(1), self.bar(0)]     return self.a #returns [2,2]  @internal def bar(i:uint256)->uint256:     return self.a[i]  In this second example, boo temporarily assigns values to a before emptying it. the values stored in a are however still readable from foo as a call to foo here returns [11,12,3,4].  a:DynArray[uint256, 10]  @external def foo()->DynArray[uint256,10]:     self.a = [1,2,self.boo(),4]     return self.a # returns [11,12,3,4]  @internal def boo() -> uint256:     self.a = [11,12,13,14,15,16]     self.a = []     # it should now be impossible to read any of [11,12,13,14,15,16]     return 3  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   Metadata Journal Can Rollback Incorrectly",
        "body": "  To  fix  the  issue  of  incorrect  type  checking  of  loop  variables,  a  commit/rollback  scheme  for  metadata caching has been implemented to handle speculation when trying to type a loop.  When registering two consecutive updates for a given node, the journal can have an incorrect behavior.  CS-VYPER_MAY_2023-003  Vyper - Vyper Compiler -   12  CorrectnessMediumVersion1CorrectnessMediumVersion1          \fAssuming  that  the  compiler  has  entered  the  speculation  mode  (while  typing  a  loop  for  example),  and considering  an  AST  node  A  which,  at  the  time  of  entering  the  speculation  had  M0  as  metadata,  if  the following events happen, the cached metadata for A would become incorrect (considering M0!=M1):  1. The metadata of A is updated a first time (using register_update) resulting in M1.  2. The metadata of A is updated a second time resulting in M2 (which might or might not be equal to  M1).  3. _rollback_inner is called to roll back A's metadata to its state pre-speculation.  While the correct state of A's metadata should be M0, the resulting metadata will currently be M1 as the second call to register_update has \"overwritten\" the first one.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.4   Assertion Could Be More Precise in",
        "body": " parse_Binop  CS-VYPER_MAY_2023-004  the   function   In  assertion in  is_numeric_type(left.typ) could be performed before the LShift and RShift cases are those operators are only defined for numeric types.  Expr.parse_BinOp   generation,   code   the   the   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.5   Assertions Are Not Constant",
        "body": "  The definition of the class Context introduce the flag in_assertion which, when set, indicates that the context should be constant according to is_constant() definition. This flag is never set during the code generation, specifically, it is possible to have a non-constant expression in an assert statement. For example, the following contract compiles.  CS-VYPER_MAY_2023-005  x: uint256  @internal def bar() -> uint256:     self.x = 1     return self.x  @external def foo():     assert self.bar() == 1  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.6   Calls to State-Modifying Functions in Range",
        "body": " Expressions Are Not Caught by the Type-Checker  CS-VYPER_MAY_2023-006  Vyper - Vyper Compiler -   13  DesignLowVersion1CorrectnessLowVersion1CorrectnessLowVersion1                  \fThe  type  checker  does  not  catch  the  use  of  a  state-modifying  function  call  in  a  range  expression,  this leads  assertion: assert use_staticcall, \"typechecker missed this\"  generator   code   due   the   fail   an   to   to   The compiler fails to compile the following with the assertion mentioned above.  interface A:     def foo()-> uint256:nonpayable  @external def bar(x:address):     a:A = A(x)     for i in range(a.foo(),a.foo()+1):         pass  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.7   Default Arguments Are Treated as Keyword",
        "body": " Arguments  validate_call_args takes kwargs, the list of valid keywords as an argument and makes sure that when a call is made, the given keywords are valid according to kwargs.  CS-VYPER_MAY_2023-007  When  being  called  from  ContractFunctionT.fetch_call_return,  the  defaults  arguments  of  the function  are  given  to  validate_call_args  in  kwargs  although  it  is  not  allowed  to  give  keywords for  gas,  value,  skip_contract_check  and arguments  default_return_value.  call  except   function   in  a   For example, when trying to compile the following contract, the call to validate_call_args made by fetch_call_return  will  succeed  although  an  invalid  keyword  argument  is  passed.  The  compilation will later fail (as it should) as fetch_call_return enforce that the kwargs should belong to the call site kwargs' whitelist.  @external def foo():     self.boo(a=12)  @internal def boo(a:uint256=12):     pass  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.8   Epsilon Is Not Documented",
        "body": "  The builtin function epsilon is not documented in https://docs.vyperlang.org/.  CS-VYPER_MAY_2023-008  Vyper - Vyper Compiler -   14  DesignLowVersion1DesignLowVersion1              \f5.9   IfExp Cannot Be Used in a Subscript  The  IfExp  AST  node's  case  in  util.py:types_from_Subscript  and annotation.py:visit_subscript.  The  following  example  does  not  compile,  and  the  compiler returns: vyper.exceptions.StructureException: Ambiguous type  is  missing   CS-VYPER_MAY_2023-009  @external def boo() :     a:uint256 = ([1] if True else [2])[0]  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.10   IfExp Fails at Codegen When Used With Self",
        "body": " or Environment Variables  Some complex expressions including the new IfExp node might typecheck, however, no corresponding case is implemented in the codegen leading the compiler to fail.  CS-VYPER_MAY_2023-010  The  (isinstance(contract_address.typ, InterfaceT)) in ir_for_external_call.  following   example   compile   fails   with   an   assertion   to   @external def foo():     (self if True else self).bar()  @internal def bar():     pass  The  vyper.exceptions.TypeCheckFailure: Name node did not produce IR.  following   example   fails   to   compile   error  with  @external def foo():     a:Bytes[10] = (msg if True else msg).data  Note:  In  case  the  first  example  was  to  be  allowed  by  Vyper,  one  would  need  to  be  careful  as  several analysis and sanity checks (e.g circularity checks) rely on the fact that function calls are always on the form self.FUNC_NAME.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.11   IfExp Not Annotated When Used as Iterable",
        "body": " for a Loop  CS-VYPER_MAY_2023-011  Vyper - Vyper Compiler -   15  DesignLowVersion1DesignLowVersion1DesignLowVersion1                \fThe  IfExp  AST  node's  case  the StatementAnnotationVisitor to omit the annotation of a IfExp node when used as iterable in a loop. The following example does not compile, and the compiler returns: KeyError: 'type'.  in  annotation.py:visit_For   is  missing   leading   @external def foo():     for x in [1,2] if True else [0,12]:         pass  Note  that  if  a  new  case  for  IfExp  is  created  in  annotation.py:visit_For  to  fix  this  issue,  the function  local.py:visit_For  should  be  updated  carefully  as  the  check  that  ensures  that  for  loops must have at least 1 iteration would not be performed on IfExp nodes.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.12   Implements Statement Does Not Enforce the",
        "body": " Same Indexation of Events  When  using  the  implements  statement,  the  contract's  events  fields  are  not  enforced  to  match  the interface's events fields on their indexation.  For example, the following code compiles although the spender field of Approval is not indexed.  CS-VYPER_MAY_2023-012  from vyper.interfaces import ERC20  implements: ERC20  event Transfer:     sender: indexed(address)     receiver: indexed(address)     value: uint256  event Approval:     owner: indexed(address)     spender: address     value: uint256  name: public(String[32]) symbol: public(String[32]) decimals: public(uint8)  balanceOf: public(HashMap[address, uint256]) allowance: public(HashMap[address, HashMap[address, uint256]]) totalSupply: public(uint256)  @external def __init__(_name: String[32], _symbol: String[32], _decimals: uint8, _supply: uint256): pass  @external def transfer(_to : address, _value : uint256) -> bool: return True  @external def transferFrom(_from : address, _to : address, _value : uint256) -> bool: return True  @external def approve(_spender : address, _value : uint256) -> bool: return True  Vyper - Vyper Compiler -   16  CorrectnessLowVersion1        \f5.13   Imported Contracts Are Not Fully Semantically Validated  When  importing  a  contract,  only  the  function  signatures  are  semantically  checked  (to  produce  the InterfaceT),  A  contract  that  does  not  compile  could  be  imported  in  another  one  which  would  then compile as long as the signatures of the imported functions are semantically correct.  For example, a.vy compiles although it imports b.vy which does not compile.  CS-VYPER_MAY_2023-027  #a.vy import b as B  @external def foo(addr:address):     x:B = B(addr)     x.foo()  #b.by @external def foo():     x:uint256 = \"foo\"  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.14   Incorrect Typing of Builtins Whose Return",
        "body": " Type Depends on Some of Its Argument's Types  CS-VYPER_MAY_2023-013  Builtin  functions  whose  return  type  depends  on  some  of  its  argument's  type  can  be  incorrectly  typed resulting in the compiler exiting with a TypeMismatch.  To achieve this behavior, the builtin function should be called with arguments such that:   At least one argument is not constant as the call would be folded otherwise.   get_possible_types_from_node  should  return  multiple  potential  types  for  the  arguments  on  which the return type of the builtin depends.  Below is a list of the builtins affected together with examples failing to compile although they should:   min and max:   a:uint256 = min(1 if True else 2, 1)   all unsafe builtins:   a:uint256 = unsafe_add(1 if True else 2, 1)   shift (deprecated as of v0.3.8):   a:uint256 = shift(-1, 1 if True else 2)   uint2str:  Vyper - Vyper Compiler -   17  CorrectnessLowVersion1CorrectnessLowVersion1          \f f:String[12] = uint2str(1 if True else 2)  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.15   Incorrect Typing of Loop Iterable When It Is a",
        "body": " List Literal  when a loop iterates over a literal list, the function visit_For of the StatementAnnotationVisitor annotates it with a Static Array type whose value type is the last element of the list of common types of shared by the elements. To be consistent with the previously performed analysis, the list should be typed using the type of the loop iterator as it is done with range expressions.  In this code, although it compiles, i is typed as a uint8 while [1,2,3] is annotated with int8[3].  CS-VYPER_MAY_2023-014  @external def foo():     for i in [1,2,3]:         a:uint8 = i  When  doing  the  code  generation  of  a  for  loop  iterating  over  a  literal  list,  _parse_For_list  is overwriting  the  value  type  of  the  list  with  the  type  of  the  loop  iterator  inferred  at  type  checking.  This behavior  with: TODO investigate why stmt.target.type != stmt.iter.type.value_type. By solving the issue  above,  stmt.target.type  would  be  equal  to  stmt.iter.type.value_type  and  no overwriting would be needed.  commented   is   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.16   Incorrect Typing of Raw_Call When",
        "body": " Max_Outsize=0 in Kwargs  When  called  with  max_outsize  explicitly  set  to  0  (max_outsize=0)  the  compiler  wrongly  infers  that raw_call has no return type.  CS-VYPER_MAY_2023-015  @external @payable def foo(_target: address):      # compiles     a:bool = raw_call(_target, method_id(\"someMethodName()\"), revert_on_failure=False)      # does not compile but should compile     b:bool = raw_call(_target, method_id(\"someMethodName()\"), max_outsize=0, revert_on_failure=False)      # compiles but should not compile     raw_call(_target, method_id(\"someMethodName()\"), max_outsize=0, revert_on_failure=False)  Vyper - Vyper Compiler -   18  CorrectnessLowVersion1CorrectnessLowVersion1              \f5.17   Multiple Evaluations of DST Lead to Non-Unique Symbol Errors When Copying Bytes Arrays or DynArrays  The  destination  of  byte  arrays  and  DynArray  copying  cache_when_complex is not used. This includes the following functions:  is  evaluated  multiple   times  as  CS-VYPER_MAY_2023-016   make_byte_array_copier.   _dynarray_make_setter  src.value != \"multi\").  (both   cases:   src.value   ==   \"multi\"   and  For  AssertionError: non-unique symbols {'self.bar()2'}.  compiling   example,   following   the   Vyper   code   will   output  a:DynArray[DynArray[uint256, 2],2]  @external def foo():     self.a[self.bar()] = [1,2] @internal def bar()->uint256:     return 0  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.18   Nesting a Pop in Append Results in Incorrect",
        "body": " Behavior  CS-VYPER_MAY_2023-017  When modifying the size of a DynArray during a call to append, the initial length will be the one used to compute  the  new  length  and  the  compiler  won't  consider  any  change  of  length  done  by  the sub-expression.  In  the  example  below,  the  value  returned  by  a.pop()  is  used  but  its  side  effect  of decreasing a's length is omitted.  This behavior was introduced by the fix to the security advisory OOB DynArray access when array is on both LHS and RHS of an assignment. As the length of the append is cached before the evaluation of the pop and stored in memory after, the new length produced by the pop which is stored in the memory is not taken into account as it is overwritten by the cached length.  @external def foo() -> DynArray[uint256,3]:     a:DynArray[uint256,2] = [12]     a.append(a.pop())     return a # outputs [12,12] while the same in python outputs [12]  Vyper - Vyper Compiler -   19  CorrectnessLowVersion1CorrectnessLowVersion1            \f5.19   No Sanity Check on Storage Layout Files  CS-VYPER_MAY_2023-018  When  compiling  a  contract  with  the  flag  storage_layout_file,  some  basic  sanity  checks  could  be performed on the given JSON file as currently:   The  JSON  can  have  duplicated  entries.  In  this  case,  the  last  one  will  be  the  one  used  by  the  compiler.   The JSON can have entries not matching any storage slot of the contract   The  entries  of  the  JSON  do  not  necessarily  have  to  match  with  the  type  of  the  corresponding  variables in the contract.  For  example,  a  contract  only  defining  the  storage  variable  a:uint256  can  be  compiled  given  the following storage layout:  {     \"a\": {\"type\": \"uint16\", \"slot\": 10},     \"a\": {\"type\": \"uint8\", \"slot\": 1},     \"b\": {\"type\": \"uint256\", \"slot\": 1} }  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.20   Overriding Storage Layout Fails With",
        "body": " Immutables  The check used for ignoring immutable in set_storage_slots_with_overrides is ill-defined.  When compiling a contract with a custom storage layout file, if an immutable is defined in the contract (and is not present in the json), the compilation will fail with a StorageLayoutException.  For example, the following contract fails to compile if given an empty storage layout.  CS-VYPER_MAY_2023-019  a:immutable(uint256)  @external def __init__():     a = 1  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.21   PR 3134 Has Been Reverted",
        "body": "  The PR 3134 has been reverted by the PR 2974 in the sense that neither the conflicting signatures nor the method ID are displayed when the multiple functions share the same selector.  Note however that PR 2974 fixed an issue where collision between functions having 0x00000000 has method ID were not detected since collision == 0 would be treated as collision == Null.  CS-VYPER_MAY_2023-020  Vyper - Vyper Compiler -   20  DesignLowVersion1CorrectnessLowVersion1DesignLowVersion1                \f5.22   Redundant and Incomplete Function Selector Collision Checks  CS-VYPER_MAY_2023-021  To ensure the method IDs are unique, the constructor of the ModuleAnalyzer performs two checks that are both incomplete but together cover every case:   The call to validate_unique_method_ids by the constructor of the ModuleAnalyzer does not  handle the public variable getters as they haven't been added to the AST yet.   The  generation  of  an  InterfaceT  from  the  top-level  node  has  as  a  side  effect  to  ensure  the uniqueness  of  method  IDs  of  public  variable  getters  and  external  functions  but  does  not  handle internal  variables  (not  really  required  at  the  moment  but  in  Vyper  semantics  to  prevent  breaking changes in case of a future change to their calling convention).  It would probably be better to have one check that covers everything for clarity purposes.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.23   References to Public Constant and",
        "body": " Immutables With Self Missed by the Typechecker  As  visit_VariableDecl  adds  public  constant  and  immutables  variables  to  self's  namespace, types_from_Attribute successfully typecheck references to constant and immutables using self. The compiler later fails during the codegen.  Compiling the following contract will fail with KeyError: 'a'.  CS-VYPER_MAY_2023-022  a:public(constant(uint256)) = 1  @external def foo():     b:uint256 = self.a  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.24   Semantic Analysis of the Imported Contract",
        "body": " Is Done With the Current Contract's Namespace  When  an  imported  interface  is  typed,  the  namespace  of  the  current  contract  is  used  to  generate  the interface  type  from  the  AST  of  the  imported  contract.  This  means  that  the  imported  contract's  function definitions may use the types and constants defined in the current contract.  For example a.vy would compile successfully although b.vy, which is imported by a.vy makes use of S and a, both defined in a.vy.  CS-VYPER_MAY_2023-023  Vyper - Vyper Compiler -   21  DesignLowVersion1DesignLowVersion1CorrectnessLowVersion1                  \f#a.vy import b as B  struct S:     x:uint256 a:constant(uint256) = 12  @external def bar(addr:address):     x:B = B(addr)     y:S = x.foo()  #b.vy @external def foo(a:uint256=a) -> S:     return S({x:12})  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.25   StateAccessViolation When \"Self\" Is Used as",
        "body": " a Struct Field Name  While it is allowed to use self as a field name for a struct, constructing such struct in a pure function will result in a StateAccessViolation as the compiler will consider that this is a reference to self, the address of the contract.  For example, the following contract fails to compile due to StateAccessViolation: not allowed  to query contract or environment variables in pure functions.  CS-VYPER_MAY_2023-024  struct A:     self:uint256  @external @pure def foo():     a:A = A({self:1})  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.26   TypecheckFailure When Using Address and",
        "body": " Self Members as Struct Field Name  Accessing  the  field  of  an  enum  named  after  an  address  or  self  member  (balance,  codesize, is_contract, codehash or code) results in a TypeCheckFailure.  CS-VYPER_MAY_2023-025  For  TypeCheckFailure: Attribute node did not produce IR.  example,   following   contract   fails   the   to   compile   due   to  Vyper - Vyper Compiler -   22  CorrectnessLowVersion1CorrectnessLowVersion1            \fstruct User:     balance:uint256  @external def foo():     a:User = User({balance:12})     b:uint256 = a.balance  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.27   in and Not in Cannot Be Used With DynArray",
        "body": " of Enums  When  trying  to  use  the  in  or  not  in  operator  with  a  Dynamic  Array  of  Enum,  the  compiler  fails  to compile the program with a TypeMismatch.  For example, the following contract does not compile due to the in operation.  CS-VYPER_MAY_2023-026  enum A:     a     b @external def foo():     f:DynArray[A,12] = []     b:bool = A.a in f  Vyper - Vyper Compiler -   23  CorrectnessLowVersion1      \f6   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Note on PR 3388",
        "body": "  The  code  generation  of  the  constructor  of  a  contract  is  performed  before  the  code  generation  of  the deployment version of its called functions. It hence relies on the fact that the code generation of runtime internal  functions  properly  sets  the  frame  information  of  the  constructor's  callees.  If  the  runtime  code generation would be to skip the generation of internal functions that will not be included in the runtime code for example, the MemoryAllocator of the constructor would be incorrectly initialized.  Additionally, following PR 3388, the following comment in the function _runtime_ir is now outdated:  # create a map of the IR functions since they might live in both # runtime and deploy code (if init function calls them) internal_functions_ir: list[IRnode] = []  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Unused Parameters",
        "body": "   _is_function_implemented does not use its parameter fn_name.   struct_literals does not use its parameter name.  Vyper - Vyper Compiler -   24  NoteVersion1NoteVersion1      \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Dangling Approval",
        "body": "  0  0  0  6  CS-MKSPFL-004  In  the  constructors  of  both  FlapperUniV2SwapOnly  and  FlapperUniV2,  an  approval  is  granted  to daiJoin  tokens (vat.hope(address(daiJoin))).  its  vat.dai  balance,   facilitating  exiting  or   joining  of  Dai   for  moving   In the most recent version of these contracts, the interaction with daiJoin has been handed over to the Splitter  contract.  Now  Flappers  handle  received  ERC-20  Dai  tokens  directly,  the  dangling  approval  is never used in the current Flapper's logic.    The unnecessary hope() calls have been removed. At the same time vat and daiJoin (immutables) have been removed from flapper as they are no longer needed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Incorrect Specification",
        "body": "  Library  Babylonian.sqrt()  provides  an  efficient  way  to  approximate  the  square  root  of  an  uint256. Nevertheless, the following specification is incorrect because the last if branch incorrectly checks xx with 0x8.  // this block is equivalent to r = uint256(1) << (BitMath.mostSignificantBit(x) / 2);  CS-MKSPFL-007  MakerDAO - Dss Flappers -   13  CriticalHighMediumLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSecurityLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                  \fFor  instance,  consider  x==1515,  its  hexadecimal  representation  is  0x5eb  which  has  11  bits  in  total. Thus  its  0-indexed  most  significant  bit  divided  by  2  results  in  5  and  r  should  be  32  (2^5),  while  the following code yields 16 (2^4).  // this block is equivalent to r = uint256(1) << (BitMath.mostSignificantBit(x) / 2); uint256 xx = x; uint256 r = 1; if (xx >= 0x100000000000000000000000000000000) {xx >>= 128;r <<= 64;} if (xx >= 0x10000000000000000) {xx >>= 64;r <<= 32;} if (xx >= 0x100000000) {xx >>= 32;r <<= 16;} if (xx >= 0x10000) {xx >>= 16;r <<= 8;} if (xx >= 0x100) {xx >>= 8;r <<= 4;} if (xx >= 0x10) {xx >>= 4;r <<= 2;} if (xx >= 0x8) {r <<= 1;}  is  used  as   r  it  may  not  be uint256(1)  <<  (BitMath.mostSignificantBit(x)  /  2)  as  specified,  it  is  a  sufficient approximation to the true square root, hence the algorithm's convergence remains unaffected.  iterative  algorithm.  While   the  starting  value   the   for     The code has been updated to match the behavior described in the original comment. The condition of the last if branch has been set to xx >= 0x4.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Initialization Does Not Check Divisor",
        "body": "  The  divisor  is  used  to  scale  the  MKR  price  to  NGT  (the  re-denominated  governance  token).  This  is expected to match the rate stored in the MKR and NGT converter MkrNgt.sol.  This divisor is set by the (untrusted) deployer of the contract. However, this value is not checked during the contract's (trusted) initialization.  CS-MKSPFL-009    The initialization code now features a sanity check for the divisor.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Missing Check for Bump",
        "body": "  initSplitter() does not check if bump is a multiple of RAY. In case it is not, there would be a dust vat.dai balance on Splitter accumulating over time, which cannot be used up in kick().  CS-MKSPFL-006    A check has been added to verify that bump is a multiple of RAY.  MakerDAO - Dss Flappers -   14  SecurityLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                  \f6.5   Missing Check of Reward Token on Farm Contract  initSplitter()  does  not  check  if  the  reward  token  of  the  farm  contract  matches  the  Dai  token.  In case  it  is  not,  notifyRewardAmount()  may  revert  due  to  insufficient  reward  token  sent  to  the  farm contract, and Dai cannot be claimed as reward.  CS-MKSPFL-005    The code of the initialization script now ensures that the farm's rewards token is DAI.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Splitter.cage() Does Not Lock the Splitter",
        "body": "  The  Splitter  distributes  funds  to  two  contracts.  Splitter.cage()  cages  one  of  these  contracts,  the Flapper, by calling FlapLike(flapper).cage(). This sets the Flapper's state variable live to 0 and subsequent calls to the flapper.exec() will revert since the contract is no longer live.  Meanwhile,  the  Splitter  contract  itself  is  not  caged.  splitter.kick()  can  be  executed  but  reverts upon calling flapper.exec().  However, in case all funds are directed to the farming engine (burn==0), the call to flapper.exec() will  be  bypassed,  and  splitter.kick()  can  still  be  executed  successfully  to  distribute  funds  to  the farm.  CS-MKSPFL-008    The live flag has been moved from Flapper to the Splitter. In case Splitter.cage() is called, the flag will be reset to 0 and the funds flow to both burning engine and the farming engine will be stopped.  MakerDAO - Dss Flappers -   15  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected              \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Live Flag Is Not Checked",
        "body": "  All state except the live flag of the Flapper is checked in the initialization code.  CS-MKSPFL-001    A sanity check has been added for the live flag.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   No Revert Reason When SplitterMom Stops",
        "body": " Splitter  SplitterMom  can  inhibit  Splitter  in  an  emergency.  It  does  so  by  setting  the  minimum  time  between  two executions of kick() to type.max(uint256). kick() will then revert due to the addition overflow:  CS-MKSPFL-002  require(block.timestamp >= zzz + hop, \"Splitter/kicked-too-soon\");  Except  when  kick()  has  never  been  executed  before  and  zzz  is  still  equal  to  0,  the  overflowing addition  will  cause  the  execution  to  revert  and  the  require  statement  will  not  emit  the  message \"Splitter/kicked-too-soon\".  MakerDAO states:  This is deemed an acceptable trade-off as this solution allows not having to read an additional storage variable.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Redundant daiJoin Field in Config",
        "body": "  In FlapperInit.sol, two structs (FlapperUniV2Config and SplitterConfig) are passed as the initialization  configuration  for  initFlapperUniV2  and  initSplitter  respectively.  Both  contain  the daiJoin address. daiJoin is already present in another input struct dss (DssInstance) however. It is redundant in the configuration.  CS-MKSPFL-003  MakerDAO - Dss Flappers -   16  InformationalVersion1InformationalVersion1InformationalVersion1          \fMakerDAO states:  This parameter is necessary to allow initialisation using nstJoin in the future. nstJoin will ultimately be added to DssInstance but we might need to deploy the Splitter before that happens.  MakerDAO - Dss Flappers -   17  \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Call to Vow.flap() Can Be Sandwiched",
        "body": "  Parameter want of the Flapper contracts provides slippage protection regarding the reference price feed. However,  depending  on  the  bump  and  want  parameters,  as  well  as  the  current  status  of  the  pool,  a kick()  operation  may  be  vulnerable  to  being  sandwiched  for  arbitrage  purposes.  Analysis  of  the parameters and pool status to prevent arbitrage is out of scope for this review.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Deployment Verification",
        "body": "  Since deployment of the contracts is not performed by the governance directly, special care has to be taken  that  all  contracts  have  been  deployed  correctly.  While  some  variables  can  be  checked  upon initialization through the PauseProxy, some things have to be checked beforehand.  We therefore assume that all mappings in the deployed contracts are checked for any unwanted entries (by  verifying  the  bytecode  of  the  contract  and  then  looking  at  the  emitted  events).  This  is  especially crucial for the wards mapping.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.3   Oracle Rounds Down the Price",
        "body": "  In  case  the  gem  token  used  is  a  re-denominated  version  of  an  existing  token,  the  OracleWrapper  will scale  down  the  price  of  an  existing  oracle  (pip)  by  a  certain  divisor.  If  the  return  value  from pip.read() is not a multiple of divisor, the rescaled price may be lower than the actual price (due to precision loss in the conversion).  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.4   Semantics of Flapper in the System",
        "body": "  The semantics of Flapper has slightly changed due to the introduction of the Splitter.  1. The  Vow  will  be  connected  with  the  Splitter  instead  of  directly  to  the  Flapper.  After  a  successful deployment and initialization, the Flapper state variable on Vow will return the Splitter address.  2. The interface of Flapper has been changed compared to the docs. For instance, the surplus auction has been changed to swaps/deposits on UniswapV2. And the entry point has been changed from kick() to exec().  MakerDAO - Dss Flappers -   18  NoteVersion1NoteVersion1NoteVersion1NoteVersion1              \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Gas Optimizations",
        "body": "   The state variables _name, _symbol and _decimals could be declared as constants. As a result, the compiler does not reserve a storage slot for these variables, and every occurrence is replaced by  the  respective  value.  Compared  to  regular  state  variables,  the  gas  costs  of  constant  and immutable variables are much lower. For a constant variable, the expression assigned to it is copied to  all  the  places  where  it  is  accessed  and  also  re-evaluated  each  time.  This  allows  for  local optimizations. Immutable variables are evaluated once at construction time and their value is copied to all the places in the code where they are accessed. For these values, 32 bytes are reserved, even if  they  would  fit  in  fewer  bytes.  Due  to  this,  constant  values  can  sometimes  be  cheaper  than immutable values. (see Solidity docs)  CS-FRTK-001  recipient.  Because    _transfer() does not need to use safeMath when modifying the _balances of the sender and the  in detectTransferRestriction()  to  ensure  sufficient  funds  for  the  transfer.  And  the  recipient's balance is always less or equal to totalSupply, in case totalSupply does not overflow during minting, the recipient's balance will never overflow.  sender's   checked   balance   already   been   has   the    _mint() does not need to use safeMath when updating _balances[account]. The balance of any  account  is  always  less  or  equal  to  totalSupply.In  case  the  previous  update  to _totalSupply does not overflow, _balances[account] will not overflow as well. This applies to the updates of _totalSupply in _burn() as well.   The  check  of  onlyOwner  is  redundant  for  internal  function  _mint(),  because  _mint()  is  only called by the external function mintTo(), which is already marked with modifier onlyOwner. This applies to the internal function _burn() as well.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Indexed Fields of Events",
        "body": "  The events Burn, Mint, Block and Unblock do not mark the field code as indexed. Indexing fields in events allows to easily search for certain events. code is not a random number but is a limited set and could be indexed.  CS-FRTK-002  Fire Group Ltd. states:  The field code is more an add-on-info for the reason of events. At the time of writing the contract, searching based on codes seemed not to be a requirement. Thus, it was decided to not index the code part of the event.  Fire Group Ltd. - Firetoken -   10  InformationalVersion1InformationalVersion1        \f6.3   Missing Events of KYC Roles Updates  The  contract  owner's  call  to  addUserListToKycRole()  and  removeUserFromKycRole()  will update the KYC roles, nevertheless, no events will be emitted to reflect the storage modification.  CS-FRTK-003  Fire Group Ltd. states:  KYC data is stored off-chain while executing the KYC processes. Thus, it was decided to not emit events for adding and removing KYC roles as this information is available off-chain.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Redundant Transfer Restriction",
        "body": "  Without specifications it is unclear if address(0) is an address that has transfer restrictions in the _kyc set or not. In case it does have transfer restrictions and is not part of the set, the requires in _transfer are redundant.  CS-FRTK-004  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Unused Variable _propertyAmountLocks",
        "body": "  The contract defines a state variable called _propertyAmountLocks but it is not used.  CS-FRTK-005  Fire Group Ltd. - Firetoken -   11  InformationalVersion1InformationalVersion1InformationalVersion1          \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   No Way to Recover ETH or Token Sent to the",
        "body": " Contract  The  contract  has  no  functionality  to  recover  ETH  or  token  sent  to  the  contract.  All  funds  sent  to  the contract will be locked forever.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Reserve Code <100 for Contract Internal Use",
        "body": "  When  the  owner  inserts  a  new  code  into  the  mapping,  the  code  is  required  to  be  larger  than  100. Whereas only less than 6 are used in the constructor, the rest are unused.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Unusual Decimals",
        "body": "  The  token  has  only  5  decimals.  Most  contracts  have  18  decimals  which  is  the  standard  base  in  the Ethereum network. Many issues can arise when a token with other than 18 decimals shall be included in third party protocols. Hence, Fire Group Ltd. should carefully evaluate if it is necessary to use 5 decimals and state this very clearly everywhere (in-line documentation, online documentation, website and if other protocols are using the token) to mitigate future issues.  Fire Group Ltd. - Firetoken -   12  NoteVersion1NoteVersion1NoteVersion1          \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Double Evaluation of Range's Start",
        "body": "  CS-VYPER_FEBRUARY_2024-002  The start of a range is evaluated twice, the result of the first evaluation is used as the actual starting value of the iteration. The second evaluation, which happens after the evaluation of the end argument, is used to ensure that start<=end and to compute the amount of rounds to be done.  Below is an example of this behavior. The starting value of i is max_value(uint256), the amount of iterations to be done is end-start = 3 - 1 = 2. Calling the function returns hence [11579208923 7316195423570985008687907853269984665640564039457584007913129639935,  0].  This example further exploits this behavior to silently overflow the uint256 type with the iterator variable.  @external def foo() -> DynArray[uint256, 3]:     x:DynArray[uint256, 3] = [1,3,max_value(uint256)]     res: DynArray[uint256, 3] = empty(DynArray[uint256, 3])     for i:uint256 in range(x.pop(),x.pop(), bound = 3):         res.append(i)      return res  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   Mistyped Loop Iterable",
        "body": "  Vyper - Vyper Compiler -   13  CorrectnessHighVersion1CorrectnessMediumVersion1CorrectnessMediumVersion1                \fIf a loop is defined over some non-literal static or dynamic array, the type obtained from the annotation of the  iterator  is  not  used  to  type-check  the  iterable.  If  the  iterable's  value  type  does  not  match  the annotation, the type-checker will miss it and the compiler will later panic during code generation due to some assertion.  CS-VYPER_FEBRUARY_2024-003  For  vyper.exceptions.CodegenPanic: unhandled exception , parse_For.  example,   following   crashes   code   the   the   compiler   with  @external @pure def foo() :     s:int256[3] = [1,-1,1]     for i:uint256 in s:         print(i)  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.4   Overriding Storage Allocator Does Not Handle",
        "body": " Reentrant Functions Properly  CS-VYPER_FEBRUARY_2024-004  OverridingStorageAllocator.set_storage_slots_with_overrides()  the FunctionDef  AST  nodes  of  the  top-level  module  to  find  non-reentrant  functions.  If  one  is  found,  the compiler reserves some slot according to what was provided in the JSON file of storage slots overrides and  annotates  the  function  type  with  the  given  reentrant  slot.  However,  for  the  next  functions,  the compiler will not annotate the function type with any slot. The issue is later caught at the code generation phase, where the compiler will crash.  iterates  over   For example, the following example would crash with AttributeError: 'ContractFunctionT' o bject has no attribute 'reentrancy_key_position'.  @nonreentrant @external def a():     pass  @nonreentrant @external def b():     pass  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.5   Overriding Storage Allocator Does Not Handle",
        "body": " Stateful Modules  CS-VYPER_FEBRUARY_2024-005  Vyper - Vyper Compiler -   14  CorrectnessMediumVersion1CorrectnessMediumVersion1            \fOverridingStorageAllocator.set_storage_slots_with_overrides()  does  not  handle stateful module imports and initialization properly and will not allocate storage and transient storage slots for  variables  or  reentrant  functions  defined  in  a  sub-module.  The  issue  is  only  caught  at  the  code generation stage and would most likely result in the compiler panicking.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.6   Ambiguous Imports",
        "body": "  CS-VYPER_FEBRUARY_2024-006  If a module is named after one of the built-in interfaces Vyper provides and if that module is accessed via the path ethereum.ercs, then the module will be shadowed by the built-in interface. For example, if a module is named ERC20 and is accessed via from ethereum.ercs import ERC20, the Vyper builtin ERC20 will be imported instead.  Similarly, if a module vyper.interfaces.ERC20 is defined and imported, the compiler would fail with  vyper.exceptions.ModuleNotFound: vyper.interfaces.ERC20 (hint: try renaming ` vyper.interfaces` to `ethereum.ercs`).  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.7   Assigning a Builtin to Itself Leads to Panic",
        "body": "  Assigning some builtin to itself is not prevented and leads to a compiler panic.  For  example,  compiling  the  following  code  leads  the  compiler  to  raise  the  following  exception: CodegenPanic: unhandled exception , parse_Name.  CS-VYPER_FEBRUARY_2024-007  @external def foo():     convert = convert  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.8   Codegen Fails for Raise and Assert With",
        "body": " Non-Memory Messages  The  code  generation  for  Raise  and  Assert  fails  if  the  reason  string  is  not  a  memory  variable.  This behavior is due to Stmt._assert_reason calling make_byte_array_copier with buf instead of an IR node whose value is buf and whose location is memory as it would be done by ensure_in_memory for example.  CS-VYPER_FEBRUARY_2024-008  For  example,  compiling  vyper.exceptions.CodegenPanic: unhandled exception 'int' object has no attribute 'typ', parse_Raise.  following  contract   leads   the   to   the  compiler  panicking  with  a:String[1] @external def foo():  Vyper - Vyper Compiler -   15  DesignLowVersion1DesignLowVersion1CorrectnessLowVersion1                  \f    self.a = \"a\"     raise self.a  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.9   Constants Cannot Be Imported From .vyi",
        "body": " Files  Constants  cannot  be  imported  from  .vyi  interface  files.  This  behavior  would  be  useful  as  one  would usually want this for types dependent on some value (for example a static array with some length).  CS-VYPER_FEBRUARY_2024-009  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.10   External Call Kwargs Allowed for Call to ",
        "body": " __init__  ContractFunctionT.fetch_call_return depends on self.is_internal to prevent or not the call  from  being  passed  some  external  call  reserved  kwargs  such  as  gas  or  value.  However,  an __init__ function has self.is_internal = False so it is possible to pass kwags when calling it although it should not be allowed.  For example, the contract below compiles:  CS-VYPER_FEBRUARY_2024-010  # main.vy import bar  initializes: bar  @deploy @payable def __init__():     bar.__init__(12, gas=14, value = 12, skip_contract_check= True)  # bar.vy a:uint256  @deploy @payable def __init__(x: uint256):     self.a = x  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.11   Immutables Allowed to Be Used as Default",
        "body": " Arguments  Vyper - Vyper Compiler -   16  DesignLowVersion1CorrectnessLowVersion1DesignLowVersion1                  \fAccording  to  the  documentation,  the  default  arguments  of  a  function  must  be  literals  or  environment variables, however, immutables are allowed to be used as default arguments.  CS-VYPER_FEBRUARY_2024-011  The following contract compiles:  x:immutable(uint256)  @deploy def __init__():     x = 1  @external def foo(val:uint256 = x):     pass  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.12   Imprecise Duplicate Import Check",
        "body": "  In  ModuleAnalyzer._load_import_helper(),  the  following  check  ensures  that  a  given  file  is  not imported multiple times:  if path in self._imported_modules:     previous_import_stmt = self._imported_modules[path]     raise DuplicateImport(f\"{alias} imported more than once!\", previous_import_stmt, node)  CS-VYPER_FEBRUARY_2024-012  However, the check is not performed using a normalized path as it is being done in the input bundle. This means that for a lib1 in the directory project, it can be bypassed as follows:  import lib1 from ..project import lib1 as lib2  Note however that since paths are normalized in the input bundle, if the two modules are initialized, for example, the compiler will raise an exception.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.13   Incorrect Error Messages",
        "body": "  In  VariableDecl.validate(),  instead  of  calling  the  method  self._pretty_location()  to pretty-print the location of the given variable, self._pretty_location is used.  In  _CreateBase.build_IR,  context.check_is_not_constant  should  be  called  with  an f-string and not a regular string to have self._id as the id of the built-in in the error message.  CS-VYPER_FEBRUARY_2024-013  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.14   Incorrect IR Identifier",
        "body": "  CS-VYPER_FEBRUARY_2024-014  Vyper - Vyper Compiler -   17  DesignLowVersion1CorrectnessLowVersion1CorrectnessLowVersion1                    \fThe new deploy visibility is used to abstract away the fact that the constructor can now behave either as an  actual  constructor  or  as  internal  functions  callable  in  the  deployment  context.  However, _FuncIRInfo.visibility()  has  not  been  updated  with  leading _FuncIRInfo.ir_identifier()  to  return  some  identifier  marked  as  external  although  the constructor might be treated as an internal function.  this  new  semantics,   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.15   Initialization Analysis Can Have False",
        "body": " Positive  CS-VYPER_FEBRUARY_2024-015  When analyzing that the constructor of an imported module is called in the constructor of a module that imports  and  initializes  it,  ModuleAnalyzer.validate_initialized_modules()  only  checks  that an  __init__  call  for  the  imported  module  appears  once  and  only  once  in  the  AST  of  the  importing module's  constructor.  For  similar  reasons  as  the  PR3162  issue,  this  is  not  enough  as  the  call  might appear in a loop or in an if else statement. It could hence be possible either to have some call path that never calls the constructor of the imported module or to have it called multiple times.  For example, given some module a with an __init__ function, the following code would compile without any  error  although  the  imported  module's  __init__  function  is  either  called  twice  or  never  called depending on the value of b.  import a initializes: a  @deploy def __init__(b:bool):     if b:         for i:uint256 in range(2):             a.__init__()     else:         pass  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.16   Misleading Error Message When Using ",
        "body": " @deploy on a Regular Function in an Interface  In ContractFunctionT.from_FunctionDef(), the following check is performed:  CS-VYPER_FEBRUARY_2024-016  if function_visibility == FunctionVisibility.DEPLOY and funcdef.name != \"__init__\": raise FunctionDeclarationException(     \"Only constructors can be marked as `@deploy`!\", funcdef )  this   check  moved   both Having  ContractFunctionT.from_FunctionDef() and ContractFunctionT.from_vyi() would allow performing  the  same  check  for  imported  interfaces.  Currently,  if  a  regular  function  in  an  interface  is decorated  as  @deploy,  fail  with  a  misleading  error  message Internal functions in `.vyi` files are not allowed!?  _parsed_decorators  which   compiler  will   called   the   by   to   is   Vyper - Vyper Compiler -   18  DesignLowVersion1DesignLowVersion1            \f5.17   Module Use Analysis Miss Nonreentrant Functions  When  a  module  is  never  initialized,  it  should  only  be  allowed  to  call  functions  that  are  stateless  in  the sense  that  they  do  not  access  storage  or  immutables.  However,  the  analysis  does  not  account  for non-reentrant decorators. If a non-initialized module's non-reentrant function is called, the compiler will crash during code generation after successfully passing semantic analysis.  Compiling the example below crashes the compiler with AttributeError: 'ContractFunctionT'  object has no attribute 'reentrancy_key_position'.  CS-VYPER_FEBRUARY_2024-017  # main.vy import lib  @external def foo():     lib.bar()  # lib.vy @nonreentrant @internal def bar():     pass  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.18   State Modifications Inside range Not Caught",
        "body": " at Type-Checking  Sub-expressions of a range expression should have a constant constancy, in other words, they should not be able to update the storage. However, this is not enforced during type-checking and is only caught by the following assertion in ir_for_self_call():  CS-VYPER_FEBRUARY_2024-018  # CMC 2023-05-17 this seems like it is already caught in typechecker if context.is_constant() and func_t.is_mutable:     raise StateAccessViolation(         f\"May not call state modifying function \"         f\"'{method_name}' within {context.pp_constancy()}.\",         stmt_expr,     )  This is the case of the example below:  x:uint256  Vyper - Vyper Compiler -   19  CorrectnessLowVersion1DesignLowVersion1            \f@internal def bar() -> uint256:     self.x = 1     return 1  @external def foo():     for i:uint256 in range(self.bar(), bound=10):         pass  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.19   Storage Variable of Type ModuleT and",
        "body": " InterfaceT Not Prevented  Since  ModuleT  is  a  Vyper  type,  and  since  ModuleT._invalid_locations  does  not  contain DataLocation.STORAGE, it is possible to use it as a type for a storage variable while this should not be possible.  The contract below will compile, and calling foo() will return (1,2).  CS-VYPER_FEBRUARY_2024-019  # main.vy import lib  initializes: lib  x:lib y:lib  @external def foo() -> (uint256, uint256):     return (self.x.bar(), self.y.bar())  # lib.vy a:uint256  @internal def bar()->uint256:     self.a += 1     return self.a  Note that a similar behavior can be observed for InterfaceT.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.20   Un-precise Interface Body Check",
        "body": "  CS-VYPER_FEBRUARY_2024-020  Vyper - Vyper Compiler -   20  DesignLowVersion1DesignLowVersion1            \fIn interface files (.vyi), function bodies should only contain the AST Ellipsis node (...). However given how the corresponding check is done, any statement node with a value field containing an Ellipsis node can be used in place of the Expr AST node.  if len(funcdef.body) != 1 or not isinstance(funcdef.body[0].get(\"value\"), vy_ast.Ellipsis):     raise FunctionDeclarationException(         \"function body in an interface can only be `...`!\", funcdef     )  For example, compiling a contract importing the following interface does not raise any exception:  @external def foo():     log ...  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.21   Variable Shadowing",
        "body": "  In InterfaceT._from_lists(), the argument name is shadowed by the different loop iterators. This leads  some  function,  event,  or  struct  name  to  be  used  as  the  name  of  the  InterfaceT  to  be constructed.  CS-VYPER_FEBRUARY_2024-021  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.22   IfExp's body and orelse Children Can Have",
        "body": " Arbitrary VyperType  The  ExprVisitor  does  not  enforce  any  type  on  the  IfExp's  body  and  orelse  children  except  that they should have the same type. This means that using arbitrary VyperType subclasses like ModuleT, BuiltinFunctionT  or  SelfT  is  not  prevented  and  either  results  in  a  successful  compilation  or  the compiler panicking during the code generation phase.  CS-VYPER_FEBRUARY_2024-022  Note that this issue relates to Issue_3513  For example, the following contract compiles successfully:  # main.vy import lib1  initializes: lib1  @external def foo():     (lib1 if True else lib1).bar(1)  # lib1.vy  @internal  Vyper - Vyper Compiler -   21  CorrectnessLowVersion1DesignLowVersion1            \fdef bar(x: uint256):     pass  The contracts below would fail to compile respectively with:   vyper.exceptions.CodegenPanic: unhandled exception None, parse_Attribute   vyper.exceptions.CompilerPanic: Unreachable  @external def foo():     x:uint256 = (self if True else self).balance  @external def foo():     x:uint256 = (min if True else min)(1,2)  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.23   flag Can't Be Imported",
        "body": "  While it is possible to import events and struct types both from .vy and .vyi files, it is not possible to import flags.  For interfaces, this is because InterfaceT does not hold the flags defined in the interface and hence InterfaceT.get_type_member() only returns the set of events and struct types defined.  For modules, similarly, flag types are not added to the set of members of the ModuleT at construction time.  CS-VYPER_FEBRUARY_2024-023  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.24   range Over Decimal Is Not Prevented",
        "body": "  The  range()  built-in  function  should  only  accept  integer  types.  However,  this  is  not  enforced  and instead, only the AST type of the arguments of the range is checked: either both start and stop should be Num nodes, or bound should be a Num node. This means that having them as decimal numbers is not prevented since Vyper AST type Decimal is a subclass of Num.  CS-VYPER_FEBRUARY_2024-024  For example, the following code is valid:  @external @pure def foo():     end: decimal = 2.2     for i: decimal in range(1.1, end, bound=10.1):         pass  Vyper - Vyper Compiler -   22  DesignLowVersion1DesignLowVersion1            \f6   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Inconsistent Documentation",
        "body": "  The function parse_to_ast_with_settings is documented as taking a contract_name argument, but it does not. Additionally, the documentation mentions twice the source_id argument.  CS-VYPER_FEBRUARY_2024-025  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Misleading Function Name",
        "body": "  The function _parse_and_fold_ast is misleading as it does not perform any folding on the AST.  CS-VYPER_FEBRUARY_2024-026  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Range's bound Typing",
        "body": "  CS-VYPER_FEBRUARY_2024-027  When  the  compiler  type-checks  a  range  expression,  it  ensures  that  the  start,  stop,  and  bound expressions all have the same type and that this type matches the one provided in the annotation of the iterator. However, it might be that the bound is legitimately greater than the maximum value of the given type, in such case the compiler would raise an error.  For example, the following two programs should behave similarly, however, the first one would compile successfully and one could call foo() without any revert while the second one would not compile as 137 is not an int8.  @external def foo():     # the loop performs 137 iterations     for i:int8 in range(-10, max_value(int8)):         pass  @external def foo():     end:int8 = max_value(int8)     for i:int8 in range(-10, end, bound = 137):         pass  Vyper - Vyper Compiler -   23  InformationalVersion1InformationalVersion1InformationalVersion1            \f6.4   Redundant Check of Module Use  CS-VYPER_FEBRUARY_2024-028  In ExprVisitor.visit_Call(), the following is done:  if self.function_analyzer: self._check_call_mutability(func_type.mutability)  for s in func_type.get_variable_accesses():     if s.variable.is_module_variable():         self.function_analyzer._check_module_use(node.func)  if func_type.is_deploy and not self.func.is_deploy:     raise CallViolation(         f\"Cannot call an @{func_type.visibility} function from \"         f\"an @{self.func.visibility} function!\",         node,     )  The call to _check_module_use() is done as many times as there are variable accesses in the called function,  which  is  redundant  as  it  does  not  depend  on  the  variable  accesses  and  could  be  done  only once.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   ModuleT Cached Properties Dependent on",
        "body": " Properties  In  ModuleT,  several  cached  properties  such  as  variables,  functions  or  immutables  depend  on some  non-cached  properties.  This  means  that  if  a  cached  property  is  to  be  used  before  the  value returned  by  the  correspondent  property  is  final,  the  compiler  will  always  use  this  out-of-date  cached value. Although no example of this behavior was found, such a pattern can lead to issues if, in the future, some  of  these  properties  were  to  be  used  before  the  corresponding  cached  property  is  fully  set.  An example  would  be  if  functions  were  to  be  read  before  the  AST  expansion  which  updates function_defs.  CS-VYPER_FEBRUARY_2024-029  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   enum Not Renamed to flag",
        "body": "  PR3697 renames the enum keyword to flag however not all occurrences of enum are renamed in the code, comments and documentation.  For example FlagT._enum_members should be renamed to FlagT._flag_members.  CS-VYPER_FEBRUARY_2024-030  Vyper - Vyper Compiler -   24  InformationalVersion1InformationalVersion1InformationalVersion1          \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Ambiguous Imports Are Allowed",
        "body": "  In  InputBundle.load_file(),  once  a  valid  path  is  found,  the  method  returns  even  though  there might be multiple matching paths. It could be beneficial to raise an exception in case there are multiple paths to avoid any ambiguous import.  Vyper - Vyper Compiler -   25  NoteVersion1  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Chainlink Query May Revert",
        "body": "  The Pool contract relies on ChainLink assumptions that do not hold. Chainlink's round IDs do not always increase monotonically. Therefore, the getRoundData queries can revert. Relying on _roundId-- in GeometricBrownianMotionOracle.getHistoricalPrice is not correct, since querying an invalid ID will make the swap revert.    The  call  to  the  price  feed's  getRoundData  function  has  been  moved  in  a  try/catch  block  and  the function returns (0, 0) if the oracle call reverts.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Dynamic Weights Changing Problem",
        "body": "  Swaap Labs - Swaap Core V1 -   13  CriticalHighCodeCorrectedCodeCorrectedMediumCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedDesignHighVersion1CodeCorrectedSecurityHighVersion1CodeCorrected                 \fAssume the pool has 10 X and 10 Y tokens that both have weight of 1. Initial invariant:  10X * 10Y = 100 Now  assume  attacker  sees  an  update  in  oracle  price,  that  will  change  the  weight  of  X  tokens  to  2. Attacker performs a trade: in 990 Y, out 9.9 X. New constant product:  After ChainLink price update, the X tokens weight become 2. New invariant:  (0.1X)2 * 1000Y = 10  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "0.1X * 1000Y = 100",
        "body": "  In 0.9 X, out 990 Y. The invariant holds:  New constant product:  (1X)2 * 10Y = 10  With 2 these trades that surround the price update, attacker profited by 9 X tokens.  The sandwiching can be performed using the Flashbots service. This issue is similar to the one that was discovered in Curve.    Swaap Labs introduced 2 solutions:  1. The   relative   price  AfterSwapPoolPrice/OraclePrice <= 102% + fee  difference   between   oracle   and   pool   price   is   capped:  2. If the user sells token that is in shortage, and the token price experienced increase in the current  block, extra fee is applied to compensate for a possible impermanent loss of the pool.  Together these 2 solutions help with the weight change sandwich attack.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Geometric Brownian Motion Parameter",
        "body": " Estimation  For a returns R over time window T, the code estimates Geometric Brownian Motion parameters using these formulas:  Ri  N \u2211 i = 0 T  \u03bc =  N \u2211 i = 0  \u03c32 =  (Ri \u2212 \u03bc)2 + (T \u2212 N) * \u03bc2  T \u2212 1  According to specification, the second term in s computation is responsible for times, when the sample is missing and thus the return at that point is assumed to be 0.  Assuming dt is a regular sampling period, the N = T/dt - number of samples. In that case, a common way to estimate the GBM parameters using successive observations method is given by:  Ri  N \u2211 i = 0 N  \u0302\u03bc =  N \u2211 i = 0  \u0302\u03c32 =  (Ri \u2212 \u0302\u03bc)2  T N \u2211 i = 0  (Ri \u2212 \u0302\u03bc)2  T * dt N \u2211 i = 0  Ri  T + \u03c32  2  \u03c32 =  \u0302\u03c32 dt =  \u03bc =  \u0302\u03bc  dt + \u03c32  2 =  Swaap Labs - Swaap Core V1 -   14  DesignMediumVersion1CodeCorrected        \fComparing these estimations to code estimations, we can see following discrepancies:  1. Code m estimate lacks a 0.5 * s^2 term, and thus will be underestimated. 2. Code s estimate lacks a dt scaling factor, and thus will be overestimated. 3. Code  s  estimate  has  a  (T  -  N)/T  *  m^2  term,  that  also  doesn't  help  with  precision  of  the  estimate.  To  summarize,  the  outputs  of  GeometricBrownianMotionOracle.getStatistics  can  have  big errors, that might lead to impermanent losses of LPs as well as to overpriced swaps.  In addition, for Chainlink price oracles the sampling periods are not consistent and affected by Deviation and  Heartbeat  Thresholds.  Thus  the  code  computed  estimations  in  most  cases  will  fail  to  accurately estimate the price evolution process, even if it has the GBM nature.  Code modified:  The  parameters  estimation  method  has  been  modified  to  use  the  price  ratios  between  two  successive period instead of the return. The new implementation uses the following formulas:  Si = pricei \u0394i = timestampi \u2212 timestampi \u2212 1 T log(Sn  \u03bc = 1  )  S0  \u03c32 = 1  N \u2212 1 [\u22121  T log(Sn  )2 +  N \u2211 i = 1  log( Si Si \u2212 1 \u0394i  )2  ]  S0 These formulas come from the maximum likelihood estimation (MLE) for the GBM parameters. However to be the true MLE, mu should have a correction factor of + 0.5 * sigma^2. This correction factor is not  needed  here  because  Swaap  Labs  computes  the  z-percentile  of  the  lognormal  distribution,  which only needs mu + 0.5 * sigma^2 - 0.5 * sigma^2 = mu. Thus, the computed mu and sigma are consistent with their future usage.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   Inverted Token Performance",
        "body": "  The signature of the function is:  _getTokenPerformance(uint256 initialPrice, uint256 latestPrice)  and  computes  the  performance  ratio  as  latestPrice  /  initialprice.  However,  the  function  is (latestPrice_param, always  initialPrice_param),  ratio initialPrice_param / latestPrice_param.  arguments  result  of   inverted  performance   the  call  will  yield   called  with   the  the   following   order   the   the   in     Natspec and _getTokenPerformance call input order was fixed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   View Functions Reentrancy",
        "body": "  Some  view  functions  don't  use  the  _viewlock_  modifier.  In  case  of  reentrancy  due  to  ERC20  token calls (e.g. ERC777), these getters can return unreliable data. This may break the integration with other contracts and systems that rely on these getters. Such getter functions are:  Swaap Labs - Swaap Core V1 -   15  CorrectnessMediumVersion1CodeCorrectedSecurityMediumVersion1CodeCorrected                \f getAmountOutGivenInMMM  Please note, this list might be incomplete. Any function of a contract that does external call need to be lock or viewlock protected, if other external contract might rely on the data from this contract, such as spot prices, weights, etc.    View locks have been added to all view functions in the Pool.sol contract.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.6   Zero Exit Fee Allows Just-In-Time Liquidity",
        "body": " Provision  Since the system is not totally impermanent loss resistant, liquidity providers are still exposed to a risk. To  cope  with  the  risk,  malicious  liquidity  providers  can  sandwich  large  swaps  transactions  and  collect most of the swap fee without the risk of an impermanent loss.    JIT liquidity provision is mitigated by the use of a cooldown timer of 2 blocks. A LP that provided liquidity to  a  pool  cannot  exit  the  pool  or  transfer  LP  tokens  (by  either  transfer  or  approval  and transferFrom) for a period of 2 blocks after the liquidity provision.  However, this may block proxy contracts to manage funds for users. To cope with this issue, Swaap Labs added the joinPoolForTxOrigin, a function that pulls funds from msg.sender, but deposits them to the  tx.origin.  Since  it  is  not  the  authorization  by  the  tx.origin,  this  does  not  raise  problems  like https://swcregistry.io/docs/SWC-115.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.7   Num.abs Function Name",
        "body": "  The name of Num.abs function does not match its functionality.    The Num.abs function has been renamed Num.positivePart.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.8   getRoundData Function Duplication",
        "body": "  function  getRoundData  and   in functionality  The  GeometricBrownianMotion and in ChainlinkUtils. Functionality duplication should be avoided as it increases the amount of code to deploy and deteriorates code maintainability.  is  duplicated.   implemented   its   is   It   Swaap Labs - Swaap Core V1 -   16  DesignMediumVersion1CodeCorrectedCorrectnessLowVersion2CodeCorrectedDesignLowVersion2CodeCorrected                        \f  The getRoundData function in GeometricBrownianMotion has been removed and its use has been replaced by the getRoundData function from ChainlinkUtils.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.9   Compiler Version Not Fixed and Outdated",
        "body": "  The  solidity  compiler  is  not  fixed  in  the  contracts.  The  version,  however,  is  defined  in  the truffle-config.js to be 0.8.0.  In the Factory contract the following pragma directive is used:  pragma solidity ^0.8.0;  Known bugs in version 0.8.0 are:  https://github.com/ethereum/solidity/blob/develop/docs/bugs_by_version.json#L1531  More information about these bugs can be found here:  https://docs.soliditylang.org/en/latest/bugs.html  At the time of writing the most recent Solidity release is version 0.8.12 which contains some bugfixes.    The compiler was fixed to version 0.8.12.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.10   Gas Inefficiency and Duplicated Checks",
        "body": "  1. In  the  GeometricBrownianMotionOracle.getHistoricalPrices  function,  idx  is  set  to hpParameters.lookbackInRound + 1 and then directly to 1. The second first assignation has no effect.  2. Math.getLogSpreadFactor checks horizon and variance for >= 0, this check is useless since  both values are uint256.  3. Math.getLogSpreadFactor does division by two with 5 * Const.BONE / 10, simply dividing  by 2 would save gas.  4. In  Math.getInAmountAtprice   it   is  possible   to  pack  computations   to  save  calls   to  LogExpMath.pow.  5. Some  state  variables  can   fit   in  smaller   types   (e.g.,  with   its  current  bounds,  dynamicCoverageFeesZ could fit in a uint64). Saving storage slots might save gas.  6. TokenBase's  _burn  and  _move  functions  check  that  there  is  enough  balance,  the  check  for  underflow is by default since compiler version 0.8.0.  7. PoolToken.transferFrom check that there is enough allowance, the check for underflow is by  default since compiler version 0.8.0.  8. PoolToken's  _name,  _symbol  and  _decimal  can  be  constant  and  their  respective  getter  functions can be external. This will save gas.  Swaap Labs - Swaap Core V1 -   17  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \f9. The overflow checks in numerous Num functions are not necessary anymore since compiler version ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "0.8.0,  which  features  automatic  overflow  check.  The  division  by  zero  checks  are  not  necessary,",
        "body": " solidity division will revert on a division by 0.  10. Elements  of  the  Pool.Record  struct  can  have  a  smaller  type  (e.g.  index,  denorm)  and  be  reordered to save storage.  11. The Pool's state variable _factory can be immutable.  12. Pool.joinPool, Pool.getAmountOutGivenInMMM, Pool.finalize can be external.  13. The  check  for  _controller  address  and  finalization  in  Pool.bindMMM  are  redundant  with  the  ones in Pool.rebindMMM.  14. When  resetting  storage  slots  on  mappings,  e.g.  in  unbindMMM,  the  use  of  delete  is  recommended for lower gas usage.  15. The  second  require  of  _getAmountOutGivenInMMMWithTimestamp  is  a  less  strict  version  of  the first requirement.  Version 2:  1. Const.MAX_IN_RATIO and Const.MAX_OUT_RATIO are never used in the code, they should be  removed.  2. getMMMWeight  is  always  called  with  shortage  =  true,  removing  the  argument  and  code  related to shortage = false will save gas.    1. idx is set to 1 at variable declaration.  2. Both checks for >= 0 have been removed.  3. The multiplication by 5 / 10 has been replaced by a division by 2.  4. The terms under w_o / (w_o + w_i) have been grouped together.  5. Acknowledged. Some state variables have been changed to use a smaller type.  6. The checks for sufficient balance have been removed.  7. The check for sufficient allowance has been removed.  8. PoolToken's  _name,  _symbol  and  _decimal  have  been  changed  to  constant  and  their  respective getter function have external visibility.  9. Unnecessary overflow checks in Num library have been removed.  10. index and denorm types have been reduced to uint8 and uint80 resp.  11. _factory state variable has been changed to immutable.  12. Pool.joinPool,  Pool.getAmountOutGivenInMMM,  Pool.finalize  visibility  has  been  changed to external.  13. The checks have been moved to the common _rebindMMM function.  14. delete is now used to reset the storage fields in the mappings.  15. Both require have been removed. The check has been replaced by the oracle update sandwich  protection.  Version 2:  1. Unused constants have been removed.  2. The shortage parameter of function getMMMWeight has been removed.  Swaap Labs - Swaap Core V1 -   18  \f7.11   Num Library Function Visibility  The functions of Num library have public visibility. This way, any contract that will need to deploy this library, will use it as an external contract. It means that any call to the library functions will result in quite expensive CALL opcode. If the visibility of those functions were internal, the function code would be then  inlined  at  the  point  of  use.  This  way  bytecode  size  of  Pool  will  be  smaller  and  gas  cost  for  each see: library  https://docs.soliditylang.org/en/latest/contracts.html#libraries  operation   smaller   more   well.   info   call   For   will   be   as     The visibility of the functions in the Num library has been changed to internal.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.12   Specification Mismatch",
        "body": "  1. The formula provided in the documentation for getInAmountAtPrice multiplies the desired price by  w_out  /  w_in  which  is  wrong,  however  the  implementation  correctly  multiplies  by w_in / w_out.  2. In the whitepaper, when the stochastic buy-sell spread is computed, the p-percentile of the random  variable is divided by the latest oracle price, this is not the case in the implementation.  3. The @dev natspec of getNextSample is incomplete  4. The @dev natspec of getRoundData makes a wrong assumption, the function will revert if no data  can be found as specified in https://docs.chain.link/docs/faq/#can-the-data-feed-read-revert.  5. The  specification  of  some  public  and  external   functions,  e.g.  joinPool,  finalize,  calcSpotPrice, is missing.  6. The @notice natspec of rebindMMM is incomplete.  7. The  natspec  of  Pool._getTokenPerformance  defines  twice  the  first  parameter  and  not  the  second one  Version 2:  1. The  @dev  natspec  of  GeometricBrownianMotionOracle.getHistoricalPrices  does  not reflect the implementation. If no historical data was found, the latest data and startIndex == 0 will be returned. If round data is 0, the round will simply be skipped, the algorithm will not stop filling prices/timestamps.  2. The _getParametersEstimation doesn't describe all @param.  Specification partially corrected:  1. The formula in the documentation has been corrected.  2. Specification changed.  3. The @dev natspec for getNextSample has been completed.  4. The implementation of getRoundData now matches the natspec.  Swaap Labs - Swaap Core V1 -   19  DesignLowVersion1CodeCorrectedDesignLowVersion1Speci\ufb01cationChanged                \f5. Comments or natspec have been added for some public and external functions.  6. The natspec for rebindMMM has been completed.  7. The second parameter is now described in the natspec.  Version 2:  1. The @dev natspec has been updated to reflect the implementation.  2. The missing parameters natspec has been added.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.13   Time Window of 1 Will Revert",
        "body": "  A  time  window  of  1  second  will  make  getStatistics  revert  due  to  a  division  by  zero.  The Const.MIN_LOOKBACK_IN_SEC  limit  enforced  on  _priceStatisticsLookbackInSec  storage variable  in  setPriceStatisticsLookbackInSec  function  does  not  prevent  this  case  from happening.    If time window = 1, the variance and mean are considered to be 0.  Swaap Labs - Swaap Core V1 -   20  DesignLowVersion1CodeCorrected        \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Compatibility Issues Due to tx.origin",
        "body": "  The use of tx.origin limits certain functionality of the contract. Such contracts can be not deployable on chains that don't support ORIGIN opcode, e.g. Optimism. In addition, usage of this contract by wallet contracts like Gnosis wallet can also be limited.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   ERC20 Compatibility",
        "body": "  The _pull/_pushUnderlying functions of the Pool expect transferFrom and transfer to always return  a  boolean.  However,  some  tokens,  for  example  USDT,  do  not  follow  this  pattern  and  are  thus incompatible with the system. OpenZeppelin has a SafeERC20 library, which helps with such tokens.  In addition, the usage of ERC20 tokens with fees, rebalancing tokens, or tokens with reentrancies can be problematic to integrate. Swaap Labs needs to carefully consider what tokens can be supported by the Pool.  The _pull/_pushUnderlying functions have been modified to use the SafeERC20 library for token transfer.  Swaap Labs - Swaap Core V1 -   21  NoteVersion1NoteVersion1      \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Inefficient Transfer Hook",
        "body": "  The  internal  function  ERC20Farmable.beforeTokenTransfer  is  called  before  any  transfer  logic  is executed. Assuming that user A is farming on n and user B is farming on m farms without any overlap in the sets, then,   m+n addresses are loaded from storage at the very beginning,   m+n external calls are made,   m+n storage writes to corrections,   and more reads and writes.  Furthermore,  m  and  n  are  not  limited.  A  token  transfer  could  end  up  being  very  expensive  without  the user noticing. Hence, token transfers could easily fail by running out of gas.  Risk accepted:  1inch accepts the risk.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Insufficient Documentation",
        "body": "  1inch - Farming -   9  SecurityDesignCorrectnessCriticalHighMediumLowRiskAcceptedAcknowledgedCodePartiallyCorrectedDesignLowVersion1RiskAcceptedDesignLowVersion1Acknowledged                     \fDocumentation helps users, developers and others to understand a system in a shorter amount of time. Especially if the code is to be used as a library by other developers, it could help these to prevent errors. Otherwise, no assumptions on the code and its behavior can be made.  Currently, code is undocumented. Furthermore, no behavioral description is provided on what to expect from  a  function  call.  For  example,  it  is  undocumented  how  the  libraries  handle  errors  in  external contracts.  Acknowledged:  1inch replied:  Will be improved in the future.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   Lack of Events",
        "body": "  Typically,  events  help  track  the  state  of  the  smart  contract.  Some  functions,  such  as  startFarming, emit events while others do not emit any event. Some examples lacking event emissions are:   ERC20Farmable.farm()   ERC20Farmable.claim() and FarmingPool.claim()   ERC20Farmable.exit()   Public checkpointing functions   BaseFarm.setDistributor()  Code partially corrected:  An event has been added only for setDistributor().  1inch - Farming -   10  DesignLowVersion1CodePartiallyCorrected          \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  0  1  0  7  -Severity Findings  -Severity Findings   Gas Griefing   -Severity Findings  -Severity Findings   Commented Code    Farms Rely on Token to Checkpoint    Gas Inefficiencies   Ineffective period Check   Introduction of Batched Operations    Usage as a Library   farmingCheckpoint() Has No Functionality   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Gas Griefing",
        "body": "  ERC20Farmable  calls  farm  contracts  in  every  call  to  farmedPerToken()  to  query  information  with IFarm.farmedSinceCheckpointScaled() on how many rewards have been released so far. Even though  that  call  is  handled  with  a  try/catch  block  to  prevent  the  target  contract  from  reverting maliciously, it is still possible that the farm consumes all gas.  1. A malicious farm honeypots users into joining.  2. The malicious farm contract is upgraded through an upgradeability pattern.  3. Every call to farmedSinceCheckpointScaled() consumes all gas.  Now, following is not possible:   any ERC20Farmable transfer from an affected user   any ERC20Farmable transfer to an affected user   exiting the malicious farm   Claiming from the malicious farm  Ultimately, tokens will be locked for affected users.    1inch - Farming -   11  CriticalHighCodeCorrectedMediumLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSecurityHighVersion1CodeCorrected           \fThe call to IFarm.famedSinceCheckpointScaled() now has a gas limit. If the gas limit of 200000 is exceeded, the failure is handled by behaving equivalently to a revert in the farm contract.  Additionally, the static-call was wrapped inside an assembly block to prevent the return data bomb issue in the Solidity compiler (documented here: https://github.com/ethereum/solidity/issues/12306).  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Commented Code",
        "body": "  ERC20Farmable._getFarmedSinceCheckpointscaled  contains  commented  code.  Removing  the code could help keep the code cleaner such that it is easier to understand.    Commented out code has been replaced by calls to on onError().  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Farms Rely on Token to Checkpoint",
        "body": "  Farm._updateFarmingState() calls checkpoint() of an external ERC20Farmable contract. Then, the  ERC20Farmable  contract  calls  Farm.farmingCheckpoint().  However,  a  malicious ERC20Farmable  to Farm.farmingCheckpoint(). Hence, the farm checkpoints could remain without updates.  implementation   purposefully   could   leave   call   the   out     farmingCheckpoint has been removed from the farm contracts. Hence, there is no need to call it.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Gas Inefficiencies",
        "body": "  In multiple locations code could be optimized to reduce gas cost. Some examples are:   Function UserAccounting.checkpoint() loads the stored update time and the store farmed per token  value  from  storage.  However,  to  correctly  call  that  function  it  is  required  to  first  call farmedPerToken() which also loads the same variable from storage. Hence, storage reads could be prevented.  In  function  FarmingPool.exit()  balanceOf  is  called  twice.  However,  the  second  time  it  is called it is evident that it must be zero.   _beforeTokenTransfer could exit early for self-transfers.   Casting  period  to  uint40  when  the  input  could  have  been  restricted  to  be  uint40  in  startFarming.    The overall gas consumption has been optimized.  1inch - Farming -   12  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                         \f6.5   Ineffective period Check  FarmAccounting.startFarming() contains following code:  require(period < 2**40, \"FA: Period too large\"); require(amount < 2**176, \"FA: Amount too large\"); (info.finished, info.duration, info.reward) = (uint40(block.timestamp + period), uint40(period), uint176(amount));  However, the first check is insufficient for uint40(block.timestamp + period) not to overflow.    The precondition was changed to:  require(period + block.timestamp <= 2**40, \"FA: Period too large\");  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Introduction of Batched Operations",
        "body": "  Assume a user participates in 10 farms for a farmable token. To claim all rewards the user needs to call claim()  multiple  times.  Gas  consumption  could  be  reduced  by  allowing  batched  operations  for ERC20Farmable.    Following batched operations have been introduced:   claimAll: claims on all farms   quitAll: quits all farms  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Usage as a Library",
        "body": "  ERC20Farmable  is  intended  to  be  used  as  a  library  for  farmable  ERC-20  tokens.  As  such,  some functions may require to be overridden so their functionality can be enhanced. However, no function in the  supplied  codebase  has  a  virtual  modifier,  and  so  child  contracts  cannot  override  any  method, meaning code that inherits from ERC20Farmable cannot extend its core functionality.  On the other hand, for some functions it could make sense to disallow overriding. An example could be farmedPerToken()  which  specifies  the  distribution  among  token  holders.  Allowing  developers  to modify its behaviour could lead to subtle issues that may not be caught during testing.  Assuming there is a use-case of changing the semantics of computing the farmed amount, code would require changes in several functions. First, farmed() would require changes. Second, claim() would require  changes  as  it  calls  UserAccounting.farmed()  instead  of  farmed.  Hence,  wrapping functionality  from  libraries  in  the  abstract  ERC20Farmable  and  using  the  wrapper  functions  internally could ease the overriding process and prevent errors.  1inch - Farming -   13  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \fFurthermore, it could be that some functions should not be callable by any child contracts, and there are certain  state  variables  that  should  not  be  set  in  child  contracts.  For  example,  farmTotalSupply  is  a public  variable,  querying  that  value  is  helpful  for  users  interacting  with  the  contract.  However, developers  could  unknowingly  interleave  writes  to  that  variable  in  between  updates  to  it  in  the  internal callflow  which  would  lead  to  inconsistent  state.  In  that  case,  it  could  be  helpful  to  have  a  public  getter while restricting writes in child contracts.  To  summarize,  1inch  provides  a  library  for  staking.  Since  documentation  is  also  part  of  writing  an application library, it would be helpful to explicitly document the overridability and the visibility of functions and variables, as well as their intended use.    The code has been adapted and functions have been marked as virtual.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   farmingCheckpoint() Has No Functionality",
        "body": "  FarmAccounting.farmingCheckpoint()  is  empty  and  has  no  functionality.  The  calls  to  it  further complicate the code. Moreover, replacing farm accounting logic through overriding is not easily possible.  Additionally, Farm._updateFarmingState() lacks checkpointing for a farm's state.    The function has been removed.  1inch - Farming -   14  DesignLowVersion1CodeCorrected        \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Calls to Farms",
        "body": "  Note that the system interacts with untrusted farms and untrusted contracts.  Changes  implemented  or  functionality  in  contracts  inheriting  from  ERC20Farmable  should  ensure  that there  is  no  possibility  of  re-entering  the  ERC20Farmable  contract  when  interacting  with  untrusted contracts since that could lead to possible unwanted modifications of farming state for other farms.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   farmedSinceCheckpointScaled() Decimals",
        "body": "  Note that farms may run into issues if a Farm's farmedSinceCheckpointScaled() does not return a value that is in the base of 10**(18 + rewardToken.decimals()):   Assume the call to farmedSinceCheckpointScaled() returns a value in the base of 10**x.   Then,   the   call   to   farmedPerToken  will   return   something   in   the   base   of  10**(x-ERC20Farmable.decimals()) which implies that corrections is in base of 10**x.  In farmed, the subtraction arguments will be both in base 10**x. However, the result of the division will be in the base of 10**(x-18).  Using Farm of 1inch, will ensure that x==18+rewardToken.decimals(). However, if that is not the case, errors could occur.  1inch - Farming -   15  NoteVersion1NoteVersion1       \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Unpermissioned Access to onlyMate Methods",
        "body": "  CS-MRT-001  If  the  may  role  is  assigned  to  address  zero,  methods  guarded  by  the  onlyMate  modifier  become unpermissioned.  The  purpose  of  this  is  unclear,  as  conflicting  functionality  can  be  accessed  through onlyMate methods. A user could call push() to transfer the whole balance to the configured recipient, or push(1) to transfer a very low amount to the recipient and disable further push() access, since the to and psm variables are reset to zero after push() is called. Likewise, a user could call quit(), which transfers the DAI balance to the configured quitTo address.  Since  mutually  exclusive  functionality  is  accessible  through  the  onlyMate  modifier,  leaving  it unpermissioned  opens  the  door  to  race  conditions  and  unpredictable  behavior.  Only  trusted  parties should be granted access to onlyMate guarded methods.  Similarly, but to a lesser extent, pick() and hook() are unpermissioned when address zero is granted the can role.    MakerDAO  realized  output  conduits  should  never  be  permissionless.  The  abilitiy  to  make  the  may  and can roles unpermissioned has been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Use of Unsafe Math Subject to Overflows",
        "body": "  Since the contract uses version 0.6.12 of solidity, unchecked arithmetics are used by default. Methods expectedGemAmt() and requiredDaiWad() are subject to possible artihmetic overflows. if their wad or amt parameters are set large enough.  Since  no  accounting  state  is  held  by  the  contract,  but  operations  are  performed  on  the  current  DAI balance, the overflows cannot be exploited, even by a malicious may user. However, external contracts  CS-MRT-002  MakerDAO - RWA Toolkit -   10  CriticalHighMediumCodeCorrectedLowCodeCorrectedSecurityMediumVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \fand off-chain users relying on the correctness of expectedGemAmt() and requiredDaiWad() might be negatively affected.    SafeMath  like  methods  were  introduced  to  ensure  the  calculations  in  expectedGemAmt()  and requiredDaiWad() cannot overflow.  MakerDAO - RWA Toolkit -   11  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   onTokenTransfer Wrong Accounting",
        "body": "  When triggering onTokenTransfer with only one deposit, stake_amount is assumed to be 32 STAKE but is not checked. This allows a depositor to call STAKE.transfer with 1 STAKE but to be accounted for 32 in the Merkle tree.  Code corrected  In case of a single transfer the amount is set to the transferred amount specified. In batch transfers it is set to 32 Ether. This behavior is coherent with the behavior of single deposits and batch deposits.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   EIP1967 Storage Addresses",
        "body": "  Hard-coding long strings could be error prone. The storage addresses of implementation and admin are hardcoded as hex values in multiple places. This adds complexity and is even more error prone. A clean  mitigation  would  be  to  set  the  storage  addresses  used  for  implementation  and  admin  as constants once and use this constant later on.  Code corrected  The hard coded strings were replaced by constants.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Interface Name Mismatch",
        "body": "  POA Network - SBC Deposit -   9  CriticalCodeCorrectedHighMediumLowCodeCorrectedCodeCorrectedCorrectnessCriticalVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                         \fThe name of the file and interface IERC667 should be IERC677 to be compliant with the transferAndCall Token Standard.  Code corrected  The file was renamed with the appropriate name.  POA Network - SBC Deposit -   10  \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Admin Power",
        "body": "  The system is administrated. The admin account has the complete power including withdrawing all funds by updating the implementation contract. Hence, the security of the admin key is of utmost importance as well  as  the  trust  in  the  key  holder/s.  POA  network  provided  the  information  that  they  are  aware  of  this note and will keep the admin contract under control by a multisig.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Locked Tokens in Implementation",
        "body": "  The  admin  can  withdraw  all  tokens  balances  from  the  proxy,  but  funds  sent  to  the  implementation contract are stuck.  POA  Network  reasoned  that  from  their  past  experience  with  user  support  requests,  users  tend  to mistakenly  send  tokens  only  to  the  proxy  contract,  since  only  its  address  is  being  publicly  advertised. Implementation  contract  is  \u201chidden\u201d  from  regular  users,  so  they  are  unlikely  to  send  tokens  to  that address.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Proxy/implementation Separation",
        "body": "   The proxy takes care of the zero hashes initialization. To be consistent, this logic should belong into  the implementation contract.   The admin is able to act on both the proxy and implementation logics. It is usually a good practice to  separate roles of proxy from roles of implementation.  POA network is aware of this note and explained that this is the intended behavior.  POA Network - SBC Deposit -   11  NoteVersion1NoteVersion1NoteVersion1          \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Asymmetrical Norm in Price Update Threshold",
        "body": "  In the tweak_price function the norm value is calculated to determine whether the distance between price_oracle  and  price_scale  is  sufficiently  large  so  that  a  price  update  should  be  tried.  To calculate the norm, the ratios between the price_scale and price_oracle are used. However, the ratios aren't treated symmetrically, i.e. if price_oracle = price_scale * 1.1 then the value 0.1^2 is added to the norm, but if the ratio is reversed, price_oracle * 1.1 = price_scale, then the value 0.09^2 is added. This means the price update is more sensitive to changes where the price oracle is too high, than when it is too low.  Acknowledged:  As typical differences between price_scale and price_oracle are between zero and five percent, the  effect  is  not  as  large.  Hence,  Swiss  Stake  GmbH  decided  to  not  make  any  more  changes  at  the moment  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Missing Boundary or Sanity Checks When",
        "body": " Initializing  Most  variables  have  implicitly  or  explicitly  enforced  minimal  and  maximal  values  or  should  not  take certain values like address zero. These are enforced when changing the values or given the ownership through a claiming scheme. However, there are no sanity checks or any checks at all when initializing the contract. Mistakes can happen and silently set one of the values to an obviously incorrect value.  Swiss Stake GmbH - Tricrypto -   9  DesignCriticalHighMediumLowAcknowledgedAcknowledgedAcknowledgedDesignLowVersion3AcknowledgedDesignLowVersion1Acknowledged                 \fAcknowledged  Swiss Stake GmbH is aware of the issue and confident no deployment errors will happen. In case of a factory contract the issue needs to be reconsidered.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   Potential Gas Savings in tweak_price",
        "body": "  The following code is present in the tweak_price function:  xp: uint256[N_COINS] = empty(uint256[N_COINS]) xp[0] = D_unadjusted / N_COINS for k in range(N_COINS-1):     xp[k+1] = D_unadjusted * 10**18 / (N_COINS * price_scale[k]) xcp_profit: uint256 = 10**18 virtual_price: uint256 = 10**18  these   Most  of  condition old_virtual_price  >  0  is  true.  Hence,  these  variables  could  be  moved  inside  of  the  condition  to save gas in case the condition evaluates to false.  (except  xcp_profit)  are  only  used  when   variables   the   Acknowledged  Swiss  Stake  GmbH  acknowledges  the  issue  with  the  reasoning  that  gas  savings  are  not  significant enough to make a change.  Swiss Stake GmbH - Tricrypto -   10  DesignLowVersion1Acknowledged          \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings   Certain Token Combination Cause Numerical Errors   -Severity Findings   Mismatched Bounds    Event Information Missing    Parameter Check Missing    Admin Fees Can Be Claimed Retroactively    Packed Getters Can Be More Restrictive    Slight Code Simplification   0  0  1  6  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Certain Token Combination Cause Numerical",
        "body": " Errors  If one of the tokens has very few decimals, e.g. Gemini USD which has 2 decimals, and another token either has more than 18 decimals or a fairly low token value, severe numerical errors can arise.  Example:   Token 0: Gemini USD (GUSD), 2 Decimals   Token 1: Another Token (AT), 18 Decimals, 1 AT = 0.005 USD  An exchange of 10,000 GUSD to 2,000,000 AT takes place. Note that the amounts don't matter as the error will occur based on the ratio. The price is computed as:   p = dx * 10**18 / dy   with dx = 10,000 * 10** 2   and dy = 2,000,000 * 10**18   hence, p = 0  In this case the calculated price is zero, which triggers no special checks or fallbacks.  This  situation  PRICE_PRECISION_MUL of 10**8.  is  even  more   likely  due   to   the  packing  of  calculated  prices  and   the  used  Another Example:   Token 0: USDC, 6 Decimals   Token 1: Another Token (AT), 18 Decimals, 1 AT = 1.00 USD  Swiss Stake GmbH - Tricrypto -   11  CriticalHighMediumCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedDesignMediumVersion1CodeCorrected        \fAn exchange of 10,000 USDC to 10,000 AT takes place. Note that the amounts don't matter as the error will occur based on the ratio. The price is computed as:   p = dx * 10**18 / dy   with dx = 10,000 * 10** 6   and dy = 10,000 * 10**18   hence, p = 10 ** 6  However, during packing this price will be divided by 10**8 and hence become 0.  Overall, the project has a good test suite, but it would benefit from tests containing token contracts with different decimals.    The price calculation was refactored and changed. The token amounts are now scaled to 18 decimals always instead of relative to the other token.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Mismatched Bounds",
        "body": "  The minimum and maximum values for A in the swap contract and the math contract do not match. In fact, the bounds in the math contract are more restrictive, meaning it's possible to ramp to a new value such that the math contract will revert all calls to newton_y and newton_D, basically locking the system until a valid value for A is set. Additionally, the maximum value for gamma also is mismatched, but the bounds are more restrictive in the swap contract, which does not cause any issues.    The code was corrected to make sure that the bounds of the math contract and the swap contract match.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Event Information Missing",
        "body": "  The  CurveCryptoSwap  contract  emits  different  events.  When  parameter  ramping  starts,  a RampAgamma  event  is  emitted.  However,  contrary  to  expectations  based  on  the  name,  it  contains  no information about gamma.    The relevant information was added to the RampAgamma event.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Parameter Check Missing",
        "body": "  Swiss Stake GmbH - Tricrypto -   12  DesignLowVersion3CodeCorrectedDesignLowVersion2CodeCorrectedDesignLowVersion2CodeCorrected                        \fSystem parameters can be updated by the administrators of the system. When being updated the new values are checked. The price_threshold and the mid_fee can both be updated, however, the fact that:  assert new_price_threshold > new_mid_fee  will only be checked when the price_threshold is updated and not when mid_fee is updated.    The issue was resolved through refactoring.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Admin Fees Can Be Claimed Retroactively",
        "body": "  When users see the admin_fee variable of the pool being 0 they will probably assume that no admin fees are being charged at the moment. However, this is not correct. Let's consider the following scenario:  Time Action  0  10  11  12  the pool is started with admin_fee = 0  numerous swap have occurred and xcp_profit has grown  the admin fee is set to 1% using commit_new_parameters and apply_new_parameters  the function claim_admin_fees is called  Users might expect that the admin fees will only be claimed for the time period of 11-12. However, admin fees will be claimed for the time period 0-12. This is because xcp_profit_a hasn't been updated in the meantime.  Code corrected  When changing the admin fee, the admin fees are claimed for the period until the change. Admin fees are only paid for the period beginning at the last time they were claimed. Hence, the issue is resolved.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Packed Getters Can Be More Restrictive",
        "body": "  three   to  access  packed  values:  price_oracle,  price_scale,  and There  are  last_prices. All three functions take an integer as input and retrieve the value at the respective offset. They make sure that the provided integer is:  functions   assert k < N_COINS  However, k == N_COINS - 1 is not a valid input for any of these functions and could also be blocked.  Code corrected  A check to validate k < N_COINS - 1 has been added.  Swiss Stake GmbH - Tricrypto -   13  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \f6.7   Slight Code Simplification  Within the claim_admin_fees function there is the following code:  frac: uint256 = vprice * 10**18 / (vprice - fees) - 10**18 total_supply: uint256 = CurveToken(token).totalSupply() claimed: uint256 = CurveToken(token).mint_relative(owner, frac) total_supply += claimed  During mint_relative the totalSupply will be updated. Hence, it could also be queried once after the call to mint_relative instead of querying it before and then updating it later.  Code corrected  The first total supply query was removed and the total supply is queried after the update.  Swiss Stake GmbH - Tricrypto -   14  DesignLowVersion1CodeCorrected        \f7   Notes  We  leverage  this  section  to  highlight  minor  findings  that  should  be  noted  and  considered  for  further development, but don't necessarily require an immediate code change.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Possible Price Manipulations",
        "body": "  We see the following price manipulations as possible:  1. Pushing  price_scale  towards  price_oracle.  In  case  a  user  wants  to  perform  a  larger exchange and the price inside the price_oracle is significantly better for that exchange than the price inside price_scale, then the user can push price_scale towards price_oracle using small  trades.  This  works  as  the  update  for  price_scale  only  depends  on  its  distance  to price_oracle not on previous actions within the same block.  2. The price_oracle is only affected by the last price seen in each block. Hence, big exchanges can be \"hidden\" from the price_oracle if they are followed by other exchanges with a different rate. Note that these trailing exchanges can be way smaller. Such trailing exchanges, if reliably inserted, allow full control over the price_oracle and thereby (as mentioned in the previous comment) also over price_scale.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Potential Gas Saving for Balanced Liquidity",
        "body": " Additions  In  case  last_prices  did  not  change  because  liquidity  was  added  in  the  current  pool  ratios,  the following code part could be skipped.  __xp: uint256[N_COINS] = _xp     dx_price: uint256 = __xp[0] / 10**6     __xp[0] += dx_price     for k in range(N_COINS-1):         self.last_prices[k] = price_scale[k] * dx_price / ...  However, it is unclear whether this is a worthwhile addition as a perfectly balanced liqudity addition will be a rare case unless the UI encourages it to save gas costs.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Splitting up Exchanges",
        "body": "  For users it can be beneficial to split up a larger exchange into multiple smaller exchanges in order to save fees. Depending on the price constellation and the gamma value they can remain in the \"flat\" area of the curve and hence save fees. This is of course detrimental to the liquidity providers. The usefulness of the split depends on the gas costs and the curve parameters.  Swiss Stake GmbH - Tricrypto -   15  NoteVersion1NoteVersion1NoteVersion1            \f7.4   Supported Tokens  There  is  are  variety  of  different  token  implementations  on  the  Ethereum  blockchain.  Using  tokens  with unusual behavior will lead to unexpected changes of the curve or put the smart contracts into a bad state. In particular, the following token types will not work:   rebasing tokens, where balances can change without transfers. These tokens will lead to incorrect  accounting.  tokens with transfer fees. These tokens will lead to incorrect accounting.  tokens with incorrect ERC20 implementations.  tokens with more than 18 decimals  tokens with more than one address  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   The General Case of n Token Versus A",
        "body": "  The  audit  was  scoped  for  the  case  n=3  tokens.  Nonetheless,  we  like  to  highlight  our  concerns  for  a bigger  n.  The  contracts  are  written  very  generic  for  the  case  of  n  tokens.  However,  the  n  cannot  be simply increased. As an example, with larger n space for the packed variables becomes smaller. Hence, such cases need to be tested carefully.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.6   Variable Naming",
        "body": "  Naming variables in a clear and understandable way supports the understanding of complex projects like this. Most variables have self explaining names. But some are confusing or used inconsistently like the use  of  x  and  xp.  The  value  (product  of  price  and  amount)  of  a  pool  token  is  usually  denoted  with  xp. However,  the  CurveCryptoMath3  contract  often  does  not  follow  this  naming  convention  consistently and  x  in reduction_coefficient which should be fee_gamma.  is  actually  ANN  *  A_MULTIPLIER  or  gamma   is  used.  Furthermore,  A  which   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.7   Vyper Is Still Beta",
        "body": "  Even though Vyper is used heavily in the latest DeFi projects (especially AMMs), the Vyper language is still  Beta  software  and  should  be  used  with  care  as  bugs  might  arise.  Nevertheless,  Curve  and  other AMMs have used recent Vyper versions successfully.  Swiss Stake GmbH - Tricrypto -   16  NoteVersion1NoteVersion1NoteVersion1NoteVersion1                  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   BatchTrade Should Revert on Error",
        "body": "  The  batchTrade  function  takes  a  revertOnError  config  parameter.  When  it  is  set  to  false,  the contract will not always revert on error. Instead, it will send the input tokens back to the caller. This could result in tokens remaining on the ThreeOneThirdAdapter.  In most cases, the failed BatchTrade will revert anyway, due to Enzyme's minIncoming check.  To  ensure  no  funds  can  be  left  on  the  adapter,  it  should  only  be  possible  to  call  batchTrade()  with revertOnError set to true.  CS-EZTOT-001    The revertOnError parameter has been removed from the enzyme input list. batchTrade() is now always called with revertOnError set to true.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Inaccurate minToReceive Computation",
        "body": "  The fee charged in 31Third protocol is computed and rounded down as:  feeAmount = (_receivedAmount * feeBasisPoints) / 10000;  CS-EZTOT-002  As  a  result,  parseAssetsForAction() the minimum amount to receive after fees is rounded down:  the  minimum  amount   to  receive  after   fees  will  be  rounded  up.  However,   in  Avantgarde Finance - Enzyme 31Third Adapter -   11  CriticalHighMediumLowCodeCorrectedCodeCorrectedCodeCorrectedDesignLowVersion1CodeCorrectedInformationalVersion1CodeCorrected               \fassetChanges = assetChanges.addItem(int256(trades[i].minToReceiveBeforeFees *     (10000 - feeBasisPoints) / (10000)));  As a result, the amount to receive after fees will be slightly inaccurate.    The assetChanges calculation now correctly rounds up instead of down.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Redundant Pragma",
        "body": "  CS-EZTOT-004  ABIEncoderV2  and ThreeOneThirdActionMixin. After solidity v0.8.0, ABI encoder v2 is activated by default, thus the following pragma has no effect.  ThreeOneThirdAdapter   declared   explicitly   in   is   pragma experimental ABIEncoderV2;    The redundant pragma was removed.  Avantgarde Finance - Enzyme 31Third Adapter -   12  InformationalVersion1CodeCorrected      \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Rebasing Tokens With Transfer Loss Are Not",
        "body": " Supported  The BatchTrade contract does pre- and post-balance checks when transferring tokens. This ensures at least fromAmount will be received.  CS-EZTOT-003  function _claimAndApproveFromToken(IExchangeAdapter, _exchangeAdapter,     Trade memory _trade) private {     if (_trade.from != ETH_ADDRESS) {         uint256 fromBalanceBefore = _getBalance(_trade.from);         IERC20(_trade.from).safeTransferFrom(             msg.sender,             address(this),             _trade.fromAmount         );         uint256 fromBalanceAfter = _getBalance(_trade.from);         if (fromBalanceAfter < fromBalanceBefore + _trade.fromAmount) {             revert NotEnoughClaimed(_trade, _trade.fromAmount,                 fromBalanceAfter - fromBalanceBefore);         }          IERC20(_trade.from).safeIncreaseAllowance(             _exchangeAdapter.getSpender(),             _trade.fromAmount         );     } }  However,  this  check  may  revert  on  transferring  rebasing  tokens  such  as  stETH.  Due  to  the  shares  to underlying  conversion,  there  may  be  1-2  wei  loss  during  the  transfer  and  the  receiver  will  receive  less than what is passed to safeTransferFrom(). A similar check is also performed in _callExchange.  This means that tokens such as stETH cannot always be traded using BatchTrade.  The  31Third  docs  explicitly  state  that  fee-on-transfer  tokens  are  not  supported,  but  does  not  mention rebasing tokens.  31Third responded:  The 31Third backend is aware of this. This will also be adressed in v2 of the 31Third protocol.  Avantgarde Finance - Enzyme 31Third Adapter -   13  InformationalVersion1Acknowledged      \f7.2   Replayable TradeSigner Signature  CS-EZTOT-005  The  BatchTrade  contract  (out  of  scope)  has  a  _preTradeCheck,  which  verifies  that  the to, tradeSigner  has  minToReceiveBeforeFees, and data.  fromAmount,   spender,   signed   from,   fields:   trade   the   The signed fields:   Do not contain the domain separator.   Are not bound to a msg.sender.   Do not contain a nonce or expiration timestamp.  As a result, a signature can be reused in multiple ways:   One user can reuse the signed trade data from another user.   A trade data signed for Ethereum contracts can be replayed and accepted by contracts on another  chain (e.g. Polygon) if they share the same tradeSigner.  Note that the same address may contain different code on different chains.  These scenarios should be carefully analyzed on 31Third protocol to ensure no unintended behavior is possible.  Risk accepted:  31Third responded:  Since only fund managers can rebalance their Enzyme funds this issue can be neglected.  Additionally, 31Third stated that they would change the signer on Polygon to be a different address than the one on Ethereum. This mitigates the cross-chain signature replay.  Avantgarde Finance - Enzyme 31Third Adapter -   14  InformationalVersion1RiskAccepted    \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   The Adapter Should Not Be a Feeless Wallet",
        "body": " on 31Third BatchTrade  The  owner  of  the  31Third  BatchTrade  contract  has  the  privilege  to  set  feeless  wallets.  An  address registered as a feeless wallet has their fees waived in batch swaps.  In  addition  to  the  Enzyme  Integration  Manager,  anyone  can  use  the  adapter  for  batch  swaps,  as  it  is permissionless.  31Third should not set the adapter as a feeless wallet, otherwise anyone can use the adapter to trade without fees.  Avantgarde Finance - Enzyme 31Third Adapter -   15  NoteVersion1  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Solv's BUYER_PAY Fee Pay Type Is",
        "body": " Unsupported  When buying vouchers from the marketplace, fees are paid. Note that Solv has two fee pay types such that either the buyer or the seller pays fees. If the buyer pays, the fee is added to the amount transferred from  the  buyer.  Note  that  Solv's  internal  function  _buy()  will  transfer  transferInAmount  from  the buyer which is defined as amount_.add(fee_).  The  external  position  for  the  buyer  side  does  not  consider  that  which  leads  to  the  following consequences:  1. Action BuySaleByAmount is not supported if the fee type is BUYER_PAY as the approval made will  be insufficient.  2. Action BuySaleByUnits is not supported if the fee type is BUYER_PAY as the funds sent from the  vault will not be sufficient to perform the action.  with the exception that if some unreconcilled funds are available to the external position, the funds could be sufficient to perform the action.  Code partially corrected:  1. Not corrected: Note that buying by amount on Solv will not transfer in the passed in amount but the passed  in  amount  plus  fees.  However,  BuyByAmount  does  not  consider  fees.  See  the  code  of SolvConvertibleMarket.sol  here https://etherscan.io/address/0x29935f54a45f5955ad7bc9d5416f746c3d1b9d69 on line 502.  file   if (vars.feePayType == FeePayType.BUYER_PAY) {   vars.transferInAmount = amount_.add(fee_);   ...} ...  Avantgarde Finance - Sulu Extensions V -   15  DesignCorrectnessCriticalHighMediumLowCodePartiallyCorrectedRiskAcceptedCorrectnessLowVersion1CodePartiallyCorrectedRiskAccepted              \fERC20TransferHelper.doTransferIn(       sale_.currency,       buyer_,       vars.transferInAmount   );  Ultimately, insufficient funds could be moved and the approval given to Solv could be insufficient.  2.  The code has been adapted such that the fee is in included in the transferred in  amount.  Note  that  the  fee  computation  made  for  the  BuyByUnits  action  could  be  off.  There  is  a  special  case where  the  voucher's  underlying  could  be  also  the  currency.  In  such  situations  the  fee  is  computed differently and is based on repoFeeRate instead of the market's feeRate.  Risk accepted:  Avantgarde Finance states the following:  the Solv team says that they will upgrade to the version of `SolvConvertibleMarket` that is in their GitHub repo (b207d5e), which fixes this issue (buyer fee is deducted from `amount`, and there is no longer a `repoFeeRate`). The Enzyme Council will assure that the upgrade has occurred before adding the external position type. Even if no upgrade were to occur, the worst case is that `BuySaleByAmount` will revert when there is a buyer fee, which does not result in value loss for the fund.  Avantgarde Finance - Sulu Extensions V -   16    \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings   Solv Issuer Double Accounting   -Severity Findings   Full Balance Is Pushed on Reconciliation    Offer ID and Voucher Mismatch    Solv Finance: No Support for Raw ETH as Currency    Solv Issuer Ignores Possibly Withdrawable Voucher Slots    getManagedAssets for Solv Buyer Side Reverts if Maturity Not Reached   -Severity Findings  Incomplete NatSpec for ManualValueOracleLib.init()    assetsToReceive Not Containing Assets   0  1  5  2  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Solv Issuer Double Accounting",
        "body": "  The  Solv  Issuer  external  position  keeps  track  of  the  offered  vouchers  on  the  convertible  offering marketplace. To compute their values it sums up  1. The   token  amounts   that  could  be  withdrawn  by   the   issuer  with   internal   function  __getWithdrawableAssetAmounts.  2. The  token  amounts  that  could  be  claimed  in  case  some  units  are  still  held  with  internal  function  __getOffersUnderlyingBalance()  3. The unreconciled token amounts.  __getWithdrawableAssetAmounts() iterates over all offers and further iterates over all issuer slots of the external position. There is a possibility of accounting withdrawable amounts multiple times.  for (uint256 i; i < offersLength; i++) {     // ...     ISolvV2ConvertibleVoucher voucherContract = ISolvV2ConvertibleVoucher(         INITIAL_CONVERTIBLE_OFFERING_MARKET_CONTRACT.offerings(_offers[i].offerId).voucher     );     ISolvV2ConvertiblePool voucherPoolContract = ISolvV2ConvertiblePool(         voucherContract.convertiblePool()     );     uint256[] memory slots = voucherPoolContract.getIssuerSlots(address(this));     // ...  Avantgarde Finance - Sulu Extensions V -   17  CriticalHighCodeCorrectedMediumCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedLowCodeCorrectedCodeCorrectedCorrectnessHighVersion1CodeCorrected         \f    for (uint256 j; j < slotsLength; j++) {         (uint256 withdrawCurrencyAmount, uint256 withdrawTokenAmount) = voucherPoolContract             .getWithdrawableAmount(slots[j]);         // logic for summing up         // ...  Consider the following example:  1. First offer is created with the voucher being X such that it has slot id 1.  2. Second offer is created with the voucher being X such that it has slot id 2.  3. The above code is executed.  4. The convertible pool of the voucher gives the slots 1 and 2.  5. The withdrawable amount is added twice since the inner loop for both offers will iterate over slot ids  1 and 2 and add the withdrawable amounts twice.  Ultimately, the withdrawable amounts may be added multiple times in the evaluation.    Now, not only offers are tracked but also issued voucher addresses. Hence, estimating the withdrawable amounts is done by iterating now over the issued voucher addresses which do not contain duplicates.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Full Balance Is Pushed on Reconciliation",
        "body": "  To  handle  direct  token  transfers  to  the  loan  contract  as  repayments  (and  to  handle  arbitrary  tokens received),  Avantgarde  Finance  introduces  a  reconciliation  functionality  for  arbitrary  loans,  which  allows moving  arbitrary  tokens  received  (e.g.,  insurance  payments)  to  be  moved  to  the  vault.  Furthermore,  it considers all surplus balance (compared to the borrowable amount) of the loan token as a repayment. However, it always moves the full loan token balance to the vault. While this makes sense when closing the vault, it may break the loan's logic when action reconcile is executed (e.g., borrowable amount > 0 but borrows are impossible).    Reconciliation  for  the  Reconcile  action  and  reconciliation  for  the  Close  action  are  now  performed differently.  A  boolean  _close  argument  was  added  to  the  __reconcile  function  to  make  this distinction.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Offer ID and Voucher Mismatch",
        "body": "  When  buying  an  offer  from  the  Solv  IVO,  the  fund  manager  can  specify  the  voucher  address  and  the offering  ID.  However,  the  voucher  address  could  mismatch  with  the  offer's  voucher  stored  in  the Offering struct.  Consider the following scenario:  1. Fund manager inputs an offer id such that Offer.voucher and the input voucher mismatch.  Avantgarde Finance - Sulu Extensions V -   18  DesignMediumVersion1CodeCorrectedDesignMediumVersion1CodeCorrected                \f2. The  SolvV2ConvertibleBuyerPositionParser  specifies  Offer.currency  as  the  asset  to  transfer  while specifying the amount to transfer as  uint256 amount = uint256(units).mul(voucherPrice).div(10**uint256(market.decimals));  3. The  nextTokenId()  is  queried  on  the  wrong  voucher  and  the  contract  maximum  approval  is  given to the IVO market.  4. buy() is called on the IVO market. As long as the amount computed in step 2. is sufficient, buying  will succeed.  5. The approval is revoked.  6. The input voucher and the token id from step 3 are pushed on the position's offers array.  While it requires an error by the fund manager, it could have consequences such as  tracking of a wrong voucher and token id leading to wrong estimations of the total value,   stuck tokens due to high amounts being moved also leading to wrong fund evaluations,   being stuck with the wrong voucher and token id   potential of double tracking of voucher and token id  Ultimately, to buy an offering it could be sufficient to specify solely the units and the offering id.    The voucher address is not an action argument anymore for buying from IVOs but is retrieved from the offering. Hence, the position parser and the position logic have been adapted accordingly.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Solv Finance: No Support for Raw ETH as",
        "body": " Currency  Raw ETH is not supported as a currency for the Solv convertible vouchers. This is problematic because Solv supports ETH through the doTransferOut function in the ERC20TransferHelper library, which uses a special constant address ETH_ADDRESS for such raw currency transfers. Given the lack of sanity checks for the assets in a voucher, it could be possible that such a voucher becomes unredeemable (e.g. claim action while fund currency is ETH).    The function __validateNotNativeToken was added to verify that the asset's address is not equal to the special value NATIVE_TOKEN_ADDRESS.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Solv Issuer Ignores Possibly Withdrawable",
        "body": " Voucher Slots  Avantgarde Finance - Sulu Extensions V -   19  DesignMediumVersion1CodeCorrectedCorrectnessMediumVersion1CodeCorrected                 \fWhen  creating  an  IVO  offer,  a  slot  is  created  for  the  issuer  and  the  offer  which  gives  it  a  uniqueness property  given  the  slot  details.  Action  Withdraw  allows  the  fund  manager  to  claim  assets  from  the voucher contract after maturity while action Remove removes the offer from the offering market such that the overhead underlying for the unsold units is refunded. Moreover, Remove removes the offer from the offers  array  such  that  it  becomes  untracked.  While  it  is  still  possible  to  call  Withdraw,  the  value  of getManagedAssets has dropped even though assets could still be withdrawn.  Consider the following scenario:  1. An offer is created. Some units were sold but not all.  2. The offer can be removed and there are withdrawable amounts. Assume the refund amount is 10 X  and the withdrawable amounts are 10 X and 10 Y.  3. getManagedAssets() return 20 X and 10 Y.  4. Remove is executed. 10 X are moved to the vault proxy.  5. getManagedAssets() returns 0.  6. Withdraw is executed. The fund's value rises suddenly.  In general, such behaviour could be introduced.    Now, not only offers are tracked but also issued voucher addresses. Removing an offer does not remove the issued voucher and, thus, the voucher's slots remain tracked.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   getManagedAssets for Solv Buyer Side",
        "body": " Reverts if Maturity Not Reached  getManagedAssets  evaluates  the  value  held  by  the  position.  To  do  so,  it  iterates  over  all  vouchers held,  currently  held  or  being  sold,  and  computes  internal  method __getClaimableAmount() which contains the following code:  their  value  with   uint128 settlePrice = poolContract.getSettlePrice(slotId); require(settlePrice > 0, \"Price not settled\");  Note that Solv's convertible pool contract implements getSettlePrice() such that it reverts if maturity has not been reached or if the price is negative. Ultimately, no voucher that has not reached its maturity can be evaluated and hence getManagedAssets() will revert which will block several operations in the Enzyme system. Even if getSettlePrice() did not fail, the second requirement may lead to reverts.  Specification changed:  Avantgarde Finance states:  This is an architectural decision to revert upon price lookup for all Solv vouchers (in both Buyer and Issuer features) that are issued or held prior to maturity, rather than estimate the value of an unsettled voucher. Price-dependent fund functions will revert while any such voucher is issued/held.  Avantgarde Finance - Sulu Extensions V -   20  DesignMediumVersion1Speci\ufb01cationChanged          \f6.7   Incomplete NatSpec for  ManualValueOracleLib.init()  The documentation of ManualValueOracleLib.init() is:  /// @notice Initializes the proxy /// @param _owner The owner of the oracle /// @param _updater The updater of the oracle value  Note that the _description parameter is not documented and, thus, the NatSpec is incomplete.    The description parameter has been added to the NatSpec.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   assetsToReceive Not Containing Assets",
        "body": "  Both the parsers for Solv V2 Buyer positions and Solv V2 Issuer positions could lead to untracked assets. The library used for adding items to memory arrays, creates a new memory array with the old and new items. However, in some occasions, the return value is not assigned to assetsToReceive after an item is added. Hence, it could be possible the assets remain untracked.  Note that Avantgarde Finance reported the issue.    The return values are assigned.  Avantgarde Finance - Sulu Extensions V -   21  DesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected              \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Arbitrary Loan Powers",
        "body": "  While  all  addresses  involved  in  the  arbitrary  loan  mechanism  are  fully  trusted,  such  external  positions may give managers very high control about the fund. Some (incomplete) list examples:  1. Stealing funds very easily by giving the full balance as a loan to itself.  2. Manipulating the valuation of the fund to profit by specifying an accounting module that computes  the face value when queried as extremely high.  3. Increase the number of shares by using the loan to invest in the fund.  4. Reentrancy possibilities.  5. Blocking behaviour.  Avantgarde Finance - Sulu Extensions V -   22  NoteVersion1  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Administrators Can Make Non-Native Tokens",
        "body": " Native and Native Tokens Non-Native  When the function setCustomTokenAddressPair is called, the following checks are being performed:  require(!isTokenRegistered(_bridgedToken)); require(nativeTokenAddress(_bridgedToken) == address(0)); require(bridgedTokenAddress(_nativeToken) == address(0));  However, there is no check that the _nativeToken is not bridged token, i.e.:  require(nativeTokenAddress(_nativeToken) == address(0));  This can create a weird condition where the bridged token is again a native token. Once this occurs, the bridge fails to function correctly, as the bridged tokens are now handled as native tokens.  Similarly, administrators can also register an existing native token, as a non-native token. Consider the following example:  1. A native token T exists, which has already been bridged and where tokens of type T are locked up  inside the mediator contract.  2. An  administrator  call  setCustomTokenAddressPair  with  T  as  the  _bridgedToken  and  some  other fake token F as the supposedly native token on the other side.  POA Network - OmniBridge - ChainSecurity  9  SecurityDesignCorrectnessCriticalHighMediumRiskAcceptedRiskAcceptedLowAcknowledgedRiskAcceptedRiskAcceptedCorrectnessMediumVersion1RiskAccepted            \f3. The  attacker  transfers  a  lot  of  F  token  (which  can  be  freely  minted)  over  the  brige  and  thereby  unlocks the T tokens.  This allows administrators to steal all native tokens held by the bridge.  However, the overall risk is rather low as only administrators can call setCustomTokenAddressPair.  Risk accepted:  To address this problem, POA Network added a comment saying that the function arguments should be manually validated by the administrator, as no easy solution is available.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Tokens With More Than One Token Address",
        "body": " Can Be Stolen by Admins  Tokens that have more than one address, through which they can be called, can be stolen when they are bridged. An example for such a token is TUSD. The attack would work as follows:  1. The token is already bridged using the first token address. An amount X has been transferred across  the bridge.  2. An attacker bridges the token using another token address. The attacker also bridges X tokens. Now the mediator balance on the native side is X for both token addresses. However, the actual balance, when queried from balanceOf is 2*X for both of them.  3. The attacker colludes with the administrators, which trigger a call to fixMediatorBalance on the  native side and withdraw X amount of tokens.  4. Then, the attacker can withdraw X tokens, by sending back the bridged tokens.  Overall, turned X tokens into 2*X tokens, when ignoring fees. The attacker managed to withdraw the full amount  of  bridged  tokens.  At  the  time  of  writing  118,000  TUSD  have  been  bridged  which  are  at  risk under such an attack.  Risk accepted:  No  code  changes  were  done.  POA  Network  added  a  warning  comment  to  fixMediatorBalance method.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   Documentation Mismatches",
        "body": "  The following mismatches with the documentation or within the documentation were found:  1. The  definition  of  native   is  different   in   the   code  and   in   the  documentation:  https://docs.tokenbridge.net/about-tokenbridge/features#chain-and-network-definitions  In the code, native refers to the origin of the token contract, in the documentation to the home side of the network.  2. Some documentation items mention a requiredBlockConfirmations of 8 while others mention  12.  POA Network - OmniBridge - ChainSecurity  10  SecurityMediumVersion1RiskAcceptedCorrectnessLowVersion1Acknowledged                \fAcknowledged:  Documentation will be re-worked with help of a technical writer.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.4   Function onTokenTransfer Reentrancy Case",
        "body": "  The  main  contracts  have  a  lock()  function  with  a  corresponding  variable  that  aims  as  a  reentrancy guard. In case when lock() is true, the onTokenTransfer function will silently accept the funds. This can lead to a reentrancy that can break some invariants of the contract. In case, the callback happens during the safeTransferFrom in the _relayTokens function, the from address can perform a token transfer  to  the  Bridge  contract.  Note  that  the  same  or  a  different  token  can  be  used.  Such  callbacks during  safeTransferFrom  can  occur  with  tokens  that  implement  the  ERC777  or  similar  standards. Because  the  received  tokens  are  silently  accepted  and  _setMediatorBalance  is  not  called,  the mediatorBalance won't track the balance correctly.  Risk accepted:  The described behaviour is acceptable, as ERC-777 tokens are not supported by the OmniBridge.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.5   Incompatible Tokens",
        "body": "  The following token types are incompatible with Omnibridge:   Rebasing tokens: If the balance of a token can change while it is stored inside the mediator contract, then basic assumptions no longer hold. Hence, such tokens as Ampleforth should not be bridged as the bridging might not be reversible.   Special  transfer  fees:  This  report  already  contains  issues  regarding  \"regular  transfer  fees\",  where upon transfer of X tokens, X-F tokens are transferred, while F tokens are paid to the fee receiver. In case of transfer fees, where upon transfer of X tokens, X+F tokens are subtracted from the senders balance and X tokens arrive at the receiver, the Omnibridge contracts will fail as they do not account for such fees.   Malicious tokens: Obviously, any malicious token contracts that do not follow sensible guidelines so that  for  example,  balances  can  be  arbitrarily  can  freely  manipulated,  cannot  be  bridged  in  a meaningful manner.  Users should be warned not to bridge such tokens.  Risk accepted:  POA Network manually reviewed the most important tokens to ensure their compatibility and will monitor the bridge and the bridged tokens. Furthermore, appropriate warnings will be added inside the UI.  POA Network - OmniBridge - ChainSecurity  11  SecurityLowVersion1RiskAcceptedDesignLowVersion1RiskAccepted                  \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings   Decimals in bridgeSpecificActionsOnTokenTransfer Are Not Used    ERC20 Function Calls Ignore Return Values    No Canonical Definition of Calldata for onTokenTransfer    Safe Transfers Are Not Used for All Token Transfers    Transferred Values in Case of Relaying Tokens With Fees   0  0  6   OmnibridgeFeeManager  Fee  Distribution  Reverts  in  Case  of  Tokens  With  Transfer  Fees  -Severity Findings   Code Simplification Possible    Name Collision Among Bridged Tokens With Different Origins   5   Reentrancy Into AMB    Restriction to Static Call    Superfluous Loads From Storage   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Decimals in ",
        "body": " bridgeSpecificActionsOnTokenTransfer Are Not Used  In  both  Home  and  Foreign  OmniBridge  contracts  the bridgeSpecificActionsOnTokenTransfer function during the token relaying. But this data is used only in few cases within this function:  the  decimals  are  queried   in    Token is not registered and limits need to be initialised.   Token is native to the current side of the bridge and its deployment is not yet acknowledged.  In case of non-native, acknowledged or initialised Tokens the queried decimals won't be used. Because such  cases  are  the  most  common  ones,  the  unused  data  introduces  extra  gas  costs  that  could  be avoided.    POA Network - OmniBridge - ChainSecurity  12  CriticalHighMediumCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedLowSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedDesignMediumVersion1CodeCorrected        \fThe  use  of  TokenReader.readDecimals()  was  refactored  as  so  it  is  being  called  only  when deployAndHandleTokens messages are sent.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   ERC20 Function Calls Ignore Return Values",
        "body": "  The ERC20 specification states:  Callers MUST handle false from returns (bool success). Callers MUST NOT assume that false is never returned!  In some calls to the ERC20 tokens those return values are ignored:   IBurnableMintableERC677Token(_token).mint(address(manager),   fee)   in  _distributeFee function.   IBurnableMintableERC677Token(_token).transfer(address(manager),   fee)   in  _distributeFee function.   IBurnableMintableERC677Token(_bridgedToken).mint(address(this),   1)   in  setCustomTokenAddressPair function.   _getMinterFor(_token).mint(_recipient, _value) in _releaseTokens function.  In most cases that happens during the calls to non-native Tokens that were deployed via the factory. But due  to  the  setCustomTokenAddressPair  function  the  non-native  contracts  can  have  any  behavior and the return values need to be checked explicitly.    All calls to transfer and mint function now check the return values.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   No Canonical Definition of Calldata for ",
        "body": " onTokenTransfer  The function onTokenTransfer uses inline assembly to read the receiver and calldata from the calldata arguments.  The  assembly  strongly  relies  on  some  assumptions  about  the  argument  encoding  of  the Solidity.  One  of  them  is  that  there  are  no  \"garbage  bits\"  between  the  byte  offset  of  the bytes  calldata  _data  variable  and  the  length  field  of  the  bytes  calldata  _data  argument. This  assumption  will  hold  true  in  most  cases,  but  is  not  guaranteed  to  hold.  This  assumption  can  be eliminated  letting  the  compiler  copy  the  _data  into  the  memory  and  dealing  with  it  there.  Full expectations  about  the  expected  information  in  the  _data  argument  must  be  properly  documented,  to avoid the misinterpretation of the interface.  function onTokenTransfer(     address _from,     uint256 _value,     bytes calldata _data ) external returns (bool) {  POA Network - OmniBridge - ChainSecurity  13  DesignMediumVersion1CodeCorrectedCorrectnessMediumVersion1CodeCorrected                \f  For  the  relevant  onTokenTransfer  function,  the  calldata  location  of  the  _data  variable  was replaced  with  the  memory  location.  Hence,  the  ABI  parsing  is  performed  by  the  compiler  and  only afterwards data is being parsed in inline assembly.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Safe Transfers Are Not Used for All Token",
        "body": " Transfers  For some transfers of ERC20 Tokens the SafeERC20 functions are not used. This includes:   The function _distributeFee in OmnibridgeFeeManagerConnector contract.   The function distributeFee in OmnibridgeFeeManager contract.  The first case only appears for non-native tokens at the Home side of the bridge, which in most cases should be ERC677 deployed by Factory. But due to the setCustomTokenAddressPair function, there are possible conditions when any other token can be called with this transfer.    All calls to the transfer function were replaced by a safe wrapper.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Transferred Values in Case of Relaying",
        "body": " Tokens With Fees  In a scenario with token relaying, the _relayTokens function is executed. A user provided _value is then transferred to the bridge contract via safeTransferFrom. If the token has fees on transfer (e.g. USDT-not currently charged, PAXG), the actual transferred value will be smaller than the bridged value. invariant This  Balance of bridge == total supply of bridged token.  effectively   break   the   will     This has been corrected by measuring the actually transferred token amount.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   OmnibridgeFeeManager Fee Distribution",
        "body": " Reverts in Case of Tokens With Transfer Fees  As part of the internal function _distributeFee of the OmnibridgeFeeManagerConnector contract calls  the  token  contract  to  transfer  or  mint  the  fee  amount  to  the  manager.  In  case  the  relevant  token contract  is  native  to  Home  side  it  might  have  transfer  fees.  Then,  a  value  less  than  fee  will  be  moved during  the  transfer  to  the  OmnibridgeFeeManager.  Later  the  OmnibridgeFeeManager  tries  to distribute this fee amount using distributeFee function. Because the actually transferred value will be  POA Network - OmniBridge - ChainSecurity  14  DesignMediumVersion1CodeCorrectedDesignMediumVersion1CodeCorrectedDesignMediumVersion1CodeCorrected                        \fsmaller in case of Tokens with transfer fees, the OmnibridgeFeeManager will not have enough assets to perform the reward distribution with the required values.  Hence, the whole transaction will fail and such tokens cannot be moved across the bridge.    The code has been rewritten so that  1. The  OmnibridgeFeeManager  determines   the  amount  of   fees   to  distribute  by  calling  token.balanceOf(address(this)).  2. Failure  of  the  transfer/mint  operation  during  the  fee  distribution  will  not  fail  the  Omnibridge  message processing.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Code Simplification Possible",
        "body": "  The following code can be simplified:  if (_token == address(0xb7D311E2Eb55F2f68a9440da38e7989210b9A05e)) {     // hardcoded address of the TokenMinter address     return IBurnableMintableERC677Token(0xb7D311E2Eb55F2f68a9440da38e7989210b9A05e); } return IBurnableMintableERC677Token(_token);  The if clause can be entirely omitted.  Specfication changed:  Before the OmniBridge is deployed for the ETH-xDAI instance the contract address in this check can be replaced  with  the  actual  minter  0x857DD07866C1e19eb2CDFceF7aE655cE7f9E560d  of  the  STAKE token  on  the  xDai  chain.  For  other  bridges  this  check  is  either  removed  at  all  or  did  not  have  any significant impact. A comment was added into the code to bring more clarity why this check is needed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   Name Collision Among Bridged Tokens With",
        "body": " Different Origins  When  the  bridge  creates  token  contracts  on  the  Home  chain,  the  \"  on  xDai\"  string  is  appended  to  the Foreign token name. In case of multiple bridges to different Foreign chains, different tokens that have the same  name  on  different  Foreign  chains,  will  have  same  names  on  the  Home  chain.  As  an  example, \"1INCH Token\" from Ethereum Mainnet and Binance Smart Chain will both have the \"1INCH Token on xDai\"  name  on  the  Home  chain.  While  that  has  no  direct  code-related  problems,  this  increases  the human error chance during the user interactions.    POA Network - OmniBridge - ChainSecurity  15  DesignLowVersion1Speci\ufb01cationChangedDesignLowVersion1CodeCorrected                \fNewly deployed Omnibridge contracts are using \"from X\" names where X is the respective blockchain. The Blockscout interface also renames such tokens in the UI. Unfortunately, it is not possible to change token names for already existing tokens. However such collisions are being mitigated in the UI.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   Reentrancy Into AMB",
        "body": "  When  the  Arbitrary  Message  Bridge  contract  receives  a  message  from  the  other  side,  the  following  is performed code is used to execute the message call:  setMessageSender(_sender); setMessageId(_messageId); setMessageSourceChainId(_sourceChainId);  ...  bool status = _contract.call.gas(_gas)(_data); setMessageSender(address(0)); setMessageId(bytes32(0)); setMessageSourceChainId(0);  The  called  contracts  can  query  the  information  such  as  messageId  and  messageSender.  These information provide important authorization for the called contracts. As there is no reentrancy guard on this function, this code can be reentered in the following way:  1. Call A is made, correct information for A is available  2. A triggers the reentrancy and call B is made, now B is executing and the correct information for B is  available  3. The call B completes and the information are reset to 0  4. The execution of A continues, but now the queried information will be 0  Hence,  it  is  possible  that  during  the  execution  of  a  passed  message  the  wrong  context,  namely  0  is returned  when  queried  from  the  AMB  contract.  Furthermore,  events  are  emitted  in  an  interlaced  order which might confuse connected systems.  Please note the AMB contracts were outside of the scope of this review, however, we still note this as it can affect the OmniBridge.    The  issue  was  fixed  in  https://github.com/poanetwork/tokenbridge-contracts/pull/577.  It  ensures  that  no other message relay is currently being processed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   Restriction to Static Call",
        "body": "  The contract contains the following code to determine the upgradabilityOwner:  address(this).call(abi.encodeWithSelector(UPGRADEABILITY_OWNER))  However, this function is defined as a view function:  POA Network - OmniBridge - ChainSecurity  16  SecurityLowVersion1CodeCorrectedSecurityLowVersion1CodeCorrected                \ffunction upgradeabilityOwner() external view returns (address);  Hence, a staticcall can be used to avoid unexpected state modifications.    The call was replaced with a staticcall.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.11   Superfluous Loads From Storage",
        "body": "  The Omnibridge contracts sometimes contain code like this:  require(!bridgeContract().messageCallStatus(_messageId)); require(bridgeContract().failedMessageReceiver(_messageId) == address(this)); require(bridgeContract().failedMessageSender(_messageId) == mediatorContractOnOtherSide());  As  there  is  a  storage  load  (SLOAD)  inside  the  bridgeContract()  function,  this  SLOAD  will  be executed  three  times  in  this  case.  Due  to  the  about-to-be  introduced  EIP-2929  the  additional  costs  of extra SLOADs from the same location are significantly lowered, but it could still be avoided to do it.    The return value of bridgeContract() was saved in a local variable to avoid repeated calls.  POA Network - OmniBridge - ChainSecurity  17  DesignLowVersion1CodeCorrected        \f7   Notes  We leverage this section to highlight potential pitfalls which are fairly common when working Distributed Ledger Technologies. As such technologies are still rather novel not all developers might yet be aware of these  pitfalls.  Hence,  the  mentioned  topics  serve  to  clarify  or  support  the  report,  but  do  not  require  a modification  inside  the  project.  Instead,  they  should  raise  awareness  in  order  to  improve  the  overall understanding for users and developers.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Differing Token Values",
        "body": "  The OmniBridge has limits on transfers per token. This means that only a certain amount of tokens can be  transferred  per  transaction  and  per  day.  Generally,  this  limits  are  initialized  as  a  number  of  tokens. Obviously, a certain number of tokens of one type can have a very different value than the same number of tokens from another type. Hence, these limits need to be carefully monitored.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Function requestFailedMessageFix",
        "body": " Performs Multiple Calls to bridgeContract  When a user detects a failed, bridged message, the function requestFailedMessageFix can be used to  fix  the  failed  call.  Therefore,  three  pieces  of  information  are  needed  which  are  currently  loaded  like this:     require(!bridgeContract().messageCallStatus(_messageId));    require(bridgeContract().failedMessageReceiver(_messageId) == address(this));    require(bridgeContract().failedMessageSender(_messageId) == mediatorContractOnOtherSide());  This code is execute both on Home and Foreign bridges.  Note that there are two levels of inefficiency here. First of all three separate calls are made, even though these information are generally always queried together. Second, this information is spread amount three storage  slots,  and  hence  requires  three  costly  SLOADs,  even  though  two  storage  slots  would  easily suffice, as only 321 bit of data are stored.  However,  as  this  needs  to  be  resolved  within  the  AMB  contracts,  it  is  outside  the  scope  of  this  code review.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Limits Can Be Compressed in Storage",
        "body": "  There are three storage slots being consumed on both sides of the bridge for the following information:  uintStorage[keccak256(abi.encodePacked(\"dailyLimit\", _token))] = _limits[0]; uintStorage[keccak256(abi.encodePacked(\"maxPerTx\", _token))] = _limits[1]; uintStorage[keccak256(abi.encodePacked(\"minPerTx\", _token))] = _limits[2];  These  information  are  often  accessed  together.  Given  the  value  ranges  they  could  probably  be compressed into two storage slots. This would also provide gas savings on the foreign side as it would avoid a costly SLOAD.  POA Network - OmniBridge - ChainSecurity  18  NoteVersion1NoteVersion1NoteVersion1          \f7.4   Proxy Fallback Redundant Operations  The Proxy contract does some redundant operations, such as:   let ptr := mload(0x40)   mstore(0x40, add(ptr, returndatasize()))  Preserving the free memory slot pointer at 0x40 is important when the assembly code is used together with Solidity code. But in case of the Proxy contract, this can be skipped, as no solidity code is executed after the assembly block.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   Redundant Work Performed as Part of ",
        "body": " totalSpentPerDay  The  function  bridgeSpecificActionsOnTokenTransfer  has  the  following  code,  that  checks  and adjusts the totalSpentPerDay limit for a particular token.  require(withinLimit(_token, _value)); addTotalSpentPerDay(_token, getCurrentDay(), _value);  The code of those 2 functions are quite similar.  function withinLimit(address _token, uint256 _amount) public view returns (bool) {     uint256 nextLimit = totalSpentPerDay(_token, getCurrentDay()).add(_amount);     return         dailyLimit(address(0)) > 0 &&         dailyLimit(_token) >= nextLimit &&         _amount <= maxPerTx(_token) &&         _amount >= minPerTx(_token); }  function addTotalSpentPerDay(     address _token,     uint256 _day,     uint256 _value ) internal {     uintStorage[keccak256(abi.encodePacked(\"totalSpentPerDay\", _token, _day))] = totalSpentPerDay(_token, _day).add(         _value     ); }  The  function  withinLimit,  that  is  executed  first,  reads,  increases  and  checks  limits.  The  function addTotalSpentPerDay  reads,  increases  and  writes  the  increased  value  for  the  limit.  This  is  a  small redundancy that can potentially be eliminated.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.6   Reentrancy Lock Is Gas Inefficient",
        "body": "  The  main  contracts  have  a  reentrancy  guard.  Setting  and  releasing  this  guard  inside  OmniBridge contracts is done via storage of a boolean true/false.  Please note that using locks which switch between the values 0 and 1 is more expensive than switching between the values 1 and 2 in case of a reverting transaction. However, the correct choice of this values  POA Network - OmniBridge - ChainSecurity  19  NoteVersion1NoteVersion1NoteVersion1            \fin  the  future  will  also  be  affected  by  the  currently  discussed  EIP-3298  which  is  concerned  about  the removals of refunds.  Based on EIP-2929 it would also be beneficial if the reentracy lock value would be packed into the same storage slot with another variable, but that is hard due to the chosen storage layout.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.7   State of Implementation Contract",
        "body": "  With  proxied  contracts,  the  state  generally  resides  in  the  proxy  while  the  code  resides  inside  the implementation contract. In principle, the state of the implementation contract is meaningless, unless the code  contains  selfdestruct,  callcode  or  delegatecall  opcodes.  Neither  of  these  opcodes  can  be  found inside the current Omnibridge contracts. However, we would still recommend to make the initialization of the state of the implementation contract part of the deployment scripts, as a best practice to avoid future issues.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.8   Token Creators Can Avoid Fee Payments",
        "body": "  Token  contracts  that  are  native  to  the  xDai  side  could  be  programmed  such  that  they  avoid  a  fee payment  to  the  bridge  validators,  e.g.  by  simply  ignoring  transfer  calls  to  and  from  the  fee  manager. Furthermore, existing tokens could be wrapped to avoid fees. However, as the fees are fairly low and as such tokens could be blocked on the bridge, the risk appears to be very low.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.9   Token With Transfer Restrictions",
        "body": "  Certain Tokens, especially regulated stable coins, have transfer restrictions, blacklists or even the power to seize funds. If some tainted funds would be bridged, the entire bridge balance of that particular token might become frozen or could get seized. As with any other contract where funds are deposited, users need to be aware of these potential risks.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.10   Weak Randomness",
        "body": "  The following function is used to pick a random number:  function random(uint256 _count) internal view returns (uint256) {     return uint256(blockhash(block.number.sub(1))) % _count; }  This is generally a bad way to sample randomness as, especially in the case of xDai, different attacks exist.  Furthermore,  there  randomness  is  extremely  slightly  skewed.  In  this  context,  however,  the randomness only serves to pick the account the receives the fee dust. As the corresponding monetary value is generally tiny, it seems acceptable.  POA Network - OmniBridge - ChainSecurity  20  NoteVersion1NoteVersion1NoteVersion1NoteVersion1                  \f7.11   onlyMediator Modifier  There is an onlyMediator modifier inside the BasicAMBMediator contract. It performs two checks:   Check that the call comes from AMB bridge contracts.   Check that the forwarded by AMB bridge the message sender is a mediator on the other side.  There are multiple concerns about this modifier.  Firstly, the MediatorOwnableModule has a modifier with the same name that performs only one check -  that  the  message  comes  from  OmniBridge  extension  contract.  That  can  potentially  cause misunderstandings and human errors.  Secondly,  it  seems  that  the  virtual  message  sender  is  always  needed.  This  is  currently  being  queried through  a  call  to  bridge.messageSender().  Here,  for  future  versions  of  the  AMB  protocol  a  more efficient design would be possible where this information is passed along.  /**  * @dev Throws if caller on the other side is not an associated mediator.  */ modifier onlyMediator {     _onlyMediator();     _; }  /**  * @dev Internal function for reducing onlyMediator modifier bytecode overhead.  */ function _onlyMediator() internal view {     IAMB bridge = bridgeContract();     require(msg.sender == address(bridge));     require(bridge.messageSender() == mediatorContractOnOtherSide()); }  POA Network - OmniBridge - ChainSecurity  21  NoteVersion1  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Execution Data Is Not Validated",
        "body": "  0  0  2  5  The executors always provide some execution data for the execution of the trigger. However, this data should correspond to the trigger's intention, but is not validated for the most part. Note that it still is limited in its ability to act maliciously because of the post-execution checks.  CS-OazoAutomV2-001  Risk accepted:  Summer.fi accepts the risk.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Execution Reentrancy May Be Possible",
        "body": "  Commands delegate calls to action smart contracts to act on the user's position. However, some of these action smart contracts can contain logic that would permit other external contracts.  CS-OazoAutomV2-002  Summer.fi - Automation V2 -   13  SecurityDesignCorrectnessCriticalHighMediumRiskAcceptedRiskAcceptedLowCodePartiallyCorrectedRiskAcceptedRiskAcceptedRiskAcceptedRiskAcceptedRiskAcceptedSecurityMediumVersion3RiskAcceptedSecurityMediumVersion3RiskAccepted                     \fIn  this  case,  external  contracts  could  contain  malicious  code  that  could  reenter  the  core  contracts  to add/remove triggers, or simply temper with the user's position.  Risk accepted:  Summer.fi accepts the risk.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   Future Debt Validation Does Not Take Bounds",
        "body": " Into Account  In  the  BasicSellCommand,  the  post-execution  debt  is  computed  in  isExecutionLegal()  to  validate that it will be bigger than the dust limit of the cdp's ilk:  CS-OazoAutomV2-003  uint256 futureDebt = (debt * nextCollRatio - debt * wad) /     (trigger.targetCollRatio.wad() - wad);  Note that in this computation the target collateralization ratio is accounted as is and used to predict future debt. However, the post-execution cdp's debt might not exactly correspond to this collateralization ratio, this is the reason behind the existence of the deviation parameter.  This makes it possible for the isExecutionLegal() function to return true even though execution will fail afterward because the debt is smaller than the dust limit.  Code partially corrected and risk accepted:  Now,  the  upper  bound  for  the  collateralization  ratio  is  used.  However,  this  will  yield  the  minimal  value futureDebt  could  reach.  Hence,  the  function  could  return  false  in  some  scenarios  where  the execution could be legal.  However, Summer.fi accepts the risk.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.4   Negative gasRefund Possible",
        "body": "  gasRefund should be used to decrease the necessary coverage according to the gas refunds. However, it is of type int and, hence could be negative so that the computation  CS-OazoAutomV2-004  uint256(int256(initialGasAvailable - finalGasAvailable) - gasRefund);  could increase the gas used instead of lowering it.  Note that with the current trust model, the executor providing this gas refund value should not be trusted.  Risk accepted:  Summer.fi - Automation V2 -   14  DesignLowVersion1CodePartiallyCorrectedRiskAcceptedCorrectnessLowVersion1RiskAccepted                  \fSummer.fi states that no changes were made since calls come from trusted callers. However, disallowing negative numbers (e.g. by using uint256) could help. Hence, Summer.fi accepts the risk.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.5   Overflow When Computing the Used Gas",
        "body": "  The cast from int256 to uint256 could overflow in the following code  uint256(int256(initialGasAvailable - finalGasAvailable) - gasRefund);  if gasRefund is greater than the computed gas used.  CS-OazoAutomV2-005  Risk accepted  The  gas  refund  is  limited  now  by  10**12.  However,  this  does  not  protect  against  bad  gasRefund argument since it could still be greater than (initialGasAvailable - finalGasAvailable).  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.6   Too Low execCollRatio",
        "body": "  In BasicSell, the execCollRatio could be below the liquidation ratio. Hence, the trigger validity check could allow an unexecutable trigger to be added.  CS-OazoAutomV2-006  Risk accepted:  Summer.fi replied that the data is validated with the calldata creation on the front-end.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.7   Too Low slLevel",
        "body": "  In CloseCommand, the slLevel could be below the liquidation ratio. Hence, the trigger validity check could allow an unexecutable trigger to be added.  CS-OazoAutomV2-007  Risk accepted:  Summer.fi replied that the data is validated with the calldata creation on the front-end.  Summer.fi - Automation V2 -   15  CorrectnessLowVersion1RiskAcceptedDesignLowVersion1RiskAcceptedDesignLowVersion1RiskAccepted                          \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  2  3  2  14  -Severity Findings   Arbitrary Actions and Storage Manipulations    Executor Could Draw an Unbounded Amount of Coverage   -Severity Findings   Executing a DPM Command Reverts    Removing Arbitrary Triggers Possible    Upgrades Break AutomationBot   -Severity Findings   Possible Reentrancy Through Execution    addRecord() Does Not Unlock   -Severity Findings   Wrong Event Argument   Incorrect Argument for ApprovalGranted Event    Bad Trigger Ids Emitted    Command Validation Functions Can Revert    Contracts Do Not Extend the Interfaces    Group Counter Starts at 2    Left Comments    Missing Validation in AutoTakeProfitCommand    Redundant Approval    Removing Non-Callers Emits an Event    Specification Mismatches    Unequal Array Lengths    Unused Imports    Unused Parameter, Variable and Event   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Arbitrary Actions and Storage Manipulations",
        "body": "  CS-OazoAutomV2-011  The  owner  of  the  ServiceRegistry  could  perform  arbitrary  storage  manipulations  and  actions  on  any (in  executePermit()  and position.  Namely,  executeCoverage()) allows them to execute arbitrary code in the context of the storage contract. In  the  storage  contract   the  delegatecalls   in   Summer.fi - Automation V2 -   16  CriticalCodeCorrectedCodeCorrectedHighCodeCorrectedCodeCorrectedCodeCorrectedMediumCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSecurityCriticalVersion3CodeCorrected         \faddition, a malicious command could be added along with its adapter so as to execute malicious actions on a user's position.  Let's consider different scenarios for understandability reasons:  Modifying storage in AutomationBotStorage:  1. Command X is added to the ServiceRegistry, it is a no-op command and is immediately executable.  2. Adapter X is also added.  3. The owner calls addRecord() to add a record for the command.  4. execute() happens. Arbitrary code is executed during the delegatecall made in adapter X.  Executing a malicious command:  1. Command X is added to the ServiceRegistry, it is a command that can, given a position, unwind all  funds to the owner's address and is immediately executable.  2. Adapter X is also added, its canCall() function always return true.  3. The owner calls addRecord() to add a record for the command and is allowed to do so.  4. execute() happens. Arbitrary code is executed during the execute made in AutomationBot and  funds are stolen.  Ultimately, the service registry owner may self-destruct the contract, change any storage locations, and execute any operations on any position that the AutomationBotStorage has allowance on.  Note that there are many possibilities when adding arbitrary commands and adapter, and the examples listed above are non-exhaustive.  ---    Summer.fi has changed the design. Users approve adapters which are callable by the automation bot.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Executor Could Draw an Unbounded Amount",
        "body": " of Coverage  CS-OazoAutomV2-026  The typical execution flow of a trigger is  1. Pre-condition checks.  2. Getting the coverage with getCoverage() so that the user pays for the fees.  3. Execution.  4. Post-condition checks.  Note that getCoverage() will typically create additional debt which changes also the collateralization ratio, and that the coverage amount is not bounded upwards.  A  trigger  could  potentially  be  non-executable  before  the  execution  but  become  executable  once getCoverage() has been called.  This gives the executor an ability to execute some triggers on demand.  Further  note  that  there  can  be  other  unforseeable  consequences,  but  they  are  limited  by  the post-execution validation.  Summer.fi - Automation V2 -   17  SecurityCriticalVersion3CodeCorrected        \f created an alternative for getting arbitrary coverage that severly amplifies the The changes in  owners  possibilities.  With  this  new  version,  the  executable  adapters  alway  holds  permissions  for  the position  (if  set  up  correctly),  so  that  it  can  draw  coverage  when  needed.  Now  consider  the  following scenario, where the governance would want to draw excessive coverage on a target position:  1. Governance adds a malicious command along with a malicious security adapter assigned to it. The malicious adapter returns true on canCall calls and the command allows execution but does not perform any operation. They also assign to the command a legit executable adapter, the one that the target position permitted to.  2. Governance adds a trigger record with the trigger data pointing to the target position, and using the  malicious command.  3. Execution occurs (governance has control over the executors) and the excecution adapter is called to get coverage and can (nearly) drain the target position. The maxCoverage variable was passed along the malicious triggerData in step 2, so can be arbitrary.    A user-defined maximum and a payment token has been introduced. The executable adapter is now only granted permissions when getting the coverage.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Executing a DPM Command Reverts",
        "body": "  A  typical  command  execution  flow  of  AutomationExecutor's  execute()  function  is  as  follows  (some steps are omitted for clarity):  CS-OazoAutomV2-016  1. Giving permissions to the command address  2. Calling the command to execute  3. Disallowing the command  Note  that  when  the  automation  bot  permits  the  command  address,  it  delegates  the  call  to  the  specific adapter.  This  should  work  because  the  automation  bot  was  already  permitted  when  the  trigger  was added.  In the case of the DPMAdapter, the permit() function starts with this line:  require(canCall(triggerData, msg.sender), \"dpm-adapter/not-allowed-to-call\");  This is executed in the context of the AutomationBot, so the msg.sender is still the AutomationExecutor, which has not been permitted by the owner of the proxy. The execution call will fail in all cases except when the owner of the proxy has manually permitted the AutomationExecutor.    Summer.fi changed msg.sender to address(this).  Summer.fi - Automation V2 -   18  Version4DesignHighVersion1CodeCorrected          \f6.4   Removing Arbitrary Triggers Possible  CS-OazoAutomV2-024  addRecord() adds a trigger and allows to replace a given trigger id and data with.  The following check is performed:  require(     replacedTriggerId == 0 || adapter.canCall(replacedTriggerData, msg.sender),     \"bot/no-permissions-replace\" );  However, following issues arise:  1. replacedTriggerData   is  not  validated   to  match   the  replacedTriggerId   (as   in  checkTriggersExistenceAndCorrectness()).  2. The  security  adapter  for  the  new  command  is  used.  However,  the  replaced  trigger  id  may  be  another command that has another adapter.  Users relying on the execution could be liquidated or miss out on profit scenarios.    replacedTriggerData is now checked against the hash of the replacedTriggerId since  . The original adapter is used since   .  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Upgrades Break AutomationBot",
        "body": "  The split of the storage from the AutomationBot intends to  [...] enable the upgradeability of AutomationBot implementation without the need for migration for all of the triggers.  However, note that the AutomationBot contract is given permissions for the positions but changing the address does not transfer the permissions. Ultimately, no previous triggers can be executed.  CS-OazoAutomV2-030    Now,  the  AutomationBot  does  not  hold  any  permissions.  However,  permissions  are  granted  to  the storage  contract.  Thus,  the  AutomationBot  calls  functions  on  the  storage  contract  that  can  grant commands the necessary rights.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Possible Reentrancy Through Execution",
        "body": "  CS-OazoAutomV2-015  Summer.fi - Automation V2 -   19  SecurityHighVersion1CodeCorrectedVersion2Version3CorrectnessHighVersion1CodeCorrectedSecurityMediumVersion1CodeCorrected                      \fWhen a caller executes a trigger, the automation bot permits the specific command to act on the target position/cdp  for  the  execution  call  and  removes  this  permission  after  it.  To  execute  a  trigger  the execute() function is called on the command. Note that none of the implementations of this function have access control or reentrancy protection. On execution, external smart contracts that belong to third parties will be called and it can lead to reentrancy possibilities. Entering again the execute() function would then be possible.    Now, the AutomationBot and the commands have reentrancy locks. Given that only a command at a time is granted permissions, this protects commands from being malicously executed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   addRecord() Does Not Unlock",
        "body": "  addRecord() adds new triggers. It calls lock() to ensure that emitGroupDetails() has the right calldata.  However,  note  that  emitGroupDetails(),  which  unlocks  the  lock  counter,  is  only  called  if addRecord() is used through addTriggers(). Note that this is not necessarily the case. Hence, the contract  could  temporarily  be  locked  by  direct  calls  to  addRecord()  (without  using  the  proxy  actions function addTriggers()). Calling addTriggers() would revert because of the inconsistency between the emit group details and the lockCount.  CS-OazoAutomV2-021    The  lock  is  always  cleared  using  the  new  function  clearLock()  in  addTriggers()  and removeTriggers().  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   Wrong Event Argument",
        "body": "  In  the  AutomationBot  smart  contract,  both  events  ApprovalGranted  and  ApprovalRemoved  are emitted  with  the  AutomationBot  address  as  argument,  when  the  permission  is  actually  granted  to  or removed from adapters.  CS-OazoAutomV2-032    The correct argument is now used.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   Incorrect Argument for ApprovalGranted",
        "body": " Event  CS-OazoAutomV2-019  Summer.fi - Automation V2 -   20  CorrectnessMediumVersion1CodeCorrectedCorrectnessLowVersion4CodeCorrectedCorrectnessLowVersion2CodeCorrected                        \fThe  event  ApprovalGranted(bytes  indexed  triggerData,  address  approvedEntity) should pass the approved entity as second argument. In AddTriggers(), the approval is granted to the AutomationBotStorage but the argument specifies the automationBot.  Code corrected  The correct argument is now used.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   Bad Trigger Ids Emitted",
        "body": "  The addTrigger() function triggers a call to emitGroupDetails() with bad trigger ids.  CS-OazoAutomV2-013  Consider the following scenario:  1. addTriggers() is used.  2. firstTriggerId is 0 since no triggers have been added so far.  3. addRecord() is called.  4. appendTriggerRecord() is called. The trigger is added with id 1 and the trigger counter is set to  1. The call returns.  5. addRecord() emits an event with trigger id 1 and returns.  6. addTriggers() sets the local variable triggerIds[0] to 0.  7. An event is emitted with the wrong id.  Ultimately, events with errors are emitted.    The first trigger id is now computed correctly (triggers counter + one).  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.11   Command Validation Functions Can Revert",
        "body": "  Command  smart  contracts  implement  3  different  data/execution  flow  validation  functions  that  return  a boolean:  CS-OazoAutomV2-031   isTriggerDataValid()   isExecutionLegal()   isExecutionCorrect()  All of those are wrapped in a require() in the automation bot so that the trigger data is valid and the pre and post-execution conditions also are.  However,  some  of  these  functions  in  AutoTakeProfitCommand  fail  on  some  conditions  instead  of  just returning false:  1. If the owner of the cdp is the address 0 in isExecutionLegal()  Summer.fi - Automation V2 -   21  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \f2. If the trigger execution price is greater than the next price in isTriggerDataValid()    The functions return false now.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.12   Contracts Do Not Extend the Interfaces",
        "body": "  Most  of  the  contracts  interact  with  each  other  based  on  the  interface  definitions.  For  example,  the addTrigger()  call  BotLike.addRecord()  on  the  AutomationBot.  However,  the  AutomationBot contract  itself  does  not  explicitly  implement  the  BotLike  interface.  Similarly,  other  contracts  do  not implement interfaces.  Without this, there are no compile-time guarantees that the contract will be compatible with the calls to the functions that the interface defines. This can lead to potential runtime errors and exceptions that are hard  to  debug.  It  is  important  to  explicitly  define  that  the  contracts  implement  the  corresponding interfaces, to minimize such errors.  CS-OazoAutomV2-017    The usage of interfaces has been improved.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.13   Group Counter Starts at 2",
        "body": "  Why does the group counter start at 2 when AutomationBot emits the first TriggerGroupAdded event?  CS-OazoAutomV2-018    The group counter starts now at 1.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.14   Left Comments",
        "body": "  Several TODOs are left open. Additionally, other comments are left. For example,  or type ? do we allow execution of the same command with new contract - waht if contract rev X is broken ? Do we force migration (can we do it)?  CS-OazoAutomV2-020  Such comments can increase complexity.  Summer.fi - Automation V2 -   22  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \f  The comments have been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.15   Missing Validation in",
        "body": " AutoTakeProfitCommand  The AutoTakeProfitCommand smart contract takes care of closing a cdp when its collateral has reached a certain price. This kind of trigger should not be continuous because of the way this command works.  However, isTriggerDataValid() does not check wether it is or not.  CS-OazoAutomV2-012    Now, only non-continous triggers are valid for AutoTakeProfitCommand.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.16   Redundant Approval",
        "body": "  The  AutomationExecutor  approves  Uniswap's  router  contract  twice  which  increases  gas  consumption and adds additional complexity.  CS-OazoAutomV2-022    The redundant approval was removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.17   Removing Non-Callers Emits an Event",
        "body": "  Removing non-callers emits a CallerRemoved event. In contrast, adding callers that are already callers skips the event emission.  CS-OazoAutomV2-023    Only callers can now be removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.18   Specification Mismatches",
        "body": "  Note that there are multiple specification mismatches:  CS-OazoAutomV2-025  Summer.fi - Automation V2 -   23  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                                \f1. BasicSellCommand  implies  trigger.execCollRatio.wad()  >=  nextCollRatio  which  contradicts the code in the equality case.  2. The documentation describes maxBuyPrice instead of minSellPrice.  3. The  documentation  states  that  Automation  Bot  is  a  stateless  contract.  However,  it  has  a  state  variable lockCount.  4. The  adapter  section  specifies  that  adapters  are  delegatecalled  in  the  AutomationBot  context. However,  the  functions  introduced  functions  executePermit()  and  executeCoverage() changed this behaviour since they are delegatecalled from the storage contract now.  Specification corrected  All 4 points were correct in the documentation.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.19   Unequal Array Lengths",
        "body": "  In  addTriggers(),  the  array  parameters  could  have  distinct  lengths.  The  execution  in  such  cases  is unspecified. Similarly, this holds for removeTriggers().  CS-OazoAutomV2-027    All arrays are not checked against for length.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.20   Unused Imports",
        "body": "  Some smart contracts have some unused imports, some examples are:  CS-OazoAutomV2-028  In AutomationExecutor:  1. FullMath  2. IExchange  3. ICommand  In BaseMPACommand:  1. AutomationBot  In McdView:  1. ICommand  2. BotLike  Note that this is an incomplete list of examples.    Summer.fi - Automation V2 -   24  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \fAll unused imports have been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.21   Unused Parameter, Variable and Event",
        "body": "  1. The function AutomationExecutor.execute() has an unused parameter cdpId.  2. AutomationExecutor stores the DAI address as an immutable which is unused.  3. The AutomationBot has an event ApprovalGranted that is not used.  4. AUTOMATION_BOT_STORAGE_KEY is unused in AutomationBot.  CS-OazoAutomV2-029    The event ApprovalGranted is now used and the others have been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.22   The CloseCommand Does Not Inherit",
        "body": " BaseMPACommand  The CloseCommand smart contract does not inherit the BaseMPACommand smart contract even though it executes through the MPA.  CS-OazoAutomV2-014    Inheritance was improved.  Summer.fi - Automation V2 -   25  DesignLowVersion1CodeCorrectedInformationalVersion1CodeCorrected              \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Floating Dependencies Version",
        "body": "  The  versions  of  the  contract  libraries  in  package.json  are  not  fixed.  Please  consider  the  following examples:  CS-OazoAutomV2-009  \"@openzeppelin/contracts\": \"^4.5.0\"  The caret ^version will accept all future minor and patch versions while fixing the major version. With new versions being pushed to the dependency registry, the compiled smart contracts can change. This may lead to incompatibilities with older compiled contracts. If the imported and parent contracts change the  storage  slot  order  or  change  the  parameter  order,  the  child  contracts  might  have  different  storage slots or different interfaces due to inheritance.  In addition, this can lead to issues when trying to recreate the exact bytecode.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Floating Pragma",
        "body": "  Summer.fi uses a floating pragma solidity ^0.8.13. Contracts should be deployed with the same compiler version and flags that have been used during testing and audit. Locking the pragma helps to ensure that contracts do not accidentally get deployed using, for example, an outdated compiler version that might introduce  bugs  that  affect  the  contract  system  negatively,  see  https://swcregistry.io/docs/SWC-103 (snapshot).  CS-OazoAutomV2-010  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Unecessary External Calls",
        "body": "  The  AutomationBot  smart  contract  must  sometimes  call  itself  because  of  the  delegate  logic,  however there are cases where this is not necessary:  CS-OazoAutomV2-008  1. In the emitGroupDetails() function  2. In the addRecord() function  Note that both of these function call automationBot like an external contract, but will not be called in a delegate context.  Summer.fi - Automation V2 -   26  InformationalVersion1InformationalVersion1InformationalVersion4          \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   AutomationBot Permission Handling",
        "body": "  It should be made clear to the user and in the documentation that the functions addTriggers() and removeTriggers() are only helper functions, and that data must be provided in certain ways so that the system works correctly.  For  example,  triggers  will  not  be  able  to  execute  if  a  user  adds  multiple  triggers  that  point  to  different positions/cdps through addTriggers() without manually granting permission to the AutomationBot for each of these (except the first one).  removing  multiple   Also,  through removeTriggers()  will  only  remove  the  allowance  for  the  first  position/cdp  pointed  by  the  trigger  at index 0.  the  removeAllowance   triggers  with   flag  set   true   to   Further,  a  user  could  have  cleared  all  of  their  triggers  but  still  have  some  active  permission  on  the AutomationBot for their positions.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Data for Execution",
        "body": "  The data for the execution can be freely selected by the callers. There are the following limitations:   Post-conditions of the command must hold.   Selectors are validated in commands.  However, users should be aware that the coverage token can be an arbitrary token (e.g. if Aave position is managed) and, hence, the execution could lead to unwanted risks (e.g. being exposed to very volatile tokens).  Further,  users  should  be  aware  that  the  execution  could  be  configured  so  that  re-executions could occur faster.  Ultimately,  users  should  always  consider  the  possibility  of  bad  execution  data.  However,  note  that  the callers are trusted addresses.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.3   Oracle Not Suitable for On-Chain Usage",
        "body": "  AutomationExecutor  implements  an  oracle  for  Uniswap  V3  TWAP  prices.  This  is  intended  to  be  used off-chain. Using the oracle on-chain could lead to issues.  First,  the  TWAP  is  hardcoded  to  60  seconds  which  would  allow  for  simple  manipulations.  Second,  the function iterates over a list of pools and tries to choose the biggest one. It does so by selecting the one with the highest WETH balance. However, this is not a safe value for estimating actual pool size. Note that there are some further discrepancies compared to Uniswap V3's reference implementation of price oracle. For example, AutomationExecutor adds one to the TWAP interval array values (which Uniswap  Summer.fi - Automation V2 -   27  NoteVersion1NoteVersion1NoteVersion1          \fdoes not), does not round down to negative infinity (which Uniswap does) and does not have a precision of computation as high as Uniswap in some scenarios.  Generally, the oracle-like getters are not suitable for on-chain usage. Also, the off-chain usage must be done carefully.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.4   getCoverage() Implications",
        "body": "  The typical execution flow of a trigger is  1. Pre-condition checks.  2. Getting the coverage with getCoverage() so that the user pays for the fees.  3. Execution.  4. Post-condition checks.  Note that getCoverage() will typically create additional debt which changes also the collateralization ratio.  Users should be aware that in the BasicBuy command, where a precondition is that the collateralization ratio must be above a certain threshold, could technically be violated after getCoverage(). Hence, the execute function could be executed on a vault where the collateralization ratio is below the threshold.  Further  note  that  there  can  be  other  unforeseeable  consequences.  Users  should  be  aware  that  the configuration requires consideration of the coverage.  In  aware of this and configure their positions accordingly.  ,  Summer.fi  repeats  the  precondition  checks  after  getting  the  coverage.  Users  should  be  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.5   getTick Computes the Square Root Price",
        "body": "  The naming of getTick() suggests that a tick is returned. However, it computes the square root price.  Summer.fi - Automation V2 -   28  NoteVersion1Version4NoteVersion1        \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   EIP-4626 Non-Compliance",
        "body": "  The  functions  MultiWithdrawalController.maxWithdraw  and  maxRedeem  return  values  greater than 0 when the withdrawals are not allowed in the current status of the protocol. This is in violation of the following rule:  MUST return the maximum amount of assets that could be transferred from owner through withdraw and  not  cause  a  revert,  which  MUST  NOT  be  higher  than  the  actual  maximum  that  would  be accepted (it should underestimate if necessary).  Additionally,  MultiWithdrawalController._globalMaxWithdraw  sets  the  maximum  amount  of tokens  that  can  be  withdrawn  from  a  tranche.  This  maximum  is  determined  by  the  function TrancheVault.totalAssets.  In  Live  state,  this  function  returns  the  current  waterfall  value  of  the tranche which contains the virtualTokenBalance of the entire portfolio, as well as the value of active loans. The returned value can therefore be higher than the actual amount of assets that are available for withdrawal.    MultiWithdrawalController.maxWithdraw  and  maxRedeem  now  return  0  if  withdrawals  are disallowed in the current status of the protocol.  Archblock - Controllers for TrueFi Carbon -   10  CriticalHighMediumLowCodeCorrectedDesignLowVersion1CodeCorrected        \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Redundant Event Emission",
        "body": "  A manager can configure the floor and the withdrawalAllowed mapping by calling configure. In case  the  parameters  are  the  same  as  the  ones  already  set,  the  execution  of  the  actual  setter  i.e., setFloor and setWithdrawalAllowed, is skipped. However, the manager can call setFloor and setWithdrawalAllowed directly, where there are no checks if the new values are different than the ones stored. In this case, redundant events will be emitted.  Archblock - Controllers for TrueFi Carbon -   11  InformationalVersion1  \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   No Asset Conversion",
        "body": "  MultiWithdrawalController.onRedeem  does  not  check  whether  the  given  assetAmount  of  an exception  matches  convertToAssets(sharesAmount).  If  the  manager  makes  a  mistake  or  a repayment  is  executed  on  the  contract  between  the  time  the  manager  sends  their  multiRedeem transaction and the time the transaction actually executes, the values will be wrong, resulting in either a loss or a gain for the given lender. This behavior is well documented by the specification provided to us.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Redeem Event Emission",
        "body": "  MultiWithdrawalController.onRedeem  can  be  called  by  any  user  (without  reverting)  using  the following arguments:   sender: The address of the controller contract.   shares: 0.   owner: address(0).  This  emits  a  Redeem  event  every  time.  The  assets  parameter  can  be  completely  arbitrary.  Off-chain systems reading these events should be aware of this behavior.  Archblock - Controllers for TrueFi Carbon -   12  NoteVersion1NoteVersion1      \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Note on PR 3211: Fix: Restrict STATICCALL to",
        "body": " View  CS-VYPER_JANUARY_2023-001  This issue was identified in an unmerged pull request which had not been fully reviewed internally yet, and  consequently  had  a  higher  likelihood  of  having  high  severity  issues  in  it.  It  should  not  be  directly compared  to  merged  pull  requests  to  assess  the  overall  security  of  Vyper.  The  pull  request  was  later abandoned.  Pull Request 3211 fails to fix the problem it is addressing. This PR would want to restrict @pure functions from using staticcall, since pure function should not be able to perform external calls, as they can't be statically checked to be pure.  Instead  of  forbidding  pure  functions  from  using  raw_call,  the  PR  restricts  raw_call  with is_static_call = True to view functions. Both payable and nonpayable functions should also, together with view functions, be allowed to perform static calls.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   EnumT Does Not Implement compare_type",
        "body": "  Any enum variable can therefore the assigned to any other. This compiles but should not:  CS-VYPER_JANUARY_2023-002  enum A:     a  enum B:     a     b  @internal  Vyper - Vyper compiler -   10  CorrectnessHighVersion1DesignMediumVersion1              \fdef foo():     a:A = B.b  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   Function Type_From_Annotation Performs No",
        "body": " Validation  CS-VYPER_JANUARY_2023-003  Refactored  function  type_from_annotation  introduces  three  vectors  for  type  system  bugs  to  be introduced in the compiler:  1. The context of the annotation (data location) is not checked, which matters for HashMap and  Events.  HashMaps  should  only  be  declared  as  storage  variables  or  values  of  other  hashmaps,  and events should not be a valid type for variables, function arguments, or return types.  2. Does not check that annotations instantiate the type correctly  HashMap, String, DynArray, and Bytes should always be subscripted, however this is not currently enforced.  3. Does not check that the return value from the namespace is a valid type.  The last line return namespace[node.id], will return any namespace element instead of only types: beside types that need subscripts, this could be VarInfos or builtins.  Stricter validation should be performed on the input and outputs of type_from_annotation()  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.4   Function _Check_Iterator_Modification Has",
        "body": " False Positive and False Negatives  Vyper  disallows  modifications  iterator  _check_iterator_modification python function.  to  an   CS-VYPER_JANUARY_2023-004  in   the  body  of  a   loop   through   the  Because  of  how  the  syntactic  structure  is  checked  to  perform  this  semantic  analysis  step, _check_iterator_modification is susceptible to both false positives and false negatives.  False  negative  example  (this  compiles  but  should  not  because  self.a.iter  is  modified  in  the  loop body):  struct A:     iter:DynArray[uint256, 5] a: A  @external def foo():     self.a.iter = [1,2,3]     for i in self.a.iter:         self.a = A({iter:[1,2,3,4]})  False positive example (this does not compile, but should):  Vyper - Vyper compiler -   11  DesignMediumVersion1CorrectnessMediumVersion1            \fa: DynArray[uint256, 5] b: uint256[10] @external def foo():     self.a = [1,2,3]     for i in self.a:         self.b[self.a[1]] = i  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.5   HashMap Are Declarable Outside of the",
        "body": " Storage Scope  The check that HashMaps are declared as storage variable has been suppressed after the frontend type refactor. The following is now commented out:  # if location != DataLocation.STORAGE or is_immutable: #    raise StructureException(\"HashMap can only be declared as a storage variable\", node)  CS-VYPER_JANUARY_2023-005  An  equivalent  check  has  not  been  type_from_annotation() not accepting the DataLocation anymore.  reinstated  elsewhere.  This   issue  originates   from  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.6   Interface Does Not Accept Function Names",
        "body": " Used for Builtins  Instances  of  InterfaceT  are  instantiated  by  calling  VyperType.__init__()  and  passing  a  list  of members  to  be  added  to  the  type.  The  members  are  validated  through  validate_identifier(), which also checks that they do not collide with the builtin namespace. This is needlessly restricting for external interfaces. A Vyper contract will not be able to call some contracts without resorting to low level calls.  CS-VYPER_JANUARY_2023-006  The following does not compile:  interface A:     def send(): view  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.7   InterfaceT Does Not Implement Type",
        "body": " Comparison  Typechecking is not performed between interface types, a variable of any interface type can be assigned to  any  other  interface  typed  variable.  The  reason  is  that  InterfaceT  does  not  implement  a  custom  CS-VYPER_JANUARY_2023-007  Vyper - Vyper compiler -   12  CorrectnessMediumVersion1DesignMediumVersion1DesignMediumVersion1                  \fcompare_type(),  and  reuses  the  one  from  VyperNode,  according  to  which  two  instances  of InterfaceT represent the same type, regardless of their attributes.  The following should not compile, but does:  from vyper.interfaces import ERC20  interface A:     def f(): view  @internal def foo():     a:ERC20 = A(empty(address))  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.8   InterfaceT Type Comparison Is Incorrect for",
        "body": " Return Types  Method  compare_signature  of  ContractFunctionT  compares  two  functions  to  check  wether  an interface function is implemented in the module.  To  properly  implement  a  function  type,  we  should  be  able  to  receive  at  least  whatever  type  could  be passed as argument to the interface function, and we should return at most whatever could be returned by the interface function. This means that the type of arguments should be a supertype of the interface function argument type, and the type of return should be a subtype of the interface function return type.  CS-VYPER_JANUARY_2023-008  This  matters  with  hierarchical  DynArray[type, n]. When m < n, String[m] is a subtype of String[n].  types,  which   in  Vyper  are  String[n],  Bytes[n],  and  In term of a practical example, the following compiles but should not:  interface A:     def f() -> String[10]: view  implements:A  @external def f() -> String[12]:     return '0123456789ab'  Somebody wanting to interact with the contract through interface A expects that f() returns at most 10 characters,  however  here  f()  is  returning  12  characters.  The  order  of  compare_type()  for  return types should be reversed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.9   Note on Pull Request 3104: Refactor: Optimize",
        "body": " Calldatasize Check  CS-VYPER_JANUARY_2023-009  Vyper - Vyper compiler -   13  DesignMediumVersion1DesignMediumVersion1            \fThis PR removes an unconditional check that calldata.size >= 4 before the selector matching. It introduces an optional check that calldata.size > 0, which is included only if any of the selectors for the external functions is 0x00000000.  Every external function already checks that calldata.size >= 4 + argsize, the consequences of this PR are subtle differences in behavior when calldata.size < 4.  When calldata.size < 4, before, no selector would ever be matched, and we would end up in the fallback function. Now, when calldata.size < 4 we could happen to match a selector ending with zeros, for example selector 0x11223300 (4 bytes) is now matched by calldata 0x112233 (3 bytes). We now  execute  the  function,  which  guards  against  calldata.size  <  4  with  an  assert,  which  cause  a REVERT. So now, instead of unconditionally going to the fallback function with calldata.size < 4, we either go to fallback if nothing is matched, or we revert if something is matched.  This behavior is probably not what we expect after the refactor.  the An  alternative  possibility  calldata.size  >=  4  +  argsize  assert  when  argsize  is  0,  since  if  the  calldata.size  >=  4 initial check is kept, matching any selector implies passing the assert if argsize == 0.  for  optimization  which  could  be  evaluated   remove   to   is   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.10   Pure and View Functions Can Emit Events",
        "body": "  Event  emission  is  a  state  mutating  operation,  and  causes  STATICCALL  to  revert.  It  is  therefore disallowed in pure and view functions in Solidity. In Vyper however, a pure or view function can emit events  through  the  log  statement,  or  the  raw_log()  builtin.  If  a  pure  or  view  external  function  is called, vyper will try generating a STATICCALL to it, but if it emits an event the function will revert.  CS-VYPER_JANUARY_2023-010  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.11   implements Statement Does Not Check",
        "body": " Functions Mutability  the  implements  statement  checks  if  the  module's  interface  implements  the  functions  in  an  interface, either imported or defined with an interface statement. The type of the function arguments are checked, but  the  mutability  of  functions  is  not  considered.  The  mutability  could  be  seen  as  a  hierarchical  type, where  the  implementing  function  can  only  have  mutability  equal  or  lower  than  the  interface  function  it implements.  CS-VYPER_JANUARY_2023-011  This compiles but should not:  interface A:     def f(a:uint256): view  implements:A  @external def f(a:uint256): #visibility is nonpayable instead of view     pass  Vyper - Vyper compiler -   14  DesignMediumVersion1DesignMediumVersion1              \f5.12   AnnAssign Allows Tuples Assignment, Assign Forbids Them  visit_Assign  in  vyper.semantics.analysis.local  ensures  that  the  right  hand  side  of  an assignment is not a node of type tuple, but visit_AnnAssign does not. Is there a rationale behind this difference of behavior?  CS-VYPER_JANUARY_2023-012  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.13   Call to Self Check Replicated Twice in",
        "body": " FunctionDef Analysis  Lines  113-124  of  semantics/analysis/module.py  check  that  a  function  does  not  call  itself recursively. Line 126-144 replicate this check but with more generality, since a call to self is also a cyclic call. The check at line 113-124 is redundant.  CS-VYPER_JANUARY_2023-013  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.14   Code Duplication When Return Type of a",
        "body": " Function Is a Tuple  The  condition  at  line  322  of  semantics/types/function.py  treats  the  case  where  the  return annotation  of  a  function  is  a  tuple,  getting  the  type  by  iterating  over  the  individual  tuple  elements  and builing the TupleT:  CS-VYPER_JANUARY_2023-014  elif isinstance(node.returns, vy_ast.Tuple):     tuple_types: Tuple = ()     for n in node.returns.elements:         tuple_types += (type_from_annotation(n),)     return_type = TupleT(tuple_types)  However, calling type_from_annotation() directly with the ast.Tuple node as argument achieves the same result, using the equivalent code in TupleT.from_annotation():  values = node.elements types = tuple(type_from_annotation(v) for v in values) return cls(types)  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.15   Comment Referring to Code as Dead Is",
        "body": " Incorrect  Vyper - Vyper compiler -   15  DesignLowVersion1DesignLowVersion1DesignLowVersion1DesignLowVersion1                      \fFunction types_from_BinOp in semantics/analysis/utils.py contains the comment:  CS-VYPER_JANUARY_2023-015  # CMC 2022-07-20 this seems like unreachable code  in the handling of rhs of a division/modulus operation being 0.  The code is indeed reachable. Example:  a:uint256  @internal def foo() -> uint256:     return self.a / 0  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.16   Comment Uses Outdated Type Classes",
        "body": " Name  Comment at line 91 of vyper/semantics/analysis/module.py uses the InterfacePrimitive class name which has been deprecated in favor of InterfaceT.  CS-VYPER_JANUARY_2023-016  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.17   Constant Can Be Declared With Same Name",
        "body": " as Storage Variable  A  constant  can  be  declared  to  have  the  same  name  as  a  storage  variable,  if  the  constant  declaration follows the storage variable declaration. However a storage variable can't be declared if a constant of the same  name  is  already  declared.  This  is  inconsistent  with  what  happens  with  immutables  (can't  have same name regardless of order).  CS-VYPER_JANUARY_2023-017  This compiles:  a: uint256 a: constant(uint256) = 1  But this doesn't compile, while having the same semantics:  a: constant(uint256) = 1 a: uint256  Vyper - Vyper compiler -   16  DesignLowVersion1DesignLowVersion1              \f5.18   ContractFunctionT Incorrect Namespace Argument Check  The  following  check  in  ContractFunctionT.from_FunctionDef()  is  redundant  for  contract function definitions, and wrong for interface function declarations:  CS-VYPER_JANUARY_2023-018  if arg.arg in namespace:     raise NamespaceCollision(arg.arg, arg)  At  this  point,  we  are  still  building  the  module  namespace,  so  the  check  could  pass  depending  on  the order of module body elements.  This doesn't compile:  a:constant(uint256) = 1 interface A:     def f(a:uint256): view  While this functionally equivalent code does compile:  interface A:     def f(a:uint256): view a:constant(uint256) = 1  With module function definitions, it will not compile in both cases, since the namespace is also checked in local analysis, but the error message will be different depending on order.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.19   Dead Code in _get_module_definitions",
        "body": "  In semantics/types/user.py, the code to validate that functions with the same name extend each other input in _get_module_definitions() is unused, since the same logic is already implemented in from_FunctionDef of ContractFunctionT. The code at lines 424-439 will never be executed, since the condition at line 424 is true, since functions with the same name are not allowed at the module level.  CS-VYPER_JANUARY_2023-019  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.20   Decorators Allowed Around Interface",
        "body": " Functions  In interface definitions, decorators can be used over function declarations. The decorator has however no effect on the compiler's behaviour. This compiles:  CS-VYPER_JANUARY_2023-020  interface A:     @asdfg     def f(): view  Vyper - Vyper compiler -   17  CorrectnessLowVersion1DesignLowVersion1DesignLowVersion1                \f5.21   Enum Members Are Not Valid as Keyword Argument Defaults  Function check_kwargable doesn't handle the case of Enum nodes. The following does not compile:  CS-VYPER_JANUARY_2023-021  enum A:     a  @external def f(a:A = A.a):     pass  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.22   Errors Misreport Column Offset for Vyper",
        "body": " Preparsed Keywords  The tokenizer output is annotated with lines and columns offsets, which are then used when annotating AST nodes. Some vyper keywords such as log, event, struct, and interface, are replaced with the python keyword class before parsing. The class tokens differ in position with the vyper tokens, so the column offset is misaligned for certain errors. For example the following code (which does not compile) produces an error that misreports the position of the undeclared variable d.  CS-VYPER_JANUARY_2023-022  event A:     b:uint256  @external def f():     log A(d)  The following error is raised, with the ascii art arrow pointing to the wrong location:  UndeclaredDefinition: 'd' has not been declared.   contract \"VyperContract:7\", function \"f\", line 7:12        6 def f():   ---> 7     log A(d)   -------------------^        8  Vyper - Vyper compiler -   18  DesignLowVersion1CorrectnessLowVersion1              \f5.23   ExprInfo for Tuple Allows Assigning to Immutables  Line  249-251  of  vyper/semantics/analysis/base.py  guard  against  assignment  to  an  already assigned  immutable  variable.  However  the  is_immutable  field  is  left  blank  when  creating  an ExprInfo for a tuple (vyper/semantics/analysis/utils.py:90-97).  The following code generates an error in code generation, instead of typechecking:  CS-VYPER_JANUARY_2023-023  c:(uint256, uint256) d: public(immutable(uint256)) e: immutable(uint256)  @external def __init__():     d = 1     e = d  @external def f():     d, e = self.c  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.24   Function Declaration Checks if Return Type",
        "body": " Annotation Is a Call Node  Function  semantics/types/function.py the following check:  from_FunctionDef   ContractFunctionT   of   CS-VYPER_JANUARY_2023-024  performs   at   line   320   of  elif isinstance(node.returns, (vy_ast.Name, vy_ast.Call, vy_ast.Subscript)):     return_type = type_from_annotation(node.returns)  However, node.returns has no reason to be a Call. No type annotation is a Call.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.25   HashMap Variable Can Be Left-Hand of",
        "body": " Assignment if Wrapped in Tuple  Line  249-251  of  vyper/semantics/analysis/local.py,  in  visit_Assign,  ensure  that  lhs  of assignment  cannot  be  a  hashmap  without  a  key.  However  this  check  is  skipped  if  the  hashmap  is wrapped in a tuple.  The  following  code  passes  the  check,  and  fails  compilation  during  code  generation,  in  a  check considered maybe redundant.  CS-VYPER_JANUARY_2023-025  Vyper - Vyper compiler -   19  CorrectnessLowVersion1DesignLowVersion1CorrectnessLowVersion1                \fa: HashMap[address, uint8] b: HashMap[address, uint8] c: HashMap[address, (HashMap[address, uint8], HashMap[address,uint8])] @internal def f():     (self.a, self.b) = self.c[empty(address)]  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.26   Import Level of ImportFrom Ignored",
        "body": "  The python ImportFrom ast node defines a field level which specifies the level of a relative import. This field is ignored in Vyper, so the following code is valid and compiles:  CS-VYPER_JANUARY_2023-026  from ......................vyper.interfaces import ERC20  implements: ERC20  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.27   Inaccurate Comment on TYPE_T",
        "body": "  Class TYPE_T is commented in semantics/types/base.py with  # A type type. Only used internally for builtins  CS-VYPER_JANUARY_2023-027  The  comment  is  inaccurate,  as  TYPE_T  is  also  used  to  wrap  other  callable  types,  such  as  events  or structs.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.28   Internal Functions Can Have Name Collision",
        "body": " With Builtins  If  a  function  visibility  is  @internal,  it  can  share  its  name  with  a  builtin,  if  the  visibility  is  @external, however,  a  compilation  error  is  raised.  There  is  no  valid  reason  it  should  be  so,  since  both  kind  of functions populate the self namespace and should behave consistently.  CS-VYPER_JANUARY_2023-028  This compiles:  @internal def block():     pass  This doesn't compile:  Vyper - Vyper compiler -   20  DesignLowVersion1DesignLowVersion1DesignLowVersion1                  \f@external def block():     pass  is   reason   The  true  when  calling self.add_member in visit_FunctionDef, which is used for internal and external functions, it is set to false when populating the interface of the module, which includes only external functions.  that  while  skip_namespace_validation   is  set   to   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.29   Invalid DataLocation for Tuple ExprInfo",
        "body": "  A  Tuple  is  the  only  type  of  node  whose  ExprInfo  is  the  aggregation  of  the  individual  ExprInfos  of  its nodes,  so  it  is  tricky  to  define  it  consistently.  The  ExprInfo  of  a  Tuple  containing  a  storage  and  an immutable variable has DataLocation CODE. This could cause problems if the ExprInfo was to be used in code generation.  CS-VYPER_JANUARY_2023-029  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.30   Lhs of AugAssign Not Visited by",
        "body": " _LocalExpressionVisitor  CS-VYPER_JANUARY_2023-030  _LocalExpressionVisitor is a legacy class whose sole current purpose is to check that msg.data and address.code are correctly accessed in a builtin that can handle them. The left hand side of an AugAssign  the _validate_address_code_attribute() and _validate_msg_data_attribute() checks, and causes a compiler panic:  is  not  visited  by  _LocalExpressionVisitor,  so   following  passes   the   a: HashMap[Bytes[10], uint256]  @external def foo(a:uint256):     self.a[msg.data] += 1  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.31   Note on PR 3167: Fix: Codegen for Function",
        "body": " Calls as Argument in Builtin Functions  PR 3167 correctly fixes an issue where arguments of builtins would be included twice in the generated code, resulting in reverts because of duplicated labels. The fix is implemented for builtins floor, ceil, addmod, mulmod, and as_wei_value  Arguments  are  now  correctly  evaluated  and  cached  before  being  included  in  the  intermediate representation code.  CS-VYPER_JANUARY_2023-031  Vyper - Vyper compiler -   21  DesignLowVersion1CorrectnessLowVersion1CorrectnessLowVersion1                  \fHowever, builtin functions ecadd and ecmul are still affected by the same bug. The following code does not compile but should:  @external def foo() -> (uint256[2]):     a: Foo = Foo(msg.sender)      return ecmul(a.bar(), 2)  interface Foo:     def bar() -> uint256[2]: nonpayable  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.32   Pointless Assert",
        "body": "  get_expr_info() in vyper.semantics.analysis.utils contains the assert:  assert t is info.typ.get_member(name, node)  CS-VYPER_JANUARY_2023-032  Since  t  has  just  been  defined  as  t  =  info.typ.get_member(name.  node),  and  no  mutating operation has occured, the assert will always pass.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.33   Positional Only Arguments Are Allowed but",
        "body": " Ignored in Function Definitions  Python allows specifying positional only arguments in a function definitons, which are accessible through the posonlyargs field of the arguments AST node. Since the arguments VyperNode does not sets posonlyargs as a _only_empty_fields, the field can be populated but is ignored.  CS-VYPER_JANUARY_2023-033  The following code compiles:  @internal def f(a:uint256,/): #this does not actually defines argument a             return  @external def g():             self.f() #f is called without arguments  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.34   RawRevert Should Be Set as Terminal Node",
        "body": "  CS-VYPER_JANUARY_2023-034  Vyper - Vyper compiler -   22  DesignLowVersion1DesignLowVersion1DesignLowVersion1                  \fBuiltin raw_revert has field _is_terminus unset. _is_terminus specifies if the node can terminate the  branch  of  a  function  body  which  has  a  non  empty  return  type.  The  evaluated  function  is  left  when raw_revert  is  called,  so  its  _is_terminus  attribute  should  be  set  to  True,  as  is  the  case  for SelfDestruct.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.35   Safety Check for Bytestring Classes Not",
        "body": " Reacheable  CS-VYPER_JANUARY_2023-035  Function  from_annotation  in  class  semantics.types.bytestrings._BytestringT  validates that  the  bytestring  type,  such  as  String  or  Bytes,  is  not  being  used  without  a  length  specifier (String[5]).  However  in type_from_annotation()  if  the  type  annotation  is  an  ast.Name,  so  the  check  at  line  126  of semantics/types/bytestrings.py is not effective.  function  from_annotation()  of  a   is  not  called   type   the   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.36   Storage Location of Constants Set to",
        "body": " Storage  In  visit_VariableDecl  of  vyper.semantics.analysis.module,  the  DataLocation  of constant variables is set to STORAGE. While this has no immediate consequences, since constants can't be assigned, it could be misleading and generate problems in future code changes.  CS-VYPER_JANUARY_2023-036  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.37   Struct Creation Without Assignment Results",
        "body": " in Cryptic Error Message  The  check  at  lines  512-519  of  vyper/semantics/analysis/local.py  should  output  an  error message when builtins or structs are called without assignment, however the _id attribute of fn_type is accessed,  which  causes  another  exception  to  be  thrown  for  TYPE_T(StructT),  since  they  have  no ._id field.  CS-VYPER_JANUARY_2023-037  Example:  struct A:     a:uint256 @internal def aaa():     A({a:1})  Vyper - Vyper compiler -   23  CorrectnessLowVersion1DesignLowVersion1CorrectnessLowVersion1                    \f5.38   Tuple Node Input Does Not Work With Validate_Expected_Type  Function  validate_expected_type  has  a  branch  for  the  case  when  node  is  an  instance  of vy_ast.Tuple.  However,  it  is  not  clear  what  the  purpose  of  handling  Tuple  nodes  is,  since  the expected type has to be a dynamic or static array.  CS-VYPER_JANUARY_2023-038  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.39   VarInfo for self Not Constant",
        "body": "  While self contains mutable variables, it would make sense that its VarInfo was set as constant. The compilation of the following fails in code generation, while it could fail in type checking.  CS-VYPER_JANUARY_2023-039  @external def f():     self = self  Vyper - Vyper compiler -   24  CorrectnessLowVersion1DesignLowVersion1          \f6   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Comments on PR 2974/3182",
        "body": "  These PR refactor the type system, and unify the front-end and back-end type systems.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Note on PR 3213: Fix: Constant Type",
        "body": " Propagation to Avoid Type Shadowing  Pull  Request  3213  correctly  fixes  an  issue  where  the  type  inference  for  the  iterator  of  for  loops  would result in validating conflicting types.  Instead of accessing the \"type\" metadata property of a node, which could be dirty with a provisional invalid type, get_possible_types_from_node() now accesses the new \"known_type\" metadata property, which is only assigned during constant folding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Note on PR 3215: Raise Clearer Exception",
        "body": " When Using a yet Undeclared Variable in a Type Annotation  This  PR  correctly  resolves  a  cryptic  error  message  cause  by  undeclared  variables  during  constant folding.  The  following  line  caused  problems,  when  name  was  not  in  the  namespace  and  self  had  not  been declared yet (during constant folding):  if name not in self.namespace and name in self.namespace[\"self\"].typ.members:  The  rhs  condition  name  in  self.namespace[\"self\"].typ.members  would  raise  an  exception when evaluated, because self.namespace had no self member yet.  Now the condition has been split in 3 conjunctions:  if (     name not in self.namespace     and \"self\" in self.namespace     and name in self.namespace[\"self\"].typ.members ):  When name is not in self.namespace, the condition \"self\" in self.namespace guards against raising accidentally when evaluating the 3rd conjunction.  Vyper - Vyper compiler -   25  NoteVersion1NoteVersion1NoteVersion1          \fA  more  body,  when t = self.namespace[node.id] is evaluated, since self.namespace does not containt node.id.  immediately   exception   legible   raised   after   the   is   if   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Note on Pull Request 3194: Fix Raise",
        "body": " UNREACHABLE  PR 3194 fixes a bug in code generation that would cause a raise UNREACHABLE statement to cause a compiler  panic.  It  is  implemented  correctly  and  the  resulting  code  is  correct.  We  noticed  that  in  the generated  code  a  STOP  unreachable  instruction  is  present  after  the  INVALID  instruction  generated  by the raise statement.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Note on Pull Request 3222: Fix: Folding of",
        "body": " Bitwise Not Literals  PR 3222 reimplements the binary inversion of literals during folding. The operation computes the 256 bits wide binary inverse, so that the result of the operation should always fits within uint256.  Vyper - Vyper compiler -   26  NoteVersion1NoteVersion1        \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Certain Inputs Unchecked in Constructor",
        "body": "  When  new  fees  are  committed  through  the  commit_new_fee  function  they  are  checked  against  the respective  maximum  values  to  prevent  mistakes.  However,  when  the  fees  are  initially  set  inside  the constructor no such check is performed. Hence, initial fees might be outside the permitted value range.  Similarly,  when  the  amplification  factor  is  changed  through  ramping,  it's  value  range  is  checked. However, during the constructor this check for the amplification factor does not take place.  Risk  accepted:  As  deployment  is  a  rare  event  and  as  deployed  contracts  will  be  checked  by  the development team, there is no immediate need to add these checks. An incorrect contract can be \"killed\".  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Ramping Down Might Incentivize Delayed",
        "body": " Liquidity  While  the  amplification  factor  is  ramping  down  in  an  imbalanced  pool,  liquidity  providers  have  an incentive to wait before providing extra liquidity. This is because they will receive more liquidity tokens in the  future  for  the  same  liquidity.  In  the  extreme  case  of  a  maximally  sharp  ramp  down  and  a  very imbalanced pool, waiting for ten minutes provides roughly 0.14% additional liquidity tokens.  However, this only holds as long as no further fees are accumulated during this time and as long as no re-balancing takes place inside the pool and hence constitutes a fairly unlikely scenario.  Curve.Finance - Curve ETH/sETH -   9  SecurityDesignCorrectnessCriticalHighMediumLowRiskAcceptedRiskAcceptedSecurityLowVersion1RiskAcceptedDesignLowVersion1RiskAccepted                   \fRisk accepted: As mentioned above this only applies for very sharp ramps. As the DAO will control the parameter  of  these  ramps,  the  DAO  can  also  ensure  that  the  sharpness  is  low  enough  to  avoid  any issues.  Curve.Finance - Curve ETH/sETH -   10    \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings   Reentrancies   -Severity Findings   Redundant Use of RATES and PRECISION    _xp and _xp_mem Redundant Array Access    get_D Should Handle the Case of Non-convergence   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Reentrancies",
        "body": "  0  0  1  3  1. During the execution of remove_liquidity and remove_liquidity_imbalance multiple asset transfers are made. One of these assets is ETH, while the others are ERC-20 tokens. The transfer of  ETH  can  lead  to  the  following  reentrancy.  Through  the  transfer  of  ETH,  the  execution  might reenter the contract and call donate_admin_fees. Note that this requires owner privileges. Inside donate_admin_fees, the internal balances mapping for the ERC-20 tokens will be updated as follows:  self.balances[i] = ERC20(coin).balanceOf(self)  This assignment is incorrect in this context as the contract still holds the tokens that are about to be transferred  due  is  complete: self.balances[i] > ERC20(coin).balanceOf(self). This breaks an important invariant in the contract.  liquidity.  Hence,  after   transaction   removed   the   the   to   2. During the call to withdraw_admin_fees an ETH transfer takes place. The transfer of ETH can lead  to  the  following  reentrancy.  Through  the  transfer  of  ETH,  the  execution  might  reenter  the contract  and  call  donate_admin_fees.  Note  that  this  requires  owner  privileges,  but  these  were already needed for withdraw_admin_fees. As a result, the admin fees for some of the coins will be  donated  while  the  admin  fees  for  other  coins  will  be  withdrawn,  leading  to  a  state  that  is  only reachable through a reentrancy.  3. Certain admin functions have no reentrancy protection. Hence, they can be called in a reentrancy from any of the functions that transfers ETH. However, for those reentrancies the only effects are incorrectly  ordered  events.  As  an  example,  a  NewFee  event  could  be  emitted  in  between  multiple events belonging to a remove_liquidity call.  Code  corrected:  Additional  Reentrancy  Guards  were  added.  These  now  also  cover  the  functions donate_admin_fees and apply_new_fee among others.  Curve.Finance - Curve ETH/sETH -   11  CriticalHighMediumCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedSecurityMediumVersion1CodeCorrected        \f6.2   Redundant Use of RATES and PRECISION  RATES  is  a  constant  vector  containing  in  all  cells  the  value  10**18.  PRECISION  is  a  constant  of  value 10**18.  There are cases, such as in exchange, where the value of a cell of RATES is divided by PRECISION. This division is redundant.  rates: uint256[N_COINS] = RATES # Both multiplication with rates[i] and division with PRECISION can be avoided x: uint256 = xp[i] + dx * rates[i] / PRECISION   The code was changed accordingly to remove the redundancies and to save gas.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   _xp and _xp_mem Redundant Array Access",
        "body": "  In  both  _xp  and  _xp_mem  the  array  results  is  initialized  with  the  array  RATES.  However,  results later  ends  up  equal  to  self.balance.  This  is  because  of  the  multiplication  (with  result[i])  and  a redundant division (with LENDING_PRECISION). Note, that RATES equals to LENDING_PRECISION for all i. In the general case this code is useful, however for this token pair, it provides no additional value. RATES and LENDING_PRECISION are constants, the gas overhead is fairly low.  result: uint256[N_COINS] = RATES for i in range(N_COINS):     result[i] = result[i] * self.balances[i] / LENDING_PRECISION return result   The code was changed accordingly to remove the redundancy and to save gas.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   get_D Should Handle the Case of",
        "body": " Non-convergence  The calculation of the invariant D is limited to 255 steps. If there is no convergence then a wrong invariant is returned. The invariant is used to mint liquidity provider tokens. Thus, incorrect number of tokens can be minted. For the case of non-convergence, a verification step of the computed solution could be added.  Code  corrected:  The  new  implementation  reverts  in  case  of  non-convergence.  This  ensures  that  no faulty results are used for further computation.  Curve.Finance - Curve ETH/sETH -   12  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                        \f7   Notes  We leverage this section to highlight further findings that are not necessarily issues.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Content of Events",
        "body": "  The events RemoveLiquidityImbalance and AddLiquidity contain the value D1 which represents the intermediate calculation of the invariant. Including D2 might be more helpful.  The  event  RemoveLiquidityOne  does  not  include  the  information  which  coin  was  removed  from liquidity. That might be relevant information.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Fee Avoidance",
        "body": "  It  is  theoretically  possible  to  avoid  fee  payments  completely  by  repeatedly  exchanging,  adding  or removing such small amounts that fees are zero due to arithmetic errors. This results in a loss of fees for both  fees  will  be overcompensated  by  the  additional  gas  costs.  Hence,  such  a  scenario  would  only  be  realistic  in  the context of Zero-Gasprice Transactions.  liquidity  providers  and  admins.  However,   in  almost  all  cases   the  saved   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Incentive to Remove Liquidity",
        "body": "  There  might  be  an  incentive  for  liquidity  providers  to  remove  liquidity  while  the  amplification  factor  is ramped  down.  In  case  of  a  really  imbalanced  pool  and  a  very  rapid  ramping  down  of  the  amplification factor,  the  following  sequence  might  leave  the  liquidity  provider  with  more  liquidity  tokens  that  they started with:  1. Remove liquidity by withdrawing only the non-scarce asset  2. Wait for the ramping to continue  3. Re-add the removed asset to regain liquidity tokens  In case of a very imbalanced pool and a sharp ramp, the liquidity provider could end up with 0.14% more liquidity tokens than they started with by waiting just ten minutes in step 2. This, however, only works if no other transactions take place inside the pool.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   Inefficiencies When Removing Single Coin",
        "body": "  When removing just a single coin from the pool liquidity, the remove_liquidity_one_coin function can  be  used.  However,  the remove_liquidity_imbalance function and just setting all values except for the desired one to zero. In  our  limited  experiments,  the  biggest  difference  occurred  when  remove_liquidity_imbalance provided 0.00008% additionally withdrawn assets.  in  certain  cases   less  efficient   than  using   function   this   is   Curve.Finance - Curve ETH/sETH -   13  NoteVersion2NoteVersion1NoteVersion1NoteVersion1              \fis   the   difference   Hence,  the remove_liquidity_one_coin  function  is  generally  expected  to  have  lower  gas  costs.  Finally,  it  is functions  as fee  important  remove_liquidity_one_coin  will  coin,  while remove_liquidity_one_coin will pay a roughly equivalent amount of fees in all coins.  two  the  for  the  withdrawn   is  different  in   structure  only   and  mostly   Furthermore,   negligible.   to  note   small   fees   very   that   pay   the   Curve.Finance - Curve ETH/sETH -   14  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Possible Gas Optimization for Mappings",
        "body": "  Although the value for the mapping isOracle is of type bool which needs only 1 bit of storage, Solidity uses a word (256 bits) for each stored value and performs some additional operations when operating bool values (masking). Therefore, using uint instead of bool is slightly more efficient.  Acknowledged:  Maker acknowledged the issue.  MakerDAO - G-UNI LP Oracle -   9  DesignCriticalHighMediumLowAcknowledgedDesignLowVersion1Acknowledged           \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings   Missing Documentation   -Severity Findings   Unused Constant Variable   0  0  1  1  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Missing Documentation",
        "body": "  The requirements about the oracles for the underlying tokens are not documented. In the supplied test file we see following oracles:  address constant USDC_ORACLE        = 0x77b68899b99b686F415d074278a9a16b336085A0; address constant DAI_ORACLE         = 0x47c3dC029825Da43BE595E21fffD0b66FfcB7F6e; address constant ETH_ORACLE         = 0x81FE72B5A8d1A857d176C3E7d5Bd2679A9B85763;  The oracles for USDC and DAI return the unit value of one. The ETH oracle is updated roughly once an hour hence the price returned is not live. For the proper working of the GUniLPOracle a live price feed is required, frequently updated and without a time delay. When GUniLPOracle.seek() is executed, the underlying price feeds must return live values.  Furthermore the underlying principle how the price is determined could be described more clearly in the Readme:  This price feed works by determining how many of token0 and token1 the underlying liquidity position in UniswapV3  held  by  the  GUniPool  has  at  the  current  price.  This  current  price  is  solely  determined  by Maker oracles and independent of the current state of the UniswapV3 pool. The assumption is that  1. The Maker oracles for the underlying tokens return the current market rate  2. In general, e.g. outside flashloan scenarios, the UniswapV3 pool will be balanced at the current market rate. This means that the GUnipool tokens can be redeemed at this current market rate.  Hence  such  a  GUnipool  token  collateral  is  priced  based  on  its  underlying  tokens,  independent  of  the state of the GUni/Uniswap V3 pool. The documentation may be expanded to explain and motivate this.  Specification changed:  Maker responded:  It was a mistake that the test was referring to the ETH/USD OSM. It should have referenced the ETH/USD Medianizer to get a live price feed.  MakerDAO - G-UNI LP Oracle -   10  CriticalHighMediumSpeci\ufb01cationChangedLowCodeCorrectedDesignMediumVersion1Speci\ufb01cationChanged        \fFurthermore the readme has been updated and now contains:  Underlying price oracles `orb0` and `orb1` should refer to either a Medianizer, DSValue or some other `read()` compliant oracle. OSMs should not be used to the double delay.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Unused Constant Variable",
        "body": "  The  variable  WAD  is  declared  as  constant  and  initialized  to  10  **  18,  however  it's  never  used  in  the code.    The unused constant has been removed.  MakerDAO - G-UNI LP Oracle -   11  DesignLowVersion1CodeCorrected        \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Misleading Function Name link",
        "body": "  The  function  name  link(uint256  _id,  address  _orb)  is  misleading  as  it  gives  the  impression that the token _id is linked to the respective oracle initially by this function. However, this function only updates an existing link of the token with the respective oracle (initialized in the constructor).  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   NewGUniLPOracle Indexed Fields",
        "body": "  The  event  NewGUniLPOracle  has  two  indexed  parameters  corresponding  to  the  token  addresses.  In practice, it might be useful if the field address owner is indexed also, as it would allow users to easily filter oracles from a trusted owner.  MakerDAO - G-UNI LP Oracle -   12  NoteVersion1NoteVersion1      \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   file() Has No Access Control",
        "body": "  Function  file()  can  add  and  remove  valid  domains  and  should  be  called  carefully  by  governance. However, the function lacks access control.    Access control was added to file().  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   finalize_register_teleport() Only",
        "body": " Possible When Open  Calling finalize_register_teleport() on Starknet allows users to take the slower route through Starknet message passing to L1 to prevent censorship by the oracles and ensure availability if oracles are down. However, given that the function is not callable if the bridge is closed, the system, in contrast to the Teleport for Optimism and Arbitrum, is not fully trustless, as users could be censored by closing the teleport instance. Further, censored users that had their L2 DAI burned, will not be able to recover it.    The precondition of finalize_register_teleport() has been removed.  MakerDAO - Starknet Teleport -   10  CriticalHighMediumCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedSecurityMediumVersion1CodeCorrectedCorrectnessMediumVersion1CodeCorrected                    \f6.3   No Event for finalize_teleport()  finalize_teleport() emits no event in contrast to other functions (e.g. initiate_teleport()). Emitting more events could lead to a better user-experience and easier integration with front-ends.    An event has been added.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Unused Code",
        "body": "  l2_dai_teleport_gateway  prepares  a  payload  in  initiate_teleport()  even  though  it  remains unused.  l2_dai_teleport_gateway has several unused imports:   BitwiseBuiltin   hash2   assert_le  is_not_zero   get_contract_address   uint256_lt   uint256_check    Unused imports and unused code were removed.  MakerDAO - Starknet Teleport -   11  DesignLowVersion2CodeCorrectedDesignLowVersion1CodeCorrected               \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Gas Inefficiencies",
        "body": "  0  0  0  9  We have found some gas inefficiencies that could be optimized:   Lido saves several contract addresses (e.g., the ETH deposit contract) in the storage. Since Lido is upgradeable, the mentioned variables could be exchanged with constants or immutables that can be updated with a Proxy upgrade to save storage reads on various interactions.   Lido.handleOracleReport  updates  the  BEACON_VALIDATORS_POSITION  even  when  the  amount of validators has not changed.   StakeLimitUtils.calculateCurrentStakeLimit  performs  stake  limit  calculations  even just  return  the  prevStakeBlockNumber   the  current  block  number.   It  could   is   when  prevStakeLimit in that case.   NodeOperatorsRegistry.removeSigningKeys  and  removeSigningKeysOperatorBH  are inefficient if 0 < (totalSigningKeys - 1) - _index < (_amount - 1) as more swaps from the last to the current position are performed than necessary.   NodeOperatorsRegistry._removeSigningKey  assigns  the  new  totalSigningKeys  value to a value that is loaded from storage, while the same value has already been loaded from storage before (lastIndex).  Lido - Lido -   11  DesignTrustCriticalHighMediumLowAcknowledgedRiskAcceptedAcknowledgedRiskAcceptedRiskAcceptedAcknowledgedAcknowledgedAcknowledgedRiskAcceptedDesignLowVersion1Acknowledged           \f NodeOperatorsRegistry.assignNextSigningKeys   calculates stake  +  1  >  entry.stakingLimit  while  stake  >=  entry.stakingLimit  would  be sufficient.   NodeOperatorsRegistry.assignNextSigningKeys finds the operator with the smallest stake with  the  statement  bestOperatorIdx  ==  cache.length  ||  stake  <  smallestStake. This  can  be  simplified  to  stake  <  smallestStake  by  initially  setting  smallestStake  to  the maximum value of uint256.   NodeOperatorsRegistry._storeSigningKey  and  _loadSigningKey  load  signatures  by iterating  over  the  words  of  the  signature  and  loading  them  from  the  memory  location  at add(_signature, add(0x20, i)) on every iteration. This can be simplified to i by setting the 32  +  loop  to to  i <= signature + SIGNATURE_LENGTH.  signature   execution   condition   variable   and   the    LidoOracle  pushes  reports  to  the  CompositePostRebaseBeaconReceiver  which  pushes reports to the SelfOwnedStETHBurner. Since the SelfOwnedStETHBurner is currently the only receiver, this indirect route is not necessary.   SelfOwnedStETHBurner._requestBurnMyStETH  uses  Lido.transfer  and  calculates  the share  amount  by  calling  Lido.getSharesByPooledEth.  This  second  call  could  be  avoided  by using the transferShares function.  Acknowledged:  Lido states:  Thank you for the suggestions, we will take them into consideration for the next protocol upgrade.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Inconsistent Event Order",
        "body": "  The  order  in  which  the  Transfer  and  TransferShares  events  are  emitted  is  inconsistent.  In  the transferShares  function  in  StETH,  the  TransferShares  event  is  emitted  first.  In  all  other  cases, Transfer is emitted first.  Note also that these events are always emitted after calling the _transferShares function. To avoid the duplication of emitted events and reduce code size, it would also be possible to emit the events within the _transferShares function itself.  Risk accepted:  This change is scheduled for the next update.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   LidoOracle Initialized With Wrong Epoch",
        "body": "  In the initialize function of the LidoOracle, the expectedEpoch is set as follows:  uint256 expectedEpoch = _getFrameFirstEpochId(0, beaconSpec) + beaconSpec.epochsPerFrame;  Lido - Lido -   12  DesignLowVersion1RiskAcceptedDesignLowVersion1Acknowledged                \fHowever,  _getFrameFirstEpochId  will  always  return  0  here.  So  the  first  expected  epoch  is  set  to beaconSpec.epochsPerFrame. However, it would make little sense for a member to report an epoch before the contract was deployed. Instead, the expectedEpoch could be set to an epoch which occurs after the contract is deployed, for example using _getCurrentEpochId.  Acknowledged:  The  initialize  function  can't  be  called  again  on  the  Lido  contract,  which  is  already  deployed. Therefore this is only an issue if a redeployment becomes necessary.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.4   Malicious Node Operators",
        "body": "  Node operators are trusted entities in the Lido ecosystem. They are responsible for correctly running the validators as well as distributing MEV rewards to the contract. They can only be incentivized to behave decently  so  it  is  possible  that  certain  economic  opportunities  could  incentivize  them  to  behave maliciously.  For example, it can be hard to verify the amount of MEV rewards node operators generate with the nodes they  are  running.  Malicious  node  operators  could  choose  to  not  distribute  these  rewards  but  instead pocket them themselves.  Furthermore, and most importantly, node operators have no ownership of the ETH that are locked in their validators. This means that whatever incentive they have to run the nodes benevolently could be offset by a more financially lucrative incentive. One example could be a short position in stETH that becomes profitable. As the staked ETH are not owned by the operators, this is very much possible due to slashing as can be seen in the following example (assuming the Merge has already happened and according to current spec):   A  malicious  node  operator  executes  2  attestations  to  the  same  target  on  all  of  their  controlled validator nodes. At the time of this writing, single validators run up to ~8,000 nodes of the ~400,000 nodes currently on the Beacon Chain).   Each node gets slashed by 1 ETH, reducing the amount of ETH in the protocol by ~8,000 or ~0.1%  of Lido's total supply.   After 18 days, the validators get slashed again based on the amount of validators that have been  slashed in the previous 16 days: Each validator loses ~1.8 ETH.  In total, the supply of Lido drops by ~0.5%.  If 2 node operators collude, the total supply drops by ~1.7%. If 3 operators collude, it drops by ~3.6%.  Depending  on  the  market  reaction,  the  value  of  stETH  could  decrease  dramatically  following  these events, making a decently sized short position in stETH (or more likely wstETH) profitable.  Risk accepted:  Lido states:  The  risk  is  mitigated  by  maintaining  healthy  validators  set  with  monitoring  and  DAO  governance processes. There is a set of policies and management actions:   onboarding new NOs to decentralize further;  limiting the stake amount per single NO;  Lido - Lido -   13  TrustLowVersion1RiskAccepted          \f developing  dashboards  and   tools   to  monitor  network  pasticipation  performance  (now  open-sourced https://github.com/lidofinance/ethereum-validators-monitoring)   developing  dashboards  and  tools  to  monitor  MEV  and  priority  fee  distribution  (approaching  testing stage for the upcoming Merge)  Despite  the  fact  that  Ethereum  staking  is  not  delegation-friendly,  Lido  DAO  already  has  on-chain levers  to  address  malicious  NO  behavior:  excluding  them  from  the  new  stake,  disabling  fee distribution, excluding them from the set, considering penalties on other chains if applicable, and so on.  Once  and  if  withdrawal-credentials  initiated  exits  are  implemented,  there  will  appear  additional on-chain enforcement mechanics which would allow building more permissionless schemes for the validators set.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.5   No Events on Important State Changes",
        "body": "  The DepositSecurityModule does not emit events on the following important state changes:  1. When the owner calls setLastDepositBlock.  2. When depositBufferedEther is called.  Risk accepted:  Lido states:   setLastDepositBlock will be used only if re-deploy is needed, so we may add the event for  future versions.   depositBufferedEther emits the Unbuffered event in the Lido contract which is still enough  for indexers, though, will consider the change if an upgrade is needed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.6   Typing Errors",
        "body": "   NodeOperatorsRegistry._loadOperatorCache returns an error message with a typing error:  INCOSISTENT_ACTIVE_COUNT.   Lido._setProtocolContracts emits the event ProtocolContactsSet.  Acknowledged:  This will be fixed in the next major protocol upgrade.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.7   Unused Imports",
        "body": "  Lido imports SafeMath64.sol which is not used in the contract.  Lido - Lido -   14  DesignLowVersion1RiskAcceptedDesignLowVersion1AcknowledgedDesignLowVersion1Acknowledged                        \fAcknowledged:  This will be fixed in the next major protocol upgrade.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.8   memcpy Optimizations",
        "body": "  The memcpy function in the MemUtils library is quite critical for gas costs. It is called by copyBytes, which  in NodeOperatorsRegistry.assignNextSigningKeys. The function itself also contains a loop, for a total of three nested loops.  nested   called   within   loops   from   turn   in   is   While it is already written in assembly, it can be optimized further. First, let's take a look at the loop.  for { } gt(_len, 31) { } {     mstore(_dst, mload(_src))     _src := add(_src, 32)     _dst := add(_dst, 32)     _len := sub(_len, 32) }  As  it  stands,  there  are  three  variables  which  are  modified  per  loop  iteration.  Ideally,  one  would  only change one variable per iteration, and use a loop bound based on this variable. However, this change would add additional overhead outside the loop, which may not pay off in general. Currently, the loop is only executed 1-3 times per call, as the _len parameter is only ever 48 or 96. One may also consider creating functions specifically for copying byte arrays of length 48 and 96, as this would allow a complete unrolling of the loop.  After the loop, the following code is executed:  if gt(_len, 0) {     let mask := sub(shl(1, mul(8, sub(32, _len))), 1) // 2 ** (8 * (32 - _len)) - 1     let srcMasked := and(mload(_src), not(mask))     let dstMasked := and(mload(_dst), mask)     mstore(_dst, or(dstMasked, srcMasked)) }   As _len is a uint256, it is more efficient to just check the condition if _len {.   The  mask   could   also   be  written   as  shr(0xff..ff,  shl(3,  _len))   or  shr(not(0), shl(3, _len)).  Acknowledged:  Lido states:  We decided to leave the assembly code as is to prevent possible peculiarities.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.9   sharesAmount Can Be Zero",
        "body": "  Lido - Lido -   15  DesignLowVersion1AcknowledgedDesignLowVersion1RiskAccepted                \fDue  to  rounding  errors,  the  value  returned  by  getSharesByPooledEth  can  be  zero.  In  the  function _submit in Lido, the check sharesAmount == 0 is made. This is assumed to hold either on the first deposit,  or  in  the  case  of  a  complete  slashing.  However,  this  can  also  occur  if  rounding  errors  lead  to getSharesByPooledEth returning 0. Thus, a user would receive a disproportionate amount of shares, as they would get a 1:1 rate of ETH to StETH, despite the share value being lower. Note that with the current state of the live contracts, this can only occur if msg.value == 1.  Risk accepted:  Lido is aware of rounding errors, however chooses not to fix them as they are difficult to correct without sacrificing gas efficiency or backwards compatibility.  Lido - Lido -   16  \f6   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Deposits Can Be Blocked by Node Operators",
        "body": "  DepositSecurityModule  requires  the  keysOpIndex  to  not  change  between  creation  of  a depositBufferedEther transaction and its execution:  uint256 onchainKeysOpIndex = INodeOperatorsRegistry(nodeOperatorsRegistry).getKeysOpIndex(); require(keysOpIndex == onchainKeysOpIndex, \"keys op index changed\");  Since the keysOpIndex can be changed by node operators using addSigningKeysOperatorBH or removeSigningKeysOperatorBH, malicious node operators can delay depositing even when they are not  activated.  The  only  way  to  counter  this  problem  is  to  change  the  rewardAddress  of  such  node operators.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   No Quorum Sanity Checks",
        "body": "  LidoOracle and DepositSecurityModule allow the addition of members / guardians and the setting of  a  quorum  that  has  to  be  reached  by  these  entities.  The  quorum  can  however  be  set  to  any  value (except for 0 in the case of LidoOracle) independently of the number of members / guardians.  Lido - Lido -   17  NoteVersion1NoteVersion1      \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Race Condition on Approvals",
        "body": "  Since there is no direct way to increase and decrease allowance relative to its current value, the function AllowanceTransfer.approve()  has  a  race  condition  similar  to  one  of  ERC-20  approvals.  Further details regarding the race condition can be found here.  Risk accepted:  Uniswap responded:  We opted not to address this issue. If users really care about this attack vector it means they are likely signing a spender they don\u2019t fully trust, and they can always approve(x), approve(0), approve(y). We also expose a lockdown function that can batch remove approvals for users, before setting new approvals.  Uniswap - Permit2 -   11  SecurityDesignCriticalHighMediumRiskAcceptedLowDesignMediumVersion1RiskAccepted            \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings   Permit2Lib Argument Casting   -Severity Findings  -Severity Findings   CALL to DOMAIN_SEPARATOR()   0  1  0  1  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Permit2Lib Argument Casting",
        "body": "  The  functions  permit2  and  transferFrom2  of  Permit2Lib  both  take  uint256  amount  as  an argument. The lib will first attempt to call the token directly and falls back to the call to Permit2 if it fails. However,  the  Permit2.permit  and  Permit2.transferFrom  take  uint160  amount  as  an argument. The initial uint256 amount will be cast to uint160 for that call. Assuming some contract A relies on transferFrom2 for token transfers, the following can happen:  1. The user calls a function on A that attempts to pull funds from the user using transferFrom2. For  amount, the user specifies 2**170.  2. A direct call to token.transferFrom fails.  3. Permit2Lib falls back to Permit2.transferFrom with uint160(2**170) == 0 as an amount.  4. The call is successful. No value is actually transferred.  5. Contract A now thinks that 2**170 tokens were actually transferred.  Similar casting happens in the permit2 function.    The SafeCast library is now used for casting to a uint160 before the Permit2 contract is called. The casting of a value that is greater than type(uint160).max would revert now.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   CALL to DOMAIN_SEPARATOR()",
        "body": "  EIP-712 defines the function DOMAIN_SEPARATOR() as a view function. Hence, it is expected to always work  properly  with  STATICCALL.  However,  Permit2Lib.permit2()  queries  the  domain  separator with CALL, allowing the state to change in sub-calls as well as reentrancy. The contracts that will use the Permit2Lib could break unexpectedly.  Uniswap - Permit2 -   12  CriticalHighCodeCorrectedMediumLowCodeCorrectedSecurityHighVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \f  The STATICCALL is used to query the DOMAIN_SEPARATOR in    of the code.  Uniswap - Permit2 -   13  Version2\f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Overflow Theoretically Possible for ",
        "body": " AllowanceTransfer.nonces  nonce   Nonces  are  incremented  with  unchecked  arithmetic.  This  means  that  incrementing  them  may  lead  to overflows, allowing for replay attacks. This is unlikely to happen solely through permit, which increases uint32.  However,  with the  AllowanceTransfer.invalidateNonces() overflows could happen after 65537 calls since it uses type uint16. Thus, signers can potentially endanger themselves by misusing the invalidateNonces function.  nonce   since   type   one   the   by   of   is    changes: nonce is of type uint48 in updated code. Thus, while the overflow is theoretically still  possible, practically it is highly unlikely to happen.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Signature Malleability if Misused",
        "body": "    of  the  code  the  SignatureVerification.verify  function  accepts  EIP-2098 In  the  compact 64 byte signature in addition to the traditional 65 byte signature format. If the replay protection mechanism  is  implemented  using  the  signature  itself,  an  attack  can  be  performed.  The  contracts  of Permit2  use  nonces  the SignatureVerification library must be done with this attack in mind. OpenZeppelin library had such an incident before.  thus  are  safe.  But  any   replay  protection  and   reuse  of   for   Also, the SignatureVerification does not perform checks described in Appendix F of the Ethereum Yellow  paper  e.g.  0  <  s  <  secp256k1n  \u00f7  2  +  1.  Thus,  for  any  given  signature  a  signature  with s-values in the upper range can be calculated. If the replay protection mechanism is implemented using the signature itself, an attack can be performed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   invalidateUnorderedNonces Possible",
        "body": " Arguments  SignatureTransfer.invalidateUnorderedNonces  can  invalidate  nonces  with  wordPos  values up  to  uint256.max.  However  _useUnorderedNonce  can  only  invalidate  up  to  uint248.max.  This allows the invalidation of nonces that can never be used.  Uniswap - Permit2 -   14  NoteVersion1Version2NoteVersion2Version2NoteVersion1          \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Blank Votes Not Counted",
        "body": "  0  1  5  4  4  In InclusionVote, the winner is determined as follows:  if votes > winner_votes:         candidate: address = self.candidates[epoch][i]         if self.rate_providers[candidate] in [empty(address), APPLICATION_DISABLED]:             # operator could have unset rate provider after             continue         winner = candidate         winner_votes = votes  CS-YEGOV-013  Yearn - yETH Governance -   14  CriticalHighCodeCorrectedMediumCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedSpeci\ufb01cationChangedCorrectnessHighVersion1CodeCorrected         \fThe zero (blank) candidate will not have a rate provider set. The condition for continue will be fulfilled and the winner_votes will not be set to the blank votes.  As  a  result,  the  blank  votes  are  ignored  and  a  candidate  with  fewer  votes  than  the  blank  votes  can become the winner.    A special case has been added for candidate == 0x0. Now, the votes of the zero address are counted. Additionally,  the  zero  address's  rate_provider  is  not  set  to  APPLICATION_DISABLED  when  the  zero address is the winner.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Balance Used Instead of Voting Weight in ",
        "body": " DelegateMeasure  When  computing  the  voting  weight  of  an  account,  if  the  account  has  been  delegated  to,  the  following formula is used to compute the additional weight.  weight += Staking(staking).balanceOf(delegated) * self.delegate_multiplier / DELEGATE_SCALE  CS-YEGOV-018  Since the balance can be altered without delay simply by acquiring the staking token on the spot, the call to balanceOf is prone to manipulation.  This  issue  was  found  during  the  review.  It  was  also  reported  independently  by  Yearn  while  the  review was still ongoing.    This  was  fixed  in  vote_weight at the end of the week.    by  storing  delegated  stake  in  a  separate  vault,  which  only  updates  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Griefing by Flooding Malicious Proposals",
        "body": "  In GenericGovernor, as long as an attacker holds at least propose_min_weight tokens, they can submit as many proposals as they want, paying only gas.  If these proposals would hurt the protocol, other users are forced to vote nay each time, to ensure the proposal does not pass. There is no quorum needed to pass a proposal.  It  may  also  be  problematic  if  the  same  proposal  is  submitted  multiple  times.  Voters  will  need  to coordinate and choose which of these they want to pass, while rejecting the others. See also: Voters trust proposal author not to retract.  CS-YEGOV-015    Yearn - yETH Governance -   15  CorrectnessMediumVersion1CodeCorrectedVersion2DesignMediumVersion1CodeCorrected                \fA quorum has been added to the GenericGovernor, meaning that a minimum number of yes + no votes is now  required  for  a  proposal  to  pass.  Governance  functions  for  setting  the  quorum,  as  well  as  view functions to read it have also been added.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   InclusionVote Operator Trust",
        "body": "  CS-YEGOV-016  The  InclusionVote  contract  has  an  operator  role,  which  is  tasked  with  setting  rate  providers  for proposed tokens.  In the current implementation, the operator can change the rate provider at any time. In particular, it can change the rate provider even after voters have already voted.  This design results in the operator role needing to be fully trusted to set a correct rate provider.  If an alternative design was chosen where the rate provider can no longer change between the beginning of the voting period and finalize_epoch(), the voters could ensure that they are voting for a correct rate provider and that it cannot change after their vote. This would reduce the trust assumption on the operator role.    Now, the operator can only change a rate provider that was previously set if:  1. The voting period of the current epoch has not started  2. The previous epoch has already been finalized  If the rate provider has never been set (still 0x0), it can still be added at any time.  This means that voters can now independently check that the operator has set a correct rate provider, and can be sure that it will not change after they vote. This reduces the trust required in the operator.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Proposals Can Be Enacted After More Than",
        "body": " One Epoch  CS-YEGOV-014  To enact proposals in the GenericGovernor via enact, the proposal state is checked and asserted to be  PASSED  by  calling  _proposal_state().  The  function  _proposal_state  explicitly  returns PASSED  only  if  current_epoch  ==  vote_epoch  +  1.  Consequently,  a  proposal  must  be  enacted one epoch after vote_epoch.  However, by calling update_proposal_state() on a proposal that just passed, it is possible to set the state of this proposal to PASSED in storage. In this case, it is possible to circumvent the condition that a proposal needs to be enacted one epoch after vote_epoch, because _proposal_state() returns PASSED from now on due to: if state != STATE_PROPOSED return state.  This will allow the execution of the proposal forever, even though it should revert if it is not executed in the epoch after passing.    Yearn - yETH Governance -   16  TrustMediumVersion1CodeCorrectedCorrectnessMediumVersion1CodeCorrected                \fThe  state  is  now  reevaluated  when  calling  _proposal_state(),  even  if  the  storage  was  set  to PASSED.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Voters Trust Proposal Author Not to Retract",
        "body": "  CS-YEGOV-012  In  GenericGovernor,  a  proposal  can  be  retracted  by  its  author  at  any  point  up  until  the  end  of  the voting period. This means that the author can grief voters by retracting maliciously.  Consider the following situation:  1. The community decides off-chain that a certain proposal is something they want to vote on.  2. Alice has propose_min_weight votes and anonymously submits the proposal.  3. The proposal receives 99% yea votes.  4. One hour before the vote period ends, Alice retracts the proposal.  5. Now the proposal will not be executable and it will take at least another epoch until it can be voted  on again and pass.  To avoid this, the proposal author needs to be trusted by the voters.  As a possible countermeasure, the same proposal could be submitted multiple times by different authors. However,  this  could  be  problematic  if  the  proposal  does  something  which  should  not  happen  multiple times, (e.g., send some tokens) and more than one of the proposals pass.    Proposals can now no longer be retracted once the voting period has begun.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Access Control Can Have Invalid Value",
        "body": "  The access control in Executor is set using the Access enum. When something should have a whitelist, the enum is set to a value of 1, when it should have a blacklist, it is set to a value of 2. If neither is true, it should be set to the default value of 0.  However, in Vyper it is also possible to set enum in such a way that multiple \"flags\" are set at once, not just  one.  set_access()  has  no  sanity  check  for  the  access  argument.  As  a  result,  set_access() could be called by the management with a value of 3, which is a valid value in Vyper and represents the states whitelist and blacklist being true at the same time.  However, the contract is not designed to handle this value and will treat it the same as 0.  CS-YEGOV-009    A  check  has  been  added  that  disallows  values  that  are  greater  than  2.  Now  the  only  possible  enum values are default, whitelist and blacklist.  Yearn - yETH Governance -   17  TrustMediumVersion1CodeCorrectedDesignLowVersion1CodeCorrected                  \f6.8   Delegation Could Allow Double Voting  CS-YEGOV-011  In DelegateMeasure, an address that has given a delegation to another address, has a vote_weight of 0, which means it can no longer vote directly.  However,  the  delegate()  function  does  not  check  if  the  address  that  is  giving  delegation  has previously voted during the current epoch. As a result, it is possible that an address first votes with its own vote_weight, then delegate() is called. This would allow the voting power to be used a second time by the address receiving the delegation.  Note  that  delegate()  can  only  be  called  by  the  management  role,  which  is  expected  to  be  used through the GenericGovernor. In this case, the issue can be avoided by calling enact() before the VOTE_PERIOD starts, given that the delay is smaller than VOTE_START.    This  was  fixed  in  vote_weight at the end of the week.    by  storing  delegated  stake  in  a  separate  vault,  which  only  updates  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   Number of Assets Could Change During Vote",
        "body": "  In WeightVote, the number of assets in the Pool is queried once when the first vote in a voting period happens. The value is cached and not updated for the rest of the epoch.  If the number of assets changes within the voting period, it will be impossible to vote for the newly voted asset. This would only happen if the execute function of PoolGovernor is called late (in the last week of the epoch) by the operator.  CS-YEGOV-010    Yearn removed the caching of the number of tokens and now queries them directly from the pool.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   Race Condition in GenericGovernor",
        "body": "  If a proposal is passed that stops another proposal in the same epoch from being enacted, whether by explicitly  canceling  it  or  by  modifying  common  parameters  such  as  majority,  then  a  race  condition occurs whereby depending on the order in which the proposals are enacted, the end result is different.  Note that enact() can be called by anyone, thus this ordering is also subject to MEV.  Yearn found and reported this issue while the review was ongoing.  CS-YEGOV-005    Yearn - yETH Governance -   18  DesignLowVersion1CodeCorrectedVersion2DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                      \fIn  epoch.  , enact() uses the values of majority and delay snapshotted at the end of the previous  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.11   Majority Parameter Can Be Less Than Fifty",
        "body": " Percent  In GenericGovernor, the majority parameter can counterintuitively be set to less than 50%.  This would mean that a proposal with more no votes than yes votes can pass.  CS-YEGOV-006    Yearn now enforces a range betweeen VOTE_SCALE / 2 and VOTE_SCALE for majority.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.12   Missing Events",
        "body": "  The  constructors  of  DelegateMeasure,  Executor,  GenericGovernor,  InclusionIncentives, InclusionVote, OwnershipProxy, PoolGovernor, WeightIncentives and WeightVote do not emit the SetManagement() event.  CS-YEGOV-008  Specfication changed  Yearn answered:  This is intentional, as it would require to also emit events for a lot of other parameters during the constructor to be fully consistent. For example, in the generic governor constructor we set a value for measure, delay, quorum, majority and delay.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.13   Sanity Checks",
        "body": "  Multiple  functions  do  not  sanitize  their  input.  E.g.,  the  Executor  contract  in  set_access(), set_governor(),  whitelist()  and  blacklist()  do  not  check  for  address  zero.  We  advise reviewing which functions would benefit from a sanity check, even if they are permissioned.  CS-YEGOV-007    Yearn  changed  the  listed  functions  and  implemented  sanity  checks.  We  additionally  assume  Yearn checked all other potential functions and added checks.  Yearn - yETH Governance -   19  Version2InformationalVersion1CodeCorrectedInformationalVersion1Speci\ufb01cationChangedInformationalVersion1CodeCorrected                    \f6.14   Should Governance Be Able to Evict the Treasury  CS-YEGOV-017  the   setTreasury()   In  and WeightIncentives,  the  management  role  has  the  power  to  change  the  treasury  address  to  an arbitrary  value.  The  yETH  protocol  is  designed  to  be  governed  by  st-yETH  holders.  At  the  same  time, YIP-72 says that the treasury should be the \"Yearn Treasury or an autonomous splitter contract directed by yBudget.\" Is it intended that holders are able to direct the treasury revenue away from Yearn?  InclusionIncentives   InclusionVote,   function   of   Specification changed  This described behavior was originally intended. But after being raised and careful consideration, Yearn decided that only the treasury shall be allowed to call setTrasury and changed the code accordingly.  Yearn - yETH Governance -   20  InformationalVersion1Speci\ufb01cationChanged    \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Gas Optimisations",
        "body": "  We discovered the following potential gas optimizations:  1. The Proxy interface in Executor uses Bytes[65536] as data argument, but the OwnershipProxy only  supports  Bytes[2048].  The  calldata  variable  in  execute()  also  uses  this  large  Array size.  In  Vyper,  arrays  reserve  memory  slots  for  their  maximum  size,  even  when  many  of  the elements are zero. As a result, the memory will be extended by 65536 Bytes as soon as another variable is placed in memory after the array. This is very expensive.  2. uint could be used instead of boolean values. E.g., as governor flag in Executor.  CS-YEGOV-003  Code partially corrected  Yearn decided to decrease the overall max script size to Bytes[2048]. In the rare case that a proposal requires  a  script  larger  than  this,  they  can  work  around  it  by  deploying  a  one-time  use  contract  that  is granted a temporary governor role during execution.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   PoolGovernor Can Skip Epochs",
        "body": "  The  PoolGovernor's  execute  function  always  executes  the  vote  results  for  epoch  -  1.  This  means that  if  execute()  is  not  called  during  an  epoch,  the  preceding  epoch's  vote  results  will  never  be executed.  The winner in InclusionVote has its rate_provider set to APPLICATION_DISABLED, so if an asset wins but then the execution of the winning epoch is skipped, that asset cannot be proposed again unless the operator of InclusionVote sets the rate_provider again.  The  execute  function  can  only  be  called  by  the  operator  of  PoolGovernor.  If  the  operator  is unavailable or malicious, it may not be called.  CS-YEGOV-001  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Unused Code",
        "body": "  The following code is not used:   WeightVote: the interface definition of Measure.total_vote_weight   InclusionVote: the interface Measure.total_vote_weight  CS-YEGOV-004  Yearn - yETH Governance -   21  InformationalVersion1CodePartiallyCorrectedInformationalVersion1InformationalVersion1CodePartiallyCorrected              \f InclusionIncentives:   the   interface  voting.candidates_map  and   the  constants  VOTE_START and VOTE_LENGTH.   WeightIncentives: the constants VOTE_LENGTH and VOTE_START   GenericGovernor: the interface definition Measure.total_vote_weight  Code partially corrected  The unused interfaces were removed. The unused constants still exist in WeightIncentives.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   DelegatedStaking Does Not Strictly",
        "body": " Conform to ERC-4626  maxDeposit() and maxMint() return  . Per ERC-4626, \"MUST NOT be higher than the actual maximum that would be accepted\". The balance is eventually stored packed in only 240-bits. Therefore, . However, this is not enforced in the code, rather the supply of ETH the theoretical maximum is  is assumed to upper-bound the system.  CS-YEGOV-002  Yearn - yETH Governance -   22  InformationalVersion1    \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Epoch Boundary Agreement",
        "body": "  To prevent double voting, VOTE_LENGTH should always be at most one week, EPOCH_LENGTH should always be a multiple of one week, and genesis should be set to a multiple of one week. This is to be consistent with the current Staking contract which provides voting weights.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Governance Proposal Passes In The Event Of",
        "body": " A Tie  In GenericGovernor, the condition for a proposal to be treated as passed is as follows:  if votes > 0 and yea * VOTE_SCALE >= votes * self.majority:     return STATE_PASSED  Assuming majority is 50% and a proposal has one yea and one nay vote, it will pass.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.3   Limted Number of Pool Tokens",
        "body": "  Pools have 32 slots. This sets a cap to the maximum number of tokens to add. Once included, a token can never be removed from the protocol. Removing tokens from a pool would need a redeploy.  In PoolGovernor, the execute function will get the winner of the InclusionVote and try to add it to the Pool.  If there are already 32 assets in the Pool and InclusionVote has a winner, execute() will revert. This will also make it impossible to change the weights during that epoch.  The management of InclusionVote should call disable() once there are 32 assets to avoid this.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.4   Power of the PoolGovernor Operator",
        "body": "  The specifications currently say that the operator of PoolGovernor has limited power. This is true but the operator role is still extremely powerful as it must be trusted to set the pool values like amplification and ramping in a non-exploitable way. The parameters the operator role can set are critical in a yETH pool and related to other parameters. Hence, as mentioned in the system assumptions, ths role needs to be fully trusted.  Yearn - yETH Governance -   23  NoteVersion1NoteVersion1NoteVersion1NoteVersion1                \f8.5   Ramp_Duration Should Be Chosen Carefully  The ramp_duration variable in PoolGovernor should be chosen carefully. If it is too short, it may be possible to make profitable sandwich attacks.  It  should  also  not  be  too  long.  In  particular,  it  must  be  shorter  than  the  length  of  an  epoch,  as  assets cannot be added to the Pool while there is an ongoing ramp. The operator of PoolGovernor should call  execute()  at  least  ramp_duration  before  the  end  of  the  epoch,  so  that  the  ramp  ends  by  the time execute() is callable again.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.6   Rebasing and Fee-On-Transfer Tokens Cannot",
        "body": " Be Used as Incentives  Both  InclusionIncentives  and  WeightIncentives  keep  internal  balances  for  tokens  used  as incentives. This is done in such a way that, if the contract ends up with more tokens than expected, then the  leftover  amount  will  be  lost.  If  the  contract  ends  up  with  fewer  tokens  than  expected,  then transfer() will fail and the last user to claim will not be able to receive the incentives they are owed.  Yearn - yETH Governance -   24  NoteVersion1NoteVersion1      \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   CRV Not Locked When Used to Mint YCRV",
        "body": "  When YCRV is minted with the mint() function, CRV is not locked.  In yveCRV, CRV is locked upon minting. In YCRV.mint(...) it is not locked immediately, but a separate call to StrategyProxy.lock() is needed.  assert ERC20(CRV).transferFrom(msg.sender, VOTER, amount)  # dev: no allowance self._mint(_recipient, amount) log Mint(msg.sender, _recipient, False, amount) return amount  Not locking the CRV immediately in the CRV voting escrow implies a mismatch between the total supply of  YCRV  and  the  effective  voting  power  and  total  rewards  of  VOTER.  It  also  imposes  increased  trust requirements towards governance, which might sweep the not yet locked CRV from the VOTER.  Risk accepted  Yearn states:  Locking CRV is gas intensive. Decision was made to have locking occur at some periodic interval via external process rather than burden each user with gas costs.  Yearn - yCRV and ZapYCRV -   10  SecurityDesignCorrectnessCriticalHighMediumRiskAcceptedLowRiskAcceptedCorrectnessMediumVersion1RiskAccepted             \f5.2   Trades During ZapYCRV.zap Conversions  The ZapYCRV.zap function can involve multiple Curve pools during the conversion.  First, CRV -> LPYCRV conversions will involve up to 2 trades in LPYCRV pool:  1. Trade of all CRV to yCRV  2. Trade of some yCRV to CRV, during the unbalanced deposit into the pool  Compared to trade of some CRV to yCRV and a balanced deposit, the 2 trades double pay the fees.  Second,  in  the  case  when  CVXCRV  is  an  input,  these  2  trades  are  preceded  by  a  trade  on CVXCRVPOOL.  Please  note,  that  due  to  number  of  pools  and  exchanges  during  the  conversion  process  the  min_out argument  can  be  hard  to  specify  precisely.  In  addition,  imprecise  min_out  specified  would  allow  3rd parties to front run the zap.  Risk accepted  Yearn states:  Realize that for some specific paths, this can be inefficient. However, hardcoding paths will lead to more contract complexity and overall gas consumption (including for users who\u2019s zap path touches neither of these tokens) which we view as undesirable. We agree that users can potentially lose more due to swap fees, but ultimately most of those same fees get realized to the pool LPs, helping to repay them over time.  Yearn - yCRV and ZapYCRV -   11  SecurityLowVersion1RiskAccepted        \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings   LPYCRV Outputs Not Transferred to User   -Severity Findings  Incorrect relative_price When Input Is Not Legacy and Output Is LPYCRV   -Severity Findings   ZapYCRV _min_out LPYCRV Limit   -Severity Findings   ERC20 Return Values Not Checked    ZapYCRV.zap Natspec   1  1  1  2  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   LPYCRV Outputs Not Transferred to User",
        "body": "  In the zap function of ZapYCRV, converting to LPYCRV as _output_token will not transfer LPYCRV to the user but leave it in the ZapYCRV contract instead.  When  LPYCRV  is  the  output  token,  ZapYCRV  should  first  deposit  YCRV  as  liquidity  in  the  POOL StableSwap pool, receiving the POOL liquidity token. The POOL liquidity token should then be deposited in the LPYCRV vault and the issued shares transferred to the user.  The following line of code in _convert_to_output is responsible for the specified logic.  amount_out: uint256 = Vault(LPYCRV).deposit(self._lp([0, amount], _min_out,     _recipient))  which calls the self._lp(...) function, defined as  @internal def _lp(_amounts: uint256[2], _min_out: uint256, _recipient: address) -> uint256:     return Curve(POOL).add_liquidity(_amounts, _min_out)  The  _recipient  argument  is  passed  to  the  _lp  function,  but  never  used.  The  _lp  function  doesn't actually need the _recipient argument, because ZapYCRV will still need to deposit the liquidity token into the LPYCRV vault.  The Vault(LPYCRV).deposit function is called without specifying the recipient argument, which therefore  defaults  to  msg.sender,  which  is  the  ZapYCRV  contract  in  the  context  of  the  deposit  call. Finally the zap function returns and the issued shares of LPYCRV are never transferred to the user, but left to ZapYCRV instead.  Yearn - yCRV and ZapYCRV -   12  CriticalCodeCorrectedHighCodeCorrectedMediumCodeCorrectedLowCodeCorrectedCodeCorrectedCorrectnessCriticalVersion1CodeCorrected         \fCode corrected  The recipient argument of the _lp function has been removed.  @internal def _lp(_amounts: uint256[2]) -> uint256:         return Curve(POOL).add_liquidity(_amounts, 0)  A  recipient  value  _convert_to_output function.  is  now  specified   in   the  deposit  call   to   the  LPYCRV  vault   in   the  amount_out: uint256 = Vault(LPYCRV).deposit(self._lp([0, amount]), _recipient)  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Incorrect relative_price When Input Is Not",
        "body": " Legacy and Output Is LPYCRV  In relative_price the relative price for the POOL liquidity token is returned instead of the relative price of LPYCRV when _input_token is not a legacy token and _output_token is LPYCRV.  The relative price for _input_token not in legacy_tokens and _output_token equal to LPYCRV is computed as follow:  return amount * 10 ** 18 / Curve(POOL).get_virtual_price()  This doesn't take into account that the output token is LPYCRV and not POOL, so the POOL tokens need to be used to purchase LPYCRV shares at price Vault(LPYCRV).pricePerShare().  When _input_token is a legacy token, it is computed correctly as follows:  lp_amount: uint256 = amount * 10 ** 18 / Curve(POOL).get_virtual_price() return lp_amount * 10 ** 18 / Vault(LPYCRV).pricePerShare()  Code corrected  return amount * 10 ** 18 / Curve(POOL).get_virtual_price()  is replaced with  lp_amount: uint256 = amount * 10 ** 18 / Curve(POOL).get_virtual_price() return lp_amount * 10 ** 18 / Vault(LPYCRV).pricePerShare()  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   ZapYCRV _min_out LPYCRV Limit",
        "body": "  In ZapYCRV.zap, the _min_out argument of the zap function asserts a lower bound on the amount of output token received by the user. When _output_token is LPYCRV it incorrectly asserts the amount of liquidity tokens issued as an intermediate conversion step by Curve(POOL).add_liquidity.  Yearn - yCRV and ZapYCRV -   13  CorrectnessHighVersion1CodeCorrectedDesignMediumVersion1CodeCorrected                \fIn the LPYCRV branch of _convert_to_output, _min_out gets first passed to _lp(), which uses it as a lower bound to the amount of liquidity tokens issued by Curve(POOL).add_liquidity()  @internal def _lp(_amounts: uint256[2], _min_out: uint256, _recipient: address) -> uint256:     return Curve(POOL).add_liquidity(_amounts, _min_out)  It is then used again as a lower bound for amount_out issued by Vault(LPYCRV).deposit().  amount_out: uint256 = Vault(LPYCRV).deposit(self._lp([0, amount], _min_out, _recipient)) assert amount_out >= _min_out # dev: min out  This  basically  makes  _min_out  used  for  limit  of  LPYCRV  vault  shares  and  POOL  LP  shares.  Due  to how the share values are computed, in the general case they will be not worth 1:1. Thus, _min_out as a limit is not practical.  Code corrected  The _min_out argument of the _lp function has been removed. Thus it is not used as a lower bound to the amount of liquidity tokens issued by Curve(POOL).add_liquidity() anymore.  @internal def _lp(_amounts: uint256[2]) -> uint256:     return Curve(POOL).add_liquidity(_amounts, 0)  Yearn notes:  Hardcode the minimum to 0 in add_liquidity, as we will rely on subsequent check to compare user inputted min_out.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   ERC20 Return Values Not Checked",
        "body": "  According to EIP-20, Callers MUST NOT assume that false is never returned. However, not all calls to ERC20 assert that true is returned. ZapYCRV and yCRV do not check bool success values for calls to ERC20.approve  and  ERC20.transfer.  Even  though  in  most  cases  the  contracts  are  known  in advance and it is safe not to check this value, new features and codebase reuse can lead to potential problems.  In function sweep in both contracts the return value of ERC20.transfer can be missing, if for example USDT is used. In that case the call will fail.  Code corrected  Asserts have been added to the approve and transfer calls to make sure that true is returned.  Compiler  version  has  been  increased  to  vyper  0.3.6  in  order  to  use  the  external  call  keyword argument  default_return_value=True,  which  ensures  that  transfer  calls  do  not  revert  when calling non EIP-20 compliant tokens such as USDT which do not return a boolean value.  Yearn - yCRV and ZapYCRV -   14  CorrectnessLowVersion1CodeCorrected          \f6.5   ZapYCRV.zap Natspec  The  @param  _input_token  for  zap  function  does  not  describe  that  cvxCRV  can  be  used  as  input token.  Code corrected  The cvxCRV has been added to the @param _input_token in the zap function's natspec.  Yearn - yCRV and ZapYCRV -   15  CorrectnessLowVersion1CodeCorrected      \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Some but Not All Fees Are Accounted for in ",
        "body": " calc_expected_out  The natspec of calc_expected_out says that fees are not accounted for when computing the result. But  actually,  almost  in  all  cases,  when  the  Curve  pools  are  used,  they  are  accounted.  The  only  case when the fees are not taken into account is when the output token is LPYCRV. Then the deposit of YCRV in POOL is simulated with Curve(POOL).calc_token_amount(...), which does not account for the fees.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   ZapYCRV Curve StableSwap Token Indices",
        "body": " Sanity Check  ZapYCRV  contract  uses  POOL  contract,  that  is  assumed  to  be  Curve  Finance  StableSwap  contract.  In StableSwap  the  tokens  can  be  in  any  order.  The  yCRV/CRV  pool  is  not  yet  deployed.  Thus,  the assumption that CRV will be index 0 and yCRV will have index 1 might be violated. A sanity check in the constructor  of  ZapYCRV  contract  can  prevent  human  and  misconfiguration  errors  and  lower  the  costs associated with redeployment.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   ZapYCRV Return Values Ignored",
        "body": "  the   ZapYCRV._zap_from_legacy   In  to IYCRV(YCRV).burn_to_mint  are  ignored.  Return  value  is  assumed  to  be  same  as  the  amount argument  that  the  function  takes.  However,  in  case  when  the  amount  is  equal  to  MAX_UINT256,  the burn_to_mint  might  return  other  value.  In  the  current  version  such  situation  should  never  happen, because  this  case  is  handled  by  the  zap  function  itself.  In  ZapYCRV._zap_from_legacy,  amount should never be equal to MAX_UINT256. However use of return value will prevent potential bugs in case of code reuse or if new features are added.  function   return   value   calls   the   of   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   yCRV as an ERC20 Implementation",
        "body": "  There are 2 things we would like to note regarding the yCRV token.  1. The approve function has a known race condition attack vector described here  Yearn - yCRV and ZapYCRV -   16  NoteVersion1NoteVersion1NoteVersion1NoteVersion1              \f2. The  transferFrom  function  does  not  emit  Approval  event.  While  this  is  compliant  with specification,  one  cannot  reconstruct  the  state  of  user  allowances  based  only  on  events,  since transferFrom does not emit any special events that show that approval was used.  Yearn - yCRV and ZapYCRV -   17  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Gas Savings Part 2",
        "body": "  0  0  0  3  Trading._fillFacingExchange now transfers the fee from the contract to the operator on every call. When multiple maker orders are processed, there is a fee transfer for every one of them. The fee could be sent after all orders have been processed instead.  Acknowledged:  The client acknowledges the possible gas savings and chooses to keep the code as-is.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Accidental Token Transfers",
        "body": "  Tokens that have been accidentally sent to the contract can not be recovered.  Furthermore, if either the collateral token or one of the outcome tokens have been accidentally sent to the  contract,  the  next  executed  taker  order  will  receive  these  tokens  due  to  the  implementation  of Trading._updateTakingWithSurplus.  Risk accepted  Polymarket states:  Polymarket - Exchange -   10  SecurityDesignCorrectnessCriticalHighMediumLowAcknowledgedRiskAcceptedCodePartiallyCorrectedDesignLowVersion2AcknowledgedDesignLowVersion1RiskAccepted                   \fRecovering tokens sent to the contract will require adding a permissioned ``withdrawTokens`` function, which introduces an unacceptably large trust assumption.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   Gas Savings",
        "body": "  The following parts can be optimized for gas efficiency:   The OrderStructs.OrderStatus struct occupies 2 words in storage. Decreasing the size of the remaining field by 1 byte could reduce the space requirement to 1 word. This fix has to be applied with caution using safe casts where appropriate.   The field token in the Registry.OutcomeToken struct is redundant as a specific struct can only  be accessed with that value.   The call to validateTokenId(token) in Registry.validateComplement is redundant as the  very same call is performed in the following call to getComplement.   Trading._matchOrders  and  _fillMakerOrder  redundantly  compute  the  order  hash  again,  after it has already been computed by _validateOrderAndCalcTaking.   Trading._updateOrderStatus   performs  multiple   redundant   storage   loads   of  status.remaining.   Trading._updateTakingWithSurplus  performs  a  redundant  calculation   in   the  return  statement. Returning actualAmount yields the same result at this point.   Assets.getCollateral(),   Fees.getFeeReceiver(), Assets.getCtf(),  Fees.getMaxFeeRate()  are  redundant  since  the  variables  they  expose  are  public  and  already define equivalent accessors.  Code partially corrected:  OrderStructs.OrderStatus  still  occupies  2  storage  slots.  All  other  gas  savings  have  been implemented sufficiently.  Polymarket - Exchange -   11  DesignLowVersion1CodePartiallyCorrected          \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  2  1  3  10  -Severity Findings   Signatures Are Valid for Any Address    ORDER_TYPEHASH Is Incorrect   -Severity Findings   Fee Rate Not Hashed   -Severity Findings   Fee Approval Required    Unintended Order Types Possible    Zero Address EOA Signer Considered Valid   -Severity Findings   FeeCharged Event Not Emitted in fillOrder    OrderStruct.taker Specification Inconsistent    Code Replication    Domain Separator Cached    Floating Pragma    Non-optimized Libraries Used    Order Status Possibly Incorrect    Struct Order Has Redundant Fields    Wrong Notice on Order.feeRateBps   isCrossing Incorrect When takerAmount Is 0   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Signatures Are Valid for Any Address",
        "body": "  Signatures.isValidSignature checks the validity of a given order's signature. For signature types POLY_GNOSIS_SAFE and POLY_PROXY, the code makes sure that an order's maker address belongs to the same account that signed the order.  This is not true for the signature type EOA. Any account can create a signature for an order that contains an arbitrary maker address. Since users give token approval to the protocol on order creation, malicious actors can generate orders for an account that already generated an order, but, for example, with a more favorable price. This order will then be executable although the account in question did not authorize it.  Code corrected  Polymarket - Exchange -   12  CriticalCodeCorrectedCodeCorrectedHighCodeCorrectedMediumCodeCorrectedCodeCorrectedCodeCorrectedLowCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedSecurityCriticalVersion1CodeCorrected         \fSignatures.verifyEOASignature  has  been  added,  which  additionally  ensures  Order.maker == Order.signer for EOAs.  that   the  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   ORDER_TYPEHASH Is Incorrect",
        "body": "  The  ORDER_TYPEHASH  in Hashing.hashOrder. It is used to calculate an EIP-712 compliant hash for an order which is then used to recover the signer of the given order. Since the typehash is incorrect, this mechanism will not work for correctly signed orders.  in  OrderStructs  does  not  equal   the  actual  encoded  data   Code correct  OrderStructs.ORDER_TYPEHASH is now computed at compile time on the correct structure signature.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Fee Rate Not Hashed",
        "body": "  Hashing.hashOrder does not include the fee rate of an order into the hash. If the signatures are also generated this way and users do not recognize this, operators can always specify MAX_FEE_RATE_BIPS fees.  Code correct  Order hash computation now includes feeRateBps.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Fee Approval Required",
        "body": "  Fees are charged by transferring the respective amount of tokens from the receiving user's account to the fee receiver.  The  user  has  to  give  additional  approval  for  the  token  they  actually  want  to  receive,  which  is counter-intuitive  and  also  opens  up  additional  security  risks.  Since  the  fee  is  always  smaller  than  the amount  of  tokens  sent  to  the  user,  this  special  behavior  is  not  necessary  as  the  fees  could  also  be deducted from the amount sent to the user.  Code correct  Fees are deducted directly on the exchange, instead of being pulled from the order maker. Additionally, _fillOrder implicitly collects fees by transferring the taking amount minus the fee from the operator.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Unintended Order Types Possible",
        "body": "  Polymarket - Exchange -   13  CorrectnessCriticalVersion1CodeCorrectedDesignHighVersion1CodeCorrectedSecurityMediumVersion1CodeCorrectedDesignMediumVersion1CodeCorrected                                \fTrading._matchOrders  and  _fillOrder  miss  sanity  checks  for  combinations  of  makerAssetId, takerAssetId and side in the passed order structs.  of   in combinations  Eight  [ConditionalToken,  in [ConditionalToken,  Collateral]  are  possible,  but  only  two  of  them  should  be  allowed.  This seems  possible  as  the  side  seems  redundant  or  colliding  with  the  combinations  (struct  Order  has redundant fields).  takerAssetId   Collateral],   makerAssetId   SELL],   [BUY,   side   and   in   This  allows  for  matching  of  orders  that  are  not  intended.  For  example,  matching  of  a  BUY  order  with maker asset YES and taker asset USDC to a SELL order with maker asset USDC and taker asset YES is perfectly possible as long as the YES price in these orders is over 1 USDC (otherwise, the fee calculation reverts).  Code correct  Unintended order types are no longer possible as fields makerAssetId and takerAssetId have been replaced by a single field tokenId.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Zero Address EOA Signer Considered Valid",
        "body": "  isValidSignature() returns true for signer equal to zero address, signatureType EOA and invalid signature.  The  check  is  performed  at  line  70  of  Signature.sol,  SilentECDSA.recover  returns  0  on  error. Setting the signer to zero address will incorrectly validate the signature.  Code correct  Signature  verification  now  uses  Openzeppelin's  ECDSA.recover  instead  of  SilentECDSA.  Invalid signatures now revert instead of returning the 0-address.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   FeeCharged Event Not Emitted in fillOrder",
        "body": "  in _fillOrder, the fee is charged implicitly by deducting it from the amount that is transferred to the order  maker  but  a  FeeCharged  event  is  not  emitted.  For  consistency  and  to  allow  proper  accounting based on events, FeeCharged should be emitted.    The event is now emitted.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   OrderStruct.taker Specification Inconsistent",
        "body": "  Polymarket - Exchange -   14  CorrectnessMediumVersion1CodeCorrectedDesignLowVersion2CodeCorrectedCorrectnessLowVersion2Speci\ufb01cationChanged                        \fThe taker field of the Order struct actually identifies the operator which can fill the order, not the taker that can be matched with the order as it seems to be intended from the natspec notice.  Specification changed:  The natspec of taker has been modified to reflect its actual usage.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   Code Replication",
        "body": "  Trading._fillOrder  same  _validateOrderAndCalcTaking. For maintainability reasons, code replications should be avoided.  contains   present   already   code   that   the   is   in  Code correct  Duplicated  refactored  _performOrderChecks (renamed from _validateOrderAndCalcTaking).  in  Trading._fillOrder   been   code   has   into   the   function  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   Domain Separator Cached",
        "body": "  Hashing exposes the domainSeparator with an implicit public getter for an immutable variable. When the chain id changes, for example due to a hardfork, the domainSeparator will not be correct on the new chain.    The domainSeparator is now re-calculated in case of a change of the chain id.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.11   Floating Pragma",
        "body": "  Exchange uses the floating pragma <0.9.0. Contracts should be deployed with the compiler version and flags that were used during testing and auditing. Locking the pragma helps to ensure that contracts are not accidentally deployed using a different compiler version and help ensure a reproducible deployment.  Code correct  Solidity version has been fixed to 0.8.15 in all instantiated contracts. Interfaces, libraries, and abstract contracts are left floating.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.12   Non-optimized Libraries Used",
        "body": "  Polymarket - Exchange -   15  DesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                                \f TransferHelper re-implements transfer functions while there already exists an optimized library  (SafeTransferLib) implementing these functions in the dependencies of the project.   Signatures uses SilentECDSA, a modified version of an outdated OpenZeppelin ECDSA version. The current version of this library could be used instead since it provides all required functionalities.     TransferHelper now utilizes the optimized library for transfer functions.   Signatures utilizes the OpenZepplin library.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.13   Order Status Possibly Incorrect",
        "body": "  Trading.getOrderStatus  returns  an  OrderStatus  struct  containing  a  variable  isCompleted  for any order hash. As the protocol has two distinct mechanisms of invalidating orders, this function might return that an order is still not completed, while in fact it has been invalidated by a nonce increase.    The field isCompleted has been renamed to isFilledOrCancelled which describes the behavior in an adequate way.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.14   Struct Order Has Redundant Fields",
        "body": "  In struct Order, the fields side, makerAssetId, and takerAssetId coexist redundantly.  If side is BUY, makerAssetId is implied to be 0. If side is SELL, takerAssetId is implied to be 0. a single  AssetId  field  would  therefore  be  sufficient  to  fully  specify  the  order,  or  similarly  side  can  be removed from the struct and be derived from makerAssetId and takerAssetId.  Redundant input arguments increase code complexity and facilitate potential bugs.    The fields makerAssetId and takerAssetId have been removed in favor of a new field tokenId.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.15   Wrong Notice on Order.feeRateBps",
        "body": "  The notice of feeRateBps says:  If BUY, the fee is levied on the incoming Collateral  However, the fee is always charged in the takerAssetId, which is not necessarily the collateral.  Specification changed:  The  Fee rate, in basis points, charged to the order maker, charged on proceeds.  feeRateBps   notice   now   for   reads:  Polymarket - Exchange -   16  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedCorrectnessLowVersion1Speci\ufb01cationChanged                          \f6.16   isCrossing Incorrect When takerAmount Is 0  In the event of a SELL-SELL matching, where tokens should be merged to provide collateral back to the sellers,  CalculatorHelper.isCrossing  returns  true  when  at  least  one  side's  order  has takerAmount == 0. In the case that the other side's order has a price greater than ONE, the matching is not crossing since no sufficient amount of collateral can ever be redeemed to cover price > ONE, however the isCrossing returns true.    isCrossing now returns false in the mentioned cases.  Polymarket - Exchange -   17  CorrectnessLowVersion1CodeCorrected      \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Incorrect Dense Selector When One Bucket Is",
        "body": " Empty  CS-VYPER_SEPTEMBER_2023-001  When generating a selector table with the codesize optimization, _dense_jumptable_info() tries to generate buckets and their corresponding magic number given a number of buckets. This function is called by generate_dense_jumptable_info() with different numbers of buckets to produce a table with as few buckets as possible. In the case where _dense_jumptable_info() is given some number of buckets to generate n but ends up with only m non-empty buckets (m < n), the returned python dict only contains m elements. As the code generation for the selector table uses m as the number of buckets, the latter will not behave as it should since:  Vyper - Vyper Compiler -   11  SecurityDesignCorrectnessCriticalHighMediumLowCorrectnessHighVersion1            \f To  get  the  bucket  of  a  method  id  x,  x  mod  m  is  computed  at  runtime  although  the  function  was  placed in the bucket x mod n at compile time.   The data section for the buckets header will miss one row for the empty bucket, meaning that even if there is some function with an id x such that r = x mod m = x mod n, if r > b where b was the of the empty bucket's id, the bucket r - 1 will be searched instead of the bucket r.  As m < n, the bucket information (bucket data section, bucket magic number and bucket size) copied at runtime  will  always  be  some  valid  bucket  and  won't  be  some  random  data  out  of  the  header's  data section. From there, the provided method ID is compared to the method ID of the function of the bucket whose  magic  number  matches,  the  execution  should  revert  as  in  the  case  where  the  wrong  bucket  is being  used,  no  function  will  match  the  method  ID.  In  other  words,  this  issue  makes  functions  of  the contract  revert  when  they  should  not,  but  does  not  allow  for  unexpected  or  restricted  actions  on  the contract.  For  example,  calling  the  function  aJ3EJUYUK  on  the  following  contract  compiling  with  the  codesize optimization will revert.  @external def aJ3EJUYUK()->uint256:     return 1 @external def a9XXCI8PW()->uint256:     return 2 @external def aOBAJXNGO()->uint256:     return 3 @external def a0FUKH9AF()->uint256:     return 4 @external def a5ELEP7F4()->uint256:     return 5 @external def a3Y10PU1H()->uint256:     return 6 @external def aKX7ATQCX()->uint256:     return 7 @external def aT12B3E6Y()->uint256:     return 8 @external def a7U1B9OBW()->uint256:     return 9 @external def aGLOLGNUZ()->uint256:     return 10 @external def a7V3L4VPT()->uint256:     return 11 @external def aREJI588E()->uint256:     return 12 @external def a7XVZOF81()->uint256:     return 13  Vyper - Vyper Compiler -   12  \f@external def aNJK5DHE9()->uint256:     return 14 @external def aDJT6R9PE()->uint256:     return 15  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Incorrect Re-Entrancy Lock When Key Is",
        "body": " Empty String  The nonreentrant decorator does not protect functions in the case that the provided key is the empty string. Note that this issue is being tracked in a security advisory 1  CS-VYPER_SEPTEMBER_2023-002  @nonreentrant(\"\") # unprotected @external def bar():     pass  @nonreentrant(\"lock\") # protected @external def foo():     pass  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   Memory Corruption in Builtins Utilizing msize",
        "body": "  CS-VYPER_SEPTEMBER_2023-003  As Vyper memory is statically allocated, in the cases where some data whose size is unknown at compile time must be stored in memory (calldata, extcodecopy), the compiler uses msize as the starting index of the memory that will be allocated for the data. In the general case, this solution is sufficient, however, in some edge cases, the compiler will allocate and use memory inside this buffer for other purposes after storing the data and before using them, thus, overwriting them.  The affected builtins are raw_call, create_from_blueprint and create_copy_of.   For raw_call, the argument buffer of the call can be corrupted, leading to incorrect calldata in the sub-context.  In  this  case,  when  the  data  to  pass  with  the  raw_call  is  msg.data,  as  there  is  no way to know the size of the calldata of the current context at compile time, the compiler uses msize as the beginning of the argument buffer for the call. As the argument to and the kwargs value and gas are evaluated after the calldatacopy and before the call, if their evaluation was to store to memory, it could overwrite the copied calldata.   For create_from_blueprint and create_copy_of, the buffer for the to-be-deployed bytecode can be corrupted, leading to deploying incorrect bytecode. Again, the kwargs value and salt are evaluated after the extcodecopy or codecopy and before executing create or create2. If they were to store to memory, they could overwrite the buffer for the bytecode to be deployed.  Vyper - Vyper Compiler -   13  SecurityHighVersion1SecurityHighVersion1            \fBelow are the conditions that must be fulfilled for the corruption to happen for each builtin:  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3.1   raw_call",
        "body": "   The data argument of the builtin is msg.data.   The to, value or gas passed to the builtin is some complex expression that results in writing to the  memory.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3.2   create_copy_of",
        "body": "   The value or salt passed to the builtin is some complex expression that results in writing to the  memory.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3.3   create_from_blueprint",
        "body": "   Either no constructor parameters are passed to the builtin or raw_args is set to True.   The value or salt passed to the builtin is some complex expression that results in writing to the  memory.  Note that more details and examples on the issue are described in the corresponding security advisory 2.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.4   _abi_decode Return Values Are Not Clamped",
        "body": "  The  returned  values  of  the  builtin  _abi_decode  are  not  clamped  and  can  be  out  of  bound  for  the specified Vyper type.  CS-VYPER_SEPTEMBER_2023-004  function  foo  of   The  the  contract  below  returns  3,  meaning  max_value(uint256) which is out of bounds for uint8 and that the addition overflowed 256 bits.  that  _abi_decode  returned  @external def foo() -> uint8:     x: Bytes[32] = _abi_encode(max_value(uint256), ensure_tuple = False)     y: uint8 = _abi_decode(x, uint8, unwrap_tuple=False) + 4     return y  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.5   ecrecover Can Return Undefined Data in",
        "body": " Some Edge Case  CS-VYPER_SEPTEMBER_2023-005 This  issue  is  an  edge  case  of  the  recent  security  advisory  3  for  ecrecover  that  was  missed  in  the corresponding fix 4.  As the ecrecover precompile does not fill the output buffer (memory location 0) if the signature does not verify, the ecrecover builtin would return whatever was in the buffer before. This issue was fixed by cleaning any dirty bytes at memory location 0 before evaluating the builtin.  Vyper - Vyper Compiler -   14  CorrectnessMediumVersion1SecurityMediumVersion1            \fAs the arguments of ecrecover are evaluated after this cleaning, if one of the arguments of the builtin was to be compiled to some bytecode storing to memory location 0, the data stored there would be the returned value of ecrecover in case of a signature that does not verify.  In the following contract, a foo would not revert as owner is stored at slot 0 by get_v().  owner: immutable(address)  @external def __init__():     owner = 0x7E5F4552091A69125d5DfCb7b8C2659029395Bdf  @internal def get_v() -> uint256:     assert owner == owner # force a dload to write at index 0 of memory     return 21  @payable @external def foo():     assert ecrecover(empty(bytes32), self.get_v(), 0, 0) == owner # True  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.6   Arguments Buffer Size Too Large When",
        "body": " Calling ecmul  CS-VYPER_SEPTEMBER_2023-006 PR3583  5 fixes an issue with the order of evaluation of the side effect of several builtins arguments  6. Although  the  issue  has  been  fixed  with  the  PR,  the  builtin  ecmul  is  performing  a  static  call  to  the corresponding precompile with an argument buffer size too large (128 bytes instead of 96 bytes).  Note that this issue has been communicated and fixed before the PR was merged.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.7   Arguments Passed to _abi_decode Are Not",
        "body": " Type-Checked  The type of arguments passed to _abi_decode are not validated and ensured to match the expected argument types of the builtin.  CS-VYPER_SEPTEMBER_2023-007  # should not compile but compiles @external def bar(j:String[32]) -> bool:     s:bool = _abi_decode(j, bool, unwrap_tuple= False)     return s  # should not compile but the compiler panics with: # AttributeError: 'IntegerT' object has no attribute 'maxlen'  Vyper - Vyper Compiler -   15  CorrectnessLowVersion1CorrectnessLowVersion1            \f@external def foo(j:uint256) -> bool:     s:bool = _abi_decode(j, bool, unwrap_tuple= False)     return s  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.8   Builtins' varargs Are Not Properly",
        "body": " Type-Checked  CS-VYPER_SEPTEMBER_2023-008  The builtins create_from_blueprint, print and _abi_encode use varargs to be able to accept an  arbitrary  number  of  additional  arguments.  The  compiler  only  checks  that  these  arguments  have  a proper Vyper type but does not enforce anything else. Passing for example an Hashmap or types in the varargs will make the compiler crash.  f:HashMap[uint256, uint256] @external def foo(blueprint: address):     # vyper.exceptions.TypeCheckFailure: assigning HashMap[uint256, uint256] to HashMap[uint256, uint256] 128 0 <self.f>     g:address =  create_from_blueprint(blueprint, self.f)  @external def bar():     # AttributeError: 'IntegerT' object has no attribute 'typ'     print(uint16)  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.9   Compiler Panics When Overflowing the",
        "body": " Memory  Given  some  expression  that  overflows  the  memory,  the  compiler  panics  instead  of  exiting  with  some custom error.  CS-VYPER_SEPTEMBER_2023-009  For  vyper.exceptions.CompilerPanic: out of range.  compiling   example,   the   following   contract   results   in  @external def bar():     s:String[max_value(uint256)] = \"a\"  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.10   Documentation Inconsistencies",
        "body": "  CS-VYPER_SEPTEMBER_2023-010  Vyper - Vyper Compiler -   16  CorrectnessLowVersion1DesignLowVersion1CorrectnessLowVersion1                  \fIn  the  documentation  for  create_from_blueprint,  the  keyword  argument  raw_args  is  not documented.   create_from_blueprint's example code snippet does not compile in the latest Vyper versions  as the type String is used without maximum length.   The  documentation  of  raw_call  mentions  that  in  case  gas  is  not  set,  all  remaining  gas  is  forwarded while in reality \"all but one 64th\" of the current contract's gas is forwarded.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.11   Incorrect Typing of Literal Arrays When Used",
        "body": " With len  When  trying  to  get  the  length  of  a  literal  array  with  the  builtin  len,  the  compiler  fails  with  an InvalidType exception although literal arrays can usually be typed as dynamic arrays.  For example, the following contract fails to compile with an InvalidType exception.  CS-VYPER_SEPTEMBER_2023-011  @external def foo():     a: uint256 = len([1,2,3])  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.12   Outdated or Incorrect Comments",
        "body": "  CS-VYPER_SEPTEMBER_2023-012  The following comments are inconsistent with the compiler's behaviors.  In  ModuleAnalyzer.__init__(),  \"check  for  collisions  between  4byte  function  selectors\"  is referring to a removed check.  In _MinMaxValue.evaluate(), \"TODO: to change to known_type once #3213 is merged\" refers to a pull request that has been superseded and hence is outdated.   The  documentation  for  generate_ir_for_external_function()  is  not  up  to  date  as  it mentions for example check_nonpayable which has been removed with the new selector table.   The   layout  CreateFromBlueprint._build_create_IR() is incorrect.  described   memory   in   the   comment   of  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.13   Warning and Error Messages",
        "body": " Inconsistencies  The following warning and error messages could be improved.  In BitwiseNot.evaluate(), the warning mention the bitwise xor operator ^ instead of ~.  CS-VYPER_SEPTEMBER_2023-013  Vyper - Vyper Compiler -   17  DesignLowVersion1CorrectnessLowVersion1CorrectnessLowVersion1                      \fIn _validate_msg_data_attribute(), the first raised exception do not mention that msg.data can be used with raw_call.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.14   extract32 Return Type Can Be Any byteM",
        "body": "  CS-VYPER_SEPTEMBER_2023-014  to   both   in According  Extract32.infer_kwargs_types(),  extract32  can  have  as  return  type  bytes32,  address  or any integer type. However, given the check-in Extract32.infer_kwargs_types, it is possible to specify as return type any bytesM.  documentation   exception   raised   and   the   the   For example, the following code compiles:  @payable @external def foo(b:Bytes[32]):     x: bytes8 = extract32(b, 0, output_type = bytes8)  Vyper - Vyper Compiler -   18  CorrectnessLowVersion1       \f1 2 3 4 5 6  https://github.com/vyperlang/vyper/security/advisories/GHSA-3hg2-r75x-g69m https://github.com/vyperlang/vyper/security/advisories/GHSA-c647-pxm2-c52w https://github.com/vyperlang/vyper/security/advisories/GHSA-f5x6-7qgp-jhf3 https://github.com/vyperlang/vyper/commit/019a37ab https://github.com/vyperlang/vyper/pull/3583 https://github.com/vyperlang/vyper/security/advisories/GHSA-4hg4-9mf5-wxxq  Vyper - Vyper Compiler -   19  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Infinite Minting of Position Tokens With No",
        "body": " Value  For any resolved condition it is possible to mint an infinite amount of tokens for the losing outcomes from  token (i.e., a token with a collection ID of 0x0). For this to work, one outcome must receive all a single  the payout and the other outcomes must receive none.  ,  it  is For  example,  for  a  condition  with  binary  outcomes  ( possible to mint an infinite amount of   tokens have no value at this point, it is not an issue by itself but it should always be taken into account when designing a market around conditional tokens.  ),  if  the  condition  resolves  to    tokens from a single    token. Because the   We will now explain how to mint an infinite amount of losing tokens from a single    token.  From a previous audit on the conditional tokens contracts, we learn how to obtain one  collateral token (Chapter 6). Furthermore, it is stated that a  used with any position tied to CT.   token from one  token, tied to collateral token CT, can be  In case a particular market is created using Polymarket's NegRiskAdapter (instead of directly working with  the  ConditionalTokens  contract),  the  conversion  of  a    token  to  a  token  representing  a Polymarket condition must be tied to wrapped collateral. Polymarket uses wrapped collateral tokens as collateral  for  conditional  tokens.  Users  can  obtain  wrapped  collateral  tokens  by  redeeming  conditional tokens directly on the used ConditionalTokens instead of the adapter.  We assume that we have a condition with a conditionId C with two possible outcomes ( ) and that the condition has resolved to True. Furthermore, the notation H(T) represents the elliptic curve   while  H(F)  represents  the  same  for  outcome multi-hash  set  of  conditionId  C  with  outcome   .  The  first  step  of  converting  a  following arguments:    token  to  a     token  is  a  call  to  redeemPositions()  with  the   collateralToken: The collateral token CT used when creating the    token.   parentCollectionId:   , the additive inverse of    on the given elliptic curve.   conditionId: C.   indexSets: [0b01].  Because  the  condition  has  resolved  to  calculation  the tokens that should be redeemed) to one  possible as it would require redeeming an index set of     token  (the  result  of  the  that is performed in redeemPositions() to calculate the collectionId of  tokens is not   which does not have a payout vector.   token. We note that redeeming to   ,  the  function  will  convert  one   The next step is a call to splitPosition() with the following arguments:   collateralToken: CT.   parentCollectionId:   .   conditionId: C.   partition: [0b01, 0b10].  Polymarket - Conditional Tokens -   11  NoteVersion1  \f amount: The amount of obtained    tokens.   tokens and one  Equal amounts of  with the first step of this conversion.   tokens are created. The new    tokens can be re-used    tokens  can  be  split  in  another  step  to  equal  amounts  of     and     tokens  using splitPosition():   collateralToken: CT.   parentCollectionId:   .   conditionId: C.   partition: [0b01, 0b10].   amount: The amount of obtained    tokens.  The following graphic gives an overview of the conversion steps:  We notice that from a single  token can be transformed to a  two outcomes where all losing outcome tokens can be minted infinitely from a single    token we can obtain an infinite amount of    and a    token. The same issue arises for conditions with more than   tokens, since a single    token.  It is therefore important that, once a condition is resolved in the ConditionalTokens contract, there should  no  longer  exist  any  arbitrage  opportunities  for  the  respective  tokens  and  no  external  contract's accounting should rely on the token amounts to be correct.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   No Irregular ERC-20 Tokens Supported",
        "body": "  The  ConditionalTokens  contract  does  not  support  ERC-20  tokens  that  do  not  return  values  in  the transfer/approval functions (e.g., USDT).  Polymarket - Conditional Tokens -   12  NoteVersion1      \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Provoking an Aave Liquidity Crisis",
        "body": "  AaveKandel  stops  providing  liquidity  if  too  much  is  borrowed.  Generally,  market  makers  should  be aware of that. However, one can throw Aave temporarily into a liquidity crisis by  ISSUEIDPREFIX-001  1. flashloaning the entire balance  2. borrowing the entire balance  That  could  allow  an  attacker  to  create  a  temporary  liquidity  crisis  wrapping  a  sniping  operation  on Mangrove core for his profit.  However, note that the flashloaning attack is to some degree by the economic factor of Aave flashloans while the other operation can be achieved even for free by taking out free flashloan for collateral assets on other protocols. Such attacks are however limited by the borrow caps that Aave can impose. Namely, the attack can be carried out as long as the Aave's available capital after the borrow cap is reached is less than an offer's promised amount. Note that 1. and 2. can be combined to reduce the total cost of an attack with 1. so that the limit set by the borrow caps can be bypassed.  Risk accepted:  Mangrove Association (ADDMA) replied:  1/ deploy 80 offers from AAVE kandel (WETH,USDC) on mangrove  Note 1: 80 offers is the limit beyond which one cannot collect all failing offers because of stack overflow Note 2: WETH has borrow cap on AAVE so the attack has to be on offers that have USDC outbound  Mangrove Association (ADDMA) - Kandel Strats -   11  SecurityDesignCorrectnessCriticalHighRiskAcceptedMediumLowAcknowledgedSecurityHighVersion1RiskAccepted           \f2/ attacker supplies enough DAI on AAVE to be able to borrow the whole supply of USDC  Note 1: the script mocks up a flashloan of DAI to obtain enough collateral. There is currently no real way to flashloan DAIs on polygon. In the overall cost of the attack we add 400K gas as an estimate of the flashloan cost plus the cost of repaying the borrow on AAVE which is not scripted here (AAVE on polygon still does not allow repay and borrow on the same block, although ethereum deployment does). The attack using AAVE native flashloan has also been tested but result in a prohibitive cost for the attacker (around 1000 USD worth of fees).  Note 2: there is currently a supply cap on AAVE for DAI which is just enough to do this, but supplying a bit too much DAI actually reverts  3/ attacker borrows USDC supply and triggers a market order  4/ all 80 aave kandel offers trigger a failure cascade and the bounty is sent to the attacker Assuming a tx.gasprice == Mangrove\u2019s gasprice at 90 gwei, we get:      Attack collects 0.84691197 matics for 9 936 879 gas units     cost of the attack: 0.89431911 native tokens  Conclusion:    - Under favorable gas conditions for the attacker, drying up the AAVE pool can be profitable (when tx.gasprice is     significantly lower than Mangrove\u2019s). However the profit is quite low compared to traditional flashloan attacks     and not iterable: failing Aave Kandel\u2019s offer do not repost themselves. Yet the attack would at least be griefing     users as it would result in losing provision and having their offers unpublished from Mangrove.    - We believe the best protection relies on launching AAVE Kandel Strats on markets that have a borrow cap,     which would force the attacker of going through the costly AAVE flashloan mechanism to bypass the cap.    - The above script is included in the test AaveKandel.t.sol (test_liquidity_borrow_marketOrder_attack)  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Posthook Revert Due to Overflow in Dual",
        "body": " Offer Computation  The maker posthook of Kandels can revert due to a potential overflow in dualWantsGivesOfOffer() in extreme scenarios. Consider the following example:  ISSUEIDPREFIX-002   Assume that the previously computed gives is equal to 2**96-1.   Assume that r is equal to (2*10**5)**8 = 2**8 * 10**40.   Hence, the first computed givesR will be (2**104-2**8) * 10**40, which needs 237 bits.  In  the  else  branch,  assume  that  order.offer.wants()  is  small,  e.g.  1,  the  updated  givesR now needs 256 bits   Hence,  with  offerGives  >=  2**19,  the  computed  wants  will  be  >  2**256  which  leads  to  a  reverting overflow.  Ultimately, the posthook for small offers could revert.  Acknowledged:  Mangrove Association (ADDMA) replied:  The scenario that yields an overflow occurs with unlikely values. The outcome of the overflow is to make offer logic\u2019s posthook fail and hence entails no penalty for maker.  Mangrove Association (ADDMA) - Kandel Strats -   12  DesignLowVersion1Acknowledged           \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings   Depositing ATokens Allows Stealing Them   -Severity Findings  -Severity Findings   Wrong Dual Price Computation on Crossing Boundaries   -Severity Findings   Balance in Router Can Be Present    More Precision Can Be Used for wants    Reserve Balance Does Not Include Kandel's Balance    Tokens Without Return Values    AaveKandelSeeder Missing Active Market Check   1  0  1  5  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Depositing ATokens Allows Stealing Them",
        "body": "  The Aave v3 pooled router, allows arbitrary tokens. Tokens that are not supported by Aave are kept in the  router  contract  directly  and  treated  equivalent  to  buffered  tokens  coming  from  Aave  withdrawals. However,  depositing  aTokens  leads  to  accounting  issues,  treating  the  aTokens  received  from  actual supply operations as donations and, hence, buffered tokens.  ISSUEIDPREFIX-007  Consider the following scenario:  1. 1M aDAI held by the router (DAI was supplied).  2. Attacker creates Kandel and uses depositFunds() to supply 1 aDAI.  3. Since not shares exist for aDAI, the INIT_MINT will be minted. The supply fails but the code does  not revert since noRevert is true.  4. The attacker now uses withdrawFunds() to redeem aDAI.balanceOf(router) aDAI.  5. The  router's  withdraw  function  realizes  that  there  is  enough  buffered  amount  of  aDAI.  Hence,  toRedeem is 0.  6. _burnShares() first computes the shares to burn. Since there is no overlying for aDAI, the input amount will match the aDAI balance of the contract. Hence, the total shares for aDAI will be burned which are equal to INIT_MINT and thus equal to the attacker's shares. All shares are burned since the attacker is the only holder.  7. toRedeem is 0. Hence, withdrawing from Aave will not be tried. All the aDAI balance is sent to the  attacker.  Ultimately, all funds in the Aave pooled router could be at risk.  Mangrove Association (ADDMA) - Kandel Strats -   13  CriticalCodeCorrectedHighMediumCodeCorrectedLowSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSecurityCriticalVersion1CodeCorrected        \f  On  deployment,  the  AaveKandel  tries  to  call  UNDERLYING_ASSET_ADDRESS()  on  the  base  and  the quote token. In case staticcall does not revert, the token is classified as an aToken and the deployment will  revert.  In  case  the  staticcall  reverts,  the  error  is  caught  and  execution  proceeds.  Note  that  the staticcall could revert without the error message if the base or quote token are EOAs.  Further, only the base and quote tokens can be deposited to and withdrawn from the AaveKandel.  Both restrictions combined, prevent aTokens from being deposited to the router from Kandels.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Wrong Dual Price Computation on Crossing",
        "body": " Boundaries  When the dual price is computed, the function GeomertricKandel.dualWantsGivesOfOffer is not aware of how many steps the price should move to stay within the defined boundaries and will always move it by ratio**spread. Whenever steps <= spread holds, this can lead to prices that are off by factors of ratio on the boundary of the indices, thus breaking the assumption that each index should be at a distance ratio from its neighbors.  ISSUEIDPREFIX-013  Consider the following example:  1. The following setup is active:  pricePoints = 6 spread = 3 compoundRate = p = 10 ** PRECISION  2. A trade occurs against a Bid at index = 4 so that the dual offer parameters are (note that since  the pricePoints limit of 5 is exceeded, it is set to the maximum value allowed):  virtual_dual_index = 7 => dual_index = 5  dualOffer = Ask  Hence,  we  jump  by  only  1  index  and  expect  a  price  update  of  ratio  /  p.  Hence,  the expected price is the expected price at index 5  expected_wants / expected_gives = (order.wants * ratio**1 / p**1) / (order.gives)  3. The gives of the dual offer are computed (assume now that at index 5 gives had been 0):  new_gives = order.gives * compoundRate * ratio**spread / (ratio**spread * p) <=> new_gives = order.gives  4. The wants of the dual offer are computed:  new_wants = order.wants * new_gives * ratio**spread / (order.gives * p**spread) <=> new_wants = order.wants * order.gives * ratio**spread / (order.gives * p**spread) <=> new_wants = order.wants * ratio**spread / p**spread  Mangrove Association (ADDMA) - Kandel Strats -   14  CorrectnessMediumVersion1CodeCorrected        \f5. The price at index 5 is now:  new_wants / new_gives = (order.wants * ratio**spread / p**spread) / (order.gives)  Note that the new price at index 5 is distinct from the expected price.    The spread applied to the ratio is now updated by GeometricKandel.transportDestination for the price to stay within bounds.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Balance in Router Can Be Present",
        "body": "  Note that the documentation of AavePooledRouter.__pull__() specifies:  ///@dev outside a market order (i.e if `__pull__` is not called during offer logic's execution) the `token` balance of this router should be empty. /// This may not be the case when a \"donation\" occurred to this contract /// If the donation is large enough to cover the pull request we use the donation funds  ISSUEIDPREFIX-012  However, note that this is not necessarily the case since the posthook of the first puller could revert and leave the funds inside the router without pushing them out. However, after the next execution or the next deposit, the funds should be moved to Aave if everything works correctly.  Note that an attacker could force a balance into the router without donating to it by  increasing the total supply on Aave such that the supply cap makes the first puller's flushing revert.  trading  against  an  attacker-strategy-owned  Kandel  and  then  trading  against  the  attacker  strategy that changes the router of the Aave Kandel so that the Aave Kandel does not push and supply on the Aave router.  Specification Changed:  The comment has been adapted.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   More Precision Can Be Used for wants",
        "body": "  ISSUEIDPREFIX-009  When  computing  is  used  when uint160(givesR)  ==  givesR  ||  order.wants  <  2  **  18,  but  the  second  condition  can  be relaxed to be order.wants < 2 ** 19 to allow full precision more often.  the  wants  amount  of   the  dual  offer,   full  precision     The second condition has been relaxed to accept values < 2 ** 19.  Mangrove Association (ADDMA) - Kandel Strats -   15  CorrectnessLowVersion1Speci\ufb01cationChangedDesignLowVersion1CodeCorrected                    \f6.5   Reserve Balance Does Not Include Kandel's Balance  The  reserveBalance()  is  the  available  balance  for  a  strategy  of  an  offered  token.  Note  that  Direct strategies try to use the local balance always first, see function __get__().  ISSUEIDPREFIX-011  uint amount_ = IERC20(order.outbound_tkn).balanceOf(address(this)); if (amount_ >= amount) {   return 0; }  However, the AaveKandel does not account for the local balance (potentially received through donations) in reserveBalance().    The  function  AaveKandel.reserveBalance()  has  been  updated  to  take  its  own  balance  into account.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Tokens Without Return Values",
        "body": "  The Mangrove core system and the transfer libraries used in Kandel handle tokens without return values on transfers. However, for approvals return values are always expected. Note that this is not always the case due to tokens implementing the ERC-20 standard incorrectly (e.g., USDT).  ISSUEIDPREFIX-008    The approve() function handles now the case where no return value exists.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   AaveKandelSeeder Missing Active Market",
        "body": " Check  Only  the  (BASE,QUOTE)  market  is  checked  to  be  active  on  Mangrove,  but  the  (QUOTE,BASE)  base market should also be checked as it is used as well. If the inverse market is inactive, initial Ask and the Bid dual offers will fail to be posted.  ISSUEIDPREFIX-006    The two markets are now checked to be active on Mangrove in AbstractKandelSeeder.sow().  Mangrove Association (ADDMA) - Kandel Strats -   16  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                      \f6.8   Explicit Variable Visibility  Several variables have undeclared visibility which results in variables being internal. Note that clear specifying clear visibility can help maintain code.  ISSUEIDPREFIX-005    Variables have now explicit visibility.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   Gas Inefficiencies",
        "body": "  1. The internal function DirectWithBidsAndAsksDistribution.populateChunk initializes i to  0, this is a redundant assignment.  ISSUEIDPREFIX-004  2. When  using  tokenPairOfOfferType()  with  both  offer  function,  e.g., DirectWithBidsAndAsksDistribution.populateChunk  or DirectWithBidsAndAsksDistribution.retractOffers,  one  of  the  function  calls  can  be avoided by assigning the inverted token pair.  types   in  a   3. In the function CoreKandel.retractAndWithdraw the modifier onlyAdmin is unnecessary    For 3, the modifier was not removed by choice.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   NatSpec",
        "body": "  The  NatSpec  documentation  is  extensive.  However,  there  at  several  places  the  NatSpec  is  missing  or incomplete.  For  _supply,  checkAsset,  _totalBalance  or  balanceOfReserve  return  value  undocumented.  For  _sharesOfAmount,  mintShares  or  _burnShares  an  argument  undocumented. depositFunds or withdrawFunds do not have any NatSpec.  the   is is  Note that the examples are an incomplete list of lacking NatSpec documentation.  ISSUEIDPREFIX-010  Documentation changed:  The documentation has been adapted.  Mangrove Association (ADDMA) - Kandel Strats -   17  InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1Speci\ufb01cationChanged                  \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Magic Values",
        "body": "  The use of magic numbers in the codebase is not recommended, they should be replaced by variables with a self-explanatory name. Examples are:  ISSUEIDPREFIX-003   \"mgv/writeOffer/density/tooLow\"   \"mgv/tradeSuccess\"  Acknowledged:  Mangrove Association (ADDMA) replied:  since these magic values are part of mangrove\u2019s specification, we assume they won\u2019t change.  Mangrove Association (ADDMA) - Kandel Strats -   18  InformationalVersion1Acknowledged    \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Maker Should Oversupply Due to Aave Being",
        "body": " off by 1  The maker should oversupply AaveKandel by some WEI to account for Aave internal loss of precision, that can lead the token amount to be off by 1 on redemption, as it could make the trade revert if they are the only one to use the Aave pool from a given AavePooledRouter.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Supplying Caps Not Considered",
        "body": "  Aave V3 has supply caps. However, these are not considered when supplying. Hence, supplying could fail so that tokens are treated as buffered.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.3   AaveKandelSeeder Missing Existence Check",
        "body": " of Pool for Asset  No check is done on strategy deployment for a pool of BASE or QUOTE on AaveV3. If such pools cannot be supplied, the AaveKandel strategy can be deployed but there will be no yield from the deposits to the router.  Mangrove Association (ADDMA) - Kandel Strats -   19  NoteVersion1NoteVersion1NoteVersion1          \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Impossibility to Create One-Side Token1",
        "body": " Liquidity  The DeposiorUniV3 funnel has a uniswapV3MintCallback() function for properly integrating with Uniswap V3 and move the funds. However, it only moves funds if the owed amount in token0 is greater than 0. Hence, if the current tick is outside of the position's tick range so that it leads to one-sided liquidity in  token1,  no  funds  will  be  transferrable.  Ultimately,  one-sided  token1  liquidity  cannot  be  added.  Thus, deposits could be temporarily DOSed.  CS-MKALLOC-002    amt1Owed is now used for transfers of token1.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Incorrect Uniswap V3 Path Interpretation",
        "body": "  The swapper callback contract for UniswapV3 interprets the last tokens as follows:  lastToken := div(mload(sub(add(add(path, 0x20), mload(path)), 0x14)), 0x1000000000000000000000000)  CS-MKALLOC-003  Namely, it loads the last 20 bytes as the last token. However, the path may have some additional unused data so that the last token does not have any effect on the execution. Consider the following example:  1. The path is encoded as [srcToken fee randomToken dstToken].  2. The swapper will interpret dstToken as the last token.  3. However, in UniswapV3, randomToken will be received.  Maker - DSS Allocator -   12  CriticalHighMediumLowCodeCorrectedCodeCorrectedCorrectnessLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                  \f4. In case no slippage requirements for the amount out are present, randomToken will be received  successfully and will be stuck in the swapper contract.  Ultimately,  the  path  is  wrongly  interpreted  which  could,  given  some  configurations,  lead  to  tokens  lost unnecessarily due to bad input values.    The check towards the correctness of path encoding has been removed, as it provides a false sense of security. Ultimately, the swap is protected by the minimum output token amount requirement.  Maker states:  These checks were only meant to provide more explicit revert reasons for a subset of (common) path misconfigurations and were not meant to catch all possible incorrect path arrays. Ultimately the \"\"Swapper/too-few-dst-received\"\" check is the only one that matters. But since that seems to cause confusion, we just removed the checks.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Gas Inefficiencies",
        "body": "  Below is a non-exhaustive list of gas inefficiencies:  1. In AllocatorVault.wipe(), the call vat.frob() takes address(this) as an argument for the gem balance manipulation. However, due to the gem balance not being interacted with, using address(0) may improve gas consumption minimally.  2. In  the  withdrawal  and  deposit  functions  of  the  UniV3Depositor,  an  unnecessary  MSTORE operation is performed when caching era into memory. Using only the SLOAD could be sufficient.  CS-MKALLOC-004    Code has been corrected to optimize the gas efficiency.  Maker - DSS Allocator -   13  InformationalVersion1CodeCorrected      \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Lack of Sanity Checks",
        "body": "  The code often lacks sanity checks for setting certain variables. The following is a non-exhaustive list:  1. On deployment, the conduit mover does not validate whether the ilk and the buffer match against  CS-MKALLOC-001  the registry.  2. Similarly, that is the case for the allocator vault.  Maker states:  The sanity checks are done as part of the init functions (to be called in the relevant spell).  Maker - DSS Allocator -   14  InformationalVersion1Acknowledged    \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   1T NST Minting",
        "body": "  The  documentation  specifies  that  a  maximum  of  1T  NST  should  be  placed  and  that  at  most  1T  NST should be mintable. However, that may not be the case if the spotter has mat and par set to unsuitable values. Technically, Vat.rate could be decreasing (depending on the jug). Hence, with a decreasing rate, more than 1T NST could be minted. Additionally, governance is expected to provide the allocator vault with a gem balance through Vat.slip(). Calling this multiple times would allow to re-initialize the allocator vault multiple times to create more ink than intended (and, hence, allowing for more debt than expected).  Ultimately, governance should be careful when choosing properties.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Deposit and Withdraw Share the Same",
        "body": " Capacity  The governance can set a PairLimit in DepositorUniV3, which limits the maximum amount of a pair of tokens that can be added or removed from the pool per era. Instead of setting two capacity parameters for adding liquidity and removing liquidity respectively, both actions share the same capacity.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.3   Potentially Outdated Debt Estimation",
        "body": "  In contract AllocatorVault, debt() returns an estimation of the debt that is on the Vault's urn. This estimation  could  be  outdated  if  the  vat's  rate  has  not  been  updated  by  the  jug.drip()  in  the  same block.  The getter debt() has been removed (along with line() and slot()). Maker states that they are not strictly needed and can be implemented in another contract as well.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.4   Shutdown Not Considered",
        "body": "  The shutdown was not in scope and users should be aware that consequences of a potential shutdown have not been investigated as part of this audit.  Maker - DSS Allocator -   15  NoteVersion1NoteVersion1NoteVersion1NoteVersion1                \f8.5   Topology May Break the Intended Rate Limit  The keepers' ability to move funds between conduits/buffer and swapping tokens is limited by the triplets (from, to, gem) and (src, dst, amt) respectively. However, the actual funds flow between from and to (src and dst) could exceed the config dependent on the topology of the settings.  Assume  there  is  a  config  that  limits  moving  NST  between  conduits  CA  and  CB  to  100  per  hop: (CA,  CB,  100).  If  there  are  another  two  configs  (CA,  CX,  40)  and  (CX,  CB,  60)  exist,  then keepers can move at most 100 + 40 = 140 DAI from CA to CB per hop.  The  same  situation  applies  to  Swapper.  Therefore,  the  topology  of  the  configs  should  be  carefully inspected.  Maker states:  The rate limit for each swap/move pair is an authed configuration of the allocator proxy. It is therefore assumed to know what it is doing and is allowed to set any configuration regardless of paths or duplication.  Maker - DSS Allocator -   16  NoteVersion1  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Provoking an Aave Liquidity Crisis",
        "body": "  AaveKandel  stops  providing  liquidity  if  too  much  is  borrowed.  Generally,  market  makers  should  be aware of that. However, one can throw Aave temporarily into a liquidity crisis by  CS-MGVSTRATS-004  1. flashloaning the entire balance  2. borrowing the entire balance  That  could  allow  an  attacker  to  create  a  temporary  liquidity  crisis  wrapping  a  sniping  operation  on Mangrove core for his profit.  However, note that the flashloaning attack is to some degree by the economic factor of Aave flashloans while the other operation can be achieved even for free by taking out free flashloan for collateral assets on other protocols. Such attacks are however limited by the borrow caps that Aave can impose. Namely, the attack can be carried out as long as the Aave's available capital after the borrow cap is reached is less than an offer's promised amount. Note that 1. and 2. can be combined to reduce the total cost of an attack with 1. so that the limit set by the borrow caps can be bypassed.  Risk accepted:  Mangrove Association replied:  1/ deploy 80 offers from AAVE kandel (WETH,USDC) on mangrove  Note 1: 80 offers is the limit beyond which one cannot collect all failing offers because of stack overflow Note 2: WETH has borrow cap on AAVE so the attack has to be on offers that have USDC outbound  Mangrove Association - Mangrove Strategies -   9  SecurityDesignCorrectnessCriticalHighRiskAcceptedMediumLowAcknowledgedSecurityHighVersion1RiskAccepted           \f2/ attacker supplies enough DAI on AAVE to be able to borrow the whole supply of USDC  Note 1: the script mocks up a flashloan of DAI to obtain enough collateral. There is currently no real way to flashloan DAIs on polygon. In the overall cost of the attack we add 400K gas as an estimate of the flashloan cost plus the cost of repaying the borrow on AAVE which is not scripted here (AAVE on polygon still does not allow repay and borrow on the same block, although ethereum deployment does). The attack using AAVE native flashloan has also been tested but result in a prohibitive cost for the attacker (around 1000 USD worth of fees).  Note 2: there is currently a supply cap on AAVE for DAI which is just enough to do this, but supplying a bit too much DAI actually reverts  3/ attacker borrows USDC supply and triggers a market order  4/ all 80 aave kandel offers trigger a failure cascade and the bounty is sent to the attacker Assuming a tx.gasprice == Mangrove\u2019s gasprice at 90 gwei, we get:      Attack collects 0.84691197 matics for 9 936 879 gas units     cost of the attack: 0.89431911 native tokens  Conclusion:    - Under favorable gas conditions for the attacker, drying up the AAVE pool can be profitable (when tx.gasprice is     significantly lower than Mangrove\u2019s). However the profit is quite low compared to traditional flashloan attacks     and not iterable: failing Aave Kandel\u2019s offer do not repost themselves. Yet the attack would at least be griefing     users as it would result in losing provision and having their offers unpublished from Mangrove.    - We believe the best protection relies on launching AAVE Kandel Strats on markets that have a borrow cap,     which would force the attacker of going through the costly AAVE flashloan mechanism to bypass the cap.    - The above script is included in the test AaveKandel.t.sol (test_liquidity_borrow_marketOrder_attack)  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Unsafe Casts for Geometric Kandels",
        "body": "  CS-MGVSTRATS-003  KandelLib.createGeometricDistribution()  performs  several  unsafe  casts.  Namely,  there  are casts from uint to int for _baseQuoteTickOffset and indices.  The unsafe casts for _baseQuoteTickOffset may create problems and wrong results for the usage of GeometricKandel.createDistribution(). Additionally, the parameters specified are not validated (e.g. price points could be less than or equal to the step size or they could be too high). However, the other  functions  defined  ensure  that  the  reasonable  restrictions  for  the  geometric  parameters  are enforced.  The casting of indexes, however, may even create problems for the populating functions. Consider, the following.  int tick = -(Tick.unwrap(baseQuoteTickIndex0) + int(_baseQuoteTickOffset) * int(index));  Assume that index == 2**256-1-x, then the cast will return -1-x. Ultimately, a positive tick will be turned into a negative one, only to turn it back into a positive one. That positive tick will be used for bids. The following will become the tick for the bid in such a scenario.  int tick = Tick.unwrap(baseQuoteTickIndex0) + int(_baseQuoteTickOffset) * (1+x);  As a consequence, the bid prices increase with increasing indices (worse for market makers) instead of decreasing. Hence, the bids would bid a too high price.  Note that indices can reach that size (e.g. from is high).  Ultimately, the behaviour is undefined and may create bad setups.  Acknowledged:  Mangrove Association - Mangrove Strategies -   10  CorrectnessLowVersion1Acknowledged        \fMangrove  Association  acknowledged  the  behaviour  and  indicates  that  these  parameters  should  be validated off-chain similar to other ones:  In general parameters are considered validated off-chain, e.g., through simulation before passing to the contracts, so it is up to the caller to ensure correct usage.  Mangrove Association - Mangrove Strategies -   11    \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings  -Severity Findings   Lack of Router Sanity Check    Specification Mismatch   Informational Findings   Gas Optimisations    Lack of Events   0  0  0  2  2  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Lack of Router Sanity Check",
        "body": "  While the MangroveOffer library does not enforce a router to be set, more derived contracts such as Forwarder strictly require a router. However, setRouter() is not adapted to enforce such a check.  CS-MGVSTRATS-001    A  check  has  been  added  to  Forwarder  and  to  AaveKandel  which  are  the  strategies  that  require  a router to be set.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Specification Mismatch",
        "body": "  The specification of RESERVE_ID states that  ///@dev RESERVE_ID==address(0) will pass address(this) to the router for the id field.  CS-MGVSTRATS-002  However, RESERVE_ID will never be address(0) as it is set to address(this) if the corresponding constructor argument is address(0).  Additionally,  the  documentation  of  the  geometric  price  of  baseQuoteTickIndex0  describes  the following  Mangrove Association - Mangrove Strategies -   12  CriticalHighMediumLowCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedDesignLowVersion1CodeCorrectedCorrectnessLowVersion1Speci\ufb01cationChanged                \f///@param baseQuoteTickIndex0 the tick of base per quote for the price point at index 0 [...]  However, that may be misinterpreted. Namely, considering the two markets for asks and bids, the ask's price will be denominated in quote per base (ratio of inbound and outbound) while the bids' prices will be denominated in base per quote. The documentation, thus, suggests that the tick is defined for the market of the bids. However, that contrasts the implementation where the tick is used for the ask markets.  Specification changed:  The NatSpec has been adjusted.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Gas Optimisations",
        "body": "  Below is an incomplete list of potential gas optimisations:  1. In  Forwarder.sol,  deriveGasprice()  evaluates  1e6  *  (offerGasbase  +  gasreq)  to  compute a value that is already in num.  CS-MGVSTRATS-005  2. In   CoreKandel.sol,   casting guards  newParams.pricePoints to uint32. This is unnecessary since newParams.pricePoints is already an uint32.  setParams   truncation   against   when   3. setExpiry()  and  retractOffer()  in  MangroveOrder  have  the  mgvOrOwner  modifier.  However, the core will never call these functions.    The code has been adjusted to include the above gas optimisations.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Lack of Events",
        "body": "  While the codebase emits events on many occasions, a SetAdmin is missing in the constructor of the AccessControlled contract.  CS-MGVSTRATS-006    The event is now emitted.  Mangrove Association - Mangrove Strategies -   13  InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected            \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Magic Values",
        "body": "  The use of magic numbers in the codebase is not recommended, they should be replaced by variables with a self-explanatory name. Examples are:  CS-MGVSTRATS-007   \"mgv/writeOffer/density/tooLow\"   \"mgv/tradeSuccess\"  Acknowledged:  Mangrove Association replied:  since these magic values are part of mangrove\u2019s specification, we assume they won\u2019t change.  Mangrove Association - Mangrove Strategies -   14  InformationalVersion1Acknowledged    \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Hypothetical Bad Setups for Kandels",
        "body": "  While we exclude \"weird\" setups for the Kandel from scope, we would like to give an incomplete list of examples of such breaking setups:  1. populate() does not enforce the geometric price progression over indices. The distribution could  be arbitrary.  2. populate() does not enforce that for every index a bid and ask exist. Hence, one could create  setups where the updating of dual offers would always fail due to a lack of offer ID.  3. The geometric population functions have assumptions such as the tick spacing of the market being  respected by the arguments.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Maker Should Oversupply Due to Aave Being",
        "body": " off by 1  The maker should oversupply AaveKandel by some WEI to account for Aave internal loss of precision, which can lead the token amount to be off by 1 on redemption, as it could make the trade revert if they are the only one to use the Aave pool from a given AavePooledRouter.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.3   Supplying Caps Not Considered",
        "body": "  Aave V3 has supply caps. However, these are not considered when supplying. Hence, supplying could fail so that tokens are treated as buffered.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.4   Updating Approvals on Order Update",
        "body": "  A user can update their orders by using Forwarder.updateOffer. Users need to remember that, in case the makerExecute hook to their order fails, they will have to reimburse the taker. A reason for an order to fail is that there is not enough allowance given to the router to transfer funds from the maker's reserve to the MangroveOrder contract. This is highly likely to happen after a user updates their offer by having it give more funds to the taker.  Mangrove Association - Mangrove Strategies -   15  NoteVersion1NoteVersion1NoteVersion1NoteVersion1                \f8.5   AaveKandelSeeder Missing Existence Check of Pool for Asset  No check is done on strategy deployment for a pool of BASE or QUOTE on AaveV3. If such pools cannot be supplied, the AaveKandel strategy can be deployed but there will be no yield from the deposits to the router.  Mangrove Association - Mangrove Strategies -   16  NoteVersion1  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Consistency on Zero Amount Transfers",
        "body": "  The  function  BasicDelegationPod._updateBalances  does  not  trigger  mint/burn/transfer  of delegation shares (an ERC20Pods token) on 0 amount. The ERC20 standard specifies Note Transfe rs of 0 values MUST be treated as normal transfers and fire the Transfer even t..  1inch - Delegation -   9  SecurityDesignCorrectnessCriticalHighMediumLowDesignLowVersion2           \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings   Possible Frontrunning on Registration    Pod.updateBalances() Cannot Transfer ERC20Pods   -Severity Findings   Allowances Not Completely Disabled   -Severity Findings   Broken C-E-I Pattern   Inconsistency and Zero Address Check on register()    No Event upon Registering Delegatee   0  2  1  3  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Possible Frontrunning on Registration",
        "body": "  If  a  delegatee  already  deployed  its  DelegatedShare  contact  on  its  own  and  want  to  register  it  with register(IDelegatedShare  shareToken,  address  defaultFarm),  another  user  could  front run the transaction and register the already deployed contract in place of the true delegatee, who won't be able to register the contract for itself.  This can become problematic if the DelegatedShare contract already has some accounting done.    The  register(IDelegatedShare  shareToken,  address  defaultFarm)  function  has  been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Pod.updateBalances() Cannot Transfer",
        "body": " ERC20Pods  least  one  pod   involved):  Using   Pod.updateBalances() cannot transfer (including mint or burn) tokens of another ERC20Pods (with to at  updateBalances() of a pod is executed with _POD_CALL_GAS_LIMIT amount of gas. Currently this value is hardcoded to 200_000. A transfer of an ERC20Pods within updateBalances() would trigger _updateBalances()  of  this  ERC20Pods.  The  current  call  executing  with  this  amount  of  gas  cannot forward another 200_000 gas and hence the execution reverts.  implementation  of  ERC20Pods   the  default   the  call   1inch - Delegation -   10  CriticalHighCodeCorrectedCodeCorrectedMediumCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedDesignHighVersion1CodeCorrectedDesignHighVersion1CodeCorrected                 \ffunction _updateBalances(address pod, address from, address to, uint256 amount) private {      bytes4 selector = IPod.updateBalances.selector;      bytes4 exception = InsufficientGas.selector;       assembly {  // solhint-disable-line no-inline-assembly          let ptr := mload(0x40)          mstore(ptr, selector)          mstore(add(ptr, 0x04), from)          mstore(add(ptr, 0x24), to)          mstore(add(ptr, 0x44), amount)           if lt(div(mul(gas(), 63), 64), _POD_CALL_GAS_LIMIT) {              mstore(0, exception)              revert(0, 4)          }          pop(call(_POD_CALL_GAS_LIMIT, pod, 0, ptr, 0x64, 0, 0))      }  The design of RewardableDelegationPod however requires this and hence cannot work.  Despite   Within  RewardableDelegationPod.updateBalances()  the  call  to  the  DelegatedShare  token (which  is  ERC20Pods,  and  the  accounts  are  connected  to  at  least  the  farm  pod)  is  wrapped  within try/catch.  with best  effort  of  having  consistent  shares  the  accounting  is  totally  off.  A  transfer  of  the underlying  ERC20Pod  which  triggers  RewardableDelegationPod.updateBalances()  will  never successfully execute registration[_delegate].burn(from, amount)/ registration[_del egate].mint(from,  amount).  These  calls  only  succeed  when  updateBalances()  is  called  with sufficient gas, e.g. using DelegatedShare.addPod().  annotated   function   being   itself   the     The  root  of  the  issue  has  been  addressed  in  ERC20Pods.  The  amount  of  gas  for  each  of  the  calls  in ERC20Pods._updateBalances()  is  no  longer  hardcoded  in  ERC20Pods  but  passed  as  constructor parameter.  The  ERC20Pods  that  is  DelegatedShare  has  a  fixed  100_000  gas  for  each  of  the in callbacks.  ERC20Pods->RewardableDelegationPod->ERC20Pods``, developers must be careful to set the correct amount of gas in each of them for the system to work.  ERC20Pods   stacked   When   two   like   are   function  RewardableDelegationPod.updateBalances  has  been  updated   to  call The  mint()/burn() without try/catch blocks so that every call to DelegatedShare.mint()/burn() must be successful.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Allowances Not Completely Disabled",
        "body": "  BasicDelegationPod  overwrites  and  inhibits  functions  transfer,  transferFrom  and  approve.  The increaseAllowance  and  decreaseAllowance  functions  inherited  from  OpenZeppelin's  ERC20 implementation are not overridden and hence can be used.    The functions increaseAllowance and decreaseAllowance have been explicitely disabled.  1inch - Delegation -   11  CorrectnessMediumVersion1CodeCorrected          \f6.4   Broken C-E-I Pattern  in  The  check-effects-interaction  pattern  delegated  mapping  after  _updateAccountingOnDelegate, this could lead to reentrancy or other unexpected behaviors.  function  BasicDelegationPod.delegate.  The upon contract   interaction   possible   updated   is   is   a     The mapping update and event have been moved before the call to _updateAccountingOnDelegate.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Inconsistency and Zero Address Check on ",
        "body": " register()  In function register(IDelegatedShare shareToken, address defaultFarm), it is possible to provide  shareToken=address(0),  this  would  allow  one  user  to  add  a  default  farm  for  the  zero address, and to call on of the register() functions once again, which should not be possible.    The  register(IDelegatedShare  shareToken,  address  defaultFarm)  function  has  been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   No Event upon Registering Delegatee",
        "body": "  Events  are  used  to  be  informed  of  or  to  keep  track  of  transactions  changing  the  state  of  a  contract. Generally, any important state change should emit an event.  Both functions used to register delegatees do not emit an event, hence for an observer it`s hard to track new delegatees.    Two  events  RegisterDelegatee  and  DefaultFarmSet  have  been  added,  and  are  emitted  resp. when a new delegatee registers, and when a default farm is added.  1inch - Delegation -   12  SecurityLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                      \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Users Must Add Farm if Default Farm Is",
        "body": " Updated  The deployed DelegatedShare contracts may not have a farm associated with them directly. If a farm is added later on, the users must either re-delegate or manually add the farm Pod on the DelegatedShare contract themselves.  possible   using It's  DelegatedShare.remove/removeAll()  but  still  keep  delegating  to  this  delegatee.  Users  must  be careful and understand the consequences of their actions.  remove   himself   default   farm   from   user   the   for   an   to   1inch - Delegation -   13  NoteVersion1  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Unused Import",
        "body": "  In the Lido rate provider, ERC4626 is imported and never used.  CS-YRNPR-001  Yearn - yETH Periphery -   10  InformationalVersion1  \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Implementation Might Change for Proxies",
        "body": "  Multiple  rate  providers  are  proxy  contracts.  Their  implementation  might  change.  In  consequence, incorrect rate updates or reverts might happen. Constant monitoring and updates as well as contact with the development teams of the corresponding projects might be useful for mitigation.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Providers Might Revert Instead of Returning",
        "body": " Values  When the total amount of staked tokens is null, providers behaviours can vary, some of them will return a rate of 1 to 1 with ETH while other will revert. Such a corner case should be carefully evaluated.  Yearn - yETH Periphery -   11  NoteVersion1NoteVersion1      \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Gain Exceeds Max_Debt",
        "body": "  In contract VaultV3, any strategy gains upon process_report() will be reported by increasing the strategy's  current_debt  and  the  vault's  total_debt  regardless  of  the  strategy's  max_debt parameter. In this case, the debt of a strategy can exceed its upper bound.  CS-YVV3-001  Acknowledged:  Yearn states:  This is deemed acceptable if caused by profits. Since debt can be lowered at any time after by the DEBT_MANAGER.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Reentrancy and process_report()",
        "body": "  CS-YVV3-002  process_report()  to IAccountant(accountant).report(). Note that these are trusted roles, however, if the accountant can dispatch a call from the (FORCE_)REVOKE_STRATEGY_MANAGER role, a strategy could be revoked during the process of reporting it, which breaks the correct execution flow.  the  Vault   functions   external   reenter   can   call   the   of   in   Yearn - V3 Vaults -   11  SecurityDesignCorrectnessCriticalHighMediumLowAcknowledgedRiskAcceptedCorrectnessLowVersion1AcknowledgedSecurityLowVersion1RiskAccepted                   \fFurthermore,  similarly  a  strategy  may  enter  into  proces_report()  while  an  update  of  its  debt  is  in process  (update_debt()).  Roles  are  trusted  to  not  misbehave,  the  smart  contract  implementation however does not prevent this scenario.  Risk accepted:  Yearn states:  Reentrancy was intentionally left off process_report() so that an accountant can reenter \u2018deposit\u2019 if need be to issue refunds. It is expected that the accountant never be set to a role other than accountant. And be given no other permissions.  Yearn - V3 Vaults -   12    \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings   Disproportional Unrealized Loss on Redemption   Inconsistent Debt Accounting on Withdrawal From Strategies   -Severity Findings   Add Self as a Strategy   Incorrect Return Type of Decimals   Incorrect Return Value   Incorrect and Missing Specification    Missing Event upon Role Change    Non ERC-4626 Compliant Functions    Unchecked Profit Max Unlock Time    Unprotected Sweep Function   0  0  2  8  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Disproportional Unrealized Loss on",
        "body": " Redemption  If total_idle is insufficient to fulfill a user's withdrawal, _redeem() attempts to retrieve assets from the  strategies  a  user  defined  or  overridden  by  the  queue_manager.  Should  a  queried  strategy  have unrealized loss, the user will take part of the unrealized loss. However, the user may take the loss in a disproportional way as shown in the code.   First, the user's share of the unrealized loss is computed based on assets_to_withdraw.   Afterwards, assets_to_withdraw is capped by its upper bound.  CS-YVV3-014  Yearn - V3 Vaults -   13  CriticalHighMediumCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCorrectnessMediumVersion1CodeCorrected            \funrealised_losses_share: uint256 = self._assess_share_of_unrealised_losses(strategy, assets_to_withdraw) if unrealised_losses_share > 0:     # User now \"needs\" less assets to be unlocked (as he took some as losses)     assets_to_withdraw -= unrealised_losses_share     requested_assets -= unrealised_losses_share     # NOTE: done here instead of waiting for regular update of these values because it's a rare case     # (so we can save minor amounts of gas)     assets_needed -= unrealised_losses_share     curr_total_debt -= unrealised_losses_share  # After losses are taken, vault asks what is the max amount to withdraw assets_to_withdraw = min(assets_to_withdraw, min(self.strategies[strategy].current_debt, IStrategy(strategy).maxWithdraw(self)))  If  assets_to_withdraw  is  restricted  to  strategy.maxWithdraw(self),  the  user  will  cover  more than his proportional share of the loss. In addition, the updated current_debt of this strategy as well as the  vault's  total  debt  will  diverge  from  the  real  debt  because  unrealised_losses_share  has  been overestimated.  current_debt: uint256 = self.strategies[strategy].current_debt new_debt: uint256 = current_debt - (assets_to_withdraw + unrealised_losses_share)  # Update strategies storage self.strategies[strategy].current_debt = new_debt    When  max_withdraw  is  the  limiting  factor  for  assets_to_withdraw,  the  unrealised  loss  the  user takes is now adjusted proportionally. As a result, the user no longer bears more than their fair share of the loss, and the update to current_debt is done using the correct value.  # If max withdraw is limiting the amount to pull, we need to adjust the portion of # the unrealized loss the user should take. if max_withdraw < assets_to_withdraw - unrealised_losses_share:     # How much would we want to withdraw     wanted: uint256 = assets_to_withdraw - unrealised_losses_share     # Get the proportion of unrealised comparing what we want vs. what we can get     unrealised_losses_share = unrealised_losses_share * max_withdraw / wanted     # Adjust assets_to_withdraw so all future calcultations work correctly     assets_to_withdraw = max_withdraw + unrealised_losses_share  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Inconsistent Debt Accounting on Withdrawal",
        "body": " From Strategies  If total_idle is insufficient to fulfill the redemption, _redeem() attempts to retrieve assets from the strategies.  Should  a  queried  strategy  have  an  unrealized  loss,  the  user  has  to  take  a  part  of  this  loss, which  is  regarded  as  realized  and  deducted  from  curr_total_debt.  At  the  end  of  the  loop, self.total_debt is updated to curr_total_debt.  # CHECK FOR UNREALISED LOSSES # If unrealised losses > 0, then the user will take the proportional share and realise it # (required to avoid users withdrawing from lossy strategies) # NOTE: assets_to_withdraw will be capped to strategy's current_debt within the function # NOTE: strategies need to manage the fact that realising part of the loss can mean the realisation of 100% of the loss !!  CS-YVV3-006  Yearn - V3 Vaults -   14  CorrectnessMediumVersion1CodeCorrected        \f#  (i.e. if for withdrawing 10% of the strategy it needs to unwind the whole position, generated losses might be bigger) unrealised_losses_share: uint256 = self._assess_share_of_unrealised_losses(strategy, assets_to_withdraw) if unrealised_losses_share > 0:         # User now \"needs\" less assets to be unlocked (as he took some as losses)         assets_to_withdraw -= unrealised_losses_share         requested_assets -= unrealised_losses_share         # NOTE: done here instead of waiting for regular update of these values because it's a         # rare case (so we can save minor amounts of gas)         assets_needed -= unrealised_losses_share         curr_total_debt -= unrealised_losses_share  # After losses are taken, vault asks what is the max amount to withdraw assets_to_withdraw = min(assets_to_withdraw, min(self.strategies[strategy].current_debt, IStrategy(strategy).maxWithdraw(self)))  # continue to next strategy if nothing to withdraw if assets_to_withdraw == 0:     continue  However, in case the strategy with unrealized loss reports 0 on maxWithdraw(), it will jump to the next iteration  debt code  which  (strategies.current_debt).  Consequently,  the  sum  of  all  strategies.current_debt  will exceed self.total_debt and result in an accounting inconsistency.  strategy-specific   following   updates   skip   and   the   the   current_debt: uint256 = self.strategies[strategy].current_debt new_debt: uint256 = current_debt - (assets_to_withdraw + unrealised_losses_share)  # Update strategies storage self.strategies[strategy].current_debt = new_debt # Log the debt update log DebtUpdated(strategy, current_debt, new_debt)    The updated code ensures accurate accounting before proceeding to the next loop iteration when it is not possible to withdraw funds from a strategy:  1. If funds are simply locked, the users share of the loss to cover is zero and all accounting is correct.  2. If the strategy has a complete loss, the user realiszes this loss and the strategies debt is updated.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Add Self as a Strategy",
        "body": "  The vault should not add itself as a strategy. Otherwise, update_debt will revert when funds are to be deposited into the strategy, as the recipient of the shares cannot be the vault itself.  CS-YVV3-012    In the updated code it is no longer possible to add the vault itself as a strategy.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Incorrect Return Type of Decimals",
        "body": "  decimals() of contract VaultV3 returns an uint256 which does not comply with the ERC20 standard where an uint8 is returned.  CS-YVV3-009  Yearn - V3 Vaults -   15  DesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                \f  The type of the return value has been changed to uint8 which is compliant with the specification.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Incorrect Return Value",
        "body": "  CS-YVV3-011  mint()  returns  the  calculated  amount  of  assets  to  deposit,  instead  of  the  actual  amount  of  assets into  assets  equal  max(uint256), deposited.  self._deposit()  considers  this  a  \"magic  value\"  and  will  only  deposit  the  user's  balance.  mint() however will return max(uint256) and not the actual amount of assets deposited.  If  a  user  mints  shares  which  converted   The  same  issue  exists  for  withdraw()  when  the  amount  of  assets  converted  to  shares  equals max(uint256).  The possibility of these scenarios depends on the exchange rate between shares and assets. The caller might rely on the returned values for further calculations or decision-making processes, which could lead to unintended consequences due to the discrepancy in the returned and actual deposited or withdrawn assets.    Yearn has removed the ability to pass MAX_UINT as a \"magic value\" to use the full balance.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Incorrect and Missing Specification",
        "body": "  In contract VaultV3, mint() returns the amount of assets deposited instead of shares according to its specification. In addition, the specifications of withdraw() and redeem() are missing.  CS-YVV3-010  Specification changed:  The  specification  of  mint()  has  been  corrected.  Specification  has  been  added  for  withdraw()  and redeem().  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Missing Event upon Role Change",
        "body": "  In  contrast  to  other  sections  of  the  code,  role  management  functions  (with  the  exception  of accept_role_manager)  do  not  emit  events  upon  these  important  state  changes.  Emitting  events would enable external parties to observe these important state changes more easily.  CS-YVV3-013  Yearn - V3 Vaults -   16  CorrectnessLowVersion1CodeCorrectedCorrectnessLowVersion1Speci\ufb01cationChangedDesignLowVersion1CodeCorrected                        \f  Events  have  been  added  to  set_role(),  set_open_role()  and  close_open_role().  Note  that transfer_role_manager() does not emit an event, an event is emitted upon the completion of the role transfer in accept_role_manager() only.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   Non ERC-4626 Compliant Functions",
        "body": "  In case the vault is in shutdown mode, no further deposit can be made. However, maxDeposit() does not return 0 when the vault is shutdown.  The ERC-4626 specification however requires the function to return 0 in this case:  CS-YVV3-007  ... if deposits are entirely disabled (even temporarily) it MUST return 0.  In addition, maxWithdraw() assumes a full withdrawal is possible if queue_manager is set regardless of the unrealized loss. This conflicts with the specification which reads:  MUST NOT be higher than the actual maximum that would be accepted (it should underestimate if necessary)  Besides, convertToShares() does not distinguish the following cases when total_assets is 0:   This is the first deposit where price per share is 1.   The vault is dead where there are shares remaining but no assets. The price per share is 0 because  further deposit would revert in _issue_shares_for_amount.  This  would  be  misleading  convertToShares() but fail on deposit().  for  external  contracts   to  see  a  non-zero  value  when  using  More  informational,  the  ERC-4626  specification  is  loosely  defined  in  these  corner  cases  for  these functions. Nevertheless we want to highlight the potentially unexpected amounts returned:  previewRedeem(): In case totalAssets is zero, the conversion is done at a 1:1 ratio. At this point either no shares exist (I) or the value of the existing shares has been diluted to 0 (II). For (I) the returned value  of  0  is  appropriate.  For  (II)  previewRedeem()  does  not  revert  while  redeem()  reverts;  the specification reads:  MAY revert due to other conditions that would also cause redeem to revert.  previewWithdraw()  returns  the  amount  in  a  1:1  exchange  rate  when  assets==0  but  shares!=0. Again for non-zero values the amount returned may be misleading.  Strictly  speaking  the  value  returned  is  not  breaking  the  specification  but  might  be  unexpected  by  the caller.  The  caller  should  be  aware  of  this  and  any  external  system  should  exercise  caution  when integrating with these functions.  The full specification can be found here: https://eips.ethereum.org/EIPS/eip-4626    The  code  has  been  changed  so  that  the  deposit  limit  is  set  to  0  when  the  vault  is  shutdown,  thus maxDeposit() would return 0 in this case. convertToShares() has been adjusted to distinguish the case  when  the  vault  is  dead.  The  potentially  misleading  return  value  of  previewWithdraw()  is acknowledged.  Yearn - V3 Vaults -   17  CorrectnessLowVersion1CodeCorrected        \fYearn also acknowledged the risk of maxWithdraw() and states:  It is deemed acceptable for maxWithdraw() to not take into account unrealized losses. Since this would be very gas intensive for a function potentially used on chain, and is not possible to accurately account for vaults that allow custom withdraw queues.  The  external  system  is  expected  to  exercise  caution  with  the  features  of  this  contract  during  their integration.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   Unchecked Profit Max Unlock Time",
        "body": "  In  contract  VaultV3,  profit_max_unlock_time  is  not  checked  at  initialization.  A  faulty  value  may lead  to  unexpected  behaviors.  In  case  profit_max_unlock_time==0,  the  profit  of  the  vault  will  be locked forever. In case profit_max_unlock_time is too large, the weighted average computation of new_profit_locking_period may revert, which blocks process_report() as a consequence.  CS-YVV3-015    profit_max_unlock_time  is  now  checked  in  the  vault  constructor  and  setter  ensuring  that  it  is greater than 0 and less than 1 year.  # Must be > 0 so we can unlock shares assert profit_max_unlock_time > 0 # dev: profit unlock time too low # Must be less than one year for report cycles assert profit_max_unlock_time <= 31_556_952 # dev: profit unlock time too long  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   Unprotected Sweep Function",
        "body": "  sweep()  is  not  protected  by  the  reentrancy  guard.  If  trusted  roles  misbehave  it's  possible  to  sweep assets  of  the  vault  at  a  time  when  the  value  of  total_idle  is  stale.  No  direct  issue  has  been uncovered, however this permits excessive access which may introduce unnecessary risks.  CS-YVV3-008  deposit(),   In  of by  erc20_safe_transfer_from() only if the weird underlying token calls back to the sender after transferring the token.  sweep()   reenter   calling   could   hook   one   the   in    Another case is that a strategy reenters sweep() when update_debt() calls withdraw() on the strategy.  As  the  balance  withdrawn  is  determined  based  on  the  delta  of  the  actual  balance,  this shouldn't have any negative impact, apart from potentially spurious events.    A guard has been added for extra safety.  Yearn - V3 Vaults -   18  DesignLowVersion1CodeCorrectedSecurityLowVersion1CodeCorrected                 \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Loose Token Decimal Restriction",
        "body": "  The  vault's  share  token  has  the  same  token  decimal  as  the  underlying  token.  The  underlying  token decimal is restricted (<= 38) in the VaultV3 constructor.  Token decimals are only for user representation and front-end interfaces. At the smart contract level, all balances  maintain  token  decimal  precision.  Overflows  could  potentially  occur  if  a  token  permits sufficiently large balances, leading to an overflow when these balances are multiplied. Importantly, this issue is unrelated to decimals, so the check in the constructor cannot prevent it.  Note  that  we  are  not  aware  of  any  meaningful  token  with  this  behavior,  this  is  more  a  theoretical consideration.  CS-YVV3-003  Yearn  understand  that  overflows  are  still  possible  no  matter  the  token  decimal  value  used.  The  check was updated, it now only ensures that the decimal value does not exceed an uint8. Legitimate vaults with a normal underlying token will not trigger any overflows.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Updating Queue_Manager",
        "body": "  CS-YVV3-004  The  queue_manager  smart  contract  defines  the  withdrawal  sequence  for  a  vault.  Whenever  a  new calling informs  strategy  queue_manager.new_strategy(address strategy).  queue_manager   added,   vault   the   the   by   is   The  queue  manager  for  the  vault  can  be  updated  using  set_queue_manager().  Note  that  the  new queue manager is not informed about all existing strategies of the vault; in this case the queue manager must be configured correctly manually.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   yv<Asset_Symbol> Not Enforced",
        "body": "  The  system  specification  requires  the  shares  to  be  named  yv<Asset_Symbol>.  Note  that  this  isn't enforced by the code, the share name can be freely defined when deploying a new Vault.  CS-YVV3-005  Yearn - V3 Vaults -   19  InformationalVersion1InformationalVersion1InformationalVersion1          \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Debt Rebalanced in a Linear Way",
        "body": "  During update_debt(), if the target debt value cannot be reached given the vault and strategy specific limitations on the idle and debt, it will not revert. Instead, it will rebalance the debt to the closest value towards  the  target.  This  behavior  assumes  it  is  always  better  to  be  closer  to  the  target.  However,  the assumption may not always be true for different strategies.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   No User Protection on Shares Redemption",
        "body": "  If during redemption funds must be pulled from a strategy at a loss, the user must cover his share of this not  yet  realized  loss.  Additionally,  in  case  the  call  to  strategy.withdraw()  results  in  less  than  the requested assets, the user takes the full loss.  Unaware  users  may  redeem  their  shares  for  less  of  the  underlying  than  they  expect.  There  is  no protection e.g. in form of a parameter which allows the user to specify the minimum amount of underlying to receive / shares to be burned he tolerates before the transaction should revert.  Yearn states:  It is expected that off chain users interact with the vaults through an ERC-4626 router which has logic to set minimums and slippage tolerance for deposits and withdrawals. And on chain users can either use the router or set their own limits.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.3   Queue Manager Can Pause Withdrawals From",
        "body": " Strategies  A faulty or malicious queue_manager with should_override enabled can pause users' withdrawals from  strategies  by:  (1)  directly  revert.  (2)  return  a  non-existing  strategy.  queue_manager  must  be properly configured and trusted if enabled.    the  should_override  option  has  been  removed  so  users  can  always  bypass  the In  queue_manager  if  a  customized  withdraw  queue  is  specified.  Otherwise,  the  withdraw  queue  will  be queried from the queue_manager.  Yearn - V3 Vaults -   20  NoteVersion1NoteVersion1NoteVersion1Version2          \fif queue_manager != empty(address):     if len(_strategies) == 0:         _strategies = IQueueManager(queue_manager).withdraw_queue(self)  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.4   Race Condition on Withdrawal From",
        "body": " Strategies  If total_idle is insufficient to fulfill the redemption, _redeem() attempts to retrieve assets from the strategies. Should a queried strategy have unrealized loss, the user has to take a part of this loss. In case the vault has global unrealized loss, users may engage in a race to withdraw from the optimal strategies.  In  case  the  queue_manager  is  disabled,  users  will  race  to  withdraw  from  the  strategies  without unrealized loss. As a consequence, the tardy users will take more unrealized loss.  In case the queue_manager is enabled, withdrawals may be biased across all strategies depending on the actual construction of the withdraw_queue.  Users  will  only  share  the  unrealized  loss  of  a  strategy  in  a  fair  way  if  it  is  reported  by  the REPORTING_MANAGER.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.5   Tokens With a Blacklist",
        "body": "  Tokens such as USDC maintain a blacklist that prohibits the transfer of tokens to and from the addresses listed  on  it.  Assuming  a  vault  utilizes  such  a  token,  a  blacklisted  address  would  be  unable  to  be  the recipient when funds are withdrawn. If a strategy is blacklisted, withdrawal of allocated funds would be impossible.  Furthermore,  if  a  vault  itself  is  blacklisted,  the  withdrawal  of  all  deposited  funds  would  be prevented.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.6   Trade-off in Profits Distribution",
        "body": "  All profits getting paid to vault depositors are retroactive:   New joiners of a vault will share part of the locked profits accumulated before they entered.   The locked profits generated by their deposits will be forfeited upon their withdrawals.  This is a trade-off to improve the gameability and avoid intensive gas to track specific accounts for the time they deposit. As long as the profits are distributed slowly and continuously, no whales are expected to game the system by deposit right before a profit harvest and realize full gains.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.7   User-Selected Strategies",
        "body": "  If no queue manager is configured, when idle funds are insufficient for a withdrawal, users can specify which strategies should be used to retrieve funds.  Yearn - V3 Vaults -   21  NoteVersion1NoteVersion1NoteVersion1NoteVersion1                  \fThis  could  enable  users  to  substantially  interfere  with  the  planned  allocation  of  assets,  necessitating frequent intervention from the debt_manager.  Yearn - V3 Vaults -   22  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Read-only Reentrancy",
        "body": "  It  can  be  possible  to  construct  examples  where  certain  properties  of  the  SV  mismatch  reality.  For example, during reallocations, a temporary devaluation of SVTs occurs due to SSTs being released. Due to reentrancy possibilities, certain values retrieved could be inaccurate (e.g. SV valuation).  CS-SpoolV2-024  Acknowledged:  While  the  read-only  reentrancy  does  directly  affect  on  the  protocol,  it  could  affect  third  parties.  Spool replied:  The mentioned view functions are not intended to be used while the reallocation is in progress.  Spool - Spool V2 -   20  SecurityDesignCorrectnessCriticalHighMediumLowAcknowledgedDesignLowVersion1Acknowledged             \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  1  7  5  19  -Severity Findings   Lack of Access Control in recoverPendingDeposits()   -Severity Findings   DOS Synchronization by Dividing With Zero Redeemed Shares    DOS on Deposit Synchronization    Donation Attack on SST Minting    Donation Attack on SVT Minting    Flushing Into Ongoing DHW Leading to Loss of Funds    No Deposit Due to Reentrancy Into redeemFast()    Wrong Slippage Parameter in Curve Deposit   -Severity Findings   Curve LP Token Value Calculation Can Be Manipulated    Deposits to Vault With Only Ghost Strategies Possible    Ghost Strategy Disables Functionality   Inconsistent Compound Strategy Value    Strategy Value Manipulation   -Severity Findings   Distribution to Ghost Strategy    Lack of Access Control for Setting Extra Rewards    Wrong Error IdleStrategy.beforeRedeemalCheck()    Access Control Not Central to Access Control Contract    Asset Decimal in Price Feed    Bad Event Emissions    Broken Conditions on Whether Deposits Have Occurred    Deposit Deviation Can Be Higher Than Expected   Inconsistent Handling of Funds on Strategy Removal    Misleading Constant Name    Missing Access Control in Swapper    Missing Event Fields    No Sanity Checks on Slippage Type    Precision Loss in Notional Finance Strategy    Redemption Executor   Spool - Spool V2 -   21  CriticalCodeCorrectedHighCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedMediumCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrected  \f9   State Inconsistencies Possible    Unused Functions    Unused Variable    Validation of Specification   Informational Findings   Reverts Due to Management Fee    Simplifying Performance Fees    Strategy Removal for an SV Possible That Does Not Use It    Errors in NatSpec    Distinct Array Lengths    Gas Optimizations    Nameless ERC20    NFT IDs    Tokens Can Be Enabled Twice   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Lack of Access Control in ",
        "body": " recoverPendingDeposits()  DepositManager.recoverPendingDeposits()  has  no  access  control  (instead  of  being  only callable by the SV manager). Thus, it allows arbitrary users to freely specify the arguments passed to the function. Ultimately, funds from the master wallet can be stolen.  CS-SpoolV2-039    Access control was added. Now, only ROLE_SMART_VAULT_MANAGER can access the function.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   DOS Synchronization by Dividing With Zero",
        "body": " Redeemed Shares  _sharesRedeemed describes the SSTs redeemed by an SV. That value could be zero due to rounding. Hence,  uint256 withdrawnAssets =                 _assetsWithdrawn[strategy][dhwIndex][j] * strategyShares[i] / _sharesRedeemed[strategy][dhwIndex];  CS-SpoolV2-001  could be a division by zero.  Consider the following scenario:  1. Many deposits are made to an SV.  Spool - Spool V2 -   22  CodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSecurityCriticalVersion3CodeCorrectedSecurityHighVersion1CodeCorrected                \f2. The attacker makes a 1 SVT wei withdrawal.  3. The attacker flushes the SV.  4. The   redeemed   as strategyWithdrawals[i] = strategyShares * withdrawals / totalVaultShares. strategyShares corresponds to the shares held by the SV. Hence if the SV's balance of SSTs is lower than the total supply of SSTs (recall, the withdrawal is 1), the shares to be withdrawn is 0.  computes   SSTs   are   5. The  withdrawal  manager  passes  it  to  the  strategy  registry  which  then  stores  these  values  in  _sharesRedeemed.  6. No other SV tries to withdraw.  7. The division reverts on synchronization.  Ultimately, funds will be locked and SVs could be DOSed.    Now,  in  every  iteration  of  the  loop  in  StrategyRegistry.claimWithdrawals(),  it  is  checked whether the strategy shares to be withdrawn from the SV (strategyShares) are non-zero. In the case of strategyShares being zero, the iteration is skipped. If not the case, _sharesRedeemed > 0 will In  other  words, hold.  That  strategyShares_SV > 0 => _sharesRedeemed > 0.  sum  of  all  SV  withdrawals.   is  because   the   is   it   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   DOS on Deposit Synchronization",
        "body": "  After  the  DHW  of  an  SV's  to-sync  flush  cycle,  the  SV  must  be  synced.  The  deposit  manager  decides, based on the value of the deposits at DHW, how many of the minted SSTs will be claimable by the SV. It is computed as follows:  result.sstShares[i] = atDhw.sharesMinted * depositedUsd[0] / depositedUsd[1];  CS-SpoolV2-002  The  depositedUsd  has  the  total  deposit  of  the  vault  in  USD  at  index  zero  while  at  index  1  the  total deposits of all SVs are aggregated.  To calculate result.sstShares[i] the following condition should be met:  /// deposits = _vaultDeposits[parameters.smartVault][parameters.bag[0]][0]; deposits > 0 && atDhw.sharesMinted > 0  which means that the first asset in the asset group had to be deposited and that at least one SST had to be  minted.  Given  very  small  values  and  front-running  DHWs  with  donations  that  could  be  achieved. Ultimately, a division-by-zero could DOS the synchronization.  Consider the following scenario:  1. Only withdrawals occur on a given strategy.  2. An attacker sees a DHW incoming for that strategy.  3. The attacker frontruns the transaction and makes a minor deposit so that deposits > 0 holds. Additionally,  the  assetToUsdCustomPriceBulk()  should  return  0  which  is  possible  due  to rounding. See the following code in UsdPriceFeedManager.assetToUsdCustomPrice:  Spool - Spool V2 -   23  SecurityHighVersion1CodeCorrected        \fassetAmount * price / assetMultiplier[asset];  Under  the  condition  that  assetAmount  *  price  is  less  than  assetMultiplier  (e.g.  1  wei  at  0.1 USD for a token with 18 decimals), that will return 0.  4. Additionally, the attacker donates an amount so that Strategy.doHardWork() so that 1 wei SST will  be  minted  (note  that  the  Strategy  mints  based  on  the  balances  and  does  not  receive  the amount that were deposited).  5. Finally, DHW is entered and succeeds with 1 minted share.  6. The vault must sync. However, it reverts due to depositedUsd[1] being calculated as 0.  Ultimately, an attacker could cheaply attack multiple SVs under certain conditions.    deposits  >  0  has  been  replaced  by  checking  whether  there  are  any  deposits  made  to  any  of  the underlying assets. Additionally, a condition skips the computation (and some surrounding ones) in case the deposited value is zero.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Donation Attack on SST Minting",
        "body": "  The SSTs are minted on DHW and based on the existing value. However, it is possible to donate (e.g. aTokens to the Aave strategy) to strategies so that deposits are minting no shares.  CS-SpoolV2-003  A simple attack may cause a loss in funds. Consider the following scenario:  1. A new strategy is deployed.  2. 1M USD is present for the DHW (value was zero since it is a new strategy).  3. An attacker donates 1 USD in underlying of the strategy (e.g. aToken).  4. DHW  on   the depositShareEquivalent  will  be  computed  using  multiplication  with  total  supply  which  is  0. Ultimately, no shares will be minted.  strategies  happens.``usdWorth[0]``  will  be  non-zero.  Hence,   the   Ultimately, funds could be lost.  An attacker could improve on the attack for profit.  1. A new strategy is deployed.  2. An attacker achieves to mint some shares.  3. The attacker redeems the shares fast so that only 1 SST exists.  4. Now, others deposit 1M USD.  5. The attacker donates 1M + 1 USD in yield-bearing tokens to the strategy.  6. No  shares  are  minted  due  to  rounding  issues  since  the  depositSharesEquivalent  and  the  withdrawnShares are zero.  The deposits will increase the value of the strategy so that the attacker profits.  Ultimately, funds could be stolen.  Spool - Spool V2 -   24  SecurityHighVersion1CodeCorrected        \f  While the total supply of SSTs is less than INITIAL_LOCKED_SHARES, the shares are minted at a fixed rate.  INITIAL_LOCKED_SHARES  are  minted  to  the  address  0xdead  so  that  a  minimum  amount  of shares is enforced. That makes such attacks much more expensive.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Donation Attack on SVT Minting",
        "body": "  The  SVTs  that  are  minted  on  synchronization  are  minted  based  on  the  existing  value  at  the  flush. However, it is possible to donate to SVs so that deposits are minting no shares.  CS-SpoolV2-004  A simple attack may cause a loss in funds. Consider the following scenario:  1. A new SV is deployed.  2. 1M USD is flushed (value was zero since it is a new vault).  3. An  attacker,  holding  some  SSTs  (potentially  received  through  platform  fees),  donates  1  USD  in  SSTs (increases the vault value to 1 USD). Frontruns DHW.  4. DHW on the strategies happens.  5. The  SV   gets   of if  (totalUsd[1]  ==  0)  since  the  value  is  1  USD.  The  SVTs  are  minted  based  on  the  total supply of SVTs which is zero. Hence, zero shares will be minted.  synchronization   synced.  The   branch   enter   does   not   the   6. The depositors of the fund receive no SVTs.  Ultimately, funds could be lost.  An attacker could improve on the attack for profit.  1. A new SV is deployed.  2. An attacker achieves to mint some shares.  3. The attacker redeems the shares fast so that only 1 SVT exists.  4. Now, others deposit 1M USD, and the deposits are flushed.  5. The attacker donates 1M + 1 USD in SSTs to the strategy.  6. Assume there are no fees for the SV for simplicity. Synchronization happens. The shares minted for  the deposits will be equal to 1 * 1M USD / (1M + 1 USD) which rounds down to zero.  The deposits will increase the value of the vault so that the attacker profits.  Finally,  consider  that  an  attack  could  technically  also  donate  to  the  strategy  before  the  DHW  so  that totalStrategyValue is pumped.    While the total supply of SSTs is less than INITIAL_LOCKED_SHARES, the shares are minted at a fixed rate.  INITIAL_LOCKED_SHARES  are  minted  to  the  address  0xdead  so  that  a  minimum  amount  of shares is enforced. That makes such attacks much more expensive.  Spool - Spool V2 -   25  SecurityHighVersion1CodeCorrected          \f6.6   Flushing Into Ongoing DHW Leading to Loss of Funds  The DHW could be reentrant due to the underlying protocols allowing for reentrancy or the swaps being reentrant. That reentrancy potential may allow an attacker to manipulate the perceived deposit value in Strategy.doHardWork().  Consider the following scenario:  1. DHW is being executed for a strategy. The deposits are 1M USD. Assume that for example the best  off-chain computed path is taken for swaps. An intermediary token is reentrant.  2. The  strategy  registry  communicated  the  provided  funds  and  the  withdrawn  shares  for  the  DHW  CS-SpoolV2-005  index to the strategy.  3. Funds are swapped.  4. The  attacker  reenters  a  vault  that  uses  the  strategy  and  flushes  1M  USD.  Hence,  the  funds  to  deposit and shares to redeem for the DHW changed even though the DHW is already running.  5. The funds will be lost. However, the loss is split among all SVs.  6. However, the next DHW will treat the assets as deposits made by SVs. An attacker could maximize his profit by depositing a huge amount and flushing to the DHW index where the donation will be applied. Additionally, he could try flushing all other SVs with small amounts. The withdrawn shares will be just lost.  To summarize, flushing could be reentered to manipulate the outcome of DHW due to bad inputs coming from the strategy registry.    Reentrancy protection has been added for this case.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   No Deposit Due to Reentrancy Into ",
        "body": " redeemFast()  CS-SpoolV2-006  The DHW could be reentrant due to the underlying protocols allowing for reentrancy or the swaps being reentrant. That reentrancy potential may allow an attacker to manipulate the perceived deposit value in Strategy.doHardWork().  Consider the following scenario:  1. DHW  is  executed  for  a  strategy.  The  deposits  are  1M  USD.  Assume  that  for  example  the  best  off-chain computed path is taken for swaps. An intermediary token is reentrant.  2. DHW checks the value of the strategy, which is 2M USD and fully controlled by the attacker's SV.  3. The DHW swaps the incoming assets. The attacker takes control of the execution.  4. The attacker redeems 1M USD with redeemFast(). The strategy's value drops to 1M USD.  5. DHW proceeds, a good swap is made and the funds are deposited into the protocol.  6. DHW retrieves the new strategy value which is now 2M USD.  Spool - Spool V2 -   26  SecurityHighVersion1CodeCorrectedSecurityHighVersion1CodeCorrected              \f7. The perceived deposit is now 0 USD due to 2. and 6. However, the actual deposit was 1M USD.  Ultimately, the deposit made is treated as a donation to the attacker since zero shares are minted.  Similarly, such attacks are possible when redeeming SSTs with redeemStrategyShares().  Also,  the  attack  could  occur  in  regular  protocol  interactions  if  the  underlying  protocol  has  reentrancy possibilities  (e.g.  protocol  itself  has  a  swapping  mechanism).  In  such  cases,  the  reallocation  could  be vulnerable due to similar reasons in depositFast().    Reentrancy protection has been added for this case.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   Wrong Slippage Parameter in Curve Deposit",
        "body": "  Curve3CoinPoolBase._depositToProtocol() calculates an offset for the given slippage array. This  offset  is  then  passed  -  without  the  actual  array  -  into  the  function  _depositToCurve().  The add_liquidity()  function  of  the  Curve  pool  is  then  called  with  this  offset  parameter,  setting  the slippage to always either 7 or 10:  CS-SpoolV2-007  uint256 slippage; if (slippages[0] == 0) {     slippage = 10; } else if (slippages[0] == 2) {     slippage = 7; } else {     revert CurveDepositSlippagesFailed(); }  _depositToCurve(tokens, amounts, slippage);  pool.add_liquidity(curveAmounts, slippage);  DHW calls can be frontrun to extract almost all value of this call.    Curve3CoinPoolBase._depositToProtocol()  now  passes  the  correct  value  of  the  slippages array to _depositToCurve().  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   Curve LP Token Value Calculation Can Be",
        "body": " Manipulated  CS-SpoolV2-008  Spool - Spool V2 -   27  CorrectnessHighVersion1CodeCorrectedCorrectnessMediumVersion1CodeCorrected                \fCurve3CoinPoolBase._getUsdWorth()  calculate the value of available LP tokens in the following way:  and   ConvexAlusdStrategy._getTokenWorth()  for (uint256 i; i < tokens.length; ++i) {     usdWorth += priceFeedManager.assetToUsdCustomPrice(         tokens[i], _balances(assetMapping.get(i)) * lpTokenBalance / lpTokenTotalSupply, exchangeRates[i]     ); }  This  is  problematic  as  the  pool  exchanges  tokens  based  on  a  curve  (even  though  it  is  mostly  flat). Consider the following scenario (simplified for 2 tokens):   The pool's current A value is 2000.   The pool holds 100M of each token.   The total LP value according to the given calculation is 200M USD.   A big trade (200M) changes the holdings of the pool in the following way:   300M A token   ~160 B token   The total LP value according to the given calculation is now ~300M USD.  A  sandwich  attack  on  StrategyRegistry.doHardWork()  could  potentially  skew  the  value  of  a strategy dramatically (although an enormous amount of tokens would be required due to the flat curve of the StableSwap pool). This would, in turn, decrease the number of shares all deposits in this DHW cycle receive, shifting some of this value to the existing depositors.  All  in  all,  an  attacker  must  hold  a  large  position  on  the  strategy,  identify  a  DHW  that  contains  a  large deposit to the strategy and then sandwich attack it with a large amount of tokens. The attack is therefore rather unlikely but has a critical impact.    The  Curve  and  Convex  strategies  now  contain  additional  slippage  checks  for  the  given  Curve  pool's token  balances  (and  also  the  Metapool's  balances  in  the  case  of  ConvexAlusdStrategy)  in beforeDepositCheck. As this function is always called in doHardWork, the aforementioned sandwich attack can effectively be mitigated by correctly set slippages. It is worth noting that these slippages can be  set  loosely  (to  prevent  the  transaction  from  failing)  as  some  less  extreme  fluctuations  cannot  be exploited due to the functionality of the underlying Curve 3pool.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   Deposits to Vault With Only Ghost Strategies",
        "body": " Possible  Governance  can  remove  strategies  from  vaults.  It  happens  by  replacing  the  strategy  with  the  ghost strategy.  However,  if  an  SV  has  only  ghost  strategies,  deposits  to  it  are  still  possible  (checking  the deposit  ratio  always  works  since  the  ideal  deposit  ratio  is  0  or  due  to  the  \"one-token\"  mechanics). However, flushing would revert. User funds could unnecessarily be lost. Similarly, redemptions would be possible. Additionally, synchronization could occur if the ghost strategy is registered (which should not be the case).  CS-SpoolV2-009  Spool - Spool V2 -   28  CorrectnessMediumVersion1CodeCorrected        \f  The case was disallowed by making a call to the newly implemented function _nonGhostVault, which also  gets  called  when  redeeming  and  flushing.  Hence,  depositing  to,  redeeming  and  flushing  from  a ghost vault is disabled.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.11   Ghost Strategy Disables Functionality",
        "body": "  Governance can remove strategies from SVs by replacing them with the ghost strategy. This may break redeemFast() on SVs due to StrategyRegistry.redeemFast() trying to call redeemFast() on the ghost strategy.  CS-SpoolV2-010    The iteration is skipped in case the current strategy is the ghost strategy. Hence, the function is not called on the ghost strategy anymore.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.12   Inconsistent Compound Strategy Value",
        "body": "  CompoundV2Strategy  calculates  the  yield  of  the  last  DHW  epoch  with  exchangeRateCurrent() which returns the supply index up until the current block:  uint256 exchangeRateCurrent = cToken.exchangeRateCurrent();  baseYieldPercentage = _calculateYieldPercentage(_lastExchangeRate, exchangeRateCurrent); _lastExchangeRate = exchangeRateCurrent;  CS-SpoolV2-011  On the other hand, _getUsdWorth() calculates the value of the whole strategy based on the output of _getcTokenValue() which in turn calls Compound's exchangeRateStored():  if (cTokenAmount == 0) {     return 0; }  // NOTE: can be outdated if noone interacts with the compound protocol for a longer period return (cToken.exchangeRateStored() * cTokenAmount) / MANTISSA;  This behavior has been acknowledged with a comment in the code. However, it can become problematic in the following scenario:   The compound protocol did not have interaction over a longer period.   A user has deposited into a SmartVault that contains the CompoundV2Strategy.  In the doHardWork() call, the strategy's _compound function does not deposit to the protocol (i.e. the index is not updated in Compound). This can happen in the following cases:   No COMP rewards have been accrued since the last DHW.   The  ROLE_DO_HARD_WORKER  role  has  not  supplied  a  SwapInfo  to  the  strategy's  _compound function.  Spool - Spool V2 -   29  CorrectnessMediumVersion1CodeCorrectedCorrectnessMediumVersion1CodeCorrected                 \fIn this case, the following line in Strategy.doHardWork() relies on outdated data:  usdWorth[0] = _getUsdWorth(dhwParams.exchangeRates, dhwParams.priceFeedManager);  usdWorth[0]  is  then  used  to  determine  the  number  of  shares  minted  for  the  depositors  of  this  DHW epoch:  mintedShares = usdWorthDeposited * totalSupply() / usdWorth[0];  Since some interest is missing from this value, the depositors receive more shares than they are eligible for, giving them instant gain.    _getcTokenValue() now retrieves the current exchange rate instead of the stale one.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.13   Strategy Value Manipulation",
        "body": "  CS-SpoolV2-043  SmartVaultManager.redeemFast() allows users to directly redeem their holdings on the underlying protocols  of  the  strategies  in  a  vault.  The  function  calls  to  Strategy.redeemFast()  in  which  the totalUsdValue of the respective strategy is updated.  This value can be manipulated in several ways:  If  the  given  Chainlink  oracle  for  one  of  the  assets  is  not  returning  a  correct  value,  the  user  can provide exchangeRateSlippages that would allow these false exchange rates to be used.  If the strategy's correct value calculation depends on slippage values to be non-manipulatable, the strategy's value can be changed with a sandwich attack as there is no possibility to enforce correct behavior (see, for example, Curve LP token value calculation can be manipulated). Furthermore, this sandwich  attack  is  particularly  easy  to  perform  as  the  user  is  in  control  of  the  call  that  has  to  be sandwiched (i.e., all calls can be performed in one transaction).  A  manipulated  strategy  value  is  problematic  for  SmartVaultManager.reallocate()  because  the totalUsdValue is used to compute how much value is moved/matched between strategies.  Note: This issue was disclosed by the Spool team during the review process of this report.    reallocate() now computes the value of strategies directly, rather than relying on totalUsdValue (which is now completely removed from the codebase),  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.14   Distribution to Ghost Strategy",
        "body": "  DepositManager._distributeDepositSingleAsset  assigns  all  dust  to  the  first  strategy  in  the given array. There are no checks present to ensure that this strategy is not the Ghost strategy.  CS-SpoolV2-040  Spool - Spool V2 -   30  SecurityMediumVersion1CodeCorrectedCorrectnessLowVersion4CodeCorrected                  \f  The code has been adjusted to add dust to the first strategy with a deposit.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.15   Lack of Access Control for Setting Extra",
        "body": " Rewards  setExtraRewards() has no access control. However, an attacker could set the extra rewards to false for a long time. Then, after their SV's first deposit to the strategy, could set it to true, so that they receive more compounded yield than they should have received.  CS-SpoolV2-041    The code has been corrected.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.16   Wrong Error ",
        "body": " IdleStrategy.beforeRedeemalCheck()  CS-SpoolV2-028  range-check   The  the IdleBeforeDepositCheckFailed error. However, IdleBeforeRedeemalCheckFailed would be the suiting error.  IdleStrategy.beforeRedeemalCheck()   reverts   with   in     The correct error is used.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.17   Access Control Not Central to Access",
        "body": " Control Contract  The specification defines that access control should be centralized in SpoolAccessControl:  All access control is handled centrally via SpoolAccessControl.sol.  CS-SpoolV2-012  However,  implementation which does not use the central access control contract.  factory  as  an  UpgradeableBeacon   the   implements  access  control   for  changing  Spool - Spool V2 -   31  CorrectnessLowVersion3CodeCorrectedCorrectnessLowVersion3CodeCorrectedCorrectnessLowVersion1Speci\ufb01cationChanged                        \fSpecification changed:  The documentation has been clarified:  Access control is managed on three separate levels:      - All privileged access pertaining to usage of the platform is handled       through SpoolAccessControl.sol, which is based on OpenZeppelin\u2019s       AccessControl smart contract      - Core smart contracts upgradeability is controlled through       OpenZeppelin\u2019s ProxyAdmin.sol      - SmartVault upgradeability is controlled using OpenZeppelin\u2019s       UpgradeableBeacon smart contract  Hence, the access control for upgrading the beacons is now accordingly documented.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.18   Asset Decimal in Price Feed",
        "body": "  The  asset  decimals  are  given  as  an  input  parameter  in  setAsset().  Although  being  cheaper  than directly querying ERC20.decimals(), it is more prone to errors. Fetching the asset decimals through the ERC20 interface could reduce such risks.  CS-SpoolV2-013    ERC20.decimals() is now called to fetch the underlying asset decimals.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.19   Bad Event Emissions",
        "body": "  In  StrategyRegistry.redeemFast(),  the  StrategySharesFastRedeemed()  is  emitted.  The assetsWithdrawn  parameter  of  the  event  will  be  set  to  withdrawnAssets  on  every  loop  iteration. However,  that  does  not  correspond  to  the  assets  withdrawn  from  a  strategy  but  corresponds  to  the assets withdrawn up to the strategy i.  CS-SpoolV2-014    The event takes now strategyWithdrawnAssets as a parameter.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.20   Broken Conditions on Whether Deposits",
        "body": " Have Occurred  Spool - Spool V2 -   32  CS-SpoolV2-015  DesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                        \fDepositManager.flushSmartVault(),   In  condition _vaultDeposits[smartVault][flushIndex][0]  ==  0  checks  whether  at  least  one  wei  of  the first token in the asset group has been deposited. However, the condition may be imprecise as it could technically be possible to create deposits such that the deposit of the first asset could be zero while the others  are  non-zero.  A  similar  check  is  present  in  DepositManager.syncDepositsSimulate() during deposit synchronization.  the   Note  that  this  would  lead  to  deposits  not  being  flushed  and  synchronized  (ultimately  ignoring  them). While  the  user  will  receive  no  SVTs  for  very  small  deposits  in  general,  the  deposits  here  would  be completely  ignored.  Further,  this  behavior  becomes  more  problematic  for  rather  large  asset  groups (given the checkDepositRatio() definition).    checks   The  of _vaultDeposits[smartVault][flushIndex]  to  all  assets  rather  than  only  considering  the  first asset in the group.  summation   improved   consider   been   have   the   to   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.21   Deposit Deviation Can Be Higher Than",
        "body": " Expected  The  deviation  of  deposits  could  be  higher  than  expected  due  to  the  potentially  exponential  dropping relation between the first and last assets. Note that the maximum deviation is the one from the minimum ideal-to-deposit ratio to the maximum ideal-to-deposit ratio. Ultimately, given the current implementation, this maximum deviation could be violated.  CS-SpoolV2-016    The following mechanism has been implemented. First, a reference asset is found with an ideal weight non-zero (first one found). Then, other assets are compared to that asset. Ultimately, each ratio is in the range of the reference asset.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.22   Inconsistent Handling of Funds on Strategy",
        "body": " Removal  When  a  strategy  is  removed  from  the  strategy  registry,  the  unclaimed  assets  by  SVs  are  sent  to  the emergency  wallet.  However,  the  funds  flushed  and  unflushed  underlying  tokens  are  not  (similarly  the minted shares are not).  CS-SpoolV2-018    Spool - Spool V2 -   33  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \fConsistency was reevaluated. The corner case of an SV with non-flushed deposited assets was handled by  introducing  a  recovery  function,  namely  DepositManager.recoverPendingDeposits().  The other cases were specified as intended.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.23   Misleading Constant Name",
        "body": "  In SfrxEthHoldingStrategy the constant CURVE_ETH_POOL_SFRXETH_INDEX is used to determine the coin ID in an ETH/frxETH Curve pool. Since the pool trades frxETH instead of sfrxETH, the naming of the constant is misleading.  CS-SpoolV2-019    Spool has changed CURVE_ETH_POOL_SFRXETH_INDEX to CURVE_ETH_POOL_FRXETH_INDEX.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.24   Missing Access Control in Swapper",
        "body": "  The  Swapper.swap()  function  can  be  called  by  anyone.  If  a  user  accidentally  sends  funds  to  the swapper or if it was called with a misconfigured SwapInfo struct, the remaining funds can be sent to an arbitrary address by anyone.  CS-SpoolV2-020    introduced  a  new   to Spool  has  Swapper.swap()  holds  ROLE_STRATEGY  or  ROLE_SWAPPER  role.  ROLE_SWAPPER  must  now additionally be assigned to the DepositSwap contract.  function  _isAllowedToSwap,  which  checks   the  caller   if   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.25   Missing Event Fields",
        "body": "  The events PoolRootAdded and PoolRootUpdated of IRewardPool do not include added root (and previous root in the case of PoolRootUpdated).  CS-SpoolV2-021    The code has been adapted to include the added root.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.26   No Sanity Checks on Slippage Type",
        "body": "  Spool - Spool V2 -   34  CS-SpoolV2-022  DesignLowVersion1CodeCorrectedSecurityLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                                \fSome functions do not verify the value in slippages[0]. Some examples are:  1. IdleStrategy._emergencyWithdrawImpl does not check if slippages[0] == 3.  2. IdleStrategy._compound does not check if slippages[0] < 2.    All relevant functions now check that slippages[0] has the expected value and revert otherwise.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.27   Precision Loss in Notional Finance Strategy",
        "body": "  NotionalFinanceStrategy._getNTokenValue()  calculates  the  value  of  the  strategy's  nToken balance in the following way:  (nTokenAmount * uint256(nToken.getPresentValueUnderlyingDenominated()) / nToken.totalSupply())     * underlyingDecimalsMultiplier / NTOKEN_DECIMALS_MULTIPLIER;  CS-SpoolV2-023  nToken.getPresentValueUnderlyingDenominated()  returns  values  similar  or  notably  smaller than  nToken.totalSupply.  On  smaller  amounts  of  nToken  balances,  precision  is  lost  in  this calculation.    The implementation of _getNTokenValue() has been changed to the following:  (nTokenAmount * uint256(nToken.getPresentValueUnderlyingDenominated()) * _underlyingDecimalsMultiplier)     / nToken.totalSupply() / NTOKEN_DECIMALS_MULTIPLIER;  All divisions are now performed after multiplications, ensuring that precision loss is kept to a minimum.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.28   Redemption Executor",
        "body": "  CS-SpoolV2-025  the   redeemer   Redemptions will enter WithdrawalManager._validateRedeem() that will run Withdrawal guards through with  executor.  when  SmartVaultManager.redeemFor()  with is  ROLE_SMART_VAULT_ALLOw_REDEEM.  This  address  through  RedeemBag  nor RedeemExtras.  In  this  case,  WithdrawalManager._validateRedeem()  runs  the  guards  with  the executor being set as the redeemer.  is  neither  sent   However,   executor   actual   called   user   the   the   as   a     The executor is now more accurately handled.  Spool - Spool V2 -   35  CorrectnessLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                  \f6.29   State Inconsistencies Possible  CS-SpoolV2-042  SmartVaultManager.redeemFast()  allows  users  to  redeem  their  holdings  directly  from  underlying protocols.  In  contrast  to  StrategyRegistry.doHardWork(),  users  can  set  the  slippages  for withdrawals themselves which could potentially lead to users setting slippages that do not benefit them.  This  is  problematic  because  the  amount  of  shares  actually  redeemed  in  the  underlying  protocol  is  not accounted for. Since some protocols redeem on a best-effort basis, fewer shares may be redeemed than requested (this is, for example, the case in the YearnV2Strategy). If this happens, and the user sets wrong slippages, the protocol burns all SVTs the user requested but does not redeem all the respective shares of the underlying protocol leading to an inconsistency that unexpectedly increases the value of the remaining SVTs.    The code for the Yearn V2 strategy has been adapted to check for full redeemals.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.30   Unused Functions",
        "body": "  The following functions of MasterWallet are not used:  1. approve  2. resetApprove    These functions have been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.31   Unused Variable",
        "body": "  CS-SpoolV2-026  1. DepositSwap.swapAndDeposit()   takes  an   input  array  of  SwapInfo,  which  contains  amountIn. This function however takes an input array of inAmounts.  2. The  mapping  DepositManager._flushShares   is  defined  as   internal  and   its  subfield  flushSvtSupply is never read.  3. WithdrawalManager._priceFeedManager is set but never used.  CS-SpoolV2-044    The code has been adapted to remove the unused variables.  Spool - Spool V2 -   36  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \f6.32   Validation of Specification  CS-SpoolV2-027  The  specification  of  an  SV  is  validated  to  ensure  that  the  SV  works  as  the  deployer  would  expect  it. However, some checks could be missing. Examples of such potentially missing checks are:  1. Request type validation for actions: Only allow valid request types for action (some request types  are not used for some actions).  2. If  static  allocations  are  used,  specifying  a  risk  provider,  a  risk  tolerance  or  an  allocation  provider may  not  be  meaningful  as  they  are  not  stored.  Similarly,  if  only  one  strategy  is  used  it  could  be meaningful to enforce a static allocation.  3. Static  allocations  do  not  enforce  the  100%  rule  that  the  allocation  providers  enforce.  For  consistency, such a property could be enforced.    The code has been adapted to enforce stronger properties on the specification.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.33   Distinct Array Lengths",
        "body": "  CS-SpoolV2-029  Some  arrays  that  are  iterated  over  jointly  can  have  distinct  lengths  which  lead  to  potentially  unused values and a result different from what was expected due to human error or a revert.  Examples of a lack of array length checks in the specification when deploying an SV through the factory are:  1. actions  and  actionRequestTypes  in  ActionManager.setActions()  may  have  distinct  length. Some request-type values may remain unused.  2. Similarly, this holds for guards.  3. In the strategy registry's doHardWork(), the base yields array could be longer than the strategies  array.  4. In assetToUsdCustomPriceBulk() the array lengths could differ. When used internally, that will not  be  the  case  while  when  used  externally  that  could  be  the  case.  The  semantics  of  this  are unclear.  5. calculateDepositRatio()  and  calculateFlushFactors()  in  DepositManager  are  similar to 4.    The missing checks in 1-3 have been added. However, for 4-5 which are view functions, Spool decided to keep as is.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.34   Errors in NatSpec",
        "body": "  Spool - Spool V2 -   37  DesignLowVersion1CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1Speci\ufb01cationChanged                  \fCS-SpoolV2-030  At  several  locations,  the  NatSpec  is  incomplete  or  missing.  The  following  is  an  incomplete  list  of examples:  1. IGuardManager.RequestContext: not all members of the struct are documented.  2. IGuardManager.GuardParamType: not all items of the enum are documented.  3. _stateAtDhw has no NatSpec.  4. IDepositManager.SimulateDepositParams:  documentation   line  of  bag  mentions  oldTotalSVTs along with flush index and lastDhwSyncedTimestamp.  5. StrategyRegistry._dhwAssetRatios:  is  a  mapping  to  the  asset  ratios,  as  the  name  suggests; however, the spec mentions exchange rate.  6. StrategyRegistry._updateDhwYieldAndApy(): it only updates APY and not the yield for a  given dhwIndex and strategy.  7. RewardManager.addToken():   or only  ROLE_SMART_VAULT_ADMIN  of  an  SV  and  not  \"reward  distributor\"  as  mentioned  in  the specification.  either  DEFAULT_ADMIN_ROLE   callable   by   Specification changed:  The  NatSpec  was  improved.  Naming  of  StrategyRegistry._updateDhwYieldAndApy()  was changed to _updateApy().  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.35   Gas Optimizations",
        "body": "  CS-SpoolV2-031  Some parts of the code could be optimized in terms of gas usage. Reducing gas costs may improve user experience. Below is an incomplete list of potential gas inefficiencies:  1. claimSmartVaultTokens() could early quit if the claimed NFT IDs are claimed. Especially, that may  be  relevant  in  cases  in  the  redeem  functions  where  a  user  can  specify  W-NFTs  to  be withdrawn.  2. The FlushShares struct has a member flushSvtSupply that is written when an SV is flushed. However, that value is never used and hence the storage write could be removed to reduce gas consumption.  3. swapAndDeposit()  queries  the  token  out  amounts  with  balanceOf().  Swapper.swap()  returns the amounts. However, the return value is unused.  4. RewardManager()  inherits  from  ReentrancyGuardUpgradeable.  It  further  is  initializable,  initializing only the reentrancy guard state. However, reentrancy locks are not used.  5. The constructor of SmartVaultFactory checks whether the implementation is 0x0. However, in  UpgradeableBeacon an isContract() check is made.  6. In  redeemFast()  the  length  of  the  NFT  IDs  and  amounts  is  ensured  to  be  equal.  However,  in  DepositManager.claimSmartVaultTokens() the same check is made.  7. In   the   internal   public  method flushSmartVault() is used. The _onlyRegisteredSmartVault() check will be performed twice.  SmartVaultManager._redeem(),   function   the   8. IStrategy.doHardwork()  could  return  the  assetRatio()  with  the  DHW  info  so  that  a staticcall to IStrategy.assetRatio() in StrategyRegistry.doHardwork() is not needed.  Spool - Spool V2 -   38  InformationalVersion1CodeCorrected      \f9. In  _validateRedeem()  the  balance  of  the  redeemer  is  checked.  However,  that  check  is  made  when the SVTs are transferred to the SV.  10. The input argument vaultName_ in SmartVault.initialize can be defined as calldata.  11. SmartVault.transferFromSpender()  gets  called  only  by  WithdrawalManager  with  spender equal to from.  12. SmartVault.burnNFT() checks that the owner has enough balance to burn. The same condition  is later checked as it calls into _burnBatch.  13. The  struct  SmartVaultSpecification  in  SmartVaultFactory  has  an  inefficient  ordering  of elements.  For  example,  by  moving  allowRedeemFor  below  allocationProvider  its  storage layout decreases by one slot.  14. The struct IGuardManager.GuardDefinition shows an inefficient ordering.  15. Where  ReallocationLib.doReallocation()  computes  sharesToRedeem,  it  can  replace  totals[0] - totals[1] with totalUnmatchedWithdrawals.  16. SmartVaultManager._simulateSync()   increments   the   memory   variable  flushIndex.toSync which is neither used later nor returned as a return value.  17. SmartVaultManager._redeem()  calls  flushSmartVault.  However,  the  internal  function  _flushSmartVault could directly be called.  18. SmartVaultManager._redeem()   storage  _flushIndexes[bag.smartVault] twice. It could be cached and reused once.  accesses   the   variable  19. StrategyRegistry.doHardWork() reads _assetsDeposited[strategy][dhwIndex][k]  twice. Similar to the issue above, it could be cached.  20. UsdPriceFeedManager.assetToUsdCustomPriceBulk() could be defined as external.  21. WithdrawalManager.claimWithdrawal() can be defined as an external function.  22. RewardManager.forceRemoveReward()   rewardConfiguration[smartVault][token],  _removeReward().  eventually  is   which   already   removes in  removed   23. RewardPool.claim()   can   simply   rewardsClaimed[msg.sender][data[i].smartVault][data[i].token]  data[i].rewardsTotal.  set to  24. SmartVaultManager._simulateSyncWithBurn()  can  fetch  fees  after  checking  all  DHWs  are completed.  25. Strategies are calling AssetGroupRegistry.listAssetGroup in multiple functions. The token  addresses could instead be cached in the strategy the avoid additional external calls.  26. REthHoldingStrategy._emergencyWithdrawImpl() reverts if slippages[0] != 3. This  check can be accomplished at the very beginning of the function.  27. REthHoldingStrategy._depositInternal()   if amounts[0] < 0.01 ETH. It is mentioned in its documentations, that the smallest deposit value should be 0.01 ETH  return   have   early   can   an   28. The  input  parameter  strategyName_  of  SfrxEthHoldingStrategy.initialize()  can  be  defined as calldata.  29. Strategy  calls  _swapAssets  and  then  loads  the  balances  of  each  token  again.  Since _swapAssets is not used in all of the strategies, the subsequent balanceOf calls by checking if _swapAssets actually performed any actions.    Spool - Spool V2 -   39  \fWhile not every improvement has been implemented, gas consumption has been reduced.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.36   NFT IDs",
        "body": "  The NFT IDs are in the following ranges:   D-NFTs: [1, 2**255 - 2]   W-NFTs: [2**255 + 1, 2**256 - 2]  CS-SpoolV2-032  Note  that  the  ranges  could  be  technically  increased.  Further,  in  theory,  there  could  be  many  more withdrawals  than  deposits.  The  sizes  do  not  reflect  that.  However,  in  practice,  a  scenario  with  such  a large  number  of  redemptions  does  not  seen  to  be  realistic.  Additionally,  getMetaData()  will  return deposit meta data for ID 0 and 2**255 - 1. However, these are not valid deposit NFT IDs. Similarly, the  function  returns  metadata  for  invalid  withdrawal  NFTs.  However,  these  remain  empty.  Last, technically  one  could  input  such  IDs  for  burn  (using  0  shares  burn).  Similarly,  one  could  burn  others' NFTs (0 amounts).  Ultimately, the effects of this may create confusion.    The range of valid NFT-IDs has been increased.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.37   Nameless ERC20",
        "body": "  The  SVT  ERC-20  does  not  have  a  name.  Specifying  a  name  may  help  third-party  front-ends  (e.g. Etherscan) to display useful information to users for a better user experience.  CS-SpoolV2-033    The SVT now has a name and symbol for its ERC-20. Additionally, the ERC-1155 has a URI now.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.38   Reverts Due to Management Fee",
        "body": "  An SV can have a management fee that is computed as  totalUsd[1] * parameters.fees.managementFeePct * (result.dhwTimestamp - parameters.bag[1])                 / SECONDS_IN_YEAR / FULL_PERCENT;  It  could  be  the  case  that  more  than  one  year  has  passed  between  the  two  timestamps.  Ultimately  the condition  parameters.fees.managementFeePct * (result.dhwTimestamp - parameters.bag[1]) > SECONDS_IN_YEAR * FULL_PERCENT  CS-SpoolV2-035  Spool - Spool V2 -   40  InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected                  \fcould hold if at least around 20 years have passed. That would make the fee greater than the total value.  Ultimately,  result.feeSVTs = localVariables.svtSupply * fees / (totalUsd[1] - fees);  could revert.    The code was corrected by limiting the dilution of SVTs so that the subtraction cannot revert.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.39   Simplifying Performance Fees",
        "body": "  The performance fees could further be simplified to  strategyUSD * interimYieldPct / (1 + interimYieldPct * (1-totalPlatformFees))  which is equivalent to the rather complicated computations made in the current implementation.  CS-SpoolV2-036  Code improved:  The readability of the code has been improved by simplifying the computation.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.40   Strategy Removal for an SV Possible That",
        "body": " Does Not Use It  The event StrategyRemovedFromVaults gets emitted for a strategy even if the SV does not use the strategy.  CS-SpoolV2-037    The event is now emitted per vault that uses the strategy. Furthermore, the name of this event has been changed to StrategyRemovedFromVault.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.41   Tokens Can Be Enabled Twice",
        "body": "  In  AssetGroupRegistry,  the  same  token  can  be  allowed  multiple  times.  Although  it  does  not  make any difference, regarding the internal state, it emits an event of TokenAllowed again.  CS-SpoolV2-038  Spool - Spool V2 -   41  InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected                  \f  The event is not emitted anymore in such cases.  Spool - Spool V2 -   42  \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Packed Arrays With Too Big Values Could",
        "body": " DOS the Contract  The  packed  array  libraries  could  technically  DOS  the  system  due  to  reverts  on  too  high  values.  For storing DHW indexes this is rather unlikely given the expectation that it will be only called every day or two (would generally require many DHWs). It is also expected that the withdrawn strategy shares will be less  than  or  equal  to  uint128.max.  Though  theoretically  speaking  DOS  on  flush  is  possible,  the conditions on the practical example are very unlikely.  CS-SpoolV2-034  Risk accepted:  Spool replied:  We agree that theoretically packed arrays could overflow and revert, however, we did some calculations and this should never happen in practice.  Spool - Spool V2 -   43  InformationalVersion1RiskAccepted    \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Bricked Smart Vaults",
        "body": "  Some Smart Vaults may be broken when they are deployed.  An example of such broken SVs could be that a malicious SV owner could deploy a specification with guards that allow deposits but disallow withdrawals (e.g. claiming SVT). Moreover, the owner may deploy a  specification  that  is  seemingly  safe  from  the  user's  perspective  while  then  maliciously  changing  the behaviour of the guard (e.g. removing from the allow list, upgrading the guard).  Another example could be where transfers between users could be allowed while the recipient could be blocked from redemption.  Similarly, actions or other addresses could be broken.  Users,  before  interacting  with  an  SV,  should  be  very  carefully  studying  the  specification.  Similarly, deployers should be knowledgeable about the system so that they can create proper specifications to not create bricked vaults by mistake.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Curve Asset Ratio Slippage",
        "body": "  Curve strategies return the current balances of the pool in their assetRatio() functions. These ratios are  cached  once  at  the  end  of  each  DHW.  For  all  deposits  occurring  during  the  next  DHW  epoch,  the same  ratios  are  used  although  the  ratios  on  the  pool  might  change  during  that  period.  It  is  therefore possible, that the final deposit to the protocol incurs a slight slippage loss.  Given the size and parameters of the pools, this cost should be negligible in most cases.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.3   DOS Potential for DHWs Due to External",
        "body": " Protocols  DHWs could be blocked in case external protocols cannot accept or return funds. For example, if Aave v2 or Compound v2 have 100% utilization, DHWs could be blocked if withdrawals are necessary. This can in turn prolong the time until deposits earn interest and become withdrawable again.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.4   ERC-1155 balanceOf()",
        "body": "  The balanceOf() function of the SV's ERC-1155 returns 1 if the user has any balance. The standard defines  that  the  function  should  return  the  balance  which  in  this  case  is  defined  as  the  \"fractional  Spool - Spool V2 -   44  NoteVersion1NoteVersion1NoteVersion1NoteVersion1              \fbalance\". Depending on the interpretation of EIP-1155, this could still match the standard. However, such a deviation from the \"norm\" could break integrations.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.5   Management Fee Considerations",
        "body": "  Users should be aware that the management fee is not taken based on the vault value at the beginning of the flush cycle but at the end of it (hence, including the potential yield of strategies, however not including fresh deposits).  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.6   Ordering of Swaps in Reallocations and",
        "body": " Swaps  The privileged user doing reallocation or swaps (e.g. the one holding ROLE_DO_HARD_WORKER) should take an optimal path when performing the swaps, as depositing to/withdrawing from a strategy changes its value.  Also, note that some strategies could be affected more by bad trades due to the swaps being performed in the order of the strategies. For example:  1. depositFast() to the first strategy happens. The swap changes the price in the DEX.  2. depositFast() to the second strategy happens. The swap works at a worse price than the first  strategy.  Ultimately, some deposits could have worse slippage.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.7   Price Aggregators With More Than 18",
        "body": " Decimals  Setting  decimals  with  UsdPriceFeedManager.setAsset(). Such are not supported by the system.  aggregators   more   price   than   18   will   revert   in  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.8   Public Getter Functions",
        "body": "  Users  should  be  aware  that  some  public  getters  provide  only  meaningful  results  with  the  correct  input values (e.g. getClaimedVaultTokensPreview()). When used internally, it is ensured that the inputs are set such that the results are meaningful.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.9   Reentrancy Potential",
        "body": "  Spool - Spool V2 -   45  NoteVersion1NoteVersion1NoteVersion1NoteVersion1NoteVersion1                    \fWhile  reentrancy  protection  was  reentrancy-based attacks may still exist. However, it highly depends on the underlying strategies. Future unknown strategies could introduce vulnerable scenarios.  the  code,  some  potential   implemented     of   in   for  An  example  could  be  a  strategy  that  swaps  both  on  compounding  and  on  deposits  in  DHW.  If  it  is possible  to  manipulate  the  USD  value  oracle  of  the  strategy  (e.g.  similar  to  Curve),  then  one  could effectively generate a scenario that creates 0-deposits or \"bypasses\" the pre-deposit/redeemal checks.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.10   Reward Pool Updates",
        "body": "  The ROLE_REWARD_POOL_ADMIN should be very careful, when updating the root of a previous cycle (if necessary), as it could break the contract for certain users.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.11   Slippage Loss in alUSD Strategy",
        "body": "  ConvexAlusdStrategy  never  invests  alUSD  into  the  corresponding  Curve  pool.  This  can  result  in  a slight  slippage  loss  due  to  unbalanced  deposits.  Both  deposits  and  withdrawals  are  subject  to  this problem.  The  loss  is  negligible  up  to  a  certain  amount  of  value  deposited/withdrawn.  After  that,  there  is  no  limit though.  At  the  time  this  report  was  written,  a  withdrawal  of  10M  LP  tokens  to  3CRV  incurs  a  loss  of roughly 25%.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.12   Special Case: Compound COMP Market",
        "body": "  Compound  v2  currently  has  an  active  market  for  the  COMP  token.  In  this  case,  deposits  to  the CompoundV2Strategy  would  be  absorbed  by  the  _compound()  function  if  a  compoundSwapInfo has  been  set  for  the  strategy.  The  correct  handling  is  therefore  completely  dependent  on  the  role ROLE_DO_HARD_WORKER and is not enforced on-chain.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.13   Unsupported Markets",
        "body": "  Some markets of the supported protocols in Spool V2's strategies might be problematic:   Aave markets in which the aToken has different decimals than the underlying. While this is not the case for any aToken currently deployed, Aave does not guarantee that this will be the case in the future.   Compound supports fee-taking tokens. If such a market would be integrated into Spool V2, it could be  problematic  as  the  CompoundV2Strategy._depositToCompoundProtocol()  does  not account for the return value of Compound's mint() function.   Compound's  cETH  market  is  unsupported  due  to  it  requiring  support  for  native  ETH  and  hence  having a different interface than other cTokens.  Spool - Spool V2 -   46  Version2NoteVersion1NoteVersion1NoteVersion1NoteVersion1                  \f8.14   Value of the alUSD Strategy's Metapool LP Token Overvalued  The  Curve  metapool  that  is  used  in  the  ConvexAlusdStrategy  allows  to  determine  the  value  of  LP tokens,  function calc_withdraw_one_coin(). This is used in the strategy to determine the value of one token which is then scaled up by the actual LP token amount.  is  withdrawn,  with   the  2  underlying   if  only  one  of   tokens   the   The function, however, does not linearly scale with the amount of LP tokens due to possible slippage loss with higher amounts. The LP tokens are therefore overvalued.  Spool - Spool V2 -   47  NoteVersion1  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Failing to Untrack Offers of Cancelled",
        "body": " Auctions  RemoveOffers can untrack offers when the auction has not started yet or when it has been cancelled for withdrawal. Redeem can only untrack offers when repo tokens can be redeemed and at least one repo token is in the contract. Sweep can only untrack offers if the auction has completed and if the balance of repo tokens is zero.  If the auction has been cancelled, offers cannot be untracked. While action sweep can be used to return the purchase tokens to the vault, it does not untrack the offer. Ultimately, that may lead to increased gas consumption.  CS-SUL14-001  Risk accepted:  Avantgarde Finance replied:  After consultation with the Term Finance team, this risk is accepted since (1) there is no way to observe cancelled auctions on-chain, (2) cancellations are rare (has not occurred on mainnet yet), and (3) the worst case is gas cost bloat (i.e., not security or correctness)  Avantgarde Finance - Sulu Extensions XIV -   11  SecurityDesignCorrectnessCriticalHighMediumLowRiskAcceptedDesignLowVersion1RiskAccepted             \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings   Double Tracking Term Contracts, Inflation of EP Valuation   -Severity Findings   Term EP Incorrect Loan Value   -Severity Findings   Delta Is Not Applied on Current State   Informational Findings  Inconsistent Array Lengths for Term Finance EP   0  1  1  1  1  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Double Tracking Term Contracts, Inflation of",
        "body": " EP Valuation  CS-SUL14-005  The  AddOrUpdateOffers  action  in  the  Term  Finance  EP  is  responsible  for  publishing  new  offers  or updating existing ones. When this action is called for a term auction without any tracked offers and with an empty \"submittedOfferIds\" parameter (represented as empty bytes32[]), no checks are done, the term auction  is  simply  added  to  the  array  termAuctions.  This  process  can  be  repeated  multiple  times, essentially pushing the same term auction address into the termAuctions array on each call.  Afterwards actual offers can be added for this termAuction.  getManagedAssets() iterates through the array of tracked \"termAuctions\" and assesses the individual offers. It depends on the assumption that the \"termAuction\" contract exists in the array only once. Due to the  repetitive  presence  of  the  same  \"termAuction\"  address  in  the  array,  the  same  offers  are  counted multiple times. As a result, this leads to an inaccurate and inflated valuation for the external position.  This could be abused by a malicious manager to inflate the positions valuation.    It  is  now  ensured  that  the  submitted  offer  IDs  is  not  empty.  As  a  consequence,  at  least  one  ID  is published to Term Finance. Hence, no term contract can be added without having at least one offer ID.  Avantgarde Finance - Sulu Extensions XIV -   12  CriticalHighCodeCorrectedMediumCodeCorrectedLowCodeCorrectedCodeCorrectedSecurityHighVersion1CodeCorrected           \f6.2   Term EP Incorrect Loan Value  In  getManagedAssets(),  __getLoanValue()  is  used  to  calculate  the  value  of  a  loan.  Before maturity  of  a  loan,  the  valuation  of  the  offers  may  be  inaccurate.  Namely,  a  multiplication  with redemptionValue() is missing. Hence, the repo tokens are treated as 1:1 to the underlying during the lifespan of a loan. Once expiry has been reached, redemptionValue() is taken into account (this is in line with what the tokens may be redeemed for).  CS-SUL14-002  As a consequence, the value per offer will evolve as follows:  1. Before auction completion: offer.amount.  2. Right  after  auction  completion  offer.amount  /  redemptionValue  (assuming  the  auction completion happened right at the term start. Note that value is the combination of the formulas of how many repo tokens Term Finance mints and how Enzyme valuates them - resulting in a function based on the offer's amount).  3. Linear  increase  for  the  principal  amount  computed  in  2.  over  time  according  to  interest  rate (offer.amount/redemptionValue*(1+clearingPrice*timePassedSoFar)  -  again  this formula  is  a  combination  of  formulas  to  result  in  a  formula  based  on  the  initial  offered  amount). Right before the end of the term, the value should be roughly what 4. is as nearly no time needs to pass.  4. offer.amount * (1+clearingPrice*totalTime)  To summarize, during the life time the loan value is not scaled by redemptionValue() which will lead to an undervaluation of the position. It is best visible at the borders of the lifespan of a loan where the value suddenly jumps to lower/higher values.    The code now multiplies with redemptionValue() where the multiplication was missing.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Delta Is Not Applied on Current State",
        "body": "  CS-SUL14-003  When adding an offer or updating it's amount, the delta may be applied to outdated values, leading to potentially undetected decreases. Consider the following example:  1. An offer submission is created with a delta of 100 (assume the offer ID will be X). That will lead to  an offered amount of 100 for the submission.  2. The offer at X is updated with an offer submission with a delta of 50. Since the submission of 1. has not  been  published,  this  computation  will  work  on  \"outdated\"  values.  Namely,  this  will  lead  to  an offered amount of 50.  3. The changes applied on the corresponding Term contract. Ultimately, one offer will be present with  X having 50 tokens offered.  4. As a consequence, 50 tokens are left in the contract and not swept (no decrease detected).  Note that tokens could unnecessarily be left in the EP.  Avantgarde Finance - Sulu Extensions XIV -   13  CorrectnessMediumVersion1CodeCorrectedDesignLowVersion1CodeCorrected              \f  The code has been adjusted. In case the offer IDs returned by the term auciton offer locker contract are not unique in the array, the execution reverts. Hence, the scenario of modifying two times the same offer ID in one go is not allowed anymore.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Inconsistent Array Lengths for Term Finance",
        "body": " EP  The _actionArgs of action AddOrUpdateOffers consists of three arrays that should have the same length.  However,  that  is  not  enforced  and,  hence,  unexpected  behaviour  could  occur.  Namely,  if  the amounts have a length greater than the offer IDs, the parser will compute a too high amount of funds to be  transferred  to  the  EP.  The  price  hashes  could  also  have  a  length  greater  than  the  offer  IDs  which results in some price hashes not being used (unspecified behaviour).  CS-SUL14-004    It is now validated that the arrays have the same length.  Avantgarde Finance - Sulu Extensions XIV -   14  InformationalVersion1CodeCorrected      \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Jump in Value at Auction Completion",
        "body": "  An auction could be completed after the term start. As a consequence, once the auction is completed, the value of the EP may jump from the constant value of the offered amounts to a value that includes some interest.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   TermFinance: Permissionless Redemption",
        "body": "  calling After  maturity,  TermRepoServicer.redeemTermRepoTokens().  Resulting  int  the  external  position  receiving  the purchase token. Using action Sweep, these tokens can be returned to the vault.  redemption   anyone   tokens   trigger   repo   can   the   by   of   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   ZeroEx V4 OTC Order Type Incompatible With",
        "body": " GasRelayer  In ZeroEx v4, OTC orders include a field tx.origin which must match the actual tx.origin of the execution. This verification ensures that only the authorized party can execute the order. Executing an order through the adapter, this is typically the fund manager (the caller of callOnExtension).  Consequently the GasRelayer is unusable in this scenario.  Avantgarde Finance - Sulu Extensions XIV -   15  NoteVersion1NoteVersion1NoteVersion1          \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Skim in _Free()",
        "body": "  0  0  0  3  For  End.free()  to  be  successful,  the  proxy's  art  must  be  zero.  However,  the  following  code  of DssProxyActionsEnd._free() does not strictly enforce that.  function _free(     address end,     uint256 cdp ) internal returns (uint256 ink) {     bytes32 ilk = manager.ilks(cdp);     address urn = manager.urns(cdp);     uint256 art;     (ink, art) = vat.urns(ilk, urn);     // If CDP still has debt, it needs to be paid     if (art > 0) {         EndLike(end).skim(ilk, urn);         (ink,) = vat.urns(ilk, urn);     }     // Approves the manager to transfer the position to the proxy's address in the vat     if (vat.can(address(this), address(manager)) == 0) {         vat.hope(address(manager));     }     // Transfers position from CDP to the proxy address     manager.quit(cdp, address(this));     // Frees the position and recovers the collateral in the vat registry     EndLike(end).free(ilk); }  First,  in  case  that  art  is  non-zero,  end.skim()  is  executed  on  the  urnproxy.  Next,  the  position  is transferred  to  the  proxy.  Note  that  the  proxy  could  have  non-zero  art.  Hence,  the  call  end.free() which frees the collateral of its msg.sender and requires that art is zero could revert.    MakerDAO - DSSProxyActions -   12  CriticalHighMediumLowCodeCorrectedCodeCorrectedCodeCorrectedDesignLowVersion1CodeCorrected        \fNow,  skim()  is  called  for  the  proxy  and  after  the  CDP  has  been  transferred  from  the  urn.  Thus,  it  is enforced that art will be zero.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Unused Function _sub()",
        "body": "  The internal function _sub is never used.    The unused function was removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Use Defined Constant",
        "body": "  Contract Common defines:  uint256 constant RAY = 10 ** 27;  Instead of using the constant, function _toRad has this value hardcoded:  function _toRad(uint256 wad) internal pure returns (uint256 rad) {     rad = _mul(wad, 10 ** 27); }    This function has been removed in the final version of the code reviewed.  MakerDAO - DSSProxyActions -   13  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Dust Amount of DAI to Be Drawn Leads to",
        "body": " Revert  There is a known issue in functions that use _getDrawDart(): In case the additional amount of DAI to be drawn leads to a dusty urn, the transaction reverts. This is a known edge case.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   dai Shadowed",
        "body": "  Contract Common defines the immutable dai. The internal functions _getDrawDart, _getWipeDart and _getWipeAllWad each define a local uint256 dai which consequently shadows the immutable.  In    the variables in the functions have been renamed.  MakerDAO - DSSProxyActions -   14  NoteVersion1NoteVersion1Version2      \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Incorrect Liquidity Decrease",
        "body": "  PoolCollection._calcTargetTradingLiquidity  decreases  the  BNT  trading  liquidity  if  the current funding of a certain pool is greater than its funding limit. This is done in a way that could possibly reset the pool:  uint256 excessFunding = currentFunding - fundingLimit; targetBNTTradingLiquidity = MathEx.subMax0(liquidity.bntTradingLiquidity, excessFunding);  Consider the following example:   The funding limit is 40,000 BNT.   The current funding of the pool is 40,000 BNT.   bntTradingLiquidity is 20,000 BNT (for example after the value of BNT to the corresponding  token has quadrupled).   The funding limit is now lowered to 20,000 BNT by governance.   bntTradingLiquidity is now set to 0 and the pool is reset on the next deposit.  Bancor - Bancor v3 -   13  SecurityDesignCorrectnessCriticalHighMediumRiskAcceptedRiskAcceptedLowAcknowledgedRiskAcceptedCodePartiallyCorrectedCodePartiallyCorrectedRiskAcceptedRiskAcceptedDesignMediumVersion2RiskAccepted             \fRisk accepted  Bancor plans to fix this issue in a future version and accepts the risk for now.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Missing Slippage Protection",
        "body": "  The following functions do not guarantee any slippage protection for users and are thus susceptible for front-running attacks:   BancorPortal._uniV2RemoveLiquidity   functions  removeLiqudity  and removeLiquidityETH  of  UniswapV2Router02  with  1  wei  slippage  protection  at  all circumstances.  calls   the    BancorV1Migration.migratePoolTokens   calls  removeLiquidity  StandardPoolConverter with 1 wei slippage protection at all circumstances.  in  Bancor   v1's  Risk accepted:  The client accepts the risk, stating the following:  Similar to how liquidity removal is processed on these 3rd party protocols, it is assumed that users will migrate their liquidity immediately and will be prompted with its results.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   Missing Getter for Average Rates",
        "body": "  The function PoolCoollection.poolData is commented as follows:  there  is  no  guarantee  that  this  function  will  remain  forward  compatible,  so  relying  on  it  should  be avoided and instead, rely on specific getters from the IPoolCollection interface  This  indicates  that  all  data  from  the  struct  that  is  returned  by  this  function  is  also  available  via independent getters. There is, however, no getter function available that returns the AverageRates.  Acknowledged  Bancor acknowledged the issue and plans to fix it in a future version.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.4   Fake Pool Token Migration",
        "body": "  BancorV1Migration.migratePoolTokens does not check if the given pool token is registered in the ContractRegistry. For this reason, an attacker could call the function with a fake pool token contract that returns a fake StandardPoolConverter:  IBancorConverterV1 converter = IBancorConverterV1(payable(poolToken.owner()));  Bancor - Bancor v3 -   14  SecurityMediumVersion1RiskAcceptedDesignLowVersion2AcknowledgedSecurityLowVersion1RiskAccepted                        \fThis converter can then in turn return reserve amounts of tokens that do not exist:  uint256[] memory reserveAmounts = converter.removeLiquidity(amount, reserveTokens, minReturnAmounts);  If the BancorV1Migration contract holds only tokens for some reason, these tokens can then be sent to  token  balances  before  calling converter.removeLiquidity.  the  contract  does  not  check   the  attacker  as   its   Risk accepted:  The client accepts the risk noting that the contract is not supposed to receive any tokens.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.5   Gas Savings",
        "body": "  The following list contains suggestions on how the gas consumption of Bancor v3 can be improved:   The fields of MigrationResult in BancorPortal can be rearranged to achieve tighter packing.   BancorNetwork.addPoolCollection  loads  the  latest  pool  collection  from  storage  then  calls  _setLatestPoolCollection which loads the same pool collection from storage again.   BancorNetwork.createPools loads the same pool collection on each iteration from storage.   BancorNetwork._depositBNTFor  transfers  BNT  to  the  BNTPool  which  then  burns  them.  The  tokens could be burned by BancorNetwork instead.   BancorNetwork.withdraw   to BancorNetwork. _withdrawBNT then approves BNTPool for the tokens and transfers the tokens to BNTPool. The tokens could be directly transferred from PendingWithdrawals to BNTPool.  PendingWithdrawal   transfers   tokens   from   pool    BancorNetwork._withdrawBNT transfers vBNT from the provider to BNTPool which then burns  them. The tokens could be burned directly from the provider's address.   BancorNetwork.withdraw   to BancorNetwork. _withdrawBaseToken then approves PoolCollection for the tokens which burns them. The tokens could be directly burned from PendingWithdrawals.  PendingWithdrawal   transfers   tokens   from   pool    Some  or  all  fields  in  NetworkSettings  could  be  immutable  and  updated  via  proxy  upgrade,  depending on how frequently they are updated and loaded.   Many  call  chains  unnecessarily  validate   than  once.  For  example, BancorNetwork.initWithdrawal  validates  the  pool  token  address  and  amount,  then  calls PendingWithdrawals.initWithdrawal  which  performs  the  same  validations  again  even though it can only be called by the BancorNetwork contract.  input  data  more    PoolCollection.depositFor  loads  data.liquidity.stakedBalance  from  storage  and then loads the whole data.liquidity struct from storage with no change of the data in-between.   PoolCollection.depositFor  reads  data.liquidity  from  storage,  updates  the  fields  on  storage and then loads the struct again two times from storage.   PoolMigrator.migratePool  retrieves  the  target  pool  collection  of  a  given  pool  by  calling BancorNetwork.latestPoolCollection.  It  then  calls  PoolCollection.migratePoolOut which performs the same call to check if the given target pool collection is valid.   PoolCollection._poolWithdrawalAmounts takes the Pool struct as memory copy. Since not all  words  are  accessed  and  the  function  is  only  called  with  storage  pointers,  the  data  argument could be a storage pointer and the necessary fields could be cached inside the function.  Bancor - Bancor v3 -   15  DesignLowVersion1CodePartiallyCorrected        \f PoolCollection._executeWithdrawal loads stakedBalance from storage even though it is  already cached in prevLiquidity   PoolCollection._updateTradingLiquidity calls _resetTradingLiquidity which loads liquidity.bntTradingLiquidity  from  storage  even  though  an  overloaded  version  of  the function  exists  which  takes  that  variable  as  an  argument  and  there  is  a  cached  version  of liquidity available.   PoolCollection._performTrade  loads  the  liquidity  struct  from  storage  even  though  the  values are already present in the TradeIntermediateResult argument.   PoolMigrator._migrateFromV1  translates  the  Pool  struct  from  the  old  version  to  the  new  version. Since the structs are identical, this is not necessary.   PoolToken._decimals can be immutable.  pools    Because   address, PoolTokenFactory.createPoolToken could take the override variables as arguments instead of using storage variables.  added   admin   only   can   the   be   by    AutoCompoundingRewards.terminateProgram loads ProgramData from storage to check if the given program exists. As the pool is later removed from _pools, the call would revert anyways if the the pool program did not exist.  In  AutoCompoundingRewards  some  ProgramData struct from storage even though not all words are required.  (e.g.  enableProgram)   functions   load   the  whole  In StandardRewards some functions (e.g. createProgram) load the whole ProgramData struct from storage even though not all words are required.   The fields _bntPool, _pendingWithdrawals and __poolMigrator in BancorNetwork could be  immutable  if  they  are  set  up  either  directly  in  the  constructor  of  BancorNetwork  or  with pre-known addresses.  In BancorNetwork.flashloan, the user could pay the loaned amount directly back to the master vault.   During  a  withdrawal  of  base   in PendingWithdrawals instead of burning a part of them, sending the rest to BancorNetwork and finally burning them in PoolCollection.  tokens  (not  BNT),  all  pool   tokens  could  be  burned   Code partially corrected:  The client has addressed some of the suggestions. Additionally, some are no longer relevant due to other code changes.   Corrected: The fields of MigrationResult in BancorPortal are now tightly packed.   Corrected: latestPoolCollection has been completely removed from the code.   Corrected: BancorNetwork.createPools takes the respective pool collection as argument.   Not corrected: BancorNetwork._depositBNTFor still transfers BNT to the BNTPool which then  burns them.   Corrected:   BancorNetwork._withdrawBNT   directly   transfers   pool   tokens   from  PendingWithdrawal to BNTPool.   Not  corrected:  BancorNetwork._withdrawBNT  still  transfers  vBNT  from  the  provider  to  BNTPool which then burns them.   Partially corrected: BancorNetwork._withdrawBaseToken directly transfers pool tokens from  PendingWithdrawal to PoolCollection.   Not corrected: All fields in NetworkSettings are still storage variables.  Bancor - Bancor v3 -   16     \f Not corrected: There are still many call chains that validate input multiple times.   Not   corrected:   PoolCollection.depositFor   still   redundantly   loads  data.liquidity.stakedBalance from storage.   Not  corrected:  PoolCollection.depositFor  still  redundantly   loads  data.liquidity  multiple times from storage.   Corrected: latestPoolCollection has been completely removed from the code.   Corrected: PoolCollection._poolWithdrawalAmounts takes only relevant and cached data  as input.   Not  corrected:  PoolCollection._executeWithdrawal  still  loads  stakedBalance  from  storage.   Corrected:  PoolCollection._updateTradingLiquidity  uses  the  overloaded  version  of  _resetTradingLiquidity.   Not  corrected:  PoolCollection._performTrade  still  loads  the  liquidity  struct  from  storage.   Not   corrected:   PoolMigrator._migrateFromV1   has   been   renamed   to  PoolMigrator._migrateFromV5 but still unnecessarily translates equal structs.   Not corrected: PoolToken._decimals is still a storage variable.   Not corrected: PoolTokenFactory.createPoolToken still uses storage for override variables.   Not  corrected:  AutoCompoundingRewards.terminateProgram  still  redundantly  checks  for  pool existance.   Not  corrected:  In  AutoCompoundingRewards  some  functions  (e.g.  pauseProgram)  still  load  more data from storage than required.   Not corrected: In StandardRewards some functions (e.g. _programExists) still load more data  from storage than required.   Not  corrected:  The  fields  _bntPool,  _pendingWithdrawals  and  __poolMigrator  are  still  stored in storage.   Not  corrected:  In  BancorNetwork.flashloan,  the  loaned  amount  is  still  paid  back  to  the  contract and then sent to the master vault.   Corrected: PendingWithdrawals.completeWithdrawal does not burn tokens anymore.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.6   Inconsistent Reentrancy Protection",
        "body": "   AutoCompoundingRewards.createProgram  has  a  reentrancy  protection,  while  the  functions  terminateProgram and enableProgram do not.   BancorNetwork.withdrawNetworkFees  does  not  have  reentrancy  protection,  while  other  functions that are restricted to callers with certain roles have.  Code partially corrected  function Although  all  mentioned  AutoCompoundingRewards.setAutoProcessRewardsCount  lacks  reentrancy  protection  while  all other functions restricted to the admin are protected.  functions  are  now  protected  against  reentrancy,   the  new   Bancor - Bancor v3 -   17  DesignLowVersion1CodePartiallyCorrected          \f5.7   Rounding Error Can Lock Tokens  When  creating  a  StandardRewards  program,  both  the  reward  rate  and  the  remaining  rewards  are computed as follows:  uint256 rewardRate = totalRewards / (endTime - startTime); _programs[id] = ProgramData({     ...     rewardRate: rewardRate,     remainingRewards: rewardRate * (endTime - startTime) });  Depending  on  the  token's  number  of  decimals  and  the  duration  of  the  program,  remainingRewards can be smaller than totalRewards due to the divide-then-multiply scheme. In practice, this means that in  such  cases,  totalRewards  -  remainingRewards  tokens  won't  be  distributed  and  will  never  be deduced  from  _unclaimedRewards.  This  results  in  the  tokens  being  locked  in  the  contract  and  not being able to be used for future programs.  Risk accepted:  The client accepts the risk, stating the following:  The  amount  of  tokens  which  can  be  locked  due  to  a  rounding  error  is  negligible.  We  are  also considering revamping the whole mechanism, which will also affect this code.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.8   BNTPool.renounceFunding Division by 0",
        "body": "  In  PoolCollection._executeWithdrawal,  if  the  protocol  has  to  renounce  BNT  funding  and  this results  in  the  BNT  staked  balance  being  reset  to  0,  but  the  BNT  trading  liquidity  is  still  greater  than  0, _resetTradingLiquidity  is  called  which  tries  to  renounce  BNT  funding  again.  As  the  staked balance has already been set to 0, this second call to BNTPool.renounceFunding will now revert due to a division by 0.  Consider the following case:   User A deposits TKN liquidity into an empty pool.   Trading is enabled.   User B trades a certain amount of TKN for BNT.   User A now withdraws all his supplied TKN.   The withdrawal fails due to the mentioned problem.  Risk accepted:  The client accepts the risk, stating the following:  This  is  a  rare  case  that  we  don\u2019t  expect  to  happen  in  practice,  since  trading  can\u2019t  be  enabled immediately and usually involves many depositors. In any case, we will consider addressing this in the future as well.  Bancor - Bancor v3 -   18  DesignLowVersion1RiskAcceptedCorrectnessLowVersion1RiskAccepted                \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings   Oracle Manipulation   -Severity Findings   BNT Burned Twice    Locked vBNT    Pool Denial of Service   -Severity Findings  0  1  3  18   BNT Deposit Allows msg.value > 0    Consistency Issues Between Implementation, Excel Demonstration and Documentation Regarding  the Withdrawal    Different Programs Can Share the Same Reward    Emission of Events With Arbitrary Amounts   Impossible to Migrate ETH Position   Inconsistent Naming   Inconsistent Use of ERC20.transfer    Misleading Comment    Misleading Comment in PoolCollection.enableTrading    Problematic Loop Continuation During Pool Migration    Undocumented Behavior    Unused Imports / Variables    Wrong Function Name in BancorPortal    Wrong Interface    AutoCompoundingRewards Can Burn More Pool Tokens Than Expected    BNTPool.renounceFunding Fails on Insufficient BNT Pool Token Balance    ERC20Permit Handling    MathEx.reducedFraction Can Turn Denominator to 0   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Oracle Manipulation",
        "body": "  To  prevent  manipulation,  Bancor  v3  calculates  a  moving  average  of  each  pool's  spot  price  that  is adjusted  once  per  block.  Critical  actions  like  the  increase  of  trading  liquidity  or  withdrawal  of  funds  Bancor - Bancor v3 -   19  CriticalHighCodeCorrectedMediumCodeCorrectedCodeCorrectedCodeCorrectedLowCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSecurityHighVersion1CodeCorrected           \frequires  the  spot  rate  of  a  pool  to  not  diverge  from  this  moving  average  by  more  than  a  certain percentage.  Since the moving average is calculated as an arithmetic mean, it is subject to manipulation. Consider the following scenario:   An attacker funds a pool with some tokens with a spot rate of 1 BNT : 1 token.   They perform a trade from BNT to the token by providing an amount of BNT that changes the spot  rate to 10 BNT : 1 token. The average rate is now 2.8 BNT : 1 token.  In the next block, they perform another trade from token to BNT to bring the spot rate back to 2.8 BNT : 1 token.   Since the spot rate now equals the average rate, the attacker can withdraw his supplied tokens.   The  pool  does  not  contain  enough  tokens  to  satisfy  the  withdrawal,  so  the  attacker  gets  compensated in BNT for the outstanding amount.   This compensation is calculated with the average rate of the pool which now is 2.8 BNT to 1 token  instead of the real 1 : 1 rate.   The attacker will receive 2.8 times the amount of BNT he is actually eligible to receive.  The  attacker  is  required  to  split  both  trades  in  2  consecutive  blocks.  In  the  first  block,  they  create  an arbitrage opportunity that can be utilized by an arbitrageur. To make sure, their initial investment will not be lost, they must selfishly mine 2 blocks in a row. This is possible with around 1.5% of the total hashrate of Ethereum. Renting this amount of hashrate is in the realm of possibilities and we estimate that the cost of renting the hashrate and losing out on the reward of the additional mined blocks results in a total cost of ~150.000 USD.  Alternatively, an attacker could try to spam transactions to the Ethereum network in order for their second transaction to be executed before the transactions of any arbitrage bot.  Furthermore, after Ethereum's transition to Proof-of-Stake, the attack becomes simpler: As the attacker now knows when it is their turn for validation, they could submit their first transaction right to the block before. Using Flashbots, the transaction could actually be hidden so that no arbitrage bots would see it before it is included in the block. The next block is then in the hand of the attacker.  While this attack is hard to carry out and requires a lot of capital, it can also create immense losses.    A second moving average for the inverse rate has been introduced. Averages for the rate and the inverse rate are calculated independently which prevents the aforementioned attack. The resulting inverse rate in the example would diverge from the inverse spot rate by ~100%.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   BNT Burned Twice",
        "body": "  Withdrawals  from  PoolCollection  can  result  in  the  burning  of  double  the  amount  of  BNT  than intended. This happens any time a withdrawal occurs that results in the protocol removing BNT from the this  case,  both  amounts.bntProtocolHoldingsDelta.value  and protocol  equity.  amounts.bntTradingLiquidityDelta.value are set to the same value greater than 0, resulting in a  call  to BNTPool.burnFromVault which burns the same amount of BNT again.  to  BNTPool.renounceFunding  which  burns   the  amount  of  BNT  and  a  call   In     Bancor - Bancor v3 -   20  CorrectnessMediumVersion1CodeCorrected         \fboth   If  and amounts.bntTradingLiquidityDelta.value  are  greater  than  0,  only  the  former  value  triggers token burning (via BNTPool.renounceFunding).  amounts.bntTradingLiquidityDelta.value   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Locked vBNT",
        "body": "  the   StandardRewards   In  or depositAndJoinPermitted to deposit underlying tokens and stake the obtained pool tokens in one single transaction. To perform such aggregation, the protocol transfers the tokens from the user to itself and calls BancorNetwork.depositFor to get the pool tokens that will then be used for staking.  depositAndJoin   contracts,   users   can   call   If the token being deposited is BNT, BancorNetwork will send both bnBNT and vBNT to the contract. As there is no handling for vBNT, it will stay locked into the contract, preventing the user to ever withdraw his BNT from the network.    depositAndJoin  now  keeps  the  pool  tokens,  but  sends  vBNT  back  to  the  provider  if  BNT  are deposited.  Additionally,  a  temporary  function  transferProviderVBNT  has  been  added  to  allow distribution of already accumulated vBNT to their owners by the contract admin.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Pool Denial of Service",
        "body": "  The  first  user  to  deposit  into  a  newly  created  pool  can  immediately  burn  his  pool  tokens.  In  this  case, depositing into the pool no longer works, because the following check will revert:  if (poolTokenSupply == 0) {     if (stakedBalance > 0) {         revert InvalidStakedBalance();     } }  A malicious user could create a bot that performs this attack cheaply by instantly depositing 1 wei base tokens into any newly created pool.    New deposits now reset the pool when pool token supply is 0 and staked balance is greater than 0.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   BNT Deposit Allows msg.value > 0",
        "body": "  BancorNetwork.depositFor is payable. While the _depositBaseTokenFor function makes sure that it reverts if the sent token is not equal to ETH and msg.value is greater than 0, the same check is not applied in _depositBNTFor.  Bancor - Bancor v3 -   21  DesignMediumVersion1CodeCorrectedSecurityMediumVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                        \f  _depositBNTFor now reverts if msg.value is greater than 0.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Consistency Issues Between Implementation,",
        "body": " Excel Demonstration and Documentation Regarding the Withdrawal  1. Deviating Calculation of BNT Burned  The  formula  for  BNT  trading  liquidity  to  be  burned  from  the  pool  defined  in  the  excel  spreadsheet renounce nothing method.A11 is deviating from the white paper and the implementation. It seems like the sign in front of B10*E10 needs to be removed.  The documented and implemented formula is:  P =  ax(b + c + e(2 \u2212 n)) (1 \u2212 m)(be + x(b + c \u2212 e(1 \u2212 n)))  The formula used in excel is:  2. Incorrect Denominator  P =  ax(b + c + e(2 \u2212 n)) (1 \u2212 m)(\u2212be + x(b + c \u2212 e(1 \u2212 n)))  The documentation on page 39 has the following formula documented for hmax  supr  hmaxsurp = be(en + m(b + c \u2212 e)) (1 \u2212 m)(b + c \u2212 e(1 \u2212 n))  The formula's denominator is missing the additional term (b+c-e)  Specification changed  Bancor replied the following:  Both issues outlined here were actually typing errors in the spec, while the implementation is correct. The spec was updated.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Different Programs Can Share the Same",
        "body": " Reward  AutoCompoundingRewards ensures that only one program exists for a specific pool at a given time. In practice, this means that the pool tokens allocated for such programs cannot be used by another one.  Bancor - Bancor v3 -   22  CorrectnessLowVersion1Speci\ufb01cationChangedCorrectnessLowVersion1CodeCorrected                          \fSimilarly, using _unclaimedRewards, StandardRewards makes sure that if multiple programs have the same reward token, the external reward vault must contain enough tokens to cover all of them.  However,  if  StandardRewards  and  AutoCompoundingRewards  contain  programs  for  the  same reward token and the address for the _externalRewardsVault is the same in both contracts, correct funding cannot be ensured because both programs only check that there are enough funds in the vault.    StandardRewards  now  only  distributes  BNT  via  minting.  _externalRewardsVault anymore.  It  does  not  access   the  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   Emission of Events With Arbitrary Amounts",
        "body": "  BancorNetwork._initWithdrawal does not check if the supplied pool token address belongs to a pool. An attacker could call the function with a fake pool token that returns a valid pool address:  Token pool = poolToken.reserveToken(); if (!_network.isPoolValid(pool)) {     revert InvalidPool(); }  The contract would then transfer the fake pool tokens from the attacker while the attacker keeps the real pool tokens and emit a WithdrawalInitiated event with arbitrary pool token amounts. While this is not  a  problem  for  the  protocol  itself  and  is  also  not  exploitable  in  the  final  withdrawal,  third  party applications relying on the emitted events could be affected.    _initWithdrawal now correctly checks if the supplied pool token is valid.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   Impossible to Migrate ETH Position",
        "body": "  When  trying  to  migrate  a  Uniswap  or  SushiSwap  position,  if  one  of  the  tokens  is  the  protocol  defined native token address 0xEeeeeEeeeEeEeeEeEeEeeEEEeeeeEeeeeeeeEEeE, the call to the factory to obtain  transaction  will  revert  with the  NoPairForTokens as this custom address is not used in these protocols.  the  pair's  address  will  return   the  address  zero  and   Code corrected  Bancor now interacts with Uniswap and SushiSwap using the WETH address instead of 0xEee...EEeE.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   Inconsistent Naming",
        "body": "  Bancor - Bancor v3 -   23  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \fBancorPortal.migrateSushiSwapV1Position returns a struct with \"Uniswap\" in one of its field's names.    migrateUniswapV2Position and migrateSushiSwapPosition now both return a struct with the name PositionMigration.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.11   Inconsistent Use of ERC20.transfer",
        "body": "  In some cases a normal transfer is used. Some of these occurrences have the comment:  // transfer the tokens to the provider (we aren't using safeTransfer, since the PoolToken is a fully // compliant ERC20 token contract) p.poolToken.transfer(provider, poolTokenAmount)  But the pool token is also transferred with a safe transfer in another case  poolToken.safeTransferFrom(provider, address(_pendingWithdrawals), poolTokenAmount)  The assumption that all tokens behave as expected should be carefully evaluated against gas savings between a normal transfer and a safe transfer.    BancorNetwork._initWithdrawal  now  transfers  the  pool  tokens  using  a  regular  transferFrom call.  Since  all  pool  tokens  are  PoolToken  contracts,  they  revert  on  failure  making  it  safe  to  use  the regular transferFrom function.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.12   Misleading Comment",
        "body": "  _latestPoolCollections in BancorNetwork has the following comment:  a mapping between the last pool collection that was added to the pool collections set and its type  Since the function setLatestPoolCollection allows the governance to set to latest pool collection to any pool collection, the comment is incorrect.  Furthermore, when the the \"latest\" pool collection is set to an older version, multiple pool collections with the same version can be added through addPoolCollection.    The latestPoolCollections mechanism has been completely removed.  Bancor - Bancor v3 -   24  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                  \f6.13   Misleading Comment in  PoolCollection.enableTrading  A comment of PoolCollection.enableTrading states:  if  the  price  of  one  (10**18  wei)  BNT  is  $X  and  the  price  of  one  (10**6  wei)  USDC  is  $Y,  then  the virtual balances should represent a ratio of X to Y*10**12  The explanation is ambiguous and could be misunderstood in a way that both virtual balances must be represented with the same number of decimals.    The addressed documentation has been improved to clarify possible misunderstandings.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.14   Problematic Loop Continuation During Pool",
        "body": " Migration  BancorNetwork.migratePools  checks  if  newPoolCollection  is  equal  to  the  0-address.  In  the current setup this can never happen.  Furthermore,  if  the  PoolMigrator  implementation  changes  for  future  PoolCollection  versions  so that  the  migratePool  function  could  indeed  return  the  0-address,  the  mentioned  check  leads  to  a continuation of the migration loop:  if (newPoolCollection == IPoolCollection(address(0))) {     continue; }  In this case, the pool data of the old pool would be lost and _collectionByPool would point to a pool collection that does not contain the migrated pool anymore.    The  lastPoolCollection  mechanism  has  been  completely  removed  and  migrations  to  new  pools now require the caller to pass an explicit pool collection to the migratePool function.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.15   Undocumented Behavior",
        "body": "  The  trade  functions  in  BancorNetwork  allow  the  user  to  declare  a  beneficiary.  If  the  user  sets  this beneficiary  to  the  0-address,  the  beneficiary  is  replaced  with  the  user's  address.  This  behavior  is  not documented.    Bancor - Bancor v3 -   25  DesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                      \fAll trade functions now explain the mentioned special behavior.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.16   Unused Imports / Variables",
        "body": "  The following types have been imported but not used inside the respective contracts:   BancorNetwork:   WithdrawalRequest   BancorV1Migration:   Upgradeable   BNTPool:   Utils   Fraction   IPoolCollection   Pool   PoolToken   PoolMigrator:   Fraction   AutoCompoundingRewards:   AccessDenied   StandardRewards   AccessDenied  Additionally,  BNTPool  twice,  PoolMigrator  defines  a  private  constant INVALID_POOL_COLLECTION  that  is  not  used  and  StandardRewards  defines  an  unused  error PoolMismatch.  imports  Token     All unused imports and variables have been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.17   Wrong Function Name in BancorPortal",
        "body": "  BancorPortal contains a function migrateSushiSwapV1Position indicating calls to SushiSwap v1 even though the referenced contracts belong to SushiSwap v2.    V1 and V2 strings have been removed from all function, event and variable names related to SushiSwap.  Bancor - Bancor v3 -   26  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                  \f6.18   Wrong Interface  BancorV1Migration.migratePoolTokens  v3's types  IPoolToken interface. While this is not a problem right now, future changes in the interface might create problems here.  legacy  DSToken  addresses  with     BancorV1Migration now uses a separate interface for legacy pool tokens.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.19   AutoCompoundingRewards Can Burn More",
        "body": " Pool Tokens Than Expected  On creation of a program in AutoCompoundingRewards, the caller provides the amount of tokens that should  be  distributed  during  the  lifetime  of  the  program.  Depending  on  the  token  to  be  distributed, createProgram  and PoolCollection.poolTokenAmountToBurn.  Both  functions  use  the  same  formula  to  calculate  the amount of pool tokens that have to be burned in order to distribute the given token amount:  BNTPool.poolTokenAmountToBurn   either   calls   function poolTokenAmountToBurn(uint256 bntAmountToDistribute) external view returns (uint256) {     if (bntAmountToDistribute == 0) {          return 0;      }       uint256 poolTokenSupply = _poolToken.totalSupply();      uint256 val = bntAmountToDistribute * poolTokenSupply;       return          MathEx.mulDivF(              val,              poolTokenSupply,              val + _stakedBalance * (poolTokenSupply - _poolToken.balanceOf(address(this)))          ); }  The formula allows for the burning of high amounts of pool tokens (up to the total), which can become problematic for new deposits as the value of the pool tokens now far exceeds the value of the underlying tokens, potentially leading to large rounding errors for token suppliers. To highlight this problem, consider the following example:   bnBNT total supply is 20000   The protocol holds all bnBNT (i.e. no user has supplied any BNT)  In this case  _stakedBalance * (poolTokenSupply - _poolToken.balanceOf(address(this))  is now 0. The formula is therefore reduced to:  bntAmountToDistribute * poolTokenSupply * poolTokenSupply     / bntAmountToDistribute * poolTokenSupply  Bancor - Bancor v3 -   27  CorrectnessLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected              \fThe amount of tokens to be distributed is now completely factored out of the equation. It will therefore always return poolTokenSupply to be burned, no matter the amount of tokens to distribute.    If the amount of pool tokens to be burnt in a single program exceeds 50% of the total supply, the program is  now  terminated.  This  ensures  that  the  value  of  pool  tokens  does  not  appreciate  too  much  in comparison to the underlying.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.20   BNTPool.renounceFunding Fails on",
        "body": " Insufficient BNT Pool Token Balance  BNTPool.renounceFunding  removes  a  given  amount  of  BNT  and  burns  the  corresponding  pool tokens. Because the pool tokens will be distributed to BNT liquidity providers, there can be circumstances where the protocol does not hold enough pool tokens for a given amount BNT that has to be burned. This will result in reverting transactions.  Consider the following example:  Liquidity  provider  withdrawals  that  exceed  the  amount  of  excess  tokens  in  a  given  pool  require  the protocol  to  decrease  the  liquidity  of  the  pool.  If  the  amount  of  BNT  liquidity  that  must  be  removed  is greater than the amount of BNT pool tokens the protocol holds (because enough users have provided BNT liquidity in exchange for BNT pool tokens), the call will revert.    renounceFunding  now  burns  at  most  the  amount  of  pool  tokens  available  and  updates  the  staked balance accordingly.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.21   ERC20Permit Handling",
        "body": "  The permit function of ERC20Permit tokens is called expecting them to revert if the given signature is incorrect.  While  this  is  the  correct  behavior  according  to  the  EIP  2612  specification,  numerous  token projects  have  shown  that  specifications  are  not  always  adhered  to  completely  (e.g.  the  transfer function in USDT). Therefore, it might be possible that some token project exists that does not revert but rather returns a boolean value on calls to permit.    ``ERC20Permit` support has been completely removed from the project.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.22   MathEx.reducedFraction Can Turn",
        "body": " Denominator to 0  Bancor - Bancor v3 -   28  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                        \fMathEx.reducedFraction  equally  scales  down  two  uint256  values  so  that  the  higher  value  does not exceed a defined maximum. It computes the factor by which the values have to be divided with the following code:  uint256 scale = Math.ceilDiv(Math.max(fraction.n, fraction.d), max);  In the case that fraction.d is smaller than scale, the fraction's denominator will be set to 0 causing undefined behavior. Since the function is always used with a max value of type(uint112).max, this can  only  happen  in  edge  cases  where  the  numerator  of  the  fraction  is  type(uint112).max  times greater than the denominator.  Code Corrected:  reducedFraction now reverts if the denominator is set to 0.  Bancor - Bancor v3 -   29  \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   32 Bit Timestamps in Storage",
        "body": "  Some contracts (e.g. AutoCompoundingRewards) keep timestamps with the type uint32 in storage. This will render the contracts unusable and make them hard to upgrade after the year 2106.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Impermanent Loss Protection Can Be",
        "body": " Disabled  PoolCollection.enableProtection  can  be  called  by  Bancor  v3's  governance  to  disable Impermanent  Loss  protection.  This  can  result  in  liquidity  providers  not  being  able  to  withdraw  the  full amount of tokens they are owed. In fact, LPs can end up with less tokens than originally provided and without any compensation.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Implementations Not Initialized",
        "body": "  Bancor deploys some if its contracts using a proxy pattern. However, the deployed implementations are not initialized by default. This is also evident on the current live version of the protocol. While this is not a problem  currently,  later  changes  might  introduce  DELEGATECALL  op-codes.  In  this  case,  a  malicious user  could  claim  ownership  of  the  contract  and  generate  a  DELEGATECALL  to  a  contract  containing  a SELFDESTRUCT op-code, causing a denial of service.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   Inconsistent Interface",
        "body": "  PoolCollection  defines  a  function  enableDepositing  with  a  boolean  argument  to  determine  if depositing  should  be  enabled  or  disabled.  On  the  contrary,  it  defines  the  distinct  functions enableTrading and disableTrading.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   Liquidity Growth Not Restricted",
        "body": "  When a pool gets enabled for trading, the starting liquidity is set to a pre-determined amount of BNT and not  set  to  the  full  amount  possible.  On  certain  actions,  the  trading  liquidity  is  allowed  to  grow  by  the LIQUIDITY_GROWTH_FACTOR  liquidity  by  calling  factor.  However,  anyone  can  grow   the   Bancor - Bancor v3 -   30  NoteVersion1NoteVersion2NoteVersion1NoteVersion1NoteVersion1                  \fBancorNetwork.depositFor  with  the  minimum  amount  of  1  wei  token.  Thus,  this  mechanism  only protects against accidents and not against deliberate manipulation.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.6   Missing Access Control in postUpgrade",
        "body": "  postUpgrade  has  no  access  restrictions.  Using  it  in  an  upgrade  needs  to  happen  in  one  transaction  if frontrunning should be mitigated. Bancor has a deploy script that will automatically call this function in the upgrade transaction. But this is not guaranteed and might fail. We cannot see a case that it should be callable by everyone.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.7   More vBNt Than bnBNT Obtainable",
        "body": "  If the protocol does not have any bnBNT, it should be impossible to deposit BNT and hence obtain vBNT. However, in this case, a user can first send some bnBNT to the BNTPool and then deposit some BNT to obtain both the pre-owned bnBNT and newly minted vBNT. Although the BNT the user just deposited is not  withdrawable  anymore  as  he  does  no  longer  own  the  corresponding  bnBNT,  he  is  able  to  obtain additional vBNT at this cost.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.8   No Recovery of Accidental Token Transfers",
        "body": " Possible  In  case  an  ERC20  token  other  than  the  BNT  or  one  of  the  base  tokens  is  sent  to  the  contract,  then  it cannot  be  recovered.  Among  other  reasons,  this  might  happen  due  to  airdrops  based  on  the  base tokens.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.9   Potential External Contract Manipulation",
        "body": "  functions   The  and BancorNetworkInfo.withdrawalAmounts  are  subject  to  manipulation  by  reentrancy.  If  the mentioned  functions  are  used  in  any  way  to  alter  the  state  of  an  external  contract  (for  example  an investment protocol that supplies liquidity to Bancor v3), the values they return can be manipulated by calling the external contract in the onFlashLoan callback of BancorNetwork.flashloan.  PoolCollection.withdrawalAmounts   This is possible because of the following call in PoolCollection._poolWithdrawalAmounts:  int256 baseTokenExcessAmount = pool.balanceOf(address(_masterVault)) -     data.liquidity.baseTokenTradingLiquidity;  onFlashLoan  will  be  called  after  the  balance  of  _masterVault  has  already  been  reduced  by  the flashloan amount.  Bancor - Bancor v3 -   31  NoteVersion1NoteVersion1NoteVersion1NoteVersion1                  \f7.10   Redundant Role Management  Most  contracts  are  upgradable.  Hence,  they  have  their  own  admin  account.  There  is  no  central management checking these roles are set accordingly. An admin change needs to be done individually and redundantly.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.11   Unequal Token Burning",
        "body": "  Withdrawal  of  supplied  tokens  is  subject  to  a  7-day  waiting  period.  In  this  period,  newly  generated interest is not accrued to the withdrawing user. This means, that after 7-days, the pool tokens sent to the PendingWithdrawals  contract  are  worth  slightly  more  than  the  amount  of  tokens  the  user  actually receives. Because PoolCollection completely burns all of these pool tokens, while BNTPool keeps them, the outcome of a withdrawal of BNT differs to withdrawals of other tokens. Consider the following 2 examples:  BNT:   totalSupply of bnBNT is 100.   _stakedBalance in the BNTPool is 100.   A user initiates a withdrawal with 50 bnBNT, allowing them to withdraw 50 BNT after 7 days.   After 7 days, 100% interest has accrued and the new _stakedBalance is now 200.   The  user  withdraws  their  50  BNT  (which  get  minted)  and  the  50  bnBNT  are  repossessed  by  BNTPool.   _stakedBalance is now 200.   totalSupply is now 100.  TKN:   totalSupply of bnTKN is 100.   _stakedBalance in the PoolCollection is 100.   A user initiates a withdrawal with 50 bnTKN, allowing them to withdraw 50 TKN after 7 days.   After 7 days, 100% interest has accrued and the new _stakedBalance is now 200.   The user withdraws their 50 TKN and the 50 bnTKN are burned.   _stakedBalance is now 150.   totalSupply is now 50.  Both examples illustrate the same scenario but in the BNT case, a pool token is worth 2 BNT in the end, while in the TKN case, a pool token is now worth 3 TKN.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.12   Unsupported Tokens",
        "body": "  Not all ERC20 tokens can act as base tokens for Bancor v3 contracts. In particular, the following tokens are not supported:  Bancor - Bancor v3 -   32  NoteVersion1NoteVersion2NoteVersion1          \f Tokens that return metadata fields like name and symbol encoded as bytes32 instead of string (e.g.  MKR).  PoolTokenFactory.createPoolToken  will  fail  to  create  a  pool  token  for  these tokens.   Tokens  that  take  a  fee  on  transfer  (e.g.  PAXG  and  possibly  USDT).  A  deposit  will  use  the  full  amount to mint pool tokens while the contract has received a lower amount.   Tokens that have a rebasing mechanism (e.g. AAVE's aToken). User's staked balances will not be  updated accordingly.  Additionally, the following tokens could break the protocol in the future:   Tokens with blacklists (e.g. USDT, USDC).   Upgradeable tokens that add one of the mentioned mechanisms in the future.   Pausable tokens (e.g. BNB).  Bancor - Bancor v3 -   33  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Precision Loss in rewardRate Calculation",
        "body": "  The  calculation  of  the  rewardRate  causes  a  potentially  harmful  loss  of  precision.  The  default rewardsDuration  denominator  (1  week  reward  duration)  loses  up  to  604800  wei  of  precision  every time notifyRewardAmount() is called, in the following calculation:  CS-MET-001  rewardRate = reward / rewardsDuration;  and  rewardRate = (reward + leftover) / rewardsDuration;  The amount lost due to rounding has been deposited in the contract, but the internal accounting loses track of it, rendering it unclaimable.  If  rewardsToken  is  a  token  with  a  high  value  per  wei,  the  loss  can  be  significant.  For  example,  if rewardsToken  is  USDC,  which  has  6  decimals,  the  loss  can  be  of  up  to  $  0.6048  every  time notifyRewardAmount() is called. If the token is WBTC, which has 8 decimals but much higher value per  wei,  is  computed.  Since notifyRewardAmount()  can  be  called  every  12  seconds  through  VestedRewardsDistribution,  the rounding amount can be lost up to 50400 times per week.  to  $  181  every   the  rewardRate   is  up   time   loss   the   For tokens with a higher number of decimals and a low value per wei, for example DAI or WETH, the loss is less significant. It amounts to a maximum of $ 0.00006 per week for WETH and $ 3e-18 per week for DAI. The maximum weekly loss can be calculated as follows:  weeklyLoss = rewardsDuration * tokenValuePerWei * blocksPerWeek  Risk accepted:  Maker states:  Maker - EndGame Toolkit -   10  DesignCriticalHighMediumLowRiskAcceptedDesignLowVersion1RiskAccepted         \fRisk accepted. We are aware of the issue with precision loss, however we wanted to avoid making changes to the original code as much as possible. The StakingRewards contract in this context will only ever handle tokens with 18 decimals (DAI, MKR, SubDAO tokens, NewStable \u2013 Dai equivalent, NewGov \u2013 MKR equivalent). If we take MKR as an example, its all-time high price was just short of 6,300 USD. Let\u2019s extrapolate its value imagining it could grow 100x for the duration of the staking rewards program. Using the formula you provided, we would have:  weeklyLoss  = rewardsDuration * tokenValuePerWei * blocksPerWeek             = 604800 * 50400 * (630000 * 10^(-18))             = 0.0192036096  Even in this extreme scenario, weekly losses would amount to less than 0.02 USD, which is acceptable for us.  Maker - EndGame Toolkit -   11  \f6   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Typo in Documentation",
        "body": "  In  the  NatSpec  for  the  VestedRewardsDistribution  contract  at  line  23  RewardsDistribution  is misspelled.  CS-MET-002  The typo has been corrected.  Maker - EndGame Toolkit -   12  InformationalVersion1  \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Ability to Modify name & symbol",
        "body": "   introduces functionality for the priviledge role to update the token parameter name and symbol. Note that is unusual for ERC20 tokens and must be done with care. Some downstream applications or smart contracts may not be designed to accommodate such changes.  Consider these illustrative examples:   Upon deployment the name of Curve pools is set using the traded token names.   The  representative  token  deployed  by  third-party  bridges  to  other  chains  is  often  based  on  the  original token's name and symbol.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Rewards in StakingRewards Might Take",
        "body": " Longer to Vest Than Expected  Rewards added to StakingRewards could be expected to be payed out to stakers in rewardsDuration time,  which  is  initially  set  to  7  days.  However,  every  time  notifyRewardAmount()  is  called,  a  new rewardRate  the  next the  vesting  of  rewardDuration.  the  remaining  amount  over   is  computed  prolonging   As a simple example, assume we are distributing 1000 DAI over one week, then the rewardRate will be rewardRate  =  1000  *  10**18  /  rewardDuration.  If  after  3.5  days  have  passed  we  call notifyRewardAmount(), adding a 0 reward, the new rewardRate is computed as  rewardRate = (reward + leftover) / rewardsDuration;  which  will  amount  to  rewardRate  =  500  *  10**18  /  rewardDuration.  Moreover,  the from periodFinish  initialTime  + rewardDuration.  Overall,  the  reward  distribution  will  last  1.5  times  the  expected  duration,  with  the latter rewardDuration period having half the effective rewardRate as expected.  pushed  be  rewardDuration   by  initialTime   rewardDuration/2   rewardDuration,   moving   back   will   +   +   to   it   time   If we take this reasoning to the extreme, notifyRewardAmount() can be called every block, which will the  periodFinish  by  12  seconds,  and  reduce  every  the  reward  rate  by 1 - blockDuration/rewardDuration. This is because the new rewardRate will be the old reward minus the consumed reward.  increase   rewardRatet = (rewardt \u2212 1 \u2212 rewardRatet \u2212 1 * blockDuration)  rewardDuration  rewardt \u2212 1 \u2212 rewardt \u2212 1  RewardDuration * blockDuration rewardDuration  = = rewardt \u2212 1 rewardDuration * (1 \u2212 blockDuration rewardDuration ) = rewardRatet \u2212 1 * (1 \u2212 blockDuration  rewardDuration ) from   Over  by (1-blockDuration/rewardDuration)^n,  which  is  an  exponential  decay  for  the  rewardRate,  rewardRate  will   rewardRate   decrease   block   initial   the   the   n   Maker - EndGame Toolkit -   13  NoteVersion1Version2NoteVersion1      \fcorresponding  to  an  exponential  decay  of  the  remaining  reward.  The  reward  will  therefore  not  be distributed in a finite amount of time. Numerical simulations have showed that after 1 week 63% will have been distributed, after 2 weeks 86%, after 3 weeks 95%, after 4 weeks almost 99%.  In  practice,  anybody  can  trigger  notifyRewardAmount()  at  every  block  by  calling  the  distribute method  of  VestedRewardsDistribution,  the  cost  of  doing  so  in  terms  of  gas  is  likely  to  offset  any advantage that such an attacker can get from delaying in such a way the reward rate.  Calling distribute() every block will however not pass an amount of zero notifyRewardAmount(), but it will pass the reward per block vested in dssVest. In the steady state, when the dssVest has been supplying a constant stream of reward for a long time, even factoring in the exponential decay behavior, the rewardRate in StakingRewards will converge to the same constant rate as in dssVest.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Vesting Plan Must Be Restricted",
        "body": "  If a vesting plan of DSSVest is restricted, that means only the recipient of the rewards may claim them, no one else can trigger the distribution of the rewards.  For  the  correct  operation  of  VestedRewardsDistribution  it's  important  that  the  plan  is  restricted: VestedRewardsDistribution.distribute()  in amount  =  dssVest.unpaid(vestId);  only,  any  excess  balance  held  at  the  contract  is  not forwarded.  retrieved   forwards   amount   the   Maker - EndGame Toolkit -   14  NoteVersion1    \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Flash_callback Can Return Incorrect Values",
        "body": "  CS-UNM-031  In MarginDex, the flash_callback function returns the actual_outs array, which lets the vault know how many tokens were received, so that it can transfer them back.  For exact_in orders, the return value is calculated as follows:  if swap_type == 0: # exact_in     actual_out: uint256 = self._swap(token_in, token_out, amount_in, amount_out)     actual_outs[s[1]] += actual_out     if actual_outs[s[0]] > 0: #if we have received some token_in from a previous swap         if actual_outs[s[0]] >= amount_in: #if we have enough previous in to cover the trade             actual_outs[s[0]] -= amount_in         else:             actual_outs[s[0]] = 0 #if we don't have enough previous in to cover the trader  In the last line, we set actual_outs[s[0]] = 0 if the previous swap did not give us enough tokens to cover the full trade. However, we may have also transferred some of the same token into the MarginDex from the Vault. Any remainder from the transferred in amount will not be reflected in the return value. As a result, some tokens could be remaining in the MarginDex that should have been transferred back to the Vault. These tokens can be claimed by anyone.  For exact_actual_out orders, the return value is calculated as follows:  if swap_type == 2: # exact_actual_out         remaining_needed: uint256 = amount_out - ERC20(token_out).balanceOf(self)  Unstoppable - Unstoppable Margin Dex -   12  SecurityDesignCorrectnessTrustCriticalHighMediumLowRiskAcceptedCodePartiallyCorrectedCodePartiallyCorrectedCorrectnessLowVersion2RiskAccepted            \f        if remaining_needed > 0:             actual_in: uint256 = self._swap_exact_out(token_in, token_out, remaining_needed, amount_in)             actual_outs[s[1]] += remaining_needed             actual_outs[s[0]] += amount_in-actual_in         else: #no trade             actual_outs[s[0]] += amount_in  In  the  last  line,  any  amount  that  was  transferred  from  the  vault  is  meant  to  be  accounted,  so  that  it  is correctly  transferred  back.  However,  the  amount_in  value  can  also  be  from  a  previous  trade.  In  this case, the amount was already added in the previous trade. As a result, the same tokens will be added to the  actual_outs  twice.  When  the  Vault  tries  to  transferFrom()  this  amount,  the  balance  will  be insufficient  and  the  transaction  will  revert.  However,  the  user  can  try  again  with  a  different swap_sequence and succeed.  Risk accepted:  Unstoppable is aware of the issue and accepts the risk of incorrect return values.  Unstoppable responded:  Non issue for real world swap sequences.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Debt Is Rounded in Favor of User",
        "body": "  The  function  _amount_per_debt_share  rounds  the  amount  per  debt  share  down,  causing _amount_to_debt_shares  to  round  up  and  _debt_shares_to_amount  to  round  down.  This rounding benefits the user in several functions:  CS-UNM-011  1. reduce_position rounds up shares_to_burn.  2. _close_position rounds down position_debt_amount.  3. liquidate rounds down position_debt_amount.  4. _effective_leverage rounds down debt_value.  It is considered best practice to never round in favor of the user and always round in favor of the protocol.  Code partially corrected:  The rounding has been adjusted in favor of the protocol where possible. In change_position, during partial liquidations, debt is still rounded in favor of the user.  Unstoppable responded:  The only remaining rounding issue we see is that during partial closes the rounding is \u201cin favour\u201d of the user but at the expense of other debtors (including the remaining debt of that same user). This plus the fact that rounding occurs at an extra 18 decimals leads us to assume this is not an issue in our case. Any attempt to adjust for this lead to serious issues in the internal accounting, \u201cnegative\u201d debt etc.  Unstoppable - Unstoppable Margin Dex -   13  DesignLowVersion1CodePartiallyCorrected          \f5.3   Reading Unused Values From Storage in MarginDex  The  MarginDex  reads  values  that  are  never  used  from  storage  and  writes  values  that  are  unchanged back to storage. This causes unnecessary gas consumption.  CS-UNM-012  1. User IDs:  The  open  trades  and  limit  orders  IDs  of  each  user  are  stored  in  an  array  of  1024  elements.  In _cleanup_trade()  and  _remove_limit_order(),  the  entire  array  is  copied  from  storage  to memory, an element is removed, and then the modified array is written back to storage. By operating on the array in storage instead of copying it to memory, it would be possible to reduce the (average) number of storage reads by half and write to storage only 2 times.  2. Large Order structs:  Trades and limit orders are stored in large structs (>1.6 kb). The full structs are read from storage in the following functions, even if only a few elements are used.  Trade  1. close_trade  2. partial_close_trade  3. update_tp_sl_orders  4. add_margin  5. remove_margin  6. execute_tp_order  7. execute_sl_order  8. cancel_tp_order  9. cancel_sl_order  LimitOrder  1. cancel_limit_order  Only accessing (and writing back) the elements of the struct that are used would significantly reduce the gas cost of these functions.  Code partially corrected:  The code has been changed in some but not all places to improve gas efficiency.  Unstoppable responded:  In some instances we prefer clean & readable code to minimized gas costs, especially since we're on an L2.  Unstoppable - Unstoppable Margin Dex -   14  DesignLowVersion1CodePartiallyCorrected        \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings   Bad Debt Can Be Faked for Profit    Users With Approvals Can Be Drained    Large Liquidations Can Fail    Position Can Become Impossible to Close Due to Zero Swaps    Stop-Loss Missing Slippage Protection   -Severity Findings   Bad Debt Check Is Ineffective    Swap Margin Uses Incorrect Fairness Check    TP / SL Can Increase Debt Exposure    Amount Returned From SwapRouter Is Not Validated   Inflation Attack on Newly Added Tokens    MarginDex Admin Is More Trusted Than Required    Stop-Loss Can Unintentionally Increase Leverage   -Severity Findings   Reentrancy Into flash_callback    Bad Debt Check Is Inaccurate    Blacklisted Tokens Can Be Swapped Into    Close_position Slippage May Be Too Strict    Multiple IDs for Each Position    Vault Assumes Chainlink Oracles Have 8 Decimals   Informational Findings   Floating Pragma    Event Logs Value With Unclear Interpretation    Vault Uses Incorrect ERC20 Function Interface    SwapRouter Admin Cannot Be Changed   0  5  7  6  4  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Bad Debt Can Be Faked for Profit",
        "body": "  Unstoppable - Unstoppable Margin Dex -   15  CS-UNM-023  CriticalHighCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedMediumCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCorrectnessHighVersion2CodeCorrected         \fIn  Vault,  the  change_position  function  checks  that  the  position.margin_amount  is  zero  before realizing bad debt.  if position.position_amount == 0:     # no position left -> full close     if position.debt_shares > 0:         # bad debt case         assert self.is_whitelisted_liquidator[_caller] or self.bad_debt_liquidations_allowed,         \"only whitelisted liquidators allowed to create bad debt\"         assert position.margin_amount == 0, \"use margin to lower bad_debt\"  However, the position.margin_amount is updated later in the function, after this check was made:  if actual_margin_in > 0:     self._safe_transfer_from(position.margin_token, _caller, self, actual_margin_in)     position.margin_amount += actual_margin_in  A  user  could  liquidate  themselves  and  trade  all  of  their  token  value  into  margin_amount.  This  would pass the \"fairness check\", as the trade would clear at a fair price. Then the user could have their debt deleted  and  accounted  for  as  bad  debt,  as  their  position  margin  is  zero  at  the  time  of  the  check. Afterward,  they  will  receive  the  margin_amount  from  the  trade  back.  This  would  allow  them  to  profit from the bad debt.  However,  this  is  only  possible  if  the  bad_debt_liquidations_allowed  flag  is  set  to  true,  or  if  the user is on the liquidator whitelist. If one of these conditions hold, all funds in the contract would be at risk.    The position.margin_amount is now updated before the check for bad debt. This resolves the issue.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Users With Approvals Can Be Drained",
        "body": "  CS-UNM-027  In the flash_callback functionality of the Vault, any address can be provided as the _caller, which will be used to swap tokens. In particular, any user's EOA can be used as a \"Swapper\". The provided address will receive some tokens, then transferFrom() will be called to transfer the received tokens back to the Vault.  If a user has an open approval to the Vault, for example, because they are about to make a deposit, then all their approved tokens can be taken by any trader, at a price of zero. This passes the fairness check, as it is a very good price for the trader.  If all users always deposit to the system using a multicall that approves tokens and deposits them in a single  transaction,  and  never  give  more  approval  than  required,  then  they  are  safe.  The  default Unstoppable frontend uses such a multicall flow for deposits. However, users typically expect it to be safe to give approval to a contract they trust.  Sophisticated users, that intentionally implement the P2PSwapper interface, must ensure that they never have open approvals between calls.    A  is_whitelisted_caller  whitelist  has  been  added  to  the  MarginDex.  Now,  addresses  need  to opt-in to the whitelist to be allowed as flash_callback targets. This ensures that normal users cannot  Unstoppable - Unstoppable Margin Dex -   16  SecurityHighVersion2CodeCorrected        \fbe  used  as  swappers,  unless  they  call  the  set_is_whitelisted_caller  function  and  intentionally add themselves to the whitelist.  Contracts that add themselves to the whitelist must still ensure that they never have open approvals to the vault between calls, unless they do not hold any tokens.  If  a  new  MarginDex  is  added  to  the  Vault  in  the  future,  it  should  be  ensured  that  it  also  has  a  similar whitelist mechanism.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Large Liquidations Can Fail",
        "body": "  Positions in Unstoppable Margin Dex can only be fully liquidated, never partially. Additionally, liquidations are  always  done  with  a  Uniswap  swap,  using  a  min_amount_out  based  on  the  oracle  price  and  the liquidate_slippage set by the admin.  CS-UNM-001  If there is a very large position, that causes more than liquidate_slippage of slippage on Arbitrum Uniswap when attempting to close it in a single swap, this swap will revert. As a consequence, it will be impossible  the liquidate_slippage is increased. Delaying a liquidation is a risk to the system and can cause bad debt.  liquidity  on  Uniswap   the  position  unless   improves  or   liquidate   the   to   If functionality was added to partially liquidate a position, the large position could be liquidated in chunks, where each chunk would have a smaller slippage on Uniswap than liquidating the full position at once. This  would  reduce  the  chances  of  a  liquidation  being  impossible  due  to  the  liquidate_slippage being too small. Note that if the oracle price is higher than the Arbitrum Uniswap price, it still might not be possible to execute even partial liquidations.    In  , liquidators can partially liquidate the position amount, but not the margin amount. When the margin amount is sold, the function Vault.change_position() expects a full liquidation and requires repayment of the entire debt and position. If there is a position with a large margin and debt amount but a small position amount (e.g. 1 wei), the full liquidation may cause more slippage than the fairness check allows, and the liquidation reverts.  In  ,  it  is  allowed  to  trade  from  margin  during  a  partial  liquidation.  This  also  allows  partial liquidations of positions that have a large amount of margin and debt left as long as some position is left.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Position Can Become Impossible to Close",
        "body": " Due to Zero Swaps  The _swap function in the Vault attempts to perform a swap on an external DEX for all values passed (including zero). The only DEX that is currently supported is Uniswap V3. Uniswap V3 reverts when the specified  amount  is  zero:  https://github.com/Uniswap/v3-core/blob/d8b1c635c275d2a9450bd6a78f3fa24 84fef73eb/contracts/UniswapV3Pool.sol#L603  The vault calls _swap() with amount = 0 when a user's position is closed and one of the following cases applies:  1. The user has reduced their position amount to 0 using a partial close  CS-UNM-002  Unstoppable - Unstoppable Margin Dex -   17  DesignHighVersion1CodeCorrectedVersion2Version3CorrectnessHighVersion1CodeCorrected                \f2. The user removed their full margin amount and marginToken is not the debtToken  3. Trader PnL is 0 and marginToken is not the debtToken  In all these cases, close_position() will revert, and it will be impossible to close the position.  An attacker can abuse this behavior, since it stops them from getting liquidated. For example, an attacker who has a sufficiently high PnL could remove all margin from his position, to avoid liquidation. Note that they  can  always  deposit  some  margin  tokens  back,  to  close  their  position.  This  lets  them  take  all  the potential upside of a trade, while avoiding the downside.  Note that the Vault Admin could make the position closeable again by replacing the SwapRouter with a new one that returns immediately in case the swap amount is 0.  Other decentralized exchanges may revert for other values (e.g. Curve's CryptoSwap Newton Algorithm only converges for values in a certain range).  Code Corrected:  The  vault  no  longer  directly  calls  the  _swap()  function  on  the  SwapRouter.  Instead,  it  calls  the P2PSwapper  interface's  flash_callback()  function.  The  flash_callback()  implementation  in MarginDex handles zero amounts without reverting.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Stop-Loss Missing Slippage Protection",
        "body": "  The execute_sl_order function takes a caller-provided _min_amount_out argument. However, the function  can  be  called  by  anyone.  This  means  the  _min_amount_out  can  be  set  arbitrarily  low, effectively rendering it useless.  An attacker can profit from this by sandwiching the call. The following calls can be executed atomically in a single transaction:  CS-UNM-003  1. Move the Uniswap Arbitrum market by selling the position asset  2. Call execute_sl_order(), selling position tokens with slippage  3. Buy the position tokens on Uniswap at a discount and bring the market price back to the initial value  The  attack  has  no  capital  requirements,  as  it  can  be  executed  using  a  flashloan.  It  is  profitable  if  the trading fees to move the market are lower than the profit from the sandwich.  The maximum amount of slippage that can be incurred is dependent on the type of Stop-Loss order (full or partial close) and the leverage ratio of the position. For full closes, the maximum slippage allowed by the system for liquidations is the limiting factor. For partial closes, this limit is not in place. However, the position may not get into a liquidatable state after partially closing and withdrawing part of the margin.  Consider the following example of a partial close on a pair where the liquidation threshold is 8x leverage and positionToken/debtToken oracle price is 1:  1. A user has a position of size 1000 with debt 1000 and margin 500 (2x leverage)  2. A Stop-Loss with size 500 reaches its trigger price  3. The user's Stop-Loss is executed by someone who sandwiches them to the maximum extent  4. The execution price of the Stop-Loss is 2/3 (33% slippage), leaving the user with position size 500,  debt (1000 - 500*2/3) = 666.66 and margin 500  5. 250 margin is withdrawn, leaving the user at 7.99x leverage, on the edge of liquidation  Unstoppable - Unstoppable Margin Dex -   18  DesignHighVersion1CodeCorrected        \fThe  user  incurred  a  slippage  loss  of  500/3  =  166.66  tokens.  This  amount  will  be  a  profit  to  the sandwicher,  which  will  then  need  to  deduct  the  costs  of  executing  the  sandwich.  Users  that  start  with lower leverage will incur more slippage than those that are already near the leverage limit. If a user has positive PnL at the stop loss trigger price, they will also lose their PnL amount to slippage.  The _min_amount_out for Stop-Loss execution should be lower-bounded by a value provided by the system or the user.    The  maximum  price  Vault.change_position().  impact  of   trades   is  now  always   limited  by   the   fairness  check   in  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Bad Debt Check Is Ineffective",
        "body": "  In Vault.close_position() only whitelisted liquidators should be allowed to create bad debt as long as bad_debt_liquidations_allowed is set to False. However, the check is ineffective as it is only enforced when a position is fully closed.  if position.position_amount == 0: # no position left -> full close         if position.debt_shares > 0:             # bad debt case             assert self.is_whitelisted_liquidator[_caller] or self.bad_debt_liquidations_allowed,             \"only whitelisted liquidators allowed to create bad debt\"  CS-UNM-028  A liquidator that is not whitelisted can still partially close a position by selling all but 1 wei of the position amount. This creates a position with unrealized bad debt:  positionValue + marginValue < = debt    A check has been added that ensures that the positionValue + marginValue is greater than the debt after a position is changed by a non-whitelisted liquidator. This means that there cannot be any unrealized bad debt in this case, given that the oracle price used to calculate these values is correct.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Swap Margin Uses Incorrect Fairness Check",
        "body": "  Function Vault.swap_margin() defines a fairness check to ensure that the user sets an appropriate minimum amount they should receive from the swap (\"amount1\"). However, the implemented check does not enforce a lower bound on the amount received but instead ensures that the amount returned is lower than the amount expected by the user.  assert (self._quote(_token0, _token1, _amount0) * (PERCENTAGE_BASE + self.reasonable_price_impact[_token0]) / PERCENTAGE_BASE) >= _amount1, \"unfair margin swap\"  CS-UNM-029  The code later asserts that the realized amount is greater than the amount1, allowing the user to get a better price than the oracle price:  Unstoppable - Unstoppable Margin Dex -   19  DesignMediumVersion2CodeCorrectedCorrectnessMediumVersion2CodeCorrected                \fassert actual_amount1 >= amount1, \"[MS:cb] too little out\"  However, there is no guarantee that the user will receive at least the oracle price minus some slippage, as intended.  inAmount > = outAmount * (1 + slippage)  As  MarginDex  limits  access  to  this  function  to  the  user  themselves  and  their  delegatee,  (who  is  fully trusted) the impact is limited.    The fairness check has been corrected to ensure that the user receives at least the oracle price minus some slippage.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   TP / SL Can Increase Debt Exposure",
        "body": "    of  the  MarginDex  contract,  the  execute_tp_order  and  execute_sl_order  functions In  allow the caller to set arbitrary values for _debt_change, _margin_change, and _realized_pnl. A malicious actor could choose _debt_change < 0 and _realized_pnl > 0 to create additional debt and offset the debt by moving more margin to the position. This is permissible as long as the final position meets the leverage criteria and the trade is fair.  For instance, consider a trader with an initial position of:  CS-UNM-030   position_amount = 100   margin_amount = 10   debt_amount = 100  leverage = 10  trader margin balance = 5  A malicious executor could execute a take-profit (or stop-loss) order with the following parameters:   reduce_by_amount = position_change = -50   debt_change = -50   margin_change = +100   realized_pnl = +5  The trade can be executed since the fairness condition is fulfilled:  positionChange + debtChange = marginChange  After the trade, the trader has a modified position that has the same leverage as before, but higher debt:   position_amount = 50   margin_amount = 115   debt_amount = 150  leverage = 10  trader margin balance = 0  Unstoppable - Unstoppable Margin Dex -   20  DesignMediumVersion2CodeCorrectedVersion2            \fThe  attacker  profits  from  executing  the  orders,  as  higher  trading  volume  increases  the  extractable slippage.  Further,  users  with  standing  TP/SL  orders  can  be  griefed  by  executing  their  orders  with  a  negative realized_pnl to consume all of their available margin. This stops them from opening a new position, as they are unable to pay the trading fee.    The following checks have been added to the execute_tp_order and execute_sl_order functions:  assert _debt_change >= 0, \"no new debt during tp/sl\" assert _realized_pnl <= 0, \"cannot add more margin during tp/sl\"  For TP/SL orders that do not fully close a position, additional checks are made:  assert not is_full_close, \"was supposed to be full close\"  assert Vault(self.vault).positions(_trade_uid).margin_amount <= position.margin_amount, \"cannot increase margin on partial tp\"  This ensures that no unexpected changes to the position can be made.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   Amount Returned From SwapRouter Is Not",
        "body": " Validated  According to the trust model of the system, the SwapRouter is not fully trusted. As such, the Vault verifies that  it  has  received  the  expected  quantity  of  tokens  from  the  swap  by  comparing  the  token  balance before and after the swap.  CS-UNM-004  token_out_balance_before: uint256 = ERC20(_token_out).balanceOf(self)  amount_out_received: uint256 = SwapRouter(self.swap_router).swap(     _token_in, _token_out, _amount_in, _min_amount_out )  token_out_balance_after: uint256 = ERC20(_token_out).balanceOf(self) assert (     token_out_balance_after >= token_out_balance_before + _min_amount_out )  However,  the  vault  only  verifies  that  the  token  balance  has  increased  by  at  least  min_amount_out, without confirming it has increased by amount_out_received.  The received amount is used to calculate the Trader's profit. If the SwapRouter returns a value that is too large, this extra amount will be credited to the trader, which can then be withdrawn. In the worst case, this could drain all funds in the vault and make it insolvent.    Unstoppable - Unstoppable Margin Dex -   21  CorrectnessMediumVersion1CodeCorrected        \fThe Vault no longer directly calls the SwapRouter. Instead, it calls an untrusted P2PSwapper contract. The  value  returned  by  the  P2PSwapper  is  checked  to  be  at  least  as  large  as  expected.  Afterward,  a safe_transfer_from call is used to transfer this amount of tokens from the P2PSwapper to the Vault. If the P2PSwapper does not have a sufficient balance, the transfer will revert. As a result, an incorrect return value can no longer cause issues.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   Inflation Attack on Newly Added Tokens",
        "body": "  CS-UNM-005  Shared Vaults such as the Unstoppable Vault have a known issue called an \"inflation attack\", where an attacker  increases  the  price  per  share  of  vault  shares  by  a  lot,  such  that  a  small  rounding  error  in  the number of shares other users receive results in a large percentage of the deposit being lost to rounding. This is generally only possible if the attacker is the first depositor to an empty vault.  The Unstoppable Vault mitigates this attack in 2 key ways:  1. It does not count any tokens sent directly to the vault as belonging to LPs, so it is hard to \"donate\"  to the LP.  2. When minting initial shares, 10E18 shares are minted per wei of token deposited. This makes the total number of shares large, even if only 1 wei is deposited. Additionally, withdrawal amounts can only be specified in underlying tokens, not shares.  However, both of these mitigations can be circumvented:  1. Tokens cannot be donated to the LPs directly, but interest from borrowing can accrue and be paid to LPs. In particular, interest from funds lent by one module, such as the base_lp, can be paid to the  other  module,  such  as  the  safety_module_lp  (or  the  other  way  around),  even  if  the safety_module_lp  has  no  shares  or  few  shares.  This  allows  donating  a  lot  of  interest  (by depositing a lot of base_lp and borrowing it all) while keeping the number of safety_module_lp shares small.  2. Once  the  price  per  share  has  been  increased  by  at  least  1E18,  it  will  be  possible  to  withdraw  a  partial amount of the initially minted shares and only leave 1 share left.  Combining these factors, the following attack can be executed on any token that is newly added to the system and has no LPs in one of the modules (here illustrated with the safety_module_lp) yet:  1. Deposit a large amount to the base_lp  2. Borrow 100% of available liquidity from yourself.  3. Deposit 1 wei of token to safety_module_lp. Receive 1E18-1 shares.  4. Partially close an amount of the borrow position such that exactly 1E18-2 tokens are paid as fees to the safety_module_lp. Now the price per share is 1 (initially it was 1/(1E18-1)). This allows us to withdraw a precise number of shares.  5. Withdraw  1E18-2  tokens  from  the  safety_module_lp.  Now  there  is  1  wei  token  and  1  wei  shares left.  6. Wait for a significant amount of interest to accrue. Close the borrow position. If X interest accrued to  the safety_module_lp, the price per share of safety_module_lp will now be X+1.  7. Wait for another user to deposit to the safety_module_lp. When they do, the shares minted will be rounded up, then reduced by 1. This means they will receive up to 1 share less than if there was no  rounding.  Since  1  share  is  worth  X+1  wei  tokens,  up  to  X+1  wei  tokens  will  be  accounted  as belonging to the existing LPs (the attacker) instead of the depositing user.  Note that all future users will suffer from up to X+1 rounding, not just the first one:  Unstoppable - Unstoppable Margin Dex -   22  SecurityMediumVersion1CodeCorrected        \fIn step 6., the attacker pays interest of 1000E18 USDC to the safety_module_lp   As there is only one share, the price per share is now 1000E18 + 1.   A second user deposits 2000E18 USDC in step 7. The rounded-up number of shares they should receive is 2. This number is reduced by 1 to account for rounding. The user only receives 1 share and the price per share now increases to 1500E18. The attacker made a profit of 500E18 USDC, which came from the second user.   A  third  user  deposits  1500E18  USDC.  Their  rounded-up  shares  are  1,  which  is  reduced  by  1,  so they receive 0 shares. The price per share increases to 2250E18. The attacker and the second user both make 750E18 USDC profit, which came from the third user.  The maximum amount that can be donated in step 6. is limited by the following factors: The amount the attacker  deposits,  the safety_module_lp, and the time deposited. The time deposited is likely the largest limiting factor, as the attacker only has time until the first user deposits, after which the attacker will no longer own all the shares in the pool.  the  percentage  of   the  maximum   interest  rate,   that  goes   interest   to   In summary, the mitigations in place for inflation attacks are insufficient, and, given enough capital and time, an attacker can create a pool where all future users lose 100% of their deposit.    The  inflation  attack  was  mitigated  by  adding  a  virtual  offset  to  the  _amount_to_lp_shares  and _lp_shares_to_amount functions.  For details on this approach, see: ERC4626 - defending with a virtual offset.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.11   MarginDex Admin Is More Trusted Than",
        "body": " Required  CS-UNM-006  The  MarginDex  admin  is  a  partially  trusted  role.  It  should  be  able  to  set  the  MarginDex  instance's is_accepting_new_orders  flag,  which  pauses  new  orders  but  still  allows  existing  positions  to  be closed.  However,  the  admin  can  also  set  the  vault  variable,  which  points  to  the  Vault  on  which  orders  are executed. If the admin sets this variable to a different address, it will be impossible to interact with the Vault,  unless  another  MarginDex  contract  is  added  by  the  Vault  admin.  This  would  cause  a  Denial  of Service, making it impossible to adjust positions or liquidate them.  The  vault  variable  doesn't  need  to  be  updatable,  so  trusting  the  MarginDex  admin  not  to  maliciously unset the Vault is an unnecessary risk.    The  MarginDex  admin  can  no  longer  set  the  vault  variable.  The  vault  variable  is  now  set  in  the constructor and cannot be changed.  Unstoppable - Unstoppable Margin Dex -   23  TrustMediumVersion1CodeCorrected           \f6.12   Stop-Loss Can Unintentionally Increase Leverage  CS-UNM-007  In MarginDex, users can specify a Stop-Loss order that reduces their position at a certain price. If it is a partial close, some of the user's margin will also be withdrawn when the order is triggered.  This is done as follows:  amount_out_received = self._partial_close(trade, sl_order.reduce_by_amount, _min_amount_out) ratio: uint256 = sl_order.reduce_by_amount * PRECISION / position.position_amount remove_margin_amount: uint256 = position.margin_amount * ratio / PRECISION Vault(self.vault).remove_margin(trade.vault_position_uid, remove_margin_amount)  The amount removed from margin is the percentage of margin that corresponds to the percentage of the position that was partially closed. E.g. if the position was reduced by 10%, the margin is also reduced by 10%. This is intended to keep the leverage of the position unchanged.  However,  the  ratio  calculated  here  assumes  that  the  partial  close  reduces  the  debt  by  the  same percentage that the position is reduced. This is only the case if the trade executes exactly at the oracle price which is used to calculate the leverage.  This may not happen for multiple reasons:  1. The oracle price may not reflect the current price  2. There may be trading fees  3. There may be slippage  If  the  execution  price  is  below  the  oracle  price,  the  debt  of  the  position  will  be  reduced  by  less  than ratio. Withdrawing ratio of the margin will thus unintentionally increase the leverage of the position. In  the  extreme  case  where  the  position  already  has  high  leverage,  this  may  cause  the  leverage  to increase above the maximum acceptable leverage. The transaction will revert and it will be impossible to execute  the  partial-close  Stop-Loss,  even  though  it  would  have  been  possible  if  less  margin  was withdrawn.  The same issue also affects Take-Profit orders.  Specification changed:  The  specification  has  been  updated  to  allow  changes  in  leverage  up  to  the  bounds  set  by  the leverage_buffer parameter. This ensures that the leverage does not increase too much:  if Vault(self.vault).positions(_trade_uid).position_amount > 0:     # partial close     leverage_after: uint256 = self._effective_leverage(_trade_uid, 2)     assert (leverage_after >= leverage_before - min(leverage_before,     self.leverage_buffer)) and (leverage_after <= leverage_before + self.leverage_buffer),     invalid sl execution\"  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.13   Reentrancy Into flash_callback",
        "body": "  CS-UNM-032  Unstoppable - Unstoppable Margin Dex -   24  DesignMediumVersion1Speci\ufb01cationChangedDesignLowVersion2CodeCorrected              \fThe  function  flash_callback  in  the  MarginDex  contract  is  assumed  to  be  called  only  by  the  Vault contract.  However,  there  is  no  restriction  on  calling  it  from  another  contract,  and  no  protection  against the reentrancy.  A  malicious  decentralized  exchange  or  flash_callback  function.  As  the  margin  dex  holds  funds  for  the  duration  of  the  trade,  a  part  of  the funds could be stolen in this situation.  tokens  with  callbacks  could  reenter   The maximum value that can be extracted is capped, as the amount of tokens returned must still fulfill the fairness criteria enforced by the Vault contract.    A reentrancy lock was added to the flash_callback function. It is a separate lock from the one used in other functions of MarginDex.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.14   Bad Debt Check Is Inaccurate",
        "body": "  CS-UNM-008  In close_position(), there is a check that should ensure a user cannot close a position that would result in bad debt:  margin_value: uint256 = self._quote_token_to_token([...]) assert min_amount_out + margin_value >= self._debt(_position_uid), \"min_amount_out cannot result in bad debt\"  This check is inaccurate, as the margin_value is calculated using the oracle price. The actual price that swapping the margin token to debt token would execute at may be lower due to slippage. For the position token, this is taken into account by using the min_amount_out.  As a result, it may be possible for the user to close a position that results in bad debt.    The close_position function was removed and replaced with the more generic change_position function, which checks a position's health based on the remaining tokens after the swap has taken place. While the oracle price is still used for the remaining tokens, the realized price of the swap is token into account for the swapped tokens.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.15   Blacklisted Tokens Can Be Swapped Into",
        "body": "  The  Vault  prevents  the  user  from  funding  their  account  with  assets  that  are  not  on  the  whitelist. However,  they  can  call  the  swap_margin  function  to  swap  into  tokens  that  were  removed  from  the whitelist,  given  that  they  still  have  a  route  configured  in  the  SwapRouter.  They  can  then  use  the blacklisted token to top-up an existing margin position via add_margin.  CS-UNM-009    The swap_margin function now enforces a whitelist on the token being swapped into.  Unstoppable - Unstoppable Margin Dex -   25  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                  \f6.16   Close_position Slippage May Be Too Strict  In Vault, close_position() enforces that the min_amount_out given by the user is at least as large as the system_min_out.  CS-UNM-010  assert min_amount_out >= system_min_out, \"too little min_amount_out\"  This  condition  is  stricter  than  necessary.  As  there  is  a  check  later  that  the  min_amount_out  chosen cannot cause bad debt, a user should be allowed to specify a min_amount_out that is smaller than the one set by the system. A large value set by the system can cause the close to revert. This would be most likely to be a problem when the oracle price is higher than the Arbitrum Uniswap price.    The close_position function was removed and replaced with the more generic change_position function.  Trades  are  now  protected  from  too  much  slippage  by  a  single  \"fairness  check\"  in change_position.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.17   Multiple IDs for Each Position",
        "body": "  The MarginDex stores two IDs for each position, a position_uid and a vault_position_uid. In the contracts in scope, both IDs are always the same.  CS-UNM-037    The secondary ID was removed, and a single position_uid is now used everywhere.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.18   Vault Assumes Chainlink Oracles Have 8",
        "body": " Decimals  In  Vault._to_usd_oracle_price,  it  is  assumed  that  Chainlink  USD  price  feeds  have  8  decimals.  This condition is not validated when a new asset and its price feed are whitelisted, so it is possible to add a price feed with a differing number of decimals.  CS-UNM-013  like  Note  https://etherscan.io/address/0xe20CA8D7546932360e37E9D72c1a47334af57706#readContract  AMPL   feeds   some   have   price   USD   that   18   /   decimals  Specification Changed:  Unstoppable clarified that they plan on only utilizing price feeds from the \"verified\" tier with 8 decimals of precision.  Unstoppable - Unstoppable Margin Dex -   26  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedCorrectnessLowVersion1Speci\ufb01cationChanged                      \f6.19   Event Logs Value With Unclear Interpretation  The  MarginDex  emits  the  LimitOrderPosted  event  for  each  limit  order  placed.  The  event  has  the  field amount_in, which is defined as the sum of margin_amount and debt_amount.  The  value  has  an  unclear  interpretation  when  the  margin  token  is  not  equal  to  the  debt  token,  as balances of two different tokens are summed together.  CS-UNM-017    The event was removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.20   Floating Pragma",
        "body": "  Unstoppable uses a floating pragma vyper ^0.3.10. Contracts should be deployed with the same compiler version and flags that have been used during testing and audit. Locking the pragma helps to ensure this.  CS-UNM-018    Unstoppable has fixed the pragma to vyper version 0.3.10.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.21   SwapRouter Admin Cannot Be Changed",
        "body": "  The  SwapRouter  admin  role  is  set  once  and  cannot  be  transferred  to  another  address.  The  other contracts contain functionality to change the admin.    The suggest_admin and accept_admin functions have been added to the SwapRouter contract.  CS-UNM-021  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.22   Vault Uses Incorrect ERC20 Function",
        "body": " Interface  The Vault defines the incorrect interface for the ERC20 token. The approve function should return true on success.  Note  that  changing  this  may  break  compatability  with  tokens  that  incorrectly  implement  the  ERC20 standard, such as USDT on Ethereum mainnet.  CS-UNM-025  Unstoppable - Unstoppable Margin Dex -   27  InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected                        \f  The approve function has been removed from the interface defined in Vault.  Unstoppable - Unstoppable Margin Dex -   28  \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Arbitrum Sequencer Could Affect",
        "body": " Block.Timestamp  The protocol makes use of block.timestamp. On Arbitrum, a malicious sequencer is able to change the block timestamps information to 24 hours earlier then the actual time or 1 hour in the future. See also:  https://docs.arbitrum.io/for-devs/concepts/differences-between-arbitrum-ethereum/block-numbers-and-ti me#block-timestamps-arbitrum-vs-ethereum  If  the  timestamp  value  is  set  to  a  previous  time,  the  Vault  can  accept  stale  Chainlink  prices,  and MarginDex can execute limit orders that have already expired.  CS-UNM-014  Acknowledged:  Unstoppable is aware of this behavior but accepts the risk due to lack of alternative solutions.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Arbitrum-Specific Code",
        "body": "  Unstoppable  is  targeting  an  initial  launch  to  Arbitrum,  with  plans  to  extend  to  additional  networks. However, certain parts of the code work exclusively on Arbitrum:  1. The  withdrawTo  function,  exclusive  to  Arbitrum's  extended  WETH,  isn't  compatible  with  other  WETH implementations (e.g., Optimism, Mainnet).  2. The addresses for WETH, ARBITRUM_SEQUENCER_UPTIME_FEED, and UNISWAP_ROUTER  are hard-coded to Arbitrum's deployment.  CS-UNM-015  Acknowledged:  Unstoppable responded:  Part of the deployment checklist.  Unstoppable - Unstoppable Margin Dex -   29  InformationalVersion1AcknowledgedInformationalVersion1Acknowledged            \f7.3   Avoiding Liquidation Penalty in Self-Liquidation  In  , a user's position can be liquidated by anyone if it becomes undercollateralized. The user is then  required  to  pay  a  liquidation  penalty  based  on  the  remaining  position  margin  after  liquidation. However, if no margin tokens are left, the liquidation penalty becomes zero:  CS-UNM-033  # full liquidation, penalty from margin if position.margin_token != position.debt_token:     penalty = self._quote(position.debt_token, position.margin_token, penalty) penalty = min(penalty, position.margin_amount)  If a trade returns more debt tokens than required to cover the debt, the excess tokens are credited to the user before any penalty is applied. This means that in a self-liquidation scenario, the user can avoid the liquidation penalty by moving the proceeds from the liquidation into the debt token. Note that the trade must  still  fulfill  the  fairness  criteria  and  the  check  caps  the  debt  change  to  the  minimum  position  debt amount:  amount_in[0] = min(position_debt_amount, convert(_debt_change, uint256))  Acknowledged:  Unstoppable responded:  Very unlikely that a user is willing and capable to outperform MEV liquidators, but he doesn\u2019t simply close his position before it becomes liquidatable and a penalty is even in question. Doesn\u2019t justify the added complexity to cover this case in code.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   Blacklisted Tokens Can Be Credited",
        "body": "  Users are prevented from funding their accounts with assets that are not whitelisted in fund_account and fund_account_eth. But, similar to Blacklisted Tokens Can Be Swapped Into, a user can fund their account  through  other  means:  If  a  user  has  a  debt  position  in  a  token  that  was  removed  from  the whitelist, they can close their position by choosing a route that generates more debt tokens than required to cover their debt. The excess tokens are then credited to the user's margin and can be used to top up existing positions by calling the change_position function with realized_pnl set to a negative value.  CS-UNM-034  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   Cannot Mint or Redeem Shares When Price Is",
        "body": " 0  CS-UNM-016  Unstoppable - Unstoppable Margin Dex -   30  InformationalVersion2AcknowledgedVersion2InformationalVersion2InformationalVersion1Acknowledged              \fThe  price  of  an  LP  share  can  fall  to  zero  when  bad  debt  is  generated.  When  liquidity  is  provided  or removed, the contract divides by the share price and the transaction reverts.  Acknowledged:  Unstoppable answered:  Bad debt would have to be repaid first.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.6   Liquidity Provider Can Withdraw Small",
        "body": " Amount of Lent Out Assets  According to code comments, Liquidity Providers should not withdraw liquidity that is currently lent out.  The code enforces this by comparing the proposed amount with total liquidity - debt.  However, the contract does not update the debt before making this comparison, so LPs can withdraw a small amount of outstanding interest.  CS-UNM-019  Acknowledged:  Unstoppable responded:  Interest accrued is not the same as lent out liquidity. An LP can withdraw before ``update_debt`` is called, but in exchange \u201cdonates\u201d his interest to the remaining LPs in this case.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.7   No Address 0 Checks",
        "body": "  The following setter functions do not do a sanity check that the address passed is not zero:  CS-UNM-020  1. Vault.set_is_whitelisted_dex: _dex  2. Vault.set_configuration: swap_router  3. MarginDex.set_vault: _vault  Code partially corrected:  function  Vault.set_configuration  no   The  MarginDex.set_vault  the  Vault.set_is_whitelisted_dex still does not check for address 0.  longer  sets  from   removed   been   has   the  swap   router.  The   codebase.   The   function function  Unstoppable responded:  Due to code size limitations we had to remove low value checks.  Unstoppable - Unstoppable Margin Dex -   31  InformationalVersion1AcknowledgedInformationalVersion1CodePartiallyCorrected            \f7.8   No Grace Period for Sequencer Uptime Feed  The  Vault  retrieves  the  status  code  of  the  Arbitrum  Sequencer  from  a  Chainlink  oracle.  When  the sequencer is down, the Vault does not accept the prices provided by Chainlink and reverts.  The Chainlink documentation recommends to wait an additional grace period after the sequencer is back up to give users time to improve their leverage.  https://docs.chain.link/data-feeds/l2-sequencer-feeds#example-code  Waiting  for  the  grace  period  increases  the  risk  of  price  jumps,  but  could  reduce  the  risk  of  mass liquidations.  CS-UNM-036  Acknowledged:  Unstoppable responded:  The recommendation makes sense for overcollateralized use-cases, in the undercollateralized environment we are working in, we want to react as quickly as possible instead of waiting for users who may or may not react manually.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.9   SwapRouter's Exact Output Swap Does Not",
        "body": " Handle Non-Standard Tokens  CS-UNM-035  In SwapRouter.swap_exact_out(), the contract grants approval to the Uniswap Router to spend the maximum  amount  of  tokens.  However,  the  router  only  withdraws  the  necessary  tokens  for  the  swap, leaving some approval remaining.  This can be problematic with certain non-standard ERC20 tokens (e.g., USDT on Ethereum) that require the  approval  to  be  reset  to  0  before  a  new  approval  can  be  set.  As  a  result,  the  router  could  become locked after the first swap not consuming the full approval. While resetting the approval to 0 post-swap could resolve this, it would render the router contract incompatible with other ERC20 tokens like BNB (on Ethereum) that explicitly prohibit setting the approval to 0.  To  accommodate  these  non-standard  tokens,  a  safe_approve  wrapper  function  could  be  used  (see: Transfer in SwapRouter does not handle non-standard tokens).  For  https://github.com/d-xo/weird-erc20?tab=readme-ov-file#approval-race-protections  context,   more   refer   the   to   following   link:  Note that we are currently not aware of any such tokens on Arbitrum, although they may exist.  Acknowledged:  Unstoppable responded:  Unstoppable - Unstoppable Margin Dex -   32  InformationalVersion1AcknowledgedInformationalVersion2Acknowledged            \fMarginDEX functionality will be limited for the foreseeable future to a handful of the main tokens, no plans to add or support exotic/non-standard tokens.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.10   Transfer in SwapRouter Does Not Handle",
        "body": " Non-Standard Tokens  The SwapRouter uses the transfer function to transfer tokens.  It  is  considered  best  practice  to  use  safe_transfer_from  for  transfers,  to  check  the  return  value  and handle non-standard ERC20 tokens, such as those that do not return a boolean value on success (such as USDT and BNB on Ethereum mainnet).  https://github.com/d-xo/weird-erc20?tab=readme-ov-file#missing-return-values  CS-UNM-022  Acknowledged:  Unstoppable is aware of this behavior and notes that they have no plans to use non-standard tokens.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.11   Utilization Rate Is Overestimated",
        "body": "  The system accrues debt every second due to interest. However, the interest is paid to Liquidity Provider only  when  traders  close  their  position  or  get  liquidated.  As  a  result,  the  contract  underestimates  the actual available Liquidity and overestimates the utilization ratio (debt / liquidity).  This leads to a higher interest rate than expected.  CS-UNM-024  Acknowledged:  Client is aware of this behavior, but has decided to keep the code unchanged.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.12   Withdrawing Liquidity Can Intentionally",
        "body": " Increase Utilization  Liquidity providers can withdraw their liquidity from the protocol to increase the utilization rate. A larger utilization ratio increases the interest rate charged to borrowers. Rates will stay high until borrowers close positions or additional LPs deposit, both of which will likely take some time. It is crucial to ensure that the maximum interest returned by the interest rate model is not too large.  In the worst case, the interest accrued in a short period (e.g. one block) could be sufficient to liquidate all borrowers.  CS-UNM-026  Unstoppable - Unstoppable Margin Dex -   33  InformationalVersion1AcknowledgedInformationalVersion1AcknowledgedInformationalVersion1Acknowledged                  \fAcknowledged:  Unstoppable is aware of this behavior.  Unstoppable - Unstoppable Margin Dex -   34  \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Behavior in Case of Sequencer Downtime",
        "body": "  Blocks on Arbitrum are ordered by the sequencer. In case this sequencer goes down, blocks will only be created again once it comes back online, or by using the force-inclusion mechanism, which can include transactions on L2 through L1, after waiting for the minimum delay of 24 hours.  While the sequencer is down, the Oracle used by the Vault reverts. As a result, it will be impossible to open, close, or modify any position (as these actions call the oracle for a leverage check). In particular, it will also be impossible to liquidate positions. Delaying liquidations may lead to bad debt for the system.  In the special case where the sequencer goes down and never comes back online, users will be able to withdraw from their margin balances as well as the LP using the force-inclusion mechanism. However, it will be impossible to close positions. This means any margin used in a position, as well as any LP funds that are used in active positions will be irrecoverable until the sequencer comes back online. For LPs, this means  that  there  will  be  a  race  to  withdraw  first.  Any  LPs  that  withdraw  while  there  are  still  unutilized funds available will receive their money back, while those that withdraw later when the remaining funds are fully utilized will be unable to withdraw.  Overall, the system is likely to experience bad debt in case the sequencer goes down, especially if it goes down for extended periods.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Delegates Can Profit From Bad Trades",
        "body": "  According to the trust model, the delegate of a user in MarginDex should be able to trade on their behalf, but they should not be able to withdraw from their balance.  However,  a  delegate  can  indirectly  steal  from  the  user's  balance  by  making  trades  with  bad  slippage parameters and then sandwiching the user, see also Sandwiching order execution.  As a result, the trader should only delegate to addresses they fully trust.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.3   Interest Is Only Paid When the Positions Are",
        "body": " Closed  Traders  accumulate  interest  continuously,  but  Liquidity  Providers  only  get  paid  when  positions  are closed.  If  a  Liquidity  Provider  adds  funds  right  before  a  position  closure,  they  earn  interest  for  the position's  entire  duration.  But  if  they  withdraw  right  before  a  closure,  they  get  no  interest,  even  if  they were deposited for most of the position's duration.  Unstoppable - Unstoppable Margin Dex -   35  NoteVersion1NoteVersion1NoteVersion1            \f8.4   Limit Orders Can Become Executable Below Market Price  Limit orders contain a min_amount_out set by the user. This ensures that the order executes at a price that is no worse than the one set by the user. Usually, this is set to a price that is better than the current price.  A limit order that has hit its minimum execution price is only executable if the user has a sufficient margin balance in the Vault. This may not be the case, for example, if the user had another limit order trigger that uses  the  same  margin  token.  As  a  result,  the  limit  order  will  stay  open  with  a  price  that  is  now  below market price. If the user receives sufficient margin balance again later, (e.g. by closing a position), then the order will be executable again, unless it has passed its expiry. The user can get sandwiched and receive only their min_amount_out, even though the current market price may be significantly higher.  Users can protect themselves from this in multiple ways:  1. Ensure there is always enough margin to execute all open limit orders.  2. Set the expiry of limit orders to a short time  3. Cancel  limit  orders  that  have  hit  their  execution  price,  but  cannot  be  executed  due  to  insufficient  margin.  Updated behavior:  In  can now execute at the configured maximum slippage compared to the oracle price.  , a \"fairness check\" was added to all trades, meaning that in the worst case a stale limit order  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.5   Non-Standard ERC-20 Tokens",
        "body": "  We assume that the contract only handles standard ERC-20 Tokens.  We have identified the following issues with non-standard ERC-20 Tokens:  1. The internal accounting of the Vault does not handle rebasing or fee-on-transfer Tokens  2. The price of tokens without decimals function cannot be calculated  3. Pausable tokens can stop the Vault from closing positions  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.6   Oracle Manipulation on FIFO L2s",
        "body": "  Unstoppable  relies  on  price  oracles  for  the  \"fairness  check\"  on  swaps,  which  is  critical  to  the  system's security.  Price oracles must be robust and manipulation-resistant. It must be expensive to manipulate the markets which are used as price sources.  Usually,  the  factor  that  makes  price  manipulation  expensive  is  arbitrage.  If  a  manipulator  pushes  the price of an asset too high or too low, arbitrageurs will see this and make a profit by moving the price back to the \"true price\". Any profit made by arbitrageurs will be a loss to the manipulator.  Unstoppable - Unstoppable Margin Dex -   36  NoteVersion1Version2NoteVersion1NoteVersion1          \fThis \"arbitrage assumption\" breaks down in two cases:  1. All markets for the token are manipulated simultaneously, so it is difficult to determine the \"true  price\". There is no other market to arbitrage against.  2. Arbitrageurs  are  not  able  to  see  the  manipulated  price  quickly  enough,  so  they  cannot  take  advantage of it.  Attacks that target condition 2. are known as \"Multi-block MEV\" attacks. The idea is that a manipulator could control the order of transactions in a block, which allows the following:  In block n, the manipulator sends a transaction (through a private mempool like Flashbots) that manipulates the price of an asset.  In block n+1, the manipulator ensures that the first transaction in the block is one where they revert the price back to the original value.  As a result, arbitrageurs will have no chance of reacting to the manipulation, as it will already be over by the time they can get a transaction included in the block. However, if there is an Oracle that reads the price at the beginning of block n+1, it will see the manipulated price.  This  attack  is  well-known  on  Ethereum,  but  is  generally  deemed  expensive  to  execute,  as  it  requires being ,or having an agreement with, the ETH staker that is chosen to propose block n+1. If the attack should  be  repeated  multiple  times,  it  requires  being  chosen  as  block  proposer  multiple  times  within  a short time frame, which requires a significant amount of ETH staked.  However, on L2s, block production works differently. Instead of a different proposer being chosen in each block, there is typically a single sequencer that decides on a block ordering policy. One commonly used policy  used  by  chains  such  as  Arbitrum,  Optimism  and  Base  is  \"FIFO\"  (First  In,  First  Out),  where transactions are included in the order they were received.  In FIFO ordering, the order of transactions is determined by time, not by the price a user is willing to pay. This can be taken advantage of to fulfill condition 2. above, without needing to be a block producer.  The FIFO attack looks as follows:  1. The manipulator experiments to figure out their latency to the sequencer (and ideally minimizes  it).  2. The  manipulator  sends  a  manipulation  transaction  at  a  time  such  that  it  will  arrive  at  the  sequencer towards the end of the period in which it is building block n.  3. The manipulator sends a second transaction so that it reaches the sequencer at the beginning  of the period in which it is building block n+1.  Arbitrageurs are only able to see the manipulated price once block n is published by the sequencer. By that  time,  the  manipulator  has  already  sent  the  second  transaction  that  reverts  the  price  back  to  the original value. As time is the only relevant factor, it is impossible for a transaction that is created later to be included in the block first (unless the arbitrageur has significantly lower latency to the sequencer).  The only cost to the attacker is the trading fees paid. As the attack cannot use a flashloan, they must also have sufficient capital available to manipulate the price by the percentage they aim for. The attack can be repeated as many times as the attacker wants, although repeated attacks could be speculatively frontrun by  arbitrageurs  if  they  detect  a  pattern.  Repeated  attacks  can  be  used  to  circumvent  outlier-detection mechanisms and TWAPs.  A policy that modifies transaction ordering to be based on a payment in addition to timing would make the attack significantly more expensive. For example, \"Arbitrum time-boost\" has been proposed, but not yet implemented. See Time Boost Medium post.  Note  that  Multi-block  MEV  attacks  have  historically  been  considered  mostly  in  the  context  of  TWAP manipulation. However, if there is an off-chain oracle, such as ChainLink, that uses an on-chain market as a primary price source, the attack also applies there. In fact, the effect will be much larger, as off-chain  Unstoppable - Unstoppable Margin Dex -   37    \foracles typically do not use a time-weighted average. Instead, they read the spot price at a single point in time.  As  a  result,  executing  the  attack  once  could  lead  to  a  heavily  manipulated  price.  Some  off-chain oracles  may  implement  outlier-detection  to  mitigate  this,  but  this  is  often  not  clearly  documented,  if  it exists at all. If outlier-detection exists, the attack could be executed multiple times.  In  summary,  Multi-block  MEV  attacks  are  likely  much  more  realistic  to  execute  on  FIFO  L2s  (such  as Arbitrum)  than  on  Ethereum,  as  they  are  possible  without  needing  to  be  a  block  producer.  They  can affect on-chain TWAPs as well as any off-chain oracles that use L2 on-chain markets as a primary price source.  This  must  be  considered  when  deciding  which  assets  have  an  oracle  that  is  robust  enough  to use.  It should be carefully considered before any asset is added to the system for which the price oracle is based primarily on L2 markets.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.7   Repay Bad Debt Applies to All LPs",
        "body": "  The Vault has a repay_bad_debt function, that can be used to repay bad debt that was incurred. One use-case of this could be an insurance fund.  Note that when bad debt is repaid, it will be repaid to all LPs of that token that have shares affected by bad debt (usually just the safety module). In particular, it will also apply to LPs that deposited after the bad debt is incurred. Instead of being compensated for their earlier loss, the payment will be a profit to these new LPs.  As a result, the repay_bad_debt should be used in a way that is not predictable, as otherwise, it will be profitable to deposit to the LP before the repayment happens.  This is not a problem in case the bad debt is so large that the protocol goes into \"defensive mode\", which disallows deposits to the LP. The admin could also intentionally activate defensive mode.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.8   Sandwiching Order Execution",
        "body": "  Swaps on Unstoppable Margin Dex, such as opening, closing, or liquidating positions, are always routed through Uniswap. The swaps always have a min_amount_out configured to define a maximum allowed amount of slippage.  In some cases, the swap transaction can be executed by anyone. This is the case for limit, take-profit and stop-loss  orders,  as  well  as  liquidations.  In  these  cases,  it  is  trivial  for  the  executor  to  \"sandwich\"  the swap  with  2  additional  swaps  on  Uniswap  that  happen  in  the  same  transaction,  manipulating  the execution price. This will cause the swap to execute such that exactly the min_amount_out is returned, but  no  more.  The  difference  to  the  unmanipulated  price  will  be  a  profit  to  the  executor.  This  can  be executed using a flash loan, so it has no capital requirements.  For transactions that are only executable by certain addresses (such as a user closing their own position) it is much harder to sandwich, as Arbitrum One does not use a public mempool and has FIFO ordering. However, if it would be possible to tell using some offchain metric that a user is about to execute a trade, they could still be frontrun. On a chain that has a different transaction ordering methodology, it may be possible to reliably frontrun and sandwich these types of transactions too.  It should also be noted that the FIFO ordering means that an arbitrage bot that is optimized for latency should be expected to execute orders before Unstoppable's own off-chain \"Liquidation engine\" does, as it is likely less optimized.  In  summary,  for  transactions  executable  by  anyone,  it  should  be  expected  that  they  clear  at  the min_amount_out price with no surplus.  Unstoppable - Unstoppable Margin Dex -   38  NoteVersion1NoteVersion1        \fUpdated behavior:  In    orders  are  no  longer  always  routed  through  Uniswap.  Instead,  they  are  routed  through  a caller-provided  P2PSwapper  contract,  which  can  have  arbitrary  functionality.  This  means  that  now  a liquidator  can  ensure  that  the  swap  is  executed  at  the  worst  price  that  still  passes  the  fairness  check, even  without  manipulating  the  Uniswap  market  price.  This  means  the  costs  of  \"sandwiching\"  are  now lower.  However,    also  introduces  partial  liquidations,  which  allows  setting  a  tighter  slippage bound for liquidations.  The  conclusion  that  transactions  executable  by  anyone  should  be  expected  to  clear  at  the  worst acceptable price with no surplus still holds.  A  MarginDex  implementation  that  includes  an  auction  mechanism  could  be  added  in  the  future  to improve this.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.9   Slippage Limit Considerations",
        "body": "  The liquidate_slippage is a critical parameter that can be set per token pair by the Vault admin. It is used to set the min_amount_out of swaps such as liquidations to an amount corresponding to the most recent oracle price minus liquidate_slippage.  We illustrate this using the following example:   The current Oracle price of ETH/USDC is 1000   The liquidate_slippage is set to 5%   A position of 1 ETH needs to be liquidated   This will result in a swap with min_amount_out of 950 USDC  The liquidate_slippage must not be set too large nor too small.  If it is too large, the min_amount_out may be less than the amount needed to close the position without creating bad debt. Even if it does not create bad debt, it can lead to bad trade execution for the trader. Note that liquidations should always be expected to clear at min_amount_out with no surplus. See also Sandwiching order execution.  If  the  liquidate_slippage  is  set  too  small,  the  swap  will  revert.  This  will  make  it  impossible  to liquidate the position until the oracle price updates or liquidity on Uniswap improves. Delayed liquidations could lead to bad debt for the system. Slippage being too small should mostly be a problem if a position is very large compared to the liquidity on Arbitrum Uniswap, see also Large Liquidations Can Fail.  bad   debt,   avoid   liquidate_slippage   To  at  most overcollateralization  -  oracle_max_move,  where  overcollateralization  can  be calculated as 1/(max_leverage+1), since liquidations will be triggered once a position hits a leverage ratio of max_leverage+1. The oracle_max_move is the maximum percentage that the oracle price is expected to move within a single oracle update. For example, if the max_leverage on ETH/USDC was 9x (10% overcollateralization) and the oracle price is expected to move at most 5% in one update, then a slippage limit up to 5% would ensure there cannot be any debt caused by a liquidation, as long as the oracle_max_move assumption holds.  should   set   be   to   Note that the above calculation only ensures that the liquidate_slippage is not too large, it may still result  in  a  limit  that  is  too  small,  which  could  lead  to  delays  in  liquidations.  Also  note  that oracle_max_move may be difficult to predict in the case of a black swan event such as a flash crash, chain congestion, or the Arbitrum sequencer going down.  Unstoppable - Unstoppable Margin Dex -   39  Version2Version2NoteVersion1    \fUpdated behavior:  In  as now a liquidation can be split into multiple smaller trades with lower price impact.  , partial liquidations were introduced. This allows setting tighter slippage limits than behavior,  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.10   Unintuitive Max_Leverage Definition",
        "body": "  The  max_leverage  per  token  pair  can  be  set  by  the  Vault  admin.  Note  that  the  max_leverage  is defined as follows:   Once the leverage of a position reaches max_leverage + 1, it is liquidatable.  For example, if max_leverage is 10, a position with 10.99 leverage will not be liquidatable. It will be liquidatable once it reaches leverage 11.  The admin setting the leverage parameter, as well as anyone analyzing the risk of the system, must take this unintuitive definition into account.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.11   User Pays Liquidation Penalty on Positive",
        "body": " Slippage  During a liquidation, a penalty is charged as a percentage of the debt tokens paid back. However, the number  of  debt  tokens  paid  back  is  not  capped  by  the  user's  debt  and  can  be  slightly  larger  (when actual_debt_in > position_debt_amount).  The user will end up paying the liquidation penalty on any unexpected excess that they receive.  Unstoppable - Unstoppable Margin Dex -   40  Version2NoteVersion1NoteVersion2        \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Redundant External Calls",
        "body": "  The  function  calculateTargetSupply()  makes  redundant  calls  to  the  interest  strategy  contract  to get  the  variableRateSlope1  value.  It  would  be  more  efficient  if  the  return  value  of  the  first  call  is stored in memory, hence avoiding the second call.  Similarly,  the  function  exec()  makes  two  external  calls  to  get  the  total  debt  (from  stableDebt  and variableDebt),  and  then  calls  the  calculateTargetSupply()  which  makes  again  the  same external function calls.  Acknowledged:  Maker acknowledges:  This function is only called by a keeper bot, and likely infrequently enough to not overly worry about gas savings. Will re-assess if exec() starts getting called a lot.  MakerDAO - D3M -   9  DesignCorrectnessCriticalHighMediumLowAcknowledgedDesignLowVersion1Acknowledged            \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings  -Severity Findings  ink Used as daiDebt   0  0  0  1  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   ink Used as daiDebt",
        "body": "  Function _unwind() contains following comment:  // IMPORTANT: this function assumes Vat rate of this ilk will always be == 1 * RAY (no fees).  This means the debt in art equals the amount in DAI.  The value for daiDebt is queried as follows:  if (mode == Mode.NORMAL) {     // Normal mode or module just caged (no culled)     // debt is obtained from CDP ink (or art which is the same)     (daiDebt,) = vat.urns(ilk, address(this));  Note that the first return value is the ink while the second one is the art. Hence the ink and not the art is used as value for the debt in DAI. As documented, this requires that the rate for the collateral is 1. However, additionally it is required that the spot price of the collateral must always be 1. This is not fully documented.  In Function reap the daiDebt is the art:  (, uint256 daiDebt) = vat.urns(ilk, address(this));    The value for daiDebt in function _unwind is now based on the art of the CDP.  MakerDAO - D3M -   10  CriticalHighMediumLowCodeCorrectedCorrectnessLowVersion1CodeCorrected         \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Possible Overflow for 2 ** 255",
        "body": "  The functions _unwind(), exit(), cull() and quit() check if a conversion of a uint256 value to  a  negative  int256  overflows:  require(value  <=  2  **  255).  Theoretically,  if value == 2 ** 255 the overflow will happen twice, but the result matches the expected value in such cases.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Shutdown Vat and exit()",
        "body": "  exit() does not explicitly check whether the Vat is not live. Technically this seems to be unnecessary as during normal operation only this contract can have a non-zero entry for this special gem. However given that it's so unlikely that the exit function is used and the dire consequences if for any other reason an  account  has  a  non-zero  balance  of  this  gem,  it  is  worth  considering  adding  the  explicit  check  as  a precautionary measure.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Shutdown of Vat",
        "body": "  In case of a shutdown of the Vat, the ideal scenario for this module is that all its debt can be unwound in the first phase of the shutdown.  Should  this  not  be  possible,  e.g.  because  there  was  no  sufficient  liquidity  in  the  Aave  pool  or  no  one called  exec  before  MCD_END.debt()  was  set,  the  settlement  of  the  remaining  DAI  holders  gets complicated:  In this phase of the settlement, users receive a share of all ilks. These shares are jointly worth one DAI for each DAI redeemed by the user. These shares will include the collateral share of this special ilk. For this ilk, special handling is necessary. However, after some steps, users have a Vat.gem balance which they can exit.  For this special ilk no join adapter exists and users will have to use the exit() function of this contract and receive aDAI.  Two scenarios can happen:   This aDAI is worthless as there is no liquidity in the aDAI pool and users are unable to redeem their aDAI for DAI. This could happen because free DAI have been submitted in the shutdown process. During  global  settlement,  however,  the  price  of  one  aDAI  was  taken  as  1  DAI.  The  overall consequence is that users receive less than one dollar worth of collaterals for 1 DAI \"cashed out\".   There  is  remaining  liquidity  in  the  Aave  pool  and  users  can  redeem  their  aDAI  for  DAI.  Having received this new DAI, the user can now redeem this DAI, again receiving a share of all collaterals including aDAI again. Note that, as many ilks exist, in practice this will be a very small percentage overall. Hence users may do following workaround:  MakerDAO - D3M -   11  NoteVersion1NoteVersion1NoteVersion1          \f1. Exit their share of the gem for this special ilk and receive aDAI first.  2. Convert this aDAI to DAI by withdrawing from the pool.  3. Redeeming this DAI. This increases the gem balance of the users for all ilks.  4. Only  now  exit  the  other  gems.  The  aDAI  received  at  this  step  may  be  forfeited  as  their value like is negligible and the user was able to redeem his DAI for collateral being worth close to 1 dollar.  MakerDAO - D3M -   12  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Hook Adjustments Can Be Unbacked",
        "body": "  CS-DFM-001  Negative hook adjustments can create extra incentives for users. However, they have to be backed by earlier burns (or by earlier positive hook adjustments). However, the positive hook adjustments are also included in the fees. Thus, there is positive hook adjustments can be double-spent.  Consider the following example:  1. Assume that fees are freshly collected over all markets so that no interest is pending and so that minted  =  total_debt  +  redeemed  (for  simplicity).  Assume  that  total_debt  =  100  and redeemed = 100 so that minted = 200.  2. Alice creates a loan of 100. The debt adjustment is set to 100. Thus, Alice creates a loan of 200 that  and  mints  100.  Hence,  total_debt  =  300  and  minted  =  300.  Note,  hook_debt_adjustment is increase by 100, too.  3. Ultimately,   collected  100 = total_debt + redeemed - minted tokens are minted.  (with   fees   are   an   empty  market   list)   again   and  4. Now  Bob  performs  an  action  that  has  a  negative  debt  adjustment.  Ultimately,  the  rebate  will  be  based on already spent amounts.  To summarize, it can be possible that hook debt adjustments and fees lead to double-minting so the hook limitations are not working as intended.    The code has been adjusted. Now it is ensured that this double counting does not occur.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Bad Interface Used in MarketViews",
        "body": "  The  newly  introduced  MarketViews  tries  to  call  AMM.collateral_balance  as  defined  in  the interface. However, that function has been removed from the AMM as of   .  CS-DFM-031    The code now uses the ERC20.balanceOf function.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Hook Debt Increase",
        "body": "  DeFi.Money - DFM Core -   16  CS-DFM-032  CodeCorrectedCodeCorrectedCodeCorrectedCorrectnessMediumVersion1CodeCorrectedCorrectnessLowVersion3CodeCorrectedVersion2CorrectnessLowVersion2CodeCorrected                        \fThe increase_hook_debt function changes the fees currently available to the system which may lead to a loss of debt adjustments.  Consider the following example:  1. Assume   that  minted  =  1000,  redeemed  =  500,  total_debt  =  1500  and  total_hook_debt = 0.  2. Note that this implies that 1000 = 1500 + 500 - 0 - 1000 fees are available.  3. Alice increases the hook debt. Now, total_hook_debt = 200.  4. That  implies  that  800  =  1500  +  500  -  200  -  1000  fees  are  available.  200  has  become  unavailable as fees.  5. Now, consider that the hook is removed. That would add 200 back. However, 200 would ultimately  be lost.  Due  to  violating  the  property  that  an  increase  of  the  debt  hook  should  not  affect  the  fees,  tokens  are burned and not collected as fees. It is possible for attackers to withold fees from the fee recipient.  Note  that  Alice  could  also  increase  the  hook  debt  by  more,  using  tokens  being  external  of  this accounting, leading to an underflow that would DOS collect_fees for a while. (Imagine here having a total_hook_debt = 1000)    The code has been corrected by increasing redeemed by the increase amount.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   AMM Migration",
        "body": "  Setting AMM hooks might lead to dangerous scenarios. Especially, since there is a strict equality in the comparison of pre- and post-collateral balances.  CS-DFM-002  assert AMM(amm).collateral_balance() == amount, \"DFM:C balance changed\"  Consider, the following scenarios:  1. The hook invests WETH in stETH. Due to the rebasing nature of stETH, transfers are not accurate. Thus,  the  new  collateral  balance  of  the  AMM  will  slightly  decrease.  However,  that  could  be  fixed with simple donations.  2. Governance wants to update the hook. But someone donated pre-execution a small amount to the  hook. That may DOS governance actions. However, that can be fixed in different ways.  3. There is an exit fee in an external system used. That cannot be handled.  4. A  hook's  collateral  balance  function  could  be  broken  and  return  wrong  results.  Technically,  that could be also fixed by setting an intermediate exchange hook with a temporarily broken mechanism and fixing later on (e.g. upgrade, storage variable or similar).  Ultimately,  the  strict  equality  may  lead  to  migration  problems.  The  mechanism  can  be  dangerous  - especially due to the strict equality.    DeFi.Money - DFM Core -   17  DesignLowVersion1CodeCorrected        \fAmm hooks were removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Decreasing Hook Adjustments",
        "body": "  The hook debt adjustments can be increased by arbitrary parties. However, they can be decreased only by  hooks.  In  case  the  governance  decides  to  deactivate  hooks,  tokens  could  be  unretrievable.  Thus, there is a lack of decreasing options for hook adjustments.  CS-DFM-003    The hook adjustment can be reduced by removing the hook.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Errors in Controller Simulations",
        "body": "  The MainController's get_close_loan_amounts() and get_liquidation_amounts() incorrectly return  an  adjusted  amount  of  debt  repaid.  Namely,  both  functions  compute  total_debt_repaid  as debt  +  hook_adjustment.  However,  in  both  the  closing  of  loans  and  the  adjustment  of  loans,  the hook adjustment is used to increase/decrease the burned amount. The repaid debt is not affected by the hook adjustment.  CS-DFM-004    The code now correctly returns the data.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Failure of Returning Market Data",
        "body": "  The get_market() and get_amm() functions in the MainController try to return 0x0 for indexes that are out of the array's bounds.  CS-DFM-005  if i > len(self.collateral_markets[collateral]):     return empty(address)  However, if i == len(...), the array is also accessed out of bounds.    Code corrected by changing the condition to i >= len(...).  DeFi.Money - DFM Core -   18  DesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                          \f6.8   Flashmint Breaks Previous Assumptions  In our previous audit of Curve stablecoin, the assumption is made that the total balances are smaller than 2**127.  This  assumption  is  broken  by  the  Flashmint  function,  which  can  mint  an  arbitrary  amount  of tokens.  CS-DFM-006    maxFlashLoan was overridden to be limited to 2**127 - totalSupply().  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   Inconsistent Parameter Validation",
        "body": " Governance Functions  CS-DFM-007  market   The  and change_market_monetary_policy() are not validated to be existing markets. That is inconsistent with other governance functions which do not allow operating on non-existing markets.  set_market_hooks()   parameter   passed   to     A new internal function _assert_market_exists() was added to validate the market parameter. This function  is  called  from  set_market_hooks()  (more  specifically,  the  functions  that  replaced set_market_hooks())  and  change_market_monetary_policy()  to  ensure  the  market  exists before proceeding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   Interface Incompleteness",
        "body": "  The interface ICoreOwner does not have the method feeReceiver that is used in the implementation of the MarketController and the PegKeeper.  CS-DFM-008    ICoreOwner  was  deleted  and  replaced  by  IProtocolCore.  This  new  interface  implements  required methods for all contract in scope.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.11   NG Pools Are Not Supported by PegKeepers",
        "body": "  CS-DFM-009  DeFi.Money - DFM Core -   19  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                              \fThe  supported  signatures  supported  by  PegKeepers  are  using  uint256[2]  whereas DynArray[uint256, 8] is used for the CurveStableSwapNG pools.  The PegKeepers are in consequence only supporting old pools types.    The Curve interface was updated to support the CurveStableSwapNG pools.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.12   Reentrancy Locks",
        "body": "  CS-DFM-010  Some  external  calls  to  the  collateral  token  deviate  from  the  checks-effects-interactions  pattern.  If  no reentrancy  lock  is  present,  these  calls  might  introduce  reentrancy  possibilities  (especially  read reentrancies)  before  the  state  is  fully  updated.  We  could  not  find  a  case  where  the  non-updated  state might  be  the relevant  checks-effects-interactions pattern.  it  might  be  worth  considering   information.  Still,   fully  adhering   to   Further, the reentrancy locks appear to be set inconsistently. We cannot see the underlying logic of how they are added. For example, some governance setters have a nonreentrant decorator and some do not.  Please see 6.1 of our crvUSD report.  Specification changed:  DeFi.Money specified that no token and no hook will have callbacks to untrusted addresses.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.13   Remaining Mintable Wrong",
        "body": "  MainController.get_market_states()  computes  and  aggregates  data  of  input  markets. However, when computing the amount that is mintable based on the global debt ceiling and global debt, the pending interest is not included. Thus, the estimation of the remaining mintable amount could be off. Note that the interest is accounted for in the market-specific mintable amount.  CS-DFM-011    The getter now includes the pending interest for a given market when checking against the global debt ceiling.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.14   Rounding up",
        "body": "  The  MarketOperator.min_collateral  should  round  up  to  the  nearest  integer  to  ensure  that  the returned value is not below the minimum. For reference, note that Curve implements rounding up.  CS-DFM-012  DeFi.Money - DFM Core -   20  DesignLowVersion1Speci\ufb01cationChangedCorrectnessLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                        \fFurther, note that rounding of debt is not done in favor of the system. In contrast, Curve rounds the debt of users in favour of the system. As a consequence, for DFM Core, sum(user_debt) < total_debt can  also  hold  in  certain  situations.  That  may  not  allow  for  graceful  exits  of  the  system  and  may  leave some  dust  in  total_debt.  In  contrast,  Curve  ensures  that  sum(user_debt)  >=  total_debt (rounding up errors, however requiring to handle user_debt > total_debt) on repays.    The  function  MarketOperator.min_collateral  has  been  updated  to  round  up  to  the  nearest integer.  The  case  where  sum(user_debt)  <  total_debt  holds  is  solved  by  adding  this  dust  to  the debt_adjustement variable if the last user is repaying (or being liquidated). This ensures that the total debt is always zeroed out when no more users are in the system.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.15   _price_in_range Can Suffer From",
        "body": " Over/Underflow  PegKeeperRegulator._price_in_range  can  suffer  from  over/underflow  with  potential  price manipulation in the following code:  CS-DFM-013  return unsafe_sub(unsafe_add(deviation, _p0), _p1) < deviation << 1  Assume  that  the  deviation  is  1000.  Set  the  _p0  to  max_value(uint256)  and  _p1  to  10  or  visa versa, the result will be True because of the over/underflow. Note that due to flashminting high amounts such prices might be possible.    This  is  no  longer  possible  since  the  flashminting  feature  has  been  reduced  to  fit  the  max  balance assumption of 2**127.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.16   Built-in Min Value Can Be Used",
        "body": "  In  MainController._adjust_loan_bounds(),  -2**255  is  used  to  define  the  min  value,  for consistency with the max value, it can be replaced with min_value(int256).  CS-DFM-014    The code has been adjusted accordingly.  DeFi.Money - DFM Core -   21  CorrectnessLowVersion1CodeCorrectedInformationalVersion1CodeCorrected                \f6.17   Error Message Can Be Misleading  In the MainController.get_pending_market_state_for_account(), the first assertion checks the  following  condition:  convert(debt,  int256)  +  debt_change  >  0.  This  assertion  is  correct however the error message can be misleading since the sum can be zero and it will still fail. The error message should be updated to reflect this.  CS-DFM-015    The error message has been adjusted to reflect that the value is non-positive.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.18   Event Improvements",
        "body": "  Some events can be improved:  1. The  SetImplementations  event  in  the  MainController  does  not  log  for  which  A  the  new implementations are set. This is a problem because the MainController can have different A-s and it is not clear for which A the new implementations are set.  2. When a loan is manipulated (through the MainController), three different events can be emitted (CreateLoan, AdjustLoan, CloseLoan). However, none of these events include the address of the  caller  (not  necessarily  the  same  as  the  account),  which  obfuscates  the  origin  of  the manipulation (delegation or not).  CS-DFM-016    The events emit the additional data.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.19   Getter Lacks Dynamic Fee",
        "body": "  get_amount_for_price computes the amount that needs to be exchanged to reach a given price in the  AMM.  However,  the  computation  lacks  the  dynamic  fee  and  thus  might  be  imprecise.  In  contrast, Curve includes an estimation with the dynamic fee.  CS-DFM-018    The  code  has  been  adjusted  to  include  the  dynamic  fee  and  corrsponds  now  to  the  Curve implementation.  DeFi.Money - DFM Core -   22  InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected                  \f6.20   Inconsistent Rate Updates  The  loan-adjusting  functions  inconsistently  update  the  rate.  Namely,  the  _update_rate()  occurs typically  after  minted  or  redeemed  has  been  updated.  However,  for  adjust_loan()  and collect_fees  that  occurs  earlier.  Thus,  there  is  an  inconsistency  in  execution.  While  that  has  no impact on the monetary policy in scope, future monetary policies could rely on correct values (should rely on consistent updates of these).  Note  that  mints,  burns  and  transfers  typically  occur  after  the  rate  updates.  The  rate  will  not  have  the ability to update according to ERC20 balances reliably.  CS-DFM-019    The code has been adjusted to update the rate always as the last operation. Note that in any case it is not  expected  that  data  of  hooks  is  relevant  for  the  rate  updates  (e.g.  increase  and  decrease  of  hook debt).  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.21   Log Precision and Efficiency Could Be",
        "body": " Increased  Curve upgraded the log2 to logn for log calculations. This makes the log calculations more consistent between the AMM (already using logn) and the MarketOperator (using log2) but also makes it more gas efficient.  CS-DFM-020    The code is corrected and the log calculations were upgraded to logn.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.22   No MAX_RATE Limitation for Monetary",
        "body": " Policies  The monetary policies could return unexpectedly high values. Limiting these values in the main controller could help reduce the impact of errors in future monetary policies.  Note,  that  the  forked  code  of  code  has  a  MAX_RATE  parameter  that  limits  the  value  returned  by  the monetary policies.  CS-DFM-022    The rate updates done by the MainController now validate against a MAX_RATE.  DeFi.Money - DFM Core -   23  InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected                  \f6.23   Overflow With Threshold  The peg keeper regulator disables liquidity provisions as follows:  if largest_price < unsafe_sub(price, self.worst_price_threshold):     return 0  Note that price could be very low in case of a severe depeg. While not providing liquidity in such cases might be reasonable, the behaviour of worst_price_threshold is undocumented.  CS-DFM-023  Specification Changed:  An explanatory comment has been provided. In case of an underflow, no liquidity will be provided.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.24   Sanity Check off by One",
        "body": "  add_market() enforces that  assert admin_fee < MAX_ADMIN_FEE  CS-DFM-024  Note  that  100%  however  would  be  a  legitimate  value.  That  would  make  the  initialization  of  a  market consistent with the market operator's set_amm_admin_fee() function.    The check validates now that it is <= instead of <.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.25   Specification Mismatches",
        "body": "  The  functionality  is  documented  as  NatSpec  or  as  comments.  The  following  errors  and  imprecise descriptions were uncovered:  1. get_market and get_amm specify:  CS-DFM-025  Iterate over several amms for collateral if needed  However, they do not iterate but only access the i-th element.  2. The NatSpec of get_market_states_for_account specifies:  Account health (liquidation is possible at 0),  However, liquidations are possible at health < 0.  DeFi.Money - DFM Core -   24  InformationalVersion1Speci\ufb01cationChangedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected                \f3. A comment in collect_fees specifies:  # Difference between to_be_redeemed and minted amount is exactly due to interest charged  However, technically, the fee could be also charged due to a hook.  4. A comment in AMM.__init__ specifies:  # sqrt(A / (A - 1)) - needs to be pre-calculated externally  However, this is not the case anymore.  5. A comment in AMM.__init__ specifies:  # 18 decimals: math.log2(10**10) == 59.7  However, the log is of 10**18.  6. The specification of AggMonetaryPolicy2.TARGET_REMAINDER specifies that the rate is scaled  by two at 90% utilization of the debt ceiling. However, it is scaled by a factor of 1.9.   All the above issues were corrected.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.26   Target Debt Fraction Zero",
        "body": "  The constructor of the monetary policy allows target_debt_fraction = 0. However, that may lead to divisions-by-zero in calculate_rate. Furthermore, it could make it would make it more consistent with the setter of the target debt fraction.  CS-DFM-026    The code has been adapted to ensure that target_debt_fraction > 0.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.27   Unused Variables",
        "body": "  The following variables are defined but not used in the code:  1. MarketOperator.STABLECOIN  2. MarketOperator.MAX_RATE  3. PegKeeper.ADMIN_ACTIONS_DELAY  4. MainController.MAX_ACTIVE_BAND  CS-DFM-027  Also, note that AMM.BORROWED_PRECISION is used and defined but has no effect and, thus, increases the size of the bytecode unnecessarily.  DeFi.Money - DFM Core -   25  InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected            \f  The unused variables have been removed. The borrowed precision in the AMM is not used anymore.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.28   PegKeeperRegulator.aggregator Could",
        "body": " Be Immutable  PegKeeperRegulator.aggregator could be immutable since it's never updated after initialization.  CS-DFM-028    The aggregator is now an immutable.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.29   _call_view_hooks Is Inconsistent",
        "body": "  _call_view_hooks  is  inconsistent  with  _call_hooks.  Namely,  the  latter  asserts  the  bounds  and limits only when the adjustment is non-zero. Even though the result will be the same, having the same execution flow for both functions may help improve maintainability and consistency.  CS-DFM-029    The code has been adjusted to be more consistent.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.30   max_borrowable Might Return Incorrect",
        "body": " Values  CS-DFM-030  Since  MarketOperator.max_borrowable  doesn't  check  range  of MIN/MAX _TICKS, it will return non-zero values for n_bands that are out of the range, even though the market does not support them.  if  n_bands   the   in   is     The code has been corrected to only accept valid n_bands values.  DeFi.Money - DFM Core -   26  InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected                  \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Events Not Emitted",
        "body": "  Event emissions can help retrieve data. While the smart contracts typically emit events, the events are not always emitted. Below is a (potentially incomplete) list where logging is missing:  1. MainController.__init__: Adds monetary policies but does not emit AddMonetaryPolicy.  CS-DFM-017  2. MarketOperator.initialize: Does not emit any relevant event.  3. AMM.initialize: Does not emit any relevant event.  4. StableCoin.setMinter: Does not emit any relevant event.  Code partially corrected:  All but 3. have been implemented. Note that the MainController when initializing also does not the events for the AMM initialization values.  Acknowledged::  DeFi.Money acknowledged 3.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   NatSpec Problems",
        "body": "  NatSpec can help document the code. While the codebase has quite a lot of NatSpec, much is missing. Note that NatSpec can also help frontends such as Etherscan show details about the functions.  CS-DFM-021  Below is a list of examples of missing NatSpec or NatSpec errors:  1. setDelegateApproval lacks parameter documentation.  2. Similarly, that is the case for change_existing_monetary_policy.  3. stored_admin_fees does not define an @return.  4. _calculate_debt_n1 does not include amm and price.  5. adjust_loan in MarketOperator is missing.  Note  that  these  examples  are  not  a  complete  list.  We  would  highly  encourage  to  check  for  more occurrences (and complete the NatSpec at least for the external-facing functions).  Code partially corrected:  The NatSpec documentation has been improved. Nevertheless, some NatSpec is incomplete.  DeFi.Money - DFM Core -   27  InformationalVersion1CodePartiallyCorrectedAcknowledgedInformationalVersion1CodePartiallyCorrectedAcknowledged              \fAcknowledged:  DeFi.Money acknowledged the above.  DeFi.Money - DFM Core -   28  \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Batched Getters Get Results for Independent",
        "body": " Executions  Users  of  public  getters  should  be  aware  that  the  getters  such  as  get_market_states()  do  not consider the actions to be sequentially executed. More formally, the iterations are independent of each other and do not affect each other.  Similarly, that is the case for get_liquidation_amounts() where the hook debt adjustments could be depending on the previous iterations. Thus, a user should not expect the result to be the same when the same batch is liquidated iteratively.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Bridge Pausing",
        "body": "  Note  that  the  OFT  bridging  functionality  can  be  paused.  Pausing  should  be  always  be  considered carefully due to the possibility of pending messages.  Further, note that the view functions are not pause (e.g. quoting functions) and will return values under the assumption that the bridge is not paused.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.3   Changing the Address of Monetary Policy",
        "body": "  Note that due to gas reasons, the rate is not updated on AMMs when the address that a mp_idx points is changed. The consequence is, that the old rate will be used. The new monetary policy will be actually used  for  a  market  after  the  first  interaction  with  a  market  or  when  collecting  fees  (note  that  NatSpec recommends doing this, too).  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.4   Changing the Implementation for an A",
        "body": "  Users should be aware that the implementation can change for an A. However, that does not impact the implementation of already deployed markets.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.5   Debt Ceilings",
        "body": "  DeFi.Money - DFM Core -   29  NoteVersion1NoteVersion1NoteVersion1NoteVersion1NoteVersion1                  \fA  debt  ceiling  is  put  in  place  for  each  market.  Additionally,  a  global  debt  ceiling  is  present  that  works across all markets. It's worth noting that these ceilings are not strict limits. Namely, both ceiling types may be exceeded due to interest generated. For the global ceiling, the interest generated by all markets will have an impact on the ceiled debt. Note that the codebase does not account for the interest of all markets when trying to bound the debt ceiling (that is expected due to gas).  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.6   Insufficient Validation",
        "body": "  Note  when  setting  new  implementations  the  A  is  validated.  Similarly,  when  setting  the  oracle  the  read price and the written price are ensured to be equal. However, users and governance should be aware that these checks are helpful sanity checks but do not guarantee the correctness of these contracts in the future.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.7   Jumps in Monetary Policy",
        "body": "  Users  and  governance  should  be  aware  that  the  monetary  policy  might  have  high  jumps  in  interest  in case of infrequent updates. More specifically:  1. The monetary policy depends on the total market debt. However, that value might be outdated in  case some market has not been touched for a long time.  2. The monetary policy depends on the stablecoin price. If the price changes between rate updates,  the interest rate might have high jumps.  In case all markets are active, the interest rate should be relatively smooth for the case mentioned above.  Also jumps in rate can happen every time a new monetary policy is set. This is hardly predictable for a user, but he must be aware that the rate could change at any time.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.8   Market Hook Behaviour and Impact",
        "body": "  The market and global hooks' return values are limited to safe amounts for the protocol. However, the hooks  can  have  a  great  impact  on  the  execution  flows  of  the  smart  contracts.  Below  is  a  list  of considerations:  1. Hooks can increase the debt users and charge very much.  2. Hooks can make the protocol unsafe by reverting (e.g. blocking liquidations).  3. Hooks can make weird execution paths more profitable (e.g. repay 50% of debt and then close the  loan could be the better option than just closing the loan).  4. The view-hooks should always return the value that the write-hooks return.  Governance should carefully design the hooks. Note that the list above might be incomplete.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.9   Oracle Considerations",
        "body": "  DeFi.Money - DFM Core -   30  NoteVersion1NoteVersion1NoteVersion1NoteVersion1                \fOracles should be secure. Insecure oracles or bad ones may lead to breaking assumptions (as in Curve).  Note  that  besides  the  Curve  assumptions,  one  has  been  added.  Namely,  the  non-view  price  function should always return the same value as the view function (in any order in the same trace of an entry-point of the system).  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.10   Pausing Main Controller",
        "body": "  close_loan  and  liquidate  cannot  be  paused  as  these  reduce  the  debt.  However,  note  that adjust_loan could be technically also allowed when only the debt is reduced.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.11   Peg Keeper Considerations",
        "body": "  The  pegkeeping  mechanism  tries  to  allocate  liquidity  to  pools  with  other  stablecoins  so  that  liquidity  is provided at the peg. Users and governance should be aware of the following behaviour:   The market conditions may not allow to withdraw the provided liquidity (or to ever provide liquidity). Note  that  this  implies  that  the  peg  keepers  may  not  be  removable  (due  to  the  non-zero  debt checks).   The  regulator  does  not  try  to  steer  peg  keepers  to  withdrawals,  if  the  debt  ceiling  has  been  reduced and owed debt is outstanding.   With  the  migration  of  pegkeepers  to  a  new  regulator,  the  behaviour  of  the  mechanism  may  significantly change.   Governance should assign the stablecoin minter role to the new regulator and remove it from the  old one when a regulator migration occurs.  Further, note that the other stablecoins might lose their peg which may impact the peg.  DeFi.Money - DFM Core -   31  NoteVersion1NoteVersion1        \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Circumvention of Ramping",
        "body": "  The management account of Pool can initiate a change of asset weights or the amplification factor for a pool.  The  change  should  be  applied  slowly  to  minimize  profits  from  sandwiching  attacks,  see Sandwiching  Curve  changes.  However,  the  function  add_asset  allows  the  management  to  modify (reduce)  the  weights  of  assets  and  the  amplification  factor  by  avoiding  the  ramping  limitations  entirely. The natspec description of the function notes:  @dev Every other asset will have their weight reduced pro rata @dev Caller should assure that effective amplification before and after call are the same  Code partially corrected:  The function add_asset now sets an upper limit of 1% on the initial weight of the new asset being added to  the  pool.  Although  this  reduces  the  likelihood  of  accidentally  changing  the  weights  of  assets  Yearn - Yearn yETH -   11  SecurityDesignCorrectnessCriticalHighMediumCodePartiallyCorrectedLowAcknowledgedAcknowledgedCodePartiallyCorrectedAcknowledgedCodePartiallyCorrectedRiskAcceptedRiskAcceptedAcknowledgedAcknowledgedDesignMediumVersion1CodePartiallyCorrected             \fsignificantly, it does not enforce any restriction on the amplification factor (_amplification represents the  term  A  *  f^n  in  the  whitepaper).  Therefore,  management  should  consider  sandwiching  attacks when calling this function and carefully choose input parameters. The response of Yearn is:  Added a limit to the new asset weight, it is not allowed to exceed 1%. Since the `amplification` in the pool represents 'A * f^n', we cannot easily put bounds on the amplification factor. It is up to the management role to make sure the call cannot be sandwiched, either by picking a new amplification factor and initial weight (even lower than 1%) that minimises the effect or by first pausing the pool and in a separate call add the asset before unpausing.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Decreasing Pool Value Through Rate Updates",
        "body": "  Big rate updates might drain value from the pool. Assuming a swap_fee of 0.3%, then a rate update of 1% (e.g. from 1.00 -> 1.01) seems already too big. Generally, it seems that any rate change twice as big as the swap_fee (so any rate change >= 0.6% for a swap_fee of 0.3%) leads to this issue.  We provide an example with three assets. In the beginning, everything is balanced and the rates are all ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "1.00. Now, the pool can lose value in the following way:",
        "body": "   The price of asset 2 in the market rises from 1.00 -> 1.01   Assuming  an  efficient  market,  trades  happen  inside  the  pool  which  imbalance  the  pool  so  that get_dy(2, 0, 10**18) == get_dy(2, 1, 10**18) == 1.01 * 10**18. (If such trades do not happen an attacker can front-run the rate update with such trades.) Here the pool is selling asset 2 too cheaply.   Now the rate update is performed, setting the rate of asset 2 from 1.00 -> 1.01.   As  a  consequence,   (and asset 2 => asset 0), will now go to roughly 1.02. The pool is paying too much to obtain asset 2.  from  asset  2  =>  asset  1   the  pool's  exchange   rate    Therefore an attacker trail-runs the rate update and sells asset 2 to the pool.   Eventually, the price of asset 2 goes back down from 1.01 -> 1.00.   Again  trades  happen  which  change  the  balance  of  the  pool  so  that  it  has  a  1:1  exchange  ratio  between the assets. Here the attacker or others sell asset 2 to the pool.   Now the rate update is performed, setting the rate of asset 2 from 1.01 -> 1.00.  As a consequence, the pool's exchange rate is so that asset 2 can be bought too cheaply. Hence, the attacker  buys  asset  2  cheaply.  After  all,  trades  are  settled,  the  pool  has  fewer  funds  than  at  the beginning.  In  this  example,  they  might  have  lost  0.3%  of  value.  As  a  consequence,  the  balance  in  the Staking contract is now smaller, even though all prices are the same as in the beginning.  Generally, the significance of this issue depends on different parameters, like number of assets, weights and amplification factor. In some configurations, it will be more severe than in others. A combination of smaller, parallel rate updates for different assets might also be problematic.  Acknowledged  Yearn  is  aware  of  the  issue  and  acknowledges  it.  They  will  take  care  to  mitigate  it  by  only  using high-quality rate providers that return the backing rate on the beacon chain which they assume will not fluctuate  much  to  be  an  issue.  Additionally,  these  oracles  are  assumed  to  be  not  influenced  by  the market. Yearn emphasized that every oracle will be rigorously tested and simulated before being used.  Yearn - Yearn yETH -   12  DesignLowVersion1Acknowledged        \f5.3   Guardian Can Front-Run Kill Command  The guardian role in contract Pool can set or unset the paused flag, while only management can set the  flag  killed  to  true.  For  the  function  kill  to  execute  successfully,  the  flag  paused  should  be true. Therefore, guardian can prevent the execution of function kill by frontrunning the transaction with a call to function unpause.  Acknowledged:  Yearn  acknowledges  the  risk  of  frontrunning  and  accepts  the  consequences  of  the  attack  with  the following  reasoning:  \"In  the  unlikely  case  the  guardian  decides  to  grief  by  front-running  such  a  call, management has the option to replace the guardian\".  We  want  to  note  that  the  replacement  of  the  guardian  can  also  be  front-run  by  the  guardian  as set_guardian can be called by both roles.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.4   Implementation Mismatch With ERC-4626",
        "body": "  The  contract  Staking  implements  the  external  functions  specified  in  the  standard  ERC4626.  The implementation  of  functions  maxWithdraw  and  maxRedeem  is  not  in  line  with  the  standard.  Both functions return max_value(uint256), but the standard for maxWithdraw (similarly for maxRedeem) states:  MUST return the maximum amount of assets that could be transferred from ``owner``  through ``withdraw`` and not cause a revert, which MUST NOT be higher than the  actual maximum that would be accepted (it should underestimate if necessary).  MUST factor in both global and user-specific limits, like if withdrawals are  entirely disabled (even temporarily) it MUST return 0.  Code partially corrected:  Both functions have been updated in  can be withdrawn or redeemed by address _owner.   to return the maximum amount of assets or shares that  However,  the  special  case  when  totalSupply  cannot  be  less  than  MINIMUM_INITIAL_DEPOSIT  is not handled correctly. Therefore, it is possible that both functions maxWithdraw and maxRedeem return non-zero values, while the respective functions withdraw and redeem could revert, which violates the standard.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.5   Inefficient Initial Approximation Value for Pi in",
        "body": " Supply Calculation  Yearn - Yearn yETH -   13  SecurityLowVersion1AcknowledgedCorrectnessLowVersion1CodePartiallyCorrectedVersion3DesignLowVersion1Acknowledged                        \fWhen  a  rate  change  or  balance  change  occurs,  the  starting  value  for  pi  (vb  product),  to  later approximate the supply, is:  vb_prod * self._pow_up(prev_rate * PRECISION / rate, wn) / PRECISION  or  vb_prod_final * self._pow_up(prev_vb * PRECISION / vb, wn) / PRECISION  The result of this calculation is then passed into _calc_supply. In _calc_supply an iterative method is used to approximate the correct supply. Starting with the result as the first guess for r in:  r = unsafe_div(unsafe_mul(r, sp), s)  The initial guess seems inefficient and almost always dominated by the old value for pi as starting value.  Acknowledged:  Yearn replied:  The value for pi needs to be updated somewhere before or during the iteration process, as otherwise the supply will not converge to the correct value. It might be possible to save on iterations by updating pi to the correct value after the first iteration, but such a change would significantly complicate the function and as such is deemed not worth it.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.6   Missing Sanity Checks",
        "body": "  The following functions update important state variables but do not perform any sanity check on inputs.  Staking contract:  1. _asset in function __init__.  2. _fee_rate in function set_performance_fee_rate.  3. _management in function set_management.  4. _treasury in function set_treasury.  5.  6.  Pool contract:  : If _value is larger than current allowance, an underflow happens.  : _spender in functions that modify allowance.  7. _assets in function __init__ can include duplicate.  8. _duration in function set_ramp can be 0.  9. _rate_provider in function set_rate_provider.  10. _staking in function set_staking.  11. _guardian in function set_guardian.  12. _management in function set_management.  Yearn - Yearn yETH -   14  DesignLowVersion1CodePartiallyCorrectedVersion2Version2        \fCode partially corrected:  Missing sanity checks reported in the Staking contract have been added. Additionally, the same checks were applied in the Token contract. In the Pool contract sanity checks for points 10 and 12 were added. The sanity check for _guardian (point 11) is intentionally left out to allow for flexibility of burning the role in the future.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.7   Possible to Frontrun the First Deposit in Pool",
        "body": "  The first liquidity provider in a pool does not pay any fee. Other liquidity providers do not pay a fee only if they deposit tokens in the same ratio as the current state of the pool. If a user adds liquidity into a pool in an unbalanced manner (e.g., single token or with different ratios from the current state), a fee is payed.  An attacker can frontrun the first deposit to add tokens in a pool in a wrong ratio such that the victim user pays high fees. The fees are sent to the Staking contract and can be claimed after a delay by users that have  staked  their  yETH.  The  profits  of  the  attacker  depend  on  the  amount  of  tokens  deposited  by  the victim  and  the  share  of  yETH  staked  by  the  attacker  at  the  time  rewards  (includes  fee)  move  to unlocked bucket in Staking contract.  Risk accepted:  Yearn replied:  This is acceptable behaviour, and can be mitigated by setting a very tight value for the minimum amount of tokens received for the initial deposit.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.8   Possible to Update Ramp Step While Ramping",
        "body": "  The  function  set_ramp_step  sets  a  new  ramp_step  without  checking  if  there  is  currently  an  active ramp. Raising ramp_step while there is an active ramp increases the risks of sandwiching attacks (see Sandwiching Curve changes) as the _duration of ramping remains the same.  Risk accepted:  Yearn replied:  We\u2019d like to retain the option to increase the step size, even during a ramp. However, management should take care not to increase it to such a degree that it affects the sandwich risk in a significant way. This is in line with the responsibilities the management account already has. It has the ability to set the duration of a ramp, which suffers from the same consequences if not set properly  Yearn - Yearn yETH -   15  DesignLowVersion1RiskAcceptedCorrectnessLowVersion1RiskAccepted                  \f5.9   Violation of Sum of Weights  The  trading  curve  is  defined  by  a  function  that  assumes  that  the  sum  of  all  weights  in  a  pool  equals PRECISION  (100%).  However,  this  invariant  does  not  apply  always  as  the  weights  of  assets  change when: i) adding a new asset, ii) updating weights in a ramp. Therefore, it is possible that these dynamic changes of weights break the invariant due to rounding errors. For instance, current is rounded down in the following code:  if current > target:     current = current - (current - target) * span / duration else:     current = current + (target - current) * span / duration  Acknowledged:  Yearn acknowledges the issue.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.10   Voting Weight Increase Differs for New and",
        "body": " Existing Positions  Transferring  shares  to  a  position  increases  the  voting  weight  of  the  receiving  position.  For  the  same amount  of  shares  transferred,  the  new  voting  weight  depends  on  the  existing  state  of  the  receiver, namely variable Weight.t.  The picture below plots voting power where x-axis is the time and y-axis is the voting weight. The blue line  illustrates  a  position  that  has  staked  25  shares  for  a  long  time.  If  this  position  receives  25  more shares, its voting power will change over time as shown by the red dashed line.  However,  if  25  shares  are  sent  to  a  new  position,  its  voting  weight  increases  according  to  the  violet dashed  line.  The  green  line  shows  the  difference  on  the  voting  weight  after  new  tokens  are  received between  an  existing  position  (red  dashed  line)  versus  existing  position  and  new  position  that  receives tokens (blue line and violet dashed line). The plot suggests that receiving shares in new positions instead of existing ones maximizes the voting weight of a party.  Acknowledged:  Yearn - Yearn yETH -   16  CorrectnessLowVersion1AcknowledgedCorrectnessLowVersion1Acknowledged              \fYearn replied:  This is an acceptable side effect of our choice to have a asymptotically increasing weight function.  Yearn - Yearn yETH -   17    \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  0  0  5  10  -Severity Findings  -Severity Findings  -Severity Findings  Incorrect Computation of Product Term    Missing Transfer of Tokens When Adding New Assets    Pool Might End up With Less Shares Than MINIMUM_INITIAL_DEPOSIT    Share Distribution Depends on First Deposit    Wrong Calculation of Voting Weight for Withdrawn Shares   -Severity Findings   Approve Can Be Frontrun    Default Target Weight   Incomplete Specifications for Paused Pool   Inconsistent Behavior of Conversion Function    Mismatch of Code With the Specification for Pending Rewards    Missing Slippage Protection When Adding New Asset    No Meaningful Revert Messages    Possible to Lock Management Role    Types of Variables in Weight    Unused Event in Staking   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Incorrect Computation of Product Term",
        "body": "  The product term pi in the whitepaper depends on D, w_i and x_i. The function _calc_vb_prod takes as input _s which is the sum of tokens in the Pool and is different from D if the pool is not at equilibrium point.  This issue was found by Yearn also while the review was ongoing.    function  _update_weights  has  been  updated   The  _calc_vb_prod as follows:  to  pass  supply  when  calling   function  Yearn - Yearn yETH -   18  CriticalHighMediumCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCorrectnessMediumVersion1CodeCorrected           \fsupply: uint256 = self.supply if supply > 0:     vb_prod = self._calc_vb_prod(supply)  Furthermore, the function _calc_vb_prod_sum, which is called on first deposit or when adding a new asset, is revised to not take _s (sum term) as an input parameter.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Missing Transfer of Tokens When Adding New",
        "body": " Assets  Function  add_asset  can  be  called  only  by  management  which  is  trusted  to  behave  correctly  in  the contract  Pool.  The  parameter  _amount  in  function  add_asset  is  the  amount  of  tokens  that  are deposited into the Pool when the new asset is added. However, the code does not pull the funds from an external  account  (if  approved)  or  check  that  the  Pool  has  already  the  required  balance  (if  already transferred).    The issue has been resolved by adding the code in function add_asset that pulls the respective tokens from msg.sender:  assert ERC20(_asset).transferFrom(msg.sender, self, _amount, default_return_value=True)  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Pool Might End up With Less Shares Than ",
        "body": " MINIMUM_INITIAL_DEPOSIT  The  new  MINIMUM_INITIAL_DEPOSIT  amount  does  not  mitigate  that  a  user  manipulates  the  share amount to be very low before another user deposits or rewards are accounted.  A malicious user might deposit MINIMUM_INITIAL_DEPOSIT tokens but could immediately call redeem in  such  a  way  that  they  end  up  with  one  remaining  share.  This  breaks  the  assumption  that  the  pool always has a minimum amount of assets, which could have unintended side effects.    The  internal  function  _withdraw  has  been  updated  in    to  enforce  that  totalSupply  in  the contract Staking is either 0 or larger than MINIMUM_INITIAL_DEPOSIT. This restriction is implemented in the following code:  if total_shares < MINIMUM_INITIAL_DEPOSIT:     assert total_shares == 0  Yearn - Yearn yETH -   19  CorrectnessMediumVersion1CodeCorrectedDesignMediumVersion1CodeCorrectedVersion3                  \f6.4   Share Distribution Depends on First Deposit  The user's shares when depositing an amount of yETH are calculated as:  _assets * _total_shares / _total_assets  However, in the case of the first deposit, the number of assets deposited is the number of shares the user receives. In case a user deposits a very small amount (at best 1 WEI), they would receive 1 share. When the total assets increase because profits are made, the fraction _total_shares / _total_assets will become 0 for amounts smaller than _total_assets. Additionally, when adding assets, they need to  be  multiples  of  _total_assets.  Hence,  the  first  deposit  determines  the  minimum  step  size  or rounding error for the following deposits.  The was independently reported by Yearn while the review was ongoing.    implemented  a  practical   Yearn  specifying  a  minimum  deposit  amount MINIMUM_INITIAL_DEPOSIT of 1e15 which makes the attack unlikely in practice. However, we would like to highlight that the core issue is still present even with this practical mitigation. The issue arises only in case of a high discrepancy between the first deposit and the potential rewards which now should be higher by a factor of 1e15.  solution  by   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Wrong Calculation of Voting Weight for",
        "body": " Withdrawn Shares  By depositing yETH into the Staking contract, users gain voting power that continuously increases over time.  The  voting  power  depends  on  the  amount  of  shares  a  user  has  and  the  time  they  have  been for  a  user:  weights  and deposited  previous_weights. weights track the latest state of a position, while previous_weight stores the state of the position in the week before latest changes.  the  contract.  The  contract  stores   two  checkpoints   in   The function vote_weight should consider previous_weights when the position is updated on the ongoing week. However, the code checks for two conditions as follows:  if weight.week > week or weight.week == 0:     weight = self.previous_weights[_account]  The  second  condition  is  true  for  users  that  have  withdrawn  or  transferred  out  all  their  shares.  In  this case, the code still considers their previous_weights and incorrectly computes a voting power based on the state of the position before its shares were removed. This can be exploited by attackers to create positions that gain voting power, and then move shares to a new position.  This issue was uncovered by Yearn also while the review was ongoing.  Code partially corrected:  : The internal function _update_account_shares has been revised to reset only field t when  an account withdraws all of its shares:  Yearn - Yearn yETH -   20  CorrectnessMediumVersion1CodeCorrectedCorrectnessMediumVersion1CodeCorrectedVersion2              \fif shares == 0:     t = 0     last_shares = 0  The function vote_weight checks if the position of an account has been updated on the ongoing week as follows:  if week > current_week or week == 0:     packed_weight = self.previous_packed_weights[_account]  The second condition week == 0 is true only for empty accounts, which should have a voting weight of 0 and there is no need to consider their previous state.    : The unnecessary check week == 0 has been removed from function vote_weight.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Approve Can Be Frontrun",
        "body": "  The function approve in Staking contract is vulnerable to frontrunning attacks. The function approve always overwrites the current value without checking if the allowance has been consumed or not.  Assume  a  scenario  where  Alice  provides  an  allowance  of  value  X  to  a  spender.  Then,  she  decides  to change the allowance to a value Y. The spender can front-run the second transaction, spend X, and then spend the new allowance Y also. This attack vector and possible mitigations are discussed in EIP20.    increaseAllowance and decreaseAllowance functions were added. These functions are similar to approve  function,  but  they  do  not  overwrite  the  current  value.  Instead,  they  increase  or  decrease  the current value with a given delta.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Default Target Weight",
        "body": "  The function weight in contract Pool returns 0 as the default target weight when no ramp is active:  if self.ramp_last_time == 0:     target = 0  Furthermore, the function add_asset does not set 0 as target weight although no ramp is active.    The  external  function  weight  has  been  updated  to  return  the  current  weight  of  an  asset  in  the  pool when there is no active ramp.  Yearn - Yearn yETH -   21  Version3SecurityLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                  \f6.8   Incomplete Specifications for Paused Pool  When a pool is paused no swaps can be executed. Furthermore, rate providers cannot be updated while the pool is in this state as _update_rates reverts. Specifications do not describe these behaviors.  The following functions cannot be executed when a pool is paused:   update_rates   update_weights   set_ramp   swap   swap_exact_out   add_liquidity   remove_liquidity_single   set_rate_provider  Specifications changed:  The specifications regarding pause mode have been extended in file specification.md.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   Inconsistent Behavior of Conversion Function",
        "body": "  External  view  functions  convertToShares  and  convertToAssets  return  the  input  value,  _assets and  _shares  respectively,  when  total_assets  is  0.  However,  on  the  same  conditions  (`` _total_assets  ==  0``)  both  internal  functions  _preview_deposit  and  _preview_mint  return  0. Therefore, depositing and minting in this scenario reverts.    Yearn corrected the code and both external functions are now in line with the internal ones.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   Mismatch of Code With the Specification for",
        "body": " Pending Rewards  The specifications of the contract Staking state:  If the balance has increased, it is added to the pending bucket. If one or more week has been missed, the increase is distributed instead over the three buckets fairly.  However, the function _get_amounts adds rewards to the streaming bucket if it is called on the first day of a new week:  Yearn - Yearn yETH -   22  CorrectnessLowVersion1Speci\ufb01cationChangedCorrectnessLowVersion1CodeCorrectedCorrectnessLowVersion1Speci\ufb01cationChanged                      \fif weeks == 1 and block.timestamp % WEEK_LENGTH <= DAY_LENGTH:     streaming += rewards  Specification changed:  Yearn added a more concise specification for this scenario:  If the first update of the week is in the first day, it is added to the streaming bucket directly instead.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.11   Missing Slippage Protection When Adding",
        "body": " New Asset  The management can add a new asset into a Pool by calling the function add_asset. The caller should send _amount tokens of the new asset to the pool, which increases the overall value of the Pool. The function mints the difference in the total supply (supply - prev_supply) as LP tokens to the address _receiver, however no slippage protection is implemented.    The function add_asset has been revised to take an additional argument _min_lp_amount as input and  now  explicitly  asserts  that  supply  has  strictly  increased  and  the  caller  receives  more  LP  shares than _min_lp_amount:  ... assert supply > prev_supply lp_amount: uint256 = unsafe_sub(supply, prev_supply) assert lp_amount >= _min_lp_amount PoolToken(token).mint(_receiver, lp_amount) ...  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.12   No Meaningful Revert Messages",
        "body": "  Reverts  could  emit  meaningful  messages  to  provide  the  reason  for  failed  calls.  The  downside  of informing  users  accordingly  is  the  slightly  increased  gas  costs.  Hence,  Yearn  needs  to  evaluate  if  a meaningful revert message should be returned.    Yearn added selected revert messages.  Yearn - Yearn yETH -   23  SecurityLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                  \f6.13   Possible to Lock Management Role  Both  contracts  Staking  and  Pool  implement  the  function  set_management  that  allows  the  existing management  account  to  set  a  new  management  address.  As  management  is  responsible  for  setting multiple parameters of contracts, measures should be taken to avoid mistakes when updating it. Besides sanity  checks,  the  update  of  critical  roles  that  cannot  be  recovered  should  follow  the  set/accept approach.    Both  functions  were  changed  to  a  commit/accept  scheme  with  two  functions  set_management  and accept_management.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.14   Types of Variables in Weight",
        "body": "  The types uint16, uint56 and uint128 are used for variables of struct Weight. Together these values fit in a storage slot (256 bits). However, Vyper does not optimize storage used by packing together variables  that  fit  in  32  bytes.  As  each  value  is  stored  in  a  separate  storage  slot,  EVM  uses  additional operations to convert the value from 32 bytes to the correct type.    Yearn  added  a  custom  way  to  pack  the  variables  in  a  single  storage  slot  for  the  variables: previous_packed_weights  and  packed_weights.  This  optimization  on  the  storage  comes  with slighly added gas costs on execution due to packing and unpacking of variables in a single storage slot.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.15   Unused Event in Staking",
        "body": "  The event SetMinter in the contract Staking is not used.    The unused event has been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.16   Functions Return True Always",
        "body": "  The natspec description for the return value of functions transfer and transferFrom states:  @return Flag indicating whether the transfer was successful  Both functions return only True, otherwise they revert.  Yearn - Yearn yETH -   24  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedInformationalVersion1CodeCorrected                            \f  The natspec description for the return value has been updated: @return True.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.17   Missing Natespec",
        "body": "  A  majority  of  the  critical  logic  is  implemented  in  internal  functions.  In-line  documentation  and  proper natspec for all functions can significantly improve code readability to understand correctly the intended behavior of the code.    Natspec was added to all functions.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.18   Possible to Index Event Parameters",
        "body": "  It  is  recommended  to  index  the  relevant  event  parameters  to  allow  integrators  and  dApps  to  quickly search  for  these  and  simplify  UIs.  We  would  like  to  highlight  that  asset  could  be  indexed  in  the respective events.    The  parameter  asset  SetWeightBand.  is  now   indexed   in  events  Swap,  RemoveLiquiditySingle  and  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.19   Possible to Mark Functions as View",
        "body": "  Functions virtual_balance and rate in Pool do not modify the state and can be marked as view.    Both functions have been marked as view functions.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.20   Redundant Code in _Calc_Supply",
        "body": "  The code inside if/else branches in the function _calc_supply is redundant and could be removed if the delta between values s and sp is computed first.  Yearn - Yearn yETH -   25  InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected                        \f  The function _calc_supply has been revised to avoid the redundant code.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.21   Return Values When Removing Liquidity",
        "body": "  The function remove_liquidity_single returns dx which is the amount of tokens being withdrawn for the target asset. However, the function remove_liquidity does not return any value.  Specification provided:  Yearn informed ChainSecurity that this was done intentionally as a gas saving measure, as otherwise it would need to construct and return an array of up to 32 values of type uint256.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.22   Transfers of 0 Values Revert in Staking",
        "body": "  Both  functions  transfer  and  transferFrom  check  that  value  being  transferred  is  non-zero (assert _value > 0). This behavior is not in line with EIP20 which has the following note:  Transfers of 0 values MUST be treated as normal transfers and fire the Transfer event.    Yearn changed the code to allow zero value transfers.  Yearn - Yearn yETH -   26  InformationalVersion1Speci\ufb01cationChangedInformationalVersion1CodeCorrected            \f7   Open Questions  Here,  we  list  open  questions  that  came  up  during  the  assessment  and  that  we  would  like  to  clarify  to ensure that no important information is missing.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Adding New Assets When Paused",
        "body": "  The function add_asset does not check if the pool has been paused when adding a new asset. Is this behavior intentional?  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Approval Events on transferFrom",
        "body": "  The Staking.transferFrom function does not emit any event regarding the approval change. Thus, it is  not  possible  to  recover  state  based  on  Approval+Transfer  events.  While  this  is  compliant  with ERC4626/ERC20  specification,  some  libraries  like  OpenZeppelin,  emit  explicit  Approval  event  during the transferFrom. On the other hand, DAI token does not emit such event. We would like to bring this detail to your attention and know if it is as expected in your case.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Total Assets Can Be 0",
        "body": "  Both  functions  _preview_deposit  and  _preview_mint  check  if  _total_assets  ==  0  although _total_shares are non-zero. Can you please describe the scenarios when this happens?  Yearn - Yearn yETH -   27  OpenQuestionVersion1OpenQuestionVersion1OpenQuestionVersion1          \f8   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Extracting Value From First Deposit in Pool",
        "body": "  The  attacks  based  on  strategies  that  artificially  inflate  the  value  of  LP  shares  in  Pool  are  unlikely  to succeed  due  to  the  way  how  rewards  (donations)  are  tracked  in  different  buckets.  Nevertheless,  it  is theoretically  possible  for  an  attacker  to  extract  value  from  the  first  depositor  if  certain  conditions  hold before first deposit, e.g., significant rewards are ready to be moved to unlocked bucket.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Incomplete Natspec",
        "body": "  The natspec description for the return value of function update_weights is incomplete.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.3   Missing Events in Staking Contract",
        "body": "  Functions  rescue,  set_half_time,  set_management  and  set_treasury  in  contract  Staking update the state, but no event is emitted.  Code partially corrected:  The respective events in the functions listed above were added except function rescue, which still does not emit an event.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.4   Preview Functions Round in Favor of Users",
        "body": "  The functions _preview_withdraw is used to calculate the number of shares a user needs to pay for withdrawing a given amount of assets. The calculation rounds in favor of the user. This means the user needs to pay slightly less shares for the respective assets. Hence, reducing the value of all shares. The same  issue  is  also  present  in  _preview_mint.  The  magnitude  of  the  rounding  error  depends  on  the share-to-assets ratio.  This  violates  the  invariant  that  the  share  value  can  only  go  down  by  incurred  losses.  Still,  the  impact should be limited and the issue is mainly theoretical.  Yearn - Yearn yETH -   28  InformationalVersion2InformationalVersion1InformationalVersion1CodePartiallyCorrectedInformationalVersion2                  \f8.5   Theoretical Underflow in _Get_Amounts  The function Staking._get_amounts can theoretically underflow when the shortage is higher than the  sum  of  all  tokens  accounted  in  the  buckets.  The  underflow  happens  in  the  statement unlocked  -=  shortage.  However,  practically  this  should  not  happen  as  the  loss  cannot  be  larger than the balance of Staking contract in yETH.  Yearn - Yearn yETH -   29  InformationalVersion1  \f9   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "9.1   Assets Cannot Be Removed From Pool",
        "body": "  Contract  Pool  implements  the  function  add_asset  that  allows  the  management  account  to  add  new assets  into  the  Pool,  up  to  a  total  of  32  assets.  We  highlight  that  the  contract  does  not  implement  a functionality to remove an asset from a Pool. Therefore, the asset removal requires a redeployment of the contract, which forces all LPs to withdraw their liquidity from the old Pool and deposit into the new one.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "9.2   Assumption on Balance of Staking",
        "body": "  The  internal  function  _update_supply  is  called  when  key  functionalities  of  the  contract  Pool  are performed.  Based  on  the  activity  of  the  Pool  LP  tokens  are  minted  to  the  staking  (if  supply increases),  or  LP  tokens  are  burned  from  the  staking  (if  supply  decreases).  The  implementation  of the function assumes that the staking contract has always enough balance in yETH to cover the losses of the pool such that the burning of LP tokens will always succeed.  Yearn  is  aware  that  after  deployment  or  in  certain  conditions  (e.g.,  no  staked  tokens)  this  assumption might not hold, and extra measures need to be taken for the function to work as intended.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "9.3   Buckets Can Be Updated at Most Once per",
        "body": " Block  The function _get_amounts returns the current state if the buckets have already been updated in the same block:  if updated == block.timestamp:     return self.pending, self.streaming, self.unlocked, 0, 0  If the Staking contract receives rewards in a block, after function _update_totals has already been called,  the  pending  and  streaming  buckets  do  not  get  updated.  Note  that,  the  unlocked  bucket  is always updated when users stake or unstake their yETH tokens.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "9.4   Charged Fees Are Unclear",
        "body": "  The function add_liquidity charges fees depending on the differences between deposited amounts and the current state of the pool. The larger the delta, the higher the fees. However, it is not easy for a  Yearn - Yearn yETH -   30  NoteVersion1NoteVersion1NoteVersion1NoteVersion1              \fliquidity  provider  to  know  the  actual  fees  payed.  Similarly,  the  function  remove_liquidity_single charges fees but it is not explicit to the caller.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "9.5   Decay of Voting Weight on Transfers",
        "body": "  Voting weight is computed by a asymptotic function that depends on the amount of shares and the time they  have  been  staked.  The  variable  Weight.t  is  adjusted  (lowered)  when  a  position  receives  new shares  such  that  the  voting  weight  before  and  after  the  transfer  remains  the  same.  However,  when transferring out tokens the variable Weight.t is not modified.  The side effect of this behavior is that if a position with a voting weight v1 receives x shares and then transfers out the same amount x shares, ends up with a lower voting weight v2 (v2 < v1) although the number of staked shares has not changed. Furthermore, transfers also affect the global voting weight as transfers decrease voting weight of individual positions.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "9.6   Large Ratio Drops for an Asset Break Pool",
        "body": " Composition  Pool  implements  a  safety  mechanism  to  ensure  that  the  portfolio  composition  of  underlying  assets  is according to specified parameters. Each asset in the Pool has a target weight (a range) associated with it.  User  operations,  like  swap,  deposit,  or  withdraw,  that  change  the  asset  balances  in  the  Pool  are permitted only if they do not move the actual weights of the involved assets outside the specified ranges. However, the Pool composition changes also when updating rates as asset balances change. The safety mechanism is not enforced in such changes of Pool composition.  While  the  mechanism  of  safety  bands  helps  to  maintain  the  desired  composition  of  the  Pool  when  all assets have a backing ratio as expected (around 1 ETH), they do no limit the value loss of the Pool when the  ratio  of  one  asset  drops  significantly  (e.g.,  goes  towards  0).  A  lower  rate  for  an  asset  results  in  a lower  virtual  balance  for  the  asset,  which  lowers  its  weight  in  the  Pool,  therefore  enabling  trades  that transfer  the  cheaper  asset  into  the  Pool  and  transfer  out  other  assets.  If  the  rate  of  one  asset  drops significantly  (e.g.,  due  to  a  hack),  the  Pool  should  be  paused  immediately,  before  the  new  ratio  is published by the respective provider, to prevent traders from selling the worthless asset to the Pool.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "9.7   Precision of Packed Weights",
        "body": "  The precision of weight variables passed as arguments in function is 18 decimals. This precision is lost when the variables are stored as packed in storage due to space limitations. Variables weight, target, lower and upper are limited to 20 bits, therefore they can store values with a precision of 6 digits only. The  management  account  should  take  into  consideration  this  behavior  when  setting  the  respective parameters of Pool.  For instance, the function set_ramp does not enforce a lower bound on the values passed in the array _weights.  If  a  value  smaller  than  10**12  is  passed  as  target  weight  for  an  asset,  the  function _pack_weight will store 0. In this case, the ramp cannot complete and main functionalities of the Pool stop  working  as  the  function  _update_weights  calls  function  _calc_vb_prod  which  requires  the weight of each asset to be non-zero: assert weight > 0.  Yearn - Yearn yETH -   31  NoteVersion1NoteVersion1NoteVersion1              \f9.8   Sandwiching Curve Changes  There  are  many  ways  a  Curve  can  significantly  change  its  shape.  A  prominent  attack  example  is  the sandwich attack on Curve when the amplification factor is changed. Therefore, these important changes are ramped (split in smaller changes over a defined time) to minimize the revenue of sandwiching these changes. Yearn also implements ramping for weight changes and amplification factor. However, ramping does not guarantee that an attack is not profitable. As Yearn does have more potential ways to change their Curve than e.g., the original Curve by Curve finance, this risk is increased.  Ramping  can  be  initiated  only  by  the  trusted  account  management  which  should  carefully  select  the parameters  _amplification,  _weights,  _duration  and  ramp_step.  First,  as  _amplification represents  the  factor  A  *  f^n  and  f  depends  on  weights,  both  target  _amplification  and  target _weights should be chosen such that they stay in line with each-other in intermediary steps of ramping. Otherwise, management should execute each step as a separate ramp. For instance, transitioning from a pool with weights (10%, 20%, 70%) to a pool with weights (60%, 30%, 10%) introduces an error in the amplification factor of up to 49% in the intermediary steps of the ramping. The error gets higher for more excessive changes. For example, transitioning from a pool with weights (1%,99%) to weights (99%,1%) introduces an error up to 72% in the intermediary steps of the ramping.  Finally,  _duration  and  ramp_step  should  be  carefully  chosen  such  that  each  step  of  ramping  does not  change  the  curve  significantly.  Any  update  of  the  ramp_step  should  take  into  consideration  the ongoing ramp.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "9.9   Staking Does Not Lock Tokens",
        "body": "  Users holding yETH can stake their tokens into the contract Staking. The contract does not lock staked tokens and there is no time restriction to withdraw them. The only incentive to keep tokens staked is the increasing voting weight. Hence, yETH holders might have a stronger incentive to stake their tokens if the Pool generates rewards and withdraw if there are losses.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "9.10   Supply Updates in Pool",
        "body": "  The rate update of underlying assets can be triggered explicitly by calling the function update_rates or it  gets  triggered  when  sensitive  operations  are  executed,  e.g.,  adding/removing  liquidity  or  swaps.  The rate update changes the composition of the virtual balances of assets in the pool. The new supply is then computed, and Pool mints or burns tokens to/from the staking based on the positive or negative delta.  Updates of the supply provide different incentives to users. For instance, if new rates are published and they  lower  supply,  an  existing  LP  can  profit  by  sandwiching  the  transaction  that  triggers  the  supply update by withdrawing their tokens first and then deposing again after the supply gets updated.  On the other case, if supply is going to be increased, LPs have an additional incentive to stake their yETH to claim the respective rewards (subject to delays).  Yearn - Yearn yETH -   32  NoteVersion1NoteVersion1NoteVersion1          \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Incorrect Comments",
        "body": "  1. in TickTreeLib, the comment for bestNonEmptyBinPos is incorrect and should read:  pos is initially 1 if leaf has some nonzero bit in its MSB half, 0 otherwise. Then pos is A | B, where A is iszero(pos)<<1, so A is 0 if leaf has some nonzero bit in its MSB half, 2 otherwise. And B is 0 if leaf >> (pos << 7) has some nonzero bit in its most significant 192 bits, 1 otherwise.  2. The comment for Bitlib.fls indicates:  The fls function below is general-purpose and used by tests but not by Mangrove itself.  CS-MGVC-004  However, the function DensityLib.from96X32 uses it.  3. In MgvOfferTaking, there is a typo (be instead of by):  We start by enabling the reentrancy lock for this offer list.  4. In MgvOfferTaking, the following comment above applyPenalty() is misleading:  If the transaction was a success, we entirely refund the maker and send nothing to the taker.  The applyPenalty function is never called if the transaction is successful. In this case, the provision stays in the order and the Maker is not automatically refunded.  Specification changed:  All comments have been corrected.  Mangrove Association (ADDMA) - Mangrove Core -   13  CriticalHighMediumLowSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedDesignLowVersion1Speci\ufb01cationChanged           \f6.2   Redundant Input Validation  In marketOrderForByVolume(), the following checks are performed:  require(uint160(takerWants) == takerWants, \"mgv/mOrder/takerWants/160bits\"); require(uint160(takerGives) == takerGives, \"mgv/mOrder/takerGives/160bits\");  These checks are redundant relative to the stricter checks performed by ratioFromVolumes().  CS-MGVC-005    The redundant checks have been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Withdraw Does Not Revert",
        "body": "  When calling withdraw() to withdraw native tokens that were used for gas provisions, a low-level call is used. If the call fails, withdraw() returns with a false boolean as return value. It does not revert.  The amount is debited from the user's internal balance, so the user will not be able to withdraw anymore.  This locks the native tokens in the contract.  CS-MGVC-003    The withdraw function now reverts when the low-level transfer fails and always returns true if it does not revert.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Typo in Error String",
        "body": "  In src/core/MgvOfferTaking.sol line 573, the error string should be mgv/totalGave/overflow instead of mgv/totalGot/overflow.  CS-MGVC-002    The typo has been corrected.  Mangrove Association (ADDMA) - Mangrove Core -   14  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedInformationalVersion1CodeCorrected                    \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Permit Does Not Specify Price and Lasts",
        "body": " Forever  CS-MGVC-001  In MgvOfferTakingWithPermit, an allowance can be given to another address, allowing it to make orders on an address's behalf.  This allowance lets the spender take orders at any price. No maxTick is specified. Essentially, it is an allowance to execute a market order at any price. The impact is limited, as Mangrove only allows taking the best order on the order book. However, if orders are removed from the book inbetween the allowance being given and the order execution, the trade may have a much worse execution price than expected.  The  _allowance  given  lasts  forever.  The  spender  could  execute  marketOrderFor  at  a  much  later time, when the price is totally different.  The  usage  here  is  different  than  in  Uniswap,  from  which  the  permit()  function  was  adapted.  In Uniswap, the permit is used instead of an ERC20 approval. The user will still need to call the swap() function themselves. Here, the _allowance is much more powerful. It allows a trade to happen without the user making a transaction at all.  As a result, allowances should only be given by users if the full allowance is expected to be used within a short time. Otherwise, trades may be executed at unintended prices. Unused or partially used allowances should be retracted.  Acknowledged:  Mangrove Association (ADDMA) clarified that this is intended behavior:  This is on purpose. Additional restrictions can be set up by the authorized contract itself, but the main purpose is to have a general delegation mechanism that works e.g. for cold wallets that want to allow the hot wallet some uses (such as trading on Mangrove) but not arbitrary token transfers.  Mangrove Association (ADDMA) - Mangrove Core -   15  InformationalVersion1Acknowledged    \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Gas Price Set at Offer Creation",
        "body": "  The gasprice for an order's gas provision is set at offer creation time and not updated automatically.  As a result, orders that were created at a time when gas was cheap may not have enough provision to fully reimburse the Taker if executed when the chain's gas price is higher. There will also be no incentive to clean failing orders where this is the case.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Gasmax Must Be Smaller Than Block Gas",
        "body": " Limit  The global gasmax parameter can be set by governance.  The maximum possible value for gasmax is 2^24 - 1. If the value chosen is close to the block gas limit of  the  chain  on  which  the  contracts  are  deployed,  a  Maker  will  be  able  to  create  a  failing  order  with  a gasreq of gasmax. It will be impossible to clean this order, as it will be impossible to supply sufficient gas for the Maker call. The order will always revert and blame the Taker.  Note that the maximum possible value for gasmax is around 16.7 million, which is more than Ethereum's average gas target per block. Other chains may have lower gas block limits.  Governance should be careful not to set gasmax to a value that is too high, as it may cause a permanent DoS.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.3   Large Offers Could Have Low Effective",
        "body": " Density  The minimum offer density (gas per token given) is enforced based on the total size (gives) of the order:  require(     ofp.gives >= ofp.local.density().multiply(ofp.gasreq + ofp.local.offer_gasbase()),     \"mgv/writeOffer/density/tooLow\"   );  This means that the gasreq can be very high, as long as the total order size is very large. If an order with a very large size is created, it is likely that most Takers will only partially fill the order.  This would lead to the effective density (gas per token received) being low.  Governance  can  limit  the  maximum  gasreq  that  a  Maker  can  set  by  changing  the  global  gasmax parameter.  Mangrove Association (ADDMA) - Mangrove Core -   16  NoteVersion1NoteVersion1NoteVersion1          \f8.4   Maker Can Exclude by Tx.Origin  A Maker could create an order that checks tx.origin and fails for certain addresses.  Such an order would be impossible for another address to clean using cleanByImpersonation(), as the tx.origin cannot be impersonated.  However,  the  targeted  address  can  clean  the  order  themselves,  or  just  accept  the  gas  refund  when taking the order.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.5   Tokens That Revert on Zero-Transfer Not",
        "body": " Supported  ERC20-like tokens that revert when transfer() is called with amount == 0 are not supported. If such a token was used, any Offer that gives that token could be cleaned by specifying takerWants == 0, which would incorrectly blame the Maker.  Reverting  on  zero-transfer  does  not  correctly  comply  with  the  ERC20  standard.  However,  there  are tokens  in  use  that  have  this  functionality.  Governance  should  check  the  token's  ERC20-compliance before activating a market using it.  Mangrove Association (ADDMA) - Mangrove Core -   17  NoteVersion1NoteVersion1        \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Pausing Auto-Compounding Can Be Unfair to",
        "body": " Users  CS-EVERSTKB2C-001  The  flag  PAUSE_REWARDS_POSITION  introduced  in  the  Accounting  allows  for  pausing  rewards auto-compounding. This led to the following:  1. During the period rewards auto-compounding is disabled, all users joining the protocol and having their stake activated will collect the same amount of rewards independently of the time their stake became active.  2. Provided that enough interchanging is available, a user who wants to begin staking can monitor the mempool  and  frontrun  the  Everstake's  transaction  that  reenables  reward  auto-compounding  to keep its ETH liquid for the largest amount of time possible while maximizing its rewards.  Acknowledged:  Everstake  is  aware  of  this  issue  and  responded  that,  depending  on  their  SOP  for  each  edge  case, staking may be manually paused along with the pausing of the rewards.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Interchanging Is Not Performed in Order When",
        "body": " Withdrawing  Everstake - ETH B2C Staking -   13  CS-EVERSTKB2C-004  DesignCorrectnessCriticalHighMediumLowAcknowledgedAcknowledgedAcknowledgedDesignLowVersion3AcknowledgedDesignLowVersion1Acknowledged                   \fBecause  of  the  implementation  of  AddressSet,  when  interchanging  with  pending  deposits  during  a withdrawal,  the  interchanges  are  not  done  in  the  order  the  stakers  deposited.  This  means  that  some users might have to wait for their deposit to become active longer than another user who deposited after them, hence missing the rewards that were distributed during this time.  This issue can be taken advantage of by a user who wants to stake x ETH but does not wish to wait for their deposit to become active. By looking at the mempool, the user can spot transactions withdrawing from the contract. If he finds a withdrawal greater than or equal to x + y where y is the amount that could  be  the transaction  with  his  call  to  Pool.stake  will  guarantee  him  to  be  interchanged  with  the  withdrawal, overtaking all the users in _slotPendingStakers()[activeRound].  interchanged  with  _slotPendingStakers()[activeRound][0],   frontrunning   Acknowledged:  Everstake  responded  that  this  behavior  is  known  and  kept  as  it  is  to  save  gas  since  using  the  proper order would be costly given OpenZeppelin's AddressSet implementation.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Minimum Stake Consistency",
        "body": "  The  Pool  forces  stakers  to  stake  at  least  MIN_STAKE_AMOUNT  per  deposit,  but  it  is  possible  to circumvent this by calling stake() and then either unstakePending() or unstake() to have a final deposited amount smaller than MIN_STAKE_AMOUNT.  CS-EVERSTKB2C-005  Acknowledged:  Everstake  acknowledged  this  behavior  and  explained  that  this  check  is  more  about  excluding  cases when the fees of the transaction would be relatively large compared to the actual deposited amount.  Everstake - ETH B2C Staking -   14  DesignLowVersion1Acknowledged          \f7   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  0  2  6  22  -Severity Findings  -Severity Findings   Replacing a Validator Eventually Blocks the System    Usage of address(this).balance in restake Can Block the System   -Severity Findings   renounceOwnerShip Leaves the _pendingOwner Pending    Missing Input Sanitization    Pausing Withdrawing Is Ineffective    Slashing Is Not Taken Into Account    _simulateAutocompound's Computation of pendingRestaked Is Incorrect    _simulateAutocompound's Computation of totalShare Is Incorrect   -Severity Findings   Wrong Address in Event upon acceptOwnership    RewardsTreasury Overrides SendETH With Identical Implementation    ValidatorList.get Might Not Represent the Reality    _simulateAutocompound Ignores Paused Rewards    Batch Deposit in First Round Skips Shortcut    Events Missing   Inconsistent Event Emission Order   Interchanged Part of a Deposit Is Not Added to depositBalance   Interfaces Not Implemented    Missing Documentation    Missing Indexing of Events    Status of Replaced Validators Is Not Reset    Unnecessary Function Parameter    Variables and Functions Names Are Not Representative    View Functions Are Incorrect for Round 0    Withdrawing May Fail Due to Underflow    Wrong Restake Condition   InterchangeDeposit Emitted When No Interchange    activatedRound Cached Value Not Updated    activeRound==0 Shortcut Breaks Semantics   Everstake - ETH B2C Staking -   15  CriticalHighCodeCorrectedCodeCorrectedMediumCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrected    \f onlyGovernor Not Used    unstakePending Does Not Update _slotPendingStakers   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Replacing a Validator Eventually Blocks the",
        "body": " System  The function ValidatorList.replace does not set the status of the new validator to Pending. This will make ValidatorList.shift() revert when the next pending validator will be the new validator as its status will be Unknown. If this happens, staking and withdrawing will be blocked. The funds can only be unlocked if the validators are closed and the rewarder on the RewardsTreasury can be changed.  CS-EVERSTKB2C-034    The function has been updated and the new validator' status is now set to Pending.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Usage of address(this).balance in",
        "body": " restake Can Block the System  CS-EVERSTKB2C-025  The function restake defined in the pool contract is called when auto-compounding is performed and tries  to  deposit  to  the  beacon  deposit  contract  with  fresh  validators  as  much  as  possible  given  the balance of the contract.  As this function relies on the balance of the contract and not the balance computed by the accounting the following is possible:  If  ETH  is  forced  into  the  pool  contract  (using  selfdestruct  for  example),  one  can  increase  the balance  of  the  contract  such  that  any  subsequent  function  call  triggers  a  deposit  to  the  beacon deposit  contract  via  _autocompound  when  it  would  not  without  the  extra  ETH.  As  accounting's pending amount will now be much greater than the actual balance of the pool, any call to deposit or withdraw will eventually revert as it will try to send to the beacon deposit contract ETH that is no longer in the pool.   When a user stakes, _autocompound() is called by deposit() before the deposit is accounted for in _deposit() and after the deposit of the user has been added to the contract's balance. If the balance  of  the  contract,  upon  transferring  the  rewards  from  the  treasury  to  the  pool  contract,  is greater  than  32  ETH,  restake  will  deposit  to  the  beacon  deposit  contract.  As  part  of  the  user's deposit will be gone, the accounting performed by _deposit() will not match the actual balance of the contract and the call will revert as _stake cannot send BEACON_AMOUNT to the beacon deposit contract.    A parameter activatedSlots to indicate how many validators must be deposited to has been added in the restake functions, and the Pool does not rely on its internal balance anymore.  Everstake - ETH B2C Staking -   16  CodeCorrectedCodeCorrectedCorrectnessHighVersion1CodeCorrectedDesignHighVersion1CodeCorrected                 \f7.3   renounceOwnerShip Leaves the _pendingOwner Pending  CS-EVERSTKB2C-033  functions   The  and OwnableWithSuperAdmin.renounceOwnership  delete  the  _owner,  but  not  the  _pendingOwner. When renouncing ownership, there may be still a pending owner. The goal of renouncing ownership is to leave the contract without an owner forever, but if the current owner does initiate ownership transfer and then renounces, the pending owner can still claim ownership of the contract.  TreasuryBase.renounceOwnership     The two functions have been updated to delete the _owner and the _pendingOwner.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   Missing Input Sanitization",
        "body": "  CS-EVERSTKB2C-031  Some function inputs are not sanitized:  1. Pool.initialize(): the parameters rewardsTreasury and poolGovernor are not checked  for address(0).  2. Accounting.initialize():   the  parameter  accountingGovernor   is  not  checked   for  address(0), and poolFee is not checked to be smaller than FEE_DENOMINATOR.  3. TreasuryBase.setRewarder(): rewarder is not checked for address(0).  4. TreasuryBase.setOwner(): owner is not checked for address(0).  5. Pool.setGovernor(): newGovernor is not checked for address(0).    1. Zero address checks are done.  2. Zero address and fee sanitization checks are done.  3. Zero address check is done.  4. the function has been removed and replaced by a transfer-and-accept pattern.  5. Zero address check is done.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   Pausing Withdrawing Is Ineffective",
        "body": "  The function pauseWithdraw can be called by a privileged role to (un)pause the withdrawals. While the function unstakePending has the modifier whenWithdrawActive to ensure that it can only be called  CS-EVERSTKB2C-039  Everstake - ETH B2C Staking -   17  DesignMediumVersion3CodeCorrectedDesignMediumVersion1CodeCorrectedDesignMediumVersion1CodeCorrected                        \fonly when withdrawals are allowed, unstake() is not and can be called independently of the pausing of withdrawals.    The function Pool.unstake has been updated with the whenWithdrawActive modifier.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.6   Slashing Is Not Taken Into Account",
        "body": "  CS-EVERSTKB2C-003  The protocol assumes that slashing will never happen for any of its validators. While the risk of slashing can be greatly reduced by good infrastructure maintenance and monitoring, it can never be zero, in this case, the slashing of a validator could result in putting the protocol in unexpected states and a potential loss  of  funds  for  users.  All  implementations  of  nodes  can  potentially  have  bugs  that  might  lead  to undesired slashing.  For example, any transfer of less than 32 ETH from the validator is considered as an incoming reward, while  if  slashed  this  can  be  an  entire  stake  of  the  validator.  Thus,  if  slashed  just  before  unstaking,  the wrong accounting can lead to unexpected results.    Everstake  added  the  feature  to  stop  the  update  of  rewards  in  case  of  emergency.  When  it  comes  to updating  the  user's  balance  and  refunding  the  users,  see  Trust  Model  and  Users  may  not  be  fully refunded in case of slashing.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.7   _simulateAutocompound's Computation of",
        "body": " pendingRestaked Is Incorrect  When  simulating  the  activation  of  rounds  in  _simulateAutocompound(),  for  each  round  being activated,  pendingRestaked  is  decremented  by  BEACON_AMOUNT.  As  it  might  be  the  case  that pendingAmount/BEACON_AMOUNT  >  pendingRestaked/BEACON_AMOUNT,  a  call  to  the  function could revert after trying to underflow the variable pendingRestaked.  CS-EVERSTKB2C-017    _simulateAutocompound  that pendingAmount/BEACON_AMOUNT > pendingRestaked/BEACON_AMOUNT and correctly decrement pendingRestaked.  assumption   makes   longer   the   no   Everstake - ETH B2C Staking -   18  DesignMediumVersion1Speci\ufb01cationChangedCorrectnessMediumVersion1CodeCorrected                  \f7.8   _simulateAutocompound's Computation of totalShare Is Incorrect  CS-EVERSTKB2C-018  is   by   called   _deposit   When  deposited (AUTO_COMPOUND_TOTAL_SHARE_POSITION) is incremented with the rewards (both the part that has been  side, __simulateAutocompound()  increments  totalShare  by  unclaimedReward  which,  at  this  point, only  includes  the  part  of  the  rewards  that  is  not  interchanged.  The  totalShare  returned  by _simulateAutocompound() will hence not always match the result of an autocompounding.  _autocompound(),   deposited).  On   interchanged   that  will   amount   other   total   part   and   the   the   the   be     _simulateAutocompound  now  matches  _autocompound()  behavior  and  takes  into  account  the interchanged amounts when computing the total pool's balance.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.9   Wrong Address in Event upon ",
        "body": " acceptOwnership  CS-EVERSTKB2C-043  The  and OwnableWithSuperAdmin._transferOwnership  emit  the  event  the  addresses  of  _owner  and newOwner, which are the same at that point.  TreasuryBase._transferOwnership   functions     The two functions have been updated to emit the event with the previous owner and the new owner.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.10   RewardsTreasury Overrides SendETH With",
        "body": " Identical Implementation  RewardsTreasury overrides SendETH with the same implementation as TreasuryBase.  CS-EVERSTKB2C-035    Everstake  RewardsTreasury not to have to override sendETH.  inheritance  between   revised   the   the  contracts  and   their   interface   to  allow   for  Everstake - ETH B2C Staking -   19  CorrectnessMediumVersion1CodeCorrectedDesignLowVersion3CodeCorrectedDesignLowVersion3CodeCorrected                        \f7.11   ValidatorList.get Might Not Represent the Reality  Given  a  set  of  Validators  with  the  status  Deposited,  they  may  be  not  closed  in  the  same  order  they appear in _validatorsPubKeys. In such case, calling markAsExited will mark the n first Deposited validator of the list as excited, without caring about which exact validator was closed. This may lead the function  ValidatorList.get  to  return  a  status  that  is  not  representative  of  reality  in  the  case Everstake  did  not  close  validators  in  the  order  they  appear  in  _validatorsPubKeys  (e.g.  in  case  of slashing or leaked private key).  CS-EVERSTKB2C-002    Everstake added the function markValidatorAsExited and a corresponding internal function to the Pool  and  to  ValidatorList  to  allow  for  marking  as  closed  validators  given  its  index  in _validatorsPubKeys.  Provided  right  method  between markValidatorsAsExited  and  markValidatorAsExited  to  close  the  validators  that  have effectively been closed, ValidatorList.get should return the correct status.  that  Everstake  always  uses   the   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.12   _simulateAutocompound Ignores Paused",
        "body": " Rewards  Accounting._simulateAutocompound does not take the pausing of rewards into account, and thus does not mirror what autocompound would do when the rewards are paused.  CS-EVERSTKB2C-036    function  _simulateAutocompound  has  been  updated   The  _autocompound() when the rewards are paused.  to   reflect   the  behavior  of  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.13   Batch Deposit in First Round Skips Shortcut",
        "body": "  CS-EVERSTKB2C-022  the   first   round   If  in Accounting._activateRound()  will  be  skipped  as  activeRound  >  0.  In  this  case,  round  0  will have to be activated as any other round by calling activateValidators.  is  closed  within  a  batch  deposit,   (activeRound==0)   the  shortcut     The special handling of the case activeRound==0 has been removed from _activateRound().  Everstake - ETH B2C Staking -   20  DesignLowVersion3CodeCorrectedCorrectnessLowVersion3CodeCorrectedDesignLowVersion1CodeCorrected                        \f7.14   Events Missing  CS-EVERSTKB2C-029  Even  though  many  events  are  emitted  by  the  protocol,  several  important  state  changes  do  not  emit events:  1. OwnableWithSuperAdmin.__OwnableWithSuperAdmin_init_unchained()  does  not  emit  SetSuperAdmin after setting the super admin.  2. Accounting.withdraw()  does  not  emit  InterchangeDeposit  when  interchanging  with  the  pending restaked amount.  3. No  event  is  emitted  by  Accounting.activateValidators()  when  one  or  several  validators  are activated.  4. No  event   is  emitted  when   the  minimum  amount   to   restake   is   set  using  Accounting.setMinRestakeAmount().  5. In Accounting, deposit(), withdrawPending() and withdraw() could emit events as they are  not  necessarily  respectively  called  by  Pool.stake(),  Pool.unstakePending()  and Pool.unstake().  6. Pool.unstake()  emits  no  event  when  no  amount  is  withdrawn  from  the  pending  value  of  the  pool.  7. Pool.restake(),   Pool.setPendingValidators(), Pool.replacePendingValidator(),  Pool.markValidatorsAsExited()  emit  no  event while they perform important state changes.  8. GovernorChanged   in  Pool.initialize()  and Accounting.initialize(), similarly, FeeUpdated is not emitted when setting the pool fee in initialize().  is  emitted  when  setting   the  governor   :  9. OwnableWithSuperAdmin.renounceOwnership  TreasuryBase.renounceOwnership does not.  emits   an   event   but  10. markValidatorsAsExited is defined and emitted in the library ValidatorList, meaning that  it won't be part of the Pool's ABI as it is not redefined there.    The points 1., 2., 3., 4., 6., 7. (all but setPendingValidators), 8., 9., 10. have been fixed.  For 7., Everstake states:  Pool.setPendingValidators()  -  not  important  state  changes.  It's  internal  processing  which  can  be indexed without events.  For point 5.:  Everstake answered that the concerned functions of the accounting can be called either by the pool or by the owner. In the former case, the pool emits relevant events. For the latter case, Everstake states that the owner should call these functions only in an emergency and thus, Everstake claims that no events are needed in those cases as observers would anyway know that this is the owner's actions.  Everstake - ETH B2C Staking -   21  DesignLowVersion1CodeCorrectedVersion3        \f7.15   Inconsistent Event Emission Order  1. While most of the functions emit events after calling functions that might themselves emit an event, Pool._deposit emits StakeDeposited before calling deposit which will itself emit events.  2. Additionally,  in  the  codebase,  the  rule  seems  to  be  doing  storage  change  first  and  then  emitting  events, however, some functions do not follow this pattern:  CS-EVERSTKB2C-024   OwnableWithSuperAdmin.transferOwnership   Governor._updateGovernor    1. The event has been moved after the call to deposit.  2. The events have been moved after the state changes.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.16   Interchanged Part of a Deposit Is Not Added",
        "body": " to depositBalance  When  staking,  the  part  of  the  deposit  that  is  interchanged  with  withdrawals  is  not  added  to sourceStaker.depositBalance.  CS-EVERSTKB2C-026    The  function  AutocompoundAccounting._depositAutocompound  has  been  updated  to  add  the interchanged amount to the sourceStaker.depositBalance.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.17   Interfaces Not Implemented",
        "body": "  Some  of  the  contracts  do  not  implement  their  interfaces  (FooBar  is  IFooBar).  This  would  be  a guarantee for integrators that the contracts carry the same functions signatures as the interfaces. Such contracts are listed below:  CS-EVERSTKB2C-027   TreasuryBase   RewardsTreasury    The  contracts  TreasuryBase  and  RewardsTreasury  have  been  updated  to  implement  their respective interfaces.  Everstake - ETH B2C Staking -   22  DesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                      \f7.18   Missing Documentation  Most of the functions are poorly documented or have no NatSpec description at all.  CS-EVERSTKB2C-028    Extensive documentation has been added for external and public functions.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.19   Missing Indexing of Events",
        "body": "  All  events  defined  in  Accounting,  Governor,  Pool,  RewardTreasury,  TreasuryBase  and Withdrawer  contain  no  indexed  fields.  Indexing  some  relevant  fields  will  help  for  searching  events quicker.  CS-EVERSTKB2C-030    The relevant fields have been indexed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.20   Status of Replaced Validators Is Not Reset",
        "body": "  In the function ValidatorList.replace, the status of the replaced validator is not assigned (=), but compared (==) to ValidatorStatus.Unknown. This line of code will have no effect, and it will not be possible to add again the replaced validator at a later stage.  CS-EVERSTKB2C-037    The status of the replaced validator is correctly reset to Unknown.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.21   Unnecessary Function Parameter",
        "body": "  The function AutocompoundAccounting._activatePendingBalance(), is always called with the parameter  minPresentedAmount  set  to  true,  thus  the  parameter  and  logic  related  to  it  should  be removed from the codebase.  CS-EVERSTKB2C-038  Everstake - ETH B2C Staking -   23  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                                \f  The unnecessary function parameter minPresentedAmount and its related logic have been removed from the codebase.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.22   Variables and Functions Names Are Not",
        "body": " Representative  Having  self-explanatory  names  for  variables  and  functions  greatly  help  the  understanding  of  the  code. The  names  of  some  of  the  variables  and  functions  in  the  codebase  are  misleading.  Here  is  a non-exhaustive list:   all  the  functions  named  with  autocompound,  except  autocompound()  and  _autocompound()  have nothing to do with autocompounding.  CS-EVERSTKB2C-040   AUTO_COMPOUND_TOTAL_SHARE_POSITION  represents   total  amount  of  ETH  currently deposited in the validators, not a share. Moreover, the amount is not only from auto-compounded rewards.  the    ShareState.totalShare represent the total deposited amount at some period, not a share.   ShareState.shareIndex represent the total minted shares at some period, not an index.   STAKER_AUTOCOMPOUND_BALANCES_POSITION  and  the  struct  AutocompoundStakerMining  have nothing to do with autocompounding.    The functions and variables names have been changed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.23   View Functions Are Incorrect for Round 0",
        "body": "  The special case for activeRound==0 in _activateRound() sets activatedRound to 1 although the validator is not necessarily active yet.  This  means  that  the  following  functions  might  return  incorrect  results  relative  to  the  semantics  of pendingDeposited and active:  CS-EVERSTKB2C-041   pendingDepositedBalance()   pendingDepositedBalanceOf()   depositedBalanceOf()   autocompoundBalanceOf()    The special handling of the case activeRound==0 has been removed from _activateRound().  Everstake - ETH B2C Staking -   24  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                  \f7.24   Withdrawing May Fail Due to Underflow  CS-EVERSTKB2C-042  When computing _shareToAmount(totalShare,  autoCompoundShareIndex, autoCompound TotalShare) - originActiveDepositedBalance in _withdrawFromAutocompound, amounts deposited by the user are compared with amounts obtained from shares using _shareToAmount(), as there might have been a rounding error in the computation of the latter, their comparison might result in an underflow, leading the call to revert.  An easy way to obtain this behavior is to have the user deposit a very low amount of ETH x (10 wei for example) by calling stake() with some large value before calling unstakePending() to leave in the pending deposit of the user x ETH. Supposing now that the price of a share is high at the moment of the activation  of  the  validator,  it  is  possible  that  _shareToAmount(_amountToShare(x))  <  x  as _amountToShare() might have done some rounding.    When only a portion of the user's shares are burned, the accounting subtracts the deposited balance to whatever is larger between the deposited balance and the amount obtained from the shares to be burned to avoid underflow.  When all the shares are burned, no such comparison is done and the deposited amount is updated to be the user's pending amount.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.25   Wrong Restake Condition",
        "body": "  CS-EVERSTKB2C-044  for   the  Pool   to  deposit  on  a  restake   The  condition  If balance == BEACON_AMOUNT the active round would have been incremented and the pending amount updated  accordingly  during  _autocompound()  because  the  system  expects  a  new  validator  to  be provisioned. But in that case, the validator will not be provisioned because of the strict inequality above. Moreover, the internal accounting of the pending amount will not be representative of the true pending value until the next deposit or reward auto-compounding.  is  balance  >  BEACON_AMOUNT.     The restake condition has been modified and relies on activatedSlots instead of balance.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.26   InterchangeDeposit Emitted When No",
        "body": " Interchange  In the function withdraw, InterchangeDeposit is emitted even if no interchange happened for the given pending staker (activatedAmount==0).  CS-EVERSTKB2C-023  Everstake - ETH B2C Staking -   25  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                      \f  The  withdraw  function  has  been  updated  so  the  InterchangeDeposit  event  is  emitted  only  when some amount is interchanged.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.27   activatedRound Cached Value Not Updated",
        "body": "  CS-EVERSTKB2C-020  At  the  beginning  of  the  function  Accounting._depositBalance,  activatedRound  is  cached  in memory  and  later  used  when  calling  _depositAccount().  If  activeRound==0  and  enough  ETH  is deposited  so  that  _activateRound()  is  called,  activatedRound  is  set  to  1  in  the  storage  but  its cached value is not updated. Because of this, if _depositBalance was to call _depositAccount() after  _activateRound's  call  (the  user  deposited  enough  to  activate  two  or  more  rounds), _autocompoundAccount()  would  in the  pendingDepositedBalances although the deposit should be active at this time and shares should be minted.  round  0   deposit   cache   user's   the   for     The special handling of the case activeRound==0 has been removed from _activateRound().  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.28   activeRound==0 Shortcut Breaks",
        "body": " Semantics  The implemented shortcut in _activateRound(), the shortcut that marks the round 0 activated breaks the semantics of the activatedRound, which should only represent the number of validators that have been effectively activated.  CS-EVERSTKB2C-021    The special handling of the case activeRound==0 has been removed from _activateRound().  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.29   onlyGovernor Not Used",
        "body": "  The modifier onlyGovernor defined in the Governor is never used in the code base and thus should be removed.  Moreover, as the check ensuring that the msg.sender is the governor is performed after the function's call the modifier is applied to, if the modifier was to be used on a function updating the governor, it could be  that  the  function  is  not  protected  and  could  be  called  by  anyone  providing  themselves  as  the  new governor.  CS-EVERSTKB2C-032  Everstake - ETH B2C Staking -   26  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \f  The modifier onlyGovernor has been removed from the Governor contract.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.30   unstakePending Does Not Update",
        "body": " _slotPendingStakers  When  his  _slotPendingStakers[activeRound] is not updated to remove the staker.  withdraws   pending   stake   user   full   using   a   CS-EVERSTKB2C-019  unstakePending,    The Accounting.withdrawPending function has been updated such that the staker is removed from _slotPendingStakers[activeRound] if they remove all of their pending stakes.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.31   Deleting a struct With a Mapping Has No",
        "body": " Effect  CS-EVERSTKB2C-008  In Solidity, if a struct contains a mapping and one deletes the struct, the mapping will not be deleted. In  deletes _slotPendingStakers()[activeRound],  an  AddressSet,  but  only  the  _values  field  of  the  Set will be defaulted.  Accounting._activateRound()   codebase,   the     The deletion of _slotPendingStakers()[activeRound] has been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.32   Event Reentrancy",
        "body": "  CS-EVERSTKB2C-009  In several functions, an event is emitted after an external call to some address, in the case that the call would reenter the contract, it would be possible to have events emitted out of order.  The list of such patterns is shown below.   Pool.unstake() with _safeEthSend() and the event Unstake.   Pool.unstakePending() with _safeEthSend() and the event StakeCanceled.   Withdrawer._claimWithdrawRequest()  with  ITreasuryBase.sendEth()  and  the  event  ClaimWithdrawRequest.   Accounting.claimPoolFee()  with  IRewardsTreasury.sendEth()  and   the  event  ClaimPoolFee.  Everstake - ETH B2C Staking -   27  DesignLowVersion1CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected                    \f  All the patterns above have been updated to emit the event first, and then transfer ETH.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.33   Gas Optimizations",
        "body": "  CS-EVERSTKB2C-011  1. The type casting from address to address is not required in Pool.initialize(), removing it  might save gas during initialization depending on the compiler's optimization setting.  2. pendingValidatorPubKey is read twice from storage in Pool._deposit(), the value could be  cached in memory to avoid one SLOAD.  3. The  checks  of  the  form  a  !=  b  &&  a  !=  c  can  be  modified  following  De  Morgan's  law (!(a  ==  b  ||  a  ==  c))  to  leverage  the  lazy  evaluation  of  the  condition  and  save  gas  on runtime.  4. Some function arguments on call can be replaced by constants. Some examples are:   Accounting._activateRound(): the variable activeRound can be replaced by 0 in  the call _makeAutocompoundRoundCheckpoint(activeRound).   Accounting._depositBalance():  in  the  call  to  _activateRound()  of  the  branch >  parameter replaced  by  if  pendingTotalShare  +  closeCurrentRoundAmount  can  be  BEACON_AMOUNT.  (pendingAmount   0),   the    Accounting._depositBalance(): in the call to _depositAccount() of the branch if  (depositToPendingAmount  >  0),  the  parameter  interchangedAmount  will always be 0.   Accounting._depositBalance():   call AUTO_COMPOUND_PENDING_SHARE_POSITION.setStorageUint256() of the branch if  (depositToPendingAmount  >  0),  the  parameter  pendingTotalShare  will always be 0.  the   in   5. The  activatedSlots  in  the  branch  if  (pendingTotalShare  >  0)  of  the  function Accounting._depositBalance() can be set to 1 instead of incrementing the variable to save gas on runtime.  loop   while  and  multiple  (depositToPendingAmount   branch 6. The  if  function Accounting._depositBalance can be replaced by one update for each involved variable. If the while  loop  was  to  stay,  a  do-while  construct  could  save  gas.  The  same  applies  in _simulateAutocompound().  variables  BEACON_AMOUNT)   stack  >=   increments   the   the   of   in   pendingTotalShare  7. Setting  >=  (depositToPendingAmount  if  Accounting._depositBalance is redundant.  to   0   in  BEACON_AMOUNT)   the   of   the   branch function  8. The  while  loop  in  the  function  Accounting.withdraw()  can  be  simplified  since  in  the  case isFullyDeposited==false,  then  the  remaining  interchangeWithPendingDeposits  is zero.  9. In   the   branch  if  (withdrawFromPendingAmount  >  0)   function Accounting.withdraw,  pendingRestakedValue  -  withdrawFromPendingAmount  is computed twice while it could be done only once.  the   of   Everstake - ETH B2C Staking -   28  InformationalVersion1CodeCorrected      \f10. In  the  function  Accounting.withdraw,  the  pendingTotalShare  is  read  from  storage  twice  when it could be cached in the memory.  11. In   the   branch if  (unclaimedReward  <  MIN_RESTAKE_POSITION.getStorageUint256())  of  the function  Accounting._simulateAutocompound(),  the  constant  0  can  be  used  instead  of unclaimedReward  statement   return   the   of   12. When  simulating  the  withdraw  queue  filling  in  Accounting._simulateAutocompound(),  the in  same  way   done   the   in   is   it   if/else  unified  Withdrawer._interchangeWithdraw().  branches   could   be   13. The  modifier  Governor.onlyGovernor()  does  the  address  check  after  executing  the  code.  Reverting early would save gas.  14. In the function Pool._stake(), value cannot be zero.  15. The increment i++ can be in an unchecked block in multiple for loops.  16. The  function  Withdrawer.  _calculateValidatorClose  can  return  only  one  value,  as  the  two values are linked by a constant factor, one can easily deduce a value from the other one.  17. In   the   function  Withdrawer._calculateWithdrawRequestAmount,   the   withdrawFromActiveDeposit  true  withdrawFromActiveDeposit > pendingTotalShare is true and is hence redundant.  always   will   be   >   0   condition if  18. In the function WithdrawRequests.add, the assignation requests._values[i] = request can  be  moved  inside  the  if  (requests._values[i].value  ==  0)  block  and  the  function can return right after.  19. In   the   functions   WithdrawRequests.info, requests.value[i].afterFilledAmount  is  read  twice  from  the  storage  while  it  could  be cached to avoid one SLOAD.  WithdrawRequests.claim   and   20. In  the  functions  WithdrawRequests.claim  and  WithdrawRequests.info,  the  condition requests._values[i].afterFilledAmount  >  actualFilledAmount  can  be  relaxed  to an  if requests._values[i].afterFilledAmount  ==  actualFilledAmount  their  difference  is null.  comparison   unstrict   since   21. In  the  function  WithdrawRequests.info,  requests._values.length  is  read  from  the  storage at each iteration of the loop. Caching it in the memory would avoid several SLOAD.  22. In   the   function   and set._activePendingElementIndex  are  both  read  three  times  from  the  storage  when  their value could be cached in the memory.  set._activeValidatorIndex   ValidatorList.add,   23. In  the  function  ValidatorList.shift,  set._activePendingElementIndex  is  read  two  times from the storage when its value could be cached in the memory.  24. In   the   _autocompoundAccount, _autoCompoundUserPendingDepositedBalance,  and _withdrawFromAutocompound  field pendingDepositedBalances.length of the staker is read from the storage at each iteration of the loop. Caching it in the memory would avoid several SLOAD.  _autoCompoundUserBalance   AutocompoundAccounting,   functions,   the   of   25. In the first for loop of the function AutocompoundAccounting._autocompoundAccount, both staker.pendingDepositedBalances[j].period  and staker.activePendingDepositedElementIndex are read twice from the storage and could be cached.  26. In  AutocompoundAccounting._autocompoundAccount(),  when  updating  the  pending times  status  three  staker.activePendingDepositedElementIndex from storage, it could be cached.  pendingDeposited,   execution   read   path   one   to   Everstake - ETH B2C Staking -   29  \f27. In  AutocompoundAccounting._autocompoundAccount(),  when  updating  the  pending status to pendingDeposited or to activated, both staker.pendingBalance.balance and staker.pendingBalance.period are read twice from storage.  28. In   AutocompoundAccounting._autoCompoundUserPendingDepositedBalance(),  staker.pendingBalance.period is read twice from storage.  if   29. In  AutocompoundAccounting._autoCompoundUserBalance(),  at  each  iteration  of  the  for both loop,  stakerAutocompoundBalance.pendingDepositedBalances[j].balance  and stakerAutocompoundBalance.pendingDepositedBalances[j].period  are  read  twice from storage.  statement   condition   met,   the   the   not   if   of   is   :  30. The calls to _userActiveBalance to get only the depositedBalance could be replaced by a  simple storage read to save gas.  31. At   the   end   Accounting._simulateAutocompound(), pendingAmount  ==  pendingRestaked  always  holds  as  if  if  (pendingAmount  >  0)  is entered,  then  they  are  both  set  to  0.  Otherwise  pendingAmount==0  and  hopefully  one  should always  have  pendingAmount  >=  pendingRestaked  meaning  that  there  is  no  need  to  keep both var for the while loop.  of     The gas optimizations have been applied.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.34   Governor Is Immutable",
        "body": "  While  the  Governor  role  of  the  Pool  can  be  transferred  to  another  address  by  the  Owner,  the SuperAdmin or the governor himself at any time, the Governor of the Accounting contract can only be set when calling Accounting.initialize.  CS-EVERSTKB2C-012    The Governor of the Accounting can now be updated using the function setGovernor.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.35   Unneeded return Statement",
        "body": "  When a function signature looks like function foo() external returns(uint a, uint b), the statement return (a, b) is not necessary when the values to be returned have been assigned earlier to the returned variables.  CS-EVERSTKB2C-015  Some examples:   AutocompoundAccounting._withdrawFromAutocompound()   AutocompoundAccounting._autocompoundAccount()  Everstake - ETH B2C Staking -   30  Version3InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected            \f  Some of the unnecessary return statements have been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.36   Unused Imports",
        "body": "  The following imports are not used:  1. \"./interfaces/IPool.sol\" and \"./interfaces/ITreasuryBase.sol\" in Accounting.  2. \"./interfaces/IPool.sol\" in WithdrawTreasury.  3. \"./interfaces/IRewardsTreasury.sol\" in RewardsTreasury.  4. \"./ITreasuryBase.sol\" in IRewardsTreasury.  CS-EVERSTKB2C-016    All unused imports have been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.37   Validator Cannot Be Marked as Exited",
        "body": " Immediately  In  ValidatorList,  markAsExited()  changes  the  status  of  num  validators  from  Deposited  to Exited provided that:  CS-EVERSTKB2C-010   Their status is Deposited.   They are all stored consecutively in set._validatorsPubKeys.   The   first   is  set._validatorsPubKeys.  validator   stored   at   index   set._activeValidatorIndex   of  By the design of the List struct and the functions add and shift, validators that are Deposited are not  always  at  starting  at set._activeValidatorIndex and can be interleaved by validator with another status. A Deposited validator  in  such  configuration  cannot  have  his  status  changed  to  Exited  until  all  previous  validators have the state Deposited or Exited.  slice  of  set._validatorsPubKeys   \"front\"  of   the   the     markAsExited() has been updated in such ways that the num validators to be marked as Exited no longer need to be stored consecutively. Additionally, Pool.reorderPending() can be used to order pending validators to be deposited to in the order as they appear in _validatorsPubKeys. Depending on how Pool.reorderPending() is called this can be used to keep _validatorsPubKeys's length from growing.  Everstake - ETH B2C Staking -   31  InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected            \f7.38   initializer Used Over onlyInitializing  CS-EVERSTKB2C-014  The  functions  __OwnableWithSuperAdmin_init_unchained  onlyInitializing would be more correct.  __OwnableWithSuperAdmin_init  the   and initializer  modifier  while  have     The modifier onlyInitializing is used instead of initializer.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.39   minStake's Value Differs From the",
        "body": " Documentation  In the Pool.initialize, the minimum stake is set to 0.01 ETH while the documentation states that the minimum users are allowed to stake is 0.1 ETH.  CS-EVERSTKB2C-013    The minimum stake is now set to 0.1 ETH in Pool.initialize.  Everstake - ETH B2C Staking -   32  InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected            \f8   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Inconsistent Use of override and virtual",
        "body": "  In solidity, it is not mandatory to use the override keyword when implementing a function from a parent interface.  For  the  sake  of  consistency,  either  none  or  all  implementations  should  be  annotated  with override.  Additionally, Pool.setGovernor is set as virtual although no contract inherits from Pool.  CS-EVERSTKB2C-006  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   The Sum of Shares Can Be Less Than the",
        "body": " Total Shares Supply  Due  to  some  rounding  errors,  the  shares  distributed  to  individual  stakers  for  a  given  round  might  not match the total number of shares minted for that round, i.e. _amountToShare(X+Y+Z) >= _amountT oShare(X)  +  _amountToShare(Y)  +  _amountToShare(Z).  The  difference  in  value  cannot  be claimed by anyone.  CS-EVERSTKB2C-007  Everstake - ETH B2C Staking -   33  InformationalVersion1InformationalVersion1      \f9   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "9.1   Deposited Amount Is Gifted if Less Than 1",
        "body": " Share  Users should be aware that any amount resulting in less than a share will be a donation to the pool. Even though  this  should  be  avoided  by  the  minimum  stake  constraint,  it  is  possible  to  stake  and  unstake pending, leaving a small amount to be activated, which may result in 0 share.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "9.2   Users May Miss Rewards on Closed Validator",
        "body": "  If  some  validator  is  expected  to  close,  i.e.  EXPECTED_CLOSE_VALIDATORS  >  0,  any  rewards accumulated in the RewardsTreasury that is above 32ETH will be considered as a stake returned by a closing  validator  instead  of  a  reward.  So  any  staker  withdrawing  when  one  or  more  validators  are expected to close and when 32ETH of staking rewards or more are available in the RewardsTreasury will miss that reward.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "9.3   Users May Not Be Fully Refunded in Case of",
        "body": " Slashing  According  to  the  Trust  Model,  Everstake  plans  to  deploy  an  emergency  treasury  fund,  but  do  not guarantee all the users to be fully refunded in case of slashing.  Everstake states:  We understand and don't neglect the risks related to slashing and we will have a special Emergency Treasury Fund - an Ethereum wallet address for Emergency Cases. Emergency Treasury fund will have some amount of Ethereum to cover at least partly possible unlikely slashing related issues. We also plan to send some defined share of Ethereum service fee received from the Pool by Everstake, approximately 10%.  Example: Pool Service fee is 10% Emergency Treasury Fund share is 10% If all Validators within the Pool generated 10 000 ETH Then Everstake will receive 1 000 ETH as a Pool Service Fee And 100 ETH from Pool Service fee will be send to Emergency Treasury Fund  Everstake - ETH B2C Staking -   34  NoteVersion1NoteVersion1NoteVersion1          \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Public Setter Functions Can Be Frontrun",
        "body": "  The following functions can only be executed once and have no access controls:  1. FxBaseRootTunnel.setFxChildTunnel  2. FxBaseChildTunnel.setFxRootTunnel  3. FxRoot.setFxChild  4. FxChild.setFxRoot  5. FxERC20.initialize  6. FxERC721.initialize  7. FxERC1155.initialize  If  deployment  and  initialization  is  not  done  within  one  transaction  it  would  be  possible  for  a  malicious actor to frontrun the deployer's call to the functions and instead call them with malicious values first. This will cause the deployer's function call to revert.  FxBaseRootTunnel  and  FxBaseChildTunnel  are  to  be  inherited  by  contracts  in  order  to  use  the bridging  functionality  of  the  Fx  Portal.  This  may  lead  to  problems  with  their  deployment.  Implementors should be aware of this behavior, mitigate this and ensure/verify that initialization is done correctly. If their setTunnel functions are frontrun, the contract will need to be redeployed. This can be expensive in terms of gas.  The  Wrapper  contracts  FxRoot  and  FxChild  for  the  interaction  with  the  StateSender  have  already been  deployed  and  initialized  correctly.  If  a  new  instance  of  one  of  these  contracts  is  deployed,  the the  Token  contracts the  deployer  must  verify  FxERC20/ERC721/ERC115  used  the in  initialize() function is called from contracts within the same transactions.  the  examples  minimal  proxy  contracts  are  deployed   functions  are  called  correctly.  For   that   Polygon - Fx Portal -   12  DesignCorrectnessCriticalHighMediumRiskAcceptedCodePartiallyCorrectedLowDesignMediumVersion1RiskAccepted          \fRisk accepted:  Polygon states:  It is a known risk that initialization functions can be frontrun, but this is low-risk since there is no incentive for a malicious actor to do so.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Use (Up to Date) Dependencies",
        "body": "  Several  contracts  present  in  lib  or  tokens  are  copy  &  pasted  from  third  party  repositories.  An exception  to  this  pattern  is  the  SafeERC20  library  which  is  imported  from  a  dependency  listed  in  the package.json  file.  This  pattern  is  generally  preferable.  Note  that  several  of  the  copy  &  pasted dependencies are also from this OpenZeppelin contracts dependency, hence could simply be imported from there.  Package.json  package-lock.json allows to fix specific version.  the  dependencies  and   lists   the   requirements  on   the  version,  while  This allows to effortlessly update to newer versions of these contract which may include bug fixes. Note that  this  must  be  done  with  due  care  as  functionality  could  change.  Once  a  new  version  has  been deemed suitably safe, the new version can be fixed in package-lock.json.  Most copy & pasted contracts are old versions, furthermore the version of the OpenZeppelin dependency is  outdated.  Notably,  the  implementation  of  ERC721  contains  several  changes  reloading  state  after beforeTokenTransfer(), which may have updated this data.  Code partially corrected:  The  dependencies  in  package.json  were  changed  to  more  recent  versions.  ERC20.sol  and IERC20.sol were updated to OpenZeppelin v4.7.3.  The other copy & pasted contracts in lib have not been updated.  Polygon - Fx Portal -   13  DesignMediumVersion1CodePartiallyCorrected          \f7   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings   mapToken() Callable Only by Mappers   -Severity Findings   Description of toBoolean() Is Incorrect    FxMintableERC20RootTunnel connectedToken Initialized Incorrectly   -Severity Findings   Codehash Variable Type Could Be Set to Immutable    FxMintableERC20ChildTunnel Has No withdrawTo Function    FxMintableERC20RootTunnel Events Missing    Outdated Compiler Version    Return Value of _checkBlockMembershipInCheckpoint()    SafeMath Library Is Redundant    Unused Variable in FxMintableERC20RootTunnel    _processMessageFromChild Comment Incorrect   0  1  2  8  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   mapToken() Callable Only by Mappers",
        "body": "  In FxERC20RootTunnel and FxERC721RootTunnel, the mapToken function is annotated as follows:  /**  * @notice Map a token to enable its movement via the PoS Portal, callable only by mappers  * @param rootToken address of token on root chain  */ function mapToken(address rootToken) public {  The function however has no access control, anyone may map a token.  The  same  function  in  FxERC1155RootTunnel  lacks  a  function  description.  It  also  has  no  access control.  Specification changed:  The comment has been changed to:  //@notice Map a token to enable its movement via the PoS Portal, callable by anyone  Polygon - Fx Portal -   14  CriticalHighSpeci\ufb01cationChangedMediumSpeci\ufb01cationChangedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCorrectnessHighVersion1Speci\ufb01cationChanged        \f7.2   Description of toBoolean() Is Incorrect  In RLPReader, the description of toBoolean() states that \"any non-zero byte is considered true\". The function takes an RLPItem as input.  In  RLP  encoding,  byte  values  in  the  range  [0x80-0xff]  are  encoded  as  2  bytes  like  this: [0x81, the_byte]. For RLPItems encoding such values, toBoolean() will revert, since it enforces that the length of the RLPItem is 1. This is a mismatch, as these values are non-zero and should return true according to the comment.  Specification changed:  The comment has been changed to:  // any non-zero byte < 128 is considered true  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   FxMintableERC20RootTunnel",
        "body": " connectedToken Initialized Incorrectly  the  _deployRootToken   rootToken's In  _connectedToken field is initialized as rootToken. This means the rootToken's _connectedToken will be itself, not the childToken on the other chain.  function  of  FxMintableERC20RootTunnel,   the     The _connectedToken is now correctly initialized with the childToken.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   Codehash Variable Type Could Be Set to",
        "body": " Immutable  In  the  following  contracts  the  variable  childTokenTemplateCodeHash  could  be  changed  to  an immutable:  1. FxERC20RootTunnel.sol  2. FxERC721RootTunnel.sol  3. FxERC1155RootTunnel.sol  This avoids unnessesary and expensive reads from storage, hence reduces the gas consumption.  Polygon - Fx Portal -   15  CorrectnessMediumVersion1Speci\ufb01cationChangedCorrectnessMediumVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \f  These and more variables have been declared immutable.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   FxMintableERC20ChildTunnel Has No",
        "body": " withdrawTo Function  The  FxMintableERC20ChildTunnel  has  no  withdrawTo  function,  unlike  the  other  example contracts. Tokens can only be withdrawn to the same address on the RootChain as the calling address on the ChildChain.  This may make it impossible for some smart contract wallets to bridge tokens, since the user may not be able to deploy the smart contract wallet at the same address on the other chain.    A  withdrawTo()  function  has  been  added,  which  takes  a  receiver  argument.  It  calls  an  internal function  _withdraw(),  which  is  identical  to  the  previous  withdraw()  function,  except  that  it  calls _sendMessageToRoot() with the receiver address instead of msg.sender.  The public withdraw() function's functionality is unchanged.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.6   FxMintableERC20RootTunnel Events Missing",
        "body": "  The  FxMintableERC20RootTunnel  contract  emits  no  events  when  tokens  are  deposited  or withdrawn, which is different behavior than all other example contracts.    The missing events have been added.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.7   Outdated Compiler Version",
        "body": "  The project's hardhat config specifies an outdated version of the Solidity compiler.  solidity: { version: \"0.8.0\",  Known bugs in version 0.8.0 are:  https://github.com/ethereum/solidity/blob/develop/docs/bugs_by_version.json#L1685  More information about these bugs can be found here: https://docs.soliditylang.org/en/latest/bugs.html  At the time of writing, the most recent Solidity release is version 0.8.16.  Polygon - Fx Portal -   16  DesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \f  The compiler version has been updated to 0.8.17.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.8   Return Value of ",
        "body": " _checkBlockMembershipInCheckpoint()  FxBaseRootTunnel._validateAndExtractMessage()   to In  _checkBlockMembershipInCheckpoint() is made. This internal function has a return value which however is ignored.  call   a     The return value has been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.9   SafeMath Library Is Redundant",
        "body": "  An  old  version  of  FxERC20MintableRootTunnel.  the  SafeMath   library  (made   for  Solidity  <0.8)   is  used   in  ERC20  and  The main use of SafeMath was previously to revert on arithmetic overflow. As of Solidity 0.8, overflow checks were introduced into the Solidity compiler.  This makes the use of SafeMath redundant.    The SafeMath library has been removed.  ERC20.sol  and  IERC20.sol  have  been  updated  to  OpenZeppelin  v4.7.3,  which  does  not  use SafeMath. The required IERC20MetaData.sol has also been added.  FxERC20MintableRootTunnel no longer uses SafeMath.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.10   Unused Variable in",
        "body": " FxMintableERC20RootTunnel  The  childTokenTemplateCodeHash  variable  in  FxMintableERC20RootTunnel  is  declared  but never used.    Polygon - Fx Portal -   17  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \fThe unused variable has been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.11   _processMessageFromChild Comment",
        "body": " Incorrect  The comment of _processMessageFromChild() in FxBaseRootTunnel says that is called from the onStateReceive function. This is incorrect. It is actually called from receiveMessage().  Specification changed:  The comment has been changed to  //This is called by receiveMessage function.  Polygon - Fx Portal -   18  CorrectnessLowVersion1Speci\ufb01cationChanged        \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   FxERC20RootTunnel Cannot Map All ERC-20",
        "body": " Tokens  mapToken in FxERC20RootTunnel calls ERC20.decimals().  //name, symbol and decimals ERC20 rootTokenContract = ERC20(rootToken); string memory name = rootTokenContract.name(); string memory symbol = rootTokenContract.symbol(); uint8 decimals = rootTokenContract.decimals();  In the ERC-20 standard, decimals is optional.  If the rootToken does not have a decimals function, the call will revert and it will be impossible to map this token.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   _processMessageFromRoot() Must Succeed",
        "body": "  Messages synced from Ethereum to Polygon via the StateSender are executed only once. This execution through  FxChild.onStateReceived()  has  5  million  gas  available.  Should  the  execution  revert  for any reason, the message is lost.  The  individual  implementation  of  _processMessageFromRoot()  of  smart  contracts  using  the FxStateChildTunnel  of  the  Fx  Portal  must  respect  that.  They  should  not  contain  external  calls  or anything that may revert if lost messages cannot be tolerated.  Polygon - Fx Portal -   19  NoteVersion1NoteVersion1      \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Balancer Flashloan Can Break Proxy Access",
        "body": " Rights  The OperationExecutor supports Flashloans. For this, a callback interface for the FlashloanProvider must be  provided.  As  the  UserProxy  does  not  have  the  required  interface,  this  callback  is  made  to  the OperationExecutor, which then calls execute() to switch back into the Proxy's account/storage context  CS-DMAV2-005  The transaction flow for Flashloans is as shown below:  Context: UserProxy  UserProxy delegatecall -> OperationExecutor -> TakeFlashloan Action -> FlashloanProvider  Context: OperationExecutor  FlashLoan Callback -> UserProxy.execute()  Context: UserProxy  OperationExecutor.callbackAggregate()  To facilitate this flow, the OperationExecutor is given the permission to call execute() on the UserProxy for the duration of the Flashloan.  In the case of using Maker's Flashloan, this callback is correctly restricted to only call execute() on the initiator (msg.sender) of the Flashloan.  For the Balancer integration however, the initiator is given in calldata of the Balancer call instead of Balancer returning the msg.sender. This means there can be a callback into any proxy for which the OperationExecutor  has  execution  rights,  even  if  Balancer  was  called  from  an  address  other  than  the Proxy.  This is an issue if there is an unsafe external call in any action nested in the FlashLoan. Any address can reenter the receiveFlashloan function of OperationExecutor by taking a Flashloan on Balancer, and use its execute() privileges to execute any actions from within the context of the proxy.  Summer.fi - DeFi Modular Actions v2 -   12  CriticalHighCodeCorrectedMediumLowCodeCorrectedCodeCorrectedCodeCorrectedSecurityHighVersion1CodeCorrected         \fWe illustrate what an attack could look like using the following set of actions performed by a user:  1. TakeFlashloan  2. SwapAction  3. TransferAction  First, the user will take a Flashloan. This will give the OperationExecutor permission to call execute() on  the  proxy.  Second,  the  user  swaps  tokens.  Assume  that  this  makes  an  unsafe  external  call  to  an attacker's contract, for example through a transfer hook in the traded token.  Now, the attacker has control flow and can execute the reentrancy attack. They take another Flashloan, setting  the  FlashloanRecipient  to  the  OperationExecutor  and  the  initiator  to  the  UserProxy. receiveFlashloan()  will  be  called,  which  calls  execute()  in  the  UserProxy.  The  functionSelector will  always  be  callbackAggregate,  but  the  flData.calls  is  provided  by  the  attacker  when  they take  their  Flashloan.  Now,  those  actions  chosen  by  the  attacker  will  be  executed  in  the  context  of  the UserProxy. For example, the attacker can call the SendToken, SetApproval or Withdraw action and drain all funds in the proxy.  The actions taken by the attacker will be recorded in the txStorage and it will be checked if they belong to an operation that exists at the end of the execution. This means the attack only works if there exists an action that is the same as the one the user called, but with additional actions added.  For example, for the set of actions above to be attackable there would have to be another legal operation that has those steps and additional ones at the location of the reentrancy.  Such as:  1. TakeFlashloan  2. SetApproval  3. SwapAction  4. TransferAction  The same issue is also present in OperationExecutor v1, when taking a Balancer Flashloan and making an unsafe external call. However, here the limitation of the actions needing to form a legal operation is not present, as the operations are only checked in the beginning, not at the end. So an attacker can add any operations they want using reentrancy.  In summary, if there is an unsafe external call (reentrancy) in any nested action taken by a user during a Balancer Flashloan, their entire Proxy's balance can be drained.    Nested  OperationExecutorV2 at a time when it has execution rights on the Proxy of the original caller.  flashloans  are  now  prevented,   the  main  concern  of   this  solves   reentering   the  Technically this works as follows: OperationExecutorV2 now features a flag isFlashloanInProgress. Upon  a  callback  through  one  of  the  flashloan  interfaces  (the  callback  by  the  flashloan  provider  is executed in the context of the OperationExecutorV2) checkIfFlashloanIsInProgress ensures no flashloan is in progress already by ensuring the flag is equal to 1. processFlashloan() sets the flag to 2 before dispatching the callback to the Proxy context and resets the flag to 1 after it returned.  Note that outisde of flashloan actions, the following still applies:  For the Balancer integration however, the ``initiator`` is given in calldata of the Balancer call instead of Balancer returning the ``msg.sender``.  It is important that outside of flashloan actions the OperationExecutorV2 does not have any priviledges on any proxy.  Summer.fi - DeFi Modular Actions v2 -   13  \f6.2   Inefficient txStorage  In OperationExecutor's aggregate(), actions are written into txStorage as follows:  txStorage.actions = abi.encodePacked(txStorage.actions, targetHash);  CS-DMAV2-006  This  unnecessarily  reads  all  past  actions  out  of  storage  and  then  rewrites  the  same  data  into  storage again, which costs gas each time. To reduce gas consumption, just the new data could be added at the end.  Writing  to  (multiple)  storage  slots  is  expensive.  It  would  also  be  possible  to  hash  actions  one  by  one instead of at the end, allowing only a single storage slot to be used instead of one for each action.    aggregate() now pushes the executed action to the storage without reading the previous actions every time:  txStorage.actions.push(targetHash);  executeOp()  retrieves  the  stored  actions  once  after  the  execution  of  aggregate()  completed  and encodes them, the result is the same as the previous txStorage.actions.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   SafeMath Is Not Needed",
        "body": "  An outdated version of the SafeMath library is used.  Since  Solidity  0.8,  the  overflow  checks  that  were  previously  done  in  SafeMath  are  now  enforced  by default. As a result, the library is no longer needed.  If SafeMath is used for the custom revert strings, the new version of SafeMath should be used.  CS-DMAV2-003    SafeMath has been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   SendToken Functionality Differs for Native",
        "body": " Tokens  The SendToken action has the following NatSpec:  CS-DMAV2-004  Summer.fi - DeFi Modular Actions v2 -   14  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                        \f//@title SendToken Action contract //@notice Transfer token from the calling contract to the destination address  For ERC-20 tokens, the implementation sends tokens that are held by the delegatecalling contract.  However, for native ETH, the implementation only forwards ETH that was sent as msg.value along with the originating function call. In this case send.amount is ignored. It cannot send ETH that was already held by the delegatecalling contract.  After  the  intermediate  report  the  description  was  updated  and  now  explains  the  different  behavior  for ERC-20 tokens and Ether.  The description for Ether is inaccurate however:  The amount of ETH that can be transferred is either the whole or partial (whether some amount has been used in other actions) amount from the amount that the transaction has been called with ( msg.value ). If the proxy contract contains any prior ETH balance, it CANNOT be transferred.  The delegatecalls into the code of the actions during the loop in aggregate() preserve msg.value. payable(address).transfer(msg.value) attempts to transfer this amount which succeeds only if sufficient  Ether  is  available.  Either  the  Ether  sent  along  the  original  call  has  not  yet  been  spent  and  is available for the onward transfer or the Proxy has additional Ether balance which can be used.    SendToken  has  been  changed,  the  behavior  for  the  native  token  now  matches  the  functionality  for ERC-20 tokens. The new description now describes the actual behavior of the action.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   ERC-1967",
        "body": "  The description of library StorageSlot reads:  CS-DMAV2-002  This library is a small implementation of EIP-1967. Unlike that EIP which usage is to store an address to an implementation under specific slot, it is used to storage all kind of information that is going to be used during a transaction life time.  While  the  library  is  suitable  for  the  intended  use,  mentioning  EIP-1967  can  be  confusing  and  strictly speaking  is  incorrect:  This  EIP  standardises  the  storage  slots  for  the  the  following  addresses: implementation, beacon and admin only. The EIP states:  More slots for additional information can be added in subsequent ERCs as needed.  The StorageSlot library borrows the idea how the storage slot is chosen to avoid any collision with high probability  from  the  EIP-1967  but  is  otherwise  not  connected  to  and  does  not  implement  or  adhere  to EIP-1967.  Summer.fi - DeFi Modular Actions v2 -   15  InformationalVersion1Speci\ufb01cationChanged      \fSpecification changed:  Summer.fi removed the misleading reference to ERC-1967 from the description.  Summer.fi - DeFi Modular Actions v2 -   16  \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Missing Event",
        "body": "  In OperationsRegistry, the transferOwnership function does not emit an event.  CS-DMAV2-001  Acknowledged:  Summer.fi states they do not emit events on ownership change in any contract.  Summer.fi - DeFi Modular Actions v2 -   17  InformationalVersion1Acknowledged    \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   DsProxy With Unsupported Authority",
        "body": "  A user is free to set the authority contract of his own DSProxy. Depending on the authority contract set, which may be arbitrary, ProxyPermission.givePermission() may not be successful.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Reentrancy Could Delete Transient Storage",
        "body": "  The executeOp function in OperationExecutor could be reentered, which deletes the txStorage.  However, this is only possible if the msg.sender has execute() privileges for the executeOp function on the UserProxy and can reenter.  This should only be the case for the user, meaning they could only circumvent the legal operations check for themselves by deleting txStorage.  Summer.fi - DeFi Modular Actions v2 -   18  NoteVersion1NoteVersion1      \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Debt Recovery",
        "body": "  Debt recovery via single installment is not enforced. The Redeem stage of the PortfolioDebtToken can start with no assets inside the contract. In addition, the single redemption event is not guaranteed as well. These properties are hard to enforce, but users need to be aware of the potential issues.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Gas Optimizations",
        "body": "  The  function  PortfolioDebtToken.status  does  two  storage  loads  (SLOAD)  upon  the  assertion assert(mintDeadline < redeemDeadline); followed by one or two more SLOAD in the if-else block.  The  same  result  can  be  achieved,  by  burning  less  gas,  and  by  loading  only  one  of  the  two variables in the assertion.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Mint and Redeem Stage Durations",
        "body": "  the   checks  enforce   While  statuses (Mint->Redeem->Recover), the actual durations can be too short for the actions to be performed. In the extreme  case,  the  difference  between  mintDeadline  and  redeemDeadline  can  be  less  than  the difference between timestamps of two consecutive blocks.  sequence  of  PortfolioDebtToken   the  proper   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Zero Value Events",
        "body": "  Even though the mint and deposit are disabled via the 0 max value setting, the 0 value deposits can still be performed by the users at any point. In the same way, the 0 value withdrawals and redeems can be performed not in redeem state of the PortfolioDebtToken. While such actions do not change the state of the contract, Deposit and Withdraw events will be still emitted.  Archblock & TrueFi - Portfolio Debt Token -   10  InformationalVersion1InformationalVersion1InformationalVersion1InformationalVersion1              \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   IERC20 Incompatible With Tether",
        "body": "  USDT,  one  of  the  collaterals,  is  not  fully  ERC20  compliant,  notably  some  features  lack  the  mandatory return value to comply with the standard.  In  MultiplyProxyActions  the  interface  IERC20  is  used  to  interact  with  the  token  contracts.  In  the interface definition a return value is expected for e.g., the approve and the transfer functions. Hence the Solidity compiler generates bytecode that expects a return value and reverts if there is none.  Risk accepted:  Oazo Apps Limited replied:  Oazo Apps Limited - Multiply -   11  DesignCorrectnessCriticalHighMediumRiskAcceptedLowAcknowledgedAcknowledgedAcknowledgedCodePartiallyCorrectedAcknowledgedRiskAcceptedCodePartiallyCorrectedAcknowledgedAcknowledgedRiskAcceptedAcknowledgedCodePartiallyCorrectedAcknowledgedRiskAcceptedDesignMediumVersion1RiskAccepted                \fCurrently, Tether is not used as collateral in Maker Protocol. In case Tether is onboarded to Maker Protocol, the multiply feature will be disabled for it.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Flash Loan Preparation When Skipping",
        "body": " Flashloan  In  version  two,  flashloans  can  be  skipped.  However,  some  parameters  for  taking  the  flashloan  are prepared  even  though  they  will  remain  unused.  More  specifically,  the  assets,  amounts  and  modes arrays  are  set  which  increases  gas  cost  of  the  actions  skipping  flashloans.  That  part  of  flashloan preparation could be moved to the new takeAFlashloan function which would also further reduce the size of the code.  Acknowledged:  Oazo Apps Limited replied:  This is a minor gas inefficiency, will be fixed after MVP.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Unnecessary Execution of Code",
        "body": "  _getDrawDart()  returns  the  change  in  debt  needed  in  order  to  have  access  to  the  DAI  amount specified in paramter wad.  This function executes two external calls which could be omitted under certain conditions:  In case the DAI amount needed is 0 the function the function could return 0 immediately  In case enough DAI is available already, the call to Jug.drip() could be omitted.  Note  that  with  the  new  skip  flashloan  functionality  the  case  that  enough  DAI  is  already  available  will happen frequently and hence the code should be optimized for it.  Acknowledged:  Oazo Apps Limited replied:  This is a minor gas inefficiency, will be fixed after MVP.  Oazo Apps Limited - Multiply -   12  DesignLowVersion2AcknowledgedDesignLowVersion2Acknowledged                    \f6.4   Approval for Full Balance Instead of Amount Transferred  In  MultiplyProxyActions._closeWithdrawDai()  the  exchange  contract  is  approved  to  transfer the full token balance of the MultiplyProxyActions contract. The exchange contract however uses this approval only to transfer ink amount of collateral.  Acknowledged:  Oazo Apps Limited replied:  Exchange contract is fully trusted by the multiply proxy actions contract.  To  the  question  why  not  a  \"infinite\"  (uint256(-1))  approval  is  given  once  for  all  executions  to  the exchange contract, Oazo Apps Limited responded:  Infinite approval could cause unexpected implications, therefore it is skipped in the scope of the MVP; the only negative impact is gas inefficiency.  Note:  This  issue  was  raised  and  discussed  in  Version  1  of  the  code  reviewed  where  the  skipFL functionality did not yet exist. After the introduction of the skipFL functionality access control to the swap functions of the Exchange contract has been removed, hence the trust model has changed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Avoid Repeated Calls",
        "body": "  In  MultiplyProxyActions.joinDrawDebt(),  IManager(manager).urns(cdpData.cdpId)  is called twice in succession. Caching the address of the urn would be more efficient.  IManager(manager).urns(cdpData.cdpId)  for Additionally,  called  closeVaultExitCollateral()  and  closeVaultExitDai().  For  both,  in closeVaultExitGeneric()  and  the  third  call  is  in  wipeAndFreeGem().  The  second  call  is  in _closeWithdrawCollateral() and _closeWithdrawDai() respectively. Similarly, the same holds for IManager(manager).vat().  times  first  call   three  the   is   is   Moreover,  IVat(vat).hope(DAIJOIN)  is  called  on  every  increase  action  in  the  context  of MultiplyProxyActions  in  the  joinDrawDebt  function.  However,  the  opposite  function  nope  is  never called,  meaning  that  DAIJOIN  will  always  be  able  to  modify  the  gem  or  DAI  balance  of MultiplyProxyActions.  As  this  behaviour  is  required  and  the  permission  is  never  revoked,  it  could  be called only once in the constructor to reduce the amount of needed gas.  Code partially corrected:  in  joinDrawDebt()  was  optimized  by  caching   The  occurence  to IManager(manager).urns(cdpData.cdpId)  during  the  flow  of  closing  and  exiting  have  been reduced from three to two. For the last reported repeated call, IVat(vat).hope(DAIJOIN) the code remained unchanged.  the  value.  The  calls   Acknowledged:  Oazo Apps Limited replied for the unchanged sub-issues:  Oazo Apps Limited - Multiply -   13  DesignLowVersion1AcknowledgedDesignLowVersion1CodePartiallyCorrectedAcknowledged                \fThis is a minor gas inefficiency, will be fixed after MVP.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Breaks for Collaterals With More Than 18",
        "body": " Decimals  Function convertTo18 converts the amount into wad as follows:  wad = amt.mul(10 ** (18 - IJoin(gemJoin).dec()));  For  tokens  with  more  than  18  decimals,  the  subtraction  results  in  an  underflow.  The  subsequent exponentiation and multiplication likely overflow resulting in a random value returned.  Risk accepted:  Oazo Apps Limited replied:  Such approach is consistent with the current Multi-Collateral DAI implementation and does not affect any existing collateral.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Event Issues",
        "body": "  There are several issues regarding events:  1. The callback function executeOperation in MultiplyProxyActions.sol contains the logic for using the flash loan. It emits the event FLData, logging how much was borrowed and how much is to be returned to Aave. It is emitted as follows:  emit FLData(IERC20(DAI).balanceOf(address(this)),borrowedDaiAmount);  While borrowedDaiAmount actually specifies the value that must be returned to Aave, the balance of  the  MultiplyProxyAction  contract  may  not  be  the  amount  that  was  borrowed  since  the  method increaseMultipleDepositDai may also increase the balance.  2. Event  FLData  in  MultiplyProxyActions.sol  indexes  the  amount  borrowed  and  the  amount  to  be returned. While in general indexing events is useful, there is no direct use of indexing this event and, thus, the cost of emitting this event could be reduced.  3. Event AssetSwap in Exchange.sol is unindexed. It could be helpful to index the assets associated  with this event.  4. Event  FeePaid  in  Exchange.sol  does  not  log  the  beneficiary.  This  issue  is  related  to  issue feeRecepient of AddressRegistry and how it is resolved. If the receiver of the fee is not fixed for the contract, then logging the beneficiary could be useful since the beneficiary of the fee may change.  Code partially corrected:  Oazo Apps Limited - Multiply -   14  DesignLowVersion1RiskAcceptedDesignLowVersion1CodePartiallyCorrectedAcknowledged                  \f1. Corrected: The event does not emit the balance anymore. Now, the difference between the balance  and depositDai is emitted.  2. Corrected: FLData is now unindexed.  3. Corrected: assetIn and assetOut are indexed.  4. Not corrected: FeePaid now logs the beneficiary. Since the feeBeneficiary is public and cannot  be changed, it is not necessary to log the beneficary. Gas costs could be reduced.  However, Oazo Apps Limited responded to that last point as follows:  Such approach allows us to immediately find fee beneficiary for every future instance of exchange; it results in a minor gas inefficiency.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   Repeated Identical Multiplications",
        "body": "  Some  multiplications  are  done  repeatedly  within  the  same  functions.  E.g.,  in  _getDrawnDart(), wad.mul(RAY) is calculated three times. Avoiding repeated multiplications and calculating it only once and storing the result may be favorable.  Acknowledged:  Oazo Apps Limited replied  The outcome of the proposed fix is negligible, however, it is prioritized for a future update.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   Unchecked Return Values and Non-Compliant ",
        "body": " IGem Interface  The IGem Interface is used when handling collateral inside the MultiplyProxyActions contract. The return values of these calls is, however, never checked. While most ERC-20 tokens revert on a failed transfer, according to the ERC-20 specification it is sufficient to return false. A collateral with this behavior may not be supported correctly.  function approve(address, uint) virtual public; function transfer(address, uint) virtual public returns (bool); function transferFrom(address, address, uint) virtual public returns (bool);  Additionally,  note  that  the  function  approve  defined  in  IGem  has  no  return  value.  According  to  the ERC-20 specification ( https://eips.ethereum.org/EIPS/eip-20 ) this function must have a boolean return value:  function approve(address _spender, uint256 _value) public returns (bool success)  Oazo Apps Limited - Multiply -   15  DesignLowVersion1AcknowledgedDesignLowVersion1RiskAccepted                \fRisk accepted:  Oazo Apps Limited replied:  Such implementation is compliant with the current Maker Protocol - it was consulted and confirmed with the Maker DAO\u2019s Protocol Engineering Core Unit.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   Unnecessary Call of getAaveLendingPool",
        "body": "  After  receiving  the  requested  flash  loan  from  Aave,  its  lending  pool  contract  calls  function executeOperation. As the lending pool is the message sender of this call, it would be unnecessarily expensive  to  retrieve  the  lending  pool  address  from  Aave's  lending  pool  provider.  However,  in executeOperation of contract MultiplyProxyActions the lending pool is retrieved as follows:  ILendingPoolV2 lendingPool = getAaveLendingPool(addressRegistry.aaveLendingPoolProvider);  getAaveLendingPool retrieves the Aave lending pool address from the lending pool provider. Thus, gas could be saved.  Acknowledged:  Oazo Apps Limited replied:  Optimisation will be done in a future version of the contract.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.11   Variables Could Be Immutable and Constant",
        "body": "  In  Exchange.sol  the  token  swap  logic  is  defined.  The  state  variable  feeBase  is  initialized  upon declaration and the state variable fee is initialized in the constructor. Both cannot be modified. Hence, they could be declared as constant and immutable respectively.  Code partially corrected:  feeBase was made constant. fee now has a setter and can no longer be immutable. However, with the updates Oazo Apps Limited decided to stick with the feeBeneficiaryAddress in Exchange.sol. However, this variable cannot be modified and, hence, it could be made immutable.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.12   _getWipeDart() Returns art When Closing",
        "body": "  _getWipeDart()  is  used  in  MultiplyProxyActions.wipeAndFreeGem()  to  determine  the amount for dart to be passed to frob(). For closing operations, the intention is to wipe the whole art of the  urn  and,  thus,  calling  _getWipeDart()  creates  an  overhead  in  computation  as  it  will  return  the whole  art  of  the  urn.  The  actual  value  would  be  available  even  before  calling  wipeAndFreeGem().  Oazo Apps Limited - Multiply -   16  DesignLowVersion1AcknowledgedDesignLowVersion1CodePartiallyCorrectedDesignLowVersion1Acknowledged                        \fWhen closing a vault, immediately before the call to wipeAndFreeGem() the ink of the urn is querried from the vat:  (uint256 ink, ) = IVat(vat).urns(cdpData.ilk, urn);  Note  that  the  second  return  value,  the  art  of  the  urn  is  dropped.  Hence  the  value  would  be  available without any meaningful extra gas overhead. Therefore, the cases of wiping some and wiping all art when freeing gem could be distinguished, as it is similarly done in the DSS Proxy Actions contract, to reduce the gas cost of multiply closing actions.  Acknowledged:  Client  responded  that  they  want  to  remain  consistent  with  the  original  Proxy  Actions  in  the  Maker Protocol and refers to the DssProxyActions contract.  vault)  one  would  already   In  the  function  of  DssProxyActions  refered  to,  wipeAllAndFreeETH  is  public  and  works  with  the arguments passed. In MultiplyProxyActions, wipeAndFreeGem is an internal function. Depending on the call path one already knows whether it's a full or partial wipe. Notably in the case of a full wipe (closure of the  to (uint256 ink, ) = IVat(vat).urns(cdpData.ilk, urn); (where the returned value for art is  currently  ignored).  Note  that  the  original  Proxy  Actions  contract  implements  two  different  functions wipeAllAndFreeGem()  Actions, wipeAllAndFreeGem()  queries  vat.urns()  for  dart  while  in  MultiplyProxyActions  this  call  is already  made  in  the  function  calling  wipeAndFreeGem()  so  the  identical  functions  cannot  but  the concept could be reused.  wipeAndFreeGem().   for  dart  due   the  amount   original   Proxy   know   and   call   the   the   to   In   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.13   transfer Is Used for ETH Transfers",
        "body": "  Solidity  offers  different  options  to  perform  ETH  transfers.  When  performing  a  decrease  action withdrawing  collateral,  MultiplyProxyActions  receives  ETH  in  return  for  the  WETH  withdrawn  from  the vault in function _withdrawGem(). In the same function, the solidity transfer feature for sending ETH from the MultiplyProxyActions contract to the user. As transfer sends a fixed gas cost along with the funds, it is assumed that EVM gas costs remain constant in the future. Note that gas costs have change in  the  past,  which  has  led  to  issues  with  the  use  of  transfer.  Hence,  possible  integration consequences need to be considered.  Risk accepted:  Oazo Apps Limited replied:  Malfunction requires Ethereum hard fork. We will update the contract if that occurs.  Oazo Apps Limited - Multiply -   17  DesignLowVersion1RiskAccepted          \f7   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  0  0  7  10  -Severity Findings  -Severity Findings  -Severity Findings   withdrawCollateral Is Added to borrowCollateral    Disabled Optimizer   Impossible Decrease Operations   Incorrect Decimals When Handling Collateral    Unclear Parameter Specification    Undocumented Public Functions   feeRecepient of AddressRegistry   -Severity Findings   Cannot Update Fees    Specification Mismatches    Unused Constant    skipFL Case in Flashloan Callback    Code Duplication    No Check on Amount Received From Flash Loan    Possible Casting Overflow    Unnecessary transferFrom    Use Available Constant and Avoid Call   increaseMultipleDepositDai Is Payable   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   withdrawCollateral Is Added to",
        "body": " borrowCollateral  In the updated specification received after the intermediate report, borrowCollateral is specified as follows:  If a Multiply decrease action: the amount of collateral that is needed to decrease multiple (it includes the ``withdrawCollateral`` amount if any is specified).  Oazo Apps Limited - Multiply -   18  CriticalHighMediumSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedLowCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCorrectnessMediumVersion2Speci\ufb01cationChanged            \fThat  implies  that  borrowCollateral  already  includes  withdrawCollateral.  However,  in  function _decreaseMP  the  amount  of  collateral  to  draw  from  the  vault  passed  to  wipeAndFreeGem()  is computed as follows:  cdpData.borrowCollateral.add(cdpData.withdrawCollateral)  Thus, withdrawCollateral is accounted twice and wipeAndFreeGem() will exit more collateral than intended.  Specification changed:  The  documentation  has  been  updated  and  no  longer  states  that  borrowCollateral  includes withdrawCollateral.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Disabled Optimizer",
        "body": "  The solidity optimizer has been disabled in the hardhat configuration:  solidity: \"0.7.6\",     settings: {         optimizer: {             enabled: false,             runs: 1000      } },  The optimizer reduces both code size (thereby deployment costs), and execution costs.    The optimizer was enabled.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Impossible Decrease Operations",
        "body": "  wipeAndFreeGem()  is  used  in  each  decrease  operation  to  withdraw  collateral  from  the  vault  to  the MultiplyProxyActions contract. However, the function reverts if the collateral has less than 18 decimals.  function wipeAndFreeGem(     address manager,     address gemJoin,     uint256 cdp,     uint256 borrowedDai,     uint256 collateralDraw ) public {     ...     uint256 wadC = convertTo18(gemJoin, collateralDraw);     IManager(manager).frob(cdp, -int256(wadC), _getWipeDart(vat, IVat(vat).dai(urn), urn, ilk));     IManager(manager).flux(cdp, address(this), wadC);     IJoin(gemJoin).exit(address(this), wadC); }  Oazo Apps Limited - Multiply -   19  DesignMediumVersion1CodeCorrectedDesignMediumVersion1CodeCorrected                \fFollowing scenario could occur if the collateral is GUSD which has only two decimals.  1. Parameter collateralDraw is converted to 18 decimals representations which is stored in local  variable wadC. Meaning that wadC == collateralDraw * (10**16).  2. frob and flux are called with wadC as part of the argument.  3. GemJoin.exit() is also called with wadC as an argument.  4. In  GemJoin  contract's  exit(),  the  GemJoin  contract  will  try  to  call  the  GUSD  contract  to  transfer  wadC tokens.  5. The  transaction  reverts  since  wadC  is  much  higher  than  the  balance  in  GUSD  of  GemJoin  at  that  moment.  Since exiting creates a transfer in the GUSD contract, it must use the amount of decimals the token has.    collateralDraw instead of wadC is now passed to the call to gemJoin.exit() which is in the correct unit.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   Incorrect Decimals When Handling Collateral",
        "body": "  The  functions  _closeWithdrawCollateralSkipFL  and  _closeWithdrawCollateral  receive multiple inputs including the ink of the relevant urn. The ink value has previously been queried from the vat. The ink value is then used as follows:  require(   IERC20(exchangeData.fromTokenAddress).approve(address(exchange), ink),   \"MPA / Could not approve Exchange for Token\" );  The ink value, however, has been adjusted to 18 decimals and hence will be incorrect here for all tokens that do not have 18 decimals.  Note that for the functions _closeWithdrawCollateral and _closeWithdrawDai the ink value is also incorrectly passed to wipeAndFeeGem.    The  updated  implementation  now  passes  cdpData.borrowCollateral  instead  of  ink  when  calling _closeWithdrawCollateralSkipFL and _closeWithdrawCollateral. Inside the called function this parameter is called ink. Althrough this solution technically works, it is not ideal:   Note   that  both   functions  already  cdpData.borrowCollateral separately is redundant.  take   the  struct  cdpData  as  parameter,  so  passing   The  call  to  token.approve()  remains  unchanged.  The  exchange  is  approved  to  transfer  the amount ink (which now is cdpData.borrowCollateral) however the amount the exchange will transfer is exchange.fromTokenAmount.  Risk accepted:  Refactoring / improvements are planned after the MVP.  Oazo Apps Limited - Multiply -   20  CorrectnessMediumVersion1CodeCorrected        \ffor  collaterals  with  non  18  decimals  has  been  uncovered   An  additional  problem  in _closeWithdrawCollateralSkipFL()  after  the  draft  report:  wipeAndFreeGem()  expects  the collateral  amount  in  the  unit  of  the  collateral  token  and  converts  it  to  the  18  decimal  representation. However in _closeWithdrawCollateralSkipFL this conversion is already done before the second call to wipeAndFreeGem(), hence the conversion will happen twice and result in an incorrect value for collaterals with less than 18 decimals. This has been correct by removing the conversion before the call to wipeAndFreeGem().  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   Unclear Parameter Specification",
        "body": "  There  are  several  input  parameters  to  each  call.  These  are  passed  in  three  different  structs: ExchangeData,  CdpData,  AddressRegistry.  Some  definitions  of  the  parameters  of  the  strucs  are unclear and may lead to mistakes.   borrowCollateral  is  specified  to  be  the  collateral  to  buy  with  the  flashloan  in  increase operations.  However,  it  is  used  differently.  More  precisely,  it  is  used  in  function  _decreaseMP  to specify how much collateral to be withdrawn from the vault. The frontend may create mistakes. If the intention  of  borrowCollateral  is  to  be  used  as  the  amount  that  will  be,  together  with depositCollateral,  deposited  to  the  vault,  then  with  positive  slippage,  joinDrawDebt  would deposit too much collateral into the vault.   depositCollateral  is  specified  to  be  the  amount  of  collateral  the  user  deposits  in  increase actions that deposit collateral. For ETH that is not the case since msg.value is used and no check if  it  equals  depositCollateral  is  done.  The  call  will  work  but  the  result  may  differ  from  the expected behaviour.   fromTokenAmount is specified to be the amount of tokens to be exchanged. depositDai is the amount of DAI that should be exchanged jointly with the flashloaned DAI in increase operations. In _increaseMP in the call to swap the tokens to collateral, the to be swapped amount is specified as the  sum  of  fromTokenAmount  and  depositDAI.  However,  according  to  specification, fromTokenAmount should already be accounting for the deposit.   Depending on what the intended use of the parameters is, specifying invariants could be helpful to clarify  for  example  whether  the  fromTokenAmount  in  increase  operations  is  the  sum  of  the flashloaned and deposited DAI.  Clarifying  these  and  similar  ambiguities  may  help  users  to  understand  the  parameters  of  their transactions better.  Specification changed:  The parameters are now more precisely defined.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.6   Undocumented Public Functions",
        "body": "  Function wipeAndFreeGem of the MultiplyProxyActions contract is public. The function is only used internally and there is no valid use case to call it directly. Direct calls to this function will likely fail due to preconditions not being met. Furthermore the documentation does not list it as one of the public functions.  Similarly _collectFee() of the Exchange contract is public despite being used only internally. Here as well the documentation does not list _collectFee() as public function.  Oazo Apps Limited - Multiply -   21  DesignMediumVersion1Speci\ufb01cationChangedDesignMediumVersion1CodeCorrected                \f  The functions are now internal.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.7   feeRecepient of AddressRegistry",
        "body": "  In  the  last  paragraph  of  section  Architectural  decisions  of  the  specification  document  it's mentioned  that  the  feeRecipient  is  part  of  the  off-chain  registry  (the  struct  AddressRegistry passed as function parameter):  A caveat that has been raised is that using an off-chain registry managed by the frontend opens for other frontends using our smart contract while passing their own fee wallet address in the params.  This struct features a field feeRecepient:  struct AddressRegistry {     address jug;     address manager;     address multiplyProxyActions;     address aaveLendingPoolProvider;     address feeRecepient;     address exchange; }  However  in  the  smart  contracts  reviewed,  this  field  is  never  read.  The  exchange  contract  uses  a feeBeneficiary variable set in the constructor.    feeRecepient was removed from the struct.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.8   Cannot Update Fees",
        "body": "  In version two, setFee() was introduced to enable updating the fee variable for fees going to Oazo. The caller must be authorized. However, the only authorized caller is the MultiplyProxyActions contract which does not call setFee() and, hence, the fees cannot be update.    The feeBeneficiary is now also whitelisted and can set fees.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.9   Specification Mismatches",
        "body": "  Oazo Apps Limited - Multiply -   22  CorrectnessMediumVersion1CodeCorrectedDesignLowVersion2CodeCorrectedDesignLowVersion2Speci\ufb01cationChanged                        \fIn  version  two,  new  parameters  to  the  CdpData  struct  were  introduced.  However,  the  methodName element in the struct is unspecified in the documentation while it is used in the code.  Specification changed:  methodName was added to the documentation.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.10   Unused Constant",
        "body": "  In MultiplyProxyActions, a constant ETH_ADDR is defined. However, it is not used in the code.    The constant was removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.11   skipFL Case in Flashloan Callback",
        "body": "  Function  executeOperation  is  the  callback  for  the  Aave  flashloan.  It  is  not  intended  to  be  used  if flashloans are not utilized.  The following code snipped can be found at the end of the function:  if (cdpData.skipFL == false) {   IERC20(assets[0]).approve(     address(getAaveLendingPool(addressRegistry.aaveLendingPoolProvider)),     borrowedDaiAmount   ); }    The code was removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.12   Code Duplication",
        "body": "  When  crafting  the MultiplyProxyActions  contract  have  the  same  code.  This  code  duplication  could  be  removed  by moving the respective code into an internal function.  flashloan  contract,  multiple   to  and  calling   functions  of   the  call   the     The common parts have been extracted into a function takeAFlashLoan.  Oazo Apps Limited - Multiply -   23  DesignLowVersion2CodeCorrectedDesignLowVersion2CodeCorrectedDesignLowVersion1CodeCorrected                        \f7.13   No Check on Amount Received From Flash Loan  The documentation specifies following check on the amount received from the flash loan:  We check in our smart contract whether the delivered amount matches our expected amounts. If not enough funds are delivered we revert the transaction with the message: \u201cFL malfunction\u201d.  However, this check is not made. Moreover, that could allow a malicious Aave to send less funds than requested. Performing an increase operation with personal DAI besides the flashloan may lead to Aave being paid more if the front-end does not set parameters such that this transaction would revert. In any case, there is a mismatch between documentation and implementation.  A require statement has been added to check whether sufficient funds have been received:  require(   cdpData.requiredDebt == IERC20(DAI).balanceOf(address(this)),   \"requested and received amounts mismatch\" );  However note that this require statement now breaks increaseMultipleDepositDai() for the case when  a  flashloan  is  used:  The  DAI  amount  to  deposit  has  already  been  transferred  onwards  to MultiplyActionsProxy, this amount will be included in the in the DAI balance and hence the balance will not equal the flashlaon amount. The transaction will revert.    The check has been changed to:  require(   cdpData.requiredDebt.add(cdpData.depositDai) <= IERC20(DAI).balanceOf(address(this)),   \"requested and received amounts mismatch\" );  For  the  final  version  of  the  code  the  strict  requirement  for  equality  has  been  weakened  to  allow  for surplus DAI balance at the contract.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.14   Possible Casting Overflow",
        "body": "  In  function  wipeAndFreeGem  it  is  necessary  to  cast  the  amount  of  collateral  to  be  withdrawn  from uint256  to  int256  so  it  can  be  passed  as  an  argument  when  calling  frob()  on  the  manager.  The cast  can  overflow  since  it  is  using  a  regular  cast  and,  hence,  frob()  could  be  called  with  wrong parameters. Instead, toInt256() could be used since it reverts if overflows occur.    toInt256() is now always used for casting from uint256 to int256.  Oazo Apps Limited - Multiply -   24  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                  \f7.15   Unnecessary transferFrom  In function wipeAndFreeGem the MultiProxyActions contracts transfers DAI from itself to itself.  IDaiJoin(DAIJOIN).dai().transferFrom(address(this), address(this), borrowedDai);  As this call does not modify any DAI balance, it could be removed to save gas.    The call was removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.16   Use Available Constant and Avoid Call",
        "body": "  In MultiplyProxyActions.wipeAndFreeGem() DAI is handled as follows:  IDaiJoin(DAIJOIN).dai().transferFrom(address(this), address(this), borrowedDai); IDaiJoin(DAIJOIN).dai().approve(DAIJOIN, borrowedDai);  Instead of using the DAIJOIN address and calling it repeatedly to query the DAI address, the constant DAI representing the address of the DAI contract could be used directly.    The constant DAI is now used directly.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.17   increaseMultipleDepositDai Is Payable",
        "body": "  The system allows users to deposit additional DAI that will be, along with the flash-loaned DAI, swapped to the underlying collateral to enable increasing the leverage position. This functionality is implemented in the payable function increaseMultipleDepositDai. However, this method does not require having any additional ETH collateral and, thus, ETH could be mistakenly transferred to the contract executing the delegatecall to MuliplyProxyActions.    In the updated code increaseMultipleDepositDai is no longer payable.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.18   transferFrom Used Instead of transfer",
        "body": "  In function _collectFee of Exchange.sol, IERC20(asset).transferFrom(address(this), fe eBeneficiaryAddress,   feeToTransfer)   simplified   could   be   to  Oazo Apps Limited - Multiply -   25  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedNoteVersion1CodeCorrected                            \fIERC20(asset).transfer(feeBeneficiaryAddress,  feeToTransfer).  transfer()  could be safer to use if, at any point in the future, Oazo decides to accept other tokens than DAI for fees, even though this is currently not the case nor is it planned for the future. For example, that call would revert if asset was USDT which reverts if the contract has not approved itself in such a scenario.    The code was changed to use safeTransfer().  Oazo Apps Limited - Multiply -   26  \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  Hence,  the mentioned topics serve to clarify or support the report, but do not require a modification inside the project. Instead,  they  should  raise  awareness  in  order  to  improve  the  overall  understanding  for  users  and developers.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Deprecated safeApprove",
        "body": "  In function swap of the Exchange, safeApprove() is called. However, a deprecated implementation of safeApprove() is used. Be aware that using the most recent implementation, safeApprove() may revert if the approval has not been set to zero.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Documentation Treats Should as Must",
        "body": "  The documentation uses should when describing what values the parameters passed from the frontend to the backend will have.  RFC 2119 defines should as follows:  SHOULD This word, or the adjective \"RECOMMENDED\", mean that there may exist valid reasons in particular circumstances to ignore a particular item, but the full implications must be understood and carefully weighed before choosing a different course.  For example, following exchange parameter is defined as follows in the documentation:  allowPartialFill  -  Value  should  be  set  to  false  in  order  to  ensure  that  the  whole  amount  is swapped, otherwise the tx will fail.  That allows allowPartialFill to be true in certain scenarios. However, it could be dangerous to set this value to true since in _closeWithdrawDai() the contract swaps collateral for DAI and does not check whether there is some unswapped collateral returned from the exchange. Hence, users could lose funds. Clarifying how parameters are set clearly may help avoid mistakes.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.3   Gas Costs Vs Flashloan Fee",
        "body": "  MultiplyProxyActions  uses  a  flashloan  to  leverage  the  exposure  of  the  collateral  in  one  action. There is an implicit assumption that the fee for the flashloan is less than what the gas costs would be to reach  the  same  multiply  ratio  by  using  the  borrowed  dai  to  buy  collateral  and  to  borrow  additional  dai repeatedly.  For  very  large  amounts  the  flashloan  fee  may  exceed  the  gas  cost  and  using  the MultiplyProxyActions may be more expensive than doing the actual steps repeatedly.  Oazo Apps Limited replied:  From our experience in implementing a Multiply solution using repeated actions on Vaults we do not believe this approach to be feasible from a practical point of view. Further, going forward we expect to integrate to several flash loan providers and we expect the flash loan fee to go towards zero.  Oazo Apps Limited - Multiply -   27  NoteVersion1NoteVersion1NoteVersion1          \f8.4   No Checks on Outcome  The MultiplyProxyAction smart contract does not check the actual outcome of an action on a vault. However,  the  execution  highly  depends  on  the  front-end  and  the  APIs  it  interacts  with  and  has  much interaction with external contracts. In such systems, there is typically an optional feature enabling users to enforce certain postconditions such as a minimum collateralization ratio or other similar properties in order to safeguard their actions.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.5   Opposite Effect of What the Function Name",
        "body": " Suggests Possible  Note that while in general increaseMultiple... increases and decreaseMultiple... decreases the leverage of a vault, due to the added possibility of adding or withdrawing within the same action the final collateralization ratio / leverage may be changed in the opposite direction to what the function name increase/decrease suggested.  The documentation does not describe this behavior in detail.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.6   Whitelisted Contracts for Exchange Not Public",
        "body": "  In Exchange.sol, there is an internal mapping WHITELISTED_CALLERS specifying which contracts can use the Exchange contract. Since currently only the MultiplyProxyActions will be set in the constructor, it is  relatively  simple  to  decide  whether  a  contract  is  whitelisted  or  not.  However,  in  the  future  more contracts may be whitelisted. Thus, making this mapping public could be useful.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.7   CDPManager Must Have Created Vault",
        "body": "  The  MultiplyProxyActions  contract  is  only  compatible  with  vaults  that  have  been  opened  through the  CDPManager.  Vaults  that  have  been  opened  directly  are  not  supported  as  the  CDPManager  is unable to acquire permission to modify the vault. The documentation is vague on this topic and may be clarified.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.8   closeVaultExitCollateral Surplus DAI",
        "body": " Transferred to fundReceiver  Function  closeVaultExitCollateral  of  the  MultiplyProxyActions  contracts  can  be  used  to close  a  vault  and  exit  all  funds  in  collateral  to  the  fundReceiver  address.  A  part  of  the  collateral  is necessary  to  repay  the  flashloan  and  hence  is  exchanged  into  DAI.  Note  that  should  there  be  surplus  Oazo Apps Limited - Multiply -   28  NoteVersion1NoteVersion1NoteVersion1NoteVersion1NoteVersion1                    \fDAI tokens after the exchange, these are transferred to the fundReceiver address in addition to the collateral.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.9   msg.value Unchecked for ERC-20 Deposits",
        "body": "  In  function  increaseMultipleDepositCollateral,  collateral  is  deposited.  msg.value  should  be non-zero  if  the  collateral  to  lock  in  the  vault  will  be  WETH.  However,  it  could  also  be  non-zero  if  the collateral  is  a  ERC-20  token.  The  ETH  sent  along  with  the  ERC-20  will  be  unused  will  remain  in  the contract after the transaction has finished.  Oazo Apps Limited - Multiply -   29  NoteVersion1    \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Unhandled Alternative Flashloan Providers",
        "body": "  Currently the MultiplyProxyActions relies on the assumption that the lender will call onFlashLoan() and revert  if  the  flashloan  fails.  However,  EIP-3156  does  not  require  flashLoan()  to  revert  if  it  is unsuccessful.  In  any  scenario  where  the  flash  loan  fails  but  does  not  revert,  the  funds  sent  to  the MultiplyProxyActions could remain in the contract (since it is possible that onFlashLoan() is not called) and can be accessed by anyone via direct call to the onFlashLoan(). In addition, only relying on the bool return value of flashLoan() is insufficient since returning true is also allowed in case of failures.  The DssFlashmit contract reverts if onFlashLoan() fails. However, using another flashloan EIP-3156 lender contract can potentially lock the funds of the users.  Risk accepted:  Oazo Apps Limited plans on using FMM solely.  Oazo Apps Limited - Multiply FMM extension -   10  DesignCorrectnessCriticalHighMediumLowRiskAcceptedDesignLowVersion1RiskAccepted            \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings  Incorrect Balance Check for Vault   Incorrect Conversion to 18 Decimals   -Severity Findings  0  0  2  0  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Incorrect Balance Check for Vault",
        "body": "  Checking whether the MultiplyProxyActions contract holds enough funds has been modified to:  require(   cdpData.requiredDebt.add(cdpData.depositDai) >= IERC20(DAI).balanceOf(address(this)),   \"requested and received amounts mismatch\" );  The check should ensure that the MultiplyProxyActions contract holds enough Dai for the operation on the vault. Thus, if less DAI than needed is available the code should revert while a surplus of DAI could be tolerated. However, the change proceeds with the execution if the balance is lower than the amount needed while it reverts if there is a surplus of DAI.    The condition has been changed to <=.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Incorrect Conversion to 18 Decimals",
        "body": "  An  additional  call  to  convertTo18()  has  been  added  compared  to  the  codebase  from  the  previous report.  In _closeWithdrawCollateralSkipFL(), the following code is executed:  cdpData.withdrawCollateral = convertTo18(cdpData.gemJoin, cdpData.withdrawCollateral);  wipeAndFreeGem(   addressRegistry.manager,   cdpData.gemJoin,  Oazo Apps Limited - Multiply FMM extension -   11  CriticalHighMediumCodeCorrectedCodeCorrectedLowCorrectnessMediumVersion1CodeCorrectedCorrectnessMediumVersion1CodeCorrected                  \f  cdpData.cdpId,   cdpData.requiredDebt,   cdpData.withdrawCollateral );  wipeAndFreeGem()  contains  cdpData.withdrawCollateral:  the   following  code  where  collateralDraw   is  equal   to  uint256 wadC = convertTo18(cdpData.gemJoin, collateralDraw);  Thus,  withdrawCollateral*10**(18-gem.decimals())*10**(18-gem.decimals()).  that results in an incorrect amount.  wadC   will   be Ultimately,    The conversion to 18 decimals has been removed in _closeWithdrawCollateralSkipFL().  Oazo Apps Limited - Multiply FMM extension -   12  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Redundant Calculation in _yank",
        "body": "  When _yank is called, it determines how much reward can still be claimed by the recipient. If the new _end  of  the  vesting  plan  is  before  the  beginning  or  the  cliff  date  of  the  vesting  plan,  the  entire  reward amount is cancelled. Otherwise, the following calculation is done:  awards[_id].tot = toUint128(                     add(                         unpaid(_end, _award.bgn, _award.clf, _award.fin, _award.tot, _award.rxd),                         _award.rxd                     )                 );  unpaid calculates the following result:  function unpaid(uint256 _time, uint48 _bgn, uint48 _clf, uint48 _fin, uint128 _tot, uint128 _rxd) internal pure returns (uint256 amt) {     amt = _time < _clf ? 0 : sub(accrued(_time, _bgn, _fin, _tot), _rxd); }  As  we  know  that  _end  is  after  the  beginning  and  cliff  date  of  the  vesting  plan,  this  calculation  can  be simplified.  The  addition  of  _rxd  in  _yank  and  subtraction  of  _rxd  in  unpaid  cancel  out,  so  the  final result is simply: toUint128( accrued(_end, _bgn, _fin, _tot) ).  Acknowledged:  Giry chooses not to modify the code out of caution, as the original dss-vest code has been the subject of extensive formal checking and is battle-tested.  Giry - dss-vest -   9  DesignCriticalHighMediumLowAcknowledgedAcknowledgedAcknowledgedAcknowledgedAcknowledgedDesignLowVersion1Acknowledged           \f6.2   Redundant Overflow Checks  As  of  Solidity  version  0.8.0,  the  compiler  automatically  inserts  overflow  checks  when  doing  integer arithmetic. As such, the add, sub and mul functions are redundant.  Additionally, the following require statement in _create can also be considered redundant:  require(ids < type(uint256).max, \"DssVest/ids-overflow\");  This statement makes sure that the increase of the id (id = ++id) in the following line will not overflow.  Acknowledged:  Giry chooses not to modify the code out of caution, as the original dss-vest code has been the subject of extensive formal checking and is battle-tested.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Redundant Storage Load in _yank",
        "body": "  The _yank function loads awards[_id] from storage multiple times:  function _yank(uint256 _id, uint256 _end) internal lock {     require(wards[msg.sender] == 1 || awards[_id].mgr == msg.sender, \"DssVest/not-authorized\");     Award memory _award = awards[_id];  It  is  important  to  note  that  since  the  Berlin  hardfork,  the  memory  slot  of  awards[_id]  is  considered warm, thus the benefit of such optimization is limited.  See more here https://eips.ethereum.org/EIPS/eip-2929.  Acknowledged:  Giry chooses not to modify the code out of caution, as the original dss-vest code has been the subject of extensive formal checking and is battle-tested.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Reentrancy Lock Can Be Cheaper",
        "body": "  Using different values for the locked variable results in cheaper transactions overall. Setting a storage variable  from  0  to  1,  but  then  resetting  it  back  to  0  costs  ~20112  gas  but  causes  19900  gas  to  be refunded. However, the total refund amount a transaction is eligible for is limited to a fraction of the total gas expended by the transaction. Hence, for simple transactions it is likely that not the entire gas refund will be received.  Instead, one could initialize the locked variable with a value of 1 in the constructor. Then, at the start of a transaction set it to 0 for the reentrancy lock and setting it back to 1 at the end. This costs ~3012 gas, but refunds 2800. Assuming a complete refund, this costs the same amount of gas per transaction, but is more likely to be completely refunded as the total refund amount is smaller.  For completeness, we should note that a similar practice is utilized by the OpenZeppelin library. In this case, the values 1 and 2 are used instead of values 1 and 0. The efficiency of this approach is similar.  Giry - dss-vest -   10  DesignLowVersion1AcknowledgedDesignLowVersion1AcknowledgedDesignLowVersion1Acknowledged                      \fFor  more  information  https://eips.ethereum.org/EIPS/eip-3529.  about   gas   refunds   and   the   exact   refund   amounts,   see  Acknowledged:  Giry chooses not to modify the code out of caution, as the original dss-vest code has been the subject of extensive formal checking and is battle-tested.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Unnecessary Calculation in accrued",
        "body": "  In the accrued function, unnecessary calculations are performed in the case where _time == _bgn. In this case, the result will be 0. As such, the first if condition could be modified to be _time <= _bgn in order to save gas in this case.  function accrued(uint256 _time, uint48 _bgn, uint48 _fin, uint128 _tot) internal pure returns (uint256 amt) {     if (_time < _bgn) {         amt = 0;     } else if (_time >= _fin) {         amt = _tot;     } else {         amt = mul(_tot, sub(_time, _bgn)) / sub(_fin, _bgn); // 0 <= amt < _award.tot     } }  Acknowledged:  Giry chooses not to modify the code out of caution, as the original dss-vest code has been the subject of extensive formal checking and is battle-tested.  Giry - dss-vest -   11  DesignLowVersion1Acknowledged          \f7   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings  -Severity Findings   Code Duplication   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Code Duplication",
        "body": "  0  0  0  1  The _bless and unbless functions check for the condition wards[msg.sender] == 1. This is the same  condition  as  is  enforced  by  the  auth  modifier.  In  order  to  reduce  code  duplication,  the  auth modifier could be applied to these functions instead.    The condition check was removed and replaced with the auth modifier.  Giry - dss-vest -   12  CriticalHighMediumLowCodeCorrectedDesignLowVersion1CodeCorrected        \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Defaulted Loan Repayment",
        "body": "  CS-TFCarbon-001  Loans  can  be  marked  to  be  repayable  after  default.  In  the  case  of  a  defaulted  loan  being  repaid  later, new  investors  of  the  equity  tranche  gain  an  unfair  advantage  over  users  that  invested  in  the  tranche before the loan has been marked as defaulted.  This behavior can even be exploited by borrowers to regain some of the repaid loan by investing in the equity tranche after the default of their own loan. Consider the following example (assuming no fees and interest for simplification):   A portfolio consists of 3 tranches and is in Live status with no active loans.   Users have deposited 100 tokens to each tranche with no accrued interest (i.e., 1 share per token).   A new loan of 99 tokens is issued to a borrower.   After some time, the manager marks the loan as defaulted.   The value of the equity tranche is now 1 token with a total supply of 100 shares.   The borrower deposits 100 tokens into the equity tranche and receives 10,000 shares back.   The borrower repays the loan, raising the equity tranche's value to 200 tokens.   The borrower is now entitled to ~198 tokens in the tranche.  TrueFi - Carbon -   11  SecurityDesignCorrectnessCriticalHighAcknowledgedMediumRiskAcceptedRiskAcceptedLowRiskAcceptedRiskAcceptedDesignHighVersion1Acknowledged           \fIssue acknowledged:  TrueFi replied:  we are aware of this issue, but it's more of manager responsibility to pause deposits/withdrawals in case  of  risk  in  portfolio  (so  before  marking  loan  as  defaulted  manager  should  first  disable deposits/withdrawals)  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   DoS for Start",
        "body": "  The  manager  can  turn  the  system  Live  by  calling  StructuredPortfolio.start().  When  this  is done, the system checks if the ratios of the values stored in each tranche are appropriate. If it is not, the transaction  reverts.  This  means  that  depositing  or  withdrawing  an  amount  -  if  allowed  -  before  the manager  calls  start  can  block  the  system  from  turning  live  since  the  ratios  will  not  be  correct.  The depositController  and  withdrawController  enforce  a  ceiling  and  a  floor  respectively  but  the issue can still arise.  CS-TFCarbon-002  Risk accepted:  TrueFi accepted the risk giving the following statement:  Shouldn\u2019t occur, but in case managers want to be safe, withdrawals and deposits can be disabled before starting the portfolio.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   Loan Default Frontrunning",
        "body": "  In Live state, and if withdrawals are enabled, lenders in any tranche can withdraw the full amount even if there are open loans that are using some of the available funds. Consider the following example:  CS-TFCarbon-003   Each tranche has a value of 100 tokens.   A loan for 150 tokens has been issued.   Users of the junior tranche now withdraw all 100 tokens.   The loan defaults resulting in the value of the senior tranche being reduced to 50.  If the users in the junior tranche observe the call to StructuredPortfolio.markLoanAsDefaulted, they can frontrun it to redeem all of their tokens, while the other tranches suffer from the loss.  Risk accepted:  TrueFi accepted the risk giving the following statement:  Shouldn\u2019t occur, but in case managers want to be safe, withdrawals can be disabled before calling StructuredPortfolio.markLoanAsDefaulted.  TrueFi - Carbon -   12  DesignMediumVersion1RiskAcceptedSecurityMediumVersion1RiskAccepted                  \f5.4   Fee Transfer DoS  Fees are (as long as funds are available) transferred onto the protocol treasury and manager beneficiary address  on  every  interaction.  Since  the  manager  beneficiary  might  be  an  EOA  also  used  in  other activities,  and  since  some  tokens  implement  blacklisting  (e.g.,  USDC)  or  pausing  (e.g.,  BNB),  portfolios using such underlying tokens could be susceptible to a Denial of Service when the manager beneficiary address is used in an illicit activity or the token is set to a paused state.  CS-TFCarbon-004  Risk accepted:  TrueFi responded:  Both addresses are trusted and can be changed in case of emergency. Changes were introducing too  much  complexity  in  the  code.  There  was  a  code  change  in  setManagerFeeBeneficiary  to first change beneficiary and then pay the fee as otherwise function was reverting.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.5   Lost Repayments in Closed State",
        "body": "  If a portfolio is closed, users are encouraged to withdraw their assets as no interest accrues anymore but protocol fees are still accrued. If a tranche is completely emptied by withdrawals (i.e. there are no more shares) and a repayment occurs, the repaid value in that tranche is lost as no one is able to withdraw these assets (apart from the protocol admin that can update the implementation contract).  CS-TFCarbon-005  Risk accepted:  The client accepts the risk with the following statement:  By default there is protocol fee in closed state to encourage withdrawal of the assets as there always is  small  smart  contract  risk.  But  in  case  there  was  a  default  and  the  manager  is  in  process  of regaining the assets they should create a proposal to disable protocol fees on that portfolio. It\u2019s the matter of communication between manager and lenders. If they want to exit early they can, but then they won\u2019t be able to profit from recovered funds.  TrueFi - Carbon -   13  SecurityLowVersion1RiskAcceptedDesignLowVersion1RiskAccepted                \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  0  1  3  12  -Severity Findings  -Severity Findings   Waterfall Miscalculation   -Severity Findings   Calling StructuredPortfolio.updateCheckpoints Increases Deficit    Fees in Deficit    No Deficit Update on Deposit / Withdrawal   -Severity Findings   Fee Accrual on Unpaid Fees    Unpaid Fee Calculation    Balance Underflow    Gas Optimizations   Imprecise Specifications    Missing Interface Functions    Missing Sanity Check    Shadowed Variable    Specification Nonconformity    Unused Function    Unused Return Value    configure Function Does Not Include TransferController   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Waterfall Miscalculation",
        "body": "  CS-TFCarbon-013  The  can  StructuredPortfolio.updateCheckpoints. We expect the following property to hold:  updated   tranche   anyone   value   be   by   of   a   by   calling  Executing updateCheckpoints consecutively in one block (with no other transactions in between) should not change the checkpoints since no time has passed and the value of the portfolio has not been changed.  However,  this  property  does  not  hold.  To  showcase  that,  we  need  to  consider  how  the  waterfall  is calculated.  The waterfall is calculated by using each tranche's checkpoints and adding the deficit of a tranche to it. This  is  considered  the  total  assumed  value  of  the  tranche.  This  means  that  if  we  would  call  TrueFi - Carbon -   14  CriticalHighCodeCorrectedMediumCodeCorrectedCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCorrectnessHighVersion1CodeCorrected         \fupdateCheckpoints  multiple  times,  the  deficit  of  a  tranche  would  be  added  up  again  on  every calculation of the waterfall.  Normally, however, this is not the case since the resulting waterfall values are bound by the total value of the  portfolio  (virtual  token  balance  +  loans  value)  that  hasn't  been  used  by  the  less  risky  tranches. Therefore, we assume the following property:  If a tranche has a deficit > 0, all riskier tranches (i.e., all tranches with a lower waterfall index) have a value of exactly 0.  In practice, this assumption does not hold as can be seen in the following example (assuming no fees and no compounding for simplification):   The senior tranche has a 1% interest.   The junior tranche has a 2% interest.   Each tranche holds a value of 100 tokens.   Two loans are issued:   Loan A: 102 tokens with 0% interest.   Loan B: 180 tokens with 10% interest.   Loan A defaults.   A deficit of 2 tokens is added to the junior tranche and the equity tranche now holds 0 value.   After one year, the total assets of the portfolio is 216 (18 tokens in balance + 180 tokens in principal  of open loans + 18 tokens in interest).   The Senior tranche should hold 101 tokens.   The Junior tranche should hold 102 tokens but still has a deficit of 2 tokens.   The equity tranche is assigned 13 tokens.  This violates the assumed property. We can now call StructuredPortfolio.updateCheckpoints multiple times and add up the deficit of 2 tokens, until the value of the junior tranche is 115 and the value of the equity tranche is 0. After 1 year, the junior tranche has now accrued 15% interest while it should have  accrued  2%.  In  other  words,  calling  the  StructuredPortfolio.updateCheckpoints consecutively changes the value of the tranches.    If some loan in a portfolio has defaulted, StructuredPortfolio.updateCheckpoints subtracts the delta of the previous and the updated value of a tranche from the tranche's deficit. This allows the deficit to be settled with accrued interest, fixing the described problem.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Calling ",
        "body": " StructuredPortfolio.updateCheckpoints Increases Deficit  Given a portfolio where all 3 tranches have a value of 100 tokens each and the manager fee is set to 2% for all tranches, consider the following sequence:  CS-TFCarbon-007  TrueFi - Carbon -   15  CorrectnessMediumVersion3CodeCorrected        \f1. A loan is issued for 300 tokens, i.e., the full value held by the portfolio (with 1% interest).  2. The loan is marked as defaulted.  3. This means that the deficit for the senior and the junior tranches is 100 and the value held by  them is 0.  4. A year passes by.  5. A user calls StructuredPortfolio.updateCheckpoints. At this point the assumed value of the senior tranche is 103 i.e., 2 tokens manager fee plus the deficit which is 101 for each tranche. The real assets held are 0 thus the new deficit is set to 103 which gets checkpointed.  6. A  user  calls  StructuredPortfolio.updateCheckpoints  again.  At  this  point  the  assumed value is 105 (103 is the previous deficit plus 2 for the manager fees).  This means that the deficit increases with every call to updateCheckpoints while it shouldn't. Note that when the portfolio closes, the deficit is used to set the maxValueOnClose which determines the amount of assets expected to be filled into each tranche by possible loan repayments.    In the current implementation, the fees are properly deducted so that they are not counted multiple times.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Fees in Deficit",
        "body": "  StructuredPortfolio._calculateLoansDeficit  updates  tranche  deficits  by  calculating  the current assumed value of the tranche and subtracting the accrued fees and current waterfall value of that tranche. The fees are calculated on the full assumed value (including the deficit generated by defaulted loans):  uint256 assumedPendingFees = tranches[i].totalPendingFeesForAssets(assumedTotalAssets);  CS-TFCarbon-010  actual   The  by the  TrancheVault.updateCheckpointFromPortfolio. It is calculating fees with the current waterfall value (which does not contain defaulted loans) of the tranche:  checkpoints   tranches   updated   are   in   uint256 pendingFee = _pendingProtocolFee(_totalAssetsBeforeFees); ... uint256 pendingFee = _pendingManagerFee(_totalAssetsBeforeFees);  Where _totalAssetsBeforeFees is calculated by this function:  function totalAssetsBeforeFees() public view returns (uint256) {     if (portfolio.status() == Status.Live) {         return portfolio.calculateWaterfallForTrancheWithoutFee(waterfallIndex);     }      return virtualTokenBalance; }  TrueFi - Carbon -   16  CorrectnessMediumVersion1CodeCorrected          \fIn  the  case  of  defaulted  loans,  these  2  calculations  diverge  as  the  assumed  value  will  be  higher  in tranches  with  a  deficit.  Therefore,  the  calculated  fees  will  be  higher  as  well,  reducing  the  deficits  over time while the (paid or unpaid) fees over that time frame are smaller. If at any point the defaulted loan is repaid, the difference will be awarded to the equity tranche.  Consider the following (extreme for demonstration) example:   Consider a portfolio with a really long duration (more than 50 years).   Then manager (and/or protocol) fee are 2%.   Junior tranche has 5% interest, senior tranche has 2% interest.   Each tranche has 100 value.   A loan of 300 value, 1 year runtime and 10% interest is issued.   1 year later, the loan defaults resulting in 0 value for all tranches and 105 / 103 deficit for junior /  senior tranche.   50 years later updateCheckpoints is called. The deficit of junior and senior tranches is now set to  0. Each tranche has ~2 tokens in unpaid fees.   The loan is repaid. Junior and senior tranche hold 0 tokens value, while the equity tranche holds 324  tokens value.    Fees  are  now  calculated  only  based  on  the  value  of  the  waterfall  calculation  and  they  are  propagated along  the  execution  of  the  StructuredPortfolio.updateCheckpoints  as  using  the  array pendingFees.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   No Deficit Update on Deposit / Withdrawal",
        "body": "  TrancheVault.deposit() / mint() and withdraw() / redeem() update their checkpoints locally but  never  call  StructuredPortfolio.updateCheckpoints().  Therefore,  the  deficit  in  the tranchesData struct is not updated to the latest value before a user deposit / withdrawal is processed. This means, that the period from the last checkpoint update up until the user action is not accounted for. Consider the following example:  CS-TFCarbon-015   The given vault accrues no fees.   The junior tranche accrues 5% interest per year.   The senior tranche accrues 3% interest per year.   All tranches hold a value of 100 tokens in the beginning.   300 tokens have been disbursed.   180 tokens have been marked as defaulted.   The junior tranche now has 20 totalAssets and 80 deficit.   1 year passes without any interaction on the protocol.   A new user deposits 100 tokens to the junior tranche.   The senior tranche now holds 103 tokens while the junior tranche holds 117 tokens and 80 tokens  deficit.   The manager updates the outstandigAssets back to 300 tokens.  TrueFi - Carbon -   17  CorrectnessMediumVersion1CodeCorrected        \f The junior tranche now holds a value of 201 tokens.  If we, instead, run updateCheckpoints right before the new deposit, the value of the junior tranche is 205  tokens  instead.  That  is,  because  the  call  updates  the  deficit  of  the  tranche  to  88  tokens  (80  +  3 tokens shifted to senior tranche + 5 tokens interest accrued), accounting for the accrued interest.    Deficits are now stored in the TrancheVault checkpoints instead of the StructuredPortfolio and updated every time, the checkpoints are updated.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Fee Accrual on Unpaid Fees",
        "body": "  Fees are calculated by TrancheVault.totalPendingFeesForAssets on the current waterfall value of  the  tranche.  The  waterfall  value  is  calculated  by  _assumedTrancheValue  which  calculates totalAssets:  uint256 assumedTotalAssets = _withInterest(checkpoint.totalAssets, targetApy, timePassedSinceCheckpoint) +         checkpoint.unpaidFees;  CS-TFCarbon-006  totalPendingFeesForAssets calculates the _pendingProtocolFee:  _accruedFee(checkpoint.protocolFeeRate, _totalAssetsBeforeFees)  ... and the _pendingManagerFee:  _accruedFee(managerFeeRate, _totalAssetsBeforeFees)  ... based on the totalAssets value that includes the unpaid fee. That means fees are calculated on past fees if they cannot be paid out immediately.    Unpaid fees are now deducted from the waterfall value. This means that unpaid fees do not contribute to the value on which the fees accrue.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Unpaid Fee Calculation",
        "body": "  If  the  protocol's  virtualTokenBalance  is  lower  than  the  amount  of  fees  that  have  to  be  paid  in  a checkpoint  update,  the  unpaid  amount  is  stored  to  be  paid  for  later  soon  as  the  system  has  some available tokens.  Unpaid  fees  are  also  added  to  each  tranche's  checkpoint.  If  unpaid  fees  have  been  added  to  a checkpoint and sometime later, the checkpoints are updated, the waterfall is calculated by applying the APY to the checkpoint (that contains the unpaid fee), effectively applying the APY to the fee. The saved unpaid  fee  is  then  subtracted  from  the  calculated  value.  This  waterfall  value,  in  turn,  is  stored  in  the checkpoint by adding the unpaid fees again.  CS-TFCarbon-020  TrueFi - Carbon -   18  DesignLowVersion7CodeCorrectedCorrectnessLowVersion5CodeCorrected                \fThe fee is multiplied by the APY, then the fee is subtracted and then added again. This means, there is a slight  gain  added  to  the  checkpoint  in  comparison  to  a  checkpoint  update  without  stored  unpaid  fees. This gain is ultimately taken from the equity tranche.  Code Corrected:  A new field (unpaidFees) was introduced in the checkpoint struct to store the fees. Thus fees do not contribute to interest accrual of the tranche.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Balance Underflow",
        "body": "  StructuredPortfolio.fundLoan  calls  LoansManager._fundLoan  which  in  turn  checks  the contract's balance of the underlying token to determine how much principal is available for loan funding. An  error  message  is  returned  when  the  requested  principal  exceeds  the  balance  of  the  contract. However,  fundLoan  subtracts  the  amount  of  principal  from  the  virtualTokenBalance  afterward.  If any  amount  of  tokens  has  been  directly  transferred  to  the  contract  before,  the  first  check  could  pass, while the subtraction fails, resulting in a revert without the given error message.  CS-TFCarbon-021    The following check has been added which prints an informative message:  require(virtualTokenBalance >= principal, \"SP: Principal exceeds balance\");  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   Gas Optimizations",
        "body": "  The following parts of the code could potentially be optimized for gas efficiency:   The CustomFeeRate struct used in a mapping in ProtocolConfig requires two storage slots. As the feeRate does not require 256 bits, the struct field could be reduced to a smaller type in order to shrink  the  size  requirement  of  the  struct  to  1  storage  slot.  This  should,  however,  be  carefully handled.   Redundant storage loads are performed in various places. Some examples are:  CS-TFCarbon-012   StructuredPortfolio.initialize  loads  the  tranches  variable  to  emit  an  event  while it is already available in memory variables.   StructuredPortfolio.fundLoan  checks   that   the  status   is  Live,   then  calls  updateCheckpoints which performs the same check again.   Redundant external calls are performed in various places. Some examples are:   StructuredPortfolio.start  calls  checkTranchesRatios  which  gets   the totalAssets of each tranche. It then calls totalAssets, which, in a status other than Live, gets the totalAssets of each tranche again.  TrueFi - Carbon -   19  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \f StructuredPortfolio.calculateWaterfall   the calculateWaterfallWithoutFees,  then  proceeds  to  call  totalPendingFees  on calls each  StructuredPortfolio.calculateWaterfallForTrancheWithoutFee twice.  calculates   tranche   which   turn   in    Redundant storage writes are performed in various places. Some examples are:   The  loop  in  StructuredPortfolio.start  adds  values  from  each  tranche  to  the virtualTokenBalance storage variable, resulting in multiple storage writes to the same variable.   StructuredPortfolio.markLoanAsDefaulted  updates  tranches and then immediately overwrites these checkpoints.  the  checkpoints  of   the  In  LoanManager._tryToExcludeLoan,  in  case  the  last  loan  is  deleted  a  redundant performed: is  assignment  activeLoanIds[i] = activeLoanIds[loansLength - 1]   Complicated call paths are performed in various places. Some examples are:   StructuredPortfolio.checkTranchesRatios  calls  each  tranche's  totalAssets which  to StructuredPortfolio.calculateWaterfallForTrancheWithoutFee  which  then calls back to the tranche's getCheckpoint function.  status)   Live   back   call   (in    StructuredPortfolio._defaultedLoansDeficit computes interest even when the deficit of  the given checkpoint is 0.   Some  state  variables  are  never  updated  and  could  be  set   to  immutable   in  StructuredPortfolio:   trancheImplementation   portfolioImplementation   protocolConfig   Cheap  deployment  has  been  chosen  over  cheap  contract  interactions.  Gas  for  user  interactions could  be  greatly  reduced  by  sacrificing  deployment  costs  of  managers.  For  example,  in  a  full deployment  of  TrancheVault  (as  opposed  to  a  proxy  deployment  of  a  given  implementation contract),  4  state  variables  that  are  used  in  many  of  the  state-changing  functions  could  be  set  to immutable.   TrancheVault.checkpoint is declared public while a redundant getter getCheckpoint exists.  the   In Live state, each vault transfers a chunk of fees from the portfolio to the beneficiary's addresses. As  in StructuredPortfolio.updateCheckpoints  is  sufficient.  Even  then,  fee  transfers  on  every interaction are unnecessarily costly.  anyways,   portfolio   transfer   funds   held   one   are   the   in     choices.  The  gas   Most relevant code optimizations have either been implemented or chosen not to be implemented due to design  (e.g., StructuredPortfolio.start)  slightly  and  some  new  inefficiencies  have  been  introduced  (e.g., StructuredPortfolio.getTranchesData  with StructuredPortfolio.getTrancheData which is a copy of the existing automatic getter).  code  parts  has   consumption  of   increased   replaced   some   been   has   TrueFi - Carbon -   20      \f6.9   Imprecise Specifications  CS-TFCarbon-017  The following specifications are imprecise:   The field targetAPY of struct TrancheData is not documented to be in basis points.   The field targetAPY of struct TrancheInitData is not documented to be in basis points.   StructuredPortfolio.endDate  is  commented  to  return  the  actual  end  date  after  the  close.  This is not true if the portfolio has been closed prematurely.   StructuredPortfolio.close  is  commented  to  revert  if  any  loans  are  still  active.  However,  portfolios can always be closed after the end date.   StructuredPortfolio.calculateWaterfallForTranche   is  commented  executable by the tranche with the given ID. Such restriction is however not enforced.  to  be  only   TrancheVault.updateCheckpointFromPortfolio  is  commented  to  be  only  executable  in Live  state.  However,  there  is  no  restriction  preventing  it  from  being  executed  in  Closed  state. Nevertheless, StructuredPortfolio is calling the function in Live state only.  Moreover in the extra documentation provided to us:  It  is  mentioned  that  deposits  are  blocked  in  Closed  state  and  withdrawals  are  blocked  in CapitalFormation state. However, this is never enforced in the code.  Specification changed:  The specification has been updated to correctly describe the code.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   Missing Interface Functions",
        "body": "  Some  interfaces  are  missing  public  functions  that  are  implemented  in  the  contracts.  Here  are  two examples:   ITrancheVault is missing the declaration for setTransferController.   ITrancheVault is missing the declaration for totalAssetsWithoutFees.  CS-TFCarbon-016    Both  functions  have  been  added  to  the  interface.  totalAssetsWithoutFees  was  renamed  to totalAssetsBeforeFees.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.11   Missing Sanity Check",
        "body": "  A sanity check is missing in TrancheVault.deposit. More specifically, the function does not prevent the parameter amount from being 0 while mint which implements similar functionality does.  CS-TFCarbon-008  TrueFi - Carbon -   21  DesignLowVersion1Speci\ufb01cationChangedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                      \f  The missing sanity check has been added.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.12   Shadowed Variable",
        "body": "  The variable fixedInterestOnlyLoans in StructuredPortfolio.initialize is shadowed by a storage variable with the same name. While this does not impact the functionality of the given code, it could create problems during code maintenance.  CS-TFCarbon-019    The name of the variable has been changed to _fixedInterestOnlyLoans.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.13   Specification Nonconformity",
        "body": "  The architecture specification states that  They  [vaults]  do  not  store  the  capital,  they  only  handle  interactions  between  the  investors  and  the portfolio.  This is in contrast to the fact that vaults store balances both in CapitalFormation and Closed states.  CS-TFCarbon-011  Specification changed:  The specification has been updated to the following:  They store the capital when the portfolio is NOT in the Live state (so in the Capital Formation state and in the Closed state).  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.14   Unused Function",
        "body": "  The  internal  function  TrancheVault._requirePortfolioOrManager  is  never  used  inside  of TrancheVault.  CS-TFCarbon-014    The function has been removed.  TrueFi - Carbon -   22  DesignLowVersion1CodeCorrectedDesignLowVersion1Speci\ufb01cationChangedDesignLowVersion1CodeCorrected                          \f6.15   Unused Return Value  TrancheVault._payProtocolFee  and  TrancheVault._payManagerFee  return  the  protocol  fee and the manager fee paid respectively. However, this value is never used.  CS-TFCarbon-009    The return values have been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.16   configure Function Does Not Include",
        "body": " TransferController  The  function  TrancheVault.configure  can  be  used  to  simultaneously  set  multiple  variables configurable by the portfolio manager. While DepositController and WithdrawController can be set, TransferController is not included in the function.  CS-TFCarbon-018    The TransferController can now be set in the TrancheVault.configure function.  TrueFi - Carbon -   23  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected              \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Ambiguous Deficit Data in Closed State",
        "body": "  Deficit  checkpoints  are  used  to  determine  the  potential  interest  of  tokens  that  have  been  lost  due  to defaulted  loans  (which  can  still  be  repaid  in  some  circumstances).  In  Closed  state,  no  interest  is accrued. Therefore, repayments of defaulted loans are not decreasing the deficit again. However, a call to  StructuredPortfolio.close  still  updates  the  deficit  checkpoints.  This  update  works  in  a non-intuitive  fashion  and  results  in  ambiguous  data:  If  a  portfolio  with  no  defaulted  loan  is  closed,  the deficit will be 0. If, on the other hand, a portfolio with at least one defaulted loan is closed, all loan values (including the loans that have not defaulted) are counted towards the deficit.  While this is not problematic for Carbon itself, other contracts integrating with it might rely on consistent data.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Compounding Interest Computed in Arbitrary",
        "body": " Intervals  Every  time  the  checkpoints  are  updated  through  a  state-changing  function,  interest  is  compounded. Since  StructuredPortfolio.updateCheckpoints  can  be  called  at  any  time  during  Live  status, the results can be different. Consider the following example:   A user deposits 100 tokens on a tranche with 10% APY.   After 1 year of inactivity on the platform, they receive a yield of 10 tokens.  If the user calls updateCheckpoints after 6 months, they receive a yield of 10.25 tokens after 1 year.  If the user calls updateCheckpoints each month, they receive a yield of 10.47 tokens after one year.  The same situation produces different results based on how often the checkpoints are updated (without any other interactions).  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Fee Accrual in Closed State",
        "body": "  Fees  are  still  accrued  in  Closed  state.  TrueFi  claims  this  is  done  to  incentivize  fast  withdrawals. However, withdrawals in Closed state might still be delayed by late loan repayments.  TrueFi - Carbon -   24  NoteVersion3NoteVersion1NoteVersion1              \f7.4   Fee Accrual on Yield  Fees are accrued on the principal plus the yield on each tranche. This means that the same percentage of yield and fees on a tranche results in negative growth. For example, a tranche with 100 tokens value, 2% yield and 2% fees will have 99.96 value after one year.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   Manager Fee Accrual",
        "body": "  Manager fees are accrued on the virtualTokenBalance plus the value of the currently running loans. If a loan defaults and the manager marks the loan as defaulted on-chain, manager fees are no longer accrued  on  the  loan.  Therefore,  managers  are  incentivized  to  not  mark  loans  as  defaulted  until  the portfolio is closed, resulting in bigger fees than necessary for lenders.  The fee accrual for non-defaulted loans can even go beyond the runtime of the loan.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.6   Only the Recipient of a Loan Can Repay It",
        "body": "  The  system  allows  only  LoanManager._repayFixedInterestOnlyLoan by the following line:  recipients  of  a   repay   loan   the   to   it.  This   is  enforced   in   the  require(fixedInterestOnlyLoans.recipient(loanId) == msg.sender, \"LM: Not an instrument recipient\");  Users losing their private keys will not be able to repay their loans in any way.  TrueFi claims that only KYC addresses should be able to repay loans. However, there is no mechanism implemented that deals with the aforementioned problem.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.7   Skewed Interest Distribution",
        "body": "  Protocol and manager fees are calculated from the whole balances instead of the accrued interest. This potentially  results  in  skewed  interest  rate  distributions  depending  on  the  chosen  fee  rates  per  tranche. Consider the following example:   The protocol fee is 1% and the manager fee is 1% on every tranche.   The junior tranche has 5% interest and 100 tokens in value.   The senior tranche has 3% interest and 100 tokens in value.   Without fees (and disregarding compounding effects), the tranches will yield 5 and 3 tokens in yield  respectively.   With  fees  (and  disregarding  compounding  effects),  the  tranches  will  yield  2.9  and  0.94  tokens  respectively.  The ratio is now different after accounting for fees as 5 / 3 !== 2.9 / 0.94.  TrueFi - Carbon -   25  NoteVersion1NoteVersion1NoteVersion1NoteVersion1                \f7.8   Use of Non-standard ERC20 Tokens  Managers (and users) should be aware that using a non-standard ERC20 token as the underlying can be dangerous  for  the  system.  Non-standard  ERC20  tokens  include  but  are  not  limited  to  the  following behaviors:  Tokens With Reentrancies:  If a portfolio is set up with an underlying token that is reentrant (e.g., ERC-777), various possibilities of reentrancy attacks are enabled. Here is an example of one possible attack vector:   A portfolio consists of 3 tranches and is in Live status with no active loans.   Users have deposited 100 tokens to each tranche with no accrued interest (i.e. 1 share per token).   An attacker calls deposit on the junior tranche with 99 tokens.  In the safeTransferFrom call, the underlying token calls back to the attacker's contract.   At  this  point,  the  checkpoint  of  the  junior  tranche  has  already  been  updated,  while  the  virtualTokenBalance in the portfolio has not.   The attacker now reenters into the deposit function if the equity tranche with a deposit of 100 tokens.   10,000  shares  are  minted  to  the  attacker  as  the  virtualTokenBalance  is  still  300,  while  the checkpoints of senior and junior tranches return a sum of 299 tokens, leaving only 1 token for the equity tranche waterfall value.   After the call, the attacker now holds shares representing 99 tokens in the junior tranche and ~198  tokens in the equity tranche resulting in an instant profit of ~98 tokens.  Tokens With Fees:  When transferring tokens with fees, the receiver does not get the amount the sender sends but a part of it as  fees  are  deducted.  However,  updating  the  virtualTokenBalance  for  example  makes  the assumption  the  whole  amount  has  been  received.  Thus,  repetitive  transfers  will  create  a  discrepancy between the internal accounting of the portfolio which uses the virtualTokenBalance and the actual amount held by the portfolio.  Rebasing Tokens:  With  rebasing  tokens,  the  amount  of  tokens  each  account  holds  changes  over  time.  This  will  lead, similarly to tokens with fees, to internal accounting being wrong.  Pausable Tokens:  When a token is paused, it might revert on every call to functions like transfer. As Carbon extensively uses transfers in many functions, the system could become unusable on such occasions.  TrueFi - Carbon -   26  NoteVersion1   \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Trade Function Discrepancy",
        "body": "  Users  can  call  the  trade  functions  tradeBySourceAmount  and  tradeByTargetAmount  with tradeActions  that  contain  the  same  strategy  multiple  times.  During  the  execution  of  the  trade functions, the corresponding strategies are updated after each trade action has been executed.  This  is,  however,  not  true  for  the  view  functions  tradeSourceAmount  and  tradeTargetAmount:  y and z values of the associated strategies are not updated during the execution. If the same strategy is traded against multiple times in one call, the trade result might therefore diverge from the result of the corresponding trade functions in the same state.  Risk accepted:  Bancor accepts the risk with the following statement:  This is a known issue and is considered an edge case with minimal risk, as matching is done by the SDK  that  prevents  this  case.  The  alternative  would  be  to  check  for  duplicate  strategies  during  the trade which would increase the gas costs for all trades, so we decided against adding such a check  Bancor - Carbon -   10  SecurityDesignCorrectnessCriticalHighMediumLowRiskAcceptedCorrectnessLowVersion1RiskAccepted             \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings   Overflow Might DOS the App    Price Precision Very Low for Some Tokens   -Severity Findings  -Severity Findings   Missing Events    No Function for Fee Withdrawal    Read-only Reentrancy    Zero Amount ERC20 Transfers   0  2  0  4  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Overflow Might DOS the App",
        "body": "  The _tradeTargetAmount and _tradeSourceAmount functions compute the input/output needed to perform  a  trade  in  a  Strategy.  However,  Strategy  inputs  are  only  constrained  by  the  z  variable  which should be greater or equal to y. This implies that A or B can be set arbitrarily by a user and z has no no limit to the upside.  Let's take the example of _tradeTargetAmount:  function _tradeTargetAmount(uint256 x, Order memory order) private pure returns (uint128) {     uint256 y = uint256(order.y);     uint256 z = uint256(order.z);     uint256 A = uint256(order.A);     uint256 B = uint256(order.B);      if (A == 0) {         return MathEx.mulDivF(x, B * B, ONE * ONE).toUint128();     }      uint256 temp1 = y * A + z * B;     uint256 temp2 = (temp1 * x) / ONE;     uint256 temp3 = temp2 * A + z * z * ONE;     return MathEx.mulDivF(temp1, temp2, temp3).toUint128(); }  Here,  z  could  potentially  be  type(uint128).max,  which  would  imply  that  the  temp3  computation overflows, and the transaction reverts.  An  attacker  could  create  a  simple  Strategy  with  all  parameter  values  (except  the  liquidity)  maxed  out. This Strategy will yield great results in the SDK: It returns extremely favorable rates for any trade. And as the computation in the SDK is not bound by 256 bit limits, these rates will always be sorted to the top of  Bancor - Carbon -   11  CriticalHighCodeCorrectedCodeCorrectedMediumLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedDesignHighVersion1CodeCorrected        \feach getTradeData call without errors. This results in all users relying on the SDK now trading against a Strategy that reverts on-chain.  that   the  mulDiv  Note  type(uint128).max due to the safe downcast to 128 bits.  it  might  also  happen  when   function's  result  ends  up  greater   than    The SDK now incorporates checks to verify that each calculation (e.g., mulDivC) does not exceed 256 functions  _tradeSourceAmount  and bits  and  does  not  go  below  0.  Additionally,  _tradeTargetAmount now calculate factors that are used to scale down intermediate numbers that are too big to fit in 256 bits.  the   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Price Precision Very Low for Some Tokens",
        "body": "  Pairs containing a very low-value token and a low decimal token create some precision issues. Assume the existence of a token named TOK with 18 decimals and another token named USD with 6 decimals precision. Let's say the price of TOK is 0.00001 USD per TOK.  If  a  user  wants  to  buy  some  TOK  at  constant  price  P  =  0.00001  USD  per  TOK,  then  they  need  to compute the B parameter this way:  B = 2^32 * sqrt(0.00001 * 1e6 / 1e18) B = 13.581879131294592  However,  B  must  be  an  integer,  meaning  it  will  be  rounded  up  or  down  (depending  on  the  frontend implementation). In any case, the price will differ greatly from the intended price resulting in possible loss or no execution for the user.  Note: This issue was already disclosed by Bancor at the beginning of the audit.    Bancor added precision by increasing the multiplying factor to 2^48 instead of 2^32, and implemented an encoding logic to be able to stretch the range of possible rates. Values greater than 2^48 now can have a (negligible) precision loss.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Missing Events",
        "body": "  Some state-changing actions are missing an event emission. For example, most setters in the Voucher contract are not emitting events.    Missing events have been added to all state-changing functions.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   No Function for Fee Withdrawal",
        "body": "  Each trade accumulates fees in Strategies._accumulatedFees. There is, however, no function to withdraw  these  fees.  Withdrawal  is  still  possible  by  assigning  the  ROLE_ASSET_MANAGER  role  to  the owner  of  the  contract  and  withdrawing  funds  via  MasterVault.withdrawFunds.  This  is,  however,  Bancor - Carbon -   12  CorrectnessHighVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \ferror-prone as more than the actual amount of fees could be withdrawn. The past has shown that faulty governance proposals can be executed. This should be avoided by restricting the fee withdrawal directly in the contract.    A ROLE_FEES_MANAGER role was added along with a function to withdraw a specific amount of fees of a particular token.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Read-only Reentrancy",
        "body": "  When updating a strategy, funds are first transferred or withdrawn (which might lead to a callback to the user, for example if the native token is used) before the strategy is updated in storage. Considering the possibility of an external protocol integrating with Carbon, it might be the case that the protocol wants to measure the value of a strategy by reading the order parameters in storage. In this case, the read value would not correspond to the real value of the strategy.  For example, an external integration might accept a Strategy NFT and give the user something in return based on the liquidity the NFT holds. Consider the following process:   The user approves the NFT for the given contract.   The user calls updateStrategy to reduce the liquidity of the Strategy associated with the NFT.  In the callback, the user calls the contract's function that transfers the NFT.   The contract transfers the NFT, checks the associated liquidity and gives the user a return.   The liquidity of the Strategy is reduced and the tokens are sent to the user.    Order data is now updated in storage before any possible calls to the user are performed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Zero Amount ERC20 Transfers",
        "body": "  Some  tokens  revert  on  transfers  of  0  amount.  Calls  to  CarbonController.createStrategy potentially  try  to  perform  such  0-amount-transfers  if  one  of  the  given  orders  does  not  contain  liquidity. The call would revert in this case.    The code now transfers tokens only if the amount is greater than 0.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Ambiguous Naming",
        "body": "  Some functions / error messages are named ambiguously in contrast to the naming of other entities:   The  error  GreaterThanMaxInput  is  thrown  in  CarbonController.tradeByTargetAmount  when a value is smaller than maxInput.   CarbonController.tradeSourceAmount  and  CarbonController.tradeTargetAmount are easily confused with tradeByTargetAmount and tradeBySourceAmount, but the meaning of target and source is reversed.  Bancor - Carbon -   13  SecurityLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrectedInformationalVersion1CodeCorrected                       \f Strategies._tradeSourceAmount  and  _tradeTargetAmount  are  easily  confused  with tradeByTargetAmount and tradeBySourceAmount, but the meaning of target and source is reversed.    Function names were changed and the error name was corrected.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   Gas Inefficiencies",
        "body": "  1. If a pool does not already exist when creating a Strategy, the _createPool function returns  the created pool but it is not used and instead read from storage afterwards.  2. The Pool struct id field is redundant as the struct can only be accessed through a mapping  with Pool ID as key.  3. The StoredStrategy struct id field is redundant as the struct can only be accessed through  a mapping with Strategy ID as key.  4. In  _createPool,  the  _poolIds  mapping  is  set  up  with  the  tokens  in  sorted  and  reversed order. Instead, _pool could always sort the tokens before searching in the mapping with little overhead.  5. When updating a Strategy, the packed orders could be updated word by word, just like in the  _trade function.  6. In  tradeBySourceAmount  /  tradeByTargetAmount,  _validateTradeParams  loads  all Strategies  associated  with  the  given  trade  actions  from  storage.  _trade  later  loads  the Strategies from storage again.  7. In _trade, StoredStrategy fields are accessed multiple times (in storage), but could have  rather been saved to memory once.  8. In StoredStrategy, the fields owner and token1 might be redundant as they are not used in the contracts (except in events). Off-chain applications could extract the data elsewhere.    1. The returned pool from the _createPool function is now being used.  2. The id field was removed from struct.  3. The id field was removed from struct.  4. Sorting is now performed where needed, instead of the double sided storage.  5. Orders are now updated word by word.  6. validateTradeParams no longer loads the strategies.  7. Trade flow now loads values only once.  8. Both owner and the tokens were removed from the strategies.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   Typographical Errors",
        "body": "  Some comments / symbol names contain typographical errors. Some examples are:  Bancor - Carbon -   14  InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected            \f PoolDoesNotExists error thrown in Pools._validatePoolExistance.   The comment \"revert here if the minReturn/maxInput constrants is unmet\" in Strategies._trade.   The   comment   \"the   address   of   the   admin   can't   be   change,   so   [...]\"   in  TransparentUpgradeableProxyImmutable.  Errors corrected:  Typographical errors in various sections of the code have been improved or removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   Unused Code",
        "body": "  A few pieces of code seem to be nut in use in the project anymore. This list is non-exhaustive:  1. In CarbonController, the error ZeroLiquidityProvided is unused.  2. In the MathEx library, the Math library of OpenZeppelin is imported but unused.  3. In Strategies, the StrategyUpdate struct is unused.    Unused code has been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.11   _updateOrders Error Message",
        "body": "  Strategies._updateOrders  removes  the  target  amount  of  a  trade  from  the  respective  order's  y value. If this amount is actually larger than y, the transaction reverts on underflow. As this is a common case (for example for trades that are executed after some other trades on the same Strategy), an actual error message might make sense.    An error message has been created and is returned for this specific case.  Bancor - Carbon -   15  InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected            \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   No Automatic Order Execution",
        "body": "  Orders  are  not  evaluated  against  the  set  of  currently  active  orders  upon  creation.  This  means,  that  an order with a price outside of the spread between buy and sell orders (on the respective \"other side\") is not executed against other orders but just included into the set of active orders. If a user were to place an order with a price that is not intended (e.g., due to keyboard input error), this order will be executed at exactly  that  price  (as  soon  as  a  trade  occurs),  even  if  there  are  other  open  orders  the  order  could  be executed against for a better price.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Order Prices",
        "body": "  Users are able to choose order prices arbitrarily, making it possible to create strategies that do not make sense market-wise but might happen by mistake for example.  One could create a Strategy with the buy order prices being greater than the sell order prices, basically giving out liquidity to other users.  Another  possibility  is  a  Strategy  with  partially  overlapping  prices.  In  this  case  there  are  conditions  that could  lead  to  the  user  also  losing  liquidity.  Consider  the  following  example  of  a  Strategy  with  opposite orders in the same price range:   Fees are 0% for simplification.   The buy order buys A tokens for 100 B tokens with a price range of [1, 4].   The sell order sells 50 A tokens for B tokens with a price range of [1, 4].   A trader now buys 100 B tokens for a total of 50 A tokens on the buy curve.   The 50 A tokens are added to the liquidity of the sell curve, resulting in 100 A tokens liquidity. The  capacity of the sell curve is adjusted to 100, moving the curve.   The trader now immediately buys ~67 A tokens on the sell curve for the 100 B tokens they received  before.   The trader made an instant profit of ~17 A tokens.  For these reasons, it is important to note that users should be fully aware of the consequences of their strategy parameters choice.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Token Incompatibilities",
        "body": "  Some tokens are not compatible with the system:   Tokens with fees.   Rebasing tokens.  Bancor - Carbon -   16  NoteVersion1NoteVersion1NoteVersion1          \f7.4   Trade Frontrunning  CarbonController.tradeBySourceAmount  and  tradeByTargetAmount  implement  slippage protection  in  order  to  mitigate  risks  of  frontrunning.  However,  as  Strategies  can  be  updated  by  their owners  for  relatively  cheap  and  with  arbitrary  values,  frontrunning  trades  in  Carbon  is  simpler/cheaper than on traditional AMMs. For this reason, users should keep their slippage protection tight and expect their minima/maxima to be hit regularly.  Consider the following example:   User1 creates a strategy with:   A = 1   B = 1   y = 100   z = 100   User2 creates a trade transaction based on this strategy and expects to receive exactly 100 tokens for the 50 tokens they send in (not considering fees). They set the minimum amount of tokens they want to receive to 80.   User1  observes  the  mempool  and  sees  the  transaction  User2  just  created.  They  now  create  an  updateStrategy transaction with the following changes to their strategy:   A = 0.5   User1 pays a miner to include this transaction before the transaction of User2 (or any other trade  transaction that is performed on the given strategy) in the next block.   After User2's transaction is executed, they receive only ~82 tokens instead of the expected 100.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   updateStrategy Denial of Service",
        "body": "  CarbonController.updateStrategy  employs  a  mechanism  that  ensures  that  a  strategy  has  not been  altered  between  the  creation  of  a  transaction  and  the  actual  execution.  An  attacker  could theoretically  block  certain  users  from  ever  updating  their  Strategies  by  frontrunning  their  calls  to updateStrategy with miniscule trades.  Nevertheless, users still have the possibility to delete and re-create their Strategies if they were targeted in such an attack.  Bancor - Carbon -   17  NoteVersion1NoteVersion1        \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Temporary DoS Due to Max Deposit in",
        "body": " Metamorpho  The Metamorpho contract's maxDeposit() function may overestimate the maximum amount of assets that can be deposited:  /// @dev Warning: May be higher than the actual max deposit due to duplicate markets in the supplyQueue.  CS-D3M4626-001  Hence, it could be possible, that the D3M may try to deposit more than possible into the pool. Ultimately, the D3M could revert and deposits could be temporarily DoSed.  Note that for regular ERC-4626 tokens, the following holds:  MUST return the maximum amount of assets deposit would allow to be deposited for receiver and not cause a revert, which MUST NOT be higher than the actual maximum that would be accepted (it should underestimate if necessary).  To summarize, deposits could be theoretically DoSed due to an overestimation of the maximum allowed deposit for Metamorpho.  Risk accepted:  MakerDAO is aware of the issue.  MakerDAO - D3M ERC-4626 -   9  CorrectnessCriticalHighMediumLowRiskAcceptedCorrectnessLowVersion1RiskAccepted         \f6   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Lack of NatSpec and Documentation",
        "body": "  While  the  README  and  comments  generally  document  the  codebase  sufficiently,  adding  further documentation could be helpful. Namely, the following parts could be improved:  1. The  D3MOperatorPlan,  in  contrast  to  the  new  ERC4626  pool,  does  not  have  any  NatSpec  (inherited from its interface).  2. The README contains descriptions for other pools and plans. However, it has not been extended  to include the new contracts.  CS-D3M4626-002  MakerDAO - D3M ERC-4626 -   10  InformationalVersion1  \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Imprecise Handling of Standard ERC-4626",
        "body": " With Fees  EIP-4626 defines the convertToAssets() to satisfy the following property:  MUST NOT be inclusive of any fees that are charged against assets in the Vault.  While Metamorpho provides an accurate estimate for mints and burns, the standard specifies that these should not be included. Hence, for tokenized vaults with fees charged against assets in the vault (e.g. withdrawal  fees),  convertToAssets()  may  overestimate  the  assets  that  will  be  received  (for ERC-4626 with fees).  Note that convertToAssets() does not include other parameters in its calculation (e.g. slippage) and hence the number of assets managed could be underestimated in certain scenarios.  As  a  consequence,  the  D3MHub  may  make  a  wrong  decision  regarding  winding  or  unwinding  or  an imprecise one.  MakerDAO - D3M ERC-4626 -   11  NoteVersion1  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   EIP-4626 Non-Compliance",
        "body": "  CS-CPER-001  A Pool implements the EIP-4626 Tokenized Vaults standard. Some code parts are, however, not fully compliant with the standard as can be seen in the following list:   convertToAssets  and  convertToShares  revert  when  PoolLib.isSolvent  returns  false. This is in violation of the requirement MUST NOT revert unless due to integer overflow caused by an unreasonably large input.   maxDeposit  and  maxMint  revert  on  totalAvailableAssets  >  poolMaxCapacity  which  violates the rule MUST NOT revert.   maxDeposit, maxMint, maxWithdraw and maxRedeem do not return 0 when the Pool is paused. This behavior is not allowed under the MUST factor in both global and user-specific limits, like if deposits are entirely disabled (even temporarily) it MUST return 0 requirement.   withdraw and redeem require the owner parameter to be equal to msg.sender. This makes the scheme required by the rule MUST support a withdraw flow where the shares are burned from owner directly where msg.sender has EIP-20 approval over the shares of owner. not possible.   The  first  parameter  of  the  events  Withdraw  and  Deposit  is  named  caller  while  the  standard  requires it to be named sender.   PermissionedPool.maxWithdraw  and  maxRedeem  are  not  checking  permissions.  Since permissions  can  invalidate  after  some  time,  the  functions  violate  the  requirement  MUST  factor  in both global and user-specific limits.     maxDeposit and maxMint no longer revert on underflow.  Circle - Perimeter -   15  SecurityDesignCorrectnessCriticalHighMediumCodePartiallyCorrectedLowAcknowledgedRiskAcceptedCorrectnessMediumVersion1CodePartiallyCorrected           \f maxDeposit, maxMint, maxWithdraw and maxRedeem now return 0 when the Pool is paused.   The Withdraw and Deposit are now emitted with the correct parameter naming.   PermissionedPool.maxWithdraw and maxRedeem are now correctly checking permissions.  Code not corrected:   withdraw and redeem still don't support EIP-20 approval for owner.  Risk accepted:  Circle accepts the risk of the convertToAssets and convertToShares non-compliance, stating:  We implemented nearly all the changes recommended in the finding, except for the convertToAssets()/shares() functions reverted on Pool insolvency. Since that\u2019s essentially a terminal state for the Pool, and the code change being non-trivial, we opted to leave it as-is.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   ERC-4626 Donation Attack",
        "body": "  The  Pool.deposit()  function  is  susceptible  to  a  frontrunning  attack  that  involves  donations  of  the underlying token. Consider the following example:  CS-CPER-002  1. A new Pool has been deployed.  2. An attacker deposits 1 wei of the liquidity asset into the pool and mints 1 share.  3. A regular user deposits 10000 full tokens of the liquidity asset into the pool.  4. Before the transaction of the user is executed, the attacker executes another transaction in which  they transfer 5000 full tokens directly onto the pool.  5. The  user  now  receives  1  share  for  the  10000  tokens  deposited.  The  attacker  also  holds  1  share  while they only deposited 5000 tokens (+ 1 wei).  6. The attacker profited 50%.  Since the attacker is not able to instantly withdraw the funds, this attack can be noticed and necessary steps (e.g., change of withdrawGate or removal of the necessary permissions of the attacker) can be taken before any real danger occurs.  Acknowledged:  Circle has acknowledged the issue.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   ToS Acceptance Registry Update",
        "body": "  PoolAccessControlFactory.create  sets  the  tosAcceptanceRegistry  in  the  newly  created PoolAccessControl  contract  from  the  value  in  ServiceConfiguration.  This  value  cannot  be In updated  anymore.  The  value,  however,  can  be  updated  PermissionedPool, the poolAccessControl address cannot be updated either. This means, if the ToSAacceptanceRegistry ever changes to a new address, permissioned pools can only be updated by updating the beacon implementation of all PoolAccessControl instances.  in  ServiceConfiguration.   CS-CPER-003  Circle - Perimeter -   16  SecurityLowVersion1AcknowledgedDesignLowVersion1RiskAccepted                \fRisk accepted:  Circle accepts the risk with the following statement:  We have no plans to introduce separate ToS Acceptance Registries, so it feels premature to build around that right now. We accept the risk given that in a worst-case scenario, we could upgrade PoolAccessControl contracts to point to a new registry if needed.  Circle - Perimeter -   17    \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings   cancelFunded Counts Assets Twice   -Severity Findings   Withdrawal DoS   feeVault Stuck Funds   -Severity Findings   Full Cancel Request Not Possible    Late Fees Do Not Go to First Loss Vault    Missing Permission Checks    paymentDueDate Updated After Last Payment   -Severity Findings   Callback State Not Used   Inconsistent State After Withdrawal Cancellation    Missing Sanity Checks    Pool Tokens Not Transferable    completeFullPayment Return Value    onlyPoolAdmin Modifier   1  2  4  6  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   cancelFunded Counts Assets Twice",
        "body": "  Loan.cancelFunded does not call Pool.onLoanPrincipalReturned.  This means that outstandingPrincipals will not be reduced by the loan amount and the loan will be counted twice in totalAssets.  This  will  increase  the  value  of  a  pool  share,  allowing  lenders  to  withdraw  more  assets  than  they deposited, leading to the Pool becoming insolvent.  CS-CPER-024    LoanLib's returnCanceledLoanPrincipal now calls Pool.onLoanPrincipalReturned.  Circle - Perimeter -   18  CriticalCodeCorrectedHighCodeCorrectedCodeCorrectedMediumCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCorrectnessCriticalVersion1CodeCorrected            \f6.2   Withdrawal DoS  CS-CPER-026  The snapshot algorithm creates snapshots in each period containing aggregation sums and differences (as pointed out in the System Overview). Over time, the sums converge to 1 RAY while the differences converge  to  0.  When  the  difference  hits  the  0  value,  it  is  set  to  1  RAY  resulting  in  the  whole  process starting from the beginning (the sums now converge to 2 RAY).  As the difference converges to 0, rounding errors intensify. If the difference is exactly 1, rounding errors approach 100%: Eligible shares in the global state are converted to redeemable shares according to the withdraw gate, while in the user state, no eligible shares are converted at all.  In  the  next  call  to  WithdrawController.simulateSnapshot,  the  user's  eligible  shares  are  then multiplied by the difference between the aggregation results (in RAY), multiplied with 1 RAY, divided by 1 and then divided by 1 RAY, leaving a number for redeemable shares that is orders of magnitude higher than the actual requested shares of the user:  uint256 sharesRedeemable = withdrawState.eligibleShares.mul(     endingSnapshot.aggregationSumRay - offsetSnapshot.aggregationSumRay ); sharesRedeemable = sharesRedeemable     .mul(offsetSnapshot.aggregationDifferenceRay > 0 ? PoolLib.RAY : 1)     .div(         offsetSnapshot.aggregationDifferenceRay > 0             ? offsetSnapshot.aggregationDifferenceRay             : 1     )     .div(PoolLib.RAY);  The function then reverts on buffer underflow in the following section:  withdrawState.eligibleShares -= sharesRedeemable;  All functions (including Pool.withdraw) that calculate the user's withdrawal state will revert from this point on.  This issue can be exploited by an attacker, with low cost:  To achieve a difference of exactly 1, an attacker has to perform a few withdrawal requests with amounts below  the  withdrawal  gate.  The  decimals  of  the  amounts  used  in  the  request  must  sum  up  to  27  (the decimals of RAY). Depending on the withdrawal gate and the deposited amounts, a difference of 1 can be achieved in a few (~three) withdraw periods. The next withdrawal in any following period will result in at least one user being unable to withdraw. All users performing withdrawal requests in the same period will be affected. Withdrawal requests in the following periods will work as expected again.  Consider the following example:   The withdrawal gate is 25%.   The token has 6 decimals.   User 1 deposits 40,000 tokens.   User 2 deposits 40,000 tokens.   An attacker deposits 20,010 tokens.  In period 1, the attacker requests a withdrawal of 10,000 tokens.  In period 2, the attacker requests a withdrawal of 10,000 tokens.  Circle - Perimeter -   19  CorrectnessHighVersion1CodeCorrected        \fIn period 3, the attacker requests a withdrawal of 10 tokens minus 2 wei.   The difference is now 1 and the aggregation sum is 999999999999999999999999997.   The attacker withdraws their whole balance.   A few periods pass without any interaction.  In period 10, user 1 requests a withdrawal of 40,000 tokens.  In period 11, user 1 still has 0 withdrawable assets due to the rounding error.   Starting from period 12, interactions with the contracts revert for user 1.  In period 12, user 2 can request a withdrawal and everything works out as expected.  The attacker has performed a DoS attack on a subset of the protocol's users for a low cost: They paid only the gas fees and the pool's request fees. If User 2 had also tried to withdraw in period 10, their funds would be stuck too. If the attacker performs the attack in the last period before the end date of the pool, chances are high that a large amount of users are affected as they try to withdraw immediately after the pool  closes.  The  attacker  could  repeat  the  attack  by  depositing  again  and  making  more  withdrawal requests.    The snapshot algorithm has been replaced by a mechanism that saves the conversion rates of eligible shares to redeemable shares individually. Users that want to request a withdrawal (or cancel requested shares) are now required to manually update their state by calling claimSnapshots if their last action was performed in a past period and their current state contains some eligible shares.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   feeVault Stuck Funds",
        "body": "  Pool.initialize creates a feeVault. The owner of the Vault is set to the Pool. Only the owner can withdraw funds from the Vault.  As Pool does not contain any function that withdraws from the feeVault, any funds sent to it will be stuck.  CS-CPER-019    A  function  withdrawFeeVault  has  been  added  to  the  Pool,  which  can  be  called  by  the  Pool  Admin through the PoolController to withdraw from the Fee Vault.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Full Cancel Request Not Possible",
        "body": "  A  discrepancy  between  Pool.maxRequestCancellation  and  cancelRedeemRequest  / cancelWithdrawRequest  leads  to  users  not  being  able  to  cancel  all  of  their  requested  (but  not  yet redeemable) shares. Consider the following example:  CS-CPER-020   A user holds 500 shares on a Pool.   Request fee is 0% and request cancellation fee is 10%.   The user requests a withdraw for 500 shares. His requested shares are now 500.  Circle - Perimeter -   20  CorrectnessHighVersion1CodeCorrectedCorrectnessMediumVersion1CodeCorrected                    \f The user now decides to cancel the full withdrawal request.   maxRequestCancellation returns 450.   The user calls cancelRedeemRequest with 450 shares.   45 shares are burned, 450 shares are removed from the withdrawal request.   5  tokens  remain  in  the  withdrawal  request  because  the  mentioned  functions  calculate  fees  in  a  different way.    PoolLib.calculateMaxCancellation  now  returns  all  requested  /  eligible  shares  (ignores  fees). When executing the cancellation, fees are burned, and then the requested amount is deducted from the withdrawal state.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Late Fees Do Not Go to First Loss Vault",
        "body": "  The late payment fees are supposed to be a fixed amount that goes to the first loss vault.  However, they are instead paid to the Pool in completePayment.  Additionally,  the  documentation  incorrectly  states  that  \"Late  fees  are  [...]  a  percent  of  the  payment amount  on  interest.\"  This  is  incorrect,  as  late  fees  are  a  fixed  amount.  In  particular,  if  multiple  late payments are made at once using completeFullPayment(), the fee is only charged once.    Late Payment Fees are now transferred to the First Loss Vault instead of the Pool.  CS-CPER-021  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Missing Permission Checks",
        "body": "  Contracts  in  the  permissioned  directory  extend  the  base  contracts  by  adding  permission  checking using the Verite protocol. This is done by overriding dummy modifiers of the base contracts. As Verite identities can expire, permissions have to be checked on each interaction. This is, however, not enforced in all parts of the base contracts:  CS-CPER-023   Loan.cancelFunded does not check borrower and admin permissions.   Loan.claimCollateral does not check borrower and admin permissions.   Loan.reclaimFunds does not check admin permissions.    Loan and PoolController have been refactored. The Pool Admin now only interacts with the Loan via the PoolController, which enforces permissioning. It was clarified that permissions should not be checked for the borrower on Loan.cancelFunded.  Circle - Perimeter -   21  CorrectnessMediumVersion1CodeCorrectedCorrectnessMediumVersion1CodeCorrected                  \f6.7   paymentDueDate Updated After Last Payment  CS-CPER-025  The  paymentDueDate  through is  updated  after  completeNextPayment. This is incorrect as the loan should end in the period of the last payment. The final paymentDueDate is one period after the loan end date. Repayment of principal within this period will not be considered late, meaning there will be no late fee charged even though there should be.  last  payment  made   in  Loan   the     paymentDueDate is now only incremented if paymentsRemaining is larger than zero.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   Callback State Not Used",
        "body": "  The LifeCycleState enum contains the Callback state. This state is never used, as callbacks are not enforced on-chain in the current version.  CS-CPER-015    The Callback state has been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   Inconsistent State After Withdrawal",
        "body": " Cancellation  WithdrawController.performRequestCancellation  a PoolLib.calculateWithdrawStateForCancellation update on both the requesting user's state and  the  global  state.  The  function  first  tries  to  match  all  requested  shares  before  matching  eligible shares. If multiple users have open requested shares, the values differ between global and user state. This leads to an inconsistency: If the user's cancellation request removes eligible shares, the global state will have more requested shares removed. Consider the following example:  performs   CS-CPER-022   User 1 has requested 500 shares and 500 shares are already eligible.   User 2 has requested 500 shares and 500 shares are already eligible.   The global state, therefore, has 1000 requested shares and 1000 eligible shares.   User 1 now cancels 1000 shares.   0 requested shares and 1000 eligible shares remain in the global state.   500 requested shares and 500 eligible shares remain in user 2's state.  As soon as a new period starts, the data matches again.  While  we  have  found  no  issues  arising  from  this  inconsistency,  third  party  protocols  might  rely  on  the data.  Circle - Perimeter -   22  CorrectnessMediumVersion1CodeCorrectedDesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                      \f  The changes in user state are now saved in memory, so that an equal amount can be removed from the global state.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   Missing Sanity Checks",
        "body": "  CS-CPER-016  The following checks are not performed, leading to misconfiguration possibilities:   LoanFactory.createLoan  allows   the  creation  of  a  Loan   that  does  not  match   the  liquidityAsset of its Pool.   PoolFactory.createPool does not check that serviceFeeBps is lower than 10,000.   Pool.redeem does not revert with an error message when maxRedeem is reached (as opposed to  Pool.withdraw).   VaultFactory.createVault does not revert with error when beacon implementation is not set.   WithdrawControllerFactory.createController  does  not  revert  with  error  when  beacon  implementation is not set.    All aforementioned problems have been resolved.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.11   Pool Tokens Not Transferable",
        "body": "  The _beforeTokenTransfer() function of Pool has been overwritten to disallow token transfers.  This is a mismatch with the specification, which states:  Pool Tokens are transferable, but to redeem the token back the new Pool Token holder will still need to comply with the pool\u2019s lender access requirements.  CS-CPER-027  Specification changed:  The documentation has been updated to clarify that Pool Tokens should not be transferable.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.12   completeFullPayment Return Value",
        "body": "  Loan.completeFullPayment returns payment even when a different amount has been paid.  CS-CPER-017    The return values for both completeFullPayment and completeNextPayment have been removed.  Circle stated that an event may be added in a future version to support easier off-chain accounting.  Circle - Perimeter -   23  CorrectnessLowVersion1CodeCorrectedCorrectnessLowVersion1Speci\ufb01cationChangedCorrectnessLowVersion1CodeCorrected                        \f6.13   onlyPoolAdmin Modifier  In Loan, all Pool Admin functions are accessed through the PoolController, except reclaimFunds and markCallback. For these, the onlyPoolAdmin modifier is used which allows the Pool Admin to call the Loan contract directly. The interface is not consistent.  CS-CPER-018    functions   The  and markLoanCallback  have  been  refactored  so  that  they  can  only  be  accessed  through  the PoolController.  claimLoanCollateral,   reclaimLoanFunds,   cancelFundedLoan   Circle - Perimeter -   24  DesignLowVersion1CodeCorrected        \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Events Could Be More Informative",
        "body": "  This  is  a  collection  of  events  that  could  benefit  from  containing  more  information.  The  list  contains examples and is non-exhaustive:   PoolController  emits  the  PoolSettingsUpdated  event.  This  event  is  emitted  by  4  different functions and contains no information about which values were changed or what the old and new values are.  CS-CPER-004   PoolLib  emits   the  FirstLossApplied  event.   the  loan  address  and firstLossRequired. However, it does not contain the outStandingLoanDebt. This means the event  is  not  sufficient  to  know  whether  the  firstLoss  vault  had  sufficient  funds  to  cover  the defaulted loan or if the loss was socialized among lenders.  It  contains    Some  setters  (e.g.,  ServiceConfiguration.setPaused)  emit  events  even  when  the  value  of  the respective storage variable is not changed.   Pool._performRedeemRequest  emits  an  event  with  shares  and  assets.  The  amount  of assets, however, is non-conclusive at this point, since it can be higher if another loan repayment occurs before the period ends.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Inconsistent Naming",
        "body": "  Pool contains multiple functions that are called by PoolController. Their naming, however, does not follow  a  common  scheme.  For  example,  PoolController.defaultLoan  calls seem  Pool.onDefaultedLoan, while PoolController.fundLoan calls Pool.fundLoan.  to   CS-CPER-005  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Missing Events",
        "body": "  Some events are missing. We list some examples here. Note that this list may be incomplete:   markCallback()  is  used  to  have  on-chain  evidence  of  the  timestamp  at  which  a  callback  of  an  open loan was initiated. Currently this only sets a storage variable, but does not emit an event.  CS-CPER-006   ILoan  defines   the  LifeCycleStateTransition  event.   in Loan.markDefaulted.  The  event  is  missing  in  all  other  functions  of  Loan  that  change  the Lifecycle  State.  Note  that  IPool  also  defines  an  event  with  the  same  name,  which  may  be confusing.  is  only  emitted   It   Circle - Perimeter -   25  InformationalVersion1InformationalVersion1InformationalVersion1          \f The  PoolAccessControlFactory  does  not  emit  an  event  when  a  proxy  is  created,  the  other  factories do.   The PoolSettingsUpdated event in PoolLib exists but is never emitted.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   Possible Gas Optimizations",
        "body": "  The following code parts can be optimized for gas efficiency. The list is non-exhaustive:   Redundant storage reads are performed in various places, for example:  CS-CPER-007   Loan.postFungibleCollateral  (as  well  as  many  other  functions  in  Loan)  possess  the actual value of _state (because it has just been written) and still return the state by reading from storage.   Loan.fund loads the _state two times in a row from storage.   Redundant storage writes are also performed in various place, for example:   Loan.postFungibleCollateral writes to _state even though the contents of _state are  already known and might be identical to the new value.   WithdrawController.performRequest  sets  the  latestSnapshotPeriod  of  the  user state to the latestSnapshotPeriod of the global state although this has already been done in the prior snapshotLender call.   ToSAcceptanceRegistry._termsSet is set on an update to _termsOfService. A length check of _termsOfService, however, is sufficient to determine whether the variable was set.   External  calls  are  more  expensive  than  internal  calls.  Redundant  external  calls  are  performed  in  various places, including:   The RAY constant is read from PoolLib and LoanLib many times. Reading a constant from  an external library requires an extra delegatecall each time.   Some Pool settings are only used in Pool (e.g., requestFee, requestCancellationFee) but  are  stored  in  PoolController.  Accessing  these  variables  (and  their  respective calculation functions) requires an external call every time.   Pool.onActivated   to  call PoolController.settings  while  the  settings  could  have  just  been  passed  directly  to  the function.  the  PoolController,   then  proceeds   is  called  by    Some   limited   functionality  (3   libraries,  e.g., PoolLib.executeFirstLossWithdraw.  This  barely  helps  with  deployment  costs  but requires an additional external call.  lines  of  code)   is  extracted   to  external    PoolController.withdrawFirstLoss  calls  Pool.firstLossVault,  which  in  turn  calls  PoolController.firstLossVault.   Redundant calculations can be found in the following places:   Pool._performRedeemRequest calls WithdrawController.maxRedeemRequest which calculates  _currentWithdrawState.  Then,  WithdrawController.performRequest  is called which calculates _currentWithdrawRequest again.   WithdrawController.performRequest  calculates  _currentWithdrawState  with  a  state that has already been updated by the prior call to snapshotLender.   WithdrawController.snapshot   calculates   the   withdrawPeriod,   then   calls  _currentGlobalWithdrawState which calculates the withdrawPeriod again.  Circle - Perimeter -   26  InformationalVersion1    \f The initializer of Loan sets the _state to Requested. Since Requested is item 0 in the enum, this is  already  in PoolController.initialize which sets the Pool state to Initialized even though it is the default value.  is  unnecessary.  The  same   the  default  value  and   the  case   is    Pool.onlyPoolController  checks  that  poolController  is  not  the  0-address  and  that  it  is  msg.sender. The first check is redundant.   Some  contracts  (e.g.,  Pool)  use  transferFrom  with  the  from  address  set  to  themselves.  To make this work, they also set an approval to themselves beforehand. A simple transfer would be sufficient.  In  IPoolAccountings,  fields  totalAssetsDeposited,  totalAssetsWithdrawn, totalDefaults and totalFirstLossApplied are written but never read. Off-chain accounting can also be achieved with events.  the    LoanLib.postFungibleCollateral  inserts  new  collateral  addresses  into  the  collateral  state variable in non-constant time (as opposed to e.g., an EnumerableSet).   PoolLib.calculateWithdrawStateForCancellation could return early in the first condition.   PoolLib.calculateMaxCancellation  uses  Math.max  on  an  unsigned  integer  and  0  and  is  thus redundant.   WithdrawController.simulateSnapshot  could  return  early  on  eligibleshares  ==  0  or  endingSnapshot == offsetSnapshot.  In   , the following gas optimization can be achieved:   Each  IPoolSnapshotState  occupies  4  slots  in  storage.  As  redeemableRateRay  is  not  larger than RAY, fxRateRay is not larger than several multiples of RAY, sharesRedeemable is not used anywhere in the code and any amount of periods can easily be captured in 40 bits, the whole struct could be reduced to 1 word per snapshot:   uint108 redeemableRateRay   uint108 fxRateRay   uint40 nextSnapshotPeriod  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   Shadowed Variable",
        "body": "  Vault.initialize  uses  a  parameter  owner  OwnableUpgradeable.  that  shadows   the  owner   function   in  CS-CPER-008  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.6   Snapshot Restricted to Admin in",
        "body": " PoolController  Pool.snapshot can be called by anyone. PoolController.snapshot calls Pool.snapshot but is restricted to pool admin access. The function could be safely removed or given public access.  CS-CPER-009  Circle - Perimeter -   27  Version2InformationalVersion1InformationalVersion1           \f7.7   Spelling Errors  Some code comments inside the contracts contain spelling errors. Here are some examples:   The parameter liquidityAsset in Pool.initialize is an asset held by the poo.   Pool.liquidityPoolAssets   contains   the   following   comment:  do not include any loan principles.  CS-CPER-010   LoanLib.payFees   contains  This include both the service fee and origiantion fees.  the   following   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.8   Unused Code",
        "body": "  comment:  CS-CPER-011   PoolController.isInitializedOrActive and isActiveOrClosed are not used and do not  have value for external parties.   ILoanLifeCycleState.Callback is never used.   ServiceConfiguration.protocolFeeBps is set to 0 and never used.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.9   Withdrawal Request Interface",
        "body": "  The following functions have been added as an extension to the existing EIP-4626 interface:  CS-CPER-012   maxRedeemRequest   maxWithdrawRequest   maxRequestCancellation   previewRedeemRequest   previewWithdrawRequest   requestRedeem   requestWithdraw   cancelRedeemRequest   cancelWithdrawRequest  The functions should roughly mimic their counterparts from the EIP. However:   The  standard  defines   from  a  user. requestWithdraw  and  requestRedeem  make  shares  available  for  later  withdrawal  and  burn additional shares as a fee.  that  withdraw  and  redeem  burn  exactly  shares    Referencing  the  previous  point,  previewWithdrawRequest  and  previewRedeemRequest subtract the fee from the input parameter. The rule MUST return as close to and no more than the exact amount of assets that would be withdrawn in a redeem call in the same transaction is therefore violated.  Circle - Perimeter -   28  InformationalVersion1InformationalVersion1InformationalVersion1          \f The  current  interface  of  requestWithdraw  and  requestRedeem  is  now  inconsistent  with cancelWithdrawRequest and cancelRedeemRequest, which handle the shares argument in the same way as the standard.  ,  functions  that  rely  on  the  current  state  of  the  user  (maxRedeemRequest  and In  maxRequestCancellation) should return 0 if claimRequired is true for the given user address.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.10   Withdrawn Collateral Is Shown in View",
        "body": " Functions  When a borrower posts collateral, the collateral's address (and ID for NFTs) is added to a storage array. When  withdrawing  collateral,  it  is  not  removed  from  storage.  The  storage  can  be  read  using  the fungibleCollateral() and nonFungibleCollateral() view functions.  For  example,  a  borrower  may  have  posted  a  certain  ID  of  an  NFT  collection  as  collateral.  After  the collateral has been withdrawn, calling nonFungibleCollateral() will still return the address and ID of the NFT, even though the contract no longer owns it. This may be different from expected behavior.  CS-CPER-013  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.11   Wrong Inline Comment",
        "body": "  CS-CPER-014  PoolLib.calculateWithdrawStateForCancellation  reads ensure  the  \"latestRequestPeriod\"  is  set  to  the  current  request  period.  This  is, however, never done in the function.  contains  a   comment   that   The function is always called in a context where the latestSnapshotPeriod is already updated.  Circle - Perimeter -   29  Version2InformationalVersion1InformationalVersion1         \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Borrower Can Withdraw Additional Tokens",
        "body": "  Tokens  sent  to  the  collateralVault  of  a  Loan  in  error  by  other  users  can  be  redeemed  by  the borrower after the loan has matured.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Fees Can Be Changed During Runtime",
        "body": "  The PoolController allows a pool admin to change fees during the runtime of a pool:   Request fees can be changed in Initialized state only.   Request cancellation fees can be changed in Initialized state only.   Service fees can be changed at any time.   Fixed fees can be changed at any time.  Note that there is no maximum on how high fixed fees can be.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.3   Instant Withdrawal After Deposit",
        "body": "  Instant withdrawal after deposit can lead to loss (on top of the withdrawal fee). Users that deposit after the  start  of  a  period  are  subject  to  expected  interest  that  has  accrued  but  has  not  been  paid  yet.  On deposit, the resulting amount of shares for a given amount of assets is calculated taking this expected interest  into  account.  This  means,  an  instant  withdrawal  after  a  deposit  leads  to  a  loss  as  assets  to shares are calculated without expected interest.  Furthermore,  existing  lenders  experience  an  instant  increase  in  value  per  share  after  another  user deposits with expected interest.  As soon as the expected interest is actually paid, all ratios normalize.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.4   PoolController Approvals",
        "body": "  PoolController.depositFirstLoss  calls  transferFrom  on  the  liquidity  asset  with  a  from address supplied by the caller. If any user gives approvals to the contract, their funds can therefore be transferred to the First Loss Vault by the Pool Admin.  Note  that  there  is  no  reason  for  a  user  to  give  approval  to  the  PoolController,  it  would  only  happen accidentally.  Circle - Perimeter -   30  NoteVersion1NoteVersion1NoteVersion1NoteVersion1                \f8.5   Proxy Deployment  ServiceConfiguration  and  ToSAcceptanceRegistry  should  always  be  deployed  using  the upgradeToAndCall  mechanism  of  the  used  UUPS  proxy  to  ensure  that  the  initializer  cannot  be frontrun.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.6   Request Fee Paid in Shares",
        "body": "  Request fees and request cancellation fees are paid by burning users' shares. This means that the value of  the  burned  shares  is  distributed  among  all  users  of  the  platform.  In  the  case  where  only  one  single user is using a Pool, the fees are therefore non-existent.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.7   Snapshot Every Period",
        "body": "  Withdrawal requests are processed at the beginning of each period. If a period is skipped due to inactivity on  the  contracts,  withdrawal  requests  will  also  not  be  processed  in  this  period.  Users  that  have  open withdrawal  requests  have  to  make  sure  that  Pool.snapshot  or  any  other  function  that  triggers  the snapshot  mechanism  is  called  at  least  once  per  period.  Otherwise,  it  may  take  longer  until  they  can withdraw their full amount.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.8   ToSAcceptanceRegistry Not Versioned",
        "body": "  The ToSAcceptanceRegistry allows an operator to update its terms of service URL. This means it is assumed that acceptances are automatically given to changes in the ToS at a later time.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.9   withdrawPeriods After Close",
        "body": "  WithdrawController.withdrawPeriod calculates the current period the following way:  (currentTimestamp - activatedAt) / withdrawalWindowDuration;  The withdrawalWindowDuration possibly decreases after a Pool enters Closed state, resulting in suddenly inflated period numbers.  Circle - Perimeter -   31  NoteVersion1NoteVersion1NoteVersion1NoteVersion1NoteVersion1                  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Distributing Multiple Times Is Possible Even",
        "body": " in the Same Block  The documentation specifies that the next distribution must be 7 days away from the last distribution. However, this is not necessarily the case. Consider the following example:  1. lastDistribute is block.timestamp - 2 weeks - 1  2. preDistribute() is called. lastDistribute is now block.timestamp - 1 weeks - 1  ISSUEIDPREFIX-001  3. Optionally, distribute() is called.  4. preDistribute() is called. lastDistribute is now block.timestamp - 1  5. Optionally, distribute() is called.  That may occur if the initial lastDistribute value is low (lack of sanity check in the constructor) or if the distribution is not called regularly. Ultimately, the specification is violated.  Further, the behaviour in such cases is unspecified.  Acknowledged:  USDFI has acknowledged this issue stating that:  Emergency option to resync time in case of epoch desync (ie, force majeur event)  USDFI - AMM, Gauges and Bribes -   11  DesignCorrectnessCriticalHighMediumLowAcknowledgedAcknowledgedRiskAcceptedRiskAcceptedCorrectnessLowVersion1Acknowledged            \f5.2   Lost Rewards  The  reward  rate  in  gauges  is  typically  computed  as  reward  /  DURATION.  If  reward  <  DURATION holds, the reward rate will be 0. Ultimately, the rewards are lost as they will not be accounted in in the future.  ISSUEIDPREFIX-002  Acknowledged:  USDFI replied  Rewards must be lost to prevent griefing attacks that can occur due to non-shareable numbers!  However, it could be possible to cache the non-distributable rewards so that they could be accounted for in the future.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   Poking May Revert",
        "body": "  Poking  can  revert  when  _prevWeight  *  _weight  <  _prevUsedWeight  holds.  That  may  be  the case  when  the  user  had  a  big  decrease  in  balance.  Another  scenario  could  be  when  the  user  had specified a small amount of weight allocated to a gauge (e.g. 1, balance decrease from 100 to 99). The revert occurs in the bribe where _deposit() and _withdraw() revert with zero amounts.  Ultimately, a user may not be poked anymore, which could lead to reverts in the gauge's updateReward modifier. However, the issue may be repaired by using vote() or reset().  ISSUEIDPREFIX-003  Risk accepted:  USDFI states:  Smaller amounts are not allowed by the voter, because of the linear drop no fast drops are possible (poking  reversion  is  completely  ruled  out  by  the  vote  escrow  function  in  the  vote  escrow  contract (outside of audit scope)).  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.4   burn() Read-Only Reentrancy",
        "body": "  The  burn()  function  in  the  pair  contract  first  reduces  the  total  supply  and  the  user's  balance,  then transfers  the  underlying  tokens,  and  last  reduces  the  stored  reserves.  If  the  transferred  token  is  a reentrant token, a state inconsistency between the supply and the stored reserves is created.  Note that any computation based on the current supply and the underlying reserves may return wrong results.  ISSUEIDPREFIX-004  Risk accepted:  USDFI has accepted the risk to keep their implementation closer to Uniswap V2.  USDFI - AMM, Gauges and Bribes -   12  DesignLowVersion1AcknowledgedDesignLowVersion1RiskAcceptedDesignLowVersion1RiskAccepted                      \fUSDFI - AMM, Gauges and Bribes -   13    \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings   Contracts Do Not Extend the Interfaces    DOS on Gauges When Derived Supply Is 0    ERC-2612 Violations    Lack of Testing   -Severity Findings   Different Library Versions    Fees Claimable After 50 Weeks   Initial Referral Fee    Lack of Events    Maximum Referral Fee    Used Weights Are Not Reset    recoverERC20() Allows Recovering Arbitrary Tokens   0  0  4  7  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Contracts Do Not Extend the Interfaces",
        "body": "  Most  of  the  contracts  interact  with  each  other  based  on  the  interface  definitions.  For  example, GaugeFactory  relies  on  IBribe  to  handle  the  calls.  However  the  Bribe  contract  itself  does  not explicitly implement the IBribe interface (addReward is missing).  ISSUEIDPREFIX-012  The following is an incomplete list of further examples:   BaseV1Pair does not implement IBasePair   BaseV1Factory does not implement IBaseV1Factory   GaugeFactory does not implement IGaugeFactory   Similarly, this is true for other contracts.  Without typing, there are no compile-time guarantees that the contract will be compatible with the calls to the functions that the interface defines. This can lead to potential runtime errors and exceptions that are hard  to  debug.  It  is  important  to  explicitly  define  that  the  contracts  implement  the  corresponding interfaces, to minimize such errors.  USDFI - AMM, Gauges and Bribes -   14  CriticalHighMediumCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedLowCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedDesignMediumVersion1CodeCorrected         \f  The contracts are implementing now the corresponding interfaces.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   DOS on Gauges When Derived Supply Is 0",
        "body": "  The subtraction  (rewardPerToken() - userRewardPerTokenPaid[account])  ISSUEIDPREFIX-008  in earned() implies that the rewardPerToken() function should be an increasing function. Otherwise, the subtraction will revert. However, its value could decrease when the derived supply goes to zero.  Consider the following scenario:  1. Assume a user for whom userRewardPerTokenPaid[userA] > 0 holds. The derived supply is  0. The reward per token is 0.  2. A deposit to address 0 is made by an attacker with 1 wei. rewardPerTokenStored is set to 0.  3. User A wants to deposit again. The subtraction above reverts.  Note that a scenario for step 2 could occur when user A gets poked first so that his weight changes to 0 (and the total weight too). Then he could get kicked as his derived balance is 0. Ultimately, he will not be able to receive any rewards anymore.  Ultimately, user A will not be able to perform any actions on the gauge anymore.    Code  returns  0  if  derivedSupply  ==  0.  Hence,  the  aforementioned  scenario  cannot  revert earned().  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   ERC-2612 Violations",
        "body": "  The permit() functionality is defined in ERC-2612 which is based on ERC-712. Note that there are two violations of the standards:  1. The PERMIT_TYPEHASH violates EIP-712 which describes the typehash to be the keccak256 of the  encoded struct. However, its value does not match the hash.  2. The lack of an external DOMAIN_SEPARATOR() function violates the ERC-2612 standard.  ISSUEIDPREFIX-017  Ultimately, the implemented standard is violated.    The code has been corrected.  USDFI - AMM, Gauges and Bribes -   15  DesignMediumVersion1CodeCorrectedCorrectnessMediumVersion1CodeCorrected                  \f6.4   Lack of Testing  The codebase does not include any tests. Note that it is highly recommended to properly test intended and unintended behaviour with unit and end-to-end tests. These tests help can build an understanding of undocumented functionality.  ISSUEIDPREFIX-014    USDFI  has  implemented  a  testing  infrastructure  using  Hardhat.  Please  note  that  tests  are  considered out-of-scope. Hence, their correctness and/or coverage are not reviewed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Different Library Versions",
        "body": "  The  libraries  have  different  versions.  For  example,  the  Audit/gauge_factory/Address.sol  and Audit/bribe_factory/Address.sol files have different versions.  ISSUEIDPREFIX-011    The issue has been addressed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Fees Claimable After 50 Weeks",
        "body": "  The documentation specifies that fees are not claimable after 50 weeks. However, the code implements this differently.  Consider, the scenario where userTimestamp is 100 weeks ago. Then, the iteration in earned() will start at the userTimestamp and iterate for 50 weeks. Afterwards, the userTimestamp is updated to the current epoch. Hence, it forfeits the new rewards.  ISSUEIDPREFIX-018  Specification changed:  USDFI has decided to change his documentation, claiming that:  We believe that it's not logical to assume that a user actively votes in the protocol\u2019s governance, but does not claim his rewards for 50 consecutive weeks which are visibly on display every time he votes using the frontend.  Note  that  during  the  fix  window,  we  have  not  received  any  formal  documentation  (rather  than  code comments) from the USDFI to validate this specification has been changed.  USDFI - AMM, Gauges and Bribes -   16  DesignMediumVersion1CodeCorrectedDesignLowVersion1CodeCorrectedCorrectnessLowVersion1Speci\ufb01cationChanged                        \f6.7   Initial Referral Fee  The documentation specifies that the default base referral fee shall be 2%. However, it is 0%.  ISSUEIDPREFIX-016  Code Corrected:  USDFI has correctly hardcoded baseReferralFee to 2000.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   Lack of Events",
        "body": "  Events  are  not  emitted  always  emitted  on  important  state-modifying  actions.  Note  that  this  is  the  case across all contracts. The following is an incomplete list of functions that lack event emissions:  ISSUEIDPREFIX-015   BaseV1Factory.setBaseStableFee()   BaseV1Factory.setBaseVariableFee()   BaseV1Factory.setShouldGasThrottleAndMaxGasPrice()   BaseV1Factory.setOwner()   BaseV1Factory.acceptOwner()   BaseV1Factory.setPause()   BaseV1Factory.setProtocolAddress()   BaseV1Factory.setAdmins()   BaseV1Factory.setPause()   BaseV1Factory.setPause()   BaseV1Factory.setPause()   BaseV1Pair.setFee()   GaugeFactory.preDistribute()   GaugeFactory.updateVeProxy()   GaugeFactory.updatePokeDelay()   GaugeFactory.updateMaxVotesToken()   GaugeFactory.updateReferrals()   ProtocolGovernance.setGovernance()   ProtocolGovernance.acceptGovernance()   ProtocolGovernance.setAdminAndVoter()   ProtocolGovernance.setStableMiner()   ProtocolGovernance.updateBaseReferrals()   Gauge.kick()   Gauge.updateReferral()   Gauge.setWhitelisted()  USDFI - AMM, Gauges and Bribes -   17  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected              \f BribeFactory.createBribe()   Bribe.addRewardtoken()   Bribe.setWhitelisted()   Bribe.updateReferral()  Emitting events could ease following the state of the contract.    USDFI has added emitting relevant events to the functions of the above list.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   Maximum Referral Fee",
        "body": "  The documentation specifies that the referral fee for gauges and bribes is at most 10%. However, that is not enforced, and; hence, the referral fee may exceed 10%.  ISSUEIDPREFIX-007    USDFI has corrected the code by enforcing this limit:  require((_baseReferralFee <= 10000), \"must be lower 10%\");  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   Used Weights Are Not Reset",
        "body": "  When weights are reset, usedWeight is not set to 0. While this has no impact on voting or execution, the automatic getter for usedWeight may return outdated values.  ISSUEIDPREFIX-013    USDFI has successfully corrected the code by setting usedWeights[_owner] to zero.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.11   recoverERC20() Allows Recovering",
        "body": " Arbitrary Tokens  The  recoverERC20()  function  should  according  to  the  documentation  allow  the  governance  to withdraw non-reward tokens from the bribe contract. However, reward tokens can be withdrawn, too.  ISSUEIDPREFIX-020  USDFI - AMM, Gauges and Bribes -   18  CorrectnessLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                        \f  USDFI correctly has changed to code to check that the token to be withdrawn is not a reward token.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.12   Comments With Errors",
        "body": "  The code contains some comments with errors. Examples are:  1. The comment for the stable parameter of BaseV1Pair specifies that is not immutable, while it is.  2. The comment for the baseStableFee of BaseV1Factory mentions that it is 0.04%. However, it  ISSUEIDPREFIX-009  is 0.05%.    USDFI has successfully resolved both the aforementioned errors.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.13   Gas Optimisation",
        "body": "  ISSUEIDPREFIX-019  The  codebase  has  several  inefficiencies  in  terms  of  gas  costs  when  deploying  and  executing  smart contracts. Here, we report a list of non-exhaustive possible gas optimisations:  1. Bribe.constructor:  To  deploy  a  bribe  contract,  in  order  to  set  firstBribeTimestamp, referralContract,  and  referralFee,  multiple  queries  to  the  gaugeFactory  are  made. However,  the  memory  variable  _gaugeFactory  has  the  same  address  and  using  it  instead  of gaugeFactory reduces number of storage reads.  2. getRewardForOwnerToOtherOwnerSingleToken of Bribe has a visibility of public, with input parameter in the memory. As this function is only called externally, its visibility can be changed to external and consequently the input parameters to calldata.  3. The visibility of updateReferral in Bribe can be changed to external and its input parameters to  calldata.  4. BribeFactory defines a storage variable named last_bribe, which is set but never read. Apart from  that,  the  constructor  returns  this  storage  variable,  although  a  local  memory  variable lastBribe holds the same address and returning it is more gas efficient.  5. Gauge  defines  two  state  variables  token  and  TOKEN,  which  necessarily  hold  the  same  address once set. Following the code path, they never get out of sync and are always equal. Hence, holding just one of them and cast it whenever neccesary.  6. gaugeFactory  in  Gauge  is  never  modified  after  being  set  in  the  constructor.  Hence,  it  can  be defined as immutable. Apart from that, they way it is set in the current implementation, it holds the same value as DISTRIBUTION.  7. Gauge._claimVotingFees  calculates  bribe  even  in  the  case,  where  neither  claimed0  nor  claimed1 is non-zero. Calculating bribe inside the if-statement makes it more gas efficient.  8. Gauge._deposit defines a local memory variable userAmount, which holds the value of input  parameter amount. It seems to be unnecessary.  USDFI - AMM, Gauges and Bribes -   19  InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected            \f9. GaugeFactory._vote  updates  totalWeight  incementally  in  each  iteration  of  the  loop.  By accumulating all the changes at updating totalWeight after the last iteration, gas consumption can be reduced significantly.  10. GaugeFactory.addGauge  writes  to  the  last  element  of  maxVotesToken.  However,  this  last  element has the same value as the input parameter _tokenLP.  11. GaugeFactory.preDistribute  inside  the  loop,  makes  multiple  accesses  to  the  storage variable lockedWeights[_tokens[i]]. Doing the intermediate calculations in the memory and writing them back to storage is more gas efficient.  12. GaugeFactory.updateReferrals  can  be  defined  as  external  along  its  input  parameters  as  calldata.  13. GaugeFactory.delay can be defined as constant, as its value never changes later.  14. GaugeFactory.STABLE  after  being  assigned  a  value  in  the  constructor  never  gets  modified.  Hence, it can be defined as immutable.  15. BaseV1Pair.permit  recalculates  DOMAIN_SEPARATOR  for  every  call.  It  makes  sense  as  a prevention mechanism against forks. The storage write could potentially be done only if the chain id changed.  16. BaseV1Pair defines an event named Claim. It is called only once with sender and recipient  holding the same address.  17. BaseV1Factory.constructor sets the storage variable isPaused to false, which is the default  value for any boolean values.  18. BaseV1Factory defines three storage variables _temp0, _temp1, and _temp. These variables are  used  solely  as  input  parameters  when  deploying  a  BaseV1Pair.  Instead  of  occupying  extra storage for these variables, they can easily be defined as input parameters to the BaseV1Pair.  19. The  modifier  BaseV1Pair.gasThrottle  can  be  implemented  more  optimised,  by  assigning maxGasPrice == 0 as should not throttle, which consequently removes the need to define state variable shouldGasThrottel in BaseV1Factory.    USDFI  has  correctly  addresses  most  of  the  aforementioned  gas  inefficiencies.  The  following inefficiencies are going to be reviewed later by USDFI:  1. GaugeFactory.divisor can be defined as constant. Its value is not later set during deployment  through constructor.  2. BaseV1Factory defines three storage variables _temp0, _temp1, and _temp. These variables are  used  solely  as  input  parameters  when  deploying  a  BaseV1Pair.  Instead  of  occupying  extra storage for these variables, they can easily be defined as input parameters to the BaseV1Pair.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.14   No NatSpec",
        "body": "  While documentation was provided, the individual functions are not documented in the code. It is highly recommended  to  at  least  describe  each  entry  point  with  descriptive  comments  (e.g.  NatSpec  for  all functions).  ISSUEIDPREFIX-021  USDFI - AMM, Gauges and Bribes -   20  InformationalVersion1CodeCorrected      \f  Comments have been added. However, no NatSpec was used.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.15   Referrals Default Values",
        "body": "  The  referralContract  by  default  is  the  0-address,  indicating  that  this  feature  is  deactivated. However, the code will revert if governance does not have a valid referral contract.  Further, if there is no mainRefFeeReceiver specified, the 0-address receives funds.  ISSUEIDPREFIX-010    Initial values need to be provided on construction now.  USDFI - AMM, Gauges and Bribes -   21  Version1CodeCorrected    \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Magic Values",
        "body": "  The use of magic numbers in the codebase is not recommended, they should be replaced by variables with a self-explanatory name. Examples are:  ISSUEIDPREFIX-005   The scaling factor 1e18   1000   10000   100000   50 (number of maximum iterations in Bribe.earned)  Code partially corrected:  Some of the numbers have been replaced by variables with a self-explanatory name.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Voting Twice per Epoch Possible",
        "body": "  poke() can be considered as a voting function. However, it ignores lastVote. Hence, it is technically possible to revote with the same allocations.  ISSUEIDPREFIX-006  Acknowledged:  USDFI has acknowledged this issue stating that:  This is by design since poke may be executed voluntarily at any time. Please note that re-poking and re-voting without acquiring more veTokens is only to the detriment of the user himself as the passage of time always reduces his voting power (veTokens) and is also costly  USDFI - AMM, Gauges and Bribes -   22  InformationalVersion1CodePartiallyCorrectedInformationalVersion1Acknowledged          \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   DOS Possibilities",
        "body": "  If governance adds to many gauges, preDistribute() may hit the gas limit. Additionally, users could vote for too many gauges so that they DOS themselves.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Deprecated Gauges May Have Locked",
        "body": " Rewards  The function preDistribute() considers the weight of the deprecated gauges for the total amount of votes. However, the distribute() function will never distribute such rewards. Hence, as long as there are  any  deprecated  gauges  with  remaining  votes,  tokens  will  be  locked  in  the  contract.  It  is  worth mentioning  that  this  is  required  since,  otherwise,  the  distribution  could  be  DOSed,  if  a  gauge  was resurrected between predistribution and distribution.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.3   Low Default Fee Value for LPs",
        "body": "  LPs should be aware that by default only 20% percent of the accrued fees will be allocated to them.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.4   Reward Mechanics",
        "body": "  An  LP  with  high  liquidity  may  provide  liquidity  to  gauges,  when  he  sees  a  high  rate.  Other  users,  who bribed the voters to receive rewards, may end up getting less profit compared to just receiving fees.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.5   Sandwiching",
        "body": "  Users  should  be  aware  that  sandwiching  swaps  is  possible  (similar  to  Uniswap  V2  like  pools).  As described  in  System  Overview,  users  should  use  helper  contracts  that  allow  specifying  slippage protection so that sandwich attacks are limited to some degree.  USDFI - AMM, Gauges and Bribes -   23  NoteVersion1NoteVersion1NoteVersion1NoteVersion1NoteVersion1                    \f8.6   What Should Happen With Voteless Bribes?  If a bribe is notified about a reward, it stores the reward for the next epoch. However, if no voter voted for the allocations, and hence did not receive bribe shares, no one will be able to claim the bribes. Note that it is assumed that at least a voter will cast a vote to claim the rewards. However, gas fees could be higher than the reward's value.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.7   distribute() Without preDistribute()",
        "body": "  When  a  gauge  is  added,  hasDistributed  for  the  LP  token  will  be  false.  Hence,  it  is  technically possible to distribute rewards without preDistribute(), although its reward will be zero.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.8   gasThrottle",
        "body": "  The gasThrottle modifier is applied to the swap() function to reduce the impact of front-running by specifying a maximum gas price an action should be able to have. However, such a mechanism brings certain risks. The following is an incomplete list of examples:  1. Gas price changes naturally and exceeds the maximum. Swaps can be broken temporarily until the  maximum price is updated.  2. It is still be possible to front-run users with mints so that the price is affected. Consider the example, in  which  only  one  LP  exists.  Minting  does  not  yield  a  loss  for  the  user  in  that  scenario  but  can change the price significantly.  3. Some  liquidators  may  want  to  exchange  the  liquidated  funds  against  the  repayment  currency  so that the profit in the repayment currency is guaranteed. Since liquidations are time-sensitive, higher gas prices are set. gasThrottle could make it undesirable for liquidators to use the exchange in such scenarios.  Further,  note  that  MEV  often  is  done  by  transferring  ETH  to  the  block  creator  directly.  Hence,  in  such cases the mechanism is ineffective.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.9   refLevelPercent Is Ended With 0 Elements",
        "body": "  Users should be aware that a zero element in refLevelPercent will break the fee distribution for the subsequent elements.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.10   rewardsPerToken() Can Return",
        "body": " rewardsPerEpoch  The  function  rewardsPerToken()  returns  the  ratio  of  the  rewards  and  the  supply  at  a  given  epoch number. However, if the total supply is zero, rewardsPerEpoch is returned.  USDFI - AMM, Gauges and Bribes -   24  NoteVersion1NoteVersion1NoteVersion1NoteVersion1NoteVersion1                  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Approximated Fee Charged in Debt Transfer",
        "body": "  In function vaultManager.getDebtOut, a fee is charged according to the different borrowFee and repayFee  between  two  vault  managers.  It  will  be  an  approximation  which  slightly  round  if  both borrowFee and repayFee are enabled.  We assume the borrowFee and repayFee are f1 and r1 on vaults A. And f1 and r1 for B as well. We assume f1<f2 and r1>r2. Then if a debt X is transferred from A to B, the following fee will be charged.  \u03b4fee = (f2 \u2212 f1) * X + (  \u2212 r2 (1 \u2212 r1)(1 \u2212 r2) )] * X > = (\u03b4f + \u03b4r) * X  1 \u2212 r2 ) * X  r1 1 \u2212 r1  r1 \u2212 r2  \u03b4fee = [(f2 \u2212 f1) + (  where  \u03b4f = f2 \u2212 f1 \u03b4r = r1 \u2212 r2  This is slightly larger than the formula used in the project given that both f and r are small:  \u03b4fee = (\u03b4f + \u03b4r \u2212 \u03b4r * \u03b4f) * X  Acknowledged  Angle replied:  It is possible that it slightly rounds down, overall we do not expect to have both fees taken up at the same time on the same vaultManager. And as we're aware that it's an approximation, fees should be set accordingly.  Angle - Angle Borrowing Module -   12  SecurityDesignCorrectnessCriticalHighMediumLowAcknowledgedAcknowledgedAcknowledgedAcknowledgedDesignLowVersion1Acknowledged            \f5.2   Ignored Return Value of _repayDebt  The  return  value  of  the  call  to  _repayDebt  in  the  function  VaultManager.liquidate  is  ignored, although it gives the correct amount of stable coins that need to be burned for the debt payment. Instead amounts[i] is used, as shown below:  if (vault.collateralAmount <= collateralReleased) {    ... } else {     ...     _repayDebt(         vaultIDs[i],         (amounts[i] * liquidationSurcharge) / BASE_PARAMS,         liqData.newInterestAccumulator     ); } ... liqData.stablecoinAmountToReceive += amounts[i];  Acknowledged  Angle replied:  The repayDebt function rounds down the stablecoin amount in the case where it is bigger than the total debt of the vault. In a liquidation setting, the amount in repayDebt is: 'amounts[i]*liquidationSurcharge / BASE_PARAMS' where 'amounts[i]<=maxStablecoinAmountToRepay' and 'maxStablecoinAmountToRepay <= debt of the vault + 1'. As such, in the worse scenario possible, the output value of the repayDebt function will very slightly be rounded down from what should theoretically be taken: we should therefore view this as a slightly higher fee taken by the protocol on the liquidation.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   Possible Gas Optimization in Mappings",
        "body": "  Several contracts of the system use mappings in the format: mapping(key_type => bool). Solidity uses a word  (256  bits)  for  each  stored  value  and  performs  some  additional  operations  when  operating  bool values  (due  to  masking).  Therefore,  using  uint  instead  of  bool  is  slightly  more  efficient.  A  list  of  such mappings:   isMinter in agToken.   vaultManagerMap in Treasury.   isWhitelisted and _operatorApprovals in VaultManagerStorage.  Acknowledged:  Angle - Angle Borrowing Module -   13  DesignLowVersion1AcknowledgedDesignLowVersion1Acknowledged                \fThe mappings vaultManagerMap, isWhitelisted and _operatorApprovals have been modified and now use uint256 instead of bool as pointed out above.  Only the mapping isMinter remains unchanged because the Angle has already deployed a version of the contract.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.4   Unchecked Collateral Amount",
        "body": "  In  the  contract  VaultManager,  when  a  user  calls  _addCollateral  or  _removeCollateral,  no checks are performed on the collateral amount. Hence, a vault can have an amount of collateral which is below the _dustCollateral parameter.  Acknowledged  Angle replied:  There is no need to check for the `_dustCollateral` parameter when people are adding or removing collateral from their vault. What is important is that people with a debt have an amount of collateral in their vault which is higher than `_dustCollateral` and this can be for sure implemented if `_dust` parameter is set accordingly with the `collateralFactor` parameter and the `_dustCollateral` parameter.  It is not a problem for the protocol if people decide to add collateral little by little or remove their collateral little by little if they are no longer in debt or their debt is small.  Angle - Angle Borrowing Module -   14  DesignLowVersion1Acknowledged          \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  1  0  3  16  -Severity Findings   Unchecked VaultManager Address   -Severity Findings  -Severity Findings  Inconsistent Access Control   Incorrect Accounting of Global Debt    Stuck Ether   -Severity Findings  Incomplete Specifications BaseReactor    Mismatch of Specifications in _repayDebt    Unclear Specifications for Swap Function   Incomplete Specifications   Inconsistent Error Message    Misleading Function Name    Mismatch of Specifications for Function _isSolvent    Missing Description of Variable Decimals    Missing Sanity Checks on Vault Creation    No Event Emitted on Flashloan's Parameters Update    Possible to Optimize Struct    Precision Loss in Division    Specification Mismatch in _handleRepay    Specification Mismatch setUint64    Unchecked Array Length    Unchecked VaultID When Adding Collateral   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Unchecked VaultManager Address",
        "body": "  The  fetchSurplusFromVaultManagers  the  contract treasury/Treasury.sol,  as  displayed  below,  input VaultManager  function can  address.  An  accrueInterestToTreasury  which  can  return  arbitrary  numbers  to  maliciously  update  the  state variables surplusBufferValue and badDebtValue.  is  no  check  a   function  of  towards   the  user  a   is  an  external   contract  with   adversary   function   deploy   there   Angle - Angle Borrowing Module -   15  CriticalCodeCorrectedHighMediumCodeCorrectedCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedSecurityCriticalVersion1CodeCorrected             \ffunction fetchSurplusFromVaultManagers(address[] memory vaultManagers) external returns (uint256, uint256) {     (uint256 surplusBufferValue, uint256 badDebtValue) = _fetchSurplusFromList(vaultManagers);     return _updateSurplusAndBadDebt(surplusBufferValue, badDebtValue); }  function _fetchSurplusFromList(address[] memory vaultManagers) internal returns (uint256 surplusBufferValue, uint256 badDebtValue) {     badDebtValue = badDebt;     surplusBufferValue = surplusBuffer;     uint256 newSurplus;     uint256 newBadDebt;     for (uint256 i = 0; i < vaultManagers.length; i++) {         (newSurplus, newBadDebt) = IVaultManager(vaultManagers[i]).accrueInterestToTreasury();         surplusBufferValue += newSurplus;         badDebtValue += newBadDebt;     } }    The  vulnerable  function  fetchSurplusFromVaultManagers  has  been  removed  from  the  updated code. Hence, the functionality to collect the surplus only from a subset of vault managers is not available anymore.  function fetchSurplusFromAll should be called.  the  surplus  accrued  by  all  VaultManager  contracts,   to  collect   In  order   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Inconsistent Access Control",
        "body": "  The setup of roles for the contract CoreBorrow is implemented in the function initialize. The admin of the GUARDIAN_ROLE is set to GUARDIAN_ROLE, which may lead to an exploit as a malicious guardian can  remove  all  governors  from  the  GUARDIAN_ROLE.  In  such  scenario,  the  functions  addGovernor, isGovernorOrGuardian, and all the functions in other contracts that call isGovernorOrGuardian with  a  governor  address  would  revert,  as  they  no  longer  have  the  GUARDIAN_ROLE,  and  thus  are  no longer the admin of the GUARDIAN_ROLE.  function initialize(address governor, address guardian) public initializer {     require(governor != address(0) && guardian != address(0), \"O\");     require(governor != guardian, \"12\");     _setupRole(GOVERNOR_ROLE, governor);     _setupRole(GUARDIAN_ROLE, guardian);     _setupRole(GUARDIAN_ROLE, governor);     _setRoleAdmin(GUARDIAN_ROLE, GUARDIAN_ROLE);     _setRoleAdmin(FLASHLOANER_TREASURY_ROLE, GOVERNOR_ROLE); }  function addGovernor(address governor) external {     grantRole(GOVERNOR_ROLE, governor);     grantRole(GUARDIAN_ROLE, governor); }  function isGovernorOrGuardian(address admin) external view returns (bool) {     return hasRole(GUARDIAN_ROLE, admin); }    The  issue  has  been  addressed  in  code  ,  the  governor  is  set  as  the  admin  of  the GUARDIAN_ROLE,  hence  a  guardian  cannot  change  anymore  the  roles  of  a  governor  address.  Angle - Angle Borrowing Module -   16  SecurityMediumVersion1CodeCorrectedVersion2        \fFurthermore, the function removeGovernor has been updated to allow a governor address to remove its roles, i.e., revoke its roles as guardian and then as governor.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Incorrect Accounting of Global Debt",
        "body": "  The following issue was reported by Angle during the review process. The function _closeVault in the contract VaultManager.sol does not update the global debt state variable totalNormalizedDebt.    The  function  _closeVault  has  been  revised  to  update  the  global  debt  state  when  a  vault  is  closed: totalNormalizedDebt -= vault.normalizedDebt;.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Stuck Ether",
        "body": "  The function angle in the contract VaultManager is declared as payable, however the code has no logic to deal with the incoming Ether. Therefore, the Ether sent when calling the function angle is not accounted and gets stuck into the contract.    The  keyword  payable  has  been  removed  from  the  function  VaultManager.angle,  hence  users cannot send Ether to the contract when calling this function.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Incomplete Specifications BaseReactor",
        "body": "  The parameter _protocolInterestShare in BaseReactor._initialize is missing the NatSpec description.    The NatSpec description has been added for the parameter _protocolInterestShare in the function _initialize.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Mismatch of Specifications in _repayDebt",
        "body": "  The function VaultManager._repayDebt will not revert on a non-existing vault, however the NatSpec comments assume that it will revert.  Angle - Angle Borrowing Module -   17  CorrectnessMediumVersion1CodeCorrectedSecurityMediumVersion1CodeCorrectedCorrectnessLowVersion2CodeCorrectedCorrectnessLowVersion2CodeCorrected                                \f/// @dev This function will revert if it's called on a vault that does not exist    The sentence above has been removed from the NatSpec of the function _repayDebt.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Unclear Specifications for Swap Function",
        "body": "  The NatSpec descriptions for parameters in ISwapper.swap are confusing, for example the parameter outTokenOwed has the following description:  @param outTokenOwed Minimum amount of outToken this address should have at the end of the call  It is unclear if this address refers to the contract Swap or to the recipient address.    The NatSpec description for the parameter outTokenOwed has been revised:  @param outTokenOwed Minimum amount of outToken the `outTokenRecipient` address should have at the end of the call.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   Incomplete Specifications",
        "body": "  Several  NatSpec  descriptions  non-exhaustive list:  for   the   function  parameters  are  not  complete.  We  provide  a   The description of `` data`` in VaultManager.liquidate.   supply in BaseReactor._convertToShares.   Return values in BaseReactor._getFutureDebtAndCF.  Specification changed:  The NatSpec descirptions have been added for the examples listed above:  /// @param data Data to pass to the repayment contract in case of... /// @param _supply Optional value of the total supply of the reactor, it is recomputed if zero /// @return futureStablecoinsInVault Future amount of stablecoins borrowed in the vault /// @return collateralFactor Collateral factor of the vault if its debt remains unchanged but `toWithdraw` collateral  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   Inconsistent Error Message",
        "body": "  Angle - Angle Borrowing Module -   18  CorrectnessLowVersion2CodeCorrectedCorrectnessLowVersion1Speci\ufb01cationChangedDesignLowVersion1CodeCorrected                        \fin  BaseAgTokenSideChain.sol  and The  error  codes  function setTreasury in BaseOracleChainlinkMulti.sol are inconsistent with the respective descriptions in errorMessages.json.  in  modifier  onlyTreasury   Furthermore,  most  of  the  contracts  use  numbers  as  error  messages,  and  the  file  errorMessages.json maps each error code to a meaningful description. However, in BaseReactor the following messages are used:  require((assets = _convertToAssets(shares, usedAssets + looseAssets, 0)) != 0, \"ZERO_ASSETS\"); require(currentAllowance >= shares, \"ERC20: transfer amount exceeds allowance\");    The error messages have been revised on the whole codebase and a new approach is used:  if(!condition) revert CustomErrorMessage();  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   Misleading Function Name",
        "body": "  In  contract  EulerReactor.sol,  the  function  name  _maxStablecoinsAvailable  does  not  match with  the  specifications  and  the  code,  which  returns  the  maximum  amount  of  assets  that  can  be withdrawn.    The function _maxStablecoinsAvailable has been renamed to _maxAmountWithdrawable, and the NatSpec description has been updated accordingly:  @return maxAmount Max amount of assets that can be withdrawn from the reactor  considering Euler liquidity for the stablecoin.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.11   Mismatch of Specifications for Function",
        "body": " _isSolvent  The NatSpec comment for the function VaultManager._isSolvent states:  /// @notice Verifies whether a given vault is solvent (i.e., should be liquidated or not) ... /// @dev If the oracle value or the interest rate accumulator has not been called at the time of the /// call, this function computes it  The first sentence above states that the function verifies if the vault is solvent, however the function does not verify the vault status, but only computes some parameters.  The second sentence above states that the function computes the interest rate accumulator if it has not been called before, however the implementation does not perform it.  Angle - Angle Borrowing Module -   19  CorrectnessLowVersion1CodeCorrectedCorrectnessLowVersion1Speci\ufb01cationChanged                \fSpecification changed:  The NatSpec descriptions have been revised to reflect the behavior of the function implementation:  /// @notice Computes the health factor of a given vault. This can later be used to check whether a given vault is solvent  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.12   Missing Description of Variable Decimals",
        "body": "  The  documentation  pages  state  that  the  codebase  generally  uses  three  bases:  BASE_TOKENS  (18 decimals),  BASE_PARAMS  (9  decimals)  and  BASE_INTEREST  (27  decimals).  However,  to  improve readability and integrations with other systems, the code would benefit from having a description of the expected base for each variable.  Specification changed:  The  NatSpec  descirption  for  VaultManagerStorage.BASE_PARAMS  states  that  unless  specified otherwise all the parameters are in 9 decimals:  /// @notice Base used for parameter computation: almost all the parameters of this contract are set in `BASE_PARAMS`  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.13   Missing Sanity Checks on Vault Creation",
        "body": "  The  function  VaultManager.angle  does  not  perform  any  sanity  check  on  vault  creation  for  the parameter to, which is the owner of the vault.    The  sanity  check  to  prevent  vaults  being  minted  to  address(0)  has  been  added  into  the  function VaultManagerERC721._mint:  if (to == address(0)) revert ZeroAddress();  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.14   No Event Emitted on Flashloan's Parameters",
        "body": " Update  The  function  FlashAngle.setFlashLoanParameters  updates  the  fee  and  the  maximum  amount that can be borrowed by the module; however, no event is emitted.  Angle - Angle Borrowing Module -   20  CorrectnessLowVersion1Speci\ufb01cationChangedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \f  The following event will be triggered every time the function is successfully called.  event FlashLoanParametersUpdated(IAgToken indexed stablecoin, uint64 _flashLoanFee, uint256 _maxBorrowable); ... emit FlashLoanParametersUpdated(stablecoin, _flashLoanFee, _maxBorrowable); ...  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.15   Possible to Optimize Struct",
        "body": "  The struct FlashAngle.StablecoinData can be optimized to occupy 2 storage slots instead of 3 if reordered.    The struct is reordered to occupy 2 storage slots.  struct StablecoinData {     uint256 maxBorrowable;     uint64 flashLoanFee;     address treasury; }  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.16   Precision Loss in Division",
        "body": "  This line below from the function _checkLiquidation of contract VaultManager.sol uses division, which is prone to rounding errors. In this case it is possible to use multiplication as needed to have both sides of the comparison operator in the same decimals instead of using division.  if (currentDebt <= (maxAmountToRepay * surcharge) / BASE_PARAMS + dust)    The updated code avoids the division operator and evaluates the condition as follows:  if (currentDebt * BASE_PARAMS <= maxAmountToRepay * surcharge + dust * BASE_PARAMS) {     ... }  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.17   Specification Mismatch in _handleRepay",
        "body": "  Angle - Angle Borrowing Module -   21  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedCorrectnessLowVersion1Speci\ufb01cationChanged                        \fThe NatSpec description for the parameter to in VaultManager._handleRepay states:  @param to Address to which stablecoins should be sent  However, the function only sends collateral tokens to the address to:  if (collateralAmountToGive > 0)     collateral.safeTransfer(to, collateralAmountToGive);  Specification changed:  The NatSpec comments has been updated:  @param to Address to which collateral should be sent  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.18   Specification Mismatch setUint64",
        "body": "  The  function  setUint64  in  the  contract  VaultManager.sol  is  protected  with  the  modifier onlyGovernorOrGuardian,  however,  it  says  When  setting  parameters governance should make sure .... The Angle team should assess and clarify the intended behaviour and update the specification or the modifier accordingly.  the  specification,   in   Specification changed:  The specification is changed to comply with the modifier:  /// @dev When setting parameters governance or the guardian should make sure that...  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.19   Unchecked Array Length",
        "body": "  The  function  angle  in  the  contract  VaultManager  does  not  check  if  the  input  arrays  actions  and datas have the same length and trigger an early revert if the input parameters do not match, thus be more gas efficient.    The  updated  code  performs  a  check  that  arrays  actions  and  datas  have  the  same  length. Furthermore, it also checks that the arrays have a non-zero length:  if (actions.length != datas.length || actions.length == 0)     revert IncompatibleLengths();  Angle - Angle Borrowing Module -   22  CorrectnessLowVersion1Speci\ufb01cationChangedDesignLowVersion1CodeCorrected                  \f6.20   Unchecked VaultID When Adding Collateral  The  function  angle  does  not  perform  any  check  to  verify  if  a  vault  exists  when  the  action  is addCollateral. The internal function _addCollateral also does not perform such checks, hence it is  possible  to  add  collateral  to  vaults  that  are  not  created  yet,  or  to  vaults  that  have  been  burned,  i.e., locking tokens.    The  function  _addCollateral  has  been  updated  to  check  if  the  collateral  is  being  added  into  an existing vault:  if (!_exists(vaultID)) revert NonexistentVault();  Angle - Angle Borrowing Module -   23  DesignLowVersion1CodeCorrected      \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Default VaultID Value",
        "body": "  The function angle in the contract vaultManager/VaultManager.sol will use the latest vaultID if the action's parameter vaultID is 0. Users should be aware of this default behavior and be careful to use vaultID = 0 only when the first action of a batch operations is createVault.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Dependency on Freshness of Chainlink Oracle",
        "body": " Prices  The  Angle  Borrowing  Module  queries  Chainlink  oracles  to  get  the  price  of  an  asset  and  the  function _readChainlinkFeed performs the following sanity checks:  (uint80 roundId, int256 ratio, , uint256 updatedAt, uint80 answeredInRound)     = feed.latestRoundData(); if (ratio <= 0     || roundId > answeredInRound     || block.timestamp - updatedAt > stalePeriod)         revert InvalidChainlinkRate();  If the price is carried over from an old round (answeredInRound < roundID), or the price is outdated (block.timestamp  -  updatedAt  >  stalePeriod),  then  the  function  reverts.  Therefore,  actions that  query  oracles  cannot  be  executed  if  the  returned  price  do  not  pass  the  sanity  checks,  e.g., closeVault,  removeCollateral,  borrow,  getDebtIn,  liquidate.  This  might  become problematic for the system if Chainlink oracles stop working at any point in future for collateral assets.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Event MinterToggled Can Be Emitted Multiple",
        "body": " Times  In  contract  AgToken.sol,  MinterToggled event without checking if the minter has already been added or removed.  functions  addMinter  and  removeMinter  will  always  emit  a  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   Inconsistency Between Debt and Issued",
        "body": " Stable Coins  Angle - Angle Borrowing Module -   24  NoteVersion1NoteVersion1NoteVersion1NoteVersion1              \fWhen a user wants to transfer debt from VaultManager B to VaultManager A, the function angle in the contract  VaultManager.sol  does  not  check  if  VaultManager  B  is  a  valid  VaultManager.  If  a  user deploys a contract with the VaultManager interface and set its address as B, then the debt of the user increases without issuing any stable coins.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   Repay Fee Calculation",
        "body": "  The repay fee in the function VaultManager.angle is calculated with the following code:  uint256 stablecoinAmountPlusRepayFee = (stablecoinAmount * BASE_PARAMS) / (BASE_PARAMS - repayFee);  If  the  user  wants  to  repay  100  USDC  when  the  repay  fee  is  3%,  the  formula  above  will  calculate ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "103.0927835052 USDC as the total amount needed to be repaid.",
        "body": "  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.6   System Inconsistency",
        "body": "  In contract AgToken.sol, functions burnNoRedeem and burnFromNoRedeem burn the stable tokens and  interact  with  IStableMaster  which  is  not  part  of  the  borrowing  module  reviewed  in  this  audit. Users of the borrowing module have no incentive to call these functions.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.7   Unbounded Loops in Treasury Contract",
        "body": "  Functions  setTreasury,  _fetchSurplusFromList  and  removeVaultManager  loop  through  the array vaultManagerList. However, there are no bounds on the size of the array, which means there is a possibility that the transaction exceeds the block gas limit. In those cases, the transaction will revert. Hence, the governance should ensure that the number of entries in vaultManagerList is limited so the transaction cost remains under the block gas limit.  Angle - Angle Borrowing Module -   25  NoteVersion2NoteVersion1NoteVersion2            \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   execute() Gas Calculation Can Underflow",
        "body": "  In  AccountImplementation,  execute()  subtracts  5000  from  gas()  using  assembly  subtraction.  If gas() is less than 5000, this will underflow and wrap around to a very high value.  The solidity overflow checks are disabled when using assembly, so this will not revert.  Risk accepted  Oasis accepts the risk of this underflow occurring and states that under normal use this will not happen, as the proxy is intended for state-changing operations and hence the delegate call should never cost less than 5000 gas to execute.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Inefficient Boolean Mappings",
        "body": "  The AccountGuard has the following mappings:  mapping(address => mapping(address => bool)) private allowed; mapping(address => mapping(bool => bool)) private whitelisted;  Oasis - PositionManager -   10  DesignCorrectnessCriticalHighMediumRiskAcceptedLowCodePartiallyCorrectedAcknowledgedAcknowledgedCodePartiallyCorrectedAcknowledgedCodePartiallyCorrectedRiskAcceptedCodePartiallyCorrectedAcknowledgedCorrectnessMediumVersion1RiskAcceptedDesignLowVersion2CodePartiallyCorrectedAcknowledged                              \fMappings  that  contain  boolean  variables  are  inefficient  in  general,  as  the  Solidity  compiler  masks  the values when saving and loading these values from storage to prevent dirty bits from contaminating the values.  For  the  whitelisted  mapping,  there  is  a  superfluous  level  of  indirection.  The  (bool  =>  bool) mapping  could  be  replaced  by  a  different  type,  e.g.  an  enum  or  an  integer,  which  would  reduce  the number of SLOADs needed to retrieve an entry. Alternatively, two separate mappings could be used for the two whitelists.  Code partially corrected  The  type  of  the  whitelisted  mapping  was  changed  to  mapping(address  =>  uint8).  The allowed mapping was not modified.  Acknowledged  Note that reading and writing uint8 and bool values to and from storage results in inefficient bytecode, as the Solidity compiler masks the values to ensure no dirty bits are propagated. As there is no possibility of  writing  to  arbitrary  storage  locations,  these  checks  are  superfluous.  Using  mappings  that  store  the uint256 type eliminates these checks. Oasis has acknowledged this inefficiency.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   External Calls Could Be Avoided",
        "body": "  In  the  EVM,  external  calls  to  other  contracts  cost  more  gas  than  internal  calls  to  a  contract's  own functions.  The  AccountFactory  makes  external  calls  to  AccountGuard.  Both  contracts  are  dependent  on  one another - they need to know each other's addresses in order to set the owners of newly created proxies. This introduces a circular dependency.  As neither contract is upgradeable and neither contract allows setting a new address for the other, the increased gas cost and circular dependency could be avoided by combining both contracts' functions into a single contract. This also allows for the removal of some storage variables.  Acknowledged  Oasis has acknowledged the issue.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.4   Function Arguments Can Be In Calldata",
        "body": "  bytes   The  AccountImplementation.execute() can be in calldata instead of memory in order to save gas.  AccountImplementation.send()   arguments   memory   _data   in   and  Code partially corrected  The _data argument of the send() function was changed to bytes calldata.  Acknowledged  For execute(), Oasis acknowledged the issue and decided not to make code changes.  Oasis - PositionManager -   11  DesignLowVersion1AcknowledgedDesignLowVersion1CodePartiallyCorrectedAcknowledged                  \f5.5   Inefficiencies in execute()  The execute() function in AccountImplementation has multiple inefficiencies:   Only gas() - 5000 gas is passed to the delegate call. This may force users to attach more gas than  needed  to  their  calls.  While  it  does  guarantee  that  the  remaining  operations  after  the delegatecall  will  complete,  it  also  makes  it  more  likely  for  the  delegatecall  to  run  out  of  gas.  It  is simpler to just attach all the gas to the call and assume it returns before consuming all the gas.   execute() only returns 32 bytes of return data from the delegate call. If any contract that is called  returns more than 32 bytes of data, it will be lost.   The return data is not directly returned in the assembly block, but by the function itself. This means that  it  will  be  copied  before  returning,  which  expands  the  memory  and  costs  more  gas.  Instead,  it could be directly returned in the assembly block using a return call.   The switch condition can be changed to succeeded instead of iszero(succeeded). There is no  reason to invert the condition.  For  an  example  implementation  of  a  similar  function,  see  the  _delegate  function  in  OpenZeppelin's Proxy  contract.  It  allows  returning  more  than  32  bytes  of  data.  Note  that  its  functionality  may  not  be completely identical, so the code should not be directly copied.  Code partially corrected  The  return  data  is  now  directly  returned  in  the  assembly  block.  Additionally,  the  switch  condition  was changed to succeeded, eliminating the extra iszero operation.  The newly introduced line returndatacopy(0, 0, returndatasize()) is used to copy the revert data to memory in case of failure. It is redundant in the success case, as the delegatecall already copies the  first  word  of  returndata  to  memory.  If  the  delegate  call  returns  more  than  32  bytes  of  data,  it  will expand the memory unnecessarily.  Risk accepted  Oasis accepts the risks regarding users being forced to attach too much gas to their calls, and only being able  to  return  the  first  32  bytes  of  return  data.  These  issues  may  reduce  the  ways  in  which  users  can interact with the proxy contract.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.6   Various Event Issues",
        "body": "  Some event parameters are not indexed, even though they might be useful for filtering events.   AccountFactory: The AccountCreated event does not have an indexed proxy address.   AccountGuard: The OwnershipTransfered event does not have an indexed newOwner address.  The  OwnershipTransfered  event  is  very  similarly  named  to  the  OwnershipTransferred  event  which  it inherits from OpenZeppelin's Ownable contract. Consider renaming it so that these two events cannot be confused.  Lastly, the vaultId parameter of the AccountCreated event is confusingly named, as there is no other place in the code which refers to vaults. Renaming this to a more suitable description of the parameter should be considered.  Oasis - PositionManager -   12  DesignLowVersion1CodePartiallyCorrectedRiskAcceptedDesignLowVersion1CodePartiallyCorrectedAcknowledged                    \fCode partially corrected  The indexed keyword has been added to the addresses in the mentioned events.  OwnershipTransfered has been renamed to ProxyOwnershipTransfered.  Acknowledged  The vaultId parameter name is unchanged. The ProxyOwnershipTransfered event has a misspelling, it should be ProxyOwnershipTransferred.  Oasis - PositionManager -   13    \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  0  1  1  12  -Severity Findings  -Severity Findings  ImmutableProxy Is Unnecessary   -Severity Findings   New Owner Cannot Permit   -Severity Findings   AccountGuard Variable Could Be Immutable    Checking Conditions in AccountImplementation    Execute Does Not Forward Revert Reason    Floating Compiler and Dependency Versions    Function Visibility Can Save Gas   Incorrect Error Messages   Increment Can Be Done in Event to Save Gas    Missing Sanity Checks    Redundant Initializations    Separate Whitelists    Unnecessary Checks    Unused Imports   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   ImmutableProxy Is Unnecessary",
        "body": "  The  ImmutableProxy  is  designed  as  a  small  proxy  contract  which  delegatecalls  into  a  fixed implementation  address.  Except  for  the  implementation()  getter,  its  functionality  is  identical  to  the minimal proxy contract described in EIP1167.  OpenZeppelin's Clones library, which is used to deploy clones of the ImmutableProxy contract, deploys clones by using the contract described in EIP1167 - so it simply deploys a contract which delegatecalls the target contract. All in all, this means that we have a minimal proxy, which calls the ImmutableProxy, which then calls the AccountImplementation. This double proxy setup is unnecessary and wastes gas.  Instead, it would be much simpler and cheaper to directly clone the AccountImplementation and discard the ImmutableProxy contract. The minimal proxy contract is hand-written bytecode which is designed to be as cheap as possible both to deploy and execute.  Oasis - PositionManager -   14  CriticalHighCodeCorrectedMediumCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedDesignHighVersion1CodeCorrected           \fCode corrected  The  ImmutableProxy  contract  was  removed.  Instead,  the  Clones  library  is  used  to  directly  clone  the AccountImplementation.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   New Owner Cannot Permit",
        "body": "  In  AccountGuard,  when  an  owner  is  initially  set  by  the  factory  they  also  receive  an  entry  in  the allowed[caller][target] mapping. However, when changeOwner() is called, the new owner only receives  an  entry  in  the  owners  mapping  but  is  not  added  to  the  allowed  mapping.  Hence,  the  new owner cannot call permit on the proxy they now own.  Note  that  not  even  someone  else  who  is  allowed  to  permit  on  the  proxy  can  admit  the  owner,  as permitting the owner will revert with \"account-guard/cant-deny-owner\". The only way to allow the new owner would be to transfer ownership to someone else who is already allowed to permit.  The owner would still be able to make transactions from the proxy, as canCall() always returns true for the owner, even if they are not allowed.  Code corrected  changeOwner now adds the new owner to the allowed addresses.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   AccountGuard Variable Could Be Immutable",
        "body": "  In  AccountFactory,  the  AccountGuard  variable  is  set  in  the  constructor  and  then  never  changed.  It could be made immutable to be more gas-efficient.  Code corrected  The variable has been made immutable.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Checking Conditions in",
        "body": " AccountImplementation  When calling send() or execute() in the AccountImplementation, the following checks are performed:  1. First, the auth modifier checks that guard.canCall(address(this), msg.sender) returns  true.  2. Next, it is checked that _target != address(0).  3. Lastly, the condition guard.isWhitelisted(_target) is checked.  Here, the AccountGuard contract is called twice to check whether the call should be allowed. These calls could be combined into a single cross-contract call to reduce gas costs.  Assuming that address(0) is never whitelisted, the second check is redundant.  Oasis - PositionManager -   15  CorrectnessMediumVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \fNote  also  that  the  same  conditions  are  checked  in  both  cases,  hence  they  could  be  included  into  the auth modifier in order to reduce code duplication.  Code corrected  The  calls  to  AccountGuard  were  combined  into  a  single  call  of  the  new  canCallAndWhitelisted function and moved into the auth modifier. The _target != address(0) check was removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Execute Does Not Forward Revert Reason",
        "body": "  In AccountImplementation, execute() reverts with (0,0) if the delegatecall fails. It does not revert with the revert reason from the delegatecall.  It would be easier for users to debug their reverted transactions if the revert reason contained information from the delegatecall.  Code corrected  The return data is now copied and returned. If the delegatecall fails, the revert reason will be returned.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Floating Compiler and Dependency Versions",
        "body": "  Oasis  uses  the  floating  pragma  solidity  ^0.8.9.  Contracts  should  be  deployed  with  the  same compiler  version  and  flags  that  have  been  used  during  testing  and  audit.  Locking  the  pragma  helps  to ensure that contracts do not accidentally get deployed using, for example, an outdated compiler version negatively that  (https://github.com/SmartContractSecurity/SWC-registry/blob/b408709/entries/SWC-103.md).  introduce   contract   system   affect   might   bugs   that   the   In hardhat.config.ts, the compiler version 0.8.17 is specified.  The versions of the contract libraries in package.json are also not fixed. In particular:  \"@openzeppelin/contracts\": \"^4.7.3\"  The caret ^version will accept all future minor and patch versions while fixing the major version. With new versions being pushed to the dependency registry, the compiled smart contracts can change. This may lead to incompatibilities with older compiled contracts. If the imported and parent contracts change the  storage  slot  order  or  change  the  parameter  order,  the  child  contracts  might  have  different  storage slots or different interfaces due to inheritance.  In addition, this can lead to issues when trying to recreate the exact bytecode.  Code corrected  The Solidity compiler version has been specified as exactly 0.8.17 for all contracts in scope.  The OpenZeppelin version has been specified as exactly version 4.7.3 in package.json.  Oasis - PositionManager -   16  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                  \f6.7   Function Visibility Can Save Gas  Reducing a function's visibility from public to external saves gas. The following functions could be defined as external:   AccountFactory.createAccount()   AccountGuard.isWhitelisted()   AccountGuard.setWhitelist()   AccountGuard.initializeFactory()   AccountImplementation.send()   AccountImplementation.execute()   MakerMigrationsActions.migrateMaker()   MakerMigrationsActions.migrateAdditionalVaults()   McdView.getRatio()   McdView.getMakerProxy()  Additionally, the self storage variable in MakerMigrationsActions should not be public, as it only contains the address of the contract itself. Hence, making it private or internal reduces bytecode size as the getter is unnecessary.  Code corrected  The  mentioned  functions  in  AccountGuard,  AccountFactory,  and  AccountImplementation  have  been changed  to  external.  The  visibility  of  the  self  storage  variable  in  MakerMigrationsActions  was changed to private.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   Incorrect Error Messages",
        "body": "  The auth modifier in AccountImplementation and the permit() function in AccountGuard both revert with the error message \"account-guard/not-owner\".  However, the owner is actually not the only user that is checked for. In both cases, it is checked whether the msg.sender is the owner OR has been permitted. The error message makes it seem like only the owner is allowed to use these functions.  Also,  migrateAdditionalVaults  the  message \"factory/already-migrated\"  in  case  it  is  called  from  an  address  that  has  not  yet  migrated.  This  error message states the opposite of what actually happened.  in  MakerMigrationsActions   reverts  with   Code corrected  permit()   The  with \"account-guard/no-permit\".  The  revert  message  in  migrateAdditionalVaults  was  also changed.  authandWhitelisted  modifier   function   revert   now   and   Oasis - PositionManager -   17  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \f6.9   Increment Can Be Done in Event to Save Gas  In  AccountFactory,  createAccount()  increments  the  accountGlobalCounter  variable.  Later,  it  is emitted in the AccountCreated event. This means it must be loaded from storage twice.  The  accountGlobalCounter  could  be  cached  or  incremented  in  the  event  emission,  which  would save one SLOAD operation and be more gas-efficient.  Code corrected  The value of the counter is now cached after being incremented.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   Missing Sanity Checks",
        "body": "  Sanity checks on values are missing in several places. This makes it more likely for incorrect values to accidentally be set.  In  AccountFactory.createAccount(address  user),  address(0).  it   is  possible   for  user   to  be  In  AccountGuard.changeOwner(address  newOwner,  address  target),  it  is  possible  for newOwner to be address(0).  In the AccountImplementation constructor, _guard could be address(0).  In the MakerMigrationsActions constructor, _serviceRegistry could be address(0).  Code corrected  Sanity checks have been added to all mentioned functions.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.11   Redundant Initializations",
        "body": "  Some storage variables are initialized to their default values, which is redundant and wastes gas.  In the AccountFactory constructor, accountsGlobalCounter is initialized to 0.  In AccountGuard, factory is initialized to address(0).  Code corrected  Both redundant initializations were removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.12   Separate Whitelists",
        "body": "  Oasis - PositionManager -   18  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                                    \fThe AccountImplementation allows calls and delegatecalls to any whitelisted contracts. Currently, there is just one whitelist for both cases. However, there may be some contracts that are safe to call but not delegatecall or vice versa.  Code corrected  The  whitelisted  mapping  of  the  AccountGuard  now  contains  a  (bool  =>  bool)  mapping.  This extra bool lookup parameter allows specifying whether a specific address is whitelisted for regular calls, delegatecalls, or both.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.13   Unnecessary Checks",
        "body": "  permit() in AccountGuard has the following check:  if (msg.sender == factory && allowance)  The AccountFactory only has one function that calls permit(). It always calls it with allowance set to true. Hence, just checking for msg.sender == factory is equivalent, as allowance is always true if this holds (unless AccountFactory is changed in the future).  There  are  also  unnecessary  checks  in  send()  and  execute()  in  AccountImplementation,  which  are described in Checking Conditions in AccountImplementation.  These checks can be removed to save gas.  Code corrected  The check for allowance has been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.14   Unused Imports",
        "body": "  There are several imported files which are never used:  In AccountFactory:   \"./interfaces/IProxyRegistry.sol\"   \"./interfaces/ManagerLike.sol\"   \"./interfaces/IServiceRegistry.sol\"   \"./utils/Constants.sol\" (AccountFactory inherits from it but no values are used)  In AccountGuard:   \"@openzeppelin/contracts/proxy/Proxy.sol\"  Code corrected  The unused imports were removed.  Oasis - PositionManager -   19  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Permissions Stay When Changing Owner",
        "body": "  When  the  changeOwner()  function  of  AccountGuard  is  called,  the  permissions  of  the  old  owner  are revoked.  However,  the  permissions  of  all  other  addresses  are  unaffected.  Any  addresses  that  were permitted by the old owner will still have permissions unless the new owner calls permit() to remove them.  Anyone receiving ownership over a proxy should ensure they trust all permitted addresses before using it.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Proxy Storage Layout",
        "body": "  The  AccountImplementation  allows  delegatecalls  into  arbitrary  whitelisted  contracts.  Such  a  contract could read/write to storage. If two different contracts are delegatecalled that both use the same storage slots, they may conflict with each other and read data written by the other contract.  The AccountGuard owner should keep this in mind when whitelisting contracts. They should either not whitelist  conflicting  contracts  or  explicitly  warn  users  not  to  use  multiple  contracts  that  use  the  same storage from the same proxy.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   send Function Name Is Confusing",
        "body": "  The send function of AccountImplementation has a lot more functionality than just sending ETH. It can be used to call arbitrary functions on any whitelisted contract.  This is not obvious from the function name and could be confusing to users.  Oasis - PositionManager -   20  NoteVersion1NoteVersion1NoteVersion1          \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Wrong Chainlog Identifiers",
        "body": "  UniV2PoolMigratorInit.init()  retrieves  the  DaiNst  and  MkrNgt  addresses  from  the  chainlog the following way:  CS-UV2M-001  DaiNstLike daiNst = DaiNstLike(dss.chainlog.getAddress(\"DAINST\")); MkrNgtLike mkrNgt = MkrNgtLike(dss.chainlog.getAddress(\"MKRNGT\"));  The  correct  strings  (as  set  by  the  corresponding  deployment  scripts),  however,  are  \"DAI_NST\"  and \"MKR_NGT\" respectively.    Labels DAINST and MKRNGT have been replaced with the correct ones: DAI_NST and MKR_NGT.  MakerDAO - UniV2 Migration -   10  CriticalHighMediumLowCodeCorrectedCorrectnessLowVersion1CodeCorrected        \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Note on the Safety of Uniswap Operations",
        "body": "  Two  main  considerations  have  been  made  when  assessing  the  security  of  the  script's  Uniswap operations with regard to potential unwanted value extraction by adversaries.  1. Let's consider a Uniswap V2 pool with token amounts   , and we split it into two pools with amounts ,   amount   and   . This is equivalent to creating two smaller pools at the original price    in any combination in the two pools is at most equal to the amount   as  happens  when  removing  liquidity  and  creating  a  new  pool  with  that  liquidity.  Then,  the  obtained by trading an amount  obtained when trading  returns the output amount when trading   as can be seen from its pool, with  .  This  shows  that  splitting  a  big 0  derivative  in  that  point  and  its  negative  second  derivative  over  pool  into  two  smaller  pools,  as  the  script  does,  does  not  expose  value  that  can  be  extracted  by back-running.   in the  , and observing that the function is at a maximum when    in the original pool. This can be seen by examining the function    pool and    in the   , which  2.  When  presented  with  a  pool  with  amounts  obtained  by  trading    in  the  first  pool,  then  shows  that  when  replacing  a  token  with  a  scaled  version,  such  as  MKR  and  NGT,  the  Uniswap operations safely scale in the same way.    is   in  the  second  pool.  This    and  another  pool  with  amounts     is  obtained  by  trading   ,  if   In conjunction, these considerations make it so that:  1. no extractable value is exposed when splitting the pool (removing liquidity and creating a new pool)  without slippage checks.  2. no extractable value is exposed when converting the MKR tokens to NGT for the new pool.  MakerDAO - UniV2 Migration -   11  NoteVersion1  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Cure.cage() Might Block Shutdown Procedure",
        "body": "  The cage function of the Cure contract, when called, requires that live is 1 and sets it to 0 :  function cage() external auth {     require(live == 1, \"Cure/not-live\");     live = 0;     /*...*/ }  The function is meant to be called from the End contract :  function cage() external auth {     /*...*/     cure.cage();     /*...*/ }  If an authorized user (the Governance) were to call the cage function of the Cure contract before the End  contract,  then  live  would  be  0,  therefore  the  call  to  cage  would  revert,  effectively  blocking  the shutdown process.  Risk Accepted:  MakerDAO states:  We accept this risk as it is, and actually exists in other modules such as the Vow. We understand each governance action might have important consequences. Each spell needs to be carefully evaluated.  MakerDAO - DSS Cure -   9  DesignCriticalHighMediumRiskAcceptedLowAcknowledgedDesignMediumVersion1RiskAccepted         \f5.2   Possible Optimizations  When using a uint256 as a boolean value, it is more efficient to check if it is non-zero than to check if it is equal to 1. Both the auth modifier and the liveness checks can be optimized in order to reduce gas costs and bytecode size.  The auth modifier could be implemented as follows:  modifier auth {     require(wards[msg.sender] != 0, \"Cure/not-authorized\");     _; }  The liveness could be checked like this:  require(live != 0, \"Cure/not-live\");  In total these changes reduce the bytecode size by 36 bytes and the cost of each check by 6 gas.  Acknowledged:  Rather than prioritizing minimal gas optimization Maker prefers to follow the standard of how things have been done before.  MakerDAO - DSS Cure -   10  DesignLowVersion1Acknowledged        \f6   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Delete Amt[Src] in Drop Function Is Useless",
        "body": "  In  the  drop  function,  the  entry  in  the  mapping  amt  that  corresponds  to  the  source  that  is  removed  is deleted :  function drop(address src) external auth {     /*...*/     delete amt[src];     /*...*/ }  This function can only be executed when the Cure contract is live :  function drop(address src) external auth {     require(live == 1, \"Cure/not-live\");     /*...*/ }  On  the  other  hand,  the  amt  mapping  can  only  be  updated  in  the  load  function,  which  can  only  be executed when the Cure contract has been caged :  function load(address src) external {     require(live == 0, \"Cure/still-live\");     /*...*/     uint256 newAmt_ = amt[src] = SourceLike(src).cure();     /*...*/ }  Since the Cure contract cannot become live again after it has been caged, the amt mapping cannot be non zero during a call to drop, thus it is useless to remove the entry.  MakerDAO - DSS Cure -   11  NoteVersion1  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Disable Borrowing",
        "body": "  CS-SKW-002  The main intention of Kill Switch is to put SparkLend into a lockdown mode preventing further borrowing but still allow users to top up collateral and repay/withdraw. While this can be achieved with the current design  setting  LTV  to  zero  for  assets  being  used  as  collateral  and  freezing  borrow  only  assets, SparkLend  offers  a  more  direct  way  to  achieve  this  by  simply  using  setBorrowEnable()  to  disable borrowing for each asset.  Compared to setting LTV for each collateral to zero the differences are:  ValidationLogic.validateAutomaticUseAsCollateral will return false in case LTV=0 since ValidationLogic.validateUseAsCollateral will return the same. This has effects in for example SupplyLogic.executeSupply.  Namely,  if  isFirstSupply  is  true,  the  newly  supplied  token cannot be used as collateral. Hence, top ups can only be done with used collateral tokens. In contrast, setBorrowingEnabled(asset, false) does not have this behaviour and allows for topups where the collateral token is new for the user.    setBorrowEnable() is now used.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Pending Governance Spells",
        "body": "  The  KillSwitchOracle  iterates  over  all  markets  to  perform  the  required  operations  to  disable borrowing. However, in case governance has plotted a plan in the DSPause e.g. to add a new asset to the Sparklend lending market or to change the LTV of an existing asset, a market could be activated after  CS-SKW-003  Sparklend - Kill Switch -   10  CriticalHighMediumCodeCorrectedLowCodeCorrectedSpeci\ufb01cationChangedDesignMediumVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \fthe trigger has been called due to the permissionless DSPause.exec() function. Ultimately, borrowing for such an asset could be enabled.  Governance should be aware that such scenarios could occur.    The code has been adjusted so that trigger() can be called repeatedly as long as reset() has not been called.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Specification Mismatch",
        "body": "  CS-SKW-001  The README specifies the following:  [...] anyone can permissionlessly trigger to set SparkLend into lockdown mode in which all collateral assets have their LTVs set to 0 and all borrowable assets are frozen. [...]  However, note that not all borrowable assets are frozen but only the borrow-only assets are frozen (also documented in the comments in code).  The NatSpec description of function reset() incorrectly states:  Resets the contract, clearing all set oracles and thresholds  The implementation of reset() only resets the contract.  Specification changed:  1. The specification now specifies that:  [...] lockdown mode [...] prevents new borrows on all assets.  which is consistent with the changes implemented in   .  2. The NatSpec of reset() was corrected and now reads:  Resets the trigger, allowing the kill switch to be triggered again.  Sparklend - Kill Switch -   11  CorrectnessLowVersion1Speci\ufb01cationChangedVersion2        \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   No Functionality to Recover From Bridge",
        "body": " Failure  CS-ZCHF-002  The documentation states:  \"In order to protect the Frankencoin from a crash of the connected stablecoins,     the bridge contract is limited in time and volume.\"  However, there is no functionality to recover from such a situation.  Suppose  there  are  10  million  Frankencoin  minted  in  total.  3  million  of  them  are  equity.  1  million  were minted through the stablecoin bridge.  Now  the  other  stablecoin  loses  peg  and  becomes  worthless.  So  there  is  no  value  in  burning  any Frankencoin using the bridge. There is more than enough equity in the Equity contract to cover the loss, but there is no mechanism to update the accounting such that the Equity can take the loss. Governance cannot vote to burn 1 million ZCHF that are in equity. There would be 1 million \"unbacked\" Frankencoins in circulation, with no way of changing the accounting so that they are backed again.  Frankencoin - Frankencoin -   13  SecurityDesignCorrectnessCriticalHighRiskAcceptedMediumRiskAcceptedLowRiskAcceptedRiskAcceptedAcknowledgedSpeci\ufb01cationPartiallyChangedAcknowledgedDesignHighVersion1RiskAccepted           \fThis  should  cause  Frankencoin  to  depeg,  falling  below  a  price  of  1  CHF,  even  though  the  loss  in  the bridge was relatively small and could be covered by equity.  Risk accepted:  Frankencoin understands and accepts the risk.  Frankencoin responded:  The purpose of the StablecoinBridge is to help with bootstrapping the system. In the long run, we would provide swap facilities on decentralized exchanges along the following lines: https://github.com/Frankencoin-ZCHF/FrankenCoin/issues/10  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Restructuring Equity Shares Does Not",
        "body": " Enforce Payment  In case the system suffers losses and its equity goes below MINIMUM_EQUITY (1000 ZCHF), any user with at least 3% of the voting power should be able to receive 100% of the equity shares if they pay for the losses.  For  that,  the  function  restructureCapTable  allows  the  caller  to  wipe  equity  shares  for  any address.  As  noted  in  restructureCapTable  May  Take  Multiple  Blocks,  depending  on  the  number  of shareholders, restructureCapTable can take more than one block to complete.  The function does not enforce that the surviving FPS shareholder actually pays for the losses. Therefore, it  is  possible  that  a  user  with  3%  of  the  voting  power  calls  restructureCapTable  quickly  to  remove other shareholders but do not bootstrap the system as expected by paying for the losses.  CS-ZCHF-009  Risk accepted:  Frankencoin is aware about this behavior of the restructuring functionality but has decided to keep the code unchanged given that pool shares do not have any value when restructuring conditions are met.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   Challenge Can Leave Dust Amount",
        "body": "  When a challenge is started, it is checked that the challenged amount is larger than minCollateral.  However, the amount remaining in the position is not considered. The challenge could be for an amount that leaves a dust amount of collateral in the position after the challenge is successful. If the dust amount is not worth the gas of holding an auction, it won't be liquidated.  Having unliquidated dust collateral can lead to small losses for the system.  CS-ZCHF-033  Risk accepted:  Frankencoin is aware of this issue but has decided to keep the respective code unchanged.  Frankencoin - Frankencoin -   14  DesignMediumVersion1RiskAcceptedDesignLowVersion3RiskAccepted                  \f5.4   Rounding Error in _calculatePrice  The  function  _calculatePrice  in  MintingHub  performs  a  division  before  multiplication  which introduces a rounding error:  CS-ZCHF-040  return (liqPrice / phase2) * timeLeft;  The rounding error is in favor of the bidder against the position's owner or the system (equity pays slightly more if the position causes a loss).  Risk accepted:  Frankencoin is aware of this issue but has decided to keep the function unchanged.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.5   Cloned Positions Can Have Arbitrary",
        "body": " Expiration  CS-ZCHF-006  MintingHub implements two functions for cloning a position:  - function clonePosition(address position, uint256 _initialCollateral,     uint256 _initialMint) public returns (address);  - function clonePosition(address position, uint256 _initialCollateral,     uint256 _initialMint, uint256 expiration) public returns (address);  The second function takes expiration as a user input and does not perform any check if it is in the future. The function reduceLimitForClone enforces that expiration of the clone is between start and expiration of the original position. However, one can still create a clone that has expiration in the past if current timestamp has passed start of the original timestamp.  The  position  will  be  able  to  mint  tokens  in  the  initializeClone  function  even  though  it  is  expired, circumventing the alive check, hence minting ZCHF from an expired position.  Acknowledged:  Frankencoin is aware of the possibility to clone positions that are expired at creation time but considers it to be an expected behavior.  In  , a clone of a position can have an expiry that is at most the expiry of the original position that was created. In particular, if cloning reduces the expiry but then that cloned position is cloned again, the expiry of the second clone can be equal to the original position.  Frankencoin - Frankencoin -   15  CorrectnessLowVersion3RiskAcceptedDesignLowVersion1AcknowledgedVersion3                \f5.6   Mismatch of Natspec With Implementation in ERC20  CS-ZCHF-012  The natspec of the function approve states:  - `spender` cannot be the zero address.  This  restriction  is  not  implemented  in  the  function  approve  and  it  is  possible  to  call  the  function  with spender being the zero address.  Similar  statements  are  present  in  natspec  comments  of  functions  _approve,  and  _burn  but  the respective checks are not implemented.  Specification partially changed:  The stated restrictions have been removed from the natspec of _burn() and _approve().  The natspec for approve() still incorrectly states that spender cannot be the zero address. However, this should not be relevant in practice, as the zero address should never have a non-zero balance.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.7   Missing Sanity Checks",
        "body": "  CS-ZCHF-015  The following functions set or update important state variables but do not implement any sanity check on the inputs:  1. kamikaze() could check that target address is not msg.sender.  2. Frankencoin.constructor()   could   enforce   a   minimum   value   for  MIN_APPLICATION_PERIOD to prevent deployments with wrong parameters.  3. MintingHub.constructor() does not check for address(0) on the input parameters.  4. Position's parameters reserveContribution and yearlyInterestPPM (deciding the interest rate of the loan) should not exceed 100%, to avoid underflows in the function getUsableMint.  5. Position.constructor() should enforce that challengePeriod is at least 30 minutes to ensure that a new challenge does not end before ongoing challenges in which bids postpone end time by 30 minute.  6. StablecoinBridge.constructor() does not check for zero values in the inputs.  Acknowledged:  Frankencoin is aware of the missing sanity checks but and has decided to add checks only for point 4.  Frankencoin - Frankencoin -   16  CorrectnessLowVersion1Speci\ufb01cationPartiallyChangedDesignLowVersion1Acknowledged                \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings   Successfully Challenged Positions May Not Close   -Severity Findings   Bidding After Challenge Ends Adds No Time    Position Limits Can Be Used for Free   -Severity Findings   Challenges of Expired Loans Can Be Averted    Double Entry Point Protection Can Be Insufficient    Possible to DoS Minting Functionalities    Reentrant Collateral Could Mint During Liquidation    redeemFrom Does Not Reduce Allowance    Bids Could Be Reverted by Frontrunning    Bridge's Risk Exposure Limit Can Be Circumvented   Incorrect Comparison in Function _mulDiv    Minimum Collateral Can Be Partially Withdrawn    Parallel Challenges Are Expensive to Bid on   -Severity Findings  Inconsistent Value Formats Emitted in Events    Challenge State Treated Inconsistently   Incorrect Documentation for Denied Positions   Incorrect Natspec Regarding Allowances in Frankencoin    Low Precision on Cubic Root Approximation    Missing Event for New Positions    Missing Implementation of Described Functions    Pool Shares Limit Not Enforced    Wrong Liquidation Price Emitted in Event    _cubicRoot Returns 0 for Large Inputs    calculateSharesInternal Can Return Large Numbers   Informational Findings   Unused Import    Misleading Function Name isPosition   1  2  10  11  3  Frankencoin - Frankencoin -   17  CriticalCodeCorrectedHighCodeCorrectedCodeCorrectedMediumCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrected    \fIncorrect Decimals Comments   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Successfully Challenged Positions May Not",
        "body": " Close  When  a  position  is  below  its  liquidation  price,  one  or  multiple  successful  challenges  should  sell  all  its collateral, and the position should be closed.  However, positions do not get closed if there is still an open challenge.  CS-ZCHF-034  if (balance < minimumCollateral && challengedAmount == 0) {         _close();     }  Consider the following situation:  1. Attacker Alice creates a new position with normal parameters and deposits minCollateral + 1  of collateral.  2. After   the  initPeriod  has  passed  (can  no   longer  be  vetoed),  Alice   increases   the  liquidationPrice to a very high price. This restricts minting for 3 days.  3. Alice immediately challenges herself, with a size of minCollateral. It is not worth the gas for  anyone else to challenge the remaining 1 wei of unchallenged collateral.  4. Alice waits until phase 2 of the first challenge starts, then starts another challenge with size of 1.  5. Someone bids the true price of the collateral in the first auction and buys all the collateral except 1 wei.  notifyChallengeSucceeded()  is  called  on  the  position,  but  the  challengedAmount  is still more than 0, so the position is not closed. The minting restriction is reset to 3 days.  6. Alice bids on her second challenge before it enters phase 2. This averts the challenge and reduces challengedAmount to 0. There is still 1 wei of collateral in the position, but it is not worth the gas for anyone to challenge it. The position is not closed, as the challenge was not successful.  7. Alice waits until the 3 day minting restriction is over.  8. Alice deposits collateral and immediately mints the limit amount of the position at the very high (above market) price that she had set in step 2. She passes the noChallenge and noCooldown checks. The minted tokens are undercollateralized, leading to losses for the system.  This  attack  can  be  repeated  multiple  times.  The  tokens  minted  in  the  first  attack  will  be  challenged successfully, which will reset the minted amount of the position to zero. Alice can again start a second challenge as soon as the other challenge is about to enter phase 2, which avoids the position from being closed.  After  averting  the  second  challenge  and  waiting  3  days,  she  can  once  again  deposit  collateral and mint limit amount of tokens. This can be repeated infinitely.  Anyone  (for  example  an  FPS  share  holder  with  an  interest  in  avoiding  system  losses)  can  delay  the attack  by  challenging  the  position  even  when  it  has  no  collateral.  This  has  a  capital  cost (minCollateral  required  for  challenge)  and  a  gas  cost.  The  attacker  can  counter  this  by  starting another  challenge  afterwards,  just  before  the  first  challenge  enters  phase  2.  This  also  has  the  same capital and gas cost for the attacker as for the \"defender\". The attacker has a direct incentive to pay this cost (the value of the minted tokens if the attack is successful), while the defender is being altruistic and just avoids a loss for the system without any direct reward for themselves. Each time the defender starts a  challenge,  they  delay  the  attack  by  at  least  3  days.  However,  they  can  never  stop  it  entirely  if  the attacker always answers with a challenge of their own.  Frankencoin - Frankencoin -   18  CodeCorrectedSecurityCriticalVersion3CodeCorrected         \fUltimately,  the  issue  is  that  there  can  be  open  positions  with  small  amounts  of  collateral  that  are  not worth challenging. This can lead to attacks that require altruistic users to pay costs forever to delay them, or that can lead to unlimited losses if not answered.    The issue has been fixed by adding a check that closes a position if it has less than minCollateral when a challenge is averted (not just when a challenge is successful).  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Bidding After Challenge Ends Adds No Time",
        "body": "  When Frankencoin's bid() is called, the challenge endTime will be extended such that it is at least 30 minutes in the future.  CS-ZCHF-001  uint256 earliestEnd = block.timestamp + 30 minutes; if (earliestEnd >= endTime && block.timestamp < endTime) {     challenge.end = earliestEnd; }  However, if the endTime has already passed, the time will not be extended.  It  is  intentionally  possible  to  bid  after  the  end  of  a  challenge  by  frontrunning  the  execution  of  end(). However, as the time will not be extended in this case, a bidder can guarantee that they win the auction by bidding after endTime and then immediately calling end(). This will make it so that no other bidders can overbid him. If all the bidders follow this strategy, the one with the first transaction in the block after endTime will win the auction. This changes the auction mechanism to a gas bidding war, instead of the intended auction design, which could increase the losses of the system significantly.    The function bid has been revised to always push the auction deadline with at least 30 minutes when a new bid is recorded. This change mitigates the frontrunning issue described above as it is not possible anymore to call functions bid and end in the same block. The code implementation is revised as follows:  uint256 earliestEnd = block.timestamp + 30 minutes; if (earliestEnd >= endTime) {     challenge.end = earliestEnd; }  Note that bids that are submitted after the endTime will not be considered if they are executed after the function end was called to close the auction.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Position Limits Can Be Used for Free",
        "body": "  CS-ZCHF-003  Frankencoin - Frankencoin -   19  DesignHighVersion1CodeCorrectedDesignHighVersion1CodeCorrected                \fOpening a new position through the MintingHub requires users to pay a fee of 1000 ZCHF and wait for at least  3  days  for  the  initialization  period  to  pass.  Users  cannot  clone  positions  during  the  initialization period and position owners cannot mint Frankencoin during this time.  Once  the  initialization  period  is  complete,  users  can  clone  the  original  position  which  reduces  its  limit. When  minting,  they  pay  interest  fees  to  the  Equity.  The  system  allows  users  to  freely  choose  the expiration of the cloned position and the yearly interest rate is applied such that interest is only paid for the loan duration. Cloning a position that is expired or with a short loan duration (a few seconds), results in  zero  or  very  small  fees  for  the  interest.  However,  the  minting  limit  of  the  original  position  gets consumed anyway. As new positions should wait for the initialization period (+3 days) to complete before they  become  usable,  one  could  consume  the  limit  of  all  positions  by  cloning  positions  for  a  very  short amount of time (paying nearly no fees) and cause a denial-of-service, while also wasting the 1000 ZCHF fee that was paid for opening the position.  The  issue  is  even  easier  to  be  exploited  in  the  current  codebase  due  to  Cloned  Positions  Can  Have Arbitrary  Expiration.  An  attacker  can  set  the  expiration  of  cloned  position  into  the  past  or block.timestamp to have zero interest fees. This way, the attacker can reduce the limit of a position to zero by cloning, repaying, and withdrawing the collateral in the same transaction. Flashloans can also be used for the required collateral to consume large positions.  Code partially corrected:  The  functionality  for  creating  and  cloning  positions  has  been  re-organized  in    such  that  the amount of ZCHF for which the owner has already deposited collateral is \"reserved\" and cannot be used by clones. This logic is enforced in function reduceLimitForClone which relies on the new function limitForClones:  function limitForClones() public view returns (uint256) {     uint256 backedLimit = (_collateralBalance() * price) / ONE_DEC18;     if (backedLimit >= limit) {         return 0;     } else {         // due to invariants, this is always below (limit - minted)         return limit - backedLimit;     } }  This approach only mitigates the problem for position owners, and only for those owners which deposit the full amount of collateral they will want to use upfront.  For other users, the issue is still present. An attacker can consume from the limit of positions without paying any fees, until only the owner-reserved amount is left. Hence, nobody else will be able to clone and  the  position  cloning  functionality  can  be  rendered  useless.  According  to  the  documentation  it  is supposed to be the main way for ordinary users to mint ZCHF:  [Cloning] is the standard way to obtain Frankencoins against a collateral. Unlike creating an entirely new position, which takes a lot of time, borrowing by cloning an established position can be done immediately.    The Position contract in   introduces a minimum interest fee that is applied to all new positions independently of their duration. Therefore, creating a new position that is already expired or has a short  Frankencoin - Frankencoin -   20  Version2Version3\fduration (a few seconds), as described above, now incurs a cost that corresponds to the interest rate for a duration of 4 weeks.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Challenges of Expired Loans Can Be Averted",
        "body": "  Each  position  has  an  expiration  which  is  used  to  compute  the  interest  fee  when  minting  new frankencoins. The system assumes that users will pay their loan on time as expired positions should be challenged  and  then  liquidated  with  the  auctioning  mechanism.  However,  in    users  can postpone  repayments  indefinitely  as  long  as  the  position's  liquidation  price  remains  below  the  market price. Any challenge initiated for such positions would be averted, hence challengers make a loss.  In earlier versions, it was not possible to avert challenges on expired positions.  CS-ZCHF-035    The  liquidation  process  has  been  adjusted  in    such  that  the  duration  of  the  phase  1  (when  a challenge can be averted) is capped by the position's expiration. Therefore, launching a challenge for an expired  position  immediately  triggers  phase  2  (dutch  auction)  of  the  liquidation.  This  change  is implemented in the following function:  function challengeData(uint256 challengeStart) external view returns (uint256 liqPrice, uint64 phase1, uint64 phase2) {     uint256 timeToExpiration = challengeStart >= expiration ? 0 : expiration - challengeStart;     return (price, uint64(_min(timeToExpiration, challengePeriod)), challengePeriod); }  Note that position owners should always withdraw their collateral from expired positions, otherwise they will be liquidated, even if the position is over-collateralized.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Double Entry Point Protection Can Be",
        "body": " Insufficient  CS-ZCHF-036  In Position, the withdraw function looks as follows:  function withdraw(address token, address target, uint256 amount) external onlyOwner {     if (token == address(collateral)) {         withdrawCollateral(target, amount);     } else {         uint256 balance = _collateralBalance();         IERC20(token).transfer(target, amount);         require(balance == _collateralBalance()); // guard against double-entry-point tokens     } }  The  comment  states  that  this  should  protect  from  double-entry-point  tokens.  That  is,  a  token  that supports multiple addresses through which transfers can happen.  However, it could be possible that the double-entry-point token has a transfer hook that calls the target address. In this case, there could be a reentrant call to adjust(), which deposits an equal amount of tokens  as  are  being  withdrawn.  The  second  require  statement  would  pass,  even  though  there  was  a double-entry-point token used to incorrectly withdraw collateral.  Frankencoin - Frankencoin -   21  CorrectnessMediumVersion3CodeCorrectedVersion3Version4CorrectnessMediumVersion3Speci\ufb01cationChanged                \fIf there is a pre-transfer hook, the attacker could deposit and mint tokens using reentrancy, then withdraw collateral  using  the  second  entry-point  (that  is  not  considered  to  be  the  collateral  address)  after  the reentrant  call  returns,  circumventing  the  _checkCollateral  check  that  usually  happens  upon withdrawing collateral. This could leave the position undercollateralized, leading to losses for the system.  Consider the following example:  1. A  position  has  a  collateral  that  has  a  pre-transfer  hook  to  the  receiver  and  has  two  entry  points. 1000 collateral tokens are deposited. Each token has a value of 1 ZCHF. 1000 ZCHF are already minted.  2. The position owner calls withdraw(), using the address of the token's second entry point (which is not the collateral address). The _collateralBalance of 1000 is saved and the transfer call happens. Now, the pre-transfer hook is executed and gives execution control to the attacker.  3. The  attacker  calls  adjust(2000,2000,1).  1000  additional  collateral  are  deposited,  then mint()  is  called  to  mint  an  additional  1000  ZCHF.  There  are  2000  collateral  tokens,  so  the collateral check in mint() passes.  4. The adjust() call returns, then the pre-transfer hook returns.  5. The transfer of the second entry-point of the collateral happens.  6. Now,   the   saved  _collateralBalance  of  1000   current _collateralBalance, which is also 1000, as that additional amount was deposited. The check passes.  compared   the   to   is   7. Now, there are 2000 ZCHF minted against a position with 1000 ZCHF worth of collateral.  The undercollateralized minting can only happen if there is a collateral that has a double-entry-point AND a  pre-transfer  hook  that  calls  the  recipient  (ERC-777  tokens  are  not  an  example,  they  only  call  the recipient after a transfer, not before). This combination of traits does not seem to appear in commonly used tokens.  Specification changed:  Frankencoin has decided to revise the criteria of acceptable tokens that can be used as collateral. More specifically,  tokens  that  implement  transfer  hooks  (such  as  ERC-777)  should  not  be  used  as  collateral and governance should deny any position with such collateral tokens.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Possible to DoS Minting Functionalities",
        "body": "  In  , the system allows any user to launch a challenge for any position and immediately avert it in the same transaction. Besides gas costs, there are no other costs for such behavior. However, the side effect of the challenge/avert operations is that the victim position is set in cooldown for 1 day:  CS-ZCHF-037  function notifyChallengeAverted(uint256 size) external onlyHub { ...     _restrictMinting(1 days); }  An  attacker  can  exploit  this  behavior  to  disrupt  the  system  by  putting  specific  positions  on  cooldown, therefore blocking cloning and minting functionalities in victim positions.  This was not possible in earlier versions.  Frankencoin - Frankencoin -   22  SecurityMediumVersion3CodeCorrectedVersion3        \f  The  function  _avertChallenge  now  checks  that  the  challenge  has  not  been  launched  in  the  same block (based on timestamps):  function _avertChallenge(Challenge memory _challenge, uint32 number, uint256 liqPrice, uint256 size) internal {     require(block.timestamp != _challenge.start);     ... }  A challenger can still challenge a position with a correct liquidation price (below market price) to put it on cooldown  for  one  day.  However,  the  challenger's  collateral  can  then  be  sold  to  other  bidders  in  future blocks, as the challenge cannot be immediately cancelled. The challenger will still be able to cancel their challenge in a later block if their cancellation transaction is included in the chain before a bid from another bidder. However, this will likely require the challenger to incur a high gas cost.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Reentrant Collateral Could Mint During",
        "body": " Liquidation  When a challenge is successful, notifyChallengeSucceeded() is called on Position.  This function does the following 3 things in order:  CS-ZCHF-038  1. reduce challengedAmount  2. send collateral to bidder  3. restrict minting for 3 days  Step 2. can cause a reentrancy during an inconsistent state (minting not yet restricted) if the collateral is reentrant (e.g. ERC-777).  Consider the following attack:  1. Attacker Alice creates a new position with normal parameters and deposits an ERC-777 collateral.  2. After   the  initPeriod  has  passed  (can  no   longer  be  vetoed),  Alice   increases   the  liquidationPrice to a very high price. This restricts minting for 3 days.  3. A challenge is started. Assume the duration of phase 1 + phase 2 is more than 3 days.  4. When the auction price gets close to the value of the collateral, Alice calls bid().  5. notifyChallengeSucceeded() is called, which reduces the challengedAmount to 0.  6. The  Position's  collateral  is  sent  to  Alice,  which  allows  her  to  reenter.  She  deposits  additional collateral  to  the  position  and  mints  limit  tokens  at  the  high  price  she  set  in  step  2.  The noChallenge  modifier  passes,  as  the  challengedAmount  is  0.  The  noCooldown  modifier passes  and notifyChallengeSucceeded()  has  not  yet  restricted  minting.  The  tokens  are  minted  at  an incorrectly high price, which leads to losses for the system.  price  was   adjusted   passed   since   have   days   the   as   3   If the auction duration is less than 3 days but more than 1 day, Alice could start the challenge herself and avert it for free before it reaches phase 2. This will set the cooldown to 1 day. While Alice has an open challenge for the full collateral amount, nobody else is incentivized to start another challenge.  Specification changed:  Frankencoin - Frankencoin -   23  SecurityMediumVersion3Speci\ufb01cationChanged        \fFrankencoin has decided to revise the criteria of acceptable tokens that can be used as collateral. More specifically,  tokens  that  implement  transfer  hooks  (such  as  ERC-777)  should  not  be  used  as  collateral and governance should deny any position with such collateral tokens.  Futhermore,  the  function  notifyChallengeSucceeded  has  been  updated  to  set  the  cooldown  to  3 days first, and later withdraw the collateral:  function notifyChallengeSucceeded(address _bidder, uint256 _size)     external onlyHub returns (address, uint256, uint256, uint32) {    ...     _restrictMinting(3 days);      _withdrawCollateral(_bidder, _size); // transfer collateral to the bidder and emit update     ... }  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   redeemFrom Does Not Reduce Allowance",
        "body": "  In  other users if the user has given an approval.  , the redeemFrom function is added to Equity. It allows redeeming FPS tokens on behalf of  CS-ZCHF-026  The approved amount is checked, but it is not reduced.  require(_allowance(owner, msg.sender) >= shares);  As a result, if an approval of 1 share is given, it can be reused to redeem an unlimited number of shares.    The allowance is now reduced when calling redeemFrom().  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   Bids Could Be Reverted by Frontrunning",
        "body": "  The MintingHub's bid function contains the following check:  if (expectedSize != challenge.size) revert UnexpectedSize();  CS-ZCHF-004  This exists so that a bidder does not accidentally bid a wrong amount on a challenge that was split using splitChallenge(). However, this can also be used as a DoS vector.  Consider the following situation:  There  is  a  position  of  1  million  ZCHF  with  200  *  minCollateral  of  collateral  that  should  be liquidated.  A  challenger  creates  a  challenge  for  the  full  amount  and  immediately  bids  1  ZCHF  for  the collateral. There are no bids until 30 minutes before the end of the auction, as bidders want to limit the risk of the collateral losing value after their bid is placed. Starting from 31 minutes before the end, the challenger calls splitChallenge(challengeNumber, minCollateral + R), where R is a small random  number,  in  each  block  with  a  relatively  high  amount  of  gas,  such  that  they  expect  their transaction to happen in the block before any bids. Now, any bid will revert, as the position no longer has  Frankencoin - Frankencoin -   24  CorrectnessMediumVersion2CodeCorrectedVersion2DesignMediumVersion1CodeCorrected                \fthe expected size. The end time is not increased, as there is no new bid. At the end time, the challenger can buy the collateral worth over 1 million ZCHF for 1 ZCHF. The system takes a massive loss.  As  there  are  only  about  150  Ethereum  blocks  per  30  minutes,  the  attacker  has  the  ability  to  split  their challenge once every block without hitting the minCollateral limitation.  In case the attacker fails to split early enough in one of the blocks and a bid comes through, they have only lost gas and incur no other cost. The bidders have little incentive to pay a lot of gas to avoid being frontrun, as they are not guaranteed to win the auction by making a single bid. They may be outbid by someone else, which would make their high gas bid worthless.  The  challenger  could  also  use  more  sophisticated  frontrunning  methods,  where  they  only  split  their challenge if they really expect a bid in that block.  A  bidder  could  work  around  the  reverts  by  deploying  a  contract  that  reads  the  current  size  of  the challenge on-chain and places a bid of the correct size. This cannot revert, as the size will always be up to  date.  It  requires  the  bidder  to  have  considered  this  situation  already  and  have  the  infrastructure  in place beforehand, as it is unlikely they will be able to set it up within 30 minutes.    When  splitting  a  challenge  in  ,  it  is  now  required  that  the  resulting  bid  on  both  resulting challenges is at least 2500 CHF, so no very small bids can be made. It is still possible to cause bids to revert by splitting a challenge, but it now requires a higher bid on the initial challenge to do so.  In    the splitChallenge function has been removed with the change to dutch auctions.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   Bridge's Risk Exposure Limit Can Be",
        "body": " Circumvented  The  StablecoinBridge  contract  implements  a  mechanism  to  restrict  the  exposure  towards  an  external stablecoin that might lose value or get compromised, e.g., due to a malicious implementation upgrade. The immutable variable limit sets an upper limit on the amount of Frankencoin that can be minted from the bridge. The limit is enforced in the internal function mintInternal:  CS-ZCHF-005  require(chf.balanceOf(address(this)) <= limit, \"limit\");  The correctness of the protecting mechanism relies on the external contract returning a correct balance when the balanceOf function is called. However, if the chf contract becomes malicious it could return arbitrary values as balanceOf. For example, the contract could be upgraded to return 0 balance, or it could have an admin function that allows burning of a specific address's balance.  As a result, limit can be circumvented and the maximum exposure of the Frankencoin system to the external stablecoin is not bounded by limit. Instead, there could be an infinite number of Frankencoin minted through the bridge.    Internal  accounting  for  the  number  of  tokens  minted  by  the  bridge  has  been  added  in  means limit is now correctly enforced without relying on any functions of the chf contract.  .  This  Frankencoin - Frankencoin -   25  Version2Version3SecurityMediumVersion1CodeCorrectedVersion3          \f6.11   Incorrect Comparison in Function _mulDiv  CS-ZCHF-032  The  internal  function  _mulDiv  checks  if  the  computation  x  *  factor  fits  in  a  uint256  before performing the multiplication. If the result is larger than type(uint256).max, the function performs the division first to avoid the potential overflow of the multiplication.  The  implementation  incorrectly  does  the  opposite,  dividing  first  when  the  result  of  x  *  factor  fits  in uint256, and overflowing otherwise:  function _mulDiv(uint256 x, uint256 factor, uint256 divisor) internal pure returns(uint256) {     if (...){         ...     } else if (type(uint256).max / factor > x){         ...         return x > factor ? x / divisor * factor : factor / divisor * x;     } else {         return x * factor / divisor;     } }    The function has been revised to perform the division first only when the result of x * factor does not fit in a uint256.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.12   Minimum Collateral Can Be Partially",
        "body": " Withdrawn  The documentation states:  [...]if the minimum collateral is 1 WETH, one cannot reduce the collateral to     0.9 WETH even if there is no outstanding Frankencoins.  However, this is not enforced in the Position contract.  This  may  lead  to  leftover  collateral  amounts  that  are  too  small  to  be  effectively  liquidated,  due  to  gas costs. This can lead to losses for the system.  CS-ZCHF-007    The  public  function  withdrawCollateral  has  been  updated  to  revert  if  a  dust  amount  of  collateral remains in a position after a withdrawal:  function withdrawCollateral(address target, uint256 amount) public onlyOwner noChallenge {     ...     uint256 balance = _withdrawCollateral(target, amount);     ...  Frankencoin - Frankencoin -   26  CorrectnessMediumVersion1CodeCorrectedDesignMediumVersion1CodeCorrected              \f    if (balance < minimumCollateral && balance > 0) revert InsufficientCollateral(); }  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.13   Parallel Challenges Are Expensive to Bid on",
        "body": "  CS-ZCHF-008  There can be many parallel challenges for the same position, each with their own end time. In case the sum of challenged collateral is higher than the position collateral, only the first ended challenges will be able to receive collateral, until there is none left.  Consider the following situation:  There is a position that should be liquidated, where challenges will likely not be averted. This may be due to the market price being significantly below the liquidation price, or because the position was expired. Now,  a  challenger  starts  many  challenges  (e.g.  100)  on  the  same  position  within  the  same  block, meaning they have the same end time. The challenger will need at least 100x minCollateral to do this, but they know the challenge will not be averted, so they are not risking their collateral. Assume the total challenged amount is significantly more than the position collateral. Assume there are not many bids before the final 30 minutes of the auction (this seems likely as the bidders take the risk of the collateral value falling before the end of the auction). With 29 minutes left, a bidder bids a competitive price on one of  the  auctions.  This  extends  the  auction  time  by  30  minutes.  However,  the  end  time  of  the  other  99 auctions is not increased. This means that if nothing else happens, the full collateral will be sold to the auctions with no or small bids, instead of the competitively priced one. To change this, someone will need to  bid  a  small  amount  (or  a  competitive  amount,  but  this  has  capital  costs)  on  each  of  the  other  99 positions  before  they  end,  paying  gas  fees.  Whenever  this  happens,  the  current  highest  bidder  of  the non-competitive positions has the option of making a bid on the competitive auction to extend the end once again and force someone else to bid on all the 99 other positions once again.  Overall,  creating  multiple  challenges  with  more  collateral  in  total  than  the  position  collateral  can massively increase the gas costs of auctions at a relatively small cost to the attacker. The cost consists of the gas for opening the challenges plus the capital cost of locking the challenge collateral, though for a common collateral like ETH this may not be a big hurdle.  If nobody is willing to pay the gas to extend the time of the uncompetitively priced auctions, the collateral could be sold massively under its market value, leading to losses for the system.    The issue has been resolved by changing the auction type to a dutch auction in  longer a moving end time.  . There is no  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.14   Inconsistent Value Formats Emitted in",
        "body": " Events  The  format  of  parameters  in  events  Loss  and  Profit  is  not  consistent.  Specifically,  the  variables included in the event Loss represent raw frankencoin amounts, while the variables in Profit are in E6 format (multiplied by 1e6).  CS-ZCHF-039  Frankencoin - Frankencoin -   27  DesignMediumVersion1CodeCorrectedVersion3DesignLowVersion3CodeCorrected                \f  The  codebase  has  been  updated  to  emit  events  with  parameters  in  frankencoin  amounts.  Events  now include  only  the  reporting  minter  and  the  realized  loss  or  profit  Here  is  one  example  from  function burnWithoutReserve:  emit Profit(msg.sender, reserveReduction / 1000_000);  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.15   Challenge State Treated Inconsistently",
        "body": "  Function  isChallengeOpen  returns  true  if  challenge.end  is  in  the  future,  otherwise  it  returns false. However, this is not in line with the bid function, which accepts new bids until a challenge has been either averted or settled by the function end.  CS-ZCHF-027    The function was removed in   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.16   Incorrect Documentation for Denied",
        "body": " Positions  The documentation states:  In case a new position is both challenged and vetoed, the challenge cannot be     averted any more and the collateral is simply auctioned off to the highest bidder.  However, this is not correct. Challenges can be averted in this situation. They can only not be averted when the position is expired.  CS-ZCHF-010  Specification changed:  The documentation has been updated to reflect the code.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.17   Incorrect Natspec Regarding Allowances in",
        "body": " Frankencoin  The natspec comment for function openPosition states:  CS-ZCHF-011  Frankencoin - Frankencoin -   28  CorrectnessLowVersion2CodeCorrectedVersion3CorrectnessLowVersion1Speci\ufb01cationChangedCorrectnessLowVersion1Speci\ufb01cationChanged                        \f* For a successful call, you must set allowances for both ZCHF and the collateral token,     allowing the minting hub to transfer the initial collateral amount to the newly     created position and to withdraw the fees.  This sentence is partially incorrect as the user does not need to provide allowance to the minting hub for ZCHF (Frankencoin). MintingHub has the minter role in Frankencoin and has infinite approval transfer on behalf of any account.  The same incorrect information is also present in the documentation.  Specification changed:  The inline code comments have been revised. They no longer state that the user must provide allowance for ZCHF to the minting hub.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.18   Low Precision on Cubic Root Approximation",
        "body": "  The function _cubicRoot implements the Halley approximation to compute the value x**(1/3). The returned  value  has  a  maximum  error  of  0.01  shares.  Given  that  this  function  is  used  to  compute  the number of pool shares an LP receives after investing, the rounding error might be significant if the pool shares have a high value (e.g., thousands of ZCHF).  CS-ZCHF-031    Function  _cubicRoot  has  been  updated  to  use  a  more  efficient  starting  value  for  the  approximation instead of 10**18 that was used in the previous iteration:  // Good first guess for _v slightly above 1.0, which is often the case in the Frankencoin system uint256 x = _v > ONE_DEC18 ? (_v - ONE_DEC18) / 3 + ONE_DEC18 : ONE_DEC18;  This  enables  the  approximation  algorithm  to  converge  faster  than  before,  which  allows  using  a  higher precision threshold, namely 10**(-12).  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.19   Missing Event for New Positions",
        "body": "  The contract PositionFactory does not emit any event when a new position is opened or cloned. No event is  emitted  by  MintingHub  either.  Deploying  a  new  position  is  an  important  update  for  the  system.  An event helps challengers and liquidators to easily learn about existing positions.  In  general,  it  is  recommended  to  emit  events  for  important  state  updates  and  index  the  relevant parameters in events to allow integrators and dApps to quickly search for these and simplify UIs.  CS-ZCHF-013    The event PositionOpened is now emitted by the minting hub whenever a new position is created or cloned.  Frankencoin - Frankencoin -   29  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \f6.20   Missing Implementation of Described Functions  The  comment  in  increaseAllowance are implemented:  the  contract  ERC20  states   that   functions  decreaseAllowance  and  CS-ZCHF-014  * Finally, the non-standard `decreaseAllowance` and `increaseAllowance` * functions have been added to mitigate the well-known issues around setting * allowances. See `IERC20.approve`.  However, none of the above functions have been implemented by the contract. The frontrunning attack against approve() is therefore still applicable as it always overwrites the current value without checking if the allowance has been consumed or not.  Specification changed:  The comment has been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.21   Pool Shares Limit Not Enforced",
        "body": "  Inline comments in the Equity contract suggest that a limit in the total pool shares is enforced in the code:  In fact, a limit of about 2**30 shares (that's 2**90 Bits when taking into account the decimals) is imposed when minting.  CS-ZCHF-030  However, the contract does not implement such a restriction.    The updated function invest now implements the following check that restricts the total number of pool shares minted:  require(totalSupply() <= type(uint96).max, \"total supply exceeded\");  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.22   Wrong Liquidation Price Emitted in Event",
        "body": "  Function  initializeClone  emits  the  variable  existing.price  in  the  event  PositionOpened which matches the price of the original position. The liquidation price of the cloned position is stored in the state variable pos.price and may be smaller than existing.price.  CS-ZCHF-016  Frankencoin - Frankencoin -   30  CorrectnessLowVersion1Speci\ufb01cationChangedCorrectnessLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                        \f  The event is now emitted by the minting hub using the correct price.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.23   _cubicRoot Returns 0 for Large Inputs",
        "body": "  The  function  _cubicRoot  computes  incorrect  results  for  inputs  larger  than  1e28  due  to  _mulDiv() rounding down as described in Possible Rounding to 0 in Function _mulDiv. Therefore, for input values _v larger than 1e28, the function always computes 0 in the following line:  CS-ZCHF-028  uint256 xnew = _mulDiv(x, (powX3 + 2 * _v), (2 * powX3 + _v));  The consequences of this issue in the current codebase are limited given that _cubicRoot() is called with values slightly larger than 1 (10**18):  _cubicRoot(_divD18(capitalBefore + investmentExFees, capitalBefore))  ,  a  check  is  added  on  the  input  value  _v,  however  it  only  impacts  the  initial In  the  codebase  guess  of  the  approximation  algorithm.  For  large  inputs  _v,  the  function  _cubicRoot  still  returns incorrect results.    The function mulDiv is removed from the codebase   to avoid rounding down to 0, hence the function now fails for large inputs due to arithmetic overflows. This behavior is preferred by Frankencoin as the codebase calls _cubicRoot() only with limited values (slightly larger than 10**18).  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.24   calculateSharesInternal Can Return Large",
        "body": " Numbers  CS-ZCHF-017  In Equity, calculateSharesInternal() is mostly expected to be called with a capitalBefore of more than 1000E18. However, there are edge cases where it could be called with small numbers, which lead to large return values.  Consider the following unlikely situation:  The Frankencoin equity has been almost wiped out, but not completely. The equity remaining is 1 wei of ZCHF.  There  are  more  than  1000  FPS  shares  still  in  circulation.  Now,  someone  calls  invest()  with amount 1000E18 ZCHF. This will call calculateSharesInternal(1,1000E18).  The amount of shares to mint will be calculated using the cubic root of 997E18 / 1E(-18), which is a much larger number than expected.  Frankencoin - Frankencoin -   31  CorrectnessLowVersion1CodeCorrectedVersion3Version4CorrectnessLowVersion1CodeCorrected                \f  The  function  calculateSharesInternal  has  been  renamed  as  _calculateShares  and  now  it implements a short-circuit that returns 1000 shares whenever equity is below the minimum threshold or no pool shares are minted. This avoids small inputs:  function _calculateShares(uint256 capitalBefore, uint256 investment) internal view returns (uint256) {     uint256 totalShares = totalSupply();     ...     uint256 newTotalShares = capitalBefore < MINIMUM_EQUITY || totalShares == 0 ? totalShares + 1000 * ONE_DEC18         : ...;     return newTotalShares - totalShares; }  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.25   Incorrect Decimals Comments",
        "body": "  MintingHub's  launchChallenge()  and  Position's  notifyChallengeSucceeded()  both  have  the following comment:  CS-ZCHF-041  //@param _size     size of the collateral bid for (dec 18)  However,  the  expected  input  size  should  be  given  as  a  token  amount  (in  token  decimals),  not  with  18 decimals.    The inline comments that described incorrectly the input values are removed in   .  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.26   Misleading Function Name isPosition",
        "body": "  The  function  isPosition  in  Frankencoin  contract  returns  the  address  of  the  minter  if  a  position  has been registered, and zero address otherwise. However, the name isPosition() hints that the function also  checks  if  the  position  exists,  which  can  be  misleading.  Additionally,  the  name  could  be  read  as implying that it returns a boolean (true if it is a position with minter role) instead of an address.  CS-ZCHF-022    The function has been renamed to getPositionParent.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.27   Unused Import",
        "body": "  Frankencoin - Frankencoin -   32  InformationalVersion3CodeCorrectedVersion4InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected                  \fThe file MintingHub.sol imports the contract Ownable, which is not used.  CS-ZCHF-025  Code changed:  The unused import has been removed.  Frankencoin - Frankencoin -   33  \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Compiler Version",
        "body": "  The compiler version used (0.8.20) has the following known bugs.  This is just a note as we do not see any issue applicable to the current code.  The contracts should be deployed using a compiler version they have been thoroughly tested with. Using a very recent version may not be recommended, as it may not be considered battle-tested yet.  At the time of writing the most recent version is 0.8.21. For more information please refer to the release notes.  CS-ZCHF-029  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Event Reentrancy",
        "body": "  Function end triggers a transfer in the collateral token before emitting the event. If the collateral token implements callbacks on transfer, one can reenter in the contract and therefore have events emitted out of order.  CS-ZCHF-018  Acknowledged:  Frankencoin responded:  External observers are not expected to rely on the order of events within a transaction.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Gas Optimizations",
        "body": "  The codebase could be more efficient in terms of gas usage. Reducing the gas costs may improve user experience. Below is an incomplete list of potential gas inefficiencies:  1. The  function  adjustRecipientVoteAnchor  does  not  clear  the  state  recorded  in  the  mapping  voteAnchor for users that burn or transfer out all their shares.  CS-ZCHF-019  2. The function invest could be marked as external.  3. The function calculateShares could be marked as external.  4. The function getUsableMint could be marked as external.  Frankencoin - Frankencoin -   34  InformationalVersion2AcknowledgedInformationalVersion1AcknowledgedInformationalVersion1CodePartiallyCorrected                \f5. The field end in struct Challenge could use a smaller type such that it fits into a single storage  slot with another field of type address.  6. The  modifier  onlyOwner   in   function  adjust   is   redundant  when   triggering  calls   to  withdrawCollateral(), mint() and adjustPrice().  :  7. One external call to *.collateral() could be avoided in function clonePosition.  8. The  function  adjustPrice  performs  two  external  calls  to  read  the  balance  of  the  position  via  _collateralBalance() when price is lowered.  :  9. The function StablecoinBridge._mint performs redundant SLOADs when accessing the state  variable minted.  Code partially corrected:  2. The function invest has been marked as external.  3. The function calculateShares has been marked as external.  4. The function getUsableMint has been marked as external.  5. The field end has been removed, a new field start is added which is of type uint64.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   Incomplete Natspec",
        "body": "  A  large  number  of  functions  have  incomplete  Natspec,  i.e.,  do  not  describe  all  input  parameters  and return  values.  Natspec  descriptions  help  to  more  quickly  understand  the  intention  of  functions,  which improves  code  readability.  Natspec  of  external  functions  also  helps  third-parties  that  integrate  with  the system, e.g., by providing information regarding the format of input values, or assumptions that are made about them.  CS-ZCHF-020  Acknowledged:  Frankencoin added natspec comments for some functions.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   Magic Numbers in Codebase",
        "body": "  Several  magic  values  are  used  in  the  codebase  that  could  be  declared  as  constant.  For  instance, parameters of positions are stored in 6 decimals (parts-per-million), hence the number 1000_000 is used frequently.  Similarly,  voting  thresholds  are  stored  in  basis  points.  Such  values  can  be  replaced  with constant variables to improve code readability.  CS-ZCHF-021  Acknowledged:  Frankencoin - Frankencoin -   35  Version2Version3InformationalVersion1AcknowledgedInformationalVersion1Acknowledged            \fFrankencoin has decided to keep the code unchanged as they prefer to avoid adding new variables for constants.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.6   Rounding Errors in Kamikaze Function",
        "body": "  The kamikaze function burns voting power from a target address and the caller of the function. The function  is  designed  to  burn  the  same  voting  power  from  both  accounts  as  set  in  votesToDestroy. However, the internal function reduceVotes introduces errors due to rounding:  CS-ZCHF-023  function reduceVotes(address target, uint256 amount) internal returns (uint256) {     ...     voteAnchor[target] = uint64(anchorTime() -         (votesBefore - amount) / balanceOf(target));     ...  In  the  line  above,  the  rounding  error  depends  on  amount  (corresponding  to  the  user  input votesToDestroy)  and  the  token  balance  of  the  affected  address.  Hence,  the  caller  can  choose votesToDestroy  in  such  a  way  that  its  voting  power  is  reduced  slightly  less  compared  to  the  other party.  In the worst case, the caller is able to destroy up to 1 second worth of votes more from a target than from themselves.  Acknowledged:  Frankencoin  has  acknowledged  the  issue  but  has  decided  to  keep  the  funtion  as-is  due  to  the  limited impact of the issue.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.7   Transfer of Positions' Ownership",
        "body": "  Positions  inherit  the  Ownable  contract  which  records  the  address  of  current  owner.  Ownable implements  a  single-step  transfer  of  ownership  with  a  sanity  check  for  zero  address.  Accidental ownership  transfers  are  possible  and  would  lock  positions  indefinitely,  rendering  functionalities  to  mint and withdraw collateral useless.  A  mechanism  such  as  Ownable2Step  could  be  used  to  mitigate  accidental  transfers  to  an  incorrect address.  CS-ZCHF-024  Acknowledged:  Frankencoin responded:  Worried users can create their own owner contract with arbitrary additional safety measures.  Frankencoin - Frankencoin -   36  InformationalVersion1AcknowledgedInformationalVersion1Acknowledged            \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Dutch Auction Duration",
        "body": "  The price of the dutch auction decreases linearly throughout phase 2.  Note  that  only  some  prices  will  be  available  due  to  the  Ethereum  block  time  being  12  seconds.  As  a result,  the  duration  of  phase  2  should  be  chosen  long  enough  such  that  relevant  prices  do  not  fall inbetween blocks.  For example, if the auction should have a price precision of 0.1%, the duration of phase 2 must be at least 1000 * 12 seconds.  At the same time, the whole duration (phase 1 and phase 2) should not be too long, as a longer duration gives more time for the collateral to continue falling in value once the auction starts.  Positions with bad auction duration values should be denied by governance.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Interest Fees Are Computed on the Gross",
        "body": " Minted Amount  Users  pay  an  interest  fee  in  Frankencoin  (ZCHF)  when  minting  from  the  positions  created  by  the MintingHub. The interest is computed on the gross amount of minted ZCHF, which includes the reserves and the interest fee, not just the amount that the user receives in their wallet.  The relevant code is implemented in the function mint of the Frankencoin contract:  function mint(address _target, uint256 _amount, uint32 _reservePPM,      uint32 _feesPPM)     override external minterOnly {       uint256 usableMint = (_amount * (1000_000 - _feesPPM - _reservePPM)) / 1000_000;      _mint(_target, usableMint);      _mint(address(reserve), _amount - usableMint); // rest goes to equity          as reserves or as fees    ... }  In a scenario where the reserve contribution is set at 20%, the interest fee is 5%, and the expiration is in one year, the effective interest rate on the usableMint is 0.05 / 0.75 = 6.6% per year, not 5%.  Users should be aware of the effective interest rate that they are paying, which may be unintuitive due to the way it is calculated.  Frankencoin - Frankencoin -   37  NoteVersion3NoteVersion1        \f8.3   Market Risk Taken by Challengers and Bidders  The  auction  process  takes  some  time  depending  on  the  challengePeriod  of  the  position  and  the number of bids received. During this time, the price of the collateral could change.  Market risk for challengers:  For instance, if at time t_1 the market price of the collateral is below the liquidation price of a position, one can start a challenge with the assumption that the challenge will succeed, i.e., the highest bid will be close  to  the  market  price,  which  is  below  the  liquidation  price.  However,  if  the  price  goes  above  the liquidation  price  at  time  t_2  while  the  auction  is  ongoing,  the  challenger's  collateral  will  be  sold  at  the liquidation price, which will likely result in a small loss for them, as a bidder would only bid if they can buy the asset below market price.  As a result, it should be expected that challengers only start challenges when they think it is likely that it will not be averted. They will not challenge a position if market price is only a small amount below the liquidation price.  Market risk for bidders:  Similarly,  bidders  have  exposure  to  the  price  change  of  the  collateral  when  they  place  their  bid.  The exposure  will  always  be  at  least  30  minutes.  In  case  the  price  of  the  collateral  drops  during  this  time window, they may buy the collateral at a higher price than the current market price.  As a result, it should be expected that bids will not be at market price, but instead be at a discount which compensates for the risk taken (or the cost of hedging it elsewhere).  The  reservePPM  of  positions  should  be  set  high  enough  to  cover  the  loss  occurred  due  to sub-market-price liquidations caused by the above factors.  In    of  the  codebase,  the  liquidation  process  is  based  in  dutch  auctions,  which  removes  the exposure  of  bidders  to  the  price  change.  The  auction  is  now  resolved  as  soon  as  a  bid  is  placed  (the challenge is either averted or successful), and the bidder receives the collateral immediately.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.4   Minimum Collateral Is Never Adjusted",
        "body": "  The minimumCollateral for a position is immutable. On creation, it is enforced that the minimum is >5000 ZCHF. The price of the position can be adjusted up or down, but the minimumCollateral never changes. If the price is decreased, this could lead to positions with low value, which may not be worth the gas to liquidate using the auction mechanism.  Consider the following situation:  1. Position is created when collateral is worth a lot.  2. Price falls slowly but owner keeps adjusting liquidation price down. ZCHF limit is still large.  3. Someone clones the position many times using minCollateralAmount (which is significantly under  5000 ZCHF). Each position is not worth liquidating because of gas.  This could result in up to the position's minting limit amount of losses for the system.  Frankencoin - Frankencoin -   38  NoteVersion1Version3NoteVersion1      \fGovernance should keep this limitation in mind when evaluating the collateral asset, expiration and limit of new positions. An asset that may lose significant value before the expiration should likely not be allowed with a large limit.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.5   Minters Should Not Change Their Code",
        "body": "  Contracts with the minter role should not be able to change their code.  In  particular,  they  should  not  be  upgradeable  and  they  should  also  not  be  able  to  selfdestruct.  Using create2, it would possible to propose a benign minter that is able to call selfdetruct. As soon as the veto period has ended, the deployer could selfdestruct the minter and deploy a different contract at the same address, which would now be able to mint unlimited Frankencoin.  Proposed minters and their related positions should be carefully evaluated during the veto process not to have any of the code-changing functionality such as the above or others.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.6   Nested Iterations in Function checkQualified",
        "body": "  The function checkQualified iterates through all addresses included in the array helpers. For each address in the array, the function canVoteFor is called recursively to verify that a valid delegation path exists  between  the  FPS  holder  and  msg.sender.  The  governance  address  exercising  their  veto  right should carefully choose addresses in helpers to optimize their gas costs and make sure the transaction does not exceed gas limitations.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.7   No Slippage Protection for Mint",
        "body": " onTokenTransfer  two   in  Equity:  invest()  and There  are  onTokenTransfer().  The  invest()  function  contains  an  expectedShares  argument,  which provides slippage protection. The onTokenTransfer() function does not have an equivalent.  that  can  be  used   functions   to  mint   tokens   Users  should  use  the  invest()  function  to  mint  shares  when  possible,  in  order  to  benefit  from  the slippage protection.  Code changed:  In   , the onTokenTransfer function was removed from Equity.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.8   Non-registered Positions",
        "body": "  The  contract  PositionFactory  does  not  enforce  any  access  control  for  its  external  functions createNewPosition  and  clonePosition,  hence  anyone  can  deploy  arbitrary  positions.  The  UI  Frankencoin - Frankencoin -   39  NoteVersion1NoteVersion1NoteVersion1Version2NoteVersion1                \fshould filter out such positions and users should validate that the positions they interact with are created by the correct MintingHub. Only contracts with the minter role in Frankencoin can register positions.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.9   Position Owners Should Withdraw the Excess",
        "body": " Collateral  Users should withdraw their excess collateral from positions, especially if they are expired or do not have any minted amount left. Otherwise, the position risks having its collateral liquidated if the market price falls below the liquidation price, even if the position itself might be over-collateralized (e.g., zero minted frankencoins).  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.10   Positions With Quickly Collapsing Collateral",
        "body": " Must Be Challenged  In MintingHub, the Challenge reward is calculated as follows, where offer is the value that the collateral has been liquidated for:  uint256 reward = (offer * CHALLENGER_REWARD) / 1000_000;  This becomes problematic in a case where the expected liquidation value is close to zero.  Consider the following situation:  1. A token is accepted as collateral.  2. Positions are created with a price that is valid at the time.  3. Something  catastrophic  happens,  and  the  value  of  the  collateral  declines  very  quickly  towards  0  (e.g. hyperinflation or loss of backing for a wrapped asset).  4. Now,  the  expectation  is  that  by  the  time  phase1  and  phase2  of  the  dutch  auction  finish,  the  collateral value will be 0. This means the challenger reward will also be 0.  5. If all challengers share this expectation, nobody is incentivized to start a challenge, as the gas cost  of doing so will be larger than the reward.  6. The position goes unchallenged, even when the market price goes below the liquidation price. The price is unchanged, so the position is not on cooldown. A user can clone the position and deposit collateral token, which he bought for below liquidation price on the market. He can then profitably mint up to limit ZCHF, which are undercolalteralized and will lead to a loss to the system.  This situation can be avoided if there is an attentive FPS holder, who is incentivized to avoid losses to the system. He should immediately challenge the position when it goes below liquidation price, even though they expect not to receive any challenge reward.  If the collateral value is 0, there is also no incentive for bidders to bid on a challenge once it reaches the ending price of 0. Someone also needs to call bid() altruistically (paying gas) to update the accounting and have the Equity take the loss.  In  conclusion,  FPS  holders  should  monitor  positions  and  challenge  them  even  if  they  do  not  expect  a challenge reward, in order to avoid losses to the system (which are absorbed by FPS Equity).  Frankencoin - Frankencoin -   40  NoteVersion3NoteVersion1          \f8.11   Possible Rounding to 0 in Function _mulDiv  Function _mulDiv in the library MathUtil stores the intermediate results in uint256, hence it performs the division before multiplication if the term``x * factor`` does not fit in 256 bits to avoid overflowing. Note, the  result  is  rounded  to  0  for  inputs  where  divisor  is  larger  than  both  x  and  factor,  e.g., _mulDiv(2**250,2**15,2**251).  The function _mulDiv has been removed in  example described above.   of the codebase to avoid rounding down as in the  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.12   Possible to Frontrun Veto Transactions",
        "body": "  FPS holders can delegate their voting power to 3rd parties which can use the delegated votes to veto new  proposals  (e.g.,  opening  new  positions  or  adding  minters  into  Frankencoin).  A  user  vetoing  a proposal submits a list of addresses that have delegated voting power to him (referred to as helpers).  The  function  checkQualified  ensures  that  the  total  voting  power  (own  voting  power  plus  delegated votes) of the address exercising the veto right is above 3% and all delegations are still valid. The second condition  enables  a  frontrunning  possibility  for  a  delegator  in  the  list  helpers  to  make  the  veto transaction revert by removing the delegation. Therefore, governance should exercise their veto rights as early as possible and include only trustworthy accounts as helpers.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.13   Specifics of Modifier minterOnly in",
        "body": " Frankencoin  The  modifier  minterOnly  passes  successfully  if  either  msg.sender  is  a  valid  minter  or  it  has  been added in the mapping positions by a valid minter:  modifier minterOnly() {    if (!isMinter(msg.sender) && !isMinter(positions[msg.sender])) revert NotMinter();    _; }  This behavior, among others, should be considered when evaluating proposals for adding new minters in the Frankencoin contract.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.14   restructureCapTable May Take Multiple",
        "body": " Blocks  the  system  has   If  function restructureCapTable  allows  existing  shareholders  to  restructure  the  system.  Any  shareholder  with more than 3% of the voting power can step in and bootstrap the system by paying for the losses (which  losses  and  equity   than  1000  ZCHF,   incurred   less   the   is   Frankencoin - Frankencoin -   41  NoteVersion2Version4NoteVersion1NoteVersion1NoteVersion1              \fcan  be  significantly  higher  than  1000  ZCHF)  and  become  the  only  FPS  shareholder.  As  the  function restructureCapTable  iterates  through  all  FPS  holders  given  as  input  and  burns  their  shares,  it  is possible that the block gas limit prevents wiping all existing shares in a single block.  Frankencoin - Frankencoin -   42  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Missing Length Validation in MPT Verify",
        "body": "  When  verifying  a  MPT  proof  by  verify(key,  key_len,  proof),  the  nodes  nibbles  (denoted  as n-nibbles)  are  decoded  and  matched  with  the  next  nibbles  in  the  key  (denoted  as  k-nibbles). However, length validation of the remaining nibbles is missing in the logic of matching both the Extension Node as well as the Leaf Node. Let's assume there is an MPT with two valid proofs, each contains two Branch Node, One Extension Node, and One Leaf Node denoted as:  CS-HRDTCL-005  proof 1 = Branch [ b ] | Branch [ c ] | Extension [ de ] | Leaf [ f2 ]  proof 2 = Branch [ a ] | Branch [ b ] | Extension [ cd ] | Leaf [ 0e ]  Herodotus - CairoLib -   12  CriticalCodeCorrectedHighCodeCorrectedCodeCorrectedMediumCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCorrectnessCriticalVersion1CodeCorrected         \fIn the following description, we will use these dummy proofs as examples.  Leaf Node: it retrieves the elements from k-nibbles and n-nibbles and checks if they are equal one by one. The matching will be regarded as successful if it reaches the end of the input key. However, there could still be some n-nibbles left unmatched.   As 0xbcdef2 is a valid key for proof1, verify(0xbcdef2, 6, proof1) will succeed. However, verify(0xbcdef,  5,  proof1)  will  also  succeed,  even  though  it  does  not  fully  traverse  the nibbles in the Leaf Node. As a result, a partial key can be verified and the caller will get the same value stored in the Leaf Node.  Extension Node: it retrieves the elements from k-nibbles and n-nibbles and check if they are equal one by one. The matching will be regarded as successful if it reaches the first nibble that does not match. However, this implies the following unexpected consequences:   As  n-nibbles  are  stored  in  Span<u64>  in  little  endian,  the  padding  zeros  are  indistinguishable from  valid  0  nibbles.  In  case  the  next  input  nibble  is  0,  it  will  be  accidentally  matched  with  the padding  in  the  Extension  Node,  leading  to  a  failure  when  matching  the  next  node.  For  example, verify(0xabcd0e, 6, proof2) will fail even though proof2 is valid.   An input key that fully skipped the Extension Node nibbles can bypass the matching in the Extension Node  and  be  successfully  matched.  In  contrast  to  the  failure  on  validating  a  legitimate  key  by verify(0xabcd0e, 6, proof2), a forged key 0xab0e which fully skips the Extension Node will succeed in verify(0xab0e, 4, proof2) since it directly matches the Leaf Node.  In summary, the missing length validation between the nibbles remaining and that stored in the Extension Node or the Leaf Node implies:  1. A partial key can be verified by only matching a prefix of nibbles in the Leaf Node.  2. A  legitimate  key  and  proof  may  fail  in  case  a  padding  0  in  an  Extension  Node  is  accidentally  matched with the next nibble in the key.  3. A forged key that skips nibbles of an Extension Node can be verified successfully.    The length of the nibbles stored in the nodes is propagated after RLP decoding and taken into account in MPT verification now:  1. Leaf Node: A partial key no longer works, a check ensures that all nibbles left from the input key  have been matched with all the nibbles stored in the leaf node.  2. Extension Node: The representation of the extension node now additionally contains the number of shared  nibbles.  The  matching  is  now  considered  successful  if  all  nibbles  match  and  the  code moves to the next node. This prevents skipping nibbles of an Extension node (Problem 3) as well as accidentally matching padding zeros in case the next nibble of the key is zero (Problem 2).  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Keccak Discards Leading Zero Bytes in Last",
        "body": " Little Endian Words64  fn  keccak_cairo_words64(words:  Words64)  does  not  work  correctly  in  case  there  are  trailing zeros  in  the  big-endian  input  bytes  (represented  as  leading  zeros  in  the  last  item  of  little-endian Words64).  CS-HRDTCL-001  Herodotus - CairoLib -   13  CorrectnessHighVersion1CodeCorrected        \fFor  example,  the  big-endian  bytes  [0xaaaaaaaaaaaaaabb,  0x653800]  would  be  represented  as [0xbbaaaaaaaaaaaaaa, 0x3865] in Words64. There is no way for function bytes_used_u64 to identify how  many  leading  zeros  should  be  included  since  it  operates  on  the  value.  The  trailing  zeros  are  an important part of the input however, omitting them will lead to a different hash.    Function keccak_cairo_words64 now takes the byte length of the last word (last_word_bytes) as an extra input. Using this the hash can be computed correctly even in case of leading zero bytes.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   MMR: Incorrect Root Update Possible,",
        "body": " Insufficient Peaks Validation  CS-HRDTCL-015  A Merkle Mountain Range struct consists of:  1. last_pos:  the  last  position  (size)  of  the  elements  stored.  The  shape  of  the  Merkle  Mountain  Range as well as the number of peaks can be deterministically computed from the last_pos.  2. root: a hash consists of all peaks and the last_pos.  In  mmr.append(),  peaks.valid()  does  not  check  if  the  length  of  the  input  peaks  is  correct  with respect  to  last_pos.  Given  the  special  construction  in  the  bagging  algorithm  shown  below,  one  can submit left side peaks together with an intermediate Poseidon hash of all right side peaks, which will also pass the peaks validation.  root = H(N , H(P0, H(. . . H(Pi \u2212 2 H(Pi \u2212 1, Pi)))))  For example, if we assume currently there are 4 peaks denoted as [P_0, P_1, P_2, P_3]. One can submit  the  forged  3  peaks  as  [P_0,  P_1,  H(P_2,  P_3)]  to  bypass  the  peaks  validation.  Then mmr.append() will compute the updated peaks and new root according to the wrong former peaks, and the shape of the MMR will be disrupted.  In summary, one can update the root and peaks to wrong values by replacing some right side peaks with intermediate  bagging  results.  The  insufficient  peaks  validation  (peaks.valid())  also  appears  in mmr.verify_proof().  Code partially corrected:  In  the last_pos of the current mmr.  , append() has been updated to ensure the amount of peaks given as input is correct given  In addition, verify_proof() now ensures the length of the given proof matches the expected height of the peak. This however is insufficient and still allows verification against a forged peak (see issue MMR Verify Proof: Different Nodes Can use the same index).    In  peaks given as input is correct.    verify_proof()  now  features  the  same  check  as  append()  to  ensure  the  amount  of  Herodotus - CairoLib -   14  SecurityHighVersion1CodeCorrectedVersion2Version3          \f6.4   Empty Extension and Leaf Nodes  In    of Cairo-lib, mpt.verify() has been changed to support:  1. When  encountering  an  extension  node  that  contains  no  nibbles,  the  function  will  continue  its  process with the subsequent node.  2. In the case where a leaf node has no nibbles and the provided key has been completely processed,  the function will immediately return the node's value.  The Ethereum Yellowpaper states the following on page 21:  CS-HRDTCL-002  Leaf: A two-item structure whose first item corresponds to the nibbles in the key not already accounted for by the accumulation of keys and branches traversed from the root. The hex-prefix encoding method is used and the second parameter to the function is required to be 1.  Extension: A two-item structure whose first item corresponds to a series of nibbles of size greater than one that are shared by at least two distinct keys past the accumulation of the keys of nibbles and the keys of branches as traversed from the root. The hex-prefix encoding method is used and the second parameter to the function is required to be 0.  https://ethereum.github.io/yellowpaper/paper.pdf  These would be 'empty` nodes which don't exist.    The respective conditional branches for empty nodes have been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Incorrect Break Condition in Lazy Decode",
        "body": "  CS-HRDTCL-004  An RLP encoded list (with total length rlp_byte_len = p_len + len) consists of:  1. A prefix that reveals the list type and length of its content, whose length is denoted as p_len.  2. The actual content of the list, whose length is denoted as len.  rlp_decode_list_lazy()  will  decode  only  the  corresponding  indices  of  an  RLP  encoded  list  by reading through the contents of the RLP encoded list and only slice its content if it is a target. However, one of its break condition (check if it reaches the end of the RLP encoding) compares the current cursor (current_input_index)  with  the  partial  len.  As  a  result,  rlp_decode_list_lazy()  may  return with an error due to reading out of bounds even though it hasn't.    The break condition has been corrected with rlp_byte_len.  Herodotus - CairoLib -   15  CorrectnessMediumVersion3CodeCorrectedVersion3CorrectnessMediumVersion3CodeCorrected                \f6.6   Keccak: Unsupported Empty Bytes Input Breaks EVM Equivalence  fn keccak_cairo_words64(words: Words64) does not support empty bytes as input, hence is not equivalent to the EVM's keccak256 opcode.  CS-HRDTCL-003  In  : Empty bytes have been treated as a special hardcoded case, however the hash of empty bytes  returned  is  in  big  endian.  For  all  other  inputs,  this  function  returns  the  hash  calculated  by cairo_keccak(), which returns the hash in little endian representation.    The  function  now  returns  the  correct  value  for  the  empty  input  in  little  endian.  The  description  of  the function has been enhanced to clarify the format of the return value / difference to the EVM opcode.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   MMR Verify Proof: Different Nodes Can Use",
        "body": " the Same Index  In MMR verify_proof(), the user needs to submit:   The  index  of  the  hash  element  to  build  a  direction  array,  that  determine  the  order  (left  or  right)  of  CS-HRDTCL-010  hash when reconstructing the merkle root.   A hash of the to be verified node.   A merkle proof array that reconstruct the root of a merkle trie that contains the node.   MMR Peaks to check if the reconstructed root is one of the peaks.  After it has been ensured that the peaks are valid, the peak based on the given proof, index and hash is calculated:  let peak = proof.compute_peak(index, hash);  However,  the  reconstruction  ends  if  we  have  run  out  of  the  merkle  proof  elements  regardless  of  the direction array. As a result, one index of a node can also be used in the proof of another node in case the shared part is the same.  Herodotus - CairoLib -   16  CorrectnessMediumVersion1CodeCorrectedVersion2DesignMediumVersion1CodeCorrected              \fIn  the  figure  above,  blue  nodes  denote  the  real  MMR  and  the  grey  nodes  are  imaginary  for  building direction array. Knowing that the elements of direction array is consumed in a reverse order, it is obvious that (Poof B, Direction A) can also be used to verify against node 7.  Note this also enables the verification against an intermediate node instead of a leaf node. It may not be a legitimate use case in practice, and external systems using this library should execute caution to avoid this being abused.  The  updated  code  of    ensures  the  provided  proof  has  the  correct  length  and  compares  the computed peak of the element to the specific peak in the list of peaks. The list of peaks however is an input  to  the  function  and  hence  may  be  manipulated.  Although  now  very  restricted,  it's  still  possible  to verify against a forged peak as illustrated in the following example:     verify_proof() has been strengthened: A check now ensures the number of peaks given In  as input is correct given the last_pos of the current MMR. Since MMRs are deterministic, this together with  the  validations  of  the  peaks  (peaks.valid())  ensures  verify_proof()  verifies  against  the correct MMR without forged peaks.  Herodotus - CairoLib -   17  Version2Version3\f6.8   Missing Boundary Check in MPT Verification  Note: This issue was discovered by Herodotus.  When  matching  the  input  nibbles  with  the  nibbles  stored  in  an  extension  node  or  a  leaf  node  (in MPT.verify()), the nibbles stored in the nodes, represented as individually little endian and overall big endian Words64, are read in a special order:  CS-HRDTCL-009   Within one u64, bytes are loaded from right to left.   Within one byte, nibbles are loaded from left to right.   Once it finishes an u64, it will jump to the next u64.  However,  the  jump  in  step  3  does  not  check  if  it  has  reached  the  end  of  the  Words64.  Consequently, MPT.verify() may revert on a valid proof due to reading out of bounds or overflow.    Herodotus has updated the logic of the code to avoid reading out of bounds or overflow.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   Words64TryIntoU256LE Does Not",
        "body": " Automatically Pad Input  CS-HRDTCL-008  Words64TryIntoU256LE  implements  try_into()  to  convert  a  overall  big-endian  and  individually little-endian Words64 (namely Span<u64>) into a little-endian u256. In case the input length is less than 4  u64,  it  will  not  automatically  add  leading  zero  padding  upon  conversion,  and  the  result  may  be incorrect. For example:  1. Assume the original big-endian u256 is 0x11aaaaaaaaaaaaff.  2. If its Words64 representation is an array [0xffaaaaaaaaaaaa11] with length 1.  3. As  Words64TryIntoU256LE  does  not  pad  the  input  array,  the  result  little-endian  u256  will  be  0xffaaaaaaaaaaaa11.  4. If  one  converts   it  back   to  big-endian,  one  will  eventually  get  a  much  bigger  value:  0x11aaaaaaaaaaaaff000000000000000000000000000000000000000000000000.    Words64TryIntoU256LE has been removed and the following functions have been added to facilitate the conversion between endianess with different bytes length:  fn as_u256_le(self: Words64, bytes_used: usize) -> Result<u256, felt252>; fn as_u256_be(self: Words64, bytes_used: usize) -> Result<u256, felt252>;  Herodotus - CairoLib -   18  CorrectnessMediumVersion1CodeCorrectedCorrectnessMediumVersion1CodeCorrected                  \f6.10   Bit_Length Will Revert if Input Most Significant Bit Is 1  bitwise::bit_length()  computes  the  result  by  finding  the  first  n  that  2^n  is  larger  than  the  input number.  Consequently,  if  the  input  number  of  type  T  has  1  on  the  most  significant  bit,  and  type  T implements overflow protections, bit_length() will revert due to 2^n overflows type T. For example, to measure the bit length used for 128_u8, it will compute 2^8 in the last round and revert by overflowing u8.  CS-HRDTCL-006    The code has been corrected to measure the bit length by iteratively dividing the input by 2.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.11   Right Shift Reverts on Bit Length Input",
        "body": "  bitwise::right_shift(num, shift) will divide the number by two to the power of shift (computed by  bitwise::pow()).  pow()  accepts  the  input  of  type  T  and  returns  the  result  in  the  same  type  T. Consequently,  right_shift()  will  revert  in  case  shift  >=  bit_length(max(T))  and  type  T implements overflow protection, since the return value of pow() overflows type T . For example, in case the input number is of type u32, right_shift() will revert if shift==32 since 2^32>max(u32).  CS-HRDTCL-007    Code  has  been  changed  to  achieve  right  shift  by  dividing  input  number  by  2  iteratively  instead  of computing pow().  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.12   Fast Power May Improve Gas Efficiency",
        "body": "  The  current  implementation  of  bitwise::pow()  has  a  time  complexity  O(n).  A  fast  power implementation only requires O(log(n)) time complexity and may improve gas efficiency.  CS-HRDTCL-014    A fast power (fast_pow()) implementation has been added. In addition, bitwise::pow() has been changed to execute slow_pow() if the exponential is below 16, otherwise, it will execute fast_pow().  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.13   Order of Evaluation Can Be Enforced",
        "body": "  Herodotus - CairoLib -   19  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected                          \fAt  the  time  of  this  review,  there  is  no  Starknet  official  documentation  of  the  order  of  expressions evaluation.  In  words64::Words64TryIntoU256LE,  the  execution  order  of  the  following  code  is  not guaranteed  to  be  always  from  left  to  right.  Explicit  brackets  can  be  used  to  enforce  the  order  of evaluation.  CS-HRDTCL-011    Explicit  brackets  have  been  added  in  words64::Words64TryIntoU256LE  to  enforce  the  evaluation order.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.14   Unused Import",
        "body": "  words64.cairo imports bitwise::right_shift, however, it is never used.  CS-HRDTCL-012    The unused import has been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.15   Words64TryIntoU256LE Reverts in Case of",
        "body": " Empty Input  Words64TryIntoU256LE implements try_into() to convert a Words64 (namely Span<u64>) into a u256. In case the input exceeds 256 bits, it will return an Option::None. Moreover, it does not accept empty span as input, and will reverts in this case.  CS-HRDTCL-013  In   , Words64TryIntoU256LE has been adjusted to return 0 in case the input is empty.    In  endianness for variable input length.  , two functions (as_u256_le and as_u256_be) facilitate the conversion between different  Herodotus - CairoLib -   20  InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrectedVersion2Version3            \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Lazy Decode Returns Items With Ascending",
        "body": " Indices  rlp_decode_list_lazy(input:  Words64,  lazy:  Span<usize>)  will  iterate  the  items  in  the input  (RLP  encoded  list)  and  append  the  item  to  the  output  array  in  case  the  current  index  is  in  the required indices list (lazy). As a result:   Duplicated indices in (lazy) will only be counted once.  In  the  output  array,  the  items  will  be  in  an  ascending  order  according  to  their  indices  in  the  input array, and irregardless of their positions in the input array (lazy).  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Left Shift May Revert Due to Overflow",
        "body": "  bitwise::left_shift() computes the result by multiplying the input of type T with two to the power of shift. In case type T implements overflow protection for trait TMul, the result must also fits within type T, otherwise it will revert due to overflow.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   MPT Verify Can Not Get the Value in the Root",
        "body": " Branch Node  A  branch  node  can  store  16  hashes  of  the  children  nodes  and  one  value.  In  case  the  root  node  is  a branch  node,  theoretically  we  should  be  able  to  retrieve  the  value  stored  inside.  Whereas mpt.verify()  does  not  support  this  and  would  revert  due  to  underflow  when  computing  key_pow2. Though this shouldn't be a practical use case in Ethereum.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   Missing Length Information of Type Words64",
        "body": "  A customized type Words64, as an alias of Span<u64>, is defined and heavily used across the library. In most cases, it is used to store bytes, however, the length of bytes within each u64 is missing. As a result, the leading valid zeros bytes in u64 is indistinguishable from padding in bytes_used_u64. This has lead to various problems e.g. in keccak256 and MPT verification.  Within CairoLib and Herodotus on Starknet the project this library has been build for, length information of  data  stored  in  Words64  is  handled  separately  throughout  the  codebase.  Other  users  of  the  library must be aware and handle this correctly.  Herodotus - CairoLib -   21  NoteVersion3NoteVersion1NoteVersion1NoteVersion1               \f7.5   RLP Decode Will Discard Garbage Bytes  rlp_decode()  will  only  read  and  decode  bytes  according  to  the  length  that  is  encoded  in  the  input prefix. In case there are trailing garbage bytes, they will be discarded and rlp_decode() will not revert.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.6   Reverse Endianness U64 Reverts if Significant",
        "body": " Bytes Are Larger Than 8  reverse_endianness_u64() will reverse the endianness of a u64 given the significant bytes the user wants to reverse. There is no restrictions on the significant bytes, in case the significant bytes are larger than  8,  pow2()  will  return  0  in  the  last  iteration  of  the  loop  and  reverse_endianness_u64()  will revert due to division by zero.  Herodotus - CairoLib -   22  NoteVersion1NoteVersion1        \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Problems Related to Consent and",
        "body": " ConsentVerification  The consent ECDSA signature that the depositor needs to provide has the following design issues:  1. When Alice wants to deposit 100 wei ERC20 token from Optimism to Bob on mainnet, she has to sign EIP712 hash of Consent(Bob, 100, \"\"). However, the same signature she has to provide if Alice wants to deposit 100 ERC20 token from Polygon to Bob. This signature does not contain any  information  about  origin  domain.  Only  address  of  ConsentVerification  contract  on  the destination chain is taken into account.  2. Only EOA addresses are able to sign data. Multisig wallets or any other smart contract addresses won't be able to provide a consent signature. This limits potential integrations of SRG with the other systems  3. Consent itself is redundant. Both ERC20Gateway and savETHGateway allow only deposits when msg.sender == ownerGivingConsent. Thus, only Alice will be able to insert the deposit leaf into Accumulator. Check that deposit is inserted into the Accumulator tree can be seen as an \"Alice wanted to transfer funds to Bob\" check. In addition, deposit leaf insertion contains more information and thus is a stronger constraint.  4. CONSENT_TYPEHASH violates the EIP712 specification. The type of a struct must be encoded as name || \"(\" || member_1 || \",\" || member_2 || \",\" || \u2026 || member_n \")\" where each member is written as type || \" \" || name. The CONSENT_TYPEHASH doesn't have member names.  Blockswap - SRG -   15  DesignCorrectnessCriticalHighMediumAcknowledgedLowAcknowledgedAcknowledgedAcknowledgedAcknowledgedAcknowledgedAcknowledgedDesignMediumVersion1Acknowledged          \f5. ConsentVerification.computeTypedStructHash  violates  the  EIP712  specification.  Each  encoded member value must be exactly 32-byte long. abi.encodePacked will encode address _paramOne as 20-byte long.  Acknowledged:  Blockswap responded:  We will be addressing these as part of the transportation layer upgrade we mentioned in the call  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Finalization of Extension Can Stuck",
        "body": "  Once  deposit  or  pokeLatestBalance  functions  get  called,  they  need  to  be  finalized  on  the destination  domain,  using  push  and  balanceIncrease  functions.  However,  this  second  call  can  be \"stuck\".  The  SRG  system  does  not  offer  users  any  way  to  recover  stuck  funds.  Some  reasons  can  be user  mistakes,  e.g.  user  deposited  to  addresses  nobody  has  control  over  on  their  destination  domain. However, more serious are issues where origin domain functions do not perform strict enough verification of the parameters.  For example:  1. Consent verification relies on OZ library that enforces s-value of v,r,s tuple to be in the lower range of  secp256k1n  curve.  In  general,  ecrecover  percompile  supports  both  high  and  low  s-value signatures. During the deposit function call, only the v-values are constrained.  2. If batch staking rule constant is misconfigured, a check on deposit might be satisfied, while during  the push the amountExtended value can be too small.  Acknowledged:  Blockswap responded:  Users should always be able to verify their transactions before signing to ensure funds are not locked much like when interacting with a single blockchain and ensuring things like recipient are correct etc.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   Missing Status by",
        "body": " EndorserLifecycleStatusUpdated  When  the  event  EndorserLifecycleStatusUpdated  gets  emitted,  it  just  indicates  the  status  of  a given endorser has been updated, without containing any further information about its current status. As a better practice, the current status of the endorser can be embodied in this event.  Acknowledged:  Blockswap responded:  Indexers can read the state of the contract at the time of event emission. We will address this later  Blockswap - SRG -   16  DesignLowVersion1AcknowledgedDesignLowVersion1Acknowledged                  \f5.4   Pausing and Unpausing Emit Misleading Events  Some functions, which perform the state transitions of the Gateway contract do not check, whether the contract is already in the needed state:   pauseGateway   unpauseGateway   pauseDomain   unpauseDomain  As a result, repeated calls to these functions will have no effects on the state but will trigger an event. Some of these functions also do not check, whether the killswitch was triggered for this domain. Thus, pauseGateway after triggerKillSwitch can be called.  Acknowledged:  Blockswap has acknowledged the issue without fixing it, responding:  We are ok with this. contract storage should always be checked for the source of truth  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.5   RPBS _isOnCurve Infinity Point",
        "body": "  Most  of  the  bn128  libraries  consider  that  the  infinity  point  belongs  to  the  curve.  The  _isOnCurve function does not.  Reference:   Ethereum   Clearmatic bn256  Acknowledged:  Blockswap  has  acknowledged  that  their  implementation  does  not  follow  the  implementation  of  bn128. Blockswap responded:  We will be addressing these as part of the transportation layer upgrade.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.6   Repeated Pokes",
        "body": "  For  a  single  pokeLatestBalance  action,  the  balanceIncrease  finalization  can  be  done  multiple times.  Only  the  first  balanceIncrease  will  have  an  effect.  All  other  calls  will  result  in  no  balance update, however, the poke leaf will still be inserted in the Accumulator. In theory, an attacker can spam this transaction to deplete all the leaves in the Merkle tree.  Acknowledged:  Blockswap - SRG -   17  DesignLowVersion1AcknowledgedCorrectnessLowVersion1AcknowledgedDesignLowVersion1Acknowledged                      \fBlockswap responded:  We will add a spam mitigation strategy later.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.7   saveETHManager.init Is Not Defined in",
        "body": " ISavETHManager  In StakeHouseUniverseDestinationGateway.init an ERC1967 Proxy gets deployed for the logic contract  _saveETHManagerLogic.  However,  when  encoding  _data  input  field  for  the  constructor  of ERC1967, it assumes  1. init function is implemented for savETHManager, although not defined in ISavETHManager  2. init   savETHManager  savETHDestinationReporter.init, which might be invalid assumption.  function   exact   has   the   of   same   layout   as  These assumptions can be wrong.  Acknowledged:  Blockswap has acknowledged it, claiming that calling this function from external users is not encouraged.  Blockswap - SRG -   18  DesignLowVersion1Acknowledged          \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings   Cost of bytesToHex    ERC20 Token Decimals   Inconsistent DepositEvent Amount Units    batchDeposit Reverts if the Lengths of Input Arrays Match   -Severity Findings   EIP165 Interface Implementation Check Is Not Fully Correct    Sandwich Attack Without MEV Services    Deployed Event of Gateway Is Not Informative    whenGatewayAndPushNotKilled Specification Mistmatch    dETH Dispensers Are Not a IsavETHDispenser   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Cost of bytesToHex",
        "body": "  0  0  4  5  The bytesToHex is used to convert bytes to hex string. The only reason for this is to be compliant with the elliptic-js library. The bytesToHex is an extremely inefficient on-chain. Such conversions on-chain are  strongly  discouraged.  They  are  computationally  expensive  and  may  lead  to  gas  exhaustion.  This does not pose a direct security risk, but it lowers the overall usability and scalability of the contract.    The RPBS-sol package now operates with the bytes representation directly, without conversion to hex. The  new  function  encodePoint  is  used  in  the  assessed  contracts  instead  of  encodePointHex function.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   ERC20 Token Decimals",
        "body": "  The  GatewayToken  contract  inherits  from  ERC20Upgradeable  fixed  decimals  of  18.  In  general,  this might be not the same as the original token decimals. As a result, this might break UIs that will deal with such bridged tokens. Also, protocols that rely on decimals might have problems with compatibility.  Blockswap - SRG -   19  CriticalHighMediumCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedLowCodeCorrectedSpeci\ufb01cationChangedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedDesignMediumVersion1CodeCorrectedDesignMediumVersion1CodeCorrected                 \f  The GatewayToken.decimals now returns a variable that can be set in the init function.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Inconsistent DepositEvent Amount Units",
        "body": "  The  ERC20Gateway.deposit  function  users  provide  the  amount  of  tokens  to  extend  as  a BaseInputParams.paramTwo in wei. This param in wei will contribute to the deposit leaf hash. Same paramTwo  in  wei  will  be  emitted  in  DepositEvent.  On  the  destination  domain  recipient  will  need  to specify the same paramTwo in _depositMetadata.baseDepositInfo.paramTwo.  However, this is not consistent with savETHGateway. In savETHGateway.deposit the user provides the KNOT that he wants to migrate. The savETHRegistry.knotDETHBalanceInIndex in gwei of this KNOT will contribute to the deposit leaf hash. But the knotDETHBalanceInIndex in wei will be emitted in Deposit tx. On push, _depositMetadata.amount in gwei will be converted to wei and the savETH on the destination domain will be minted. In summary, inconsistency is that units of event do not match the  value  from  _depositMetadata.amount  and  the  deposit  leaf  hash.  Assuming  that  the  endorsers will be querying the depositMetadata for the attestation, an extra conversion of deposit event values will be needed for one of these cases to compute the hash of the RPBS info.    Blockswap  has  successfully  resolved  this  inconsistency  in  various  parts  of  the  codebase  (both dispensers and ingestors).  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   batchDeposit Reverts if the Lengths of Input",
        "body": " Arrays Match  To  batch  deposit  a  set  of  transactions  to  their  corresponding  domains  given  suitable  input  params  for each deposit, the input arrays should have the same length. However, in the implementation:  uint256 numOfElements = _transactionSummaries.length; if (numOfElements == 0) revert EmptyArray(); if (numOfElements == _domainIds.length) revert InconsistentArrayLengths(); if (numOfElements == _baseParams.length) revert InconsistentArrayLengths();  Which  means  a  correctly  formed  input  will  not  be  handled.  The  functionality  of  all  functions  must  be tested before deployment.    Conditions were fixed. Now all 3 input arrays of the batchDeposit function required to be of the same length.  Blockswap - SRG -   20  DesignMediumVersion1CodeCorrectedCorrectnessMediumVersion1CodeCorrected                  \f6.5   EIP165 Interface Implementation Check Is Not Fully Correct  According to eip-165, to detect that contract implements ERC-165, the source contract needs to make 2 calls.  First  call  -  to  check  that  IERC165  is  supported.  Second  call  -  to  check  that  the  invalid  interface 0xffffffff is not supported.  However,  the  Gateway._assertModuleAdheresToERC165Interface  function  only  performs  the first call.  Source: https://eips.ethereum.org/EIPS/eip-165#how-to-detect-if-a-contract-implements-erc-165    A  check  has  been  added  to  ensure  that  a  module  supporting  IERC165  does  not  support  an  invalid interface.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Sandwich Attack Without MEV Services",
        "body": "  The savETHRegistry has the following arbitrage opportunity, that bots can profit from: if a bot sees fees being to a KNOT, that belongs to an open index, a bot can sandwich this mintDETHReserves function call by 2 transactions: isolateKnotFromOpenIndex and addKnotToOpenIndex. This way, bot will get ownership of the KNOT that will have fees minted. As a result, the savETH rate won't increase. To execute  this  sandwich  attack  on  the  mainnet,  the  bot  needs  access  to  MEV  service.  However,  on  the destination domains, with the help of the poke function bots can steal fees from the open index without such  services.  The  bot  just  needs  to  have  a  smart  contract  that  sandwiches  balanceIncrease  the same  way  as  mintDETHReserves.  Since  balanceIncrease  in  a  mintDETHReserves  on  a destination domain without access control, this is possible.  Specification corrected:  Users,  who  put  the  KNOT  into  an  open  index  voluntarily,  accept  the  lower  fees  (potentially  0).  In exchange, they get liquid assets that can be traded. Any actor is encouraged to perform balance updates (such as mintDETHReserves). The MEV sandwich described in this issue is seen as an arbitrage from that perspective. Hence, no fixes are needed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Deployed Event of Gateway Is Not Informative",
        "body": "  After initialization of a gateway through __Gateway_init, a mere event Deployed is emitted without any arguments. This event does not contain any parameters. Since it is used in the proxy initialization, this event increases the bytecode size of the deployed contract.  Specification corrected:  Blockswap responded:  Blockswap - SRG -   21  CorrectnessLowVersion2CodeCorrectedDesignLowVersion1Speci\ufb01cationChangedDesignLowVersion1Speci\ufb01cationChanged                      \fAfter  an  event  is  emitted,  all  contract  states  can  be  read  directly  from  a  node  saving  deployment costs from not emitting data in events.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   whenGatewayAndPushNotKilled",
        "body": " Specification Mistmatch  As the name of the modifier suggests, not only should the gateway be operational, but also push for the foreign domain should not be killed. However, this modifier performs the following checks:  if (!domainMetadata.operational && isPushKilled[_domainId]) revert DomainOperationsArePausedOrKilled();  It  means  the  scenarios,  in  which  either  domain  is  not  operational  or  is  killed,  the  modifier  reverts.  To make it comply with the specification, an OR operator instead of AND should be used.    the  ||  The  &&  operator  was  the whenGatewayAndPushNotKilled will not revert only when the domain is operational and push is not killed on the domain.  if  condition  above.  Now   replaced  by   the   in   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   dETH Dispensers Are Not a IsavETHDispenser",
        "body": "  The savETHGateway uses IsavETHDispenser to communicate with dETHDestinationDispenser and dETHOriginDispenser. However those contracts do not implement the aforementioned interface. Change of the code can break compliance with the interface, that will not be reported by the compiler.    dETHDestinationDispenser  and  dETHOriginDispenser  contracts  now  IsavETHDispenser interface.  implement   the  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   RPBS Endorsement Expiry",
        "body": "  Function  verify  in  RPBSVerificationLibrary  fetches  the  first  endorsement  and  verifies  that  it  is not expired require(signatureExpiry > block.timestamp, \"Signature expired\"). Then, it iterates over the array of endorsements and checks that all of them have the same expiry time as the first endorsement. Though correct, it obliges the endorsers to agree on a common signature expiration. What is the expiration definition procedure and how do endorsers guarantee that this expiration will be the same for all signatures?    In    of the code each Endorser need to specify its own expiry period.  Blockswap - SRG -   22  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedInformationalVersion1CodeCorrectedVersion3                      \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Endorser Setting Change",
        "body": "  First,  the  change  of  the  Endorser  status  from  ACTIVE  to  any  other  status  will  result  in  a  revert  of  the pending push and balanceIncrease transactions if they were endorsed by the deactivated Endorser, while it was still active.  Second,  the  increase  of  the  numberOfEndorsementsRequired  threshold  can  cause  similar  in-flight message failure.  Acknowledged:  Blockswap responded:  As long as the user can re-submit the transaction, then there is no issue.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Gas Optimisation",
        "body": "  The  codebase  has  several  inefficiencies  in  terms  of  gas  costs  when  deploying  and  executing  smart contracts. Here, we report a list of non-exhaustive possible gas optimizations:  1. The modifier Gateway.whenGatewayAndDomainNotPausedOrKilled loads information about a specific domain Id to the storage and later reads the underlying information from storage, which is quite inefficient.  2. ERC20Gateway._assertConsumptionAuthorised   reverts   msg.sender  !=  _baseParams.ownerGivingConsent.  However,  performed in _consume function, before calling to _assertConsumptionAuthorised.  the  same  check   if is  3. Gateway.injectForeignDomainCheckpoint  checks   the dispenser and then calls into Dispenser.injectForeignDomainCheckpoint which performs the exact same check.  that  recovery   is  enabled   for   4. Gateway.batchDeposit iterates through every deposit in a list and calls to Gateway.deposit which  solely  calls  into  Gateway._consume.  By  calling  _consume  directly  from  batchDeposit gas can be saved.  5. Once  Gateway.batchDeposit  directly  calls  to  _consume,  the  visibility  of  Gateway.deposit  can also be changed to external.  6. Gateway._dispense, in case of recovery not being enabled, performs a multitude of checks (e.g. validating  consent  signature,  asserting  dispense  being  authorized,  and  finally  dispensing  in  the dispenser module). After all of these gas expensive operations, it checks whether UTXO is already spent  or  not.  In  case  of  an  attempt  to  use  spent  UTXO  the  revert  will  happen  late  in  execution. Moving this check earlier would consume less gas in this scenario.  Blockswap - SRG -   23  InformationalVersion1AcknowledgedInformationalVersion1Acknowledged          \f7. Gateway._dispense, in case of recovery being enabled, checks that a non-zero recovery Merkle root  has  been  injected.  Later,  it  calls  to  dispenseViaRecovery  of  the  dispenser,  which  again assures that the recovery Merkle root is injected.  8. Domain.dispense, checks isRecoveryEnabled, however, Gateway will only call this function if it  is not set.  9. ConsentVerification.validateConsentSignature  is  defined  as  public  but  never  used  internally. Its visibility can be changed to external to save gas.  10. Both   functions   and _onlyValidStakeHouseKnot  in  savETHRegistryDestinationGateway  have  the  exact same functionality, only with different naming. It makes bytecode of the contract larger; hence, the deployment costs would be more expensive.  _onlyStakeHouseKnotThatHasNotRageQuit   11. Gateway.deposit can increase userConsentNonce without the use of the safemath.  12. The  fields  in  the  Domain  struct  from  the  IGateway  can  be  benefit  from  tight  variable  packing  patterns.  13. The  balanceIncrease  function  checks  that  accumulator  of  the  the  domain  is  not  0.  The  same check is performed in the whenGatewayAndDomainNotPausedOrKilled modifier of the same function.  14. Many functions of the savETHGateway query saveETHRegistry from the universe multiple times  in the same function.  Acknowledged:  Blockswap will consider these optimizations later and apply changes when needed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Hash Function Consideration",
        "body": "  The SRG uses sha256 function in multiple places. For example, in the Accumulator Merkle tree contract and for computation of certain constants like DEPOSIT_TYPE_HASH. While the original ETH2.0 Beacon staking  contract  uses  the  aforementioned  hash  function,  the  main  reason  for  that  was  an  assumption, that  node  software  will  be  implemented  in  languages  that  do  not  have  well-established  analog  for keccak256 function.  In  EVM  sha256  is  a  precompiled  contract,  and  calling  into  it  is  more  expensive  than  the  opcode keccak256.  sha256  is  twice  more  expensive  than  keccak256  based  on  gas  params.  This  cost difference  also  does  not  include  overhead  for  creating  memory  layout  for  the  STATICCALL  to  the precompiled contract.  Acknowledged:  Blockswap responded to the issue as:  We will look into the optimisations and consider them as and when needed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   Recovery Merkle Tree Considerations",
        "body": "  Blockswap - SRG -   24  InformationalVersion1AcknowledgedInformationalVersion1Acknowledged            \fTo enable recovery, a domain must be killed first. Once it will be killed, some state extension messages can stuck in-flight, meaning that the deposit tx happened on one domain, but the push for that deposit did not happen on the other domain. Consider the scenario, in which Alice has issued a deposit on mainnet chain to Bob on the Optimism chain. This extension is in-flight and still not pushed on Optimism. If then Optimism will be killed on Mainnet, this transaction must be considered during the Recovery Merkle Tree computation, even if Bob never pushed this on Optimism.  A similar case happens when Bob has issued a deposit from Optimism to Alice on mainnet chain. If then Optimism will be killed on Mainnet, this transaction must be considered during the Recovery Merkle Tree computation, if Alice did not push this on Mainnet before the recovery activation.  Acknowledged:  Blockswap mentioned in the response Doc, that this is by design.  Blockswap - SRG -   25  \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Asset Flow per Time Limit",
        "body": "  The SRG system consists of multiple gateways on different chains. If a certain chain gateway is hacked, e.g.  invalid  state  is  inserted  into  Accumulator,  the  attacker  can  use  connections  between  gateways  to extend the bad state to the other chains. As a result, a system as a whole depends on the security of any of its components. Limits like \"extension of X tokens per day is allowed\" can limit the effect of bad state spread and give time for reactive measures.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Checked Properties",
        "body": "  Certain  invariants  of  Blockswap  SRG  system  were  checked  during  this  assessment  or  explicitly considered:   GatewayToken needs to be deployed with the same decimal value as the original token.   ERC20  Gateway  is  capable  of  handling  simple  ERC20  tokens.  Any  special  tokens  need  to  be  wrapped. Consider this list: https://github.com/d-xo/weird-erc20   Tree leaf of the Recovery Merkle tree should never be made of 64 bytes. Intermediate nodes might become claimable due to the collisions with the total length of leaf components matching the length of  See: https://github.com/OpenZeppelin/openzeppelin-contracts/issues/3091  concatenated   hashes.   two    To prevent cross-domain replays any leaf inserted into the accumulator needs to contain origin and  destination chain ids, and origin and destination gateway addresses.   Any kind of leaf that is inserted into Accumulator needs to have a unique prefix like TYPE_HASH to  prevent collisions with other leaf types.   The  total  supply  of  ERC20  tokens  minted  on  some  destination  domain  should  equal  the  totalExtended value of the origin domain on this destination domain.   The  total  supply  of  ERC20  tokens  minted  on  some  destination  domain  should  equal  the  totalExtended value of this destination domain on the origin domain.   Balances  or  KNOTs  deposited  from  the  origin  domain  can  always  be  pushed  on  the  destination  domain, assuming both domains are not paused/killed.  In  case  of  ERC20:  ERC20OriginDispenser  must  be  ERC20DestinationIngestor must be the burner of GatewayToken.  the  minter  of  GatewayToken.  In the case of ERC20: the sum of leaf amounts in the Recovery Merkle tree should always equal the origin's totalExtended value of the recovered domain.  In the case of dETH: the set of leaf KNOTs in the Recovery Merkle tree should always be the same as  KNOTs  that  belong  to  the  destination  index  on  the  origin  domain.  No  leaf  should  contain  the same KNOT twice.  Such invariants need to be considered during future updates.  Blockswap - SRG -   26  NoteVersion1NoteVersion1         \f8.3   Handling ERC20 With Access Control Functionality  Some  ERC20  tokens  can  ban  certain  addresses  from  sending  and  receiving  the  tokens,  e.g.  USDC. Assume a scenario, where Alice deposits USDC tokens from Optimism back to the mainnet. Upon push, the receiver of USDC on the mainnet chain might be blacklisted. In this scenario, Alice's tokens will be locked and the push transaction will revert.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.4   Restrictive Partially Blind Signatures (RPBS)",
        "body": " Do Not Contain Unknown Blind Data  The  blinded  message  of  RPBS  contains  only  the  Merkle  tree  proof.  However,  the  common  RPBS  info contains  depositLeafIndex,  gatewayRoot  and  accumulatorCount.  Endorsers  even  without  knowing  the actual data in a blinded message, in the current version of the code Endorsers can recompute the proof themself. This can potentially be used by Endorsers to censor the depositor. In addition, RPBS schema does  not  bring  any  benefit  compared  to  more  simple  ECDSA  signatures.  Effectively  no  blinding  is happening.  Assuming RPBS schema will be used in future versions of the systems, where the blinded data will be used, developers must be careful with what is being blinded.  If the entropy of the blinded data is not great, e.g. the deposit leaf index is blinded, the Endorsers still can randomly guess what data is being blinded. For example with the deposit leaf index - not many indexes can potentially be pending. A source of entropy can be included in the blinded message, which will make guessing impossible.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.5   knotDETHBalanceInIndex Change Will Revert",
        "body": " Pending Transaction  The  txSummary  of  the  savETHGateway  deposit  should  include  the  knotDETHBalanceInIndex. However, the change in this value can cause pending deposits to revert. Such increases can be caused by mintDETHReserves and balanceIncrease function calls. Please note that balanceIncrease is an  unrestricted  function.  Since  the  events  of  balance  increase  are  assumed  not  to  be  frequent,  the likelihood of this problem is small.  Blockswap - SRG -   27  NoteVersion1NoteVersion1NoteVersion1            \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Emergency Resolution Mechanism Possibly",
        "body": " Not Sufficient  NegRiskOperator allows the admins of the contract to flag a question after it has been reported by the oracle. With the function emergencyResolveQuestion(), the admins are then able to set a different outcome for the respective question. This is required for several edge cases:  CS-PMNRA-001  1. All questions of a market resolve to NO.  2. More than one question of a market resolve to YES.  Questions are, however, not resolved all at once. Some markets might contain questions that resolve one after  another  with  prolonged  time  periods  in  between.  In  this  case,  the  above  cases  might  become evident  only  after  some  questions  have  already  been  resolved  and  their  corresponding  tokens  been redeemed.  For  example,  a  problem  in  a  market  in  which  all  questions  ultimately  resolve  to  NO  might  only  be discovered  when  the  last  question  resolves  to  NO.  In  this  case,  holders  of  NO  tokens  in  the  already resolved questions have already redeemed their tokens. The admins now have two/three possibilities:  1. Let the last question resolve to NO which invalidates the position of users that previously converted  their NO tokens to YES tokens using convertPositions().  2. Wrongly resolve the question to YES which invalidates the position of users that hold NO tokens of  the last question.  3. Add more questions to the market (e.g., possible in \"event happens at X\" kind of markets) which  traps collateral in the CTF contract (see Question preparation at later point for details).  Risk accepted:  Polymarket accepts the risk with the following statement:  Polymarket - NegRiskAdapter -   11  DesignCriticalHighMediumLowRiskAcceptedDesignLowVersion1RiskAccepted         \fIt is our opinion that for certain markets, the risk is acceptable that all questions resolve NO. It is true in  that  case  that  certain  funds  may  be  locked;  however,  users  are  fully  aware  of  their  net  position before and after a convert operations, so these locked funds are not user funds.  Polymarket - NegRiskAdapter -   12  \f6   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   No Safe ERC-20 Approval",
        "body": "  NegRiskAdapter calls the collateral token's approve() directly without a check of the return value. If the  chosen  collateral  token  does  not  revert  in  this  function  call,  it  is  possible  that  the  contract  can  be deployed without the correct approval being set up.  CS-PMNRA-002  Risk accepted:  Polymarket accepts the risk with the following statement:  In  the  unlikely  event  that  some  version  of  these  contracts  is  planned  to  be  deployed  with  such  an ERC20 collateral token, it would be immediately evident, giving minimal testing, that the approvals were not set properly.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Outcome Reporting Batch Function",
        "body": "  Since  many  markets  in  the  NegRiskAdapter  can  contain  questions  that  resolve  at  the  same  time,  a batch function for reporting outcomes might make sense.  CS-PMNRA-003  Risk accepted:  Polymarket accepts the risk with the following statement:  Batch reporting is a challenge due to the nature of the oracle requests. In the future, we would be interested in integrating an oracle solution which can accommodate the multi-outcome nature of neg risk markets.  Polymarket - NegRiskAdapter -   13  InformationalVersion1RiskAcceptedInformationalVersion1RiskAccepted          \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Market ID Equal to First Question ID",
        "body": "  NegRiskAdapter  creates  market  IDS  by  hashing  the  oracle  address,  the  fee  in  BPS  and  some metadata and then setting the rightmost 8 bits to 0. Such IDs are then used to create question IDs by adding the index of the question to the reserved 8 bits. Since the first question has index 0, its ID is equal to the market ID.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Question Preparation at Later Point",
        "body": "  NegRiskAdapter  (and  NegRiskOperator)  allow  to  create  a  market  and  then  successively  add questions  to  the  market.  This  means  that  further  questions  can  also  be  added  to  the  market  at  a  later point  in  time.  This  is  problematic  if  convertPositions()  for  this  market  has  already  been  used successfully before the new question is added. Consider the following example:  1. A market consists of three questions A, B and C.  2. For each question, 100 tokens of each outcome have been minted. A total of 300 collateral tokens  have been deposited into the CTF contract.  3. A  user  owns  100  B-NO  and  100  C-NO  tokens.  They  decide  to  convert  these  tokens  using convertPositions() which burns their NO tokens, mints 100 A-YES tokens and transfers 100 collateral tokens to the user.  4. An admin adds a new question D to the market for which 100 collateral tokens are split into 100  D-YES and 100 D-NO tokens.  5. D resolves to YES.  6. 100  D-YES  tokens,  as  well  as  100  A-NO  tokens,  can  be  redeemed  for  200  collateral.  No  other  tokens are eligible and yet, the contract holds 300 tokens in collateral.  This  shows  that  questions  that  have  been  added  after  a  convertPositions()  call  can  trap  tokens inside the CTF contract if they resolve to YES.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Short Reporting Delay",
        "body": "  NegRiskOperator  defines  a  DELAY_PERIOD  that  gives  the  admins  of  the  contract  time  to  interfere after  the  oracle  has  submitted  invalid  outcomes.  The  period  is  currently  set  to  1  hour.  It  is  therefore imperative  that  Polymarket  has  set  up  a  robust  reporting  and  emergency  reaction  infrastructure  to  be able to always act on problems in this short timeframe.  Polymarket - NegRiskAdapter -   14  NoteVersion1NoteVersion1NoteVersion1          \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Aave V3 Supply Cap May DOS the D3M",
        "body": "  The introduction of Aave V3 introduced several new possibilities (compared to Aave V2). However, there are some supply-limiting parameters in the V3 system. Namely, the supply cap was introduced. Note that the no plan usable for Aave V3 considers this parameter. Hence, the D3M could try to supply more than possible  to  Aave  V3.  Ultimately,  the  regular  D3M  mechanics  of  depositing  and  withdrawing  could  be temporarily locked.  ISSUEIDPREFIX-001  Code partially corrected:  The supply logic could have imprecise logic for the supply cap. Namely, before validating against supply (accruedToTreasury  and caps,  Aave  V3  updates  certain  variables  before  liquidityIndex from what we see) that can influence its result.  the  check   Risk accepted:  MakerDAO replied that it is not planned to set supply caps for the DAI market on SparkLend.  MakerDAO - Direct Deposit V2 -   13  DesignCorrectnessCriticalHighMediumCodePartiallyCorrectedRiskAcceptedLowRiskAcceptedAcknowledgedCodePartiallyCorrectedAcknowledgedAcknowledgedAcknowledgedAcknowledgedDesignMediumVersion1CodePartiallyCorrectedRiskAccepted                    \f5.2   Aave Pool Size Manipulation  To calculate the amount to be deposited into the Aave pool to reach the target interest rate is computed in D3MAavePlan.getTargetAssets*() by computing the difference of target pool size computed and the current pool size. However, estimation of the current pool size  ISSUEIDPREFIX-002  uint256 totalPoolSize = dai.balanceOf(adai) + totalDebt;  is  prone  to  manipulation.  Note  that  Aave  offers  flashloans  that  do  not  update  the  debt.  Hence,  it  is possible to manipulate the pool size and hence the amount moved into the pool by first flashloaning on Aave and then calling exec().  Risk accepted:  MakerDAO responded:  This is a concern we discussed at-length during our internal review. We have identified several scenarios where the D3M could be manipulated in this way.  The high level conclusion we came to in our internal review was that such a manipulation would 1) likely not have a high impact to the system and 2) would be relatively short lived.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   Disable Plan Without Event",
        "body": "  The disable function of both, D3MAavePlan and D3MCompoundPlan sets the target interest rate to 0 and emit the Disable event.  Both contracts feature a file function which allows to set the target interest rate to 0 without the Disable event being emitted.  ISSUEIDPREFIX-003  Acknowledged:  The \u201cDisable\u201d event is emitted when the contract is disabled using the disable function. This function can be called permissionlessly if the plan leaves the active state.  When the Maker governance uses the file function to set bar to 0, the \"File\" event is emitted. This pattern matches the pattern elsewhere in Maker contracts when parameters are changed by authorized users.  Analysts monitoring the contract for shutdown will need to look for both Disable() and File(\u201cbar\u201d, 0) in their event parsing scripts.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.4   Inconsistencies",
        "body": "  MakerDAO - Direct Deposit V2 -   14  ISSUEIDPREFIX-004  CorrectnessLowVersion3RiskAcceptedDesignLowVersion3AcknowledgedDesignLowVersion3CodePartiallyCorrectedAcknowledged                        \fSimilar contracts differ at similar places but could be more consistent. For example:   The  D3MAavePool  does  not  validate  that  the  aDAI  address  is  non-zero  while  the  D3MAavePlan  does.   file()  for  D3MCompoundPlan  validates  the  target  interest  rate  against  the  maximum  while  the  D3MAavePlan treats it as special case.   The D3MCompoundPool performs a == check after deposit() while the D3MAavePool performs a  >= check.   The target interest rate is barb in the D3MCompoundPlan and bar in the D3MAavePlan.  Pre-  and  post-conditions  may  be  treated  as  documentation  and,  hence,  having  them  consistent  and similar may clarify the assumptions the D3M Hub makes about the modules' behaviour.     The D3MAavePool now validates that the aDAI address is non-zero.  Acknowledged:  in  file()    An  additional  check   this  must  be  validated  within D3MAavePlan._calculateTargetSupply(). MakerDAO responded that the additional check in D3MCompoundPlan.file() is to prevent spell crafters from shooting themselves in the foot as the block based borrow rate Compound uses does not feel intuitive. Generally the policy is to leave the file functions as simple as possible and put guard rails into other contracts such as dss-exec-lib.  is  unnecessary  as    The  strict  equality  is  desired,  however  in  D3MAavePool  there  may  be  a  1  wei  rounding  error  depending on state hence the looser requirement.   MakerDAO responded: In this particular case, bar is a per-year interest rate in RAY units, while barb is a per-block interest rate in WAD units. To name these variables the same for consistency would likely  cause  spell  crafters,  risk,  and  governance  to  make  a  massive  mistake  in  setting  the  target borrow rate in the future. For this reason, we named them differently. That is, they are deliberately inconsistent for safety and security reasons.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.5   end.skim() May Leave ink Behind",
        "body": "  Normally, the ink / art of the pools urn at the VAT should be at a 1:1 ratio. Anyone however may use frob() and by supplying DAI one can reduce any urns debt.  Through the code of D3MHub _fix() is used to fix the urn. In one corner case this is not done:  Just before the VAT is caged, someone repays debt of the urn of a pool. art is now less than ink. After the VAT is caged exec() is called. The following code is executed:  ISSUEIDPREFIX-005  } else if (mode == Mode.MCD_CAGED) { // MCD caged // debt is obtained from free collateral owned by the End module _end = end; _end.skim(ilk, address(_pool)); daiDebt = vat.gem(ilk, address(_end));  end.skim() settles the debt of the urn by confiscating ink. As not all ink is needed to cover the art of the urn, there is some ink remaining. This collateral will be locked forever.  MakerDAO - Direct Deposit V2 -   15  CorrectnessLowVersion3Acknowledged        \fAcknowledged:  MakerDAO states:  This is an acceptable edge case that we assess to pose little or no risk. The actor that \u201cdonates\u201d DAI to create the situation loses value, and the effects on other actors are minimal. DAI holders receive the same distribution they would have had the donation not occurred (although in principle they could have received even more had the donation been taken into account). Vault holders are not affected. The external lending market now technically has a certain amount of locked DAI lending supply, but given the fundamental shift in the nature of DAI due to, Emergency Shutdown of the Maker protocol, this is unlikely to matter at all. While special-case logic could be added in `exec` to account for this, it likely isn\u2019t worth the extra complexity.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.6   Immutable InterestRateModel",
        "body": "  In the D3MCompoundDaiPlan contract, InterestRateModel is marked as immutable :  InterestRateModel public immutable rateModel;  ISSUEIDPREFIX-006  This  field  corresponds  to  the  InterestRateModel  field  of  the  CErc20  money  market  that  has  DAI  as underlying  asset.  The  CErc20  contract  inherits  from  the  CToken  contract,  which  means  the InterestRateModel can be updated :  function _setInterestRateModel(InterestRateModel newInterestRateModel) public returns (uint) {     /*...*/ }  An  update  of  the  InterestRateModel  field  of  the  CErc20  contract  cannot  be  reflected  in  the D3MCompoundDaiPlan contract since the InterestRateModel field is marked as immutable.  The stored rateModel is used in function _calculateTargetSupply. Should the interest rate model of the cDAI token be updated unexpectedly, the calculations may be incorrect.  Acknowledged:  Maker acknowledges the issue and states:  If the rate model changes unwinding can be permissionlessly triggered through the hub's `cage` function. We are now also working on having that block `exec` immediately (on a separate branch).  Update:  As  of  pool is caged.  ,  if  the  interest  rate  model  changes,  exec  will  trigger  an  unwind  as  though  the  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.7   Optimization of auth Modifier",
        "body": "  MakerDAO - Direct Deposit V2 -   16  CorrectnessLowVersion1AcknowledgedVersion3DesignLowVersion1Acknowledged                \fThe  auth  modifier  of  the  D3MPlanBase  contract  checks  the  condition  wards[msg.sender]  ==  1. However,  as  the  ward  mapping  only  contains  values  of  0  and  1,  it  is  sufficient  to  check  that wards[msg.sender] != 0. This results in a slightly more efficient compilation of the modifier.  ISSUEIDPREFIX-007  Acknowledged:  Maker prefers to stay with the current implementation as it is used in other Maker repos.  MakerDAO - Direct Deposit V2 -   17    \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings   Unclaimable or Leftover PoolShares During Global Settlement   -Severity Findings   Unwind Collects Interest, Fails to Reach Target Interest Rate    Aave V3 Reward Claiming Failure    Discrepancy in the Handling of Unachievable Target Interest Rates   Insufficient Conditions for active() Plan    No Events    No Natspec   0  0  1  6  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Unclaimable or Leftover PoolShares During",
        "body": " Global Settlement  ISSUEIDPREFIX-013  When winding DAI into a module, backed by the expected pool shares to be received, the gem balance is increased by the DAI amount to be generated. This amount of gem is then locked as ink which, due to the 1:1 ratio will correspond to the urns art.  By design, the accounting in the VAT remains unaware of any changes in the pool shares value held by the D3MPool contract. In normal operation, surplus is handled by taking the profit while the loss case is generally unhandled. Please refer to the corresponding open question at the end of this report.  If  the  VAT  is  caged,  calling  end.skim()  cancels  all  of  the  owed  DAI  from  the  Vault  and  assigns  the freed ink collateral to the END which is later distributed amongst all DAI holders.  The value of the PoolShares held by the D3MPool contract however may changes: For rebasing tokens, the amount of tokens may change (Aave aDAI). For others the exchange rate may change (Compound cDAI).  In  the  late  state  of  the  shutdown  users  will  receive  of  these  D3M  gems.  They  can  then  redeem  these gems for the underlying using D3MHub.exit().  In case of aDAI the call to D3MAavePool.transfer() will transfer the amount of gem in aDAI.  In case of cDAI the call to D3MCompoundPool.transfer() will transfer the amount of gem divided by cDai.exchangeRateCurrent(),  which  translates  to  the  current  amount  of  cDAI  token  which corresponds to this DAI amount.  MakerDAO - Direct Deposit V2 -   18  CriticalHighMediumCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCorrectnessMediumVersion3CodeCorrected         \fThe third party systems are independent of the VAT. These may continue to operate normally and accrue more interests during the Shutdown process. Or they may be excess profit which has not been collected yet.  Leftover collateral tokens will remain at the D3MPool contracts:   D3MAavePool:  The  aDAI  balance  held  exceeds  the  sum  of  gem,  hence  not  all  aDAI  can  be  distributed.   D3MCompoundPool:  Due  to  a  favorable  cDai.exchangeRateCurrent()  not  all  cDAI  will  be  consumed when users exit their gem.  Whenever there was a loss, either before or during the shutdown process, not all gem can be redeemed:   D3MAavePool: The aDAI balance held is insufficient to redeem all the gem, hence not all gem can be  redeemed.   D3MCompoundPool:  The  available  cDAI  balance  is  insufficient  to  redeem  all  gem  with  the  current  cDai.exchangeRateCurrent(), hence not all gem can be redeemed.    The gem balance is now treated as a share of the pool's LP token balance. Hence, users will be able to withdraw their corresponding share.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Unwind Collects Interest, Fails to Reach",
        "body": " Target Interest Rate  exec() determines the current state and either winds or unwinds as necessary. If no other constrains apply,  it  attempts  to  have  supplied  plan.getTargetAsset()  amount  of  DAI.  The  implementation  of unwind() however may remove more assets and the resulting pool state is not exactly as targeted.  ISSUEIDPREFIX-011  is   to   due   This  states: Upon  unwinding,  interest  will  automatically  be  collected..  Interests  however  are removed in addition to the calculated supply reduction reducing in less than the calculated amount of DAI remaining in the pool.  implementation   unwind().   README   The   the   of   The  implementation  of  unwind()  first  calculates  the  amount  to  unwind  based  on  the  calculated supplyReduction and constraints:  // Unwind amount is limited by how much: // - max reduction desired // - assets available // - dai debt tracked in vat (CDP or free) uint256 amount = _min(                      _min(                         supplyReduction,                         availableAssets                     ),                     daiDebt                 ); require(amount <= MAXINT256, \"D3MHub/overflow\");  and later adds the fee on top for the amount to withdraw.  MakerDAO - Direct Deposit V2 -   19  CorrectnessLowVersion3CodeCorrected        \f// To save gas you can bring the fees back with the unwind uint256 total = amount + fees; //uint total = amount; _pool.withdraw(total);  As too many DAI have been removed, the utilization is higher and the target interest rate is not reached. A second call to exec() could rectify this by resupplying the missing amount of DAI.    The implementation of exec() has been redesigned, the issue described above no longer exists.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Aave V3 Reward Claiming Failure",
        "body": "  The collect() function claims Aave rewards and sends them to king. Note that the interface of the reward  claiming  interfaces  are  different  between  Aave  V2  and  V3.  Namely,  Aave  V3  supports  multiple reward  tokens  while  V3  does  not.  Thus,  the  function  claimRewards()  changed  its  interface  and  the function REWARD_TOKEN() was removed. Ultimately, claiming rewards could fail for Aave V3.  ISSUEIDPREFIX-014    Now, the there are two collect() implementations. The one for Aave V2 does not take any argument and claims the rewards with the V2 interface (receiving REWARD_TOKEN()). The one for Aave V3 takes a reward  token  address  as  an  argument  and  claims  these  rewards  with  the  new  V3  reward  claiming interface.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Discrepancy in the Handling of Unachievable",
        "body": " Target Interest Rates  ISSUEIDPREFIX-012  There  is  no  upper  bound  on  the  value  of  targetInterestRate  in  the  _calculateTargetSupply function, nor on barb in the file function. Consequently, it is possible to obtain a target utilization rate (targetUtil) above 100% in _calculateTargetSupply. This is not possible in Compound, thus the target interest rate is unachievable. However, _calculateTargetSupply will return a non zero value as if the target rate was achievable.  This  is  not  consistent  with  the  behavior  of  _calculateTargetSupply  in  the  other  cases  where  the target  interest  rate  is  not  achievable:  When  targetInterestRate  is  above  normalRate  but jumpMultiplierPerBlock is zero, or when targetInterestRate is below baseRatePerBlock, _calculateTargetSupply returns 0.    _calculateTargetSupply now returns 0 when the calculated utilization is over 100%.  MakerDAO - Direct Deposit V2 -   20  CorrectnessLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                \f6.5   Insufficient Conditions for active() Plan  Plans can be manually disabled or enabled. However, that may also happen automatically. For example, the  D3MCompoundPlan  will  become  inactive  if  the  implementation  contract  has  changed.  While  the checks for both plans are rather extensive, there could be some properties that could also be considered for the active() view function.  ISSUEIDPREFIX-008  For example:   Aave  does  not  offer  querying  the  implementation  contract  such  as  compound  but  offers getRevision()  which  returns  the  version  of  the  AToken.  Similarly,  that  holds  for  other  Aave contracts such as the lending pool.   Before depositing into Aave, Aave does a validateDeposit() check which checks if an AToken  is active and not frozen.   Before depositing into Compound, the CToken calls mintAllowed() on the Comptroller to check if  the market is listed or paused.  Were these and similar properties considered and why aren't they use in the active() function?    MakerDAO responded:  The first check for Aave (ATOKEN_REVISION) is very helpful and has been added.  The other two concern a paused or inactive token in Aave or Compound. We explored this during our internal review and unfortunately, found that this is not a helpful check to add to `active`. When a plan returns `false` for active, then we attempt to unwind as much of our position as possible. In the case where the AToken is not active/frozen or the CToken is not listed/paused, any transfer of those tokens will revert so we will not be able to withdraw.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   No Events",
        "body": "  Neither  function  file  nor  disable  of  the  D3MCompoundDaiPlan  contract  emit  an  event  after  the parameter barb has been changed. Normally file functions of Maker projects emit an event.  ISSUEIDPREFIX-009    Events are now emitted.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   No Natspec",
        "body": "  MakerDAO - Direct Deposit V2 -   21  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \fThe  external  functions,  although  being  view  functions  only,  feature  no  description  /  natspec.  Is  this intentional?  Description  may  allow  user  to  better  understand  the  function  parameters  (e.g.  the currentAssets  of  getTargetAssets())  and  the  return  values,  thus  potentially  avoids  errors.  For example it's not immediately obvious if some parameters are in cDAI or DAI.  ISSUEIDPREFIX-010    MakerDAO added NatSpec documentation.  MakerDAO - Direct Deposit V2 -   22  \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Anyone Can Manipulate the Allocation",
        "body": "  By design, the plans' computations on how much to withdraw/deposit heavily depends on on-chain state: The  plans  aim  to  reach  a  target  interest  rate  which  is  depending  on  the  current  utilization  ratio.  This depends on:  1. the current pool size  2. the currently borrowed amount  Note, that both can be easily manipulated before exec() is called. This may be done within the same transaction  or  in  separate  transactions.  However,  this  is  almost  like  the  normal  intended  use  of  the system: Pool states change after interactions, exec() is used to return the pool to the desired stated.  The current pool size for example can be manipulated by sandwiching exec() as follows:  1. Deposit DAI into the external system's pool by minting LP tokens.  2. exec()  3. Withdraw DAI by burning LP tokens.  Note that such manipulation can easily be achieved at low cost to a certain degree since, for example the DAI flash mint module, offers DAI flash loans for free.  The second one can be manipulated by sandwiching exec() as follows:  1. Borrow a significant amount of DAI from the pool.  2. exec()  3. Payback the loan.  Note  that  this  manipulation  requires  some  extra  steps  such  as  depositing  collateral  to  borrow  DAI. However, the needed collateral amount could be either already held by a malicious user or could be flash loaned at potentially low cost.  In  summary,  exec()  always  attempts  to  reach  the  target  utilization.  In  a  three-step  process,  first  by modifying the state (e.g., depositing DAI minting pool shares), calling exec() which now winds/unwinds into the wrong direction to temporarily reach the target utilization. Finally, the attacker may undo the state manipulation  of  step  1)  (e.g.,  returning  the  pool  shares  he  borrowed)  and  the  pool  utilization  is significantly off.  As long as exec() works as intended, this is no issue. A subsequent call to exec can return the pool to the desired state. Note that in corner cases this may not be possible: Limitation from maxDeposit() / maxWithdraw(),  Line  or  available  liquidity  to  withdraw  DAI  may  prevent  this.  Should  an  attacker manage to trick exec() to wind/unwind but a subsequent exec() cannot undo this (temporarily), this is problematic.  A potentially costly attack could be to borrower much DAI over a long time such that the position cannot unwind  properly.  A  variation  of  this  could  be  front-running  calls  to  exec()  which  would  unwind  and remove the available DAI liquidity.  MakerDAO - Direct Deposit V2 -   23  NoteVersion1    \f7.2   Caging Arbitrary Ilks  Technically, for the governance it is possible to cage ilks to either do not exist yet or that are not D3M ilks. Potential consequences could be:   The non-existing ilk is added to the system and could be immediately culled.   The non-D3M ilks could be added that could be similarly culled. However, if 0x0 has some ink or  art for that ilk, the ink will be converted to gem while the debt will be written off.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Checks on deposit()/ withdraw()",
        "body": "  Both  pool  implementations  implement  sanity  checks  upon  deposit  in  order  to  ensure  the  expected amount of pool shares has been received.  Upon  withdrawal  the  D3MHub  enforces  that  a  sufficient  amount  of  DAI  is  present.  Otherwise,  the transaction reverts when DAIJOIN.join() fails.  Generally, this checks whether redeeming pool shares resulted in the expected amount of DAI, except in corner cases when there was additional DAI balance present for the D3MHub.  A  situation  where  redeeming  pool  shares  results  in  less  than  expected  DAI  is  not  detected  by  the D3MHub  contract.  While  the  transaction  reverts,  the  D3M  hub  will  remain  unaware.  A  later  call  to execute, after the utilization of the third party has changed, may wind more DAI into this broken system.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   Document VAT Shutdown",
        "body": "  VAT Shutdown considerations are not documented for this special ilk type. Due to the special nature / behavior such documentation should be readily available and may include:   Description of the different states a D3M ilk could be in   Effects of unwinding during shutdown (MCD_cage mode) and a description of the process   Culling and what implications a culled ilk during shutdown has   Unculling and the reasons when it could be worth calling it, and the conditions for when uncull()  can be called   Considerations when ilks were not fully unwinded (e.g. D3M oracles can not be queried and hence  the ilk cannot be caged)  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   Exposure to New Collaterals / Markets",
        "body": "  Currently the set of ilks / collaterals backing the DAI Stablecoin is rather restricted to well known and trusted assets only.  D3MHub  lends  DAI  to  third  party  protocols  such  as  AAVE  and  Compound.  This  results  in  exposure  to new  markets  and  collateral  assets.  The  risk  can  be  limited  through  the  Line  /  debt  ceiling  set  for  the corresponding ilk.  MakerDAO - Direct Deposit V2 -   24  NoteVersion1NoteVersion1NoteVersion1NoteVersion1              \f7.6   Maximizing Revenue  By supplying DAI into lending protocols such as Compound/Aave the protocols utilization is reduced and borrowing DAI gets cheaper.  With DAI generated through D3M Maker only profits from interests accrued by the DAI in the third party protocol in contrast to DAI generated with normal ilks where users have to pay the stability fee.  With Compound/Aave users earn interest on their collateral while paying interest for borrowed DAI. The users  position  has  to  be  overcollateralized,  hence  the  supply  interest  are  earned  on  a  larger  amount compared to the borrow interest on the smaller DAI amount.  There  is  a  risk  that  users  can  get  DAI  cheaper  via  these  protocol  compared  to  using  the  Maker  Dai Stablecoin system if the parameters for the target borrow rate / pool utilization are not chosen carefully.  E.g. at the time of writing (July 17th, 2022):  Aave V2: The variable borrow APY for DAI is 1.69% at a pool utilization of 33.46% while the supply APY for Ether is 0.08%. Compared to the ETH-A stability fee in Maker is 2.25%.  Compound: The borrow AP for DAI is 1.79% with a pool utilization of 31.19%. The supply APY for LINK token is 0.43% Compared to the Link-A Stability fee in Maker of 2.50%.  The target interest rate must be chosen carefully taking into account the different stability fees of different ilks for the D3M to be worthwhile. Depending on the state of the lending pool (e.g. low utilization / low rates) this may not be possible.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.7   Unhandled Loss Case",
        "body": "  When winding DAI into a module, backed by the expected pool shares to be received the gem balance is increased by the DAI amount to be generated. This amount of gem is then locked as ink which, due to the 1:1 ratio will correspond to the urns art.  By design the accounting in the VAT remains unaware of any changes in the pool shares value held by the D3MPool contract.  If the module generates a profit in form of interests the profit is accounted for.  If the third party system makes a loss, the value of the pool shares held by the D3M pool may decrease. exec() does not catch this and may continue to wind DAI into the module if the plan asks to do so. Such a module / ilk must be caged manually by the governance.  MakerDAO replied:  Note that it is true that when there is a problem, such as a hack in Compound or Aave, the exchange rate or rebalancing can be altered both ways.  We think this risk is not significantly different from existing risks in non-immutable collateral types, and is limited by debt ceilings.  MakerDAO - Direct Deposit V2 -   25  NoteVersion1NoteVersion1          \f7.8   VAT Debt Could Increase After END.thaw()  After the processing period of the shutdown, the call to END.thaw() will fix the total outstanding supply of DAI according to VAT.debt().  uncull() can still be called. This will suck() and then grab() such that the total debt of the VAT is increased  and,  thus,  it  could  be  possible  that  the  total  outstanding  DAI  supply  is  increased  even  after END.thaw().  MakerDAO states:  We are aware of the importance/need to uncull all culled D3Ms and will be working to add this to our End Keeper processes. This is similar to the importance that all collaterals get skimmed in the waiting period.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.9   deposit() Is Deprecated for Aave V3",
        "body": "  The  deposit()  function  deposits  funds  into  the  Aave  protocol.  While  both,  V2  and  V3,  support  the function, Aave suggests using supply() since deposit() was deprecated. However, both implement the same logic.  MakerDAO - Direct Deposit V2 -   26  NoteVersion1NoteVersion1      \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Missing ETH Unwrapping",
        "body": "  The  AutomationExecutor  allows  its  owner  to  withdraw  tokens  or  native  ETH.  As  the  Oazo  team informed  us,  the  main  purpose  of  this  function  is  to  withdraw  ETH  converted  from  DAI.  The  exchange contract  is  not  able  to  handle  native  ETH  but  needs  its  wrapped  version.  Hence  there  is  a  need  for unwrapping functionality to be able to use native ETH. However, such functionality is not implemented.    unwrapWETH has been implemented. It can be called only by the owner of the AutomationExecutor contract and calls weth.withdraw function.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Accidental Approval Revocation",
        "body": "  On removeTrigger a user can accidentally set the removeAllowance variable to true. If this happens the approval to the automation bot is revoked. A user can only re-approve the automation bot indirectly by adding another trigger since there is no function to do this directly. Another option for the user is to use the revocation manager.  Oazo Apps Limited - Automation Consultancy -   11  CriticalHighMediumCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedDesignMediumVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \fCode corrected  The functionality to grant approval to the automation bot has been added.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Dead Code",
        "body": "  In  ServiceRegistry,  functions  addTrustedAddress,  removeTrustedAddress  and isTrusted  manipulate  the  trustedAddresses  mapping.  However,  this  mapping  is  not  used  by  the rest of the implementation. Moreover, McdUtils.convertTo18 is also never used.  the     The dead code has been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Missing Sanity Checks",
        "body": "  There are multiple points in the contract where sanity checks are missing. The absence of such checks can allow users to assign invalid values to variables:  1. AutomationBot.addRecord  does  not  sanitize  triggerType  and  triggerData.  Also, triggerData  includes  slLevel  which  can  have  invalid  values  that  cause  reverts  inside isExecutionLegal. Should the variables store invalid data the corresponding trigger will not be able to execute at a later point in time.  2. AutomationExecutor.(transferOwnership,  setExchange)  does  not  sanitize  the  input values. Notice that there is no delayed execution implemented for this contract.  3. ServiceRegistry.constructor sanitizes the required delay by requiring it to be less than the  maximum  integer.  However,  any  value  close  to  the  maximum  integer  would  be  valid  and problematic for the system.    1. AutomationBot.addRecord   validates   the   triggerData   by   using  commandAddress.isTriggerDataValid.  2. AutomationExecutor now sanitizes the data.  3. The maximum required delay is now set to 30 days.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Outdated Compiler",
        "body": "  The system is compiled using solidity version 0.8.4. However, more recent versions are available. At the time of writing 0.8.13 is the most recent version.  Oazo Apps Limited - Automation Consultancy -   12  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \f  The compiler version 0.8.13 is now used.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Redundant Authorization",
        "body": "  In McdUtils.drawDebt, the authorization of the AutomationBot to daiJoin is given every time the call is made since the following line is always executed:  IVat(vat).hope(daiJoin);  We noticed that the implementation is quite similar to https://github.com/OasisDEX/multiply-proxy-action s/blob/develop/contracts/multiply/MultiplyProxyActions.sol#L205. However, there is always a check if the authorization is needed.    The current implementation only grants authorization to daiJoin, if it has not been given before.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Rounding Errors",
        "body": "  According to the specification (https://github.com/dapphub/ds-math), DSMath.wmul should be used with two  Wads  and  DSMath.rdiv  should  be  used  with  two  Rays.  However,  this  is  not  true  in McdView.getRatio where the following snippet exists:  uint256 ratio = rdiv(wmul(collateral, price), debt);  Here,  wmul  is  applied  on  collateral  which  is  a  wad  and  price  which  is  a  9-decimal  number.  The result will also be a 9-decimals number. Later, rdiv is applied on this 9-decimal number and debt which is a wad. The result is a Wad instead of a Ray. Wrong usage of DSMath leads to rounding errors. This means that a vault is rendered closable at different levels than the users have actually set.    In the current implementation price is a Wad and the problematic snippet has been rewritten to:  return wdiv(wmul(collateral, price), debt);  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   Specification Discrepancies",
        "body": "  Oazo Apps Limited - Automation Consultancy -   13  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1Speci\ufb01cationChanged                        \fThere  are  some  discrepancies  between  the  provided  specification  and  the  actual  implementation.  We follow the enumeration provided in the documentation.  System Requirements & Assumptions:  ServiceRegistry:  1. The addresses are not trusted, in the sense that the trustedAddresses mapping is not used. 4. removeTrustedAddress also does not use the delayedExecution modifier.  AutomationBot:  5. If a user executes addRecord directly to add a trigger then cdpAllow will not be called. 13. The permission might have been revoked by the user.  Smart Contract Architecture:  AutomationExecutor:   swapTokenForDai is documented but does not exist.   swap is implemented but not documented.  Specification changed:  All the discrepancies in the specification have been fixed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   Use Safe Calls",
        "body": "  AutomationExecutor exposes swap and withdraw functions. These functions, interact with ERC20 contracts  by  calling  ERC20.approve  and  ERC20.transfer.  However,  these  calls  will  fail,  should  a user  try  to  interact  with  a  USDT  contract.  For  example,  a  user  sends  accidentally  USDT  to  the AutomationExecutor, the amount will remain stuck there since any withdrawal by the owner will fail.    SafeERC20  used.  SafeERC20.safeIncreaseAllowance  and  ERC20.transfer  has  been  SafeERC20.safeTransfer.  ERC20.approve   library   been   now   has   is   replaced  with replaced  with  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   Zero Debt Vaults",
        "body": "  returns  0  when   the  debt  of  a  vault   McdUtils.getRatio  than CloseCommand.isExecutionLegal will return true, and thus, render the vault closable. This means that  a  caller  might  try  to  close  the  a  zero  debt  vault.  When  the  AutomationExecutor  calls AutomationBot.execute, the latter will try to withdraw extra debt (drawDaiFromVault) to cover its gas costs. However, the Maker system only allows users to withdraw debt that exceeds a specific limit (dust).  Since  the  amount  of  extra  debt  withdrawn  to  cover  the  caller  is  small  compared  to  the  dust amount, the whole transaction will revert.  is  0.  This  means     Oazo Apps Limited - Automation Consultancy -   14  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \fAn execution of the CloseCommand is legal as long as the collateralization ratio is not 0.  Oazo Apps Limited - Automation Consultancy -   15  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Missing Indexing of Events",
        "body": "  The  event  NewMonth  contains  no  indexed  fields.  The  event's  field  month  is  a  specific  number.  Yearn might consider indexing it if needed.  CS-YRNDSCNT-004  Code corrected  The field month was indexed in the event NewMonth.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Race Condition on Team Allowance",
        "body": "  If the management calls set_team_allowances a second time during the same month while a team has  some  allowance  left,  similar  to  the  well-documented  issue  with  the  ERC20  approve  function,  it  is possible for a team to front-run the transaction to spend its remaining allowance before the management set its allowance to the new amount.  CS-YRNDSCNT-005  Specification changed  Yearn  highlighted  the  trust  assumption  that  the  team  is  a  fully  trusted  party.  Misbehaving  will  lead  to disqualification from participating in the program.  Yearn - yDiscount -   10  CriticalHighMediumLowCodeCorrectedSpeci\ufb01cationChangedDesignLowVersion1CodeCorrectedDesignLowVersion1Speci\ufb01cationChanged                \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Event Reentrancy",
        "body": "  In the function buy, the callback is done before logging the event, in the case that the call would reenter the contract, it would be possible to have events emitted out of order.  CS-YRNDSCNT-001  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Gas Optimizations",
        "body": "  In  set_contributor_allowances,  self.expiration  is  read  from  storage  once  before  entering the loop and then once at each iteration of the loop, caching it in memory would avoid several SLOAD.  CS-YRNDSCNT-002  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Inconsistency of the Interface ",
        "body": " ChainlinkOracle  While the Chainlink documentation specifies that the return type of decimals is an uint8, the interface ChainlinkOracle  defines  the  function  decimals  as  returning  an  uint256.  Although  a  uint8  will always fit in a uint256, it would be more consistent to use uint8 as described in the documentation.  CS-YRNDSCNT-003  Yearn - yDiscount -   11  InformationalVersion1InformationalVersion1InformationalVersion1          \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Tokens With More Than 18 Decimals Not",
        "body": " Caught in Constructor  The constructor querries and stores the tokens decimals:  dec = gem.decimals();  Recent  JOIN  adapters,  e.g.  GemJoin7  have  an  explicit  require  statement  preventing  tokens  with decimals > 18 to initialized. This is done as additional safety measure as some integrations, e.g. proxy actions  are  incompatible  with  /  break  for  token  with  >  18  decimals.  No  such  check  is  present  in GemJoin9.    Similar  to  other  recent  GemJoin  adapters,  the  code  in  the  constructor  of  GemJoin9  now  ensures  the token decimals do not exceed 18.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   PAXG Token Used for Tests Does Not Match",
        "body": " Actual PAXG Contract  The PAXG token contract added to the repository and used for tests does not match the actual PAXG contract implementation. Testing hence is done with a different token implementation than the intended token the join adapter interacts with in production which is not ideal and might hide bugs.    Forked mainnet tests have been added in the gemjoins integration tests. This ensures the code is tested with the actual PAXG token on chain.  MakerDAO - GemJoin9 for PAXG -   10  CriticalHighMediumLowCodeCorrectedDesignLowVersion1CodeCorrectedInformationalVersion1CodeCorrected              \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   PAXG Token Is Upgradable",
        "body": "  The PAXG Token is upgradable and an upgrade could break the integration with gemjoin9.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   wad Amount in Join Event",
        "body": "  Function  function  join(address  usr,  uint256  wad)  will  from msg.sender.  However,  fees  are  going  to  be  deducted.  Hence,  the  actually  joined  amount  will  be  the amount that arrived at the join adapter. Since the return value of the internal function _join is ignored and,  hence,  the  event  is  emitted  using  the  wad  parameter,  the  emission  will  be  incorrect.  Also,  any excess tokens will be ignored for the emitted join amount.  transfer  wad   tokens   MakerDAO  responded  that  this  behavior  is  in  line  with  the  other  gemJoins  (e.g.  join-3  or  join-7).  It's always the input amount that is logged.  MakerDAO - GemJoin9 for PAXG -   11  NoteVersion1NoteVersion1      \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   No Protection for Keepers",
        "body": "  ISSUEIDPREFIX-001  Generally, keepers may just be interested in collecting the penalty of failing offers. In Mangrove however, an  offer  could  always  succeed  unexpectedly  due  to  changing  on-chain  conditions.  In  this  case,  a keeper/taker may have executed an offer he did not actually intended to take and which may had a bad exchange rate. Note that offers may only fail when significant amounts of tokens are flashloaned to the maker up front but the very same offer may succeed for lower amounts.  Unaware keepers may be tricked by honeypot offers (offers that appear to fail but in reality don't fail) by malicious makers.  Keepers may protect themself by wrapping their call in a smart contract and checking for the expected outcome, but the code of Mangrove itself does not offer such a feature directly.  Risk Accepted:  Mangrove  Association  (ADDMA)  responded:  Indeed  all  keepers  should  wrap  their  calls  in  a  reverting contract. This protective wrapper does not need to be inside Mangrove. We plan to provide a standard wrapper at a separate address.  Mangrove Association (ADDMA) - Mangrove -   14  SecurityDesignCorrectnessCriticalHighMediumRiskAcceptedLowRiskAcceptedAcknowledgedAcknowledgedRiskAcceptedDesignMediumVersion1RiskAccepted             \f6.2   ECDSA Signature Malleability  The permit function utilizes the ECDSA scheme. However missing checks for the v, r and s arguments allow  attackers  to  craft  malleable  signatures.  According  to  Yellowpaper  Appendix  F,  the  signature  is considered valid only if v, r and s values meet certain conditions. The ecrecover for invalid values will return address 0x0 and verification will fail without informative error. The OpenZeppelin's ECDSA library performs such checks and reverts with informative messages.  ISSUEIDPREFIX-002  Risk Accepted:  Mangrove  Association  (ADDMA)  responded:  Code  changes  necessary  for  improved  error  messages would go past the contract size limit.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   No Minimum Value for gasreq",
        "body": "  Either to create a new offer or to update an existing one, the maker must provide a value for gasreq. In the current implementation, there is no minimum required value. The value for gasreq may even be set to 0, which means 0 gas requirements for the calls executed on the maker's side. Nevertheless, both calls are  executed,  the  first  call  to  makerExecute  with  all  gas  defined  in  gasreq  and  the  second  to makerPosthook with the \"leftover\" gas from gasreq. With 0 gas these low-level calls are started but immediately revert. The system could allow these calls to be skipped when the maker sets a zero / low amount for gasreq.  ISSUEIDPREFIX-003  Acknowledged:  Mangrove Association (ADDMA) responded: The gas saved by treating 0-gasreq as a special case is not worth the added code complexity.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Redundant Check in writeOffer",
        "body": "  When writeOffer is called a check that ofp.gives > 0 is performed. However, the check presented below  is  also  performed  and  implies  the  same  since  both  density  and  gasbase  should  be  positive under normal circumstances.  ISSUEIDPREFIX-004  ofp.gives >=   (ofp.gasreq + $$(local_offer_gasbase(\"ofp.local\"))) *     $$(local_density(\"ofp.local\")),  No Issue:  Mangrove Association (ADDMA) - Mangrove -   15  DesignLowVersion1RiskAcceptedDesignLowVersion1AcknowledgedDesignLowVersion1Acknowledged                      \fMangrove  Association  (ADDMA)  responded:  It  is  possible  for  governance  to  set  values  such  that  the second check does not imply the first. The first check maintains a critical invariant.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Spamming the Offerbook",
        "body": "  ISSUEIDPREFIX-005  An  attacker  may  spam  the  offerbook  with  attractive  offers  reverting  immediately  upon  execution. Depending  on  the  parameters  chosen  by  the  governance  for  density  and  offer_gasbase  the resulting minimum penalty paid for the failing offer may be rather low.  Notably it is sufficient to have 85 such failing offers in the offer book (offering a very low price to ensure to be  on  top)  to  cause  a  revert  of  the  transaction  due  to  an  EVM  stack  too  deep  error.  Hence  any transaction to marketOrder() of this base/quote pair will revert leaving the state unchanged.  It's  still  possible  for  keepers  to  clean  the  offerbook  by  sniping  these  offers,  however  such  offers  may reinstantiate themself during the makerPosthook().  Risk Accepted:  Mangrove Association (ADDMA) responded: Any self-reinserting spam is vulnerable to draining by any keeper.  Mangrove Association (ADDMA) - Mangrove -   16  SecurityLowVersion1RiskAccepted          \f7   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings   Draining All Ether Provisions of Mangrove   -Severity Findings  -Severity Findings  If Condition Always True    Rounding Errors In Partial Filling   -Severity Findings   Wrong Comment    Call in makerPosthook Fails Silently    Fields of Events Not Indexed   Imprecise Comment    Maximize Penalty Collected    Misleading Variable Names in stitchOffers    Overrestrictive Check in deductSenderAllowance    Repetitive Code   1  0  2  8  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Draining All Ether Provisions of Mangrove",
        "body": "  ISSUEIDPREFIX-014  Makers can retract their offer by calling retractOffer(). This function accepts the boolean parameter deprovision which allows the maker to choose to either deprovision the offer or not.  Deprovisioning an offer credits back the provision to the maker. At the same time it must be ensured that this  offer  is  removed  from  the  offerbook  and  its  gasprice  must  be  set  to  0  as  the  offer  is  no  longer provisioned.  Not all possible cases are handled correctly inside function retractOffer(). For offers that are not live (this means they have a 0 amount for offer.gives) the provision can be credited back to the maker without the offer's gasprice being set to zero.  Hence  retractOffer()  with  deprovision  set  to  true  can  be  executed  successfully  repeatedly. Consequently a maker can reclaim more provision than he initially paid for the offer. This bug allows to eventually drain all Ether of Mangrove.  An offer can easily reach offers.gives = 0 which means it is considered to not be live:   By  calling  retractOffer()  with  bool  deprovision  set  to  false,  dirtyDeleteOffer()  is executed. This call sets offer.gives to zero however without setting offer.gasprice to zero due to deprovision being false.  Mangrove Association (ADDMA) - Mangrove -   17  CriticalCodeCorrectedHighMediumCodeCorrectedCodeCorrectedLowSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSecurityCriticalVersion1CodeCorrected          \f After the offer has been consumed by an order offer.gives is 0.  Code Corrected:  The  call  to  dirtyDeleteOffer()  was  moved  out  of  the  isLive  scope.  Hence  whenever deprovision is set to true and the provision is credited back to the Maker, the order is deprovisioned. Calling the function repeatedly on the same offer no longer allows to drain Ether of Mangrove, the issue has been resolved.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   If Condition Always True",
        "body": "  During the execution of function execute the following check is performed:  ISSUEIDPREFIX-006  if (statusCode != \"mgv/notExecuted\") {   dirtyDeleteOffer(     ...   ); }  However statusCode cannot have the value mgv/notExecuted at this point so the condition is always true.  Code Corrected:  The code now runs unconditionally.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Rounding Errors In Partial Filling",
        "body": "  A maker's order can be partially filled according to the following snippet:  if (mor.fillWants) {    sor.gives = (offerWants * takerWants) / offerGives;  } else {    sor.wants = (offerGives * takerGives) / offerWants;  }  ISSUEIDPREFIX-015  Note that the division can yield rounding errors. The rounding errors can be as extreme as giving funds to the maker without receiving anything in return or taking from the maker without giving anything back. For example,  consider  the  case  where  the  maker  offers  10  A  for  5  B  and  taker  wants  to  take  only  1  A (fillWants == true). Then, according to the formula she has to offer 5 * 1 / 10 = 0 B.  Code corrected  Mangrove Association (ADDMA) - Mangrove -   18  DesignMediumVersion1CodeCorrectedDesignMediumVersion1CodeCorrected                \fPrices are now always rounded in favor for the taker to avoid any maker draining. Hence, to calculate sor.gives when fillWants is true the code has been changed to:  uint product = offerWants * takerWants; sor.gives =   product /   offerGives +     (product % offerGives == 0 ? 0 : 1);  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   Wrong Comment",
        "body": "  ISSUEIDPREFIX-016  the   In  comment In  case  of  failure,  `retdata`  encodes  the  gas  ...  is  present  in  the  block if(success), thus should be In case of success, ....  MgvOfferTaking.execute,   function   the   Specification changed:  The comment has been corrected.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   Call in makerPosthook Fails Silently",
        "body": "  The return value success2 in makerPosthook() is never handled. Thus a failed execution of the hook can go unnoticed and unlogged.  ISSUEIDPREFIX-008  Code Corrected:  A log event is emitted on posthook revert.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.6   Fields of Events Not Indexed",
        "body": "  No parameter of the events defined in MgvEvents is marked as indexed. Indexing fields of events, e.g. addresses, allows to search for them easily.  /* Mangrove adds or removes wei from `maker`'s account */   /* * Credit event occurs when an offer is removed from the Mangrove or when the `fund` function is called*/   event Credit(address maker, uint amount);   /* * Debit event occurs when an offer is posted or when the `withdraw` function is called */   event Debit(address maker, uint amount);    /* * Mangrove reconfiguration */  ISSUEIDPREFIX-011  Mangrove Association (ADDMA) - Mangrove -   19  CorrectnessLowVersion7Speci\ufb01cationChangedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \f  event SetActive(address base, address quote, bool value);   event SetFee(address base, address quote, uint value);   event SetGasbase(     address base,     address quote,     uint overhead_gasbase,     uint offer_gasbase   );  Code Corrected:  The relevant arguments were indexed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.7   Imprecise Comment",
        "body": "  At  the  beginning  of  function  execute()  the  code  handles  whether  the  full  offer  is  to  be  consumed  or only a partial amount of the offer should be taken by the order.  ISSUEIDPREFIX-007  if (   (mor.fillWants && offerGives < takerWants) ||   (!mor.fillWants && offerWants < takerGives) ||   offerWants == 0 ) {   sor.wants = offerGives;   sor.gives = offerWants;   /* If we are in neither of the above cases, then the offer will be partially consumed. */ } else {   /* If `fillWants` is true, we give `takerWants` to the taker and adjust how much they   give based on the offer's price. Note that we round down how much the taker will give. */   if (mor.fillWants) {     /* **Note**: We know statically that the offer is live (`offer.gives > 0`) since market      orders only traverse live offers and `internalSnipes` check for offer liveness before executing. */     sor.gives = (offerWants * takerWants) / offerGives;     /* If `fillWants` is false, we take `takerGives` from the taker and adjust how much they get      based on the offer's price. Note that we round down how much the taker will get.*/   } else {     /* **Note**: We know statically by outer `else` branch that `offerGives > 0`. */     sor.wants = (offerGives * takerGives) / offerWants;   } }  The last comment  Note: We know statically by outer else branch that offerGives > 0.  is not entirely correct: While it holds that offerGives is > 0 this is not due to being in the outer else branch but due to it having been ensured earlier that the offer is live, so offerGives is >0. Due to being in the outer else branch we know that offerWants is non-zero and hence we are sure there will be no division by zero which is the important consideration here.  Code Corrected:  The comment was changed to:  Note: We know statically by outer else branch that offerWants > 0.  Mangrove Association (ADDMA) - Mangrove -   20  CorrectnessLowVersion1CodeCorrected        \f7.8   Maximize Penalty Collected  Function  snipes()  allows  keepers  to  snipe  multiple  failing  offers  at  once  and  thereby  collect  the penalty. However, when multiple offers fail within one order, the base gas fee is split amongst all failing offers. This is done in order to distribute the base fees that applies once per transaction evenly across all affected offers.  In  order  to  maximize  their  profit,  professional  keepers  may  deploy  their  own  smart  contract  calling snipe() individually on each offer without increasing their expenses significantly, in order to ensure to always collect the maximum penalty possible.  ISSUEIDPREFIX-009    The sniping mechanism has changed and, now, snipes() treats all snipes in isolation. With this change overhead_gasbase was removed and the scenario described above no longer applies.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.9   Misleading Variable Names in stitchOffers",
        "body": "  In  stitchOffers  the  variable  names  worseId  and  betterId  are  used.  However,  the  betterId refers  to  the  offer  next  to  the  offer  under  consideration  and  worseId  refers  to  the  previous  one.  This seems to contradict the naming convention holding for the offerbook. According to this convention, for a given offer, its previous offer is a better one and its next offer a worse one.  ISSUEIDPREFIX-010  Code Corrected:  The names of the variables were swapped.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.10   Overrestrictive Check in ",
        "body": " deductSenderAllowance  deductSenderAllowance checks if the amount used does for a trade does not exceed the allowance the use has set. However, it prevents the full allowed amount from being used since the equality is not checked.  ISSUEIDPREFIX-012  require(allowed > amount, \"mgv/lowAllowance\");  Code Corrected:  Mangrove Association (ADDMA) - Mangrove -   21  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \f> was replaced with >=.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.11   Repetitive Code",
        "body": "  In postExecute the following snippet is used right before the call to applyPenalty().  ISSUEIDPREFIX-013  if (gasused > gasreq) {    gasused = gasreq;  }  Later, in applyPenalty the same snippet is repeated as follows:  if ($$(offerDetail_gasreq(\"sor.offerDetail\")) < gasused) {   gasused = $$(offerDetail_gasreq(\"sor.offerDetail\")); }  which is redundant.  Code Corrected:  The second check in postExecute was removed.  Mangrove Association (ADDMA) - Mangrove -   22  DesignLowVersion1CodeCorrected        \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  Hence,  the mentioned topics serve to clarify or support the report, but do not require a modification inside the project. Instead,  they  should  raise  awareness  in  order  to  improve  the  overall  understanding  for  users  and developers.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Bitwords Benefits",
        "body": "  In the implementation of Mangrove, structs to be stored in storage and handled as bitwords. This is done to  improve  gas  efficiency.  However,  given  that  equivalent  native  solidity  structs  could  fit  in  on  storage slot, the benefits from such a decision are questionable. The main downside of this decision is the extra layer  of  complexity,  introduced  in  the  form  of  solidity  code  preprocessing,  which  aims  to  facilitate  the handling of such bitwords.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Choosing the Parameter gasreq",
        "body": "  When choosing the parameter gasreq, makers must be aware of certain things: As described in the code, the maker may receive only gasreq-63h/64 gas, where h is the overhead of (require + cost of CALL).  Nevertheless, should the call fail due to insufficient gas the maker is accountable for this and if the overall gas  remaining  in  the  transaction  is  sufficient,  the  transaction  penalizes  the  maker  and  completes successfully.  The comment states:  We let the maker pay for the overhead of checking remaining gas and making the call.  Albeit minor, the maker also pays for the overhead to handle the return data. All of this needs to be taken account when selecting the value for gasreq, especially in order to ensure enough gas will be available to the call to makerPosthook.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.3   Estimation of the Gas Limit for a ",
        "body": " marketOrder Transaction  Estimating  the  gas  limit  for  a  transaction  to  marketOrder  is  tricky.  Underestimating  it  leads  to  the transaction to revert, while overestimating it increases the risk of a high tx fee for a failing transaction.  Function  marketOrder  is  dependent  on  the  actual  status  of  the  offer  book  which  may  change significantly  between  when  the  transaction  is  generated  and  signed  and  when  it  is  executed  by  being included  inside  a  block.  Offers  may  be  added  or  removed  resulting  the  gas  requirement  for  the  offers being executed as part of the order may change significantly.  While marketOrder can skip failing offers and refund the taker, it can only do so successfully when the transaction has enough gas.  To avoid failing transactions users have to overestimate the gas required.  Mangrove Association (ADDMA) - Mangrove -   23  NoteVersion1NoteVersion1NoteVersion1          \f8.4   Payable Fallback Functions For Taker Contracts  Takers may be contracts. When makers are penalised, provision is sent to the takers by a low level call msg.sender.call{value: amount}(\"\"). In this case, taker contracts must be able to handle the ether received by implementing fallback functions.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.5   Tokens With Transfer Fees",
        "body": "  Mangrove  is  supposed  to  handle  the  exchange  of  ERC20  tokens.  As  shown  in  the  snippet  below,  the system  expects  to  send  to  the  maker  the  same  amount  (sor.gives)  it  received  from  the  taker. However, in the case of the tokens with transfer fees this trade will fail since the amount received and forwarded by Mangrove will be different than the one requested due to the fees. By providing additional balance of this token to the contract ahead of the transaction, a party may make the transfer to succeed nevertheless.  This  may  be  done  by  either  the  maker  or  the  taker.  The  other  party  then  receives  less tokens then expected, as the transfer fee will be deducted.  if (transferTokenFrom(sor.quote, taker, address(this), sor.gives)) {    if (      transferToken(        sor.quote,        $$(offerDetail_maker(\"sor.offerDetail\")),        sor.gives      )    ) {     ...  Mangrove Association (ADDMA) - Mangrove -   24  NoteVersion1NoteVersion1        \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Call to Vow.flap() Can Be Sandwiched",
        "body": "  The parameters for the FlapperUniV2 deployed at time of the audit are a lot of 5000 DAI, a cooldown period of 1577 seconds between calls to Vow.flap(), and 98% slippage tolerance through want.  An MEV searcher can therefore sandwich the Vow.flap() call and extract up to 2% of the 5000 DAI every  26  minutes.  The  gas  cost  of  calling  flap()  is  around  20$  at  the  current  gas  price  of  30  Gwei. Assuming  the  sandwich  attack  gas  cost  is  within  the  same  order  of  magnitude  (one  frontrunning transaction  and  one  backrunning  transaction,  on  warm  token  addresses,  and  warm  Uniswap  pool),  we expect a MEV searcher to extract a profit of around $50 per call. This amounts to a possible loss for the protocol of around $2800 daily.  MakerDAO - FlapperUniV2SwapOnly -   10  NoteVersion1  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Compression of Epochs in Struct",
        "body": "  0  0  0  4  It  is  unlikely  that  the  channel  struct  values  for  ticketEpoch  or  channelEpoch  will  ever  reach  the maximum  number  of  uint256.  HOPRNet  should  re-evaluate  if  these  values  can  be  bounded  e.g.  by uint128 and share a storage slot and thus lower the gas consumption of the contract.  Acknowledged  Gas efficiency issues are considered out of scope.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Gas Optimization",
        "body": "  The contract includes a struct that stores in storage a mapping with all channels and the respective state for each channel as following:  struct Channel {     uint256 balance;     bytes32 commitment;     uint256 ticketEpoch;     uint256 ticketIndex;     ChannelStatus status;  HOPRNet - Payment Channel -   8  SecurityDesignCorrectnessCriticalHighMediumLowAcknowledgedAcknowledgedAcknowledgedAcknowledgedDesignLowVersion1AcknowledgedDesignLowVersion1Acknowledged                   \f    uint256 channelEpoch;     // the time when the channel can be closed - NB: overloads at year >2105     uint32 closureTime;   }  The Channel struct includes an attribute status which is of type enum ChannelStatus and has only 4  values,  therefore  occupies  only  8  bits  in  the  storage.  Given  that  there  is  another  attribute uint32 closureTime that occupies another 32 bits, these two attribute status and closureTime should be reordered and placed together to optimize the overall storage used by the contract.  Acknowledged  Gas efficiency issues are considered out of scope.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   Node Can Set Ticket Index to Arbitrary High",
        "body": " Values  The ticket issuing node can set the ticket index at will. If this index is set to a value close or equal to max uint, the tickets would be unusable (not redeemable) quickly and the channel would need to be reset.  Acknowledged  The issue has been discussed and it was decided to check the ticket index off-chain.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.4   Redundant Sanity Checks",
        "body": "  The function fundChannelMulti checks if the two amounts are greater than zero, which are checked later again in the function _fundChannel.  The  modifier  validateSourceAndDest  is  executed  twice  for  each  call  of  _fundChannel  from fundChannelMulti if one would fund both channels directions.  Acknowledged  Hopr provided the reasoning why it is done this way and that efficiency issues are out of scope.  HOPRNet - Payment Channel -   9  DesignLowVersion1AcknowledgedDesignLowVersion1Acknowledged                  \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings   Reentrancy Can Drain Money   -Severity Findings  -Severity Findings  Inconsistent States and Events   -Severity Findings   Channel Transition Model    Redundant Imports    Token Transfers Inconsistent    Variables Could Be Labeled Immutable   1  0  1  4  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Reentrancy Can Drain Money",
        "body": "  The HoprChannels smart contract uses the ERC777 HoprToken to settle payments. The ERC777 token allows  reentrancies  during  the  transfer  via  sender  and  receiver  hooks.  An  attacker  can  utilize  this reentrancy to drain the balance of HoprChannels contract. One of the places where this can happen is in the finalizeChannelClosure function.  We describe a more elaborate attack and a straightforward attack.  Attack  setup:  Alice  and  Bob  cooperate.  They  have  created  channels  between  them,  Alice  has  called initiateChannelClosure  for  her  channel  with  Bob,  that  holds  100  tokens.  Bob  has  valid  and  yet unclaimed ticket for 75 tokens. Closure time has passed for the Alice owned channel. Alice has a smart contract registered for ERC777 hook. Bob is smart contracts that is registered in the ERC1820 registry for the ERC777 hooks.   Alice calls finalizeChannelClosure with Bob as destination.   During the call token.transfer(Alice, 100); in this function, Alice contract gets called.   Alice contract calls to Bob contract.   Bob contract calls the redeemTicket with valid unclaimed ticket.   Channel (Alice, Bob) is spending and (Bob, Alice) is earning.   Balance of (Alice, Bob) is decreased by 75. Since the balance of the channel is  still 100, the new value will be 25.   Balance of (Bob, Alice) is increased by 75.   Function redeemTicket returns.   The Bob contract execution returns to Alice  HOPRNet - Payment Channel -   10  CriticalCodeCorrectedHighMediumCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSecurityCriticalVersion1CodeCorrected         \f Alice contract returns finalizeChannelClosure call.   The execution continues after the call token.transfer(Alice, 100);   The balance (25 tokens) of Alice owned channel is nullified with delete and the status is set to the  CLOSED.  As a result of above described schema, the initial 100 tokens of (Alice, Bob) channel will be payed out to Alice, and in addition Bob will get 75 tokens from his ticket claim. Thus instead of 100 tokens 175 tokens were withdrawn.  The straightforward attack would be to reenter multiple time into the finalizeChannelClosure as the state  variables  are  changed  after  the  reentrancy  possibility.  As  a  general  rule,  all  state  dependent operations should be done before the possible reentrancy. Additionally, reentrancies could be completely blocked if not needed.    In functions that perform transfers of HOPRToken the transfer operations are moved to the end of the functions.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Inconsistent States and Events",
        "body": "  Functions using ERC777 transfers can be reentered (a reentrancy does not necessarily need to happen in  the  same  function  but  in  another  relevant  function  in  the  system.).  Some  of  these  functions  have  a code  after  the  possible  reentrancy  point.  This  might  become  problematic  if  the  logic  relies  on  state variables  like  in  finalizeChannelClosure,  redeemTicket.  Besides  the  more  critical  reentrancy issue we mentioned, these function's events might be inconsistent or misleading.  in  redeemTicket  event  ChannelUpdate   For  example,  is  emitted.  This  event  uses spendingChannel storage variable. Given the redeemTicket is called and the ERC777 hook is used to change any storage variable used in these events, the events can emit inconsistent information. This can be done if during the transfer, the hook calls the bumpChannel in between.  The same applies to the other places where logic after the reentrancy possibility relies on state variables. We do not know if the client's or third party software will rely on these events. If so, the severity of the issue would be affected.    In functions that perform transfers of HOPRToken the transfer operations are moved to the end of the functions.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Channel Transition Model",
        "body": "  According  to  the  channels  states  transition  model,  the  channel  in  Waiting  for  commitment  state cannot be taken into Pending To Close. In the smart contract code, such behavior is allowed in the initiateChannelClosure  function.  In  addition,  the  specification  provided  by  HOPRNet  also  allows such behavior.  HOPRNet - Payment Channel -   11  DesignMediumVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                \f  The transition model for channel states has been updated accordingly.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Redundant Imports",
        "body": "  The SafeERC20.sol library is imported twice in line 10 and 11.  Code corrected  The redundant import is removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Token Transfers Inconsistent",
        "body": "  The  HoprChannels  contract  has  inconsistent  use  of  SafeERC20  functions.  Since  the  token  is  known HoprToken contract that cannot be changed after the deployment, the use of SafeERC20 functions is redundant and introduces the unnecessary gas expenses.  token.transfer(msg.sender, channel.balance); token.safeTransfer(msg.sender, amount); token.safeTransferFrom(msg.sender, address(this), amount1 + amount2);  Code corrected  transfer is now used consistently.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Variables Could Be Labeled Immutable",
        "body": "  The keyword immutable and constant can be used to save gas because the compiler does not reserve a storage  slot  for  these  variables,  and  every  occurrence  is  replaced  by  the  respective  value.  Immutable variables are evaluated once at construction time and their value is copied to all the places in the code where they are accessed.  token  and  secsClosure  variable  can  not  be  changed  and  can  be  set  immutable. FUND_CHANNEL_MULTI_SIZE could be set to constant (if calculated beforehand) or else immutable as the value is known when compiling the contract and cannot be changed later.  to   Code corrected  The variables were labeled immutable.  HOPRNet - Payment Channel -   12  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Automated Security Tools",
        "body": "  While performing the audit we found a simple but severe issue which would have been flagged by basic smart contract security tools. Using linters, static analyzers and other tools could prevent these mistakes and increase the overall code quality.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Compiler Version",
        "body": "  The used compiler version 0.8.3 is six version behind the current version 0.8.9 (including bug fixes).  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Events Emit Complete Channel Struct",
        "body": "  HOPRNet might evaluate if it is necessary to emit the whole channel struct in events. We are not aware of the needs but if not the whole struct it needed, it would be more efficient to only include the relevant parts in the event.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   Pre- and Post Condition Checks",
        "body": "  If gas efficiency is not a priority, checking pre- and post conditions after important operations might be valuable. Consider for example that the contract balance could be queried before and after a transfer and it could be checked if the balance reduced or increased exactly to the expected amount.  HOPRNet - Payment Channel -   13  NoteVersion1NoteVersion1NoteVersion1NoteVersion1              \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   No Message Relayed on claim",
        "body": "  transmitted   Anytime  csToken.totalSupply()  or  funds.currentDeposit  are  changed,  the  updated  values function  does  not  call should  be  sendMessageToChild. The claim function has the enforceAndUpdateBalance modifier, which in turn  calls  _updateBalance.  This  function  may  modify  funds.currentDeposit,  and  hence  a message should be relayed to the child contract.  the  child  contract.  However,   the  claim   to   Note that the claim function is the only function with the enforceAndUpdateBalance modifier which does not call sendMessageToChild. Since the modifier itself can modify funds.currentDeposit, it may make sense to include the call to sendMessageToChild in the modifier itself.  ClayStack - ClayStack Matic -   11  CriticalHighMediumCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCorrectnessMediumVersion3CodeCorrected          \f  A message is now relayed at the end of the claim function.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Decoding Inefficiencies",
        "body": "  The ClayTunnel contract puts any message it receives directly in storage. When the stored amounts are retrieved,  they  have  to  be  decoded  each  time.  This  duplicates  effort,  as  well  as  incurring  additional storage  operations  due  to  the  use  of  the  generic  bytes  type.  A  stored  bytes  array  that  contains  64 bytes uses up 3 storage slots, one for the length and then two more for the contained values. Instead, it would  be  more  efficient  to  decode  the  message  when  receiving  it,  then  putting  the  decoded  values  in storage.  Additionally, in _processMessageFromRoot, it is possible to change the type of the data parameter from  bytes  memory  from processMessageFromRoot, where the argument passed is also a bytes calldata. This saves the effort of copying the bytes from calldata to memory.  to  bytes  calldata,  as   is  only  ever  called   function   the     The  relayed  variables  are  now  decoded  when  the  bridged  message  is  received,  and  the  decoded variables  then  persisted  in  storage.  The  data  parameter  was  changed  from  bytes  memory  to bytes calldata.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Redundant Function",
        "body": "  The  sendMessageToRoot  function  is  redundant,  as  the  root  ClayMain  contract  cannot  receive messages.  The _sendMessageToRoot function in the FxBaseChildTunnel abstract contract is similarly redundant.  The MessageSent event in FxBaseChildTunnel is only used in the above functions, hence it could be removed.    The redundant functions and event were removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Redundant Storage Variables",
        "body": "  The latestStateId and latestRootMessageSender storage variables in the ClayTunnel contract are not necessary for operation. Additionally, the latestRootMessageSender variable will only ever be set to the address of the ClayMain contract. Removing these redundant variables would reduce the execution cost of _processMessageFromRoot significantly.  ClayStack - ClayStack Matic -   12  DesignLowVersion3CodeCorrectedDesignLowVersion3CodeCorrectedDesignLowVersion3CodeCorrected                        \f  The  latestRootMessageSender  variable  was  removed.  latestStateId  is  now  used  to  enforce strictly increasing state IDs of relayed messages, meaning a reordering of messages due to validators cannot result in the child contract being set to an older state.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Variables Could Be Immutable",
        "body": "  The  storage  variable  fxChild  in  FxBaseChildTunnel  could  be  immutable,  as  it  is  only  ever  set  in  the constructor.  This  would  reduce  the  number  of  storage  operations  made  when  processing  bridged messages.  Similarly, the storage variable fxRootTunnel can only be set once, in the setFxRootTunnel function. As  this  variable  should  be  known  at  deployment,  and  it  must  be  set  in  order  to  make  the  contract operational, it could also be made immutable and set in the constructor.    The fxChild and fxRootTunnel variables were made immutable and are both set in the constructor.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Incorrect Permissions",
        "body": "  The setDefaultLiquidity function has a doc comment which states it should only be callable with the TIMELOCK_ROLE. However, the implementation checks if the caller has the CS_SERVICE_ROLE.  /**  * ...  * @notice Only `TIMELOCK_ROLE` callable.  * ...  */ function setDefaultLiquidity(uint256 value) external onlyRole(CS_SERVICE_ROLE) {     require(value < PERCENTAGE_BASE, \"CMO06\");     defaultLiquidity = value; }  Specification Changed:  The doc comment was changed to specify the function to be only callable with the CS_SERVICE_ROLE.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Inefficient Modifier",
        "body": "  ClayStack - ClayStack Matic -   13  DesignLowVersion3CodeCorrectedCorrectnessLowVersion1Speci\ufb01cationChangedDesignLowVersion1CodeCorrected                        \fThe  CsToken  contract  makes  use  of  the  onlyClayMain  modifier,  which  needs  to  know  what  the address of the ClayMatic contract is. Instead of implementing a storage value that can only be set once, an  immutable  variable  could  be  used.  This  would  also  be  far  more  gas-efficient,  since  immutable variables do not incur storage reads.    The storage variable was made immutable and the onlyOnce modifier removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   Logic Contract",
        "body": "  The ClayMatic and RoleManager contracts have problems with their UUPS logic contracts:  1. The initialize function is unprotected on the logic contracts.  2. The  upgradeTo  function  overrides  the  UUPSUpgradeable  function,  but  does  not  use  the  onlyProxy modifier.  Since there are no unprotected delegateCalls available, the effect of these problems is limited. But one can set the storage variables of logic contracts to any values. Consider using onlyProxy for functions that shouldn't be called on logic contracts directly.    The onlyProxy modifier was added to the initialize and upgradeTo functions.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   Missing Check",
        "body": "  The comment on the function setMaxWithdrawNodePercentage states:  /**  * ...  * Requirements:  * - `value` can not be zero.  * ...  */ function setMaxWithdrawNodePercentage(uint256 value) external onlyRole(CS_SERVICE_ROLE) {     require(value <= PERCENTAGE_BASE, \"CMO06\");     maxWithdrawNodePercentage = value; }  However, there is no check to make sure value is not equal to zero.    A check was added to make sure value is not equal to zero.  ClayStack - ClayStack Matic -   14  SecurityLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                  \f6.10   Missing whenNotPaused in Migrate Delegation  for All  balance  affecting  migrateDelegation,  this  seems  like  an  oversight  if  pause  is  meant  to  be  used  in  emergency  or upgrade situations where critical contract state should not change in between upgrades.  the  whenNotPaused  modifier  applied  except   functions  have     The whenNotPaused modifier was added to the migrateDelegation function.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.11   No Limit On Withdrawal and Deposit Fee",
        "body": " Amounts  There is currently no limit on any fee amounts besides being below 100%, but this should not be the case from  both  a  trust  and  correctness  perspective.  The  holder  of  TIMELOCK_ROLE  could  set  instant  or regular withdrawal fees to 100% to prevent anyone from withdrawing, or increase deposit fee to 100% to basically prevent anyone from staking any more funds without losing them all, effectively disabling those functions in a round-about way.  Consider setting hard limits in the contract beyond which fees cannot be raised without a total contract upgrade.    Maximum values were added to all fee types.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.12   Possible Underflow",
        "body": "  In the function _balanced the following check is done:  uint256 stakingFlow = (underlyingToken.balanceOf(address(this)) + funds.stakedDeposit) / 1e10; require(stakingFlow - 1e6 <= userFlow && userFlow <= stakingFlow + 1e6, \"CMB01\");  However,  if  underlyingToken.balanceOf(address(this))  +  funds.stakedDeposit  is  less than 1e16, this will result in an underflow and revert, despite not necessarily being an invalid state.    The code was refactored so the underflow is no longer possible.  ClayStack - ClayStack Matic -   15  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                        \f6.13   Reuse balanceOf Result When Possible  There  are  various  functions  which  call  underlyingToken.balanceOf(address(this))  multiple times. While in some cases, the balance does change and the additional cross-contract call is necessary, in others it is not. Therefore, the redundant calls could be omitted to save gas.  1. In autoBalance and _balanced, the balance of the contract is queried twice without any balance  change in between.  2. In _sequentiallyStake, the balance of the contract is queried once per loop iteration. While the balance  can  change  between  iterations,  it  may  instead  be  possible  to  check  that  the  balance  is greater than the total amount to stake, rather than checking individually for each staking operation.    1. The mentioned functions were updated to query the balance only once.  2. The total amount to stake is now compared to the balance at the start of the function, instead of  once per loop iteration.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.14   Staking Issues",
        "body": "  When  autobalance  is  run,  if  the  additional  amount  to  stake  is  consistently  smaller  than  the overStakingThreshold,  the  same  validator  will  be  chosen  every  time.  This  is  because  the activeStakingNode  does  not  change  if  only  the  first  node  is  used.  Thus,  the  amounts  staked  per validator  will  not  converge  if  the  amounts  to  stake  per  balancing  operation  are  consistently  below overStakingThreshold.    The  activeStakingNode  is  now  advanced  by  one  position  at  the  end  of  the  function  to  avoid  the mentioned issue.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.15   Storage Operations in Loops",
        "body": "  Many  different  functions  contain  loops  which  access  storage  variables.  Rather  than  reading  a  storage variable  once  per  loop  iteration,  it  is  more  gas-efficient  to  read  it  once  before  the  loop  and  cache  the value in a local variable.  There are also loops which write to storage variables. Again, rather than writing to storage directly in the loop, it's more gas-efficient to write to a local variable and move the final value to storage after the loop.  These optimizations can be applied in the following functions:  1. In  the  function  claim,  the  value  withdrawOrders[msg.sender]  can  be  stored  in  a  variable  outside the loop and reused.  2. In   getMaxWithdrawAmountCs,   the   storage   values   maxNodesToWithdraw   and  maxWithdrawNodePercentage can be cached.  ClayStack - ClayStack Matic -   16  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                      \f3. In  _sequentiallyStake,   the  number  of  storage  writes   to  activeStakingNode  and funds.stakedDeposit  can  be  reduced  significantly.  Additionally,  the  values  totalPoints, overStakingThreshold, stakeManager and underlyingToken could be cached. Note that it may not be possible to apply all these optimizations without causing a \"Stack too deep\" compilation error.  4. In _sequentiallyUnstake, the number of writes to activeUnstakingNode can be reduced. The  values  of  maxNodesToWithdraw  and  maxWithdrawNodePercentage  can  be  cached  to reduce storage reading operations.  5. In  _getMaxWithdrawAmount,   the  maxNodesToWithdraw can be cached.  values   of  maxWithdrawNodePercentage   and  6. In addNodes, the number of writes to totalPoints can be reduced by calculating the value in a local variable and writing to storage after the loop. Similarly, a local variable could be introduced to hold  the  value  of  countStakingNodes  and  the  final  value  written  back  only  at  the  end.  Lastly, stakeManager could be cached so it only has to be read once before the loop.  7. In autoBalance, _updatedStaked, _isNodeActive and _updateNodePoints, the value of  activeNodes.length can be stored locally to reduce storage reads.    The suggested changes were made. In the case of _sequentiallyUnstake, maxNodesToWithdraw was not cached due to the \"Stack too deep\" compilation error.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.16   Validator Contract Check Not Strict Enough",
        "body": "  Inside of ClayMatic.addNodes, the validity of a validator is checked in the following way:  require(stakeManager.isValidator(val.validatorId()) && !val.locked(), \"CMO10\");  Both  values  validated  against  are  sourced  from  the  supplied  contract  which  could  just  be  a  malicious contract  lying  about  being  a  validator.  A  check  with  stronger  correctness  would  be  to  require  that  the following is true:  stakeManager.getValidatorContract(validatorId) == val  This would prevent adding an invalid validator contract by mistake.    The suggested check was implemented.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.17   Wrong Variable Logged",
        "body": "  In  the  autoBalance  function,  any  accrued  fees  are  transferred  to  the  vault.  Additionally,  an  event  is emitted  to  log  the  transferred  fees.  However,  the  wrong  variable  is  used  for  the  event  so  the  emitted value will always be zero.  ClayStack - ClayStack Matic -   17  CorrectnessLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                \fif (funds.accruedFees != 0) {     uint256 accruedFees = funds.accruedFees;     funds.accruedFees = 0;     underlyingToken.safeTransfer(vaultManager, accruedFees);     emit LogTransferVault(vaultManager, funds.accruedFees); }    The correct variable is now used to log the event.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.18   Consider Using Modifiers for _Balanced and",
        "body": " _updateBalance Functionality  The calls to _balanced and _updateBalance could be more cleanly implemented via a modifier like the following:  modifier enforceAndUpdateBalance {  _updateBalance();  _;  _balanced(); }  It would prevent needing to manually ensure both are called, in the right order and priority, in any future update to the code and simply enforce the presence of this modifier on the relevant functions.    The suggested modifier was introduced and applied to all relevant functions.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.19   Unnecessary Require",
        "body": "  In the claim function, the following require statement is unnecessary:  require(amountAvailable >= userAmount + payableFee, \"CMC02\");  The  value  of  userAmount  is  essentially  calculated  as  receivedAmount  -  payableFee.  The  current balance  (amountAvailable)  cannot  be  smaller  than  the  amount  received,  therefore  this  check  will never fail.    The unnecessary require statement was removed.  ClayStack - ClayStack Matic -   18  NoteVersion1CodeCorrectedNoteVersion1CodeCorrected            \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Child Contract Is Not Upgradable",
        "body": "  The  child  ClayTunnel  contract  is  not  upgradable.  Therefore,  if  additional  functionality  were  to  be implemented in the ClayMain contract, which needed to be reflected on the Polygon network, a new child contract would have to be deployed. Hence, any users or protocols relying on the child contract should be aware that the address could change in the future.  ClayStack - ClayStack Matic -   19  NoteVersion3  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   DOMAIN_SEPARATOR Is Not Recomputed if",
        "body": " chainId Changes  The ERC712Permit.DOMAIN_SEPARATOR is immutable, and thus won't be changed if the chain forks. If Ethereum fork in the future (like PoW fork), the chainId will change however the BasePositionManager on forked  chain  will  still  accept  permit  with  old  chainId.  This  leads  to  cross-chain  replay  attacks,  where signature from one domain is used on the other domain.  CS-KYBE2-003  Kyber Network - KyberSwap Elastic V2 -   12  SecurityDesignCorrectnessCriticalHighMediumLowRiskAcceptedSecurityLowVersion1RiskAccepted             \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings   Oracle Observation Functions Parameters   -Severity Findings  -Severity Findings   Compiler and Library Versions    Missing Sanity Checks    Swap Amount Vs Price Limit Discrepancy    maxNumTicks Computation Can Be Wrong    secondsPerLiquidity of the First LP Starts at UNIX Time 0   0  1  0  5  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Oracle Observation Functions Parameters",
        "body": "  The PoolOracle functions observe, observeSingle, and observeFromPoolAt accept arbitrary parameters time that should serve as a reference point for the secondsAgo parameter, and tick that should  be  used  to  transform  the  latest  observation  if  needed.  But  the  Oracle  library  requires  the provided  time  to  be  the  current  block  timestamp,  and  tick  to  be  the  current  tick  of  the  pool.  More specifically  for  time,  the  function  Oracle.lte  requires  a  and  b  to  be  chronologically  before  time. Thus, an arbitrary time parameter may return a wrong value for the accumulator. The same is valid for an arbitrary value of tick, which could yield an incorrect accumulator if the last observation had to be transformed.  CS-KYBE2-001  Example with arbitrary time:  cardinality = 8 block.timestamp = 1050 time = 550 secondsAgo = 100  With  the  following  state,  for  simplicity  assume  that  tick timestamps are showed:    ==observationTimestamp i  ,  only  the i  |350| |500| |700| |900| |1024| |150| |220| |300|                             ^index  Kyber Network - KyberSwap Elastic V2 -   13  CriticalHighCodeCorrectedMediumLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCorrectnessHighVersion1CodeCorrected        \fthe function observeSingle(550, 100, 1024) will yield surrounding observations (4,0) (index 4 for  beforeOrAt  and  index  0  for  atOrAfter),  instead  of  the  expected  (0,1),  and  return  a  wrong tickCumulative value.  Description of changes:  observeFromPoolAt,   Remove  add observeSingleFromPool  to  read  a  single  observation  from  a  pool.  All  observe  functions  use block.timestamp as a time for.  observeSingle   observe,   functions,   and   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Compiler and Library Versions",
        "body": "  Solc version 0.8.9 is not the most up-to-date version and has known bugs.  The smart contract libraries used by the project are:  \"@openzeppelin/contracts\": \"4.3.1\", \"@openzeppelin/contracts-upgradeable\": \"^4.6.0\",  However, these libraries are neither up to date nor consistent with one another.  CS-KYBE2-002    The OZ libraries now both use version 4.3.1.  Regarding the solc compiler Kyber Network responded:  We  didn\u2019t  upgrade  the  solidity  version  to  latest  as  it  could  increase  the  possible  changes  for  the protocol.  Known bugs in solc 0.8.9 should not be triggered the assessed codebase.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Missing Sanity Checks",
        "body": "  The function TicksFeesReader.getNearestInitializedTicks is missing input sanitization for the tick parameter. It can accept invalid ticks such that tick < MIN_TICK or tick > MAX_TICK. The while loops won't terminate for invalid ticks.  CS-KYBE2-004    A check was added.  require(T.MIN_TICK <= tick && tick <= T.MAX_TICK, 'tick not in range');  Kyber Network - KyberSwap Elastic V2 -   14  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                  \f6.4   Swap Amount Vs Price Limit Discrepancy  CS-KYBE2-005  The  swap  terminates  in  2  cases:  specified  amount  is  exhausted  or  specified  price  limit  is  reached. However, there exists an edge case when specified amount is just enough to reach a price limit. In that case the Pool will rely on specified amount value as a limit, that will lead to computation of a new pool state  using  estimateIncrementalLiquidity  function.  If  the  price  limit  was  used,  the  new  state computation would be handled by calcIncrementalLiquidity function. The pool state is defined by prices and computation of a new state using token amounts leads to more numeric conversions and thus to less precision.  If  a  Pool  has  following  initialized  tick  ranges:  [a,  b)  [b,  c).  And  current  tick  is  b+1,  a  swap  specifying getSqrtRatioAtTick(b)  as  a  limit  would  switch  the  liquidity  to  the  value  of  [a,  b)  tick  range.  But  a swap swapQty needed to reach the same state would result in a pool state where the liquidity has not being shifted.    The computeSwapStep function uses calcIncrementalLiquidity when the usedAmount is equal to specifiedAmount. Thus, the more precise price limit is used for this edge case.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   maxNumTicks Computation Can Be Wrong",
        "body": "  In the functions TicksFeesReader.getTicksInRange , the computation of maxNumTicks can return a value that is too low when length==0, thus making the returned memory array incomplete.  CS-KYBE2-006  Example, when startTick < 0:  MAX_TICK = 2; MIN_TICK = -2; length = 0; startTick = -1; tickDistance = 1;  With this setting, maxNumTicks=3 and only the ticks -1, 0, 1 will be returned, missing the tick 2. In getAllTicks for this case will be: maxNumTicks=7, while should be 5.  Example, when startTick > 0:  MAX_TICK = 5; MIN_TICK = -5; length = 0; startTick = 2; tickDistance = 2;  With this setting, maxNumTicks=1 and only the tick 2 will be returned, missing the ticks 4 and 5.    Kyber Network - KyberSwap Elastic V2 -   15  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected              \fThe cases from above are fixed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   secondsPerLiquidity of the First LP Starts",
        "body": " at UNIX Time 0  CS-KYBE2-007  (LP)  opens   liquidity  provider   , the  When  a  1 poolData.secondsPerLiquidityUpdateTime  ==  0  and  _syncSecondsPerLiquidity()  will have  no  effect  since  no  base  liquidity  is  yet  in  the  pool.  When  the  second  position  is  opened  at  t , 2 _syncSecondsPerLiquidity() will update the state, but secondsElapsed will be equal to the time  will be accounted for since 0 delta from UNIX timestamp 0 until now (t instead of t  ). So, the liquidity added by LP  )  of  a  pool  at   first  position   (LP  1  1  2  .  t  1  Description of changes:  Always  update  the  poolData.secondsPerLiquidityUpdateTime  to  the  current  block  timestamp whenever the secondsElapsed > 0.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Code Duplication",
        "body": "  In  the  case  !isToken0,  the  function  SwapMath.calFinalPrice  computes  the  same  tmp  value  in each of the subbranches. The computation can be carried out outside of the conditional structure.  CS-KYBE2-008    The common code was moved outside the branch bodies.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   Wrong Comments",
        "body": "  The natspec of the struct IBasePositionManager.MintParams still mentions the fee in bps, but the fees have been updated to be in feeUnits.  CS-KYBE2-012    @param fee now correctly states that fee is in fee units.  Kyber Network - KyberSwap Elastic V2 -   16  CorrectnessLowVersion1CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected                    \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Gas Griefing Attack",
        "body": "  The swap function can perform multiple iterations of the while loop before terminating. Such execution can cost a lot of gas. Malicious actor can bring the pool price to an extremely high or low value. This can be  done  during  the  initial  Pool  unlock  or  via  swap.  While  swap  will  require  a  lot  of  gas  from  attacker, similar  amount  of  gas  will  also  be  required  to  bring  the  price  back  to  true  value.  Since  the  amount  of tokens needed to unlockPool is low, the cost of attack is small.  CS-KYBE2-009  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Oracle Limitations",
        "body": "  The tickCumulative from PoolOracle contract can be used to compute the time-weighted average tick for a given period of time. If the price is computed from this tick, this is effectively a geometric mean of the  time-weighted  average  price  (gm-TWAP).  Compared  to  the  arithmetic  mean  TWAP  (am-TWAP), gm-TWAP  is  more  sensitive  to  upward  price  movements  and  less  sensitive  to  downward  price movements. Any protocol that plans to use PoolOracle needs to be aware of this.  In addition, in PoS consensus, the multi-block price manipulations are possible on AMM protocols:  CS-KYBE2-010   https://chainsecurity.com/oracle-manipulation-after-merge/   https://blog.uniswap.org/uniswap-v3-oracles  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   PoolOracle Observations Mapping Collision",
        "body": "  The mapping(address => Oracle.Observation[65535]) field in PoolOracle contract allows any msg.sender to modifier consecutive 2**16 storage slots. This theoretically can write to storage slot 151 and  thus  overwrite  the  owner  of  the  contract.  Note  that  solidity  does  not  check  for  storage  pointer overflows. However, this is a practically impossible attack, since it requires attacker to find an address that corresponds to mapping storage slot with 240 fix bits.  CS-KYBE2-011  Kyber Network - KyberSwap Elastic V2 -   17  InformationalVersion1RiskAcceptedInformationalVersion1RiskAcceptedInformationalVersion1RiskAccepted                \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Excessive Memory Allocations",
        "body": "  0  0  0  3  The  slice  function  of  the  BytesLib  library  is  used  in  many  places.  In  some  cases,  it  is  used  inside  a loop. This allocates new memory on every loop iteration, even if the memory is no longer needed after the iteration finishes. Hence, it results in a much larger allocation of memory than is actually needed.  For  example,  we  can  examine  the  following  loop  from  the  _addSigningKeys  function  of  the NodeOperatorsRegistry:  for (uint256 i = 0; i < _keysCount; ++i) {     bytes memory key = BytesLib.slice(_publicKeys, i * PUBKEY_LENGTH, PUBKEY_LENGTH);     require(!_isEmptySigningKey(key), \"EMPTY_KEY\");     bytes memory sig = BytesLib.slice(_signatures, i * SIGNATURE_LENGTH, SIGNATURE_LENGTH);      _storeSigningKey(_nodeOperatorId, totalSigningKeysCount, key, sig);     totalSigningKeysCount = totalSigningKeysCount.add(1);     emit SigningKeyAdded(_nodeOperatorId, key); }  Here,  the  memory  is  only  temporarily  needed,  it  holds  the  values  copied  from  the  _publicKeys  and _signatures  arrays.  As  soon  as  the  loop  iteration  finishes,  the  key  and  sig  arrays  are  no  longer needed. However, the memory they used remains allocated.  Instead, the arrays could be declared outside the loop, and the values copied into them on each iteration. This  would  cut  the  total  memory  usage  of  the  _addSigningKeys  function  in  half.  As  memory  has  a quadratic cost, this could significantly reduce transaction costs.  The  same  optimization  could  be  applied  to  the  _makeBeaconChainDeposits32ETH  function  of  the BeaconChainDepositor contract, which also uses BytesLib.slice in a loop.  Lido - Staking Router -   11  DesignCorrectnessCriticalHighMediumLowRiskAcceptedRiskAcceptedAcknowledgedDesignLowVersion1RiskAccepted          \fthe  getSigningKeys  and  _loadAllocatedSigningKeys   Similarly,  the NodeOperatorsRegistry call _loadSigningKey in a loop. This allocates new memory in each iteration, despite each value only being needed for the duration of a single iteration.  functions   in   Changes in   ,  The  declarations  of  the  bytes  arrays  in  _addSigningKeys,  getSigningKeys  and In  _loadAllocatedSigningKeys  were  moved  outside  the  loop.  However,  they  are  still  re-allocated  in every loop iteration. _makeBeaconChainDeposits32ETH was not changed.  _addSigningKeys   For  that BytesLib.slice allocates a new bytes array every time it's called. In the case of getSigningKeys and _loadAllocatedSigningKeys, the culprit is the call to _loadSigningKey, which also allocates a new bytes array. Hence, the memory allocations still occur and the transaction costs remain the same.  _makeBeaconChainDeposits32ETH,   issue   and   the   is   Risk accepted  Lido responded:  Will be fixed in the next major protocol upgrade.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Rounding Errors",
        "body": "  1. In the _getKeysAllocation function, a number of _keysToAllocate is provided. However, it's not  guaranteed  that  all  the  keys  will  be  allocated,  as  rounding  errors  may  lead  to  an  incomplete allocation  of  the  keys.  For  example,  with  two  modules  each  with  a  targetShare  of  50%,  a _keysToAllocate  of  3  results  in  both  modules  being  allocated  just  one  key,  as  their targetKeys values will be rounded down to 1.  2. The  getRewardsDistribution  calculates  a  perValidatorReward  as  the  total  rewards divided by the total number of validators. Then it multiplies it by the number of validators per node operator. However, this leads to excessive rounding errors, as the division is performed before the multiplication. Instead, the multiplication should be performed first in order to reduce the amount of reward that is not distributed due to rounding errors.  Risk accepted:  Lido responded:  This is an expected behavior and impact is tolerable. Will be fixed in the next major protocol upgrade.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   Unnecessary Reduction of Vetted Key Count",
        "body": "  When  deleting  a  key  in  the  NodeOperatorsRegistry,  the  vettedKeysCount  is  set  to  the  index  of  the deleted key (if the deleted key is vetted). This is done because deleting a key actually swaps it with the last key, then deletes it. Hence, if the last key is swapped to a smaller index, it might otherwise become vetted.  However,  if  the  last  key  has  also  already  been  vetted,  this  could  be  unnecessary  -  instead  the vetted key count could simply be reduced by one.  Lido - Staking Router -   12  Version3Version3DesignLowVersion1RiskAcceptedDesignLowVersion1Acknowledged                \fAcknowledged  Lido acknowledges the issue and states the following:  Thank you for this finding. We won't fix this issue in current version but will address it later.  Lido - Staking Router -   13    \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings   Staking Rewards Incorrect Trimming   -Severity Findings   Dummy Iterations Can Be Avoided    MemUtils.memcpy Mask Is Wrong   -Severity Findings   Code Redundancies   Incorrect Comments   Interface Issues   Issues With Events    Non-existent Modules Are Active by Default    Sanity Checks Missing    Visibility Can Be Reduced   0  1  2  7  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Staking Rewards Incorrect Trimming",
        "body": "  In the StakingRouter, the getStakingRewardsDistribution assigns fees to recipient addresses. It then trims the resulting arrays so that there are no recipients that receive an amount of zero. However, this trimming does not work correctly.  The  recipients  and  moduleFees  arrays  are  filled  left-to-right,  using  the  same  index  as  the modulesCache.  This  means  that  the  \"empty\"  entries,  where  the  module  fees  are  zero,  occur non-deterministically throughout the array. Hence, when the last entries are trimmed, some modules that would  otherwise  receive  the rewardedModulesCount as an index for these arrays, so that modules which receive no fee would not increment the index.  fees  are  not  being  returned.  Likely,   intent  was   to  use   the   As  such,  the  results  returned  by  getStakingRewardsDistribution  have  the  potential  to  be  very incorrect,  distributing  far  less  fees  than  intended,  and  only  distributing  fees  to  the  recipients  \"lucky\" enough to be stored early in the modulesCache array.  Code corrected  The issue was fixed by using the rewardedModulesCount as an index for the resulting arrays, thereby ensuring that the modules receiving rewards are stored contiguously at the start of the returned arrays. Thus, the trimming is now done correctly.  Lido - Staking Router -   14  CriticalHighCodeCorrectedMediumCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCorrectnessHighVersion1CodeCorrected           \f6.2   Dummy Iterations Can Be Avoided  The  MinFirstAllocationStrategy  features  an  algorithm  which  allocates  items  to  buckets  with  different capacities.  In  some  cases,  the  algorithm  may  do  many  unnecessary  dummy  iterations,  which  each allocate a single item to a bucket. For example:  1. Let's start with the scenario where we have 5 empty buckets, each with a very large capacity.  2. Now, call the allocate function, with an allocationSize of 24.  3. In the first five iterations, each bucket will be allocated 4 items, as 24 / 5 is rounded down to 4.  4. Now,  an  additional  four  \"dummy\"  iterations  have  to  be  performed,  which  allocate  an  additional  single item to the first four buckets.  These  dummy  iterations  could  be  avoided,  for  example,  by  rounding  up  instead  of  down  when  the allocationSize  is  not  divisible  by  the  number  of  best  candidates.  This  would  result  in  the  first  four iterations allocating 5 items each, with the last iteration having only four items left and allocating them all to the last bucket.  Note  that  when  a  deposit  occurs,  this  algorithm  is  run  once  for  each  staking  module.  Hence,  as  this algorithm  is  executed  many  times,  reducing  the  number  of  iterations  could  reduce  business  costs, especially when more staking modules are added in the future.    The allocation algorithm was updated. Now, when there are more than one best candidates, the ceil of the division of the allocationSize by bestCandidatesCount is used.  allocated = Math256.min(     bestCandidatesCount > 1 ? Math256.ceilDiv(allocationSize, bestCandidatesCount) : allocationSize,     Math256.min(allocationSizeUpperBound, capacities[bestCandidateIndex]) - bestCandidateAllocation );  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   MemUtils.memcpy Mask Is Wrong",
        "body": "  The memcpy function in MemUtils copies a segment of memory from one location to another. It does so in  32-byte  chunks.  However,  if  the  length  of  the  segment  to  copy  is  not  divisible  by  32,  it  does  an additional copy with a masked value so that no memory values are overwritten when they shouldn't be. However, this is done incorrectly.  function memcpy(uint256 _src, uint256 _dst, uint256 _len) internal pure {     assembly {         // while al least 32 bytes left, copy in 32-byte chunks         for { } gt(_len, 31) { } {             mstore(_dst, mload(_src))             _src := add(_src, 32)             _dst := add(_dst, 32)             _len := sub(_len, 32)         }         if gt(_len, 0) {  Lido - Staking Router -   15  DesignMediumVersion1CodeCorrectedCorrectnessMediumVersion1CodeCorrected                \f            // read the next 32-byte chunk from _dst, replace the first N bytes             // with those left in the _src, and write the transformed chunk back             let mask := sub(shl(1, mul(8, sub(32, _len))), 1) // 2 ** (8 * (32 - _len)) - 1             let srcMasked := and(mload(_src), not(mask))             let dstMasked := and(mload(_dst), mask)             mstore(_dst, or(dstMasked, srcMasked))         }     } }  The mask value is calculated incorrectly. The shl instruction for Solidity assembly is specified as follows:  shl(x, y): Logical shift left of y by x bits.  Hence,  the  mask  is  not  shifting  1  to  the  left  by  some  amount.  Instead,  mul(8,  sub(32,  _len))  is being shifted to the left by 1 bit. As a result, the mask being calculated will always copy at least 30 bytes (since 2*8*(32-1)-1<512), with the remaining two bytes being partially or not at all copied, depending on the exact value of _len. In the case of _len % 32 == 16, exactly 31 bytes are copied, meaning an additional 15 bytes after the end of the memory segment are copied to the destination.  This  is  the  case  when  dealing  with  public  keys.  In  the  _loadAllocatedSigningKeys  and getSigningKeys functions of the NodeOperatorsRegistry, when the public keys are copied, the length will be 48 and hence not divisible by 32. So additional bytes are copied.  However, it happens to be the case the when _loadSigningKey is called, the allocated memory for the public key is directly followed by the signature. Hence, the 15 extra bytes which are copied are the first 15 bytes from the length field of the signature's bytes array. Because this length is always 3, these bytes are guaranteed to be zero.  Additionally, as the destination of the memory copy is filled left-to-right, for all but the last copy operation the  extra  bytes  that  are  written  are  immediately  overwritten  by  the  following  value.  Only  the  last  copy writes 15 bytes of zeroes past the end of the publicKeys bytes array. But again, due to the order of memory allocation, this array is followed in memory by the signatures bytes array. So, the extra bytes happen to overlap with the length field of the signatures array. As the length of this array is (hopefully) less than 2 ** (17 * 8), the extra bytes that are overwritten are already set to zero anyway.  All  in  all,  this  means  that  the  memcpy  function  works  correctly,  but  only  due  to  the  order  of  memory allocations,  which  happen  to  guarantee  that  the  extra  bytes  which  are  copied  to  and  from  are  always zero.  Code corrected  The argument order of the shl expression in the mask calculation was changed.  let mask := sub(shl(mul(8, sub(32, _len)), 1), 1)  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Code Redundancies",
        "body": "  In the current implementation there are a few code redundancies which can be improved. In particular:  1. In   NodeOperatorsRegistry.activateNodeOperator,  the ACTIVE_OPERATORS_COUNT_POSITION  is  increased  using  SafeMath.  However,  it  is impossible for this value to overflow.  Lido - Staking Router -   16  DesignLowVersion1CodeCorrected        \f2. In  NodeOperatorsRegistry.distributeRewards,  recipients.length  is  guaranteed to equal shares.length as it constructed by getRewardsDistribution that way. Hence, the relevant assertion will always be true.  3. In   MinFirstAllocationStrategy.allocateToBestCandidate,   condition allocationSize  ==  0  is  checked  after  the  first  loop,  despite  not  being  affected  by  it. Instead,  this  condition  could  be  checked  at  the  start  of  the  function.  Alternatively,  as  the function is only ever called from allocate, it is actually guaranteed the allocationSize is never equal to zero. Hence, the check could also be omitted fully.  the   4. In  StakingRouter.deposit,  it  is  ensured  that  keysToDeposit  does  not  exceed maxDepositableKeys,  which  is  calculated  by  querying  the  Lido  contract  and  querying  its buffered  Ether  amount.  However,  it  is  already  guaranteed  that  _maxDepositsCount  fulfills this  condition,  as  only  the  Lido  contract  can  call  this  function,  and  it  performs  checks  before making this call.  5. The  StakingRouter  has   functions,  _getStorageStakingModulesMapping  and _getStorageStakingIndicesMapping,  which  are  always  called  with  the  same  constant arguments. Instead of passing these arguments to the functions, the functions could inline the values in order to reduce unnecessary complexity and allow for more optimal bytecode.  two   6. In the StakingRouter's deposit function, a StakingRouterETHDeposited event is emitted with  the  parameter  _getStakingModuleIdByIndex(stakingModuleIndex).  However, the staking module's ID was already passed as an argument to the function, so it doesn't need to be looked up. Instead, _stakingModuleId could be used as a parameter to this event.  7. NodeOperatorsRegistry.addNodeOperator  will  always  emit  a  NodeOperatorAdded event with 0 staking limit. As there are no occasions where the event is emitted with a non-zero staking limit, this field contains essentially no information and is redundant.  8. In   NodeOperatorsRegistry._getSigningKeysAllocationData,   of nodeOperatorIds  and  exitedSigningKeysCount  arrays  are  potentially  written to is  where  redundantly  vettedSigningKeysCount, as they may be overwritten in a following iteration.  depositedSigningKeys   equal   case   cells   the   the   in   9. In  NodeOperatorsRegistry.getRewardsDistribution,  a  non-empty  recipients array could be returned even though the shares array contains only 0s. This corner case can happen if all the node operators are active but all their validators have exited.  10. NodeOperatorsRegistry.getValidatorsKeysStats  makes   of SafeMath  desired exitedKeys <= depositedKeys <= vettedKeys invariant hold, the subtractions should never underflow.  redundant  the   though,   should   even   use     Most of the redundancies reported have been fixed.  1. SafeMath is not used any more.  2. The corresponding assertion has been removed.  3. The check was moved at the beginning.  5. Now, the two functions do not accept any argument.  6. _stakingModuleId is now used.  8. The   array   elements   are   now   written   after   the  depositedSigningKeysCount == vettedSigningKeysCount check.  10. SafeMath is no longer used in the getValidatorsKeysStats function.  Lido - Staking Router -   17  \fAcknowledged:  4. Lido acknowledges the additional cost associated with the redundant check.  7. This is intended behavior in order to keep backwards compatibility.  9. The returning of empty shares entries is intended behavior.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Incorrect Comments",
        "body": "  The code contains some inaccurate comments:  1. The  doc  comment  for  the  _stakingModuleAddress  of  the  addModule  function  is  as  follows:  /**  * ...  * @param _stakingModuleAddress target percent of total keys in protocol, in BP  * ...  */  This is incorrect and describes a different parameter.  2. Point 4. in the comment in MinFirstAllocationStrategy.allocateToBestCandidate is not updated. In the current implementation, DivCeil(allocationSize, count) is used instead of integer division.  3. In  NodeOperatorsRegistry,  addSigningKeys  enforces  the  same  access  control  as addSigningKeysOperatorBH.  The  same  holds  for  removeSigningKeys  the  same  as removeSigningKeysOperatorBH.  This  implies  that  the  BH  versions  of  the  functions  are pointless and can be considered deprecated. However, they are not marked as such.    Comments 1. and 2. have been fixed. 3. is left as is, the functions exist for backwards compatibility and are hence not deprecated.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Interface Issues",
        "body": "  The interfaces for certain contracts were defined multiple times, once for version ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "0.4.24 ",
        "body": "and once for version 0.8.9. However, some of the duplicate interfaces have outdated or clashing definitions:  1. The  0.8.9   ILido   interface  defines   the   functions  updateBufferedCounters  and  getLastReportTimestamp, which are not implemented by the Lido contract.  2. The   0.4.24   function getStakingModuleMaxDepositableKeys  which  takes  a  parameter  with  the  incorrect  name _stakingModuleId. The 0.8.9 interface was changed to take the _stakingModuleIndex as a parameter instead.  IStakingRouter   interface   defines   a   Moreover,  there  are  some  mismatches  between  the  functions  defined  in  the  interface  and  the  ones actually implemented. The 0.4.24/ILido interface defines the following function signatures:  Lido - Staking Router -   18  CorrectnessLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                \ffunction getFee() external view returns (uint16 feeBasisPoints); function getFeeDistribution() external view returns (uint16 modulesFeeBasisPoints, uint16 treasuryFeeBasisPoints);  However, the Lido contract implements these functions with different return types:  function getFee() public view returns (uint96 totalFee) {     // ... }  function getFeeDistribution() public view returns (uint96 modulesFee, uint96 treasuryFee) {     // ... }  Code corrected  Regarding mismatches between different versions:  1. The unimplemented functions were removed from the 0.8.9 ILido interface.  2. The  0.8.9  version  of  the  IStakingRouter  interface  was  changed,  the  parameter  for  the of  now  _stakingModuleId   instead   is   getStakingModuleMaxDepositableKeys  _stakingModuleIndex.  Regarding mismatch of the Lido contract between interface and implementation:  The interface was corrected to match the implementation.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Issues With Events",
        "body": "  In the implementation there are some issues with the events:  In  NodeOperatorsRegistry.addNodeOperator,  two  events  are  emitted.  Namely, NodeOperatorAdded(id)  and NodeOperatorAdded(id,  _name,  rewardAddress,  0).  The  second  event  contains strictly more information than the first one.  In  NodeOperatorsRegistry.activateNodeOperator,  the  NodeOperatorActiveSet event is not emitted even though it is defined.  In NodeOperatorsRegistry.deactivateNodeOperator, the NodeOperatorActiveSet event is not emitted.  In  NodeOperatorsRegistry.distributeRewards,  the  RewardsDistributed  event uses  idx  which  is  not  the  id  of  the  node  operator  but  the  index  of  the  operator  in  the recipients array. Note that this index can vary based on the status of the various operators. Moreover, the event is emitted even if shares[idx] is 0.  In  DepositSecurityModule._setGuardianQuorum,  event will be emitted even if the quorum has not changed.  the  GuardianQuorumChanged  In StakingRouter.setStakingModuleStatus, the StakingModuleStatusSet event will be emitted even if the status of the module has not changed.  Code corrected  The issues have been remedied in the following ways:  Lido - Staking Router -   19  DesignLowVersion1CodeCorrected              \f NodeOperatorsRegistry.addNodeOperator  only  emits  the  event  with  more  information.  The definition of the other event was removed from the IStakingModule interface.   NodeOperatorsRegistry.activateNodeOperator   now   emits   NodeOperatorActiveSet event.   NodeOperatorsRegistry.deactivateNodeOperator   now   emits   a  a  NodeOperatorActiveSet event.   The RewardsDistributed event was changed to take the rewards address as a parameter. NodeOperatorsRegistry.distributeRewards  emits  the  event  with  recipients[idx] as the address. Additionally, the transfer and event emission are omitted if the shares amount is 0.   DepositSecurityModule._setGuardianQuorum  no  longer  emits  an  event  if  the  quorum  has not changed.   StakingRouter.setStakingModuleStatus  now  reverts  if  the  new  status  is  the  same  as  the old one.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   Non-existent Modules Are Active by Default",
        "body": "  Should  StakingRouter.getStakingModuleByIndex  be  called  with  a  non-existent  index,  it  will return  an  empty  StakingModule.  the  StakingModule  struct  has  a  status  field  of  type IStakingRouter.StakingModuleStatus.  Since  the  default  value  of  the  enum  is  Active,  any uninitialized  staking  module  will  be  considered  active.  This  could  be  a  potential  problem  for  other contracts calling getStakingModuleByIndex.  Code corrected  The  StakingRouter.getStakingModuleByIndex  the StakingRouter.getStakingModuleMaxDepositableKeys function was modified to take an ID as an  argument  instead  of  an  index.  However,  it  is  worth  noting  that  the  default  value  of  the StakingModuleStatus is still Active.  removed.  Additionally,   function  was   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   Sanity Checks Missing",
        "body": "  In the current implementation, a few sanity checks are missing. More specifically:  In  NodeOperatorsRegistry.removeSigningKeys,  _fromIndex  and  _keysCount  are checked to be less than UINT64_MAX. However, these checks do not suffice, as it's important that the sum of the two inputs is also less than UINT64_MAX (and strictly greater than 0). Note that in any of these cases, SafeMath calculations taking place later will revert.  In  NodeOperatorsRegistry.removeSigningKeys,  _keysCount  is  not  checked  to  be non-zero.  This  is  not  symmetric  to  the  addSigningKeys  case  where  such  a  check  is performed.  Moreover,  should  _keysCount  equal  0  the  call  will  have  no  effect,  yet  the ValidatorsKeysNonce will increase.  In theory, the NodeOperatorsRegistry can hold up to UINT64_MAX different keys for each operator ranging from indices 0 up to UINT64_MAX - 1. This means that _index cannot be from  removeSigningKey  and equal   to  UINT64_MAX.  However,   is  allowed   this   Lido - Staking Router -   20  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                   \fremoveSigningKeyOperatorBH. The inequality of the sanity check in these cases should be strict.  In StakingRouter.addModule, the _stakingModuleAddress argument is not checked to be non-zero. As this address cannot be changed later, it may be important to sanity-check the value before setting it.  In StakingRouter.addModule, the _name argument is not sanitized to be at most 64 bytes while such a check exists for the name argument in the NodeOperatorsRegistry.  In  NodeOperatorsRegistry._addSigningKeys,  while  the  public  keys  are  checked  to  be non-empty, there is no such a check for the signatures.  Code corrected  NodeOperatorsRegistry.removeSigningKeys was changed in the following ways:   The sum of _fromIndex and _keysCount is checked to be less than UINT64_MAX. Note that the  check  for  _fromIndex  <  UINT64_MAX  is  now  redundant,  as  the  sum  of  two  unsigned integers is always greater or equal than both summands (assuming no overflow occurs). Note also that the conversion uint256(_fromIndex) is redundant.   _keysCount  is  checked  to  be  non-zero  in  the  _removeUnusedSigningKeys  function,  in  order to not emit redundant events.  The NodeOperatorsRegistry was modified so that all checks comparing the index to UINT64_MAX are now done with a strict inequality.  StakingRouter.addModule was modified as follows:  It was renamed to addStakingModule in   .   The _stakingModuleAddress is checked to be non-zero.   The _name parameter is checked to be between 1 and 32 bytes in length.  Acknowledged  Regarding the missing check for signatures, Lido states  Will be fixed in the next major protocol upgrade.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   Visibility Can Be Reduced",
        "body": "  Visibility  of  certain  functions  can  be  restricted  in  order  to  reduce  gas  costs.  The  following  functions' visibility could be changed from public to external:  Lido:  1. getCurrentStakeLimit  2. getBeaconStat  3. getFee  4. getFeeDistribution  StETH:  1. getTotalShares  2. sharesOf  Lido - Staking Router -   21  Version2DesignLowVersion1CodeCorrected            \f3. transferShares  StakingRouter:  1. getKeysAllocation  Lastly,  MinFirstAllocationStrategy library to private instead of internal.  it  may  make  sense   reduce   to   the  allocateToBestCandidate   function  of   the    The visibility of the functions was changed as suggested, except for the allocateToBestCandidate function.  Lido - Staking Router -   22  \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Discrepancy in Event Argument",
        "body": "  a   is   called,   Lido.submit   When  the _emitTransferAfterMintingShares function. This event contains a field which corresponds to the amount of ETH used to mint the respective amount of shares the user received. It is likely, however, that the  amount  is  not  exactly  the  same  as  the  one  sent  by  the  user  since  the  calculation  of  the  shares amount  to  be  minted  can  incur  some  rounding  errors.  For  example,  assume  that  a  user  submits  1234 wei,  the  total  number  of  shares  is  10  and  pooled  ether  amount  is  1000  wei.  Then  the  user  will  mint 1234*10/1000 = 12 shares and the argument in the Transfer event will be 1200.  Transfer   emitted   event   by   is   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Misleading Calculation in ",
        "body": " _deleteSigningKey  The _deleteSigningKey function deletes a (key, signature) pair from storage by writing zeroes to the bytes where they were stored.  function _deleteSigningKey(uint256 _nodeOperatorId, uint256 _keyIndex) internal {     uint256 offset = _signingKeyOffset(_nodeOperatorId, _keyIndex);     for (uint256 i = 0; i < (PUBKEY_LENGTH + SIGNATURE_LENGTH) / 32 + 1; ++i) {         assembly {             sstore(add(offset, i), 0)         }     } }  of   number   The  expression (PUBKEY_LENGTH  +  SIGNATURE_LENGTH)  /  32  +  1.  However,  this  calculation  relies  on  the  fact that  PUBKEY_LENGTH  is  not  divisible  by  32,  and  that  SIGNATURE_LENGTH  is.  The  calculation  is misleading as it is not correct in the general case, where the lengths could assume any value.  calculated   zeroed   bytes   the   out   be   to   in   is   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Staking Modules Can DOS",
        "body": "  The staking router makes external calls to the staking modules in several situations. For example, when making a deposit, it calls into all active staking modules to query their validator key stats. This means that a revert by any single module prevents the staking router from depositing to any other module.  While the modules are trusted in general, it should be ensured in their development that these calls do not propagate the potential denial of service attack one level deeper, e.g. to the users running validators in the case of some distributed validator technology.  Lido - Staking Router -   23  NoteVersion1NoteVersion1NoteVersion1          \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Inconsistent Sanity Checks of Span Length",
        "body": "  In batch_renew() there are sanity checks to validate that the domain, renewer, and limit_price spans have the same length. However, similar length verifications are missing for the tax_price and metadata spans, which is inconsistent.  Discrepancies  in  length  would  ultimately  lead  to  a  failure  with  an  expect('pop_front  error'); error, nevertheless sanity checks may be implemented consistently.  CS-STKIDAUTO-005    The missing sanity checks have been added.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Incorrect Comments",
        "body": "  In  the  constructor,  the  auto  renewal  contract  approves  max  u256  (integer::BoundedInt::max()) allowance to the naming contract. Whereas the comment says the allowance is set to 2^251-1.  CS-STKIDAUTO-004  Specification changed:  The comment has been corrected to: allowing naming 2^256-1.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Admin Functions Do Not Emit Events",
        "body": "  StarknetID - Auto Renew -   11  CS-STKIDAUTO-006  CriticalHighMediumLowCodeCorrectedSpeci\ufb01cationChangedDesignLowVersion1CodeCorrectedCorrectnessLowVersion1Speci\ufb01cationChangedInformationalVersion1CodeCorrected                        \fThe admin functions to update admin address, tax contract, whitelisted renewer, toggle flag, and claim tokens  do  not  emit  events.  Users  are  not  able  to  observe  these  state  updates  by  events  and  are expected to query these up-to-date states onchain.    Admin functions changing states, except start_admin_update() now emit events.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Unused Imports",
        "body": "  The following imports are not used and could be removed.  use traits::{TryInto, Into}; use option::OptionTrait; use integer::u64_try_from_felt252; use debug::PrintTrait;    The unused imports have been removed.  CS-STKIDAUTO-003  StarknetID - Auto Renew -   12  InformationalVersion1CodeCorrected      \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Disable Renewals Do Not Check the Flag",
        "body": "  disable_renewals() will set the flag of the corresponding spending channel to false regardless of the current flag. As a result, a user can call disable_renewals on an already disabled channel and emit the DisabledRenewal event, which might be misleading to the observers of this event.  CS-STKIDAUTO-001  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   batch_renew() Reverts if One Action Fails",
        "body": "  Inherent to the design of batch_renew(), a single unsuccessful renew action within the loop reverts the entire execution. It is the responsibility of the whitelisted renewer to ensure the batch is valid.  Technically,  interference  with  the  operation  of  the  Auto  Renew  Bot  is  possible  by  front  running  its transaction,  for  instance  by  removing  token  transfer  approval,  renewing  a  domain  (which  is permissionless), disabling the flow. Given the centralized sequencer, such disruptions are not expected. However,  potential  future  decentralization  of  the  sequencer  could  elevate  the  likelihood  of  such disruptions occurring throughout the contract's lifetime (years).  CS-STKIDAUTO-002  StarknetID - Auto Renew -   13  InformationalVersion1RiskAcceptedInformationalVersion1RiskAccepted          \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   A Domain With No Owner Can Still Be",
        "body": " Renewed  There is no ownership check if a domain has an owner when it is renewed. In case a user set a renewal spending flow for a domain that nobody owns, the renewal will succeed and the domain's expiry will be set to one year. The user who buys the domain later will take the benefit from this renewal:   Alice renews a domain D that nobody owns, D will have one year of expiry since then.   Later, Bob buys domain D for one year.   Now Bob owns domain D which has two years expiry.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   The Admin Can Pause Auto Renew",
        "body": "  Though there is no specific functionality to pause calls to renew() and batch_renew(), the admin can still achieve this. The admin can set the tax contract address to 0x0. In the present ETH ERC-20 contract implementation, transactions transferring to the 0x0 address revert.  StarknetID - Auto Renew -   14  NoteVersion1NoteVersion1      \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Rounding Error Leads to Blocked Queue",
        "body": "  Rounding errors can block the processing of an operation eventually blocking the whole system. There are multiple instances of this issue.  CS-APYF-001   Redeeming  a  small  amount  through  the  master  vault  could  round  down  to  zero  one  of  the shares  computation  per  chain.  However,  a  zero  amount  shares  redemption  on ApyFlow.redeem()  reverts  because  a  computation  uses  the  number  of  shares  as  a denominator. The following computation fails in ApyFlow._redeem():  uint256 processedPricePerToken = (valueInAsset * (10 ** decimals())) / shares;  In BaseConcentratedLiquidityStrategy._redeem(), a rounding error in the calculation of the liquidity to be removed can lead the system to block as UniswapV3/QuickswapV3 does not allow removing 0 liquidity:      uint128 liquidity = uint128(     (_getPositionData().liquidity * shares) / totalSupply() );  In  BaseConcentratedLiquidityStrategy._deposit(),  a  the calculation of the liquidity to be added can lead the system to block as UniswapV3/QuickswapV3 does not allow adding 0 liquidity.  rounding  error   in    The same issues as above appears in BaseHedgedConcentratedLiquidityStrategy.  yldr.com - yldr.com -   14  SecurityDesignCorrectnessCriticalHighMediumAcknowledgedAcknowledgedLowDesignMediumVersion2Acknowledged              \fAcknowledged:  yldr.com replied:  There always will be ways of making deposit/redeem revert at some step of processing and block the queue.  Such  attacks  are  non-profitable  and  relatively  expensive  for  an  attacker  and  considered non-likely.  Even  if  attacks  will  happen,  we  have  admin  functionality  which  allows  skipping  of  such malicious operations or funds recovery in case of vault becoming fully non-functionable.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Inflating Shares Price",
        "body": "  The  exchange  rate  for  all  ApyFlowVault  contracts  depends  on  some  balances  of  the  assets  in  the smart contract. Consequently, any asset donation will be taken into account and increase the exchange rate of the vault, and the value of the shares.  A vault with a very small or equal to zero totalSupply, is therefore vulnerable to a price inflation attack.  A malicious user could first mint a small number of shares and then send a great amount of assets to the smart contract.  CS-APYF-002  subsequent   Any  computation assets.mulDiv(totalSupply_,  totalAssets_)  round  to  zero  if  the  deposit  amount  is  smaller than  the  exchange  rate,  leading  to  assets  being  transferred  to  the  contract  but  no  shares  minted  in exchange.  deposit   would   make   the   Even if the amount is greater than the exchange rate, the rest of the division would not be accounted for because  of  the  rounding  error,  leading  to  a  partial  donation  of  the  funds  to  the  current  vault  shares holders.  Client acknowledged and replied:  Our standard procedure is to deposit a small amount of funds (5-100 USD) into each newly created vault to test if it's functionable and to avoid an inflation attack.  yldr.com - yldr.com -   15  SecurityMediumVersion1Acknowledged          \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings   Minting More Shares    Price Manipulation   -Severity Findings   A Deposit Could Be Stuck Because of Slippage    Fees Are Not Properly Harvested    Missing Calculation    Aave.ltv Cannot Be Updated   -Severity Findings   Underflow in Deposit Blocks the System    Zero Redemption Blocks the System    Dust in Deposits   Idling Assets Unused in readdLiquidity()    Leftovers Are Not Handled    Queue Processing Is Slow    Redemption of Small Amounts Is Impossible    SlaveCrossLedgerVault With a Zero Portfolio Score    Unused Function    minimumOperationValue Could Block Redeems   -Severity Findings   Discrepancy Between Computed and Actual Price per Token    Queue Could Be Stuck Because of Small-Amount Swaps   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Minting More Shares",
        "body": "  2  4  10  2  The  _startDeposit()  function  in  the  MasterCrossLedgerVault  iterates  over  each  chain  and deposits  an  amount  proportional  to  their  associated  portfolio  score  returned  by  the  oracle.  In  the  case where the amount destined to this chain rounds down to zero, the chain is ignored in _deposit() and the loop continues and no message is sent to and received from the chain. This can allow a malicious user to mint more shares than the value they deposited.  The amount of shares minted is computed in the MasterCrossLedgerVault as follows:  CS-APYF-027  yldr.com - yldr.com -   16  CriticalCodeCorrectedCodeCorrectedHighCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedMediumCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedSecurityCriticalVersion2CodeCorrected         \fuint256 totalAssetsBefore = totalAssetsBeforeDeposit[opId]; uint256 totalAssetsAfter = totalAssetsAfterDeposit[opId]; uint256 deposited = totalAssetsAfter - totalAssetsBefore; uint256 shares; if (totalSupply() == 0) {     shares = totalAssetsAfter; } else {     shares = (deposited * totalSupply()) / totalAssetsBefore; }  For  a  fair  computation  of  the  shares,  totalAssetsBefore  should  denote  the  full  value  of  all  assets across all chains. totalAssetsBeforeDeposit[opId] is increased after a message is received from a slave chain that contains the total value of the assets held on the chain before the deposit of the user's assets. As no deposit is performed on the slave chain no such message is received.  The  next  important  aspect  to  understand  is  the  deposited  amount  does  not  depend  on  the  actual amount deposited by the user when the initiate the deposit. If the attacker donates to a pool used by an asset converter in the same transaction, the asset converter can receive a higher amount of the output token  than  the  current  price.  This  allows  the  attacker  to  take  advantage  of  the  rounding  down  errors caused  by  the  small  amount  originally  deposited  while  they  eventually  deposit  a  big  amount  to  the system.  Since the shares minted depend on the ratio deposited/totalAssetsBefore, the attacker is able to mint  a  big  amount  of  shares  as  they  increased  deposited  (by  manipulating  the  pool)  while  keeping totalAssetsBefore low (by skipping chains).  The  attacker  can  now  redeem  their  shares.  Redemption  works  a  bit  differently  than  depositing:  It  just iterates over all chains without taking into account the portfolio score but instead provides them with a relative  proportion  (shares  &  totalSupply),  so  that  each  SlaveCrossLedgerVault  can  use  this proportion to compute how many assets to redeem.  However,  for  totalAssetsBefore  to  be  updated  by  a  slave  vault,  a  cross-chain  deposit  must  have occurred, which isn't the case when the argument is zero in _deposit().  To sum up the attack, the attacker would:  1. Call  MasterCrossLedgerVault.deposit()  with  a  small  amount.  This  makes  every amount  round  down  to  zero  except  for  one  chain  which  would  have  a  very  small  amount deposited.  2. Increase this deposited amount by for example manipulating a liquidity pool.  3. Steal funds by directly redeeming the inflated number of shares minted.    A  new  type  of  message  has  been  introduced:  ZERO_DEPOSIT  to  handle  the  case  where  the  amount rounds down to zero. This allows chains to communicate their total assets even though no funds were deposited during the operation.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Price Manipulation",
        "body": "  CS-APYF-026  yldr.com - yldr.com -   17  DesignCriticalVersion1CodeCorrected        \fConcentrated liquidity strategies must be able to compute the price and value of their liquidity position for price  range  adaptation  and  accounting  purposes.  However,  current  price  computations  only  use manipulable pool data, which can consequently not be relied on to provide real market price and value.  Such manipulation leads to critical issues:  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2.1   Manipulate the price range rebalance process:",
        "body": " The concentrated liquidity strategies should automatically adapt their price range when the current pool price  function readdLiquidity(),  which  heavily  depends  on  the  current  pool  tick.  The  pool  tick  is  heavily manipulable  and  could  be  used  by  an  attacker  to  make  the  strategy  provide  liquidity  at  a  manipulated price.  the  currently  set  range.  This  process  happens   is  above  or  under   the   in   function readdLiquidity() public virtual {     ...     (int24 currentTick, ) = _getPoolData();     int24 tickLowerToRebalance = data.tickLower + ticksUntilRebalance;     int24 tickUpperToRebalance = data.tickUpper - ticksUntilRebalance;     bool isInRebalanceRange = (tickLowerToRebalance > currentTick) || (tickUpperToRebalance < currentTick);     ...     require(         isInRebalanceRange ||             (pricePerTokenAfter >= (lastPricePerToken * 1001) / 1000)     );  An example attack flow on a USDC-WETH pool strategy:  1. Borrow a lot of ETH in a flash loan  2. Sell all ETH in the strategy's pool: Price and tick are now manipulated, price of ETH related to  USDC is much lower than the real market price  3. Call readdLiquidity() on the strategy: The current tick is now in the rebalance range, and  the function executes and moves liquidity around the current tick  4. Buy back ETH in the pool with every USDC received from step 2: Liquidity moved in step 3 is now  at  a  very  advantageous  price  for  the  attacker,  who  makes  a  profit  out  of  the  strategy's funds.  5. Repeat  Note that this attack depends on the strategy's liquidity size, as well as the pool's size and the fees.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2.2   Manipulate the strategy's exchange rate:",
        "body": " The shares exchange rate depends on the totalAssets() function that computes the total value of the strategy's funds.  function totalAssets() public view override returns (uint256) {     ...     (uint256 amount0, uint256 amount1) = LiquidityAmounts         .getAmountsForLiquidity(             sqrtPriceX96,             sqrtPriceAX96,             sqrtPriceBX96,             _getPositionData().liquidity         );     uint256 valueInUSD;     valueInUSD += pricesOracle.convertToUSD(token0(), amount0);     valueInUSD += pricesOracle.convertToUSD(token1(), amount1);  yldr.com - yldr.com -   18  \fHere,  amount0  and  amount1  will  depend  on  sqrtPriceX96,  which  is  the  current  price  of  the  pool. These amounts will then be converted to their real current market value in USD (which may not be close to the pool price).  Note that at any point in time, some assets might be idling in the smart contract.  This issue could lead to multiple consequences:   An attacker could potentially lower the price of the liquidity position and deposit assets that will be overvalued proportionally to the liquidity position, resulting in some extra shares being minted to the attacker.  Inflating the value of the strategy shares if they are used in an external protocol (for example as collateral).   Front-running a user deposit/redeem could become profitable.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2.3   Forced slippage:",
        "body": " readdLiquidity() is allowed to execute only if either the price of the pool is out of the current liquidity range or if the price per token after execution has increased. However, being able to manipulate the price of the liquidity pool makes it possible to execute the function on request.  An attacker could use this ability to force the pool to lose value in fees and slippage because of swaps happening during execution.  Note  that  this  list  of  potential  consequences  isn't  exhaustive  as  most  function  that  rely  on totalAssets() are vulnerable.    BaseConcentratedLiquidityStrategy.checkDeviation()   been The  modifier  implemented.  The  modifier  checks  whether  the allowedPoolOracleDeviation from the price reported by an external oracle. If this condition is not true the execution reverts. This means that users are unable to redeem and withdraw their assets during this period of time. Moreover, deposits iniated from the Master vault will be blocked for this period.  the  price  of  a  pool  deviates  more   than   has   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   A Deposit Could Be Stuck Because of",
        "body": " Slippage  In  MasterCrossLedgerVault,  processing  a  deposit  operation  in  the  queue  starts  by  swapping  the deposited  asset  with  the  main  asset  of  the  vault.  To  swap  in  between  assets,  the  vault  uses  an AssetConverter, which checks that the slippage does not exceed a fixed value.  CS-APYF-014  function _startDeposit(     ... ) internal {     uint256 mainAssetValue = assetConverter.safeSwap(         params.asset,         address(mainAsset),         params.value     );  yldr.com - yldr.com -   19  DesignHighVersion1CodeCorrected         \f    ... }  However,  in  the  case  of  a  big  deposit  where  the  deposited  asset  is  not  the  same  as  the  main  asset, swapping could be impossible without causing a greater slippage than the maximum expected one.  In  this  case,  the  vault  operations  would  be  stuck  and  could  not  continue  to  process  normally  until  the slippage is changed in the asset converter.    The swap is now executed before the operation is queued.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Fees Are Not Properly Harvested",
        "body": "  CS-APYF-018  be   The ApyFlow smart contract has a feeInPpm used to compute a fee applied over all vault profit and that calling will  recomputePricePerTokenAndHarvestFee(),  which  computes  the  revenue  across  all  vaults,  and applies the fee by minting a proportional share amount.  the  feeTreasury.  These   harvested   sent   fees   can   be   by   to   Let's take a look at how it works internally:   function recomputePricePerTokenAndHarvestFee() public {     uint256 _totalAssets = totalAssets();     uint256 _totalSupply = totalSupply();      uint256 newPricePerToken = pricePerToken();     if (newPricePerToken > lastPricePerToken) {         ... // Fee shares computation         _mint(feeTreasury, shares);          lastPricePerToken = newPricePerToken;         emit FeeHarvested(fee, block.timestamp);     } }  lastPricePerToken is used to know whether or not the price per token increased since the last time fees  were  minted.  Note  that  after  minting  the  fees,  the  last  price  per  token  is  updated  to newPricePerToken, which was computed before fees were minted.  However,  because  of  the  new  shares,  the  pricePerToken  just  decreased  which  isn't  accounted  for when assigning lastPricePerToken.  lastPricePerToken is now greater than pricePerToken, meaning that no fees will be applied until the price per token reaches again the lastPricePerToken.    lastPricePerToken is now updated with the most recent value of pricePerToken() which includes the harvested fees.  yldr.com - yldr.com -   20  CorrectnessHighVersion1CodeCorrected          \f6.5   Missing Calculation  BaseHedgedConcentratedLiquidityStrategy._readdLiquidity()  calculates  the  amount  to be withdrawn from Aave which is stored in amountToWithdraw. However, this variable is only declared but not assigned, which initializes it to zero.  CS-APYF-023    The missing computation was added.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Aave.ltv Cannot Be Updated",
        "body": "  When HedgedBaseConcentratedLiquidityStrategy is initialized, the AaveLibrary.Data is set which stores the aimed ltv of the Aave position. ltv can never be updated. This can be problematic. The ltv on Aave can be different or change during the lifetime of the strategy. This means that the tvl on the strategy can be greater than the actual tvl on Aave. When the strategy tries to borrow from Aave, the transaction will revert as the strategy will request more to borrow. This limitation of the strategy can prevent deposits and redemptions in the whole system as for a system-wide operation to succeed all the operation in all vaults should succeed. Another important point is that in AaveV3, if tvl is 0 for a specific collateral this collateral cannot be withdrawn.  CS-APYF-025    function  HedgedBaseConcentratedLiquidityStrategy.updateAaveLTV()  has  been  The  added. The owner of the smart contract can now set a new ltv value.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Underflow in Deposit Blocks the System",
        "body": "  A  user  can  submit  a  0  deposit  which  can  be  added  to  the  queue.  This  will  eventually  execute _depositLocal  for  assets  ==  0  which  eventually  calls  _decreaseOpIdToActionsCount  which decreases  opIdToActionsCount  which  is  0.  This  means  that  the  operation  will  revert.  Note  that  the owners at this point cannot call setNewNextOperation as the queue is busy.  CS-APYF-017    The  opIdToActionsCount  is  now  incremented  before  the  rest  of  the  deposit  logic,  which  fixes  the underflow case.  yldr.com - yldr.com -   21  CorrectnessHighVersion1CodeCorrectedDesignHighVersion1CodeCorrectedDesignMediumVersion2CodeCorrected                        \f6.8   Zero Redemption Blocks the System  A  user  can  create  a  request  to  redeem  0  shares  from  MasterCrossLedgerVault  which  will  be successfully  added  to  the  queue.  Such  a  request  can  be  fully  processed  up  until  _completeRedeem which will calculate the pricePerToken. However, this calculation will revert blocking the completion of the  operation  since  0  shares  are  in  the  denominator.  Note  that  the  owners  at  this  point  cannot  call setNewNextOperation as the queue is busy.  Please note that the pricePerToken cannot be removed as the following issue will be enabled:  CS-APYF-010   Assume a system with one slave chain with a score higher than the master chain.   A user deposits a very small amount such that the deposited amount for the master chain is zero  and non-zero for the slave chain.   opIdToActionsCount[opId] is increased once for the operation on the slave chain   depositLocal()   is   then  executed  and  since  assets   is  0   for   the   local  chain  _finalizeCurrentAction() is called.   Then,   _decreaseOpIdToActionsCount()   is   called   which   sets  opIdToActionsCount[opId] to 0 which successfully calls _completeOperation().   operationsQueue.currentOperation  is  set  to  0  which  allows  the  next  operation  to  be  executed.    Zero shares redemption is not allowed anymore.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   Dust in Deposits",
        "body": "  In  MasterCrossLedgerVault  and  ApyFlow,  deposited  assets  are  split  based  on  a  portfolio  score. However,  it  could  be  that  there  are  some  dust  amounts  left  in  these  smart  contracts  due  to  rounding errors.  MasterCrossLedgerVault's dust would be unrecoverable for the user. ApyFlow's dust is accounted as a donation to the current shareholders.  The  last  deposited  amount  (local  deposit)  could  be  calculated  as  the  remaining  available  amount  and thus dust would be avoided.  CS-APYF-016    MasterCrossLedgerVault  now  correctly  handles  deposit  dust  by  minting  the  appropriate  shares amount and a new dustAmount variable has been introduced to keep track of the current dust and split it accordingly on redeems.  ApyFlow now also correctly takes dust into account.  yldr.com - yldr.com -   22  DesignMediumVersion2CodeCorrectedDesignMediumVersion1CodeCorrected                \f6.10   Idling Assets Unused in readdLiquidity()  CS-APYF-024  in   and Both  BaseHedgedConcentratedLiquidityStrategy  invested  when readdLiquidity  is  called  even  though  they  are  accounted  in  totalAssets().  This  results  in  the strategy giving up on some yield.  BaseConcentratedLiquidityStratey   idle  assets  are  not   the   In BaseConcentratedLiquidityStrategy._readdLiquidity(), only assets accounted for in _redeem() will be deposited back. However, some idling assets might be present in the strategy and will stay idling even after the exection of readdLiquidity().   BaseHedgedConcentratedLiquidityStrategy._readdLiquidity()   all concentrated liquidity and adapts its debt and collateral to approach the target ltv. To compute the amount of assets that are available in the vaults, the function calls _totalAssets(), which computes the total value in the Aave position, and then accounts for the token balances of the concentrated liquidity pool. However, note that it is possible that the main vault asset isn't equal to  either  token  of  the  liquidity  pool.  In  this  case,  idling  assets  present  in  the  vault  are  not accounted for, which will lead to a smaller Aave position than expected after execution.  redeems     During  _readdLiquidity()  the  total  balance  of  asset  held  by  the  contract  (not  just  the  amount redeemed) is used in the new deposit.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.11   Leftovers Are Not Handled",
        "body": "  The execution of BaseHedgedConcentratedLiquidityStrategy._readdLiquidity() can leave the  contract  with  some  extra  token0  and  token1  idling  in  the  smart  contract.  This  happens  because swaps of tokens can return a greater amount of assets than what is needed.  The  assets  which  are  not  of  type  asset  will  not  be  accounted  for  in  totalAssets().  This  could potentially reduce the value of the vault's shares until the next _harvest() function execution, which will swap them back to asset.  CS-APYF-013    The leftovers are converted to the underlying asset at the end of the execution.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.12   Queue Processing Is Slow",
        "body": "  MasterCrossLedgerVault's  operation  queue  is  very  slow  to  process,  as  each  operation  must  pass messages across multiple chains.  Waiting time for an operation to execute could be days or even weeks depending on usage.  CS-APYF-021  yldr.com - yldr.com -   23  DesignMediumVersion1CodeCorrectedCorrectnessMediumVersion1CodeCorrectedDesignMediumVersion1CodeCorrected                       \fEven  with  a  reasonably  big  minimumOperationValue,  a  wealthy  malicious  user  could  also  easily increase processing time by days, or even weeks.    MasterCrossLedgerVault.setNewNextOperation()  was  introduced.  The  owner  of  the  contract can arbitrarily set the next operation.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.13   Redemption of Small Amounts Is Impossible",
        "body": "  In MasterCrossLedgerVault, a deposit or a redemption is accepted only if the amount is greater than the minimumOperationValue:  CS-APYF-011  require(     shares / 10 ** decimals() >= minimumOperationValue,     \"Redeem value is lower than minimum\" );  However, users might be willing to partially redeem their position. In some cases it could leave them with an  amount  of  shares  that  is  smaller  than  the  minimumOperationValue,  making  it  impossible  to redeem the rest of the funds unless they deposit again to reach the minimum operation value.    The minimumOperationValue was removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.14   SlaveCrossLedgerVault With a Zero Portfolio",
        "body": " Score  The _startDeposit() function in the MasterCrossLedgerVault iterates over each chain and deposits an amount proportional to their associated portfolio score returned by the oracle. In the case where either a  chain  has  a  score  of  zero  or  the  amount  destinated  to  this  chain  rounds  down  to  zero,  the  loop continues to iterate and ignores this chain:  CS-APYF-029  for (uint256 i = 0; i < chains.length(); i++) {     uint256 chainId = chains.at(i);     uint256 score = oracle.portfolioScore(chainId);     uint256 amountToSend = (mainAssetValue * score) / totalScore;     **if (amountToSend == 0) continue;**     _deposit(opId, chainId, amountToSend, params.slippage); }  Let's also recall how the amount of shares to be minted is computed in the MasterCrossLedgerVault:  yldr.com - yldr.com -   24  DesignMediumVersion1CodeCorrectedDesignMediumVersion1CodeCorrected                \fuint256 totalAssetsBefore = totalAssetsBeforeDeposit[opId]; uint256 totalAssetsAfter = totalAssetsAfterDeposit[opId]; uint256 deposited = totalAssetsAfter - totalAssetsBefore; uint256 shares; if (totalSupply() == 0) {     shares = totalAssetsAfter; } else {     shares = (deposited * totalSupply()) / totalAssetsBefore; }  For  a  fair  computation  of  the  shares,  totalAssetsBefore  should  denote  the  full  value  of  all  assets across  all  chains.  This  is  important  because  redeeming  works  a  bit  differently  than  depositing.  It  just iterates over all chains without taking into account the portfolio score but instead provides them with a relative  proportion  (shares  &  totalSupply),  so  that  each  SlaveCrossLedgerVault  can  use  this proportion to compute how many assets to redeem.  However,  for  totalAssetsBefore  to  be  updated  by  a  slave  vault,  a  cross-chain  deposit  must  have occurred, which isn't the case when amountToSend == 0.  If a portfolio score of a chain has been set to zero, but some assets are still waiting to be redeemed on the  slave  vault,  then  funds  would  be  incorrectly  distributed  to  new  master  vault  depositors.  A  new depositor would receive shares relative to the total assets of all chains except the ones with zero scores, but redeeming these shares would still withdraw funds on the zero-score chain.    Version 2:  yldr.com replied:  We have restricted setting 0 score for chains. All chains should be removed instead of zeroing their scoring  CrossLedgerOracle.updateDataBatch()  is  implemented  to  revert  if  a  score  is  set  to  0  for  any chain of a slave vault.  Version 3:  Setting a score of 0 for a chain is now allowed because zero amounts are now properly handled during operations execution.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.15   Unused Function",
        "body": "  WormholeBridgeAdapter.adjustAmount() is never used.  CS-APYF-015    adjustAmount() is now used to round down the last decimals of the amount sent over the wormhole bridge. This is done as the wormhole bridge performs a similar operation.  yldr.com - yldr.com -   25  CorrectnessMediumVersion1CodeCorrected          \f6.16   minimumOperationValue Could Block Redeems  The minimumOperationValue variable exists as a lower limit of how many assets one can deposit or redeem on MasterCrossLedgerVault. It is denominated in US dollars, and can be compared against deposited assets as long as these are stablecoins pegged to the USD and decimals are adapted.  On redeems, however, minimumOperationValue is compared against a master vault shares amount, which has a varying price:  CS-APYF-022  require(     shares / 10 ** decimals() >= minimumOperationValue,     \"Redeem value is lower than minimum\" );  Assuming that shares accrue in value over time, the minimum value that a user must have deposited to be able to redeem will also increase with time. Note that shares might also decrease in value over time.  A  user  could  deposit  but  isn't  able  to  redeem  afterward  because  one  share  is  more  valuable  than  one token of the deposited asset. This would lock users' funds until they deposit again to reach the minimum value.    The minimumOperationValue was removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.17   Discrepancy Between Computed and Actual",
        "body": " Price per Token  In  CrossLedgerVault.processAction(),  the  user-specified  slippage  is  checked  against  the received  assets  to  make  sure  it  is  acceptable  for  this  action.  When  redeeming,  expectedAssets  is computed  with  feeInclusivePricePerToken()  of  the  underlying  root  vault,  which  for  now  doesn't contain the harvested rewards of the underlying vaults.  CS-APYF-019  However,  it  might  be  the  case  that  on  redemptions,  rewards  are  harvested,  which  changes  the pricePerToken  the redemption  feeInclusivePricePertoken()  will  return  a  smaller  price  per  token  than  it  should  have,  which would allow a bigger slippage than desired.  Consequently,   happens.   before   the     The expected assets are now computed after the redemption so that harvested rewards are accounted.  yldr.com - yldr.com -   26  DesignMediumVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                \f6.18   Queue Could Be Stuck Because of Small-Amount Swaps  In CrossLedgerVault.processAction(), the amount to deposit or redeem could be small, and lead to  some  rounding  errors  depending  on  the  pool  used  to  swap  assets  in  vaults.  Depending  on  the rounding  error,  the  slippage  might  happen  to  always  be  greater  than  expected,  which  would  block  the queue.  CS-APYF-012    The  amount  received  is  always  increased  by  100  wei  so  that  low  amounts  cannot  make  the  slippage check fail.  Note that this means bypassing the user-defined accepted slippage for small deposits.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.19   Redundant Storage",
        "body": "  Redundant storage is used in some places. More specifically:  CS-APYF-028   CrossLedgerVault.addChain() sets lzChainIdToChainId. However, mapping is never  used.   CrossLedgerVault.chains variable is only of use in the MasterCrossLedgerVault, not  in the slave vaults.   WormholeBridgeAdapter.isRootChain variable is never used.    The redundancies have been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.20   Variables Could Be Immutable",
        "body": "  The following variables are only set on construction and never written to afterwards.  CS-APYF-020   WormholeBridgeAdapter.workerImplementation   PosBridgeAdapter.isRootChain   PosBridgeAdapter.asset   PosBridgeAdapter.workerImplementation   PosBridgeAdapter.dstChainId   PosBridgeAdapter.crossLedgerVault  yldr.com - yldr.com -   27  DesignLowVersion1CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected                  \f PosBridgeAdapter.rootChainManager  Setting  these  to  immutable  will  insert  them  into  the  bytecode  at  compilation  time,  leading  to  cheaper reads compared to storage.    The variables are now immutable.  yldr.com - yldr.com -   28  \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Code Consistency",
        "body": "  logic  situations.  The lack  consistency  when  dealing  with  similar  Some  code  areas  BaseHedgedConcentratedLiquidityStrategy swaps assets from one token to another in order to supply an appropriate amount to Aave and eventually to the LP position. In multiple cases, extra care is taken so that no underflows take place. For example in _redeem() the amount to swap is bounded by the available collateralAmount:  CS-APYF-003  amountToSwap = Math.min(amountToSwap, collateralAmount);  While similar logic is implemented in most cases, there are cases where it's not implemented:  In  _readdLiquidity()  the  case  where  currentDebt  >  neededDebt  and tokenToBorrowBalacne  <  amountToRepay,  collateralBalance  is  assumed  to  be greater than amountToSwap.  in   In  _readdLiquidity()  in  the  case  where  currentCollateral  <  neededCollateral and  collateralBalance  <  amountToSupply,  tokenToBorrowBalance  is  assumed  to be greater than amountToSwap.  Enforcing  code  consistency  when  handling  specific  similar  cases  helps  to  secure  the  code  flow  and  to make it more understandable. Adding internal functions for specific tasks could help to properly split the logic.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Missing Natspec",
        "body": "  Most functions are missing proper documentation and description.  Natspec  help  the  end  users  to  interact  with  smart  contracts  as  they  produce  messages  that  can  be shown  to  the  end  user  (the  human)  at  the  time  that  they  will  interact  with  the  contract  (i.e.  sign  a transaction).  CS-APYF-004  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Missing Sanity Checks",
        "body": "   During a rebalance operation in MasterCrossLedgerVault, the REBALANCE_ROLE specifies the percentage of shares to be moved from one chain to another. This happens assuming that the total supply  of  shares  is  1000.  However,  no  sanity  check  guarantees  that  the  shareToRebalance  is  CS-APYF-005  yldr.com - yldr.com -   29  InformationalVersion1InformationalVersion1InformationalVersion1            \fless than 1000. Note that the accepted slippage and both the source and destination chain id are also  specified  but  not  sanity  checked,  which  in  the  worst  case  (slippage  input  error)  could  lead  to some loss of assets.   MasterCrossLedgerVault.setNewNextOperation()  allows  the  owner  to  set  the  next operation  id,  however,  this  value  isn't  sanity  checked  and  could  point  to  an  already  processed operation.   The beneficiery for deposits and redemptions is not checked to be non-zero.  In ApyFlow.setNewFeeDestination(), the newFeeDestination is not sanitized.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   No Events for Important State Changing",
        "body": " Operations  Some examples are:  CS-APYF-006   MasterCrossLedgerVault.addToken()   MasterCrossLedgerVault.removeToken()   MasterCrossLedgerVault.setNewMinimumOperationValue()   MasterCrossLedgerVault.setNewMinSlippageProvider()   CrossLedgerVault.addChain()   CrossLedgerVault.removeChain()   CrossLedgerVault.updateBridgeAdapter()   SuperAdminControl.call()  Events indicate major state changes. Hence, it might be useful for users to listen to certain events. Note that events do increase the gas costs slightly.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   Redundant Operations",
        "body": "  There are multiple instances of redundant operations:  CS-APYF-007   CrossLedgerVault.transferCompleted()   reads   bridgeAdapterToChainId.  However, this value is never used.   MasterCrossLedgerVault._startDeposit()  calculates  the  total  score  by  reading  the respective scores of all chains. Then, to calculate the respective deposits, the scores are read again.   BaseConcentratedLiquidityStrategy._redeem()   calls  _collect()  which   is  guaranteed to have been called before because of the harvesting mechanism.  yldr.com - yldr.com -   30  InformationalVersion1InformationalVersion1           \f7.6   Unreachable Operation  CrossLedgerVault._depositLocal() handles the case where assets == 0. However, this case is  unreachable.  _deposit()  returns  if  amount  ==  0.  If  the  deposited  amount  to  another  chain  is  0, then no deposit to that chain is actually executed.  CS-APYF-008  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.7   Unused Variables and Function",
        "body": "  Some  variables  are  unused  and  could  be  removed  either  from  the  parameter  list  of  the  respective functions or the function implementation:  CS-APYF-009   sentTransfers in MasterCrossledgerVault._startDeposit()   SlaveCrossLedgerVault._transferCompleted()'s parameter transferId   CrossLedgerVault._blockingLzReceive()'s parameter srcLzChainId  Note also that the function WormholeBridgeAdapter.adjustAmount() isn't used anywhere.  yldr.com - yldr.com -   31  InformationalVersion1InformationalVersion1      \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Asset Converters Can Always Be Frontrun",
        "body": "  Asset converters are used all across the protocol to swap between different assets.  It is important to note that at any point in time these swaps can be frontrun, and will especially be when the swapped amount is big enough.  Also note that the asset converter implements a slippage check to avoid big losses.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Asset Converters and Liquidity Provision",
        "body": "  Strategy vaults such as UniswapV3 can invest assets in LP positions of some pools. As the users deposit one specific asset, part of the deposited amount should be converted into another asset. For example, a user submits USDC only and a part of it is swapped to ETH for the two assets to be deposited together to an  LP  position  in  an  ETH-USDC  pool.  For  the  required  swap,  there's  no  guarantee  that  the  same ETH-USDC pool is not going to be used. This means that swaps needed to be performed can alter the price offered by the pool where the LP position is going to be opened. Furthermore, when the swapped amounts are big, for example during rebalances (calls to readdLiquidity), the deviation of the price of the pool can be significant. As these rebalances require two steps (redeem and deposit) which both check  for  a  potential  price  deviation  between  pools  and  oracles,  such  deviation  can  block  the  deposit step and thus block the whole rebalance process.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.3   Fees Accounting Is Based on Variable ",
        "body": " pricePerToken  Fees accounting in ApyFlow is based on the variable pricePerToken. This variable can vary in both direction because of ApyFlow's underlying strategies.  However,  fees  are  only  harvested  if  pricePerToken  has  increased  since  last  harvesting.  This mechanism makes it so that fees will only apply on the vault's total profit, but not on yields.  For example, let's say both pricePerToken and lastPricePerToken are equal to 1.1. A strategy suffers a big loss, which decreases the price per token to 1. Strategies still produce some yield, which make  the  pricePerToken  grow  back  to  1.05  after  a  few  days.  No  fees  will  be  applied  to  this  0.05 growth in the price per token.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.4   Fees Depend on the Converter",
        "body": "  yldr.com - yldr.com -   32  NoteVersion1NoteVersion1NoteVersion1NoteVersion1              \fIn  ApyFlow.redeem()  fees  are  a  portion  of  the  assets  sent  to  the  user.  However,  assets  are dependent on the assetConverter. Should the converter swap the assets with the maximum allowed slippage the fees earned by the system will be reduced.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.5   Gas Limitations",
        "body": "  In  the  ApyFlow  smart  contract,  each  underlying  vault  in  its  vaults  array  is  a  SingleAssetVault which also contains an array of underlying vaults. In the case of a relatively high number of underlying vaults,  gas  costs  can  increase  significantly  even  exceeding  the  gas  limit.  In  that  case,  any  deposit  or redemption could block which could lead to blocking the entire system.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.6   Liquidation Consequences",
        "body": "  In  the  BaseHedgedConcentratedLiquidityStrategy  smart  contract,  a  loan  is  taken  on  Aave  to distribute the liquidity position risk evenly. During high price-volatility periods, a vault could therefore risk getting liquidated.  A liquidation would have multiple consequences:   A sudden decrease in the price per token value.   A potential risk of being unable to call readdLiquidity() due to the current price per token being smaller  than  lastPricePerToken,  if  the  pool  price  returned  out  of  the  rebalance  range  after liquidation.  Note  that  yldr.com  will  configure  hedged  vaults  so  that  the  risk  is  very  low  and  vaults  should  be monitored.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.7   Slippage on Swaps Is Expected to Be",
        "body": " Relatively Small  With the current cross-ledger architecture, some token swaps will happen during operations through the asset  converter  smart  contract.  Note  that  this  asset  converter  has  a  fixed  slippage  tolerance  set  and reverts if it is not respected.  Consequently,  slippage  tolerance  should  be  properly  set  so  that  it  isn't  likely  to  block  any  cross-ledger action.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.8   Supported Tokens",
        "body": "  The  system  only  supports  standard  ERC20  tokens  without  special  behaviors,  especially  tokens  with callbacks  (ERC777)  which  would  allow  arbitrary  code  execution.  More  explicitly,  tokens  with  two  entry points should also be avoided.  Tokens with fees or any rebasing mechanism aren't supported.  yldr.com - yldr.com -   33  NoteVersion1NoteVersion1NoteVersion1NoteVersion1                \f8.9   Tokens Assumption  Some parts of the code implicitly assume that some assets are the same, without ever checking if it is the case or handling the case where they are different.  the  collateral  and The  hedged  concentrated  liquidity  strategy  sometimes  assumes  tokenToBorrow  tokens  must  be  equal  to  the  liquidity  pool  tokens.  It  also  assumes  that  the collateral token is the same as the main asset of the vault.  that   These incomplete assumptions increase the code complexity and can lead to some complex errors.  yldr.com - yldr.com -   34  NoteVersion1    \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Facilitators Have Incentive to Withdraw Funds",
        "body": "  The  allocation  system  assigns  facilitator  roles  to  some  accounts  chosen  by  the  respective  SubDAO. Facilitators can, amongst other things, call the ConduitMover contract which gives them access to the SparkConduit.withdraw() function.  Withdrawing  all  available  liquidity  from  Spark  increases  the  utilization  of  the  pool  to  100%.  Since utilization is a factor of the supply rate of the DAI/NST pools, and because third party supplying is allowed on these pools, facilitators that have an open supply position on the pool can increase their interest rate by withdrawing funds.  CS-SPC-001  Risk accepted:  MakerDAO accepts the risk giving the following statement:  This will be mitigated through Maker disincentivizing this behaviour.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   withdraw() and requestFunds() Can Be",
        "body": " Prevented  External attackers can conduct Denial of Service attacks against the conduit by targeting withdraw() and requestFunds() requirements.  CS-SPC-005  MakerDAO - SparkLendConduit -   11  SecurityDesignCriticalHighMediumLowRiskAcceptedCodePartiallyCorrectedRiskAcceptedDesignLowVersion1RiskAcceptedSecurityLowVersion1CodePartiallyCorrectedRiskAccepted                      \fAn attacker can supply 1 wei of liquidity to an aToken whose reserve balance is otherwise empty, and prevent requestFunds() from being callable.  Similarly,  an  attacker  with  enough  collateral  balance  can  borrow  all  the  available  liquidity  before withdraw() or withdrawAndRequestFunds() operations from the SubDAOs, and repay it just after, preventing the SubDAOs from withdrawing their funds, while incurring little interest accrual since the debt is only held for the time of a few blocks.  An economic incentive for these attacks could be present if the attacker is also a third-party supplier. In that  case,  it  could  be  within  their  interest  to  keep  the  interest  rates  high  by  preventing  SubDAOs  to withdraw after a requestFunds() has been triggered.  Code partially corrected:  The functions requestFunds() and withdrawAndRequestFunds() no longer exist.  Risk accepted:  Client states they will submit transactions that will not be frontrun in this way.  MakerDAO - SparkLendConduit -   12    \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings  -Severity Findings   Withdrawer Can Steal 1 Wei   Informational Findings   Gas Optimizations    Floating Pragma    Missing Event   Inaccurate Naming and Comments    Outdated Aave Version Used    subsidySpread Overflow   0  0  0  1  6  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Withdrawer Can Steal 1 Wei",
        "body": "  When  withdrawing,  an  amount  of  tokens  is  specified  and  the  corresponding  amount  of  shares  is deducted from the ilk's balance. Since _convertToShares() rounds down in its division, a too small amount  of  shares  will  be  deducted.  Specifically,  if  the  ilk  withdraws  1  wei,  0  shares  will  be  deducted (since the index is greater than 1).  CS-SPC-004    When  withdraw()  is  called,  _convertToSharesRoundUp()  is  now  used,  which  rounds  up  the amount of shares to deduct, removing the possiblity of 1 wei stealing.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Floating Pragma",
        "body": "  The  contracts  have  a  floating  pragma  of  ^0.8.13  and  there  is  no  fixed  compiler  version  in foundry.toml.  To  make  sure  that  the  contracts  are  always  compiled  in  a  predictable  manner,  the pragma should be fixed to a stable compiler version.  CS-SPC-006  MakerDAO - SparkLendConduit -   13  CriticalHighMediumLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedDesignLowVersion1CodeCorrectedInformationalVersion1CodeCorrected               \f  Solidity version has been fixed to 0.8.20 in foundry.toml.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Gas Optimizations",
        "body": "  withdrawAndRequestFunds() is guarded by the ilkAuth modifier, and calls internally withdraw() and requestFunds() which are also guarded by ilkAuth. This causes ilkAuth to be evaluated at most 3 times within a call of withdrawAndRequestFunds(), which is inefficient in terms of gas, since ilkAuth includes an external call and several SLOADs.  cancelFundRequest()  Function  requestedShares instead of setting it to 0 directly.  requires   an   unnecessary   SLOAD  when   decreasing  CS-SPC-002  withdrawAndRequestFunds() queries getAvailableLiquidity() twice, once in its own function body,  and  return  early  when getAvailableLiquidity() == 0, or generally when the amount computed at line 133 equals 0, a single querying of the liquidity would be sufficient.  If  withdraw()  would   in  withdraw().   then  again     All mentioned functions have been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Inaccurate Naming and Comments",
        "body": "  CS-SPC-003  In SparkConduit:  1. The naming of the _totalWithdrawals return parameter of getAssetData() is  ambiguous  as it represents the total requested funds.  2. The naming of the _requestedShares return parameter of getPosition() is  inaccurate  as it doesn't represent a share amount but a token amount.  In DaiInterestRateStrategy:  1. The  comment  describing  the  contract  references  D3M,  but  the  contract  will  be  used  in  the  context of the allocator system which sunsets D3M.    1. _totalWithdrawals has been renamed to _totalRequestedFunds.  2. _requestedShares has been renamed to _requestedFunds.  MakerDAO - SparkLendConduit -   14  InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected            \fDaiInterestRateStrategy still contains a comment about D3M.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Missing Event",
        "body": "  DaiInterestRateSTrategy.recompute() changes the storage but does not emit an event.  CS-SPC-007    The event Recompute is now emitted in recompute().  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Outdated Aave Version Used",
        "body": "  The  repository  currently  uses  the  Aave  v3  version  1.17.2.  The  version  still  contains  a  bug  that automatically enables tokens with an LTV of 0 as collateral as soon as they are sent to an address. This can be problematic in cases when the recipient holds a borrowing position as it prevents the withdrawal of any tokens with an LTV greater than 0.  While the SparkConduit contract currently does not hold a borrowing position, this might be changed in the future. In this case, the Aave version should be updated to prevent DoS attacks by simply sending 1 wei of aTokens to the contract.  CS-SPC-008    The Aave submodule commit hash has been updated to the v1.18.0 version.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   subsidySpread Overflow",
        "body": "  SparkConduit.setSubsidySpread()  does  not  contain  a  check  to  verify  that  subsidySpread  is small  enough  to  fit  into  a  uint128  variable  when  added  up  to  the  DSR  rate.  Therefore,  it  may  be possible that the following line in getInterestRate() overflows on unsigned downcast:  CS-SPC-009  baseRate: uint128(dsr + subsidySpread)    subsidySpread is no longer used.  MakerDAO - SparkLendConduit -   15  InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected                  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Missing Sanity Check",
        "body": "  When  the  NoDepegePolicy  is  set,  no  sanity  checks  are  performed  with  regard  to  the  asset  pairs.  This means that a fund owner could wrongfully set assets that are not even part of the supported assets. This will result, in the redeemSharesForSpecificAssets() failing as the ValueInterpreter will not be able to process the assets.  CS-SUL13-001  Avantgarde Finance - Sulu Extensions XIII -   12  DesignCriticalHighMediumLowRiskAcceptedDesignLowVersion1RiskAccepted           \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings  -Severity Findings  0  0  0  0  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Redundant Event Defintion",
        "body": "  StakingWrapperBase defines the RewardsClaimed event which is never emitted.  CS-SUL13-003    The event has been removed.  Avantgarde Finance - Sulu Extensions XIII -   13  CriticalHighMediumLowInformationalVersion1CodeCorrected      \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Deleting From Lists",
        "body": "  Lido stores the pending requests in storage. When a request is claimed, the claim request is deleted from storage.  This  happens  in  the  following  steps.  __claimWithdrawals()  iterates  over  all  the  pending requests until it finds the claimed one. It then replaces it with the last pending request in the requests list which is then popped by the end of the list. This procedure is gas-inefficient. Consider the case where the stored requests are iterated in reverse order and the requestIds passed as arguments are also in reverse  order.  Then  it's  more  likely  that  the  claimed  withdrawal  will  be  the  last  one  in  the  stored  list meaning that no iteration steps through the list are needed. Moreover, only one pop operation is needed to delete the request without any replacement.  CS-SUL13-002  Avantgarde Finance - Sulu Extensions XIII -   14  InformationalVersion1  \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Adding Collateral of Same Type",
        "body": "  When  using  the  AaveV3  external  position,  a  manager  can  only  supply  either  underlying  tokens  or aTokens. For example, if the manager wants to supply aUSDC and DAI, they have to make two separate calls to the external position.  Avantgarde Finance - Sulu Extensions XIII -   15  NoteVersion1  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Incorrect Accounting in report()",
        "body": "  PoolManager.report() is called by a strategy to report the performance when harvesting. First, some parameters are updated and funds are transferred. Then, surplus for the administration is set aside and the gain or loss for SLPs is signaled to StableMaster.  However,  the  propagation  of  loss  for  SLPs  could  lead  to  accounting  issues.  Assume  the  following scenario:   Neither interest for admins nor admin debt has been accumulated so far.   The interests are shared 50/50 for surplus and the stablemaster (the SLPs)  1. Assume 10 SanDAI have been minted and the current rate is 3, meaning that each SanDAI is worth  3 DAI. The pool has 30 of the underlying available which can be used by the strategy.  2. The strategy now signals a loss of 20.  3. loss is 20 and is split equally: lossForSurplus is 10.  4. lossForSurplus > interestsAccumulatedPreLoss holds.  5. The admins cannot currently cover any loss. Hence, their debt is increased by setting adminDebt  to 10.  6. A loss of 10 is signaled to StableMaster. The rate drops from 3 to 2.  7. However, the StableMaster accounts for a loss of 10 DAI while SLPs actually compensated with 20 DAI  since  they  are  temporarily  covering  some  loss  for  the  admins.  Hence,  the  accounting  of  the StableMaster mismatches the SLPs balance in the PoolManager which holds only 10 DAI.  8. Only 5 SanDAI can be redeemed (at the current rate of 2), the remaining 5 SanTokens cannot as they are not backed by funds since PoolMaster holds only 10 underlying tokens (but the rate is 2).  Angle - Staking and Surplus -   11  SecurityDesignCorrectnessCriticalHighMediumLowAcknowledgedAcknowledgedAcknowledgedDesignLowVersion2Acknowledged            \fOnly after the adminDebt has been paid back, sufficient funds will be available in the StableMaster. In the meantime, further issues could arise.  Acknowledged:  Angle  has  acknowledged  this  issue  since  such  scenarios  are  unlikely  to  occur.  However,  Angle  will monitor the system. If such a scenario is detected, Angle will handle the situation appropriately.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Checks on interestsForSurplus",
        "body": "  The new interestsForSurplus parameter in the pool manager contract allows to split the strategies' profits between SLPs and the fee distributor. However, that parameter can range from zero to 100%. A high  choice  may  contradict  with  the  specification  that  SLPs  will  earn  more  interest  by  depositing  to protocols through Angle compared to direct deposits. Upper-bounding the aforementioned range further could increase trust and ensure splits are fair.  Acknowledged:  Angle replied:  We don't want to add an upper bound, and as in other part of the protocol we suppose the guardians have aligned incentives with the protocol. Governance could for instance decide to set 100% of the fees for veANGLE holders and at the same time redistribute all the transaction fees to SLPs to counterbalance for that. We added comment to the function setInterestForSurplus.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Governance Differences",
        "body": "  The  Angle  distributor  and  the  liquidity  gauge  both  support  only  one  governor.  That  diverges  from  the other  contracts'  capability  of  having  multiple  governors.  That  change  of  the  governance  system  in  the new module is undocumented.  Acknowledged:  Angle replied:  These differences are due to the change of paradigm of governance where we will use snapshot voting implemented by a multisig instead of true on-chain governance. Note that technically, the `AngleDistributor` could support multiple governors.  Another reason is that most Curve contracts we have forked support only one governor. The `LiquidityGauge` forked from Curve had only one governor, we therefore decided to keep it. The same will go for the other contracts of the protocol.  Most contracts of the protocol were coded to support multiple governors. One will however be used in practice however.  Angle - Staking and Surplus -   12  DesignLowVersion1AcknowledgedDesignLowVersion1Acknowledged                \fNote that also only one governor is supported in the surplus contracts (following the same reasoning).  Angle - Staking and Surplus -   13    \f7   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  0  1  4  9  -Severity Findings  -Severity Findings  Ineffective Protection Against Sandwich Attacks, Missing Slippage Protection   -Severity Findings   Potentially Stuck Funds After Collateral Removal    Race Condition on Loss    Reverting on setGaugeKilled()    recoverERC20 Does Not Account for the New interestsAccumulated   -Severity Findings   (Missing) Checks on Path    Commented Code    Confusing Naming    Documentation Mismatches    Gas Optimizations    Guardian Powers    Outdated Compiler Version    burn in Surplus Converters Not Paused   is_killed Remains Unused   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Ineffective Protection Against Sandwich",
        "body": " Attacks, Missing Slippage Protection  The  buyback  functions  of  the  SurplusConverter  contracts  is  permissioned  in  an  attempt  to  prevent sandwich attacks. This protection however is ineffective due to a phenomena know as Miner Extracted values.  Please  see  this  blogpost  for  more  information.  In  short,  while  the  permissioned  function  may prevent a sandwich attack e.g. from within a smart contract, for miner it's still possible to put a transaction just before and after this transactions in order to sandwich it. Such attacks can actually be observed on chain, this is more than just a theoretical threat.  The calls to the exchanges within the implementations of the buyback() functions have their slippage protection disabled by setting the minimum incoming amount to 0. This is very dangerous.    Angle - Staking and Surplus -   14  CriticalHighCodeCorrectedMediumCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSecurityHighVersion1CodeCorrected          \fWhenever  there  is  potential  slippage,  the  buyback  function  now  features  an  additional  parameter specifying the minimum amount to be received. In the current SurplusConverter contracts interacting with an exchange, this value is passed as minimum incoming amount parameter to the router contracts of the exchanges.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Potentially Stuck Funds After Collateral",
        "body": " Removal  Tokens of the underlying may be stuck in the SurplusConverterSanTokens contract should a collateral be removed  from  the  StableMaster  contract.  buyback()  will  no  longer  work  after  the  collateral  has  been deactivated  in  the  StableMaster  and  it's  no  longer  possible  to  exit  the  underlying  held  by  the SurplusConverterSanToken  contract.  Should  a  collateral  be  removed,  it's  important  to  shut  down  the corresponding SurplusConverterSanTokens contract first.    A  function  recoverERC20,  callable  only  by  a  governor,  has  been  implemented  in  the  parent  contract BaseSurplusConverter to enable withdrawing funds from all the converters.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Race Condition on Loss",
        "body": "  When a strategy made a loss, a race condition between veAngle holder / long term admins and Standard Liquidity Providers (SLPs) will arise:  Angle Stakers will attempt to call pullSurplus() to evacuate the surplus and protect their profits while SLPs will try to call harvest() on the strategy, which reports the loss to the PoolManager and at least partially tries to cover the loss using interestsAccumulated of the Angle Stakers.  However, the receivers of the funds can trick the SLPs by pulling surplus after each gain immediately.    A new variable tracking the debt to be covered by the admins has been introduced. When the loss is too high such that the currently available interestsAccumulated are not enough to cover for the losses, this debt is accrued. If there is a gain, the gain is first going to reimburse the debt and only afterwards accrue new interestsAccumulated.  Note  that  upon  the  first  loss  to  be  reported  the  race  condition  still  exists.  Admins  may  withdraw  the interestsAccumulated  first  but  then  have  to  cover  the  debt  accrued  by  the  reported  loss  with  the next profit/profits reported.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   Reverting on setGaugeKilled()",
        "body": "  The AngleDistributor has the ability to remove the approval for a gauge through setGaugeKilled. That function contains following line:  Angle - Staking and Surplus -   15  DesignMediumVersion1CodeCorrectedDesignMediumVersion1CodeCorrectedCorrectnessMediumVersion1CodeCorrected                        \frequire(IGaugeController(controller).gauge_types(gaugeAddr) == -1 && lastTimeGaugePaid[gaugeAddr] != 0, \"112\");  Note that the controller's gauge_types function is defined as follows:  gauge_type: int128 = self.gauge_types_[_addr] assert gauge_type != 0 return gauge_type - 1  It  reverts  if  the  gauge  type  is  0  (return  value  -1).  However,  the  first  code  snippet  shows  that  the  call reverts if the return type is not -1. Hence, setGaugeKilled() will revert always revert.    The precondition has been simplified to  require(lastTimeGaugePaid[gaugeAddr] != 0, \"112\");  Moreover, it can now only be called by guardians.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   recoverERC20 Does Not Account for the New",
        "body": " interestsAccumulated  Function recoverERC20 of the PoolManager allows the Governor to recover ERC20 tokens held by this contract.  Any  amount  of  arbitrary  ERR20  tokens  held  by  the  contract  can  be  exited,  however  for  the token of the pool there are some restrictions in order to prevent the Governor to pull funds belonging to the protocol. Due to onchain constraints there are some limitations however and this can only be seen as sanity check. The HA claims are not included as it's not feasible to calculate this amount.  The  new  functionality  introduces  interestsAccumulated  which  contains  the  amount  of  tokens reserved as surplus and which can be exited using the pullSurplus() function, however the check in recoverERC20() has not been updated to account for them.    interestsAccumulated is now considered in the computations of recoverERC20().  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.6   (Missing) Checks on Path",
        "body": "  Function addToken of the SurplusConverterUniV2Sushi contract which can only be called by the trusted Guardian role checks the given path:  require(pathLength >= 2 && path[pathLength - 1] == address(rewardToken) && path[0] == token, \"111\");  The corresponding function of the SurplusConverterUniV3 contract doesn't do any check on the path.  Angle - Staking and Surplus -   16  CorrectnessMediumVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \f  SurplusConverterUniV3 now also implements sanity checks for the path.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.7   Commented Code",
        "body": "  In the surplus converter for UniswapV2 / Sushiswap, the buyback function has the following commented code:  // uint256 amount = IERC20(token).balanceOf(address(this));  For clarity this code could be removed.  However,  the  balance  could  be  used  to  create  a  sanity  check  for  a  successful  swap.  Both,  the UniswapV2/Sushiswap  and  the  UniswapV3  SurplusConverter  contracts  do  not  revert  early  if  the contract's balance is smaller than the specified buyback amount.    The commented code has been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.8   Confusing Naming",
        "body": "  The  contracts  called  surplusConverters  are  to  be  used  as  what  is  called  surplusDistributor inside the PoolManager contract. Especially as there exists another contract called FeeDistributior, the naming may be confusing.  PoolManager.pullSurplus() actually pushes the surplus to the surplusDistributor.  While the structure of the contracts SurplusConverterUniV2Sushi and SurplusConvertUniV3 is identical, one  has  they  are  called updateToken/revokeToken.  functions  called  addToken/revokeToken  while   the  other   in   the  SurplusConverterUniV2Sushi  contract   functions  addToken  and Inside  revokeToken take the parameter _typePath and type respectively. Although these parameters have different names, the meaning of their values is not aligned:  the  complementary   _typePath:   0: SushiswapPath              1: uniswapPath  _typePath:   0: SushiswapPath and uniswapPath              1: SushiswapPath            >-2: UniswapPath  Clear  and  structured  naming  greatly  improves  readability  of  the  code  and  helps  to  avoid  confusion  or potentially resulting coding errors.  Angle - Staking and Surplus -   17  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \f  The naming has been changed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.9   Documentation Mismatches",
        "body": "  The documentation of some functions mismatches their implementations in several places:   The  documentation  of  buyback()  for  the  UniswapV3  and  SanToken  converters,  specify  that  it  swaps on Uniswap or Sushiswap, which is incorrect (Copy&Paste error).   The  documentation  the  converter  functions  specifies  the  FeeDistributor  as  the  recipient.  However,  the recipient of the funds could also be another converter (e.g. setFeeDistributor).  Specification changed:  The comments have been corrected accordingly.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.10   Gas Optimizations",
        "body": "  The gas consumption of some functions could be reduced. For example:  PoolManager.report()   if(loss  In  interestsAccumulated is read four times from storage.  the   in   >   0)   branch,   the   variable  In PoolManager.pullSurplus() surplusDistributor is read three times and token is read twice from storage.  In BaseSurplusConverter.setFeeDistributor() rewardToken is read twice from storage.   The Sushi / UniswapV2 surplus converter stores the length of the path. Since this can be retrieved  from the array itself, that results in unnecessary storage writes.   The  buyback  in  the  Sushi  /  UniswapV2  where  both  paths  are  present  reads  either  the  path  for UniswapV2 or Sushiswap twice from storage. Similarly, the router address for one of these will be read twice from storage.   AngleDistributor.toggleDistributions() has two storage reads. However, one could be  sufficient.   Even  though  not  a  gas  optimization:  BaseSurplusConverter  imports  IUniswapRouter  which  is  unused.  This list of examples illustrates some inefficiencies in code which could increase the gas consumption of users. Some of these optimizations may or may not be done by the optimizer. As the exact behavior of the  optimizer  is  unknown/undocumented  the  optimizations  may  be  done  manually,  as  is  done  in  large parts of the Angle codebase already.    All optimizations listed above have been implemented.  Angle - Staking and Surplus -   18  CorrectnessLowVersion1Speci\ufb01cationChangedDesignLowVersion1CodeCorrected                     \f7.11   Guardian Powers  The  guardian  has  been  specified  as  a  role  that  can  change  system  parameters.  However,  when transferring funds it is typically required that the governance performs such actions. Note, that in the new code the guardian can be overly powerful (e.g. setting the fee distributor).    Now, the governor role has been introduced to the surplus converter contracts. Note that only governors can set the fee distributor. That restricts the permissions of the guardian.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.12   Outdated Compiler Version",
        "body": "  The project uses an outdated version of the Vyper compiler.  # @version 0.2.15  At  the  time  of  writing  the  most  recent  Vyper  release  of  version  0.2.x  is  0.2.16  which  contains  some bugfixes but no breaking changes.    The compiler version has been updated to 0.2.16.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.13   burn in Surplus Converters Not Paused",
        "body": "  The BaseSurplus converter specifies the following for function pause:  /// @dev After calling this function, it is going to be impossible for whitelisted addresses to buyback /// reward tokens or to send the bought back tokens to the `FeeDistributor`  However, as burn() has no whenNotPaused modifier, it is possible to send funds to the fee distributor. Without documentation the expected behavior is unclear.    The whenNotPaused modifier has been added to burn().  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.14   is_killed Remains Unused",
        "body": "  is_killed remains unused in code. Therefore, its setter has no effect on the system. That functionality could be removed to reduce code size and, hence, to reduce deployment cost.  Angle - Staking and Surplus -   19  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                              \f  The code has been removed.  Angle - Staking and Surplus -   20  \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  Hence,  the mentioned topics serve to clarify or support the report, but do not require a modification inside the project. Instead,  they  should  raise  awareness  in  order  to  improve  the  overall  understanding  for  users  and developers.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Arbitrage Opportunities for Whitelisted Role",
        "body": "  The buyback function swaps one token in another one and, hence, will change the prices of assets on one  pool.  Now  pools  will  now  price  differences  and  thus  arbitrage  opportunities  are  created.  The comments above the buyback function in the BaseSurplusConverter contract describe this. Described as a mitigation for this, the function is permissioned and can only be called by the whitelisted role.  The resulting arbitrage opportunity will anyway be taken advantage of, e.g. by bots. Depending on the amounts involved it could be worthwhile for the whitelisted role to do so / allow the code to do so. Note also that multiple buyback calls could increase the profit further by creating more arbitrage possibilities.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Vyper <-> Solidity Compatability",
        "body": "  Some of the new contracts are written in Vyper. The system now consists of interacting contracts written in Solidity and Vyper. While both compile to EVM bytecode and the interaction are normal low level calls, there might be incompatibilities: Encoding in one and decoding in the other may be problematic and there are  concerns  whether  that  works  correctly  in  all  circumstances.  Hence,  interaction  between  contracts written in Vyper and contracts with Solidity should be considered as experimental. The interaction of such contracts should be tested carefully.  Angle - Staking and Surplus -   21  NoteVersion1NoteVersion1      \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Unchecked Return Value of transferFrom",
        "body": "  In DssLitePsm, the return value of transferFrom() is not checked. It relies on the token to revert if the transfer  fails  which  is  given  for  the  intended  gem  token  (USDC).  Generally  however,  according  to  the ERC20  specification  upon  a  failed  transfer  the  token  may  revert  or  simply  returns  false.  In  case  the gem token's implementation returns false on a failed transferFrom() instead of reverting, DssLitePsm will still treat it as a success and proceed.  CS-MKPSML-001  Risk accepted:  Maker states:  We do not plan to support ERC-20 tokens that do not revert on a failed transfer. We might want to support tokens that do not return true on succeeded transfers.  Maker - PSM Lite -   12  SecurityCorrectnessCriticalHighMediumLowRiskAcceptedSecurityLowVersion1RiskAccepted            \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings  -Severity Findings  -Severity Findings  Incorrect Ilk Class    Uninitialized Vow in DssLitePsmInit   Inaccurate Specification   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Incorrect Ilk Class",
        "body": "  0  0  0  3  Regarding ilk.class, the Ilk Registry states:  Classification code (1 - clip, 2 - flip, 3+ - other)  CS-MKPSML-009  In  PSM  initialization  script  (DssLitePsmInit.sol),  the  class  of  the  existing  PSM  (src.class)  is reused  to  register  the  specific  ilk  for  DssLitePsm  (For  PSM-USDC,  src.class==1).  Nevertheless,  in contrast  to  the  existing  PSM,  DssLitePsm  does  not  have  auction  modules  and  cannot  be  liquidated. Hence directly reusing src.class does not comply to the specifications.    The  ilk.class  for  the  newly  deployed  DssLitePsm  has  been  changed  to  a  constant  6  (a  new IlkRegistry class), representing a specific ilk type without an associated GemJoin.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Uninitialized Vow in DssLitePsmInit",
        "body": "  Library DssLitePsmInit does not initialize the vow of the newly deployed DssLitePsm. Consequently the  outstanding  accumulated  fees  cannot  be  harvested  into  the  surplus  buffer  (chug()),  and  it  would require another governance spell to set the vow.  CS-MKPSML-010    Maker - PSM Lite -   13  CriticalHighMediumLowCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCorrectnessLowVersion4CodeCorrectedCorrectnessLowVersion4CodeCorrected                  \fMaker  has  corrected  the  code  in  function:  .  The  vow  is  now  initialized  in  the  DssLitePsmInit.init  DssLitePsmLike(inst.litePsm).file(\"vow\", dss.chainlog.getAddress(\"MCD_VOW\"));  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Inaccurate Specification",
        "body": "  The specification of DssPocket states \"Can grant or revoke infinite gem approvals\". Not all gem tokens treat  max(uint256)  as  truly  unlimited  allowance,  though  it  is  unlikely  to  exhaust  max(uint256) allowance in practice .  CS-MKPSML-006  Specification changed:  The specification has been updated to read up to max(uint256) instead of infinite.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Fill More Than buf Possible",
        "body": "  The  specification  of  fill()  states  \"Mints  Dai  into  this  contract  up  to  buf  value\".  This  is  not  entirely accurate since the amount of DAI to be minted depends on the current art of the urn and the amount of gem at the pocket. Both of which can be manipulated by anyone if one is ready to spend money to:  CS-MKPSML-011  Inflate tArt by donating gem tokens to DssPocket.   Deflate Art by repaying on behalf of DssLitePsm in VAT.  Consequently the amount to be refilled (computed in rush()), depending on the actual circumstances may result in:   More than buf amount of DAI at the DssLitePsm after fill().   More than buf amount of DAI minted during fill().  Specification changed:  The  specification  has  been  updated  to  reflect  how  the  extraneous  influences  might  affect  the  amount minted by fill().  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   The Optimizer Is Disabled",
        "body": "  The optimizer is disabled in foundry.toml. Enabling the optimizer can help to further improve the gas efficiency.  CS-MKPSML-008  Maker - PSM Lite -   14  Version5CorrectnessLowVersion1Speci\ufb01cationChangedInformationalVersion1Speci\ufb01cationChangedInformationalVersion1CodeCorrected                     \f  The optimizer has been enabled in foundry.toml.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Unpermissioned Repay of Art, Remaining",
        "body": " Collateral Balance  In the VAT it's possible to repay debt for any urn by using VAT.frob() without requiring permissions. If this is done for the special urn of DssLitePsm, this has the following consequences:   DssLitePSM's urn art will reduce while ink remains unchanged.   Once the fees are collected through chug() the corresponding surplus will be paid out as part of the fees.  The  collateral  accounting  in  the  VAT  is  not  updated,  the  ink  balance  remains,  despite  the funds now having left the system.  CS-MKPSML-007    In  modified by this contract.   the design has been changed, the ink of the urn is expected to be unlimited and is no longer  Maker - PSM Lite -   15  InformationalVersion1CodeCorrectedVersion2      \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Lack of Sanity Checks",
        "body": "  CS-MKPSML-002  While  DssLitePsm.to18ConversionFactor() is not validated to be the expected value.  DssLitePsmInit   implements   many   script   the   sanity   checks,  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   No Dai May Be Available if Limit Is Reached",
        "body": "  DssLitePsm  may  not  achieve  its  full  functionalities  in  case  the  individual  debt  limit  (ilk.line)  or  the global  debt  limit  (VAT.Line)  is  reached.  In  this  case,  the  pool  cannot  be  refilled.  As  long  as  no  or insufficient DAI balance is available, users can only swap DAI for gem tokens (which in turn makes some DAI available).  CS-MKPSML-003  Acknowledged:  Maker has acknowledged the behavior of the pool if the debt limit is reached.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   No Fees on Small Swap Amounts",
        "body": "  Following the design of the existing PSMs, the fees of the swaps are computed and rounded down as:  CS-MKPSML-004  fee = daiOutWad * tin_ / WAD  fee = daiInWad * tout_ / WAD;  As a result, amounts of daiOutWad or daiInWad may avoid the swap fees due to the rounding errors. Compared to the gas costs, this is negligible.  Acknowledged:  This behavior is now documented in the code.  Maker - PSM Lite -   16  InformationalVersion4InformationalVersion1AcknowledgedInformationalVersion1Acknowledged                \f7.4   Trim May Fail if Art Is Below Dust  Trim()  will  burn  Dai  and  decrease  the  debt  urn.art.  If  the  resulting  art  of  the  urn  is  non-zero  but below ilk.dust this fails. For this special collateral, ilk.dust should be set to 0.  CS-MKPSML-005  Acknowledged:  Maker has acknowledged the edge case if ilk.dust is not set properly.  Maker - PSM Lite -   17  InformationalVersion1Acknowledged    \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Changes Compared to the Existing PSMs",
        "body": "  There are currently three active PSMs for USDC, Gemini-USD and Pax-USD at the time of this review (October 2023). The PSM Lite has the following changes:  1. In the existing PSMs the gem tokens are deposited into a Gemjoin adapter before art is generated and DAIs are minted. PSM Lite use a special ilk for Dai minting ahead of time. Once these DAIs are exchanged for gem tokens, these tokens are held within DssPocket.  2. The  volume  for  a  single  swap  is  only  limited  by  the  ilk.line,  debt,  and  Line  in  the  existing implementation. PSM Lite introduces a pool of pre-minted Dai limited by buf size, which may not satisfy  a  single  swap  with  an  exceeding  volume.  In  this  case  the  single  swap  should  be  broken down  into  several  smaller  swaps,  in  between  of  which  the  pool  can  be  refilled  (fill())  by  the user.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Considerations for Initialization",
        "body": "  While the initialization script for the PSM performs many sanity checks to prevent malicious deployments, it  cannot  check  everything.  The  governance  should,  before  approving  any  spell,  carefully  evaluate  the deployment process. Namely, the following should be considered:  1. The init code of the contracts should match the init code generated by the compiler with the correct immutables attached. As a consequence, it can be ensured that the bytecode is correct and that the constructor has not been altered to perform malicious actions (e.g. give approvals to arbitrary addresses).  2. The only successful calls made to the contracts after their creation should be the following (in the  same order for both contracts):  1. rely() to give the governance a privileged role.  2. deny() to remove the privileged role from the deployer.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.3   DssLitePsm Does Not Support Global",
        "body": " Settlement  At the time of this review, Emergency Shutdown Module (ESM) is still functioning and could be triggered by  users  burning  sufficient  MKR.  However,  DssLitePsm  does  not  support  the  coordinated  Shutdown  / Global Settlement anymore. It is expected that the ESM is disabled by setting its threshold large enough prior to the deployment of DssLitePsm, so Emergency Shutdown can never be called.  Maker - PSM Lite -   18  NoteVersion1NoteVersion1NoteVersion1            \f8.4   Swaps Are Subject to Front-Running  A user's swap can be front-run by another swap of the same direction, which will leave insufficient Dai or gem tokens and revert the user's swap. In the former case, users can bundle a fill() before the swap to refill the pool with newly minted Dai. This is well documented in the README of PSM Lite.  Maker - PSM Lite -   19  NoteVersion1  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Constitution and Experts Keys",
        "body": "  0  0  0  3  All  the  registry  keys  for  common,  governance,  and  tokeneconomics  have  been  grouped  in Globals.sol  as  constant.  However,  it  is  not  the  case  with  other  keys  like  the  constitution  and governed  parameters  keys.  An  accidental  typo  in  the  string  constant  can  lead  to  potential  system misconfiguration.  Risk accepted:  Q Blockchain accepts the risk and decides to leave the code as it is.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   FxPriceFeedMedianizer Price Feed",
        "body": " Manipulation  Since  all  the  data  submitted  by  the  subfeeds  is  immediately  visible  on-chain,  malicious  subfeed  can decide what data to submit and manipulate the outcome of the computed round. By submitting a value above or below the current median the subfeed provider has limited control over the outcome. Assuming that subfeeds are trusted, this has a limited likelihood of happening.  Risk accepted:  Q Blockchain accepted the risk and states:  Q Blockchain - System contracts v1.2 -   11  DesignTrustCriticalHighMediumLowRiskAcceptedRiskAcceptedRiskAcceptedDesignLowVersion1RiskAcceptedDesignLowVersion1RiskAccepted                  \fThe subfeeds are considered trustworthy, also the price manipulation is quite limited in range since the resulting price is a median and by definition insensitive to extreme values. Therefore the impact of a malicious subfeed would be minimal.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   FxPriceFeedMedianizer Subfeeds",
        "body": " Consistency  Multiple subFeed parties need to provide the rate in a given round to compute the exchangeRate.  The following problems can potentially arise during the lifetime of this contract:  1. Due to the concurrent nature of the blockchain, subfeeds cannot control when their submit() call will  be  included  in  the  chain  history.  In  addition,  the  submit  reverts  if  the  same  subfeed msg.sender tries to republish the rate in the same round. The submit transaction submitted at the  very  start  of  the  new  round  may  be  counted  in  the  previous  round,  due  to  random  delays between transaction creation and block confirmation.  2. The  subfeeds  rates  provided  to  the  FxPriceFeedMedianizer  contract  are  not  sanitized.  It  is possible to provide subfeeds that do not match the pair, decimals, or base token address. The only sanity  check  performed  on  the  submitted  rate  is  the  rate  >=minRateValue  check.  A misconfiguration on the subfeed side can lead to a wrong exchangeRate as a result.  Risk accepted:  Q Blockchain accepts the risk and states:  1. We don't see a downside of their submission just going an earlier or later round.  2. If a subfeed reports the price for a wrong asset it will probably always be far   from the median. So, it does not immediately affect the price but the owner can   detect this and remove the subfeed. We consider this also low severity and would   accept the risk.  Q Blockchain - System contracts v1.2 -   12  DesignLowVersion1RiskAccepted          \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings  -Severity Findings   FullMath Operation Correctness Issue   -Severity Findings  -Severity Findings   Reward Allocation Can Be Blocked    Code Duplication    Floating Dependencies Versions    Reentrancy Possibility on Root Node Approval Voting    Unused Functionality and Libraries    FxPriceFeedMedianizer Missing Events    FxPriceFeedMedianizer Rate and Update Time   0  1  0  7  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   FullMath Operation Correctness Issue",
        "body": "  The  FullMath.mulDiv(uint  a,  uint  b,  uint  denominator)  the floor(a\u00d7b\u00f7denominator)  operation.  A  similar  function  exists  in  the  UniswapV3  core  codebase. However due to the change of the solidity compiler version from 0.7.6 to 0.8.9, some modifications were  made  to  account  for  the  default  SafeMath  arithmetic  operations  behavior.  This  computation happens in FullMath.mulDiv code:  function  performs   prod0 := add(prod0, mul(prod1, twos))  While Uniswap library performs this operation:  prod0 |= prod1 * twos;  Please note that this operation occurs in the unchecked block.  As a result, the FullMath.mulDiv computation yields undesired results.  For example, this assignment of arguments causes overflow and panic in the FullMath.mulDiv.  a = 2**255 b = 2**255 denominator = 57896044618658100000000000000000000000000000000000000000000000000000000000001  The correct computation should yield 5789604461865809542357098500868799828994258986484 4074485766219939100404438900.  Q Blockchain - System contracts v1.2 -   13  CriticalHighCodeCorrectedMediumLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedDesignHighVersion1CodeCorrected        \f  The FullMath.mulDiv function has been replaced by the OpenZeppelin v4.8.0 implementation. It uses Solidity compiler above 0.8.0 version.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Reward Allocation Can Be Blocked",
        "body": "  In  event was added:    of  the  code  in  ValidationRewardProxy  and  RootNodeRewardProxy  the  Allocated  emit Allocated(beforeAllocation - address(this).balance);  The allocation happens with the help of the PushPayments contract that performs a call with 30000 gas. Malicious  Validator  or  Root  in  their  fallback  function  can  transfer  an  amount  that  is  greater  than beforeAllocation  back  to  the  reward  proxy.  This  way  the  computation  of  the  event  argument  will overflow.  As  a  result,  the  allocation  of  rewards  will  be  blocked.  The  severity  of  this  issue  is  low  since Roots are trusted and Validators can be slashed.    A variable has been added to aggregate the allocated amounts instead of computing a difference.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Code Duplication",
        "body": "  1. In   the   Validators   to registry.mustGetAddress(RKEY__VOTING_WEIGHT_PROXY) is inlined multiple times, while to  registry.mustGetAddress(RKEY__VALIDATORS_SLASHING_VOTING)  are the  calls  grouped  under  the  _getSlashingVotingAddress()  view  function.  Having  a  single  getter function for the voting weight proxy registry key would be consistent with the rest of the codebase.  contract,   call   the   2. In   function clearVault(address,  _vaultId,  _amountToClear,  _beneficiary)  basically duplicates the functionality of transferCol, followed by _clearVault.  BorrowingCore,   the     1. The   inlined   calls  _getConstitutionParametersAddress() and _getVotingWeightProxyAddress().  by  more   consistent   replaced   been   have   calls   to  2. Functions  clearVault  and  transferCol  have  been  marked  as  deprecated  and  are  kept  for  backward compatibility.  Q Blockchain - System contracts v1.2 -   14  TrustLowVersion3CodeCorrectedVersion3DesignLowVersion1CodeCorrected                  \f6.4   Floating Dependencies Versions  The versions of @opengsn and @openzeppelin in package.json is not fixed. This could break the codebase if a new version has breaking changes. Upgradeable contracts that rely on proxy pattern can be  rendered  broken  if  the  new  version  of  the  dependency  contract  introduces  or  changes  the  order  of defined storage fields.    The versions of @opengsn and @openzeppelin have been fixed to 2.2.4 and 4.3.3.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Reentrancy Possibility on Root Node",
        "body": " Approval Voting  In  ARootNodeApprovalVoting.approve, there is a call to onExecute.  ARootNodeApprovalVoting._execute,   function   the   called   by  Since the ARootNodeApprovalVoting is abstract, contracts that inherit from it may execute arbitrary external  code  and  re-enter  during  this  call.  The  function  ARootNodeApprovalVoting.approve  can be  called  again  the  because  _proposal.executed  is  set  to  true  only  after  the  call  to  onExecute. However,  relying  on  the  trust  model,  should  not  be  an  issue  since  the  function  can  only  be  called  by trusted root nodes when the majority is reached. Nevertheless, the Checks-Effects-Interactions pattern is violated.    The flag _proposal.executed is set to true before the call to onExecute. The function adheres to the check effect interaction pattern now.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Unused Functionality and Libraries",
        "body": "  The following list contains problems due to imports, inheritance and usage of the libraries and contracts that are not needed. The redundant code can be removed.   The SafeMath library is not used anymore in the code since the compiler version is now 0.8.9. However,  some  SafeMath  library  imports  are  left  in  the  source  code,  as  well  as  some using SafeMath for uint256.   The  PushPayments  contract  is  Initializable  but  the  functionality  is  never  used  and  can  be  removed.  Code partially corrected:   The SafeMath library has been completely removed.  Q Blockchain - System contracts v1.2 -   15  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                      \f The PushPayments contracts Initializable functionality while not used in the current version might be needed in the future. To prevent problems with storage layout it is necessary to keep the Initializable functionality of the PushPayments.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   FxPriceFeedMedianizer Missing Events",
        "body": "  The  FxPriceFeedMedianizer  contract  does  not  emit  events  when  certain  state  changes  occur.  For example:   addSubFeed   removeSubFeed   setMinSubmissionsCount   setMinRateValue   _closeRound  The  lack  of  such  events  complicates  the  reproduction  of  the  contract  state  off-chain.  Thus,  SubFeed providers  might  need  custom  solutions  for  monitoring  the  chain  to  know  when  a  new  rate  must  be submitted.    The  events  MinSubmissionsCountSet,  FxPriceFeedMedianizer.  ExchangeRateUpdated,   SubFeedAdded,   and   MinRateValueSet   have   SubFeedRemoved, in added   been   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   FxPriceFeedMedianizer Rate and Update",
        "body": " Time  New exchangeRate is computed only after a round where minSubmissionsCount limit of submissions was reached.  External  protocols  and  systems  can  mistakenly  use  stale  exchangeRate  if  updateTime  is  not properly inspected. There is no default way to get both the rate and update time in a single call    A getter returning both the rate and the time has been added.  Q Blockchain - System contracts v1.2 -   16  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Finalized Withdraw Address",
        "body": "  For  an  address  to  be  finalized  in  WithdrawAddresses,  a  root/validator  node  must  provide  proof  of ownership to Q Development AG. One of the limitations set by Q Blockchain is to disallow withdrawals to the main account.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Gas Optimization",
        "body": "  1. The  majority  of  the  updates  of  the  form  x  =  x  +/-  y  have  been  optimized  to  x  +/-=  y,  but  there remains some unoptimized variable updates. An unexhaustive list is:   BorrowingCore.depositCol   :  userVaults[msg.sender][_vaultId].colAsset = userVaults[msg.sender][_vaultId].colAsset + _amount;   BorrowingCore.getAggregatedTotals:  _totalsInfo.outstandingDebt = _totalsInfo.outstandingDebt + _colOutstandingDebt;   Saving.deposit:  aggregatedNormalizedCapital = aggregatedNormalizedCapital + (_newNormalizedCapital - normalizedCapitals[msg.sender]);   Saving.withdraw:  aggregatedNormalizedCapital = aggregatedNormalizedCapital - (normalizedCapitals[msg.sender] - _newNormalizedCapital);  2. The modifier ARootNodeApprovalVoting.onlyRoot takes an address as an argument, but is only  used  with  msg.sender.  Removing  the  argument  and  using  directly  msg.sender  will  save gas.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Storage Variables Visibility",
        "body": "  Some  variables  that  are  currently  internal  in  contracts  that  are  not  inherited  can  be  made  private. Saving.registry, AExpertsMembershipVoting.registry,  Examples  ValidationrewardPool.registry, FxPriceFeedMedianizer.pair, or Saving.stc.  are:   Q Blockchain - System contracts v1.2 -   17  NoteVersion1NoteVersion1NoteVersion1          \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   HoprChannels ERC777 Reentrancy",
        "body": "  An  attacker  can  leverage  the  ERC777  capability  of  the  wxHOPR  token  to  drain  the  funds  of HoprChannels contract.  CS-HPRNMM23-001  Attack vector:  Assume the attacker deploys the following pair of contracts at ALICE and BOB addresses respectively.  contract Bob {      function close() public {         HoprChannels channels = HoprChannels(0x...);  HOPRNet - Node Management Module -   12  CriticalCodeCorrectedCodeCorrectedHighMediumCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSecurityCriticalVersion1CodeCorrected             \f        channels.closeIncomingChannel(ALICE);      } } contract Alice is IERC777Recipient {      bool once = false;      function tokensReceived(...) public {         if (once) {             return;         }         once = true;         HoprChannels channels = HoprChannels(0x...);         channels.fundChannel(BOB, 1);         Bob(BOB).close();     }      function hack() public {          _ERC1820_REGISTRY.setInterfaceImplementer(address(this),         TOKENS_RECIPIENT_INTERFACE_HASH, address(this));          HoprChannels channels = HoprChannels(0x...);         channels.fundChannel(BOB, 10);         Bob(BOB).close();     }  }  Exploit scenario:  When Alice.hack() is called, the following happens:  1. Alice's contract registers itself as its own ERC777TokensRecipient.  2. Alice funds outgoing channel to Bob with 10 wxHOPR.  3. Bob closes the incoming channel with Alice.  4. During  the  execution  of  closeIncomingChannel()  the  10  wxHOPR  tokens  are  transferred  to  Alice.  5. The tokensReceived() function of Alice is called. During this call:  1. Alice funds outgoing channel to Bob with 1 wxHOPR. Balance of the channel becomes  11 wxHOPR.  2. Bob  closes  the  incoming  channel  with  Alice  and  11  wxHOPR  tokens  are  transferred  to  Alice.  3. This  time  the  tokensReceived()  function  of  Alice  does  nothing.  The  balance  of  the  channel is set to 0.  6. The closeIncomingChannel() that started on step 4. sets the balance of channel to 0.  As  a  result,  attacker  using  10+1  token  can  withdraw  10+11  wxHOPR  tokens  from  the  channel.  The attacker can loop the reentrancy even more time for more profit.  Cause:  HOPRNet - Node Management Module -   13  \fThe  change  of  channel  balance  to  0  happens  after  the  reentrant  call  to  token.transfer()  in  the _closeIncomingChannelInternal()  is effectively violated. Similar violations happen in other functions of the HoprChannels contract:  function.  Thus,  checks-effects-interactions  pattern    _finalizeOutgoingChannelClosureInternal()  sets  the  channel  balance  to  0  after  the  reentrant call to token.transfer().   _redeemTicketInternal() calls indexEvent and emits events after token.tranfer() call in case when the earning channel is closed. This effectively can lead do the wrong order of events in the event log or a different snapshot root.    The  code  has  been  corrected  by  moving  the  token  transfer  to  the  end  of  the  function  in  all  relevant functions.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Winning Ticker Can Be Redeemed Multiple",
        "body": " Times  CS-HPRNMM23-002  Assume Alice has outgoing channel to Bob with 1 as ticketIndex. Following scenario is possible:  1. Alice  provides  Bob  4  non-winning  tickets  with  ticketIndex  2,  3,  4,  5  and  a  winning  ticket  with  ticketIndex 6. All of those tickets are non-aggregated and thus their indexOffset is 1.  2. Bob redeems the winning ticket. In the _redeemTicketInternal function, the ticketIndex of the spending channel is updated as: spendingChannel.ticketIndex += indexOffset. The ticketIndex of the spending channel is now 2.  3. Bob  can  redeem  the  ticket  again,  because  the  only  requirement  on  ticketIndex  is  that  it  is  greater than the ticketIndex of the spending channel.  Thus, same winning ticket can be redeemed multiple times. The ticketHash signature from Alice does not prevent this, because it does not contain any nonce or other replay protection mechanism.    The  spendingChannel.ticketIndex = TicketIndex.wrap(baseIndex + baseIndexOffset).  ticketIndex   spending   updated   channel   been   has   the   of   as:  And  been  (baseIndexOffset >= 1) && (baseIndex >= currentIndex).  validity   check   ticket   has   the   of   adjusted   to   require:  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   EIP-712 Incompliant Signed Message",
        "body": "  The  EIP-712  compliant  message  should  start  with  a  two-byte  prefix  \"0x1901\"  followed  by  the domainSeparator and the message hash struct. Whereas two 32-bytes are used in the following cases for  the  prefix  because  of  abi.encode.  Consequently  the  signatures  generated  by  the  mainstream EIP-712 compliant libraries cannot be verified in these smart contracts:  CS-HPRNMM23-003  HOPRNet - Node Management Module -   14  SecurityCriticalVersion1CodeCorrectedCorrectnessMediumVersion1CodeCorrected                \f1. registerSafeWithNodeSig() in NodeSafeRegistry.  2. _getTicketHash() in Channels.    The abi.encodePacked has been used instead of abi.encode to generate the message hash struct.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Incorrect indexEvent Input",
        "body": "  The channel will call indexEvent() when emitting a new event. In the following case, indexEvent() is incorrectly invoked with an extra channel.balance field compared to the emitted event. As a result, the snapshot will contain an incorrect event.  CS-HPRNMM23-021  indexEvent(abi.encodePacked(ChannelOpened.selector, self, account,     channel.balance)); emit ChannelOpened(self, account);    The redundant field channel.balance has been removed from the indexEvent input.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Dependencies Between Source File Folders",
        "body": "  CS-HPRNMM23-004  The packages/ethereum/contracts foundry project have following problems   Some of the files in src folder depend on smart contracts from test folder.   Some of the files in src folder depend on smart contracts from script folder.  Such dependencies are considered as bad practice and should be avoided. Potential risks are:   Separation of concerns is not respected. Testing and setup code should not impact production code.   Risk of deploying test code to production is increased.   Maintenance  of  the  project  is  more  difficult.  Changes  in  test  or  script  folders  may  impact  production code.    HOPRNet responded:  The  placement  of  specific  library  files  and  contracts  have  been  reorganized  to  align  with  improved structuring and imports.  HOPRNet - Node Management Module -   15  CorrectnessLowVersion2CodeCorrectedDesignLowVersion1CodeCorrected                  \f6.6   DomainSeparator Is Not Recomputed After a Change of Chain ID  In contracts Channels and NodeSafeRegistry, the domainSeparator is defined as an immutable in the constructor and used in the signature verification. In case there is a fork, the contracts will still verify a signature based on the old domainSeparator, whereas the forked chain is associated with a different chain  ID.  Besides,  the  signature  targeted  to  the  original  chain  can  be  replayed  to  the  forked  chain.  In order to support the potential forked chains and avoid signature replay, the domainSeparator needs to be recomputed based on on-chain chain ID.  CS-HPRNMM23-005    Function updateDomainSeparator has been introduced in contracts Channels and NodeSafeRegistry to update the domainSeparator based on the on-chain chain ID.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   HoprNodeSafeRegistry Is Not an",
        "body": " INodeSafeRegistry  The contract does not inherit from INodeSafeRegistry, which means the compiler will not check that the contract implements all functions correctly.  CS-HPRNMM23-006    The INodeSafeRegistry contract has been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   HoprNodeStakeFactory Can Clones Any",
        "body": " Module  The  clone()  function  of  the  HoprNodeStakeFactory  receives  moduleSingletonAddress  as  a parameter. However, no checks are performed to ensure that the address is a valid module. While this is not  immediately  a  problem,  since  it  concerns  only  the  msg.sender  itself.  However,  the  event NewHoprNodeStakeModule does not mention the address of the module. This complicates the process of verifying that the module is indeed a valid module.  CS-HPRNMM23-007    Description of Changes:  HOPRNet - Node Management Module -   16  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                      \fHOPRNet  has  adjusted  the  NewHoprNodeStakeModule  event  to  include  an  indexed  parameter, improving  event  clarity.  And  events  have  been  separated  from  \"HoprNodeStakeFactory\"  into  an abstract contract named \"HoprNodeStakeFactoryEvents.\"  Said changes allow inspection of the module address, and thus, verification of the module's validity.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   IHoprNodeSafeRegistry Is a Contract and Not",
        "body": " an Interface  The  I  prefix  is  usually  used  for  interfaces,  not  contracts.  IHoprNodeSafeRegistry  lies  inside  of interfaces folder whereas it is actually a contract.  CS-HPRNMM23-008    The INodeSafeRegistry contract has been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   Incorrect Flag Position Upper Bound",
        "body": "  CS-HPRNMM23-009  flags   A customized type Target is an alias of uint256, which is used to store a target address associated In  contract with  12  one-byte  util/TargetUtils.sol,  getDefaultCapabilityPermissionAt()  will  return  the  capability permission flag at a certain index: position. However, the upper bound of position is 9 instead of 8. As a  result,  the  function  will  not  revert  upon  reading  the  out-of-bound  9th  permission  flag  and  will  always return 0 due to 256 left shifts.  flags  with  9  capability  permission   (3  general   flags).     The code has been corrected: a proper upper bound of 8 is checked before reading the permission flag.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.11   Incorrect Specifications and Comments",
        "body": "  CS-HPRNMM23-010  Several incorrect specifications and comments are identified:  1. checkMultisendTransaction()  will  disassemble  the  data  into  individual  transactions  for access  checks.  Each  transaction  consists  of  1  byte  operation,  20  bytes  target  address,  32  bytes value, and the actual transaction data. The inspected actual transaction data locates at an offset of 53 bytes instead of 85 bytes in the comments.  2. The  input  encoded  data  of  decodeFunctionSigsAndPermissions()  encodes  function signature  in  a  right-padded  way  and  permissions  in  a  left-padded  way.  The  index  of  permissions grows from right to left, while the specifications incorrectly state the other direction.  HOPRNet - Node Management Module -   17  DesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                        \f  Both specifications and comments have been corrected.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.12   Missing Input Checks at tokensReceived",
        "body": "  Besides funding a channel by fundChannelSafe() or fundChannel(), a node can also directly send tokens to the Channel contract, which triggers the tokensReceived() callback and funds one channel or  a  bidirectional  channel  depending  on  the  userData.  fundChannelSafe()  and  fundChannel() enforce the balance and channel parties validations, nevertheless, tokensReceived() does not. As a result, a node can fund a channel with a balance out of restrictions or with same parties on both sides of a channel.  CS-HPRNMM23-011    Description of Changes:   Moved  validateBalance  and  validateChannelParties  from  external  functions  (fundChannelSafe and fundChannel) to the internal function _fundChannelInternal. This allows tokensReceived to perform checks on balance and channel parties.   Moved  _fundChannelInternal  before  token.transferFrom  in  fundChannelSafe  and  fundChannel  functions  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.13   Signatures Can Be Replayed",
        "body": "  The  signature  used  in  HoprNodeSafeRegistry.registerSafeWithNodeSig()  doesn't  have  a nonce, so it can be replayed.  Thus, any arbitrary msg.sender can register a node again using the same signature, even if the Safe has deregistered it. Effectively, only the node chain address that used registerSafeByNode() can be deregistered.  In  addition,  for  deregistration  the  node  should  be  a  member  of  a  Safe.  Otherwise,  the  node  cannot deregister itself from the registry.  CS-HPRNMM23-012  The correct deregister way is assumed to be:  1. Deregister at the registry.  2. Remove the node from the Safe NodeManagementModule.  If these actions are not performed in a single transaction, a malicious party can register the node again after step 1 and break this flow.    HOPRNet - Node Management Module -   18  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \fA nonce has been added as a parameter in signed data. The nonce of the given chain address will be incremented on each registration.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.14   TargetUtils Incorrect Iterator Bound",
        "body": "  A customized type Target is an alias of uint256 to store a 20-byte target address associated with 12 one-byte flags (3 general flags and 9 capability permission flags). In contract util/TargetUtils.sol, decodeDefaultPermissions() will retrieve the address and individual flags from the packed target input. When decoding the capability permission flags, the iterator falsely starts from 0 and ends at 8 (176 +  8  *  i,  for  i  in  [0,8]).  As  a  result,  the  last  general  flag  with  the  first  8  capability  permission  flags  are returned as the 9 capability permission flags.  CS-HPRNMM23-013    The starting index has been fixed and is 184 now.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.15   Timestamp Is Not Updated With Snapshot",
        "body": "  CS-HPRNMM23-014  In an out-of-scope contract Ledger, indexEvent() will update the lastestRoot.rootHash when it is  called,  and  if  a snapshotInterval  has  elapsed.  However,  the  latestRoot.timestamp  is  not  updated  together with  the  latestSnapshotRoot.  Consequently  the  lastestSnapshotRoot  will  be  updated  every time.  the  lastestSnapshotRoot   the  lastestRoot   it  will  also  push   to     The latestRoot.timestamp is updated together with the latestSnapshotRoot.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.16   isNodeSafeRegistered Returns True for",
        "body": " Unregistered Pairs if safeAddress==0  In  NodeSafeRegistry,  isNodeSafeRegistered()  returns  if  the  input  chainkey  address  is  registered with  the  input  safe  address.  In  case  a  chainkey  is  not  registered  and  the  input  safeAddress  is  0,  this function will return true. This may be unexpected for the external systems.  CS-HPRNMM23-015    If node is not registered to any safe, isNodeSafeRegistered() will return false. Thus, the 0 address of safe will not be considered as a registered safe.  HOPRNet - Node Management Module -   19  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                        \f6.17   ERC777 Reentrancy in fundChannel  fundChannelSafe()  and  fundChannel()  will  call  token.transferFrom()  to  pull  tokens,  which will trigger the callback to the token spender's registered hook. What happens before the transfer is:  CS-HPRNMM23-016  1. Validation of the safe.  2. Validation of the input balance.  3. Validation of the parties addresses.  The only thing that the token spender can do is to register or deregister at the SafeRegistry which tricks the first modifier. For example, assume a node A without registering a safe at the beginning:  1. A first calls fundChannel().  2. In the callback, A calls registerSafeByNode().  As a result, A successfully funds a channel through fundChannel() while it is already registered with a safe.  This  reentrancy  does  not  have  an  explicit  influence  to  the  contracts  though  it  could  break  the assumptions.    The  code  has  been  corrected  to  avoid  reentrancy.  The  token  transfer  is  now  done  at  the  end  of  the function, after all the state changes have been done.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.18   Order of Evaluation Can Be Enforced",
        "body": "  The Solidity documentation states:  https://docs.soliditylang.org/en/latest/ir-breaking-changes.html#semantic-only-changes  For  the  old  code  generator,  the  evaluation  order  of  expressions  is  unspecified.  For  the  new  code generator, we try to evaluate in source order (left to right), but do not guarantee it. This can lead to semantic differences.  CS-HPRNMM23-020  The new code generator is not yet the default. This means that the order of evaluation of expressions is not  guaranteed.  Explicit  brackets  can  be  used  in  e.g. decodeDefaultPermissions()  the  order  of  evaluation   to  enforce   targetPermission = TargetPermission(uint8(Target.unwrap(target) << 176 >> 248));  uint8(Target.unwrap(target) << (184 + 8 * i) >> 248)    HOPRNet has added explicit brackets to enforce the evaluation order.  HOPRNet - Node Management Module -   20  InformationalVersion1CodeCorrectedInformationalVersion1CodeCorrected            \f7   Informational  We  utilize  this  section  to  point  out  informational  findings  that  are  less  severe  than  issues.  These informational issues allow us to point out more theoretical findings. Their explanation hopefully improves the overall understanding of the project's security. Furthermore, we point out findings which are unrelated to security.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   DomainSeparator Requires Manual",
        "body": " Recompute After a Fork  updateDomainSeparator()  is  a  public  function  that  recompute  and  update  the  domainSeparator  in case  of  a  fork.  It  requires  manual  invocation  upon  a  fork.  Signatures  on  the  forked  chain  are  still replayable  before  the  call  to  updateDomainSeparator().  In  case  of  supporting  a  forked  chain,  we assume this function will be invoked immediately.  CS-HPRNMM23-017  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Users Can Flash Loan by Fund Channel",
        "body": " Reentrancy  CS-HPRNMM23-018  and   fundChannel()  will   fundChannelSafe()  in _fundChannelInternal() before calling token.transferFrom() to pull wxHOPR tokens. A user can implement and register a token sender callback, which will be invoked before the token transfer. In this callback, it can flashloan any amount of wxHOPR within the current liquidity of the channel contract by  calling  closeIncomingChannel().  At  the  end  of  the  callback,  the  flashloan  will  be  repaid  by  the real transfer of the tokens. Here is an example:  balance   internal   update   the   contract Bob {      function close() public {         // close the channel to get desiredAmount         HoprChannels channels = HoprChannels(0x...);         channels.closeIncomingChannel(ALICE);          // customized logic here     } }  contract Alice is IERC777Sender {      function tokensToSend(...) public {         Bob(BOB).close();     }      function flashloan(uint256 desiredAmount) public {         _ERC1820_REGISTRY.setInterfaceImplementer(address(this),         TOKENS_SENDER_INTERFACE_HASH, address(this));  HOPRNet - Node Management Module -   21  InformationalVersion2InformationalVersion2      \f        HoprChannels channels = HoprChannels(0x...);         channels.fundChannel(BOB, desiredAmount);     } }  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   isContract Check Can Be Bypassed",
        "body": "  addNodeSafe()  has  a  check  nodeChainKeyAddress.isContract().  However,  if  this  node  is  a contract, and it calls the registry during its construction, the check will fail. Thus, node that is a contract can still be added to the registry.  CS-HPRNMM23-019  HOPRNet - Node Management Module -   22  InformationalVersion2    \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   No Protection for Keepers",
        "body": "  Generally, keepers may just be interested in collecting the penalty of failing offers. In Mangrove however, an  offer  could  always  succeed  unexpectedly  due  to  changing  on-chain  conditions.  In  this  case,  a keeper/taker may have executed an offer he did not actually intended to take and which may had a bad exchange rate. Note that offers may only fail when significant amounts of tokens are flashloaned to the maker up front but the very same offer may succeed for lower amounts.  Unaware keepers may be tricked by honeypot offers (offers that appear to fail but in reality don't fail) by malicious makers.  Keepers may protect themself by wrapping their call in a smart contract and checking for the expected outcome, but the code of Mangrove itself does not offer such a feature directly.  Risk Accepted:  Giry responded: Indeed all keepers should wrap their calls in a reverting contract. This protective wrapper does not need to be inside Mangrove. We plan to provide a standard wrapper at a separate address.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   ECDSA Signature Malleability",
        "body": "  Giry - Mangrove -   14  SecurityDesignCorrectnessCriticalHighMediumRiskAcceptedLowRiskAcceptedAcknowledgedAcknowledgedRiskAcceptedDesignMediumVersion1RiskAcceptedDesignLowVersion1RiskAccepted                   \fThe permit function utilizes the ECDSA scheme. However missing checks for the v, r and s arguments allow  attackers  to  craft  malleable  signatures.  According  to  Yellowpaper  Appendix  F,  the  signature  is considered valid only if v, r and s values meet certain conditions. The ecrecover for invalid values will return address 0x0 and verification will fail without informative error. The OpenZeppelin's ECDSA library performs such checks and reverts with informative messages.  Risk Accepted:  Giry responded: Code changes necessary for improved error messages would go past the contract size limit.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   No Minimum Value for gasreq",
        "body": "  Either to create a new offer or to update an existing one, the maker must provide a value for gasreq. In the current implementation, there is no minimum required value. The value for gasreq may even be set to 0, which means 0 gas requirements for the calls executed on the maker's side. Nevertheless, both calls are  executed,  the  first  call  to  makerExecute  with  all  gas  defined  in  gasreq  and  the  second  to makerPosthook with the \"leftover\" gas from gasreq. With 0 gas these low-level calls are started but immediately revert. The system could allow these calls to be skipped when the maker sets a zero / low amount for gasreq.  Acknowledged:  Giry  responded:  The  gas  saved  by  treating  0-gasreq  as  a  special  case  is  not  worth  the  added  code complexity.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Redundant Check in writeOffer",
        "body": "  When writeOffer is called a check that ofp.gives > 0 is performed. However, the check presented below  is  also  performed  and  implies  the  same  since  both  density  and  gasbase  should  be  positive under normal circumstances.  ofp.gives >=   (ofp.gasreq + $$(local_offer_gasbase(\"ofp.local\"))) *     $$(local_density(\"ofp.local\")),  No Issue:  Giry responded: It is possible for governance to set values such that the second check does not imply the first. The first check maintains a critical invariant.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Spamming the Offerbook",
        "body": "  Giry - Mangrove -   15  DesignLowVersion1AcknowledgedDesignLowVersion1AcknowledgedSecurityLowVersion1RiskAccepted                        \fAn  attacker  may  spam  the  offerbook  with  attractive  offers  reverting  immediately  upon  execution. Depending  on  the  parameters  chosen  by  the  governance  for  density  and  offer_gasbase  the resulting minimum penalty paid for the failing offer may be rather low.  Notably it is sufficient to have 85 such failing offers in the offer book (offering a very low price to ensure to be  on  top)  to  cause  a  revert  of  the  transaction  due  to  an  EVM  stack  too  deep  error.  Hence  any transaction to marketOrder() of this base/quote pair will revert leaving the state unchanged.  It's  still  possible  for  keepers  to  clean  the  offerbook  by  sniping  these  offers,  however  such  offers  may reinstantiate themself during the makerPosthook().  Risk Accepted:  Giry responded: Any self-reinserting spam is vulnerable to draining by any keeper.  Giry - Mangrove -   16    \f7   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  -Severity Findings   Draining All Ether Provisions of Mangrove   -Severity Findings  -Severity Findings  If Condition Always True    Rounding Errors In Partial Filling   -Severity Findings   Call in makerPosthook Fails Silently    Fields of Events Not Indexed   Imprecise Comment    Maximize Penalty Collected    Misleading Variable Names in stitchOffers    Overrestrictive Check in deductSenderAllowance    Repetitive Code   1  0  2  7  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Draining All Ether Provisions of Mangrove",
        "body": "  Makers can retract their offer by calling retractOffer(). This function accepts the boolean parameter deprovision which allows the maker to choose to either deprovision the offer or not.  Deprovisioning an offer credits back the provision to the maker. At the same time it must be ensured that this  offer  is  removed  from  the  offerbook  and  its  gasprice  must  be  set  to  0  as  the  offer  is  no  longer provisioned.  Not all possible cases are handled correctly inside function retractOffer(). For offers that are not live (this means they have a 0 amount for offer.gives) the provision can be credited back to the maker without the offer's gasprice being set to zero.  Hence  retractOffer()  with  deprovision  set  to  true  can  be  executed  successfully  repeatedly. Consequently a maker can reclaim more provision than he initially paid for the offer. This bug allows to eventually drain all Ether of Mangrove.  An offer can easily reach offers.gives = 0 which means it is considered to not be live:   By  calling  retractOffer()  with  bool  deprovision  set  to  false,  dirtyDeleteOffer()  is executed. This call sets offer.gives to zero however without setting offer.gasprice to zero due to deprovision being false.   After the offer has been consumed by an order offer.gives is 0.  Giry - Mangrove -   17  CriticalCodeCorrectedHighMediumCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSecurityCriticalVersion1CodeCorrected          \fCode Corrected:  The  call  to  dirtyDeleteOffer()  was  moved  out  of  the  isLive  scope.  Hence  whenever deprovision is set to true and the provision is credited back to the Maker, the order is deprovisioned. Calling the function repeatedly on the same offer no longer allows to drain Ether of Mangrove, the issue has been resolved.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   If Condition Always True",
        "body": "  During the execution of function execute the following check is performed:  if (statusCode != \"mgv/notExecuted\") {   dirtyDeleteOffer(     ...   ); }  However statusCode cannot have the value mgv/notExecuted at this point so the condition is always true.  Code Corrected:  The code now runs unconditionally.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Rounding Errors In Partial Filling",
        "body": "  A maker's order can be partially filled according to the following snippet:  if (mor.fillWants) {    sor.gives = (offerWants * takerWants) / offerGives;  } else {    sor.wants = (offerGives * takerGives) / offerWants;  }  Note that the division can yield rounding errors. The rounding errors can be as extreme as giving funds to the maker without receiving anything in return or taking from the maker without giving anything back. For example,  consider  the  case  where  the  maker  offers  10  A  for  5  B  and  taker  wants  to  take  only  1  A (fillWants == true). Then, according to the formula she has to offer 5 * 1 / 10 = 0 B.  Code corrected  Prices are now always rounded in favor for the taker to avoid any maker draining. Hence, to calculate sor.gives when fillWants is true the code has been changed to:  Giry - Mangrove -   18  DesignMediumVersion1CodeCorrectedDesignMediumVersion1CodeCorrected                \fuint product = offerWants * takerWants; sor.gives =   product /   offerGives +     (product % offerGives == 0 ? 0 : 1);  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   Call in makerPosthook Fails Silently",
        "body": "  The return value success2 in makerPosthook() is never handled. Thus a failed execution of the hook can go unnoticed and unlogged.  Code Corrected:  A log event is emitted on posthook revert.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   Fields of Events Not Indexed",
        "body": "  No parameter of the events defined in MgvEvents is marked as indexed. Indexing fields of events, e.g. addresses, allows to search for them easily.  /* Mangrove adds or removes wei from `maker`'s account */   /* * Credit event occurs when an offer is removed from the Mangrove or when the `fund` function is called*/   event Credit(address maker, uint amount);   /* * Debit event occurs when an offer is posted or when the `withdraw` function is called */   event Debit(address maker, uint amount);    /* * Mangrove reconfiguration */   event SetActive(address base, address quote, bool value);   event SetFee(address base, address quote, uint value);   event SetGasbase(     address base,     address quote,     uint overhead_gasbase,     uint offer_gasbase   );  Code Corrected:  The relevant arguments were indexed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.6   Imprecise Comment",
        "body": "  At  the  beginning  of  function  execute()  the  code  handles  whether  the  full  offer  is  to  be  consumed  or only a partial amount of the offer should be taken by the order.  Giry - Mangrove -   19  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                        \fif (   (mor.fillWants && offerGives < takerWants) ||   (!mor.fillWants && offerWants < takerGives) ||   offerWants == 0 ) {   sor.wants = offerGives;   sor.gives = offerWants;   /* If we are in neither of the above cases, then the offer will be partially consumed. */ } else {   /* If `fillWants` is true, we give `takerWants` to the taker and adjust how much they   give based on the offer's price. Note that we round down how much the taker will give. */   if (mor.fillWants) {     /* **Note**: We know statically that the offer is live (`offer.gives > 0`) since market      orders only traverse live offers and `internalSnipes` check for offer liveness before executing. */     sor.gives = (offerWants * takerWants) / offerGives;     /* If `fillWants` is false, we take `takerGives` from the taker and adjust how much they get      based on the offer's price. Note that we round down how much the taker will get.*/   } else {     /* **Note**: We know statically by outer `else` branch that `offerGives > 0`. */     sor.wants = (offerGives * takerGives) / offerWants;   } }  The last comment  Note: We know statically by outer else branch that offerGives > 0.  is not entirely correct: While it holds that offerGives is > 0 this is not due to being in the outer else branch but due to it having been ensured earlier that the offer is live, so offerGives is >0. Due to being in the outer else branch we know that offerWants is non-zero and hence we are sure there will be no division by zero which is the important consideration here.  Code Corrected:  The comment was changed to:  Note: We know statically by outer else branch that offerWants > 0.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.7   Maximize Penalty Collected",
        "body": "  Function  snipes()  allows  keepers  to  snipe  multiple  failing  offers  at  once  and  thereby  collect  the penalty. However, when multiple offers fail within one order, the base gas fee is split amongst all failing offers. This is done in order to distribute the base fees that applies once per transaction evenly across all affected offers.  In  order  to  maximize  their  profit,  professional  keepers  may  deploy  their  own  smart  contract  calling snipe() individually on each offer without increasing their expenses significantly, in order to ensure to always collect the maximum penalty possible.    The sniping mechanism has changed and, now, snipes() treats all snipes in isolation. With this change overhead_gasbase was removed and the scenario described above no longer applies.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.8   Misleading Variable Names in stitchOffers",
        "body": "  Giry - Mangrove -   20  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \fIn  stitchOffers  the  variable  names  worseId  and  betterId  are  used.  However,  the  betterId refers  to  the  offer  next  to  the  offer  under  consideration  and  worseId  refers  to  the  previous  one.  This seems to contradict the naming convention holding for the offerbook. According to this convention, for a given offer, its previous offer is a better one and its next offer a worse one.  Code Corrected:  The names of the variables were swapped.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.9   Overrestrictive Check in ",
        "body": " deductSenderAllowance  deductSenderAllowance checks if the amount used does for a trade does not exceed the allowance the use has set. However, it prevents the full allowed amount from being used since the equality is not checked.  require(allowed > amount, \"mgv/lowAllowance\");  Code Corrected:  > was replaced with >=.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.10   Repetitive Code",
        "body": "  In postExecute the following snippet is used right before the call to applyPenalty().  if (gasused > gasreq) {    gasused = gasreq;  }  Later, in applyPenalty the same snippet is repeated as follows:  if ($$(offerDetail_gasreq(\"sor.offerDetail\")) < gasused) {   gasused = $$(offerDetail_gasreq(\"sor.offerDetail\")); }  which is redundant.  Code Corrected:  The second check in postExecute was removed.  Giry - Mangrove -   21  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \f8   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  Hence,  the mentioned topics serve to clarify or support the report, but do not require a modification inside the project. Instead,  they  should  raise  awareness  in  order  to  improve  the  overall  understanding  for  users  and developers.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.1   Bitwords Benefits",
        "body": "  In the implementation of Mangrove, structs to be stored in storage and handled as bitwords. This is done to  improve  gas  efficiency.  However,  given  that  equivalent  native  solidity  structs  could  fit  in  on  storage slot, the benefits from such a decision are questionable. The main downside of this decision is the extra layer  of  complexity,  introduced  in  the  form  of  solidity  code  preprocessing,  which  aims  to  facilitate  the handling of such bitwords.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.2   Choosing the Parameter gasreq",
        "body": "  When choosing the parameter gasreq, makers must be aware of certain things: As described in the code, the maker may receive only gasreq-63h/64 gas, where h is the overhead of (require + cost of CALL).  Nevertheless, should the call fail due to insufficient gas the maker is accountable for this and if the overall gas  remaining  in  the  transaction  is  sufficient,  the  transaction  penalizes  the  maker  and  completes successfully.  The comment states:  We let the maker pay for the overhead of checking remaining gas and making the call.  Albeit minor, the maker also pays for the overhead to handle the return data. All of this needs to be taken account when selecting the value for gasreq, especially in order to ensure enough gas will be available to the call to makerPosthook.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.3   Estimation of the Gas Limit for a ",
        "body": " marketOrder Transaction  Estimating  the  gas  limit  for  a  transaction  to  marketOrder  is  tricky.  Underestimating  it  leads  to  the transaction to revert, while overestimating it increases the risk of a high tx fee for a failing transaction.  Function  marketOrder  is  dependent  on  the  actual  status  of  the  offer  book  which  may  change significantly  between  when  the  transaction  is  generated  and  signed  and  when  it  is  executed  by  being included  inside  a  block.  Offers  may  be  added  or  removed  resulting  the  gas  requirement  for  the  offers being executed as part of the order may change significantly.  While marketOrder can skip failing offers and refund the taker, it can only do so successfully when the transaction has enough gas.  To avoid failing transactions users have to overestimate the gas required.  Giry - Mangrove -   22  NoteVersion1NoteVersion1NoteVersion1          \f8.4   Payable Fallback Functions For Taker Contracts  Takers may be contracts. When makers are penalised, provision is sent to the takers by a low level call msg.sender.call{value: amount}(\"\"). In this case, taker contracts must be able to handle the ether received by implementing fallback functions.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "8.5   Tokens With Transfer Fees",
        "body": "  Mangrove  is  supposed  to  handle  the  exchange  of  ERC20  tokens.  As  shown  in  the  snippet  below,  the system  expects  to  send  to  the  maker  the  same  amount  (sor.gives)  it  received  from  the  taker. However, in the case of the tokens with transfer fees this trade will fail since the amount received and forwarded by Mangrove will be different than the one requested due to the fees. By providing additional balance of this token to the contract ahead of the transaction, a party may make the transfer to succeed nevertheless.  This  may  be  done  by  either  the  maker  or  the  taker.  The  other  party  then  receives  less tokens then expected, as the transfer fee will be deducted.  if (transferTokenFrom(sor.quote, taker, address(this), sor.gives)) {    if (      transferToken(        sor.quote,        $$(offerDetail_maker(\"sor.offerDetail\")),        sor.gives      )    ) {     ...  Giry - Mangrove -   23  NoteVersion1NoteVersion1        \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   FeeTier of Swap",
        "body": "  0  0  0  2  The Swap contract allows authorized callers to add multiple fee tiers. These tiers are not documented. Any fee added as fee tier is valid. All calls to swapTokens() may simply specify the lowest allowed fee, higher fee tiers can just be avoided by the users.  Risk accepted:  Oazo Apps Limited states:  Added a note at the bottom of the Operation Registry section. We accept the risk that the user might change the fee from the front-end.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Missing NatSpec",
        "body": "  The  code  is  not  documented  in  the  NatSpec  format.  It  is  recommended  to  fully  annotate  all  public interfaces. This should help both end users and developers interact with the contracts.  Risk accepted:  To be added later.  Oazo Apps Limited - Modular Proxy Actions -   11  SecurityDesignCorrectnessCriticalHighMediumLowRiskAcceptedRiskAcceptedDesignLowVersion1RiskAcceptedDesignLowVersion1RiskAccepted                   \fOazo Apps Limited - Modular Proxy Actions -   12    \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  0  2  9  12  -Severity Findings  -Severity Findings   OperationStorage Can Be Polluted    OperationsRegistry: No Access Control   -Severity Findings  Implementation of UseStore Inconsistent With Documentation   Ineffective receiveAtLeast Check After Swap    Maker Deposit Action Uses Full Balance    No Access Control on onFlashLoan    OperationRegistry: No Entry, No Checks    Payable Action.execute()    Reentrancy Into executeOp()    Visibility of aggregate Function    sendToken: Transfers msg.value Instead of send.amount   -Severity Findings   Action Events Not Emitted    Actions: Inconsistent Destination of Tokens    DAI Address Could Be Constant    OperationStorage: Unused owner Variable    OperationsRegistry: No Events Emitted on State Change    Outdated Compiler Version    Receiver of Flashloan    Sanity Check in on Flashloan    Swap Slippage Saved Event Order    Swap.sol: ReceiveAtLeast Does Not Take Into Account the Fee    Unused Return Value of Aave Withdraw    onFlashLoan() Ignoring Fees   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   OperationStorage Can Be Polluted",
        "body": "  Oazo Apps Limited - Modular Proxy Actions -   13  CriticalHighCodeCorrectedCodeCorrectedMediumSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedSecurityHighVersion1CodeCorrected          \fOperationStorage  is  designed  to  be  used  as  a  temporary  store  of  actions  and  return  values  for  the execution of an operation. Therefore, the variables it contains are deleted at the end of every operation execution.  However,  as  it  lacks  access  control,  and  since  there  is  no  mechanism  to  ensure  that OperationStorage  is  empty  before  an  execution,  action  and  return  values  could  be  maliciously  or erroneously introduced.  In particular, an attacker could store spurious return values with the push function. In the next execution actions  may  retrieve  these  values  instead  of  the  intended  ones  which  are  appended  at  the  end  of  the array.  Finally,  it  should  be  considered  that  the  execution  of  actions  may  reach  untrusted  code  (integrations, tokens). Functions push and finalize may be accessed unexpectedly even within the execution of an action.  This  similarly  applies  to  functions  setOperationActions  and  verifyAction  were  it  is  not obvious whether this can have a negative impact.  Code partially corrected:  OperationStorage  is  now  cleared  at  the  beginning  of  OperationExecutor.executeOp(),  this ensures that the execution of operation does not start with a polluted OperationStorage which mitigates the main issue.  Within  execution  of  actions  untrusted  code  may  be  reached  (integrations,  tokens),  in  theory  they  may the  OperationStorage:  push(),  verifyAction(), execute  state  changing  clearStorageAfter().  functions  of     OperationStorage  contract  now  stores  the  return  values  from  actions  in  a  mapping  where  values  are assigned to the address that pushed them.  mapping(address => bytes32[]) public returnValues;  function push(bytes32 value) external { ... returnValues[msg.sender].push(value); }  function at(uint256 index, address who) external view returns (bytes32) { return returnValues[who][index]; }  When writing to the OperationStorage, an address can only write in the array associated to this address. When  reading  from  the  OperationStorage,  the  caller  must  specify  which  value  from  which  address  he wants to read. This prevents untrusted code to tamper with the return values during an operation.  In case of a flashloan action executed from the AutomationBot (more precicesly a Flashloan action with flag  dsProxyFlashloan  set  to  false)  execution  continues  in  the  context  of  the  OperationExecutor. The  original  initiator  will  be  pushed  to  the  OperationStorage,  when  called  from  the  OperationExecutor functions push, at and len will use this address instead of msg.sender.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   OperationsRegistry: No Access Control",
        "body": "  Oazo Apps Limited - Modular Proxy Actions -   14  SecurityHighVersion1CodeCorrected        \fThe  purpose  of  the  OperationsRegistry  contract  is  to  specify  the  set  of  actions  identified  by  a string  name.  As  this  contract  lacks  access  control,  anyone  could  modify  the  mapping  between operation  and  actions.  This  can  be  done  through  the  addOperation  function,  which  allows  not  only adding a new operation but also modifying any existing one.  As a consequence, an attacker could modify the entries for existing operations. This could prevent the corresponding  verifications  from  succeeding,  and  thus  compromise  the  availability  of  the  system.  An attacker  may  as  well  delete  the  actions  stored  for  an  operation  resulting  in  no  verification  on  the  calls being done in OperationExecutor.aggregate().  The extensive documentation lacks a description of the OperationRegistry.    Access control has been added: There is now an owner, only this owner can add/update operations to the OperationRegistry.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Implementation of UseStore Inconsistent With",
        "body": " Documentation  The implementation of the read function in UseStore is not consistent with the provided documentation. The function shown in the PDF does not subtract 1. In general, mixing 0-based and 1-based indexing can be a source of errors, so this should be well documented.  Specification changed:  The  excerpt  of  UseStore.read()  shown  in  the  documentation  has  been  updated  and  is  now  in  line with the actual implementation. Furthermore the params mapping section of the documentation has been extended.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Ineffective receiveAtLeast Check After",
        "body": " Swap  To verify that the swap executed correctly, SwapOnOneInch.execute() checks that the balance is at least what the user wanted to receive:  require(balance >= swap.receiveAtLeast, \"Exchange / Received less\");  The  check  doesn't  take  into  account  that  the  token  balance  before  the  swap  may  have  been  non-zero already.  Hence  the  check  may  pass  despite  the  swap  resulted  in  less  than  receiveAtLeast  tokens. This  code  is  intended  to  be  executed  as  Delegatecall  in  the  context  of  the  users  DsProxy,  a  non-zero balance of the token out before the swap is not an unlikely scenario.  A  similar  check  is  done  in  Swap.sol.  This  contract  however  is  used  differently:  It's  a  helper  contract which  is  not  supposed  to  hold  any  token  balances  in  between  calls,  furthermore  it  forwards  all  token balance. Hence in the Swap contract; from a caller's perspective the check ensures receiveAtLeast.  Oazo Apps Limited - Modular Proxy Actions -   15  CorrectnessMediumVersion1Speci\ufb01cationChangedCorrectnessMediumVersion1CodeCorrected                \f  File SwapOnOneInch.sol no longer exists in the updated codebase.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Maker Deposit Action Uses Full Balance",
        "body": "  While  the  DepositData  struct  contains  an  amount  parameter,  the  maker/Deposit  action  always uses the full available balance. This behavior is not documented and may be unexpected for users who specify an inferior amount.  Code partially corrected:  The code of action maker/Deposit now deposits the amount specified. However the action still exchanges all Ether balance to WETH. Is this intended?    The code wrapping ETH has been removed. This fixes the remaining issue as the user's Ether will not be exchanged to WETH. Note that the user needs to have WETH available instead.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   No Access Control on onFlashLoan",
        "body": "  The onFlashLoan function of the OperationExecutor contract is only intended to be called by the Flashloan provider. As it has no access control it can be called by anyone. The contract will then give approval to the registered lender for amount of asset. While this is not necessarily a problem, it breaks the normal pattern that the OperationExecutor is \"stateless\" in between calls, in the sense that he has given an approval to transfer tokens to a third party.    Access control has been added to OperationExecutor.onFlashLoan(). The function can only be called by the trusted lender returned by the Registry:  address lender = registry.getRegisteredService(FLASH_MINT_MODULE); require(msg.sender == lender, \"Untrusted flashloan lender\");  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   OperationRegistry: No Entry, No Checks",
        "body": "  Oazo Apps Limited - Modular Proxy Actions -   16  CorrectnessMediumVersion1CodeCorrectedDesignMediumVersion1CodeCorrectedDesignMediumVersion1CodeCorrected                        \fWhen  there  is  no  operation  stored  for  a  name,  getOperation()  returns  an  empty  array  and subsequently  nothing  is  checked.  Shouldn\u2019t  this  case  be  handled  explicitly  to  avoid  not  checking correctness by accident?  An  operation  name  is  a  string.  This  allows  displaying  the  operation  name  in  a  human  readable  way. However, this can be dangerous as strings support the Unicode charset and many lookalike characters of different alphabets exist in this charset. Hence users might be tricked.  For  https://util.unicode.org/UnicodeJsps/confusables.jsp?a=IncreaseMultipleWithFl  characters,   lookalike   insights   more   into   please   refer   to:    getOperation() of OperationRegistry now reverts on non-existing operations instead of returning an empty array (which results in skipping checks). Custom operation with empty actions have to be explicitly added to the OperationRegistry.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   Payable Action.execute()",
        "body": "  The interface Executable specifies:  function execute(bytes calldata data, uint8[] memory paramsMap) external payable;  The  code  of  actions  is  executed  as  delegatecall  from  within  OperationExecutor.aggregate(). Delegatecall preserves msg.sender and msg.value. The aggregate function of the OperationExecutor is  not  payable,  hence  msg.value  will  always  be  zero.  Calls  to  executeOp()  /  aggregate()  with non-zero msg.value will revert, hence why is the execute function of actions supposed to be payable?  Note that actions may still work with Ether despite not receiving calls with non-zero msg.value: Ether can  be  received  by  the  DsProxies  fallback  function  /  the  DsProxy  can  already  have  an  Ether  balance which can be transferred onwards.    OperationExecutor.executeOp()  is  supposed  to  handle  Ether  transactions,  hence  it  has  been changed to payable.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   Reentrancy Into executeOp()",
        "body": "  Function executeOp() can be reentered. At this time OperationStorage may be in an inconsistent state, amongst others (actions), returnValues may contain values.  While  this  is  not  an  intended  use  case,  technically  the  possibility  exists.  To  reduce  risks,  this  may  be restricted especially as the execution reaches untrusted third-party code (integrations, token contracts).  Furthermore note that after a takeAFlashloan action, the OperationExecutor temporarily has the right to  call  execute()  on  the  DsProxy  of  the  user.  OperationExecutor.onFlashloan()  uses  this  to execute aggregate() on the initiator.  Currently this is not exploitable due to:  Oazo Apps Limited - Modular Proxy Actions -   17  DesignMediumVersion1CodeCorrectedDesignMediumVersion1CodeCorrected                \f The DAI Flash Mint Module features a reentrancy protection, hence no second flashloan is currently possible. Note that this is no requirement for an ERC3165 compliant flashloan provider, an arbitrary flashloan proivder may not, e.g., the reference implementation of ERC3165 does not feature such a protection.   ERC3165 requires the initiator being the msg.sender initiating the flashloan. It's not possible for an attacker to get the initiator to be the DsProxy where the OperationExecutor holds the privilege.  In  the  aggregate function.    reentrancy  is  also  possible  with  aggregate(),  please  consider  issue  Visibility  of    The updated code prevents reentrancy into executeOp() by leveraging the OperationStorage contract: The reentrancy lock is set in the OperationStorage at the beginning of the execution and released after the operation.  Releasing  can  only  be  done  by  the  account  which  set  the  reentrancy  lock;  releasing  the  lock  sets  the stored account to 0x0. This ensures that the original call to executeOp() reverts in case of reentrancy.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   Visibility of aggregate Function",
        "body": "  Although  the  main  entry  point  into  the  OperationExecutor  contract  is  the  executeOp  function,  the aggregate  function  is  also  public.  In  the  current  implementation  this  is  required  for  the  flashloan functionality to continue execution of the subsequent calls.  This  function,  which  is  not  intended  to  be  called  directly,  may  become  a  source  of  confusion/errors.  In particular,  if  called  directly  it  will  bypass  the  verification  that  the  right  actions  are  executed  for  a  given operation  (as  specified  by  OperationsRegistry).  Furthermore  operationStorage.finalize() will not be executed.  Access to this function might be restricted. This function may be internal, with an exposed external function for onFlashloan() which accepts calls by the OperationExecutor only.    The  visibility  of  the  aggregate  function  has  been  changed  to  internal.  The  callback  from onFlashLoan to the DsProxy is executed via a new callbackAggregate function which is public but restricts execution only by OperationExecutor itself.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.11   sendToken: Transfers msg.value Instead of",
        "body": " send.amount  In  case  of  Ether  transfer,  action  sendToken  transfers  msg.value  instead  of  the  amount  specified  in sendTokenData.  Note that despite the payable modifier of function execute, (delegate)calls from the OperationExecutor to  this  action  cannot  have  a  non-zero  msg.value  since  OperationExecutor.aggregate()  is  not  Oazo Apps Limited - Modular Proxy Actions -   18  Version1DesignMediumVersion1CodeCorrectedCorrectnessMediumVersion1CodeCorrected                \fpayable and would revert on non-zero msg.value. Neither does executeOp(). Hence sendToken will never enter the msg.value > 0 branch in the current setup.    In  case  of  Ether  transfer,  action  sendToken  now  transfers  the  amount  specified  in  sendTokenData. Furthermore  OperationExecutor.executeOp()  now  features  the  payable  modifier  and  accepts calls with Ether. Since function aggregate has been made internal calls with non-zero msg.value are now supported.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.12   Action Events Not Emitted",
        "body": "  The Executable interface defines an Action event that only some actions emit. The following actions do not emit an event at the end of their execution:   common/PullToken   common/SendToken   common/SetApproval   common/SwapOnOneInch   maker/CdpAllow    All actions now emit the Action event.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.13   Actions: Inconsistent Destination of Tokens",
        "body": "  In  maker/Generate  the  destination  address  data.to  can  be  specified  by  the  caller,  but  this  is  not possible in aave/withdraw. There may be a general pattern actions should adhere to for consistency.    AAVE  withdrawal  &  borrow  actions  now  accept  the  destination  of  tokens,  consistent  with  the  Maker actions.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.14   DAI Address Could Be Constant",
        "body": "  In TakeFlashoan, the DAI address may be hardcoded instead of being queried from the registry.    Oazo Apps Limited - Modular Proxy Actions -   19  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \fThe DAI address is now an immutable set upon deployment.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.15   OperationStorage: Unused owner Variable",
        "body": "  The OperationStorage contract defines an owner variable that is set to msg.sender in the constructor, but is never used thereafter.    The unused owner variable has been removed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.16   OperationsRegistry: No Events Emitted on",
        "body": " State Change  No  events  are  defined  or  emitted  in  the  OperationsRegistry  contract.  In  general,  it  is  recommended  to emit an event on every state change. This allows to identify changes easily.    Function addOperation now emits event OperationAdded.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.17   Outdated Compiler Version",
        "body": "  The project uses an outdated version of the Solidity compiler.  pragma solidity ^0.8.5;  Known bugs in version 0.8.5 are:  https://github.com/ethereum/solidity/blob/develop/docs/bugs_by_version.json#L1753  More information about these bugs can be found here: https://docs.soliditylang.org/en/latest/bugs.html  At the time of writing the most recent Solidity release is version 0.8.16.    It was decided to update to compiler version 0.8.15. Client states:  Updated compiler version to 0.8.15. There was a new version after this that came just after we updated, but that did not have changes that were relevant to our scope.  Oazo Apps Limited - Modular Proxy Actions -   20  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                          \f6.18   Receiver of Flashloan  From the documentation we understood that the receiver of the flashloan and the callback would always be  the  OperationExecutor  contract.  For  action  TakeFlashloan  however,  the  caller  can  specify  the receiver using parameter flData.borrower. What's the intention here?    The address of the OperationExecutor is now fetched from the registry and set as borrower.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.19   Sanity Check in on Flashloan",
        "body": "  The intention behind following check in OperationExecutor.onFlashloan() is unclear:  require(amount == flData.amount, \"loan-inconsistency\");  While checking the actual balance has its limitations (e.g. not clear if token balance originates from the flashloan or whether it has been there before already), why is the sanity check on the specified amounts being done but not on the actual balance ?  After the intermediate report, the check was changed to:  require(IERC20(asset).balanceOf(address(this)) == flData.amount, \"Flashloan inconsistency\");  This is dangerous: Any additional balance of this token held by the OperationExecutor causes a revert of this function. It should be clarified what should be checked and why this is checked.  Initially  the  code  checked  whether  the  parameter  amount  the  caller  (the  flashloan  provider)  passed matches the expected amount. We questioned what's the intention behind this check and highlighted that it doesn't ascertain anything on the actual balance. Checking if at least the balance expected is present might  be  an  option,  but  it  must  be  clear  that  this  doesn't  say  how  much  tokens  have  been  transferred from the flashloan provider (as the OperationExecutor may have had a non-zero token balance before as anyone could just transfer tokens).    The check was changed to:  require(IERC20(asset).balanceOf(address(this)) >= flData.amount, \"Flashloan inconsistency\");  This  does  not  allow  to  determine  whether  the  token  balance  originates  from  the  flashloan  or  if  it  was already in the contract, but now an additional balance of this token held by the OperationExecutor will not cause a revert.  Client adds:  In the event that the lender is compromised and supplies a lesser amount then the Operation execution will fail unless another party has accidentally sent balance to  Oazo Apps Limited - Modular Proxy Actions -   21  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected              \fthe Operation Executor at some earlier time. The only impacted party would be the person who accidentally sent tokens to the Operation Executor, whose funds are lost anyway.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.20   Swap Slippage Saved Event Order",
        "body": "  Swap._swap() emits the SlippageSaved event after a swap:  balance = IERC20(toAsset).balanceOf(address(this)); emit SlippageSaved(receiveAtLeast, balance); if (balance < receiveAtLeast) {   revert ReceivedLess(receiveAtLeast, balance); }  While after a revert occurs all state changes including any event logs are thrown away, it might be more appropriate to only emit the event after it has been ascertained that more than receiveAtLeast have been received.    The event is now emitted after the check.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.21   Swap.sol: ReceiveAtLeast Does Not Take",
        "body": " Into Account the Fee  While the code of Swap._swap() ensures that after the call to the 1inchAggregateor the balance of the SwapContract is more than receiveAtLeast what is sent onwards to the user might be less as the fee may be deducted only afterwards. The expected behavior is not specified.  Specification changed:  The documentation has been updated and now reads:  receiveAtLeast - an amount that needs to be returned from swap, it does not consider fee, in case fee is collected from outgoing token the resulting amount might be less than receiveAtLeast. Sole purpose of ReceiveAtLeast is to prevent high slippage on exchange.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.22   Unused Return Value of Aave Withdraw",
        "body": "  In the Aave withdraw action, the return value of withdraw is ignored:  Oazo Apps Limited - Modular Proxy Actions -   22  DesignLowVersion1CodeCorrectedCorrectnessLowVersion1Speci\ufb01cationChangedDesignLowVersion1CodeCorrected                        \fILendingPool(registry.getRegisteredService(AAVE_LENDING_POOL)).withdraw(   withdraw.asset,   withdraw.amount,   address(this) );  This  return  value  represents  the  actual  amount  that  was  withdrawn  and  might  be  different  from  the amount given as argument.  Specifically, if type(uint256).max is given as argument amount, then the total available balance is withdrawn and returned.    The withdrawn value is now stored and can be used by subsequent actions.  Oazo Apps Limited replied:  We agreed that all Actions should push a return value to the OperationStorage even if that value is zero (Code change hasn\u2019t occurred yet). This makes paramsMapping simpler and more predictable.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.23   onFlashLoan() Ignoring Fees",
        "body": "  The  documentation  states  that  the  OperationExecutor  implements  the  IERC3156  standard.  The implementation of OperationsExecutor.onFlashloan() however does not support fees. DAI flash mint currently takes no fee hence with the intended flashloan provider the code currently works however the current code doesn't fully implement/support the ERC3156 standard.    onFlashloan() now supports fees.  Oazo Apps Limited - Modular Proxy Actions -   23  CorrectnessLowVersion1CodeCorrected        \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   DsProxy With Unsupported Authority",
        "body": "  A user is free to set the authority contract of his own DSProxy. Depending on the authority contract set,  which  may  be  arbitrary,  ProxyPermission.givePermission()  may  not  be  successful.  The documentation  only  explains  the  expected  case  were  everything  works,  it  does  not  mention  this restriction.  Oazo Apps Limited - Modular Proxy Actions -   24  NoteVersion1  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Advance to Wrong Stage",
        "body": "  When all deposits are done and meet the minimum requirements but no trades happen, consequently, the  stage  is  not  advanced  and  the  stage  FAIR_TRADING  would  never  be  active.  If  claimLP  is  called after fairTradingEnd it will not be possible to claim because the stage is still in ETH_DEPOSIT instead of FAIR_TRADING . advanceStage needs to be called first to allow claiming the LP tokens in this case to put the stage into FAIR_TRADING and allow the stage progression to be finished in the next iteration.    If fairTradingEnd is reached in the ETH_DEPOSIT stage, the next call will automatically advance the stage to FINISHED.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   ETH Transfer",
        "body": "  The contract uses the native transfer function to transfer ETH to users. As this function can only use up to 2,300 gas, users using contracts (e.g., Gnosis Safe) to transfer ETH to the contract might be in for a surprise  when  the  FAILED  stage  is  reached  and  they  want  to  call  retrieveETH:  The  transfer  won't succeed.  In  this  case,  the  ETH  of  these  users  has  to  be  transferred  manually  by  the  owner  using execute.    ETH are now transferred using low level calls.  GEARBOX - Gearbox Auction -   10  CriticalHighMediumLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                  \f6.3   Gas Optimizations  The following parts of the contracts could be optimized for gas efficiency:   _advanceStage redundantly checks for the condition if the block.timestamp has exceeded the  fairTradingStart.   _advanceStage performs multiple, redundant storage loads of stage.   _advanceStage sets the stage to ETH_DEPOSIT and then immediately sets it to FAILED.   GEAR token transfers are conducted using safeTransferFrom. This overhead is not needed as  the GEAR token's transfer functions are reverting by default.   _getCurrentMinMaxAmounts   redundantly  totalEthCommitted from storage multiple times.  loads   totalGearCommitted   and   getPendingLPAmount redundantly loads totalLPTokens from storage multiple times.   _commitETH redundantly loads totalEthCommitted from storage multiple times.   commitGEAR redundantly loads totalGearCommitted from storage multiple times.   _depositToPool   redundantly   loads   curvePool,   totalGearCommitted   and  totalEthCommitted from storage multiple times.   foundry.toml does not contain settings for the optimizer.    All listed gas optimizations have been integrated, except for the following (minor) points:   foundry.toml has not been updated with optimizer settings.   _depositToPool still loads curvePool two times from storage.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Shearing Percent Getter Wrong Before Fair",
        "body": " Trading Stage  If  getCurrentShearingPct  is  called  before  the  fairTradingStart  timestamp  is  reached,  it  will display more than the maximum shearing percentage.    getCurrentShearingPct now returns shearingPctStart before fairTradingStart.  GEARBOX - Gearbox Auction -   11  DesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected              \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Almighty Owner Function",
        "body": "  The  owner  of  the  Bootstrap  contract  is  \"almighty\".  The  function  execute  allows  non-restricted  calls  to any  contract.  This  setup  seems  fine  as  the  owner  is  planned  to  be  the  GEARBOX_TREASURY  address. The thread model assumes this address fully trusted. Still, it should be checked after deployment that all addresses were set correctly.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Fail at FAIR_TRADING Stage",
        "body": "  The  function  fail  can  be  called  by  the  owner  of  the  contract  at  any  stage.  If  it  is  called  in FAIR_TRADING  stage,  LP  tokens  have  already  been  transferred  to  the  contract  and  cannot  be distributed  through  the  claimLP  function.  Instead,  they  have  to  be  sent  to  another  contract  (with execute) on which a distribution can take place.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   Inconsistent and Floating Pragma",
        "body": "  Gearbox Auction uses the floating pragma ^0.8.10. Additionally, the compiler version is not set in the Foundry  settings.  Contracts  should  be  deployed  with  consistent  compiler  versions  and  flags  that  were used during testing and auditing. Locking the pragma helps to ensure that contracts are not accidentally deployed using a different compiler version and helps to ensure a reproducible deployment.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   Rounding Errors",
        "body": "  Due to rounding errors, the following can happen:   A call to sellGear with 3 wei of GEAR tokens (or slightly more depending on the current shearing  percentage) can be sold without the shearing fee.   Some LP tokens might not get distributed. If, for example, 25 wei LP tokens are distributed to a user that committed all of the GEAR liquidity and all of the ETH liquidity, the user only receives 24 wei LP tokens.  GEARBOX - Gearbox Auction -   12  NoteVersion1NoteVersion1NoteVersion1NoteVersion1              \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Heap Data Structure Can Be Spammed",
        "body": "  The  users'  supply  and  borrow  information  is  stored  in  Heap  data  structures.  The  parameter _maxSortedUsers sets the maximum sorted user amount in order to limit the gas spent on updating the Heap.  The  data  structure  would  halve  the  length  of  the  Heap  when  maxSortedUsers  is  exceeded. However, this behavior would potentially put an incoming user to a higher priority than an existing one. This behavior can be abused by bad actors to fill the ordered portion of the Heap with dust:  Consider the following example:   maxSortedUsers is set to 4.   Step 1: User 1 and user 2 are legitimate users that supplied 400 and 300 tokens respectively.   Step 2: An attacker now supplies 600, 500 and 1 token with three different addresses.   Step 3: The attacker withdraws 599 and 499 tokens from accounts 3 and 4.  The described behavior is detailed in Figure 1. Blue boxes show accounts in the ordered portion of the Heap, green boxes show accounts in the non-ordered portion.  Morpho Labs - Morpho (Aave v3) -   11  DesignCorrectnessCriticalHighRiskAcceptedMediumRiskAcceptedLowCodePartiallyCorrectedCodePartiallyCorrectedCodePartiallyCorrectedRiskAcceptedRiskAcceptedCorrectnessHighVersion1RiskAccepted           \fFigure 1: Spam attack on the Heap  As a result, the supplied liquidity of users 1 and 2 is now only reachable after the dust of the attacker's accounts has been matched.  Risk accepted:  Morpho Labs accepts the risk with the following statement:  We know that the heap structure has still some drawbacks (even if it\u2019s better than the double linked list implemented on the compound contracts) and we acknowledge the manipulation of the heap. The spam attack is likely to be costly to conduct, moreover, if users come after with greater amounts the dust accounts will be pushed outside the heap.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.2   Interfaces Not Implemented / Available",
        "body": "  Morpho  does  not  extend  the  IMorpho  interface.  This  can  lead  to  errors  during  development  and integration  by  third  parties  as  the  interface  might  not  match  up  with  the  implementations.  Indeed,  the IMorpho interface lacks some public functions like setInterestRates or incentivesVault.  Risk accepted:  Morpho Labs accepts the risk and tries to maintain correct interfaces.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.3   Ambiguous Naming",
        "body": "  The  function  MorphoGovernance.setInterestRates  is  a  setter  for  the  InterestRateManager address, contrary to the function name which implies it sets interest rate values.  Code partially corrected:  MorphoGovernance.setInterestRates  to MorphoGovernance.setInterestRateManager  but  still  emits  an  event  InterestRatesSet  with ambiguous naming.  renamed   been   has   Morpho Labs - Morpho (Aave v3) -   12  CorrectnessMediumVersion1RiskAcceptedDesignLowVersion1CodePartiallyCorrected                \f5.4   Gas Inefficiencies  Gas efficiency can be improved in several places:   The  underlying   (e.g. EntryPositionsManager.supplyLogic).  The  addresses  could  be  cached  in  the  contract's storage instead to avoid unnecessary external calls.  token  of  AAVE's  aTokens   in  some   functions   fetched   is    Redundant storage reads are performed in some functions. The values could be cached in the stack  or in memory:   delta.p2pBorrowDelta   is   read   multiple   times   in  EntryPositionsManager.supplyLogic.   userMarkets[_user]   is   read   in   every   iteration   of   functions   that   call  MorphoUtils._isSupplyingOrBorrowing.   Many more examples can be found.   Redundant storage writes are performed in some functions. The values could be updated in a stack  or memory variable and written to storage at the end.   ExitPositionsManager._safeRepayLogic  updates  delta.p2pBorrowAmount  up  to  3  times.   ExitPositionsManager._safeRepayLogic  updates  delta.p2pSupplyAmount  up  to  2  times.   Redundant external calls are performed in some functions. The values could be cached in the stack  or memory and passed to other called functions:   IAToken.UNDERLYING_ASSET_ADDRESS   is   called   in  EntryPositionsManager.borrowLogic and in the sub-call to _borrowAllowed.   Calls  to  pool.getConfiguration  in  ExitPositionsManager.liquidateLogic  are  already performed by the sub-call to _liquidationAllowed.   MorphoGovernance.createMarket   calls   pool.getConfiguration   and   then  pool.getReserveData which also contains the configuration.  MorphoGovernance.createMarket,   from In  pool.getReserveNormalizedIncome  and pool.getReserveNormalizedVariableDebt could be computed from the already fetched reserve data.  retrieved   values   the    Rounding  errors  can  cause  matching  of  dust.  This  could  be  avoided  by  using  fractions  to  store principal  values:  Instead  of  dividing  token  amounts  by  an  index  and  later  multiplying  again  by  an index  (division  before  multiplication),  principal  values  could  be  stored  as  (uint128,  uint128) tuples  of  the  base  value  and  the  index  at  that  time.  This  change  requires  careful  handling  of uint128 casts though.   Some  checks  can  be  performed  earlier  in  the  code,  saving  callers  some  gas  on  reverting  transactions:   _borrowAllowed in EntryPositionsManager.borrowLogic.   Maximum number of markets check in MorphoGovernance.createMarket.   Unnecessary computations:   ExitPositionsManager.withdrawLogic does not have to check if the user is supplying.  Instead, it could revert on toWithdraw == 0.  Morpho Labs - Morpho (Aave v3) -   13  DesignLowVersion1CodePartiallyCorrected         \f ExitPositionsManager._safeWithdrawLogic potentially calls _updateSupplierInDS  2 times with no overlap.   Changes in the Heap data structures that result in one account being removed and another account  being updated could be performed with a replace action instead of pop + push.   Tighter packing of storage variables is possible (careful casting is necessary though).   p2pSupplyIndex  and  p2pBorrowIndex  could  be  packed  as  uint128  into  a  single  struct,  since most of the time, both values are read from the storage together.   The fields of the structs SupplyBalance and BorrowBalance could be reduced to uint128.   Many  variables  in  MorphoStorage  (e.g.  entryPositionsManager)  could  be  defined  as immutable. Since the Morpho contract is Upgradeable, the values can be changed by updating the proxy implementation.  In  ExitPositionsManager._getUserHealthFactor  functions  with  similar use-case), each asset price is individually fetched with oracle.getAssetPrice. Since the Aave oracle exposes a function to fetch multiple asset prices at once, some external calls can be saved by using oracle.getAssetsPrices.  (and  other   Code partially corrected:   Corrected: Underlying token addresses are now saved in the market storage variable.   Partially  corrected:  Redundant  storage  reads  have  been  improved  on  some  occasions  but  still  happen in various places.   Not corrected: The mentioned examples have not been updated to reduce storage writes.   Not corrected: The first example is obsolete because of another change, the other examples have  not been addressed.   Not corrected: The suggested change has not been implemented.   Partially  corrected:  createMarket  now  checks  for  the  maximum  number  of  markets  in  the  beginning of the function.   Corrected: The mentioned redundant computations have been removed.   Not corrected: pop + push is still used.   Not corrected: Variables are not packed more tightly.   Not corrected: No variables have been changed to immutable.   Not corrected: oracle.getAssetPrices is not used.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.5   Missing Sanity Checks",
        "body": "   Morpho.createMarket does not check if the _underlyingTokenAddress is the 0-address.   Multiple Governance setters do not check if address parameters are the 0-address.   The  initializer  of  MorphoGovernance  does  not  check  if  maxSortedUsers  is  zero.  However,  the  check is applied in setMaxSortedUsers.   The ExitPositionsManager.liquidateLogic can be called with an _amount of 0, while this  is not possible in other entry points.  Morpho Labs - Morpho (Aave v3) -   14  DesignLowVersion1CodePartiallyCorrected         \fCode partially corrected:   Corrected: Morpho.createMarket now checks if _underlyingToken is the 0-address.   Corrected: Setters now check for the 0-address except if the respective field can be intentionally set  to the 0-address.   Corrected: The MorphoGovernance initializer now checks if maxSortedUsers is zero.   Not corrected: ExitPositionsManager.liquidateLogic can still be called with an _amount  of 0.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.6   Rewards Can Be Withdrawn by Admins",
        "body": "  Morpho.claimRewards  transfers  accrued  rewards  of  Morpho  (Aave  v3)'s  whole  position  from  Aave when a user claims their share of the rewards. This means that some tokens may now be owned by the Morpho contract, which can later be claimed by other users.  If one of the reward tokens is however an active market on Morpho (Aave v3), the tokens are claimable by  the  contract  admin.  In  this  case,  both  fees  and  user  rewards  are  mixed  together  and  the  contract admin could accidentally mistake all of the tokens for fees and withdraw them.  This would result in rewards not being claimable by all users that are entitled to them.  Risk accepted:  Morpho Labs accepts the risk stating that the admin (or DAO) is not advised to withdraw fees when there is a running rewards program where the reward token is equal to one of the market tokens.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.7   Variable Shadowing",
        "body": "  In  InterestRateManager.updateIndexes  and  MorphoGovernance.createMarket,  the state variable poolIndexes is shadowed by a local variable.  MorphoUtils.isMarketCreatedAndNotPaused  and In  isMarketCreatedAndNotPausedNorPartiallyPaused,  the  state  variable  marketStatus  is shadowed by a local variable.  Risk accepted:  Morpho Labs accepts the risk. Furthermore, additional storage variables are shadowed in some functions now.  Morpho Labs - Morpho (Aave v3) -   15  DesignLowVersion1RiskAcceptedDesignLowVersion1RiskAccepted                    \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  0  0  1  14  -Severity Findings  -Severity Findings  -Severity Findings   Unadapted amountToLiquidate   -Severity Findings   Free Borrowing of Small Amounts Possible    Function Can Be Restricted to Pure   Incorrect and Missing Specs    Limited Liquidation Amount    MorphoToken Not Safely Transferred    P2pBorrowDelta Always Zero    Potentially Different RewardsController Address    Redundant Code    Similar Code Abstraction    Unused Imports / Errors    Use of Deprecated Function    Withdrawal Denial of Service    Withdrawals Do Not Check Oracle Health    Wrong Event Data   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   Unadapted amountToLiquidate",
        "body": "  In liquidateLogic, amountToLiquidate is computed before amountToSeize is capped. However, amountToLiquidate is not adapted to the capped amountToSeize, which may cause the liquidator to repay more than the value of the collateral they obtain.    If  amountToSeize  exceeds  the  amount  of  the  liquidated  user's  collateral  balance  of  the  requested token, amountToLiquidate is adjusted as follows:  Morpho Labs - Morpho (Aave v3) -   16  CriticalHighMediumCodeCorrectedLowCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedDesignMediumVersion1CodeCorrected         \famountToLiquidate = ((collateralBalance * collateralPrice * vars.borrowedTokenUnit) /             (borrowedTokenPrice * vars.collateralTokenUnit))         .percentDiv(vars.liquidationBonus);  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.2   Free Borrowing of Small Amounts Possible",
        "body": "  Certain  circumstances  allow  for  the  borrowing  of  very  small  amounts  of  tokens  without  supplying collateral beforehand:  EntryPositionsManager._borrowAllowed  computes  the  values  of  the  supplied  and  borrowed tokens  in  a  base  currency  and  checks  whether  an  additional  borrowed  amount  would  result  in  the account being underwater.  For an account with 0 supplied and borrowed balances, the following computation determines if a borrow is allowed:  liquidityData.debtValue +=     (_borrowedAmount * assetData.underlyingPrice) /     assetData.tokenUnit;  Depending  on  the  price  oracle,  a  small _borrowedAmount  might  result  in  integer  division  that  rounds  to  0.  This  would  satisfy  the  final  check and allow the borrowing of the given amount:  the  decimals  of   the  decimals  of   token  and   the   liquidityData.debtValue <= liquidityData.maxLoanToValue  Morpho  (Aave  v3)  uses  the  oracles  of  the  underlying  AAVE  pool,  which  in  turn  uses  Chainlink  price feeds.  On  ETH  Mainnet,  AAVE  uses  Chainlink  price  feeds  in  ETH  base  currency,  which  have  18 decimals (this is true for AAVE v2. AAVE v3 is not yet live on Mainnet at the time of this writing). On other chains (e.g. Optimism), AAVE uses feeds with USD base currency, which only have 8 decimals. In this case, many tokens become susceptible to this problem.  Since the claimable amounts are significantly lower than the amount of gas that has to be paid, the bug is of very low severity.    The division by tokenUnit is now performed using the function Math.divUp. This function adds 1 wei to  the  debt  if  (_borrowedAmount  *  underlyingPrice)  %  tokenUnit  !=  0.  Therefore, borrowing small amounts of tokens without sufficient collateral is not possible anymore.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Function Can Be Restricted to Pure",
        "body": "  The function RewardsManager._getRewards can be restricted to pure as it does not read from the storage.    Morpho Labs - Morpho (Aave v3) -   17  CorrectnessLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                \f_getRewards is now marked as pure.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Incorrect and Missing Specs",
        "body": "  In MorphoGovernance, doc comments wrongly specify a _poolTokenAddress parameter for the MarketCreated event.   Function comments in MatchingEngine.sol should mention Aave instead of Compound.   All fields of struct Types.Delta are expressed in underlying decimals instead of in WAD as claimed  in the specs.   Some parameters are missing in the specs of RewardsManager._updateRewardData.     Corrected: The MarketCreated event is now correctly documented.   Corrected: The correct protocol name has now been added to all comments in MatchingEngine.   Corrected: The correct decimal types are now documented for all Types.Delta fields.   Corrected: RewardsManager._updateRewardData parameters are now correctly documented.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Limited Liquidation Amount",
        "body": "  Liquidations  in  Morpho  (Aave  v3)  are  only  allowed  up  to  a  maximum  of  50%  of  the  user's  borrowed assets.  This  is  true  even  when  the  health  factor  of  the  user  is  below  95%.  This  is  contrary  to  the implementation  of  the  underlying  Aave  pool,  which  allows  for  a  liquidation  of  the  whole  user  position when the user's health factor drops below 95%.  This  behavior  can  increase  the  risk  of  Morpho's  position  on  Aave  becoming  liquidatable  (for  example because liquidation bots on Morpho are not working efficiently).    User  positions  with  a  health  ExitPositionsManager._liquidationAllowed returns the respective liquidation close factor.  factor  below  95%  can  now  be   liquidated  completely.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   MorphoToken Not Safely Transferred",
        "body": "  IncentivesVault.tradeRewardTokensForMorphoTokens  transfers  MORPHO  tokens  without checking a possible return. It is advised to use SafeTransferLib.safeTransfer in this case.  This might not be necessary depending on the implementation of the MORPHO token. At the time of this writing, no such contract is known to us. Therefore, we are unable to verify if the use of transfer is safe in this case.  Morpho Labs - Morpho (Aave v3) -   18  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                         \f  tradeRewardTokensForMorphoTokens now uses safeTransfer to transfer MORPHO tokens.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   P2pBorrowDelta Always Zero",
        "body": "  When  repaying  the  fee  in  ExitPositionsManager._safeRepayLogic,  delta.p2pBorrowDelta has already been reduced to 0 at this point and could be safely removed from the equation.    _safeRepayLogic does not take delta.p2pBorrowDelta into account anymore.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   Potentially Different RewardsController",
        "body": " Address  The Morpho and RewardsManager contracts may have different RewardsController addresses as there is no synchronization between them at initialization.    RewardsManager does not store the RewardsController address anymore. Instead, the address is passed to its functions as an argument.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   Redundant Code",
        "body": "  In EntryPositionManager the second if check is redundant as shown below.  if (toWithdraw > 0) {     uint256 toAddInP2P = toWithdraw.rayDiv(p2pBorrowIndex[_poolTokenAddress]); // In peer-to-peer unit.      deltas[_poolTokenAddress].p2pBorrowAmount += toAddInP2P;     borrowBalanceInOf[_poolTokenAddress][msg.sender].inP2P += toAddInP2P;     emit P2PAmountsUpdated(_poolTokenAddress, delta.p2pSupplyAmount, delta.p2pBorrowAmount);      if (toWithdraw > 0) _withdrawFromPool(underlyingToken, _poolTokenAddress, toWithdraw); // Reverts on error. }  In  EntryPositionManager.sol,  the  function  _borrowAllowed  does  not  need  to  check  if _amount == 0, because this is already checked at the beginning of borrowLogic.  In  liquidateLogic,  the  check  _isBorrowingAny(_borrower)  is  redundant,  because  it  is already  by _isBorrowing(_borrower, _poolTokenBorrowedAddress).  beginning   checked   the   at   Morpho Labs - Morpho (Aave v3) -   19  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                           \f  The redundant code parts have been removed / are not relevant anymore.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   Similar Code Abstraction",
        "body": "  functions   The  and EntryPositionsManager._borrowAllowed  share  a  similar  code  base  that  should  be  abstracted away to avoid maintenance problems.  ExitPositionsManager._getUserHealthFactor     common   The  logic  EntryPositionsManager._borrowAllowed  MorphoUtils._liquidityData.  of   ExitPositionsManager._getUserHealthFactor   has   been   abstracted   into   the   and function  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.11   Unused Imports / Errors",
        "body": "  MorphoGovernance defines the AmountIsZero error, but it is never used in the inheritance hierarchy of the contract.    The AmountIsZero error has been removed from MorphoGovernance.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.12   Use of Deprecated Function",
        "body": "  PositionsManagerUtils.supplyToPool calls the pool.deposit function which is deprecated in Aave.    supplyToPool now calls pool.supply on Aave instead.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.13   Withdrawal Denial of Service",
        "body": "  ExitPositionsManager.withdrawLogic  calls  _getUserHealthFactor  if  the  user  is  borrowing any  tokens.  If  the  user's  borrow  balance  is  small  and  if  the  called  Aave  oracle  returns  a  number  with  Morpho Labs - Morpho (Aave v3) -   20  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                                \flower  decimals  than  the  token's,  then  _getUserHealthFactor  will  revert  on  division  by  zero, preventing any withdrawals by the user.  This issue is related to Free borrowing of small amounts possible.    The division by tokenUnit is now performed using the function Math.divUp. This function adds 1 wei to  the  debt  if  (_borrowedAmount  *  underlyingPrice)  %  tokenUnit  !=  0.  Therefore,  a division by zero even with small debts is not possible anymore.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.14   Withdrawals Do Not Check Oracle Health",
        "body": "  On  withdrawals,  Morpho  the PriceOracleSentinel of AAVE. While AAVE does this the same way, there are still risks associated. Consider the following example:  (Aave  v3)  does  not  check   for  oracle  health   through    A tokens and B tokens are both worth exactly 1 USD.   A user supplies 500 A tokens and borrows 200 B tokens.   The user can withdraw up to 200 A tokens and still maintain a good health factor.   Now  the  price  of  A  tokens  rapidly  changes  to  0.2  USD,  but  the  price  oracle  for  A  tokens  has  not  updated for a few days and still shows 1 USD / A token.   The  user  is  now  still  able  to  withdraw  200  A  tokens  while  in  reality,  his  position  is  already  under  water.  As the recent debacle with Chainlink price feeds of LUNA has shown, oracles that are not updating prices in a timely manner can become very problematic for lending protocols. It is therefore advised to check the health of such oracles.  Unfortunately,  at  the  time  of  this  writing,  AAVE  has  not  deployed  a  PriceOracleSentinel  so  the problem persists also for liquidations and borrowing until AAVE deploys these mechanisms.    ExitPositionsManager._withdrawAllowed  now  checks  priceOracleSentinel.isBorrowAllowed().  the  oracle  health  by  calling  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.15   Wrong Event Data",
        "body": "  The following events contain wrong data:   ExitPositionsManager._safeWithdrawLogic  emits  the  event  P2PBorrowDeltaUpdated  with delta.p2pBorrowAmount instead of delta.p2pBorrowDelta.   ExitPositionsManager._safeRepayLogic  emits  the  event  P2PSupplyDeltaUpdated  with  delta.p2pBorrowDelta instead of delta.p2pSupplyDelta.  Morpho Labs - Morpho (Aave v3) -   21  DesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                \f  The mentioned events are now emitted using the correct parameters.  Morpho Labs - Morpho (Aave v3) -   22  \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Accidental Ownership Transfers",
        "body": "  Morpho  (Aave  v3)  contracts  use  OpenZeppelin's  Ownable  contract  to  store  ownership.  Ownable employs  a  single-step  ownership  transfer.  Accidental  transfers  to  the  wrong  address  will  lock  out  the owner  indefinitely.  For  this  reason,  special  care  has  to  be  taken  when  updating  the  ownership  of  the contracts.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.2   Delta Reduced When P2P Is Disabled",
        "body": "  If  p2pDisabled  is  set  to  true,  the  peer-to-peer  delta  is  reduced  instead  of  borrowers  /  suppliers unmatched.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.3   IncentivesVault Security Relies on Oracle",
        "body": " Implementation  The  Security  of  IncentivesVault.tradeRewardTokensForMorphoTokens  the implementation  of  the  oracle  that  is  set  to  calculate  the  value  of  the  given  rewards.  Since  there  is  no implementation available at the time of this writing, we cannot attest if the use of this function is secure.  relies  on   Morpho Labs aims to implement a TWAP oracle based on Uniswap v3 in the future.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.4   Lack of Balance Functions",
        "body": "  The Morpho contract does not expose view functions for user balances.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.5   Liquidation Risk on Aave",
        "body": "  If Morpho's position on Aave is liquidated, the unmatched accounting of Morpho and Aave would break Morpho's  availability  and  possibly  lock  users'  funds.  Besides,  fully  pausing  Morpho  would  increase  the liquidation  risk  on  Aave.  Efficient  arbitrage  bots  are  required  to  run  on  Morpho  so  that  the  underlying position on Aave does not become liquidatable.  Morpho Labs - Morpho (Aave v3) -   23  NoteVersion1NoteVersion1NoteVersion1NoteVersion1NoteVersion1                    \f7.6   Liquidations May Affect Rates of P2P Users  ExitPositionsManager.liquidateLogic calls repayLogic and withdrawLogic with 0 gas for matching. This can lead to worse rates for P2P users as supply / borrow delta can be increased by these operations.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.7   No Delay Mechanism for Parameter Updates",
        "body": "  There  is  no  delay  mechanism  for  the  updates  of  parameters  to  take  into  effect.  Users  who  are  not satisfied with the upcoming updates would not have time to leave the market.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.8   Potentially Exceeding maxGasForMatching",
        "body": "  As  shown  below,  the  matching  functions  potentially  use  slightly  more  gas  than  the  users'  given _maxGasForMatching.  while (         remainingToMatch > 0 &&         (firstPoolSupplier = suppliersOnPool[_poolTokenAddress].getHead()) != address(0) ) {     unchecked {         if (gasLeftAtTheBeginning - gasleft() >= _maxGasForMatching) break;     }     ... }  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.9   Unsupported Tokens",
        "body": "  The following tokens can not be used in Morpho Markets without repercussions:   Aave siloed assets.   Aave isolated assets.   Tokens  with  high  decimals   (e.g.  27)  because   the  amountToSeize  calculation   in  EntryPositionsManager.liquidateLogic might overflow on realistic token amount values.   Tokens that charge a transfer fee (e.g. STA, PAXG).  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.10   Year 2106 Problem for Uint32 Timestamps",
        "body": "  Timestamps are written to storage which could impose problems on the storage layout in the year 2106.  Morpho Labs - Morpho (Aave v3) -   24  NoteVersion1NoteVersion1NoteVersion1NoteVersion1NoteVersion1                    \f7.11   safeTransferFrom Does Not Revert on Calls to an EOA  Morpho (Aave v3) uses Rari Capital's SafeTransferLib to support tokens that revert on transfers as well as tokens that return a boolean value. The functions, especially safeTransferFrom, however do not revert if the called token is not a contract. In this case, Morpho (Aave v3) contracts could be tricked into thinking that a token transfer from a user was successful when in fact nothing happened.  As of now, Morpho (Aave v3) is not affected by this behavior since all token addresses are directly taken from Aave which correctly checks for contracts in its safeTransferFrom function.  Future changes of the code should take this into account.  Morpho Labs - Morpho (Aave v3) -   25  NoteVersion1  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "5.1   Tokens EIP-721 Typehash",
        "body": "  The EIP-712 defines set of rules, how the solidity structs should be hashed.  Current LibERC721LazyMint and LibERC1155LazyMint contracts have few violations of this standart:   Mint1155Data struct has uri field, but tokenURI is used in MINT_AND_TRANSFER_TYPEHASH  In  Mint1155Data  MINT_AND_TRANSFER_TYPEHASH, the supply field follows the tokenId field.  supply   follows   struct,   field   the   the   uri   field.   In   Mint721Data struct has uri field, but tokenURI is used in MINT_AND_TRANSFER_TYPEHASH  According to EIP-712, such mismatches are not compatible with the standard.  Code partially corrected:  Field uri was renamed to tokenURI in both contracts. Currently, these contracts are already deployed and changing the supply and tokenId order cannot be fixed.  Rarible Inc. - Staking and Tokens -   8  DesignCorrectnessCriticalHighMediumLowCodePartiallyCorrectedCorrectnessLowVersion1CodePartiallyCorrected             \f6   Resolved Findings  Here, we list findings that have been resolved during the course of the engagement. Their categories are explained in the Findings section.  Below we provide a numerical overview of the identified findings, split up by their severity.  0  0  2  13  -Severity Findings  -Severity Findings  -Severity Findings   ERC721 Use of Unsafe Methods    Staking Formula Differs From Specificaiton   -Severity Findings   Mismatch in Mint Data Specification    Code Is Not Compilable   Initialization of Staking Contracts Not According to OZ Guidelines   Initializer Not Using Unchained Initializer of Ancestors    Missing updateAccount Function in ERC1155Lazy    Solidity Compiler Versions    Staking Coefficient Can Make Stake Line Longer    Staking Contracts Are Missing __gap Field    Staking Events Data    Staking Exposing Getters    Staking Is Possible When Migrating    Staking Restake Can Cut the Corner    Staking Slope Period Definition   ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.1   ERC721 Use of Unsafe Methods",
        "body": "  The ERC721 standard focuses on ensuring that token transfers do not lock / loose tokens. That is why the  use  of  \"safe\"  functions  such  as  safeTransferFrom  was  introduced.  This  applies  not  only  to transfers,  but  to  minting  as  well.  However,  the  implementation  of  mintAndTransfer  in  the  contract ERC721Lazy does not use the \"safe\" _safeMint but the _mint function, whose use is discouraged.    Function mintAndTransfer now uses _safeMint function.  Rarible Inc. - Staking and Tokens -   9  CriticalHighMediumCodeCorrectedSpeci\ufb01cationChangedLowSpeci\ufb01cationChangedSpeci\ufb01cationChangedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedCodeCorrectedDesignMediumVersion1CodeCorrected            \f6.2   Staking Formula Differs From Specificaiton  The specs define the formula as:  stake = k * tokens. K = (0.07 + 0.93 * (cliffPeriod / 104) ^ 2 + 0.5 * (0.07 + 0.93 * (slopePeriod / 104) ^ 2)).  This formula differs from solidity implementation, mostly due to use of following constants:  uint256 constant ST_FORMULA_MULTIPLIER = 1081000;       //stFormula multiplier = TWO_YEAR_WEEKS^2 * 100 uint256 constant ST_FORMULA_COMPENSATE = 1135050;       //stFormula compensate = (0.7+0.35) * ST_FORMULA_MULTIPLIER uint256 constant ST_FORMULA_SLOPE_MULTIPLIER = 465;     //stFormula slope multiplier = 0.93 * 0.5 * 100 uint256 constant ST_FORMULA_CLIFF_MULTIPLIER = 930;     //stFormula cliff multiplier = 0.93 * 100   ST_FORMULA_MULTIPLIER should be 1086000 to comply with specs.   ST_FORMULA_COMPENSATE should be 1135680 to comply with specs.   ST_FORMULA_SLOPE_MULTIPLIER should be 46.5 to comply with specs.   ST_FORMULA_CLIFF_MULTIPLIER should be 93 to comply with specs.  Specification corrected:  Specificaion  of  formula  was  changed  in  commit  6167554ff40b7b7f9f6d1ce808fd7d62d04ab3f6 to:  stake = K * tokens / 1000; K = ( 11356800 + 9300 * (cliffPeriod)^2 + 4650 * (slopePeriod)^2) / 10816;  Code  was  adjusted  in  commit  888761566077d51937cf7676417ebe0839f2bdfe  implemented according to this specificaion.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.3   Mismatch in Mint Data Specification",
        "body": "  Mint721Data   The  and LibERC1155LazyMint.sol  were  updated.  Yet,  the  documentation  in  tokens/readme.md  was  not updated. The documentation specifies that the mint data structs have element uri, while in code uri was changed to tokenURI.  LibERC721LazyMint.sol   Mint1155Data   structs   and   in   Moreover,  both  structs  have  an  element  royalties,  tokens/readme.md. That is a mismatch in the specification.  that  are  named  as  fees   in   the  Specification corrected:  The names were fixed in version 3. Names in specs match the ones in code now.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.4   Code Is Not Compilable",
        "body": "  Rarible Inc. - Staking and Tokens -   10  DesignMediumVersion1Speci\ufb01cationChangedCorrectnessLowVersion2Speci\ufb01cationChangedDesignLowVersion1Speci\ufb01cationChanged                      \fStaking contract and token contracts are not compilable due to imports of @rarible libraries. Node pulls outdated libraries that are not compatible with the new code. If imports by path are used, the code would have been compilable. Not using direct imports by path can lead to compilations with outdated libraries. Taking into account the monorepo structure of rarible github, it is safer to use direct path imports.  Specification corrected:  The compilation instructions were added to the readme.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.5   Initialization of Staking Contracts Not",
        "body": " According to OZ Guidelines  The initialization style of the contract is not according to guidelines from OpenZeppelin libary. In contract StakingBase a __StakingBase_init function is defined as public function. Usually such functions are defined as private and only most derived contract defines  public function initialize where the private chained/unchained init function are called.  Moreover, the initializer should call all unchained initializers of all ancestors of the contract. Currently the __StakingBase_init calls __Ownable_init_unchained but not __Context_init_unchained. The latter has no effect in current version of the OZ library, but that can change in future.    __StakingBase_init  was  renamed  to  __StakingBase_init_unchained.  It  does  not  call  any initializer  of  ancestors  anymore  and  was  made  internal.  The  initialization  was  moved  to  the  Staking contract where __Staking_init calls all unchained initializers of parent contracts. The guidelines are now followed.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.6   Initializer Not Using Unchained Initializer of",
        "body": " Ancestors  The  contract  Mint721Validator  implements  __Mint721Validator_init_unchained  function, that  calls  __EIP712_init  from  OpenZeppelin's  EIP712Upgradeable  contract.  The  OpenZeppelin docs suggests using unchained initializers of parent contracts to prevent initializing a contract twice.    __Mint721Validator_init_unchained calls __EIP712_init_unchained now.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.7   Missing updateAccount Function in",
        "body": " ERC1155Lazy  Rarible Inc. - Staking and Tokens -   11  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \fThe contracts should support Rarible on-chain royalties. As in ERC721Lazy there should be a method calling  _updateAccount  from  AbstractRoyalties.  That  enables  a  registered  royalty  account  to change the address for the royalties for some token ID. Such function is missing in the ERC1155Lazy.    The updateAccount function was added. It allows to perform the previously described actions.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.8   Solidity Compiler Versions",
        "body": "  The defined solidity versions are too different across staking contracts:  pragma solidity >=0.6.2 <0.8.0; pragma solidity ^0.7.0;  Too wide version range >=0.6.2 <0.8.0 can cause compilation with not the latest compiler version, where bugs can present.    The Solidity compiler version was set to 0.7.6 for all contracts in scope.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.9   Staking Coefficient Can Make Stake Line",
        "body": " Longer  When the staking bias and slope are computed, the computation is done with a certain precision. If bias has  a  significant  difference  compared  to  slope,  the  resulting  params  of  stake  line  can  make  it  longer compared to locked line. For example, bias of 5200, with slope of 100 and cliff of 52 weeks, the stake line will have bias of 23592 and slope of 453. Right after 104 weeks, the lock line will be depleted, and all funds will be withdrawable. The stake line after the same period will have remaining 36 (23592 mod 453) stake  that  will  unlock  only  on  53rd  week.  This  behavior  is  not  documented  in  specs  and  violates  the statement that stake behaves like locked tokens and is just multiplied by value.    Calculations were changed for the staking bias and slope values. The slopePeriod is now defined as ceil(amount / slopePeriod). The staking coefficient affects only staking bias. The staking slope value  is  computed  as  ceil(staking  amount  /  slopePeriod).  As  a  result  of  this  changes,  the \"remained\" will be counted as a last period of slopePeriod. The stake line and balance line will deplete at the same time.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.10   Staking Contracts Are Missing __gap Field",
        "body": "  Rarible Inc. - Staking and Tokens -   12  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                        \fAll staking contracts, Staking, StakingRestake and StakingBase, do not have the recommended __gap field for upgradeable contracts. Without this field adding new state variables in the future can be problematic.    __gap was added to the above mentioned contracts.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.11   Staking Events Data",
        "body": "  Some events emitted in staking contract do not provide enough information to easily reconstruct the state of contract.  In function restake the emitted event Restake does not emit new value of counter field. Also the account that performs restake is not emitted. The StakeCreate emits both those fields.   Event Delegate does not emit account that performs redelegation.   No events emitted on stop function call. That is important function that greatly impacts the contract  functionality.   No events emitted on startMigration function call. That is important function that greatly impacts  the contract functionality.    The events are now emitted for all actions, described above.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.12   Staking Exposing Getters",
        "body": "  In current implementation of the staking contract some fields and data is hard to query due to missing getters. The list of information that can improve user experience and minimize human errors:   Output of getStake function. Currently it is internal pure function.   Remaining locked amount   Amount available for withdrawal   For a given Line id, the owner and delegate addresses.   Field stopped of the staking contract   Getting \"current week\" of the contract. E.g. roundTimestamp function output.    Following changes were done, to fix the issues from the above list:   Function getStake is declared as public.   Function locked was added.   Function getAvailableForWithdraw was added.  Rarible Inc. - Staking and Tokens -   13  DesignLowVersion1CodeCorrectedDesignLowVersion1CodeCorrected                 \f Function getAccountAndDelegate was added.   Field stopped was made public.   Function getWeek was added.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.13   Staking Is Possible When Migrating",
        "body": "  The migration is irreversible process that is needed to move stakes to a new contract. But such actions like  stake,  delegateTo  and  restake  are  still  allowed  during  this  process.  Users  can  by  mistake performed  such  actions  and  will  need  to  submit  extra  transaction  to  migrate  their  actions  to  a  new contract.    Function mentioned above now use notMigrating operator that restricts their usage when the contract is migrating.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.14   Staking Restake Can Cut the Corner",
        "body": "  The restake function checks that the new amount of locked tokens is not lower than the old amount. Also there is a check that the end time of the new line should not be earlier that the old end time. These constraints  allow  the  user  to  restake  with  a  long  slopePeriod,  but  without  a  cliffPeriod,  which  leads  to stake being unlocked earlier than in the original line. Geometrically, this amounts to \"cutting the corner\" of the brokenline.    The restake function now performs checks, that the new line is greater (not strictly) then the old line. Geometrically, this can be interpreted as new line to be always \"above or equal\" the old stake line. This is done by a call to verification internal function.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "6.15   Staking Slope Period Definition",
        "body": "  The  current  slope  period  is  computed  as  amount  //  slope,  that  is  using  an  integer  division  that rounds down. The effect of this is that, in the week after the slope period ends, the amount % slope tokens will still be staked. This remainder does not contribute to the staking coefficient K. The remainder cannot  be  withdrawn,  but  can  be  delegated  to  and  restaked.  Also  this  extra  period  does  not  counted towards the 2 year limit for the staking period. The current version of the specification does not describe this behavior.    Rarible Inc. - Staking and Tokens -   14  DesignLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrectedCorrectnessLowVersion1CodeCorrected                        \fThe  new  slope  period  is  computed  as  ceil(amount  //  slope).  Now  the  \"remainder\"  week  is accounted for staking coefficient and 2 year limit.  Rarible Inc. - Staking and Tokens -   15  \f7   Notes  We  leverage  this  section  to  highlight  further  findings  that  are  not  necessarily  issues.  The  mentioned topics  serve  to  clarify  or  support  the  report,  but  do  not  require  an  immediate  modification  inside  the project. Instead, they should raise awareness in order to improve the overall understanding.  ",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    },
    {
        "title": "7.1   Missing Documentation for Public Functions",
        "body": "  Some functions and state variables in StakingBase.sol are now public. However, functions and getters are not documented. Following functions and variables are lacking documentation in the readme:   getStake   counter   stopped   migrateTo   totalSupplyLine  Rarible Inc. - Staking and Tokens -   16  NoteVersion1  \f",
        "labels": [
            "ChainSecurity"
        ],
        "html_url": "TODO"
    }
]