[{"title": "LienToken.transferFrom does not update a public vault's bookkeeping parameters when a lien is transferred to it.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "When transferFrom is called, there is not check whether the from or to parameters could be a public vault. Currently, there is no mechanism for public vaults to transfer their liens. But private vault owners who are also owners of the vault's lien tokens, they can call transferFrom and transfer their liens to a public vault. In this case, we would need to make sure to update the bookkeeping for the public vault that the lien was transferred to. On the LienToken side, s.LienMeta[id].payee needs to be set to the address of the public vault. And on the PublicVault side, yIntercept, slope, last, epochData of VaultData need to be updated (this requires knowing the lien's end). However, private vaults do not keep a record of these values, and the corresponding values are only saved in stacks off-chain and validated on-chain using their hash.", "labels": ["Spearbit", "Astaria", "Severity: Critical Risk"]}, {"title": "Anyone can take a valid commitment combined with a self-registered private vault to steal funds from any vault without owning any collateral", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The issue stems from the following check in VaultImplementation._validateCommitment(params, receiver): if ( msg.sender != holder && receiver != holder && receiver != operator && !ROUTER().isValidVault(receiver) // <-- the problematic condition ) { ... In this if block if receiver is a valid vault the body of the if is skipped. A valid vault is one that has been registered in AstariaRouter using newVault or newPublicVault. So for example any supplied private vault as a receiver would be allowed here and the call to _validateCommitment will continue without reverting at least in this if block. If we backtrack function calls to _validateCommitment, we arrive to 3 exposed endpoints:  commitToLiens  buyoutLien  commitToLien A call to commitToLiens will end up having the receiver be the AstariaRouter. A call to buyoutLien will set the receiver as the recipient() for the vault which is either the vault itself for public vaults or the owner for private vaults. So we are only left with commitToLien, where the caller can set the value for the receiver directly. 8 A call to commitToLien will initiate a series of function calls, and so receiver is only supplied to _validateCommit- ment to check whether it is allowed to be used and finally when transferring safeTransfer) wETH. This opens up exploiting scenarios where an attacker: 1. Creates a new private vault by calling newVault, let's call it V . 2. Takes a valid commitment C and combines it with V and supply those to commitToLien. 3. Calls withdraw endpoint of V to withdraw all the funds. For step 2. the attacker can source valid commitments by doing either of the following: 1. Frontrun calls to commitToLiens and take all the commitments C0, (cid:1) (cid:1) (cid:1) , Cn and supply them one by one along with V to commitToLien endpoint of the vault that was specified by each Ci . 2. Frontrun calls to commitToLien endpoints of vaults, take their commitment C and combine it with V to send to commitToLien. 3. Backrun the either scenarios from the above points and create a new commitment with new lien request that tries to max out the potential debt for a collateral while also keeping other inequalities valid (for example, the inequality regarding liquidationInitialAsk).", "labels": ["Spearbit", "Astaria", "Severity: Critical Risk"]}, {"title": "Collateral owner can steal funds by taking liens while asset is listed for sale on Seaport", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "We only allow collateral holders to call listForSaleOnSeaport if they are listing the collateral at a price that is sufficient to pay back all of the liens on their collateral. When a new lien is created, we check that collateralStateHash != bytes32(\"ACTIVE_AUCTION\") to ensure that the collateral is able to accept a new lien. However, calling listForSaleOnSeaport does not set the collateralStateHash, so it doesn't stop us from taking new liens. As a result, a user can deposit collateral and then, in one transaction:  List the asset for sale on Seaport for 1 wei.  Take the maximum possible loans against the asset.  Buy the asset on Seaport for 1 wei. The 1 wei will not be sufficient to pay back the lenders, and the user will be left with the collateral as well as the loans (minus 1 wei).", "labels": ["Spearbit", "Astaria", "Severity: Critical Risk"]}, {"title": "validateStack allows any stack to be used with collateral with no liens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The validateStack modifier is used to confirm that a stack entered by a user matches the stateHash in storage. However, the function reverts under the following conditions: if (stateHash != bytes32(0) && keccak256(abi.encode(stack)) != stateHash) { revert InvalidState(InvalidStates.INVALID_HASH); } The result is that any collateral with stateHash == bytes32(0) (which is all collateral without any liens taken against it yet) will accept any provided stack as valid. This can be used in a number of harmful ways. Examples of vulnerable endpoints are:  createLien: If we create the first lien but pass a stack with other liens, those liens will automatically be included in the stack going forward, which means that the collateral holder will owe money they didn't receive.  makePayment: If we make a payment on behalf of a collateral with no liens, but include a stack with many liens (all owed to me), the result will be that the collateral will be left with the remaining liens continuing to be owed  buyoutLien: Anyone can call buyoutLien(...) and provide parameters that are spoofed but satisfy some constraints so that the call would not revert. This is currently possible due to the issue in this context. As a consequence the caller can  _mint any unminted liens which can DoS the system.  _burn lienIds that they don't have the right to remove.  manipulate any public vault's storage (if it has been set as a payee for a lien) through its handleBuyout- Lien. It seems like this endpoint might have been meant to be a restricted endpoint that only registered vaults can call into. And the caller/user is supposed to only call into here from VaultImplementa- tion.buyoutLien.", "labels": ["Spearbit", "Astaria", "Severity: Critical Risk"]}, {"title": "A borrower can list their collateral on Seaport and receive almost all the listing price without paying back their liens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "When the collateral s.auctionData is not populated and thus, function gets called since stack.length is 0, this loop will not run and no payment is sent to the lending vaults. The rest of the payment is sent to the borrower. And the collateral token and its related data gets burnt/deleted by calling settleAuction. The lien tokens and the vaults remain untouched as though nothing has happened. is listed on SeaPort by the borrower using listForSaleOnSeaport, if that order gets fulfilled/matched and ClearingHouse's fallback So basically a borrower can: 1. Take/borrow liens by offering a collateral. 2. List their collateral on SeaPort through the listForSaleOnSeaport endpoint. 3. Once/if the SeaPort order fulfills/matches, the borrower would be paid the listing price minus the amount sent to the liquidator (address(0) in this case, which should be corrected). 4. Collateral token/data gets burnt/deleted. 5. Lien token data remains and the loans are not paid back to the vaults. And so the borrower could end up with all the loans they have taken plus the listing price from the SeaPort order. Note that when a user lists their own collateral on Seaport, it seems that we intentionally do not kick off the auction process:  Liens are continued.  Collateral state hash is unchanged.  liquidator isn't set.  Vaults aren't updated.  Withdraw proxies aren't set, etc. Related issue 88.", "labels": ["Spearbit", "Astaria", "Severity: Critical Risk"]}, {"title": "Phony signatures can be used to forge any strategy", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "In _validateCommitment(), we check that the merkle root of the strategy has been signed by the strategist or delegate. After the signer is recovered, the following check is performed to validate the signature: recovered != owner() && recovered != s.delegate && recovered != address(0) 11 This check seems to be miswritten, so that any time recovered == address(0), the check passes. When ecrecover is used to check the signed data, it returns address(0) in the situation that a phony signature is submitted. See this example for how this can be done. The result is that any borrower can pass in any merkle root they'd like, sign it in a way that causes address(0) to return from ecrecover, and have their commitment validated.", "labels": ["Spearbit", "Astaria", "Severity: Critical Risk"]}, {"title": "Inequalities involving liquidationInitialAsk and potentialDebt can be broken when buyoutLien is called", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "When we commit to a new lien, the following gets checked to be true for all j 2 0, (cid:1) (cid:1) (cid:1) , n (cid:0) 1: onew + on(cid:0)1 + (cid:1) (cid:1) (cid:1) + oj (cid:20) Lj where: parameter description oi onew n Li L0 k k A0 k _getOwed(newStack[i], newStack[i].point.end) _getOwed(newSlot, newSlot.point.end) stack.length newStack[i].lien.details.liquidationInitialAsk params.encumber.lien.details.liquidationInitialAsk params.position params.encumber.amount 12 so in a stack in general we should have the: But when an old lien is replaced with a new one, we only perform the following checks for L0 k : (cid:1) (cid:1) (cid:1) + oj+1 + oj (cid:20) Lj 0 0 0 k ^ L k (cid:21) A L k > 0 And thus we can introduce:  L0  o0 k (cid:28) Lk or k (cid:29) ok (by pushing the lien duration) which would break the inequality regarding oi s and Li . If the inequality is broken, for example, if we buy out the first lien in the stack, then if the lien expires and goes into a Seaport auction the auction's starting price L0 would not be able to cover all the potential debts even at the beginning of the auction.", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "VaultImplementation.buyoutLien can be DoSed by calls to LienToken.buyoutLien (cid:1) (cid:1) (cid:1) + oj+1 + oj (cid:20) Lj", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Anyone can call into LienToken.buyoutLien and provide params of the type LienActionBuyout: params.incoming is not used, so for example vault signatures or strategy validation is skipped. There are a few checks for params.encumber. Let's define the following variables: parameter value i kj tj ej e0 i lj l 0 i rj r 0 i c params.position params.encumber.stack[j].point.position params.encumber.stack[j].point.last params.encumber.stack[j].point.end tnow + D0 i params.encumber.stack[j].point.lienId i )) where h is the keccak256 of the encoding i , r 0 i , c0 i , S0 i , D0 i , V 0 i , (A0max h(N 0 i , P 0 i , L0 params.encumber.stack[j].lien.details.rate : old rate params.encumber.lien.details.rate : new rate params.encumber.collateralId 13 parameter value cj c0 i Aj A0 i Amax j A0max i R Nj N 0 i Vj V 0 i Sj S0 i Dj D0 i Pj P0 i Lj L0 i Imin Dmin tnow bi o oj n params.encumber.stack[j].lien.collateralId params.encumber.lien.collateralId params.encumber.stack[j].point.amount params.encumber.amount params.encumber.stack[j].lien.details.maxAmount params.encumber.lien.details.maxAmount params.encumber.receiver params.encumber.stack[j].lien.token params.encumber.lien.token params.encumber.stack[j].lien.vault params.encumber.lien.vault params.encumber.stack[j].lien.strategyRoot params.encumber.lien.strategyRoot params.encumber.stack[j].lien.details.duration params.encumber.lien.details.duration params.encumber.stack[j].lien.details.maxPotentialDebt params.encumber.lien.details.maxPotentialDebt params.encumber.stack[j].lien.details.liquidationInitialAsk params.encumber.lien.details.liquidationInitialAsk AstariaRouter.s.minInterestBPS AstariaRouter.s.minDurationIncrease block.timestamp buyout _getOwed(params.encumber.stack[params.position], block.timestamp) _getOwed(params.encumber.stack[j], params.encumber.stack[j].point.end) params.encumber.stack.length O = o0 + o1 + (cid:1) (cid:1) (cid:1) + on(cid:0)1 _getMaxPotentialDebtForCollateral(params.encumber.stack) sj s0 i params.encumber.stack[j] newStack Let's go over the checks and modifications that buyoutLien does: 1. validateStack is called to make sure that the hash of params.encumber.stack matches with s.collateralStateHash value of c. This is not important and can be bypassed by the exploit even after the fix for Issue 106. 2. _createLien is called next which does the following checks: 2.1. c is not up for auction. 2.2. We haven't reached max number of liens, currently set to 5. 2.3. L0 > 0 2.4. If params.encumber.stack is not empty then c0 i , (A0max i , L0 i )) where h is the hashing mechanism of encoding and then taking the keccak256. 2.6 The new stack slot and i = c0 2.5. We _mint a new lien for R with id equal to h(N 0 i and L0 i (cid:21) A0 i , V 0 i , D0 i , S0 i , P 0 i , c0 , r 0 i i 14 the new lien id is returned. 3. isValidRefinance is called which performs the following checks: 3.1. checks c0 i = c0 3.2. checks either or (r 0 i < ri (cid:0) Imin) ^ (e0 i (cid:21) ei ) i i (cid:20) ri ) ^ (e0 (r 0 is in auction by checking s.collateralStateHash's value. i (cid:21) ei + Dmin) 4. check where c0 i 5. check O (cid:20) P0 i . 6. check A0max (cid:21) o. 7. send wETH through TRANSFER_PROXY from msg.sender to payee of li with the amount of bi . 8. if payee of li is a public vault, do some book keeping by calling handleBuyoutLien. 9. call _replaceStackAtPositionWithNewLien to:  9.1. replace si with s0  9.2. _burn li .  9.3. delete s.lienMeta of li . i in params.encumber.stack. So in a nutshell the important checks are:  c, ci are not in auction (not important for the exploit)  c0 i = c0 i and L0  n is less than or equal to max number of allowed liens ( 5 currently) (not important for the exploit)  L0 i (cid:21) A0  O (cid:20) P0 i  A0max i > 0 (cid:21) o i or (r 0 i < ri (cid:0) Imin) ^ (e0 i (cid:21) ei ) i (cid:20) ri ) ^ (e0 (r 0 i (cid:21) ei + Dmin) Exploit An attacker can DoS the VaultImplementation.buyoutLien as follows: 1. A vault decides to buy out a collateral's lien to offer better terms and so signs a commitment and some- one on behalf of the vault calls VaultImplementation.buyoutLien which if executed would call LienTo- ken.buyoutLien with the following parameters: 15 LienActionBuyout({ incoming: incomingTerms, position: position, encumber: ILienToken.LienActionEncumber({ collateralId: collateralId, amount: incomingTerms.lienRequest.amount, receiver: recipient(), lien: ROUTER().validateCommitment({ commitment: incomingTerms, timeToSecondEpochEnd: _timeToSecondEndIfPublic() }), stack: stack }) }) 2. The attacker fronrun the call from step 1. and instead provide the following modified parameters to LienTo- ken.buyoutLien LienActionBuyout({ incoming: incomingTerms, // not important, since it is not used and can be zeroed-out to save tx gas position: position, encumber: ILienToken.LienActionEncumber({ collateralId: collateralId, amount: incomingTerms.lienRequest.amount, receiver: msg.sender, // address of the attacker lien: ILienToken.Lien({ // note that the lien here would have the same fields as the original message by the vault rep. ,! token: address(s.WETH), vault: incomingTerms.lienRequest.strategy.vault, // address of the vault offering a better term strategyRoot: incomingTerms.lienRequest.merkle.root, collateralId: collateralId, details: details // see below }), stack: stack }) }) Where details provided by the attacker can be calculated by using the below snippet: uint8 nlrType = uint8(_sliceUint(commitment.lienRequest.nlrDetails, 0)); (bytes32 leaf, ILienToken.Details memory details) = IStrategyValidator( s.strategyValidators[nlrType] ).validateAndParse( commitment.lienRequest, s.COLLATERAL_TOKEN.ownerOf( commitment.tokenContract.computeId(commitment.tokenId) ), commitment.tokenContract, commitment.tokenId ); The result is that:  The newLienId that was supposed to be _minted for the recipient() of the vault, gets minted for the at- tacker.  The call to VaultImplementation.buyoutLien would fail, since the newLienId is already minted, and so the vault would not be able to receives the interests it had anticipated.  When there is a payment or Seaport auction settlement, the attacker would receive the funds instead. 16  The attacker can intorduces a malicous contract into the protocol ken.ownerOf(newLienId) without needing to register for a vault. that would be LienTo- To execute this attack, the attacker would need to spend the buyout amount of assets. Also the attacker does not necessarily need to front run a transaction to buyout a lien. They can pick their own hand-crafted parameters that would satisfy the conditions in the analysis above to introduce themselves in the protocol.", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "VaultImplementation.buyoutLien does not update the new public vault's parameters and does not transfer assets between the vault and the borrower", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "VaultImplementation.buyoutLien does not update the accounting for the vault (if it's public). The slope, yIntercept, and s.epochData[...].liensOpenForEpoch (for the new lien's end epoch) are not updated. They are updated for the payee of the swapped-out lien if the payee is a public vault by calling handleBuyoutLien. Also, the buyout amount is paid out by the vault itself. The difference between the new lien amount and the buyout amount is not worked out between the msg.sender and the new vault.", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "setPayee doesn't update y intercept or slope, allowing vault owner to steal all funds", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "When setPayee() is called, the payment for the lien is no longer expected to go to the vault. How- ever, this change doesn't impact the vault's y-intercept or slope, which are used to calculate the vault's totalAs- sets(). This can be used maliciously by a vault owner to artificially increase their totalAssets() to any arbitrary amount:  Create a lien from the vault.  SetPayee to a non-vault address.  Buyout the lien from another vault (this will cause the other vault's y-int and slope to increase, but will not impact the y-int and slope of the original vault because it'll fail the check on L165 that payee is a public vault.  Repeat the process again going the other way, and repeat the full cycle until both vault's have desired totalAssets(). For an existing vault, a vault owner can withdraw a small amount of assets each epoch. If, in any epoch, they are one of the only users withdrawing funds, they can perform this attack immediately before the epoch is pro- cessed. The result is that the withdrawal shares will by multiplied by totalAssets() / totalShares() to get the withdrawal rate, which can be made artificially high enough to wipe out the entire vault.", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "settleAuction() doesn't check if the auction was successful", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "settleAuction() is a privileged functionality called by LienToken.payDebtViaClearingHouse(). settleAuction() is intended to be called on a successful auction, but it doesn't verify that that's indeed the case. Anyone can create a fake Seaport order with one of its considerations set as the CollateralToken as described in Issue 93. Another potential issue is if the Seaport orders can be \"Restricted\" in future, then there is a possibility for an authorized entity to force settleAuction on CollateralToken, and when SeaPort tries to call back on the zone to validate it would fail.", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "Incorrect auction end validation in liquidatorNFTClaim()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "liquidatorNFTClaim() does the following check to recognize that Seaport auction has ended: if (block.timestamp < params.endTime) { //auction hasn't ended yet revert InvalidCollateralState(InvalidCollateralStates.AUCTION_ACTIVE); } Here, params is completely controlled by users and hence to bypass this check, the caller can set params.endTime to be less than block.timestamp. Thus, a possible exploit scenario occurs when AstariaRouter.liquidate() is called to list the underlying asset on Seaport which also sets liquidator address. Then, anyone can call liquidatorNFTClaim() to transfer the underlying asset to liquidator by setting params.endTime < block.timestamp.", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "Typed structured data hash used for signing commitments is calculated incorrectly", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Since STRATEGY_TYPEHASH == keccak256(\"StrategyDetails(uint256 nonce,uint256 deadline,bytes32 root)\") The hash calculated in _encodeStrategyData is incorrect according to EIP-712. s.strategistNonce is of type uint32 and the nonce type used in the type hash is uint256. Also the struct name used in the typehash collides with StrategyDetails struct name defined as: 19 struct StrategyDetails { uint8 version; uint256 deadline; address vault; }", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "makePayment doesn't properly update stack, so most payments don't pay off debt", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "As we loop through individual payment in _makePayment, each is called with: (newStack, spent) = _payment( s, stack, uint8(i), totalCapitalAvailable, address(msg.sender) ); This call returns the updated stack as newStack but then uses the function argument stack again in the next iteration of the loop. The newStack value is unused until the final iterate, when it is passed along to _updateCollateralStateHash(). This means that the new state hash will be the original state with only the final loan repaid, even though all other loans have actually had payments made against them.", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "_removeStackPosition() always reverts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "removeStackPosition() always reverts since it calls stack array for an index beyond its length: for (i; i < length; ) { unchecked { newStack[i] = stack[i + 1]; ++i; } } Notice that for i==length-1, stack[length] is called. This reverts since length is the length of stack array. Additionally, the intention is to delete the element from stack at index position and shift left the elements ap- pearing after this index. However, an addition increment to the loop index i results in newStack[position] being empty, and the shift of other elements doesn't happen.", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "Refactor _paymentAH()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "_paymentAH() has several vulnerabilities:  stack is a memory parameter. So all the updates made to stack are not applied back to the corresponding storage variable.  No need to update stack[position] as it's deleted later.  decreaseEpochLienCount() is always passed 0, as stack[position] is already deleted. Also decreaseEp- ochLienCount() expects epoch, but end is passed instead.  This if/else block can be merged. updateAfterLiquidationPayment() expects msg.sender to be LIEN_- TOKEN, so this should work.", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "processEpoch() needs to be called regularly", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "If the processEpoch() endpoint does not get called regularly (especially close to the epoch bound- aries), the updated currentEpoch would lag behind the actual expected value and this will introduce arithmetic errors in formulas regarding epochs and timestamps.", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "Can create lien for collateral while at auction by passing spoofed data", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "In the createLien function, we check that the collateral isn't currently at auction before giving a lien with the following check: if ( s.collateralStateHash[params.collateralId] == bytes32(\"ACTIVE_AUCTION\") ) { revert InvalidState(InvalidStates.COLLATERAL_AUCTION); } However, collateralId is passed in multiple places in the params: params.encumber.lien. both in params directly and in 23 The params.encumber.lien.collateralId is used everywhere else, and is the final value that is used. But the check is performed on params.collateralId. As a result, we can set the following:  params.encumber.lien.collateralId: collateral that is at auction.  params.collateralId: collateral not at auction. This will allow us to pass this validation while using the collateral at auction for the lien.", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "stateHash isn't updated by buyoutLien function", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "We never update the collateral state hash anywhere in the buyoutLien function. As a result, once all checks are passed, payment will be transferred from the buyer to the seller, but the seller will retain ownership of the lien in the system's state.", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "If a collateral's liquidation auction on Seaport ends without a winning bid, the call to liquidatorN- FTClaim does not clear the related data on LienToken's side and also for payees that are public vaults", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "If/when a liquidation auction ends without being fulfilled/matched on Seaport and afterward when the current liquidator calls into liquidatorNFTClaim, the storage data (s.collateralStateHash, s.auctionData, s.lienMeta) on the LienToken side don't get reset/cleared and also the lien token does not get burnt. That means:  s.collateralStateHash[collateralId] stays equal to bytes32(\"ACTIVE_AUCTION\").  s.auctionData[collateralId] will have the past auction data.  s.lienMeta[collateralId].atLiquidation will be true. That means future calls to commitToLiens by holders of the same collateral will revert.", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "ClearingHouse cannot detect if a call from Seaport comes from a genuine listing or auction", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Anyone can create a SeaPort order with one of the considerations' recipients set to a ClearingHouse with a collateralId that is genuinely already set for auction. Once the spoofed order settles, SeaPort calls into this fallback function and causes the genuine Astaria auction to settle. This allows an attacker to set random items on sale on SeaPort with funds directed here (small buying prices) to settle genuine Astaria auctions on the protocol. This causes:  The Astaria auction payees and the liquidator would not receive what they would expect that should come from the auction. And if payee is a public vault it would introduce incorrect parameters into its system.  Lien data (s.lienMeta[lid]) and the lien token get deleted/burnt.  Collateral token and data get burnt/deleted.  When the actual genuine auction settles and calls back s.collateralIdToAuction[collateralId] check. to here, it will revert due to", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "c.lienRequest.strategy.vault is not checked to be a registered vault when commitToLiens is called", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "mentation(c.lienRequest.strategy.vault).commitToLien( ... ) of c.lienRequest.strategy.vault is not checked whether it is a registered vault within the system (by checking s.vaults). The caller can set this value to any address they would desire and potentially perform some unwanted actions. For example, the user could spoof all the values in commitments so that the later dependant contracts' checks are skipped and lastly we end up transferring funds: value after and the s.TRANSFER_PROXY.tokenTransferFrom( address(s.WETH), address(this), // <--- AstariaRouter address(msg.sender), totalBorrowed ); Not that since all checks are skipped, the caller can also indirectly set totalBorrowed to any value they would desire. And so, if AstariaRouter would hold any wETH at any point in time. Anyone can craft a payload to commitToLiens to drain its wETH balance.", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "Anyone can take a loan out on behalf of any collateral holder at any terms", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "In the _validateCommitment() function, the initial checks are intended to ensure that the caller who is requesting the lien is someone who should have access to the collateral that it's being taken out against. The caller also inputs a receiver, who will be receiving the lien. In this validation, this receiver is checked against the collateral holder, and the validation is approved in the case that receiver == holder. However, this does not imply that the collateral holder wants to take this loan. This opens the door to a malicious lender pushing unwanted loans on holders of collateral by calling commitToLien with their collateralId, as well as their address set to the receiver. This will pass the receiver == holder check and execute the loan. In the best case, the borrower discovers this and quickly repays the loan, incurring a fee and small amount of interest. In the worst case, the borrower doesn't know this happens, and their collateral is liquidated.", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "Strategist Interest Rewards will be 10x higher than expected due to incorrect divisor", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "VAULT_FEE is set as an immutable argument in the construction of new vaults, and is intended to be set in basis points. However, when the strategist interest rewards are calculated in _handleStrategistIntere- stReward(), the VAULT_FEE is only divided by 1000. The result is that the fee calculated by the function will be 10x higher than expected, and the strategist will be dramatically overpaid.", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "The lower bound for liquidationInitialAsk for new lines needs to be stricter", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "params.lien.details.liquidationInitialAsk ( Lnew ) is only compared to params.amount ( Anew ) whereas in _appendStack newStack[j].lien.details.liquidationInitialAsk ( Lj ) is compared to poten- tialDebt. potentialDebt is the aggregated sum of all potential owed amount at the end of each position/lien. So in _appendStack we have: onew + on + (cid:1) (cid:1) (cid:1) + oj (cid:20) Lj Where oj potential interest at the end of its term. is _getOwed(newStack[j], newStack[j].point.end) which is the amount for the stack slot plus the So it would make sense to enforce a stricter inequality for Lnew : (1 + r (tend (cid:0) tnow ) 1018 )Anew = onew (cid:20) Lnew The big issue regarding the current lower bound is when the borrower only takes one lien and for this lien liqui- dationInitialAsk == amount (or they are close). Then at any point during the lien term (maybe very close to the end), the borrower can atomically self liquidate and settle the Seaport auction in one transaction. This way the borrower can skip paying any interest (they would need to pay OpenSea fees and potentially royalty fees) and plus they would receive liquidation fees.", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "commitToLiens transfers extra assets to the borrower when protocol fee is present", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "totalBorrowed is the sum of all commitments[i].lienRequest.amount But if s.feeTo is set, some of funds/assets from the vaults get transefered to s.feeTo when _handleProtocolFee is called and only the remaining is sent to the ROUTER(). So in this scenario, the total amount of assets sent to ROUTER() (so that it can be transferred to msg.sender) is up to rounding errors: (1 (cid:0) np dp )T Where:  T is the totalBorrowed  np is s.protocolFeeNumerator  dp is s.protocolFeeDenominator But we are transferring T to msg.sender which is more than we are supposed to send,", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "Withdraw proxy's claim() endpoint updates public vault's yIntercept incorrectly.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Let parameter description y0 n En(cid:0)1 Bn(cid:0)1 Wn(cid:0)1 Sn(cid:0)1 Sv Bv V the yIntercept of our public vault in the question. the current epoch for the public vault. the expected storage parameter of the previous withdraw proxy. the asset balance of the previous withdraw proxy. the withdrawReserveReceived of the previous withdraw proxy. the total supply of the previous withdraw proxy. the total supply of the public vault when processEpoch() was last called on the public vault. the total balance of the public vault when processEpoch() was last called on the public vault. the public vault. 28 parameter description Pn(cid:0)1 the previous withdraw proxy. Then y0 is updated/decremented according to the formula (up to rounding errors due to division): y0 = y0 (cid:0) max(0, En(cid:0)1 (cid:0) (Bn(cid:0)1 (cid:0) Wn(cid:0)1))(1 (cid:0) Sn(cid:0)1 Sv ) Whereas the amount ( A ) of assets transfered from Pn(cid:0)1 to V is And the amount ( B ) of asset left in Pn(cid:0)1 after this transfer would be: A = (Bn(cid:0)1 (cid:0) Wn(cid:0)1)(1 (cid:0) Sn(cid:0)1 Sv ) B = Wn(cid:0)1 + (Bn(cid:0)1 (cid:0) Wn(cid:0)1) Sn(cid:0)1 Sv (cid:1) (Bn(cid:0)1 (cid:0) Wn(cid:0)1) is supposed to represent the payment withdrawal proxy receives from Seaport auctions plus the amount of assets transferred to it by external actors. So A represents the portion of this amount for users who have not withdrawn from the public vault on the previous epoch and it is transferred to V and so y0 should be compensated positively. Also note that this amount might be bigger than En(cid:0)1 if a lien has a really high liquida- tionInitialAsk and its auction fulfills/matches near that price on Seaport. So it is possible that En(cid:0)1 < A. The current update formula for updating the y0 has the following flaws:  It only considers updating y0 when En(cid:0)1 (cid:0) (Bn(cid:0)1 (cid:0) Wn(cid:0)1) > 0 which is not always the case.  Decrements y0 by a portion of En(cid:0)1. The correct updating formula for y0 should be: y0 = y0 (cid:0) En(cid:0)1 + (Bn(cid:0)1 (cid:0) Wn(cid:0)1)(1 (cid:0) Sn(cid:0)1 Sv ) Also note, if we let Bn(cid:0)1 (cid:0) Wn(cid:0)1 = Xn(cid:0)1 + (cid:15), where Xn(cid:0)1 is the payment received by the withdraw proxy from Seaport auction payments and (cid:15) (if Wn(cid:0)1 updated correctly) be assets received from external actors by the previous withdraw proxy. Then: B = Wn(cid:0)1 + (Xn(cid:0)1 + (cid:15)) Sn(cid:0)1 Sv (cid:1) = h max(0, Bv (cid:0) En(cid:0)1) + Xn(cid:0)1 + (cid:15) i Sn(cid:0)1 Sv (cid:1) The last equality comes from the fact that when the withdraw reserves is fully transferred from the public vault and the current withdraw proxy (if necessary) to the previous withdraw proxy the amount Wn(cid:0)1 would hold should be max(0, Bv (cid:0) En(cid:0)1) Sn(cid:0)1 . Sv (cid:1) Related Issue.", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "Public vault's yIntercept is not updated when the full amount owed is not paid out by a Seaport auction.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "When the full amountOwed for a lien is not paid out during the callback from Seaport to a collateral's ClearingHouse and if the payee is a public vault, we would need to decrement the yIntercept, otherwise the payee.totalAssets() would reflect a wrong value.", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "LienToken payee not reset on transfer", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "payee and ownerOf are detached in that owners may set payee and owner may transfer the LienTo- ken to a new owner. payee does not reset on transfer. Exploit scenario:  Owner of a LienToken sets themselves as payee  Owner of LienToken sells the lien to a new owner  New owner does not update payee  Payments go to address set by old owner", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "WithdrawProxy allows redemptions before PublicVault calls transferWithdrawReserve", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Anytime there is a withdraw pending (i.e. someone holds WithdrawProxy shares), shares may be redeemed so long as totalAssets() > 0 and s.finalAuctionEnd == 0. Under normal operating conditions totalAssets() becomes greater than 0 when then PublicVault calls trans- ferWithdrawReserve. totalAssets() can also be increased to a non zero value by anyone transferring WETH to the contract. If this occurs and a user attempts to redeem, they will receive a smaller share than they are owed. Exploit scenario:  Depositor redeems from PublicVault and receives WithdrawProxy shares.  Malicious actor deposits a small amount of WETH into the WithdrawProxy.  Depositor accidentally redeems, or is tricked into redeeming, from the WithdrawProxy while totalAssets() is smaller than it should be.  PublicVault properly processes epoch and full withdrawReserve is sent to WithdrawProxy.  All remaining holders of WithdrawProxy shares receive an outsized share as the previous shares we re- deemed for the incorrect value.", "labels": ["Spearbit", "Astaria", "Severity: High Risk"]}, {"title": "Point.position is not updated for stack slots in _removeStackPosition", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "uint8(params.stack.length) which would be its index in the stack. When _removeStackPosition is called to remove a slot newStack[i].point.position is not updated for indexes that are greater than position in the original stack. Also slot.point.position is only used when we emit AddLien and LienStackUpdated events. In both of those cases, we could have used params.stack.length", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk"]}, {"title": "unchecked may cause under/overflows", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "unchecked should only be used when there is a guarantee of no underflows or overflows, or when they are taken into account. In absence of certainty, it's better to avoid unchecked to favor correctness over gas efficiency. For instance, if by error, protocolFeeNumerator is set to be greater than protocolFeeDenominator, this block in _handleProtocolFee() will underflow: PublicVault.sol#L640, unchecked { amount -= fee; } However, later this reverts due to the ERC20 transfer of an unusually high amount. This is just to demonstrate that unknown bugs can lead to under/overflows.", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk PublicVault.sol#L563, LienToken.sol#L424, LienToken.sol#L482, PublicVault.sol#L376, PublicVault.sol#L422, Public-"]}, {"title": "Multiple ERC4626Router and ERC4626RouterBase functions will always revert", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The intention of the ERC4626Router.sol functions is that they are approval-less ways to deposit and redeem: // For the below, no approval needed, assumes vault is already max approved As long as the user has approved the TRANSFER_PROXY for WETH, this works for the depositToVault function:  WETH is transferred from user to the router with pullTokens.  The router approves the vault for the correct amount of WETH.  vault.deposit() is called, which uses safeTransferFrom to transfer WETH from router into vault. However, for the redeemMax function, it doesn't work:  Approves the vault to spend the router's WETH.  vault.redeem() is called, which tries to transfer vault tokens from the router to the vault, and then mints withdraw proxy tokens to the receiver. This error happens assuming that the vault tokens would be burned, in which case the logic would work. But since they are transferred into the vault until the end of the epoch, we require approvals. The same issue also exists in these two functions in ERC4626RouterBase.sol:  redeem(): this is where the incorrect approval lives, so the same issue occurs when it is called directly.  withdraw(): the same faulty approval exists in this function.", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk"]}, {"title": "UniV3 tokens with fees can bypass strategist checks", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Each UniV3 strategy includes a value for fee in nlrDetails that is used to constrain their strategy to UniV3 pools with matching fees. This is enforced with the following check (where details.fee is the strategist's set fee, and fee is the fee returned from Uniswap): if (details.fee != uint24(0) && fee != details.fee) { revert InvalidFee(); } 33 This means that if you set details.fee to 0, this check will pass, even if the real fee is greater than zero.", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk"]}, {"title": "If auction time is reduced, withdrawProxy can lock funds from final auctions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "When a new liquidation happens, the withdrawProxy sets s.finalAuctionEnd to be equal to the new incoming auction end. This will usually be fine, because new auctions start later than old auctions, and they all have the same length. However, if the auction time is reduced on the Router, it is possible for a new auction to have an end time that is sooner than an old auction. The result will be that the WithdrawProxy is claimable before it should be, and then will lock and not allow anyone to claim the funds from the final auction.", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk"]}, {"title": "claim() will underflow and revert for all tokens without 18 decimals", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "In the claim() function, the amount to decrease the Y intercept of the vault is calculated as: (s.expected - balance).mulWadDown(10**ERC20(asset()).decimals() - s.withdrawRatio) s.withdrawRatio is represented as a WAD (18 decimals). As a result, using any token with a number of decimals under 17 (assuming the withdraw ratio is greater than 10%) will lead to an underflow and cause the function to revert. In this situation, the token's decimals don't matter. They are captured in the s.expected and balance, and are also the scale at which the vault's y-intercept is measured, so there's no need to adjust for them. Note: I know this isn't a risk in the current implementation, since it's WETH only, but since you are planning to generalize to accept all ERC20s, this is important.", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk"]}, {"title": "Call to Royalty Engine can block NFT auction", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "_generateValidOrderParameters() calls ROYALTY_ENGINE.getRoyaltyView() twice. The first call is wrapped in a try/catch. This lets Astaria to continue even if the getRoyaltyView() reverts. However, the second call is not safe from this. Both these calls have the same parameters passed to it except the price (startingPrice vs endingPrice). case they are different, there exists a possibility that the second call can revert. In", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk"]}, {"title": "Expired liens taken from public vaults need to be liquidated otherwise processing an epoch halts/reverts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "s.epochData[s.currentEpoch].liensOpenForEpoch is decremented or is supposed to be decre- mented, when for a lien with an end that falls on this epoch:  The full payment has been made,  Or the lien is bought out by a lien that is from a different vault or ends at a higher epoch,  Or the lien is liquidated. If for some reason a lien expires and no one calls liquidate, then s.epochData[s.currentEpoch].liensOpenForEpoch > 0 will be true and processEpoch() would revert till someones calls liquidate. Note that a lien's end falling in the s.currentEpoch and timeToEpochEnd() == 0 imply that the lien is expired. 35", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk"]}, {"title": "assets < s.depositCap invariant can be broken for public vaults with non-zero deposit caps", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The following check in mint / deposit does not take into consideration the new shares / amount sup- plied to the endpoint, since the yIntercept in totalAssets() is only updated after calling super.mint(shares, receiver) or super.deposit(amount, receiver) with the afterDeposit hook. uint256 assets = totalAssets(); if (s.depositCap != 0 && assets >= s.depositCap) { revert InvalidState(InvalidStates.DEPOSIT_CAP_EXCEEDED); } Thus the new shares or amount provided can be a really big number compared to s.depositCap, but the call will still go through.", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk"]}, {"title": "redeemFutureEpoch transfers the shares from the msg.sender to the vault instead of from the owner", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "redeemFutureEpoch transfers the vault shares from the msg.sender to the vault instead of from the owner.", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk"]}, {"title": "Lien buyouts can push maxPotentialDebt over the limit", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "When a lien is bought out, _buyoutLien calls _getMaxPotentialDebtForCollateral to confirm that this number is lower than the maxPotentialDebt specified in the lien. However, this function is called with the existing stack, which hasn't yet replaced the lien with the new, bought out lien. Valid refinances can make the rate lower or the time longer. In the case that a lien was bought out for a longer duration, maxPotentialDebt will increase and could go over the limit specified in the lien.", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk"]}, {"title": "Liens cannot be bought out once we've reached the maximum number of active liens on one collateral", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The buyoutLien function is intended to transfer ownership of a lien from one user to another. In practice, it creates a new lien by calling _createLien and then calls _replaceStackAtPositionWithNewLien to update the stack. In the _createLien function, there is a check to ensure we don't take out more than maxLiens against one piece of collateral: if (params.stack.length >= s.maxLiens) { revert InvalidState(InvalidStates.MAX_LIENS); } The result is that, when we already have maxLiens and we try to buy one out, this function will revert.", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk"]}, {"title": "First vault deposit can cause excessive rounding", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Aside from storage layout/getters, the context above notes the other major departure from Solmate's ERC4626 implementation. The modification requires the initial mint to cost 10 full WETH. 37 + + + function mint( uint256 shares, address receiver ) public virtual returns (uint256 assets) { // assets is 10e18, or 10 WETH, whenever totalSupply() == 0 assets = previewMint(shares); // No need to check for rounding error, previewMint rounds up. // Need to transfer before minting or ERC777s could reenter. // minter transfers 10 WETH to the vault ERC20(asset()).safeTransferFrom(msg.sender, address(this), assets); // shares received are based on user input _mint(receiver, shares); emit Deposit(msg.sender, receiver, assets, shares); afterDeposit(assets, shares); } Astaria highlighted that the code diff from Solmate is in relation to this finding from the previous Sherlock audit. However, deposit is still unchanged and the initial deposit may be 1 wei worth of WETH, in return for 1 wad worth of vault shares. Further, the previously cited issue may still surface by calling mint in a way that sets the price per share high (e.g. 10 shares for 10 WETH produces a price per of 1:1e18). Albeit, at a higher cost to the minter to set the initial price that high.", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk"]}, {"title": "When the collateral is listed on SeaPort by the borrower using listForSaleOnSeaport, when settled the liquidation fee will be sent to address(0)", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "When the collateral s.auctionData[collateralId].liquidator (s.auctionData in general) will not be set and so it will be address(0) and thus the liquidatorPayment will be sent to address(0).", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk"]}, {"title": "potentialDebt is not compared against a new lien's maxPotentialDebt in _appendStack", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "In _appendStack, we have the following block: newStack = new Stack[](stack.length + 1); newStack[stack.length] = newSlot; uint256 potentialDebt = _getOwed(newSlot, newSlot.point.end); ... if ( stack.length > 0 && potentialDebt > newSlot.lien.details.maxPotentialDebt ) { revert InvalidState(InvalidStates.DEBT_LIMIT); } Note, we are only performing a comparison between newSlot.lien.details.maxPotentialDebt and poten- tialDebt when stack.length > 0. If _createLien is called with params.stack.length == 0, we would not perform this check and thus the input params is not fully checked for misconfiguration.", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk"]}, {"title": "Previous withdraw proxy's withdrawReserveReceived is not updated when assets are drained from the current withdraw proxy to the previous", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "When drain is called, we don't update the s.epochData[s.currentEpoch - 1]'s withdrawRe- serveReceived, this is in contrast to when withdraw reserves are transferred from the public vault to the withdraw proxy. This would unlink the previous withdraw proxy's withdrawReserveReceived storage parameter to the total amount of assets it has received from either the public vault or the current withdraw proxy. An actor can manipulate Bn(cid:0)1 (cid:0) Wn(cid:0)1's value by sending assets to the public vault and the current withdraw proxy before calling transferWithdrawReserve ( Bn(cid:0)1 is the previous withdraw proxy's asset balance, Wn(cid:0)1 is previous withdraw proxy's withdrawReserveReceived and n is public vault's epoch). Bn(cid:0)1 (cid:0) Wn(cid:0)1 should really represent the sum of all near-boundary auction payment's the previous withdraw proxy receives plus any assets that are transferred to it by an external actor. Related Issue 46.", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk"]}, {"title": "Update solc version and use unchecked in Uniswap related libraries", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The highlighted libraries above are referenced from Uniswap codebase which is intended to work with Solidity compiler <0.8. These older versions have unchecked arithmetic by default and the code takes it into account. Astaria code is intended to work with Solidity compiler >=0.8 which doesn't have unchecked arithmetic by default. Hence, to port the code, it has to be turned on via unchecked keyword. For example, FullMathUniswap.mulDiv(type(uint).max, type(uint).max, type(uint).max) reverts for v0.8, and returns type(uint).max for older version.", "labels": ["Spearbit", "Astaria", "Severity: Medium Risk"]}, {"title": "buyoutLien is prone to race conditions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "LienToken.buyoutLien and VaultImplementation.buyoutLien are both prone to race conditions where multiple vaults can try to front-run each others' buyoutLien call to end up registering their own lien. Also note, due to the storage values s.minInterestBPS and s.minDurationIncrease being used in the is- ValidRefinance, the winning buyoutLien call does not necessarily have to have the best rate or duration among the other candidates in the race.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "ERC20-Cloned allows certain actions for address(0)", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "In ERC20-Cloned, address(0) can be used as the:  spender (spender)  to parameter of transferFrom.  to parameter of transfer.  to parameter of _mint.  from parameter of _burn. As an example, one can transfer or transferFrom to address(0) which would turn the amount of tokens unus- able but those not update the total supply in contrast to if _burn was called.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "BEACON_PROXY_IMPLEMENTATION and WETH cannot be updated for AstariaRouter", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "There is no update mechanism for BEACON_PROXY_IMPLEMENTATION and WETH in AstariaRouter. It would make sense that one would want to keep WETH as not upgradable (unless we provide the wrong address to the constructor). But for BEACON_PROXY_IMPLEMENTATION there could be possibilities of potentially upgrading it.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "Incorrect key parameter type is used for s.epochData", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "In PublicVault, whenever the epoch key provided is to the mapping s.epochData its type is uint64, but the type of s.epochData is mapping(uint256 => EpochData)", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "buyoutLien, canLiquidate and makePayment have different notion of expired liens when considering edge cases", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "When swapping a lien that is just expired (lien's end tend equals to the current timestamp tnow ), one can call buyoutLien to swap it out. But when tnow > tend , buyoutLien reverts due to the underflow in _- getRemainingInterest when calculating the buyout amount. This is in contrast to canLiquidate which allows a lien with tnow = tend to liquidate as well. makePayment also only considers tend < tnow as expired liens. So the expired/non-functional liens time ranges for different endpoints are: endpoint expired range buyoutLien canLiquidate makePayment (tend , 1) [tend , 1) (tend , 1)", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "Ensure all ratios are less than 1", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Although, numerators and denominators for different fees are set by admin, it's a good practice to add a check in the contract for absurd values. In this case, that would be when numerator is greater than denominator.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "Factor out s.slope updates", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Slope updates occur in multiple locations but do not emit events.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "External call to arbitrary address", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The Router has a convenience function to commit to multiple liens AstariaRouter.commitToLiens. This function causes the router to receive WETH and allows the caller to supply an arbitrary vault address lien- Request.strategy.vault which is called by the router. This allows the potential for the caller to re-enter in the middle of the loop, and also allows them to drain any WETH that happens to be in the Router. In our review, no immediate reason for the Router to have WETH outside of commitToLiens calls was identified and therefore the severity of this finding is low.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "Astaria's Seaport orders may not be listed on OpenSea", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "To list Seaport orders on OpenSea, the order should pass certain validations as described here(see OpenSea Order Validation). Currently, Astaria orders will fail this validation. For instance, zone and zoneHash values are not set as suggested.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "Any ERC20 held in the Router can be stolen using ERC4626RouterBase functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "All four functions in ERC4626RouterBase.sol take in a vault address, a to address, a shares amount, and a maxAmountIn for validation. The first step is to read vault.asset() and then approve the vault to spend the ERC20 at whatever address is returned for the given amount. function mint( IERC4626 vault, address to, uint256 shares, uint256 maxAmountIn ) public payable virtual override returns (uint256 amountIn) { ERC20(vault.asset()).safeApprove(address(vault), shares); if ((amountIn = vault.mint(shares, to)) > maxAmountIn) { revert MaxAmountError(); } } In the event that the Router holds any ERC20, a malicious user can design a contract with the following functions: function asset() view pure returns (address) { return [ERC20 the router holds]; } function mint(uint shares, address to) view pure returns (uint) { return 0; } If this contract is passed as the vault, the function will pass, and the router will approve this contract to control its holdings of the given ERC20.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "Inconsistency in byte size of maxInterestRate", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "In RouterStorage, maxInterestRate has a size of uint88. However, when being set from file(), it is capped at uint48 by the safeCastTo48() function.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "Router#file has update for nonexistent MinInterestRate variable", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "One of the options in the file() function is to update FileType.MinInterestRate. There are two problems here: 1) If someone chooses this FileType, the update actually happens to s.maxInterestRate. 2) There is no minInterestRate storage variable, as minInterestBPS is handled on L235-236.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "getLiquidationWithdrawRatio() and getYIntercept() have incorrect return types", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "liquidationWithdrawRatio and yIntercept like other amount-related parameters are of type uint88 (uint88) and they are the returned values of getLiquidationWithdrawRatio() and getYIntercept() re- spectively. But the return type of getLiquidationWithdrawRatio() and getYIntercept() are defined as uint256.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "The modified implementation of redeem is omitting a check to make sure not to redeem 0 assets.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The modified implementation of redeem is omitting the check // Check for rounding error since we round down in previewRedeem. require((assets = previewRedeem(shares)) != 0, \"ZERO_ASSETS\"); You can see a trail of it in redeemFutureEpoch.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "PublicVault's redeem and redeemFutureEpoch always returns 0 assets.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "assets returned by redeem and redeemFutureEpoch will always be 0, since it has not been set in redeemFutureEpoch. Also Withdraw event emits an incorrect value for asset because of this. The issue stems from trying to consolidate some of the logic for redeem and withdraw by using redeemFutureEpoch for both of them.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "OWNER() cannot be updated for private or public vaults", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "owner() is an immutable data for any ClonesWithImmutableArgs.clone that uses AstariaVault- Base. That means for example if there is an issue with the current hardcoded owner() there is no way to update it and liquidities/assets in the public/private vaults would also be at risk.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "ROUTER() can not be updated for private or public vaults", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "ROUTER() is an immutable data for any ClonesWithImmutableArgs.clone that uses AstariaVault- Base. That means for example if there is an issue with the current hardcoded ROUTER() or that it needs to be upgraded, the current public/private vaults would not be able to communicate with the new ROUTER.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "Wrong return parameter type is used for getOwed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Both variations of getOwed use _getOwed and return uint192. But _getOwed returns a uint88.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "Document and reason about which functionalities should be frozen on protocol pause", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "On protocol pause, a few functions are allowed to be called. Some instances are noted above. There is no documentation on why these functionalities are allowed while the remaining functions are frozen.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "Wrong parameter type is used for s.strategyValidators", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "s.strategyValidators is of type mapping(uint32 => address) but the provided TYPE in the con- text is of type uint8.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "Some functions do not emit events, but they should", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "AstariaRouter.sol#L268 : Other filing endpoints in the same contract and also CollateralToken and LienToken emit FileUpdated(what, data). But fileGuardian does not.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "setNewGuardian can be changed to a 2 or 3 step transfer of authority process", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The current guardian might pass a wrong _guardian parameter to setNewGuardian which can break the upgradability of the AstariaRouter using fileGuardian.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "There are no range/value checks when some parameters get fileed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "There are no range/value checks when some parameters get fileed. For example:  There are no hardcoded range checks for the ...Numerators and ...Denominators, so that the protocol's users can trustlessly assume the authorized users would not push these values into ranges seemed unac- ceptable.  When an address get updated, we don't check whether the value provided is address(0) or not.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "Manually constructed storage slots can be chosen so that the pre-image of the hash is unknown", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "In the codebase, some storage slots are manually constructed using keccak256 hash of a string xyz.astaria. .... The pre-images of these hashes are known. This can allow in future for actors to find a potential path to those storage slots using the keccak256 hash function in the codebase and some crafted payload.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "Avoid shadowing variables", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The highlighted line declares a new variable owner which has already been defined in Auth.sol inherited by LienToken: address owner = ownerOf(lienId);", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "PublicVault.accrue is manually inlined rather than called", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The _accrue function locks in the implied value of the PublicVault by calculating, then adding to yIntercept, and finally emitting an event. This calculation is duplicated in 3 separate locations in PublicVault:  In totalAssets  In _accrue  And in updateVaultAfterLiquidation", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "CollateralToken.flashAction reverts with incorrect error", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Reverts with InvalidCollateralStates.AUCTION_ACTIVE when the address is not flashEnabled.", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "AstariaRouter has unnecessary access to setPayee", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "LienToken.setPayee. setPayee is never called from AstariaRouter, but the router has access to call", "labels": ["Spearbit", "Astaria", "Severity: Low Risk"]}, {"title": "ClearingHouse can be deployed only when needed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "When collateral is deposited, a Clearing House is automatically deployed. However, these Clearing Houses are only needed if the collateral goes to auction at Seaport, either through liquidation or the collateral holder choosing to sell them. The Astaria team has indicated that this behavior is intentional in order to put the cost on the borrower, since liquidations are already expensive. I'd suggest the perspective that all pieces of collateral will be added to the system, but a much smaller percentage will ever be sent to Seaport. The aggregate gas spent will be much, much lower if we are careful to only deploy these contract as needed. Further, let's look at the two situations where we may need a Clearing House: 1) The collateral holder calls listForSaleOnSeaport(): In this case, the borrower is paying anyways, so it's a no brainer. 2) Another user calls liquidate(): In this case, they will earn the liquidation fees, which should be sufficient to justify a small increase in gas costs.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "PublicVault.claim() can be optimized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "For claim not to revert we would need to have msg.sender == owner(). And so when the following is called: _mint(owner(), unclaimed); Instead of owner() we can use msg.sender since reading the immutable owner() requires some calldata lookup.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "Can remove incoming terms from LienActionBuyout struct", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Incoming terms are never used in the LienActionBuyout struct. The general flow right now is:  incomingTerms are passed to VaultImplementation#buyoutLien.  These incoming terms are validated and used to generate the lien information.  The lien information is encoded into a LienActionBuyout struct.  This is passed to LienToken#buyoutLien, but then the incoming terms are never used again.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "Refactor updateVaultAfterLiquidation to save gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "In updateVaultAfterLiquidation, we check if we're within maxAuctionWindow of the end of the If we are, we call _deployWithdrawProxyIfNotDeployed and assign withdrawProxyIfNearBoundary to epoch. the result. We then proceed to check if withdrawProxyIfNearBoundary is assigned and, if it is, call handleNewLiquidation. Instead of checking separately, we can include this call within the block of code executed if we're within maxAuc- tionWindow of the end of the epoch. This is true because (a) withdraw proxy will always be deployed by the end of that block and (b) withdraw proxy will never be deployed if timeToEnd >= maxAuctionWindow.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "Use collateralId to set collateralIdToAuction mapping", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "_listUnderlyingOnSeaport() sets collateralIdToAuction mapping as follows: s.collateralIdToAuction[uint256(listingOrder.parameters.zoneHash)] = true; Since this function has access to collateralId, it can be used instead of using zoneHash.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "Storage packing", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "RouterStorage: The RouterStorage struct represents state managed in storage by the AstariaRouter contract. Some of the packing in this struct is sub optimal. 1. maxInterestRate and minInterestBPS: These two values pack into a single storage slot, however, are never referenced together outside of the constructor. This means, when read from storage, there are no gas efficiencies gained. 2. Comments denoting storage slots do not match implementation. The comment //slot 3 + for example occurs far after the 3rd slot begins as the addresses do not pack together. LienStorage: 3. The LienStorage struct packs maxLiens with the WETH address into a single storage slot. While gas is saved on the constructor, extra gas is spent in parsing maxLiens on each read as it is read alone. VaultData: 4. VaultData packs currentEpoch into the struct's first slot, however, it is more commonly read along with values from the struct's second slot.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "ClearingHouse fallback can save WETH address to memory to save gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The fallback function reads WETH() from ROUTER three times. once and save to memory for the future calls.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "CollateralToken's onlyOwner modifier doesn't need to access storage", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The onlyOwner modifier calls to ownerOf(), which loads storage itself to check ownership. We can save a storage load since we don't need to load the storage variables in the modifier itself.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "Can stop loop early in _payDebt when everything is spent", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "When a loan is sold on Seaport and _payDebt is called, it loops through the auction stack and calls _paymentAH for each, decrementing the remaining payment as money is spent. This loop can be ended when payment == 0.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "Can remove initializing allowList and depositCap for private vaults", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Private Vaults do not allow enabling, disabling, or editing the allow list, and don't enforce a deposit cap, so seems strange to initialize these variables. Delegates are still included in the _validateCommitment function, so we can't get rid of this entirely.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "ISecurityHook.getState can be modified to return bytes32 / hash of the state instead of the state itself.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Since only the keccak256 of preTransferState is checked against the kec- cak256 hash of the returned security hook state, we could change the design so that ISecurityHook.getState returns bytes32 to save gas. Unless there is a plan to use the bytes memory preTransferState in some other form as well.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "Define an endpoint for LienToken that only returns the liquidator", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "It would save a lot of gas if LienToken had an endpoint that would only return the liquidator for a collateralId, instead of all the auction data.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "Setting uninitialized stack variables to their default value can be avoided.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Setting uninitialized stack variables to their default value adds extra gas overhead. T t = <DEFAULT_VALUE>;", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "Simplify / optimize for loops", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "In the codebase, sometimes there are for loops of the form: for (uint256 i = 0; <CONDITION>; i++) { <BODY> } These for loops can be optimized.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "calculateSlope can be more simplified", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "calculateSlope can be more simplified: owedAtEnd would be: owedAtEnd = amt + (tend (cid:0) tlast )r amt 1018 where:  amt is stack.point.amount  tend is stack.point.end  tlast is stack.point.last  r is stack.lien.details.rate and so the returned value would need to be r amt 1018.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "Break out of _makePayment for loop early when totalCapitalAvailable reaches 0", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "In _makePayment we have the following for loop: for (uint256 i; i < n; ) { (newStack, spent) = _payment( s, stack, uint8(i), totalCapitalAvailable, address(msg.sender) ); totalCapitalAvailable -= spent; unchecked { ++i; } } When totalCapitalAvailable reaches 0 we still call _payment which costs a lot of gas and it is only used for transferring 0 assets, removing and adding the same slope for a lien owner if it is a public vault and other noops.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "_buyoutLien can be optimized by reusing payee", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "payee in _buyoutLien can be reused to save some gas", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "isValidRefinance and related storage parameters can be moved to LienToken", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "isValidRefinance is only used in LienToken and with the current implementation it requires reading AstariaRouter from the storage and performing a cross-contract call which would add a lot of overhead gas cost.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "auctionWindowMax can be reused to optimize liquidate", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "There are mutiple instances of s.auctionWindow + s.auctionWindowBuffer in the liquidate func- tion which would make the function to read from the storage twice each time. Also there is already a stack variable auctionWindowMax defined as the sum which can be reused.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "fileBatch() does requiresAuth for each file separately", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "fileBatch() does a requiresAuth check and then for each element in the input array calls file() which does another requiresAuth check. function fileBatch(File[] calldata files) external requiresAuth { for (uint256 i = 0; i < files.length; i++) { file(files[i]); } } ... function file(File calldata incoming) public requiresAuth { This wastes gas as if the fileBatch()'s requiresAuth pass, file()'s check will pass too.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "_sliceUint can be optimized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "_sliceUint can be optimized", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "Use basis points for ratios", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Fee ratios are represented through two state variables for numerator and denominator. Basis point system can be used in its place as it is simpler (denominator always set to 10_000), and gas efficient as denomi- nator is now a constant.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "No Need to Allocate Unused Variable", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "LienToken._makePayment() returns two values: (Stack[] memory newStack, uint256 spent), but the second value is never read: (newStack, ) = _makePayment(_loadLienStorageSlot(), stack, amount); Also, if this value is planned to be used in future, it's not a useful value. It is equal to the payment made to the last lien. A more meaningful quantity can be the total payment made to the entire stack. Additional instances noted in Context above.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "Cache Values to Save Gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Calls are occurring, same values are computed, or storage variables are being read, multiple times; e.g. CollateralToken.sol#L286-L307 reads the storage variable s.securityHooks[addr] four times. It's better to cache the result in a stack variable to save gas.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "RouterStorage.vaults can be a boolean mapping", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "RouterStorage.vaults is of type mapping(address => address). A key-value is stored in the mapping as: s.vaults[vaultAddr] = msg.sender; However, values in this mapping are only used to compare against address(0): if (_loadRouterSlot().vaults[msg.sender] == address(0)) { ... return _loadRouterSlot().vaults[vault] != address(0); It's better to have vaults as a boolean mapping as the assignment of msg.sender as value doesn't carry a special meaning.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "isValidReference() should just take an array element as input", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "stack[position]: isValidRefinance() takes stack array as an argument but only uses stack[0] and function isValidRefinance( ILienToken.Lien calldata newLien, uint8 position, ILienToken.Stack[] calldata stack ) public view returns (bool) { The usage of stack[0] can be replaced with stack[position] as stack[0].lien.collateralId == stack[position].lien.collateralId: if (newLien.collateralId != stack[0].lien.collateralId) { revert InvalidRefinanceCollateral(newLien.collateralId); } To save gas, it can directly take that one element as input.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "Functions can be made external", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "If public function is not called from within the contract, it should made external for clarity, and can potentially save gas.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "a.mulDivDown(b,1) is equivalent to a*b", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Highlighted code above follow the pattern of a.mulDivDown(b, 1) which is equivalent to a*b.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "Use scratch space for keccak", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "computeId() function computes and returns uint256(keccak256(abi.encodePacked(token, to- kenId))). Since the data being hashed fits within 2 memory slots, scratch space can be used to avoid paying gas cost on memory expansion.", "labels": ["Spearbit", "Astaria", "Severity: Gas Optimization"]}, {"title": "Define a named constant for the return value of onFlashAction", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "onFlashAction returns: keccak256(\"FlashAction.onFlashAction\")", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Define a named constant for permit typehash in ERC20-cloned", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "In permit, the following type hash has been used: keccak256( \"Permit(address owner,address spender,uint256 value,uint256 nonce,uint256 deadline)\" )", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Unused struct, enum and storage fields can be removed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The struct, enum and storage fields in this context have not been used in the project.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "WPStorage.expected's comment can be made more accurate", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "In WPStorage's definition we have: uint88 expected; // Expected value of auctioned NFTs. yIntercept (virtual assets) of a PublicVault are ,! not modified on liquidation, only once an auction is completed. The comment for expected is not exactly accurate. The accumulated value in expected is the sum of all auctioned NFTs's amountOwed when (the timestamp) the liquidate function gets called. Whereas the NFTs get auctioned starting from their first stack's element's liquidationInitialAsk to 1_000 wei", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Leave comment that in WithdrawProxy.claim() the calculation of balance cannot underflow", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "There is this following line in claim() where balance is initialised: uint256 balance = ERC20(asset()).balanceOf(address(this)) - s.withdrawReserveReceived; With the current PublicVault implementation of IPublicVault, this cannot underflow since the increase in with- drawReserveReceived (using increaseWithdrawReserveReceived) is synced with increasing the asset balance by the same amount.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Shared logic in withdraw and redeem functions of WithdrawProxy can be turned into a shared modifier", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "withdraw and redeem both start with the following lines: WPStorage storage s = _loadSlot(); // If auction funds have been collected to the WithdrawProxy // but the PublicVault hasn't claimed its share, too much money will be sent to LPs if (s.finalAuctionEnd != 0) { // if finalAuctionEnd is 0, no auctions were added revert InvalidState(InvalidStates.NOT_CLAIMED); } Since they have this shared logic at the beginning of their body, we can consolidate the logic into a modifier.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "StrategyDetails version can only be used in custom implementation of IStrategyValidator, requires documentation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "StrategyDetails.version is never used in the current implementations of the validators.  If the intention is to avoid replays across different versions of Astaria, we should add a check for it in commit- ment validation functions.  A custom implementation of IStrategyValidator can make use of this value, but this needs documentation as to exactly what it refers to.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Define helper functions to tag different pieces of cloned data for ClearingHouse", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "_getArgAddress(0) and _getArgUint256(21) are used as the ROUTER() and COLLATERAL_ID() in the fallback implementation for ClearingHouse was Clone derived contract.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "A new modifier onlyVault() can be defined for WithdrawProxy to consolidate logic", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The following require statement has been used in multiple functions including increaseWith- drawReserveReceived, drain, setWithdrawRatio and handleNewLiquidation. require(msg.sender == VAULT(), \"only vault can call\");", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Inconsistant pragma versions and floating pragma versions can be avoided", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Most contracts in the project use pragma solidity 0.8.17, but there are other variants as well: 69 pragma solidity ^0.8.16; pragma solidity ^0.8.16; pragma solidity ^0.8.16; // src/Interfaces/IAstariaVaultBase.sol // src/Interfaces/IERC4626Base.sol // src/Interfaces/ITokenBase.sol pragma solidity ^0.8.15; // src/Interfaces/ICollateralToken.sol pragma solidity ^0.8.0; pragma solidity ^0.8.0; pragma solidity ^0.8.0; pragma solidity ^0.8.0; pragma solidity ^0.8.0; pragma solidity ^0.8.0; // src/Interfaces/IERC20.sol // src/Interfaces/IERC165.sol // src/Interfaces/IERC1155.sol // src/Interfaces/IERC1155Receiver.sol // src/Interfaces/IERC721Receiver.sol // src/utils/Math.sol pragma solidity >=0.8.0; pragma solidity >=0.8.0; // src/Interfaces/IERC721.sol // src/utils/MerkleProofLib.sol And they all have floating version pragmas.  In hardhat.config.ts, solidity: \"0.8.13\" is used.  In .prettierrc settings we have \"compiler\": \"0.8.17\"  In .solhint.json we have \"compiler-version\": [\"error\", \"0.8.0\"]  foundry.toml does not have a solc setting", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "IBeacon is missing a compiler version pragma", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "IBeacon is missing a compiler version pragma.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "zone and zoneHash are not required for fully open Seaport orders", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "As per Seaport's documentation,zone and zoneHash are not required for PUBLIC orders: The zone of the order is an optional secondary account attached to the order with two additional privi- leges:  The zone may cancel orders where it is named as the zone by calling cancel. (Note that offerers can also cancel their own orders, either individually or for all orders signed with their current counter at once by calling incrementCounter).  \"Restricted\" orders (as specified by the order type) must either be executed by the zone or the offerer, or must be approved as indicated by a call to an isValidOrder or isValidOrderIncludingEx- traData view function on the zone. 70 This order isn't \"Restricted\", and there is no way to cancel a Seaport order once created from this contract.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Inconsistent treatment of delegate setting", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Private vaults include delegate in the allow list when deployed through the Router. Public vaults do not. The VaultImplementation, when mutating a delegate, sets them on allow list.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "AstariaRouter does not adhere to EIP1967 spec", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The Router serves as an implementation Beacon for proxy contracts, however, does not adhere to the EIP1967 spec.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Receiver of bought out lien must be approved by msg.sender", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The buyoutLien function requires that either the receiver of the lien is msg.sender or is an address approved by msg.sender: if (msg.sender != params.encumber.receiver) { require( _loadERC721Slot().isApprovedForAll[msg.sender][params.encumber.receiver] ); } This check seems unnecessary and in some cases will block users from buying out liens as intended.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "A new modifer onlyLienToken() can be defined to refactor logic", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The following require statement has been used in multiple locations in PublicVault: require(msg.sender == address(LIEN_TOKEN())); Locations used:  beforePayment  afterPayment  handleBuyoutLien  updateAfterLiquidationPayment  updateVaultAfterLiquidation", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "A redundant if block can be removed from PublicVault._afterCommitToLien", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "In PublicVault._afterCommitToLien, we have the following if block: if (s.last == 0) { s.last = block.timestamp.safeCastTo40(); } This if block is redundant, since regardless of the value of s.last, a few lines before _accrue(s) would update the s.last to the current timestamp.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Private vaults' deposit endpoints can be potentially simplifed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "A private vault's deposit function can be called directly or indirectly using the ROUTER() (either way by anyone) and we have the following require statement: require( s.allowList[msg.sender] || (msg.sender == address(ROUTER()) && s.allowList[receiver]) ); If the ROUTER() is the AstariaRouter implementation of IAstariaRouter, then it inherits from ERC4626RouterBase and ERC4626Router which allows anyone to call into deposit of this private vault using:  depositToVault  depositMax  ERC4626RouterBase.deposit Thus if anyone of the above functions is called through the ROUTER(), msg.sender == address(ROUTER() will be true. Also, note that when private vaults are created using the newVault the msg.sender/owner along the delegate are added to the allowList and allowlist is enabled. And since there is no bookkeeping here for the receiver, except only the require statement, that means  Only the owner or the delegate of this private vault can call directly into deposit or  Anyone else can set the address to parameter of one of those 3 endpoints above to owner or delegate to deposit assets (wETH in the current implementation) into the private vault. And all the assets can be withdrawn by the owner only.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "The require statement in decreaseEpochLienCount can be more strict", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "decreaseEpochLienCount has the following require statement that limits who can call into it: require( msg.sender == address(ROUTER()) || msg.sender == address(LIEN_TOKEN()) ); So only, the ROUTER() and LIEN_TOKEN() are allowed to call into. But AstariaRouter never calls into this function.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "amount is not used in _afterCommitToLien", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "amount is not used in _afterCommitToLien to update/decrement s.yIntercept, because even though assets have been transferred out of the vault, they would still need to be paid back and so the net ef- fect on s.yIntercept (that is used in the calculation of the total virtual assets) is 0.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Use modifier", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Highlighted code have require checks on msg.sender which can be converted to modifiers. For instance: require(address(msg.sender) == s.guardian);", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Prefer SafeCastLib for typecasting", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Highlighted code above does typecasting of several constant values. In case, some value doesn't fit in the type, this typecasting will silently ignore the higher order bits although that's currently not the case, but it may pose a risk if these values are changed in future.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Rename Multicall to Multidelegatecall", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Multicall.sol lets performs multiple delegatecalls. Hence, the name Multicall is not suitable. The contract and the file should be named Multidelegatecall.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "safeTransferFrom() without the data argument can be used", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Highlighted code above sends empty data over an external call via ERC721.safeTransferFrom(from, to, tokenId, data): IERC721(underlyingAsset).safeTransferFrom( address(this), releaseTo, assetId, \"\" ); data can be removed since ERC721.safeTransferFrom(from, to, tokenId) sets empty data too.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Fix documentation that updateVaultAfterLiquidation can be called by LIEN_TOKEN, not ROUTER", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The function has the correct validation that it can only be called by LIEN_TOKEN(), but the comment says it can only be called by ROUTER(). require(msg.sender == address(LIEN_TOKEN())); // can only be called by router", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Declare event and constants at the beginning", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Events and constants are generally declared at the beginning of a smart contract. However, for the highlighted code above, that's not the case.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Rename Vault to PrivateVault", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Vault contract is used to represent private vaults.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Remove comment", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Comment at line WithdrawProxy.sol#L229 can be removed: if ( block.timestamp < s.finalAuctionEnd // || s.finalAuctionEnd == uint256(0) ) { The condition in comments is always false as the code already reverts in that case.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "WithdrawProxy and PrivateVault symbols are missing hyphens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The symbol for the WithdrawProxy token is missing a hyphen after the W, which will make the name AST-W0x... instead of AST-W-0x.... Similarly, the symbol for the Private Vault token (in Vault.sol) is missing a hyphen after the V.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Lien cannot be bought out after stack.point.end", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The _getRemainingInterest function reverts with Panic(0x11) when block.timestamp > stack.point.end.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Inconsistent strictness of inequalities in isValidRefinance", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "In isValidRefinance, we check that either: a) newRate < maxNewRate && newEnd >= oldEnd b) newEnd - oldEnd >= minDurationIncrease && newRate <= oldRate We should be consistent in whether we're enforcing the changes are strict inequalities or non-strict inequalities.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Clarify comments", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Few comments are not clear on what they are referring to: zone: address(this), // 0x20 ... conduitKey: s.CONDUIT_KEY, // 0x120", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Remove unused files", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "CallUtils.sol is not used anywhere in the codebase.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Document privileges and entities holding these privileges", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "There are certain privileged functionalities in the codebase (recognized through requiresAuth mod- ifier). Currently, we have to refer to tests to identify the setup.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Document and ensure that maximum number of liens should not be set greater than 256", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Maximum number of liens in a stack is currently set to 5. While paying for a lien, the index in the stack is casted to uint8. This makes the implicit limit on maximum number of liens to be 256.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "transferWithdrawReserve() can return early when the current epoch is 0", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "If s.currentEpoch == 0, s.currentEpoch - 1 will wrap around to type(uint256).max and we will most probably will drain assets into address(0) in the following block: unchecked { s.withdrawReserve -= WithdrawProxy(withdrawProxy) .drain( s.withdrawReserve, s.epochData[s.currentEpoch - 1].withdrawProxy ) .safeCastTo88(); } But this cannot happen since in the outer if block the condition s.withdrawReserve > 0 indirectly means that s.currentEpoch > 0. The indirect implication above regarding the 2 conditions stems from the fact that s.withdrawReserve has only been set in transferWithdrawReserve() function or processEpoch(). In transferWithdrawReserve() function 78 it assumes a positive value only when s.currentEpoch > uint64(0) and in processEpoch() at the end we are incrementing s.currentEpoch.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "2 of the inner if blocks of processEpoch() check for a condition that has already been checked by an outer if block", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The following 2 if block checks are redundant: if (address(currentWithdrawProxy) != address(0)) { currentWithdrawProxy.setWithdrawRatio(s.liquidationWithdrawRatio); } uint256 expected = 0; if (address(currentWithdrawProxy) != address(0)) { expected = currentWithdrawProxy.getExpected(); } Since the condition address(currentWithdrawProxy) != address(0) has already been checked by an outer if block.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "General formatting suggestions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": " PublicVault.sol#L283 : there are extra sourounding paranthesis", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Identical collateral check is performed twice in _createLien", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "In _createLien, a check is performed that the collateralId of the new lien matches the collateralId of the first lien on the stack. if (params.stack.length > 0) { if (params.lien.collateralId != params.stack[0].lien.collateralId) { revert InvalidState(InvalidStates.COLLATERAL_MISMATCH); } } This identical check is performed twice (L383-387 and L389-393).", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "checkAllowlistAndDepositCap modifer can be defined to consolidate some of the mint and deposit logic for public vaults", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The following code snippet has been used for both mint and deposit endpoints of a public vault: VIData storage s = _loadVISlot(); if (s.allowListEnabled) { require(s.allowList[receiver]); } uint256 assets = totalAssets(); if (s.depositCap != 0 && assets >= s.depositCap) { revert InvalidState(InvalidStates.DEPOSIT_CAP_EXCEEDED); }", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Document why bytes4(0xffffffff) is chosen when CollateralToken acting as a Seaport zone to signal invalid orders", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "bytes4(0xffffffff) to indicate a Seaport order using this zone is not a valid order.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "CollateralToken.onERC721Received's use of depositFor stack variable is redundant", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "If we follow the logic of assigning values to depositFor in CollateralToken.onERC721Received, we notice that it will end up being from_. So its usage is redundant.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "onlyOwner modifier can be defined to simplify the codebase", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "releaseToAddress checks whether the msg.sender is an owner of a collateral. CollateralToken already has a modifier onlyOwner(...), so the initial check in releaseToAddress can be delegated to the modifier.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Document liquidator's role for the protocol", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "When a lien's term end (stack.point.end <= block.timestamp), anyone can call the liquidate on AstariaRouter. There is no restriction on the msg.sender. The msg.sender will be set as the liquidator and if:  The Seaport auction ends (3 days currently, set by the protocol), they can call liquidatorNFTClaim to claim the NFT.  Or if the Seaport auction settles, the liquidator receives the liquidation fee.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Until ASTARIA_ROUTER gets filed for CollateralToken, CollateralToken can not receive ERC721s safely.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "ASTARIA_ROUTER is not set in the CollateralToken's constructor. So till an entity with an author- ity would file for it, CollateralToken is unable to safely receive an ERC721 token ( whenNotPaused and on- ERC721Received would revert).", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "_getMaxPotentialDebtForCollateral might have meant to be an internal function", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "_getMaxPotentialDebtForCollateral is defined as a public function. underscore which as a convention usually is used for internal or private functions.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "return keyword can be removed from stopLiens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "_stopLiens does not return any values but in stopLiens the return statement is used along with the non-existent return value of _stopLiens.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "LienToken's constructor does not set ASTARIA_ROUTER which makes some of the endpoints unfunc- tional", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "LienToken's constructor does not set ASTARIA_ROUTER. That means till an authorized entity calls file to set this parameter, the following functions would be broken/revert:  buyoutLien  _buyoutLien  _payDebt  getBuyout  _getBuyout  _isPublicVault  setPayee, partially broken  _paymentAH  payDebtViaClearingHouse", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Document the approval process for a user's CollateralToken before calling commitToLiens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "In the _executeCommitment's return statement: IVaultImplementation(c.lienRequest.strategy.vault).commitToLien( c, address(this) ); address(this) is the AstariaRouter. The call here to commitToLien enters into _validateCommitment with AstariaRouter as the receiver and so for it to no revert, the holder would have needed to set the approval for the router previously/beforehand: CT.isApprovedForAll(holder, receiver) // needs to be true 83", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "isValidRefinance's return statement can be reformatted", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Currently, it is a bit hard to read the return statement of isValidRefinance.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Withdraw Reserves should always be transferred before Commit to Lien", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "When a new lien is requested, the _beforeCommitToLien() function is called. If the epoch is over, this calls processEpoch(). Otherwise, it calls transferWithdrawReserve(). function _beforeCommitToLien( IAstariaRouter.Commitment calldata params, address receiver ) internal virtual override(VaultImplementation) { VaultData storage s = _loadStorageSlot(); if (timeToEpochEnd() == uint256(0)) { processEpoch(); } else if (s.withdrawReserve > uint256(0)) { transferWithdrawReserve(); } } However, the processEpoch() function will fail if the withdraw reserves haven't been transferred. In this case, it would require the user to manually call transferWithdrawReserve() to fix things, and then request their lien again. Instead, the protocol should transfer the reserves whenever it is needed, and only then call processEpoch().", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Remove owner() variable from withdraw proxies", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "When a withdrawProxy is deployed, it is created with certain immutable arguments. Two of these values are owner() and vault(), and they will always be equal. They seem to be used interchangeably on the withdraw proxy itself, so should be consolidated into one variable.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Unnecessary checks in _validateCommitment", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "In _validateCommitment(), we check to confirm that either the sender of the message is adequately qualified to be making the decision to take a lien against the collateral (ie they are the holder, the operator, etc). However, the way this is checked is somewhat roundabout and can be substantially simplified. For example, we check require(operator == receiver); in a block that is only triggered if we've already validated that receiver != operator.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Comment or remove unused function parameters", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Highlighted functions above take arguments which are never used. particular signature, comment that argument name, otherwise remove that argument completely. If the function has to have a Additional instances noted in Context above.  LienToken.sol#L726 : LienStorage storage s input parameter is not used in _getRemainingInterest. It can be removed and this function can be pure.  VaultImplementation.sol#L341 : incoming is not used buyoutLien, was this variable meant to be used?", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Zero address check can never fail", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The details.borrower != address(0) check will never be false in the current system as AstariaRouter.sol#L352-L354 will revert when ownerOf is address(0).", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "UX differs between Router.commitToLiens and VaultImplementation.commitToLien", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The Router function creates the Collateralized Token while the VaultImplementation requires the collateral owner to ERC721.safeTransferFrom to the CollateralToken contract prior to calling.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Document what vaults are listed by Astaria", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Anyone can call newPublicVault with epochLength in the correct range to create a public vault.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Simplify nested if/else blocks in for loops", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "There are quite a few instances that nested if/else blocks are used in for loops and that is the only block in the for loop. 87 for ( ... ) { if (<CONDITION>) { ... } if else (<CONDITION>) { ... } ... if else (<CONDITION>) { ... } else { revert CustomError(); } }", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Document the role guardian plays in the protocol", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The role of guardian is not documented.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "strategistFee... have not been used can be removed from the codebase.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "strategistFeeNumerator and strategistFeeDenominator are not used except in getStrategist- Fee (which itself also has not been referred to by other contracts). It looks like these have been replaced by the vault fee which gets set by public vault owners when they create the vault.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "redeemFutureEpoch can be called directly from a public vault to avoid using the endpoint from AstariaRouter", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "One can call the redeemFutureEpoch endpoint of the vault directly to avoid the extra gas of juggling assets and multiple contract calls when using the endpoint from AstariaRouter.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Remove unused imports", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "If an imported file is not used, it can be removed.  LienToken.sol#L24 : since Base64 is only imported in this file, if not used it can be removed from the code- base.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Reduce nesting by reverting early", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Code following this pattern: if (<CONDITION>) { <BODY> } else { revert(); } can be simplified to remove nesting using custom errors: if (!<CONDITION>) { revert(); } <BODY> or if using require statements, it can be transformed into: require(<CONDITION>) <BODY>", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "assembly can read constant global variables", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Yul cannot read global variables, but that is not true for a constant variable as its value is embedded in the bytecode. For instance, highlighted code above have the following pattern: bytes32 slot = WITHDRAW_PROXY_SLOT; assembly { s.slot := slot } Here, WITHDRAW_PROXY_SLOT is a constant which can be used directly in assembly code.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Revert with error messages", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "There are many instances of require and revert statements being used without an accompanying error message. Error messages are useful for unit tests to ensure that a call reverted due the intended reason, and helps in identifying the root cause.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Mixed use of require and revert", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Astaria codebase uses a mix of require and revert statements. We suggest only following one of these ways to do conditional revert for standardization.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "tokenURI should revert on non-existing tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "As per ERC721 standard, tokenURI() needs to revert if tokenId doesn't exist. The current code returns empty string for all inputs.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Inheriting the same contract twice", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "VaultImplementation inherits from AstariaVaultBase (reference). Hence, there is no need to inherit AstariaVaultBase in Vault and PublicVault contract as they both inherit VaultImplementation already.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "No need to re-cast variables", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Code above highlights redundant type castings. ERC721 CT = ERC721(address(COLLATERAL_TOKEN())); ... address(msg.sender) These type castings are casting variables to the same type.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Comments do not match implementation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": " Scenario 1 & 2: Comments note where each parameter ends in a packed byte array, or parameter width in bytes. The comments are outdated.  Scenario 3: The unless is not implemented.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Incomplete Natspec", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": " LienToken.sol#L616 s, @return missing  LienToken.sol#L738-L750 s, position, @return missing  CollateralToken.sol#L616-L628 tokenId_ missing 93  VaultImplementation.sol#L153-L165 The second * on /** is missing causing the compiler to ignore the Natspec. The Natspec appears to document an old function interface. Params do not match with the function inputs.  VaultImplementation.sol#L298-L310 missing stack and return vaule  AstariaRouter.sol#L75-L77 @param NatSpec is missing for _WITHDRAW_IMPL, _BEACON_PROXY_IMPL and _- CLEARING_HOUSE_IMPL  AstariaRouter.sol#L44-L47 : Leave a comment that AstariaRouter also acts as an IBeacon for different cloned contracts.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Cannot have multiple liens with same parameters", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "Lien Ids are computed by hashing the Lien struct itself. This means that no two liens can have the same parameters (e.g. same amount, rate, duration, etc.).", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Redundant unchecked can be removed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "There are no arithmetic operations in these unchecked blocks. For clarity, it can be removed.", "labels": ["Spearbit", "Astaria", "Severity: Informational LienToken.sol#L264,"]}, {"title": "Argument name reuse with different meaning across contracts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "ken.LienActionEncumber receiver is the lender (the receiver of the LienToken)", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "Licensing conflict on inherited dependencies", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf", "body": "The version of Solmate contracts depended in tne gpl repository on are AGPL Licensed, making the gpl repository adopt the same license. This license is incompatible with the currently UNLICENSED Astaria related contracts.", "labels": ["Spearbit", "Astaria", "Severity: Informational"]}, {"title": "The castApprovalBySig and castDisapprovalBySig functions can revert", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "The castApprovalBySig and castDisapprovalBySig functions are used to cast an approve or disapprove via an off-chain signature. Within the _preCastAssertions a check is performed against the strategy using msg.sender instead of policy- holder, the strategy (e.g. AbsoluteStrategy) uses that argument to check if the cast sender is a policyholder. isApproval ? actionInfo.strategy.isApprovalEnabled(actionInfo, msg.sender) : actionInfo.strategy.isDisapprovalEnabled(actionInfo, msg.sender); While this works for normal cast, using the ones with signatures will fail as the sender can be anyone who calls the method with the signature signed off-chain.", "labels": ["Spearbit", "Llama", "Severity: Critical Risk"]}, {"title": "The castApproval/castDisapproval doesn't check if role parameter is the approvalRole", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "A policyholder should be able to cast their approval for an action if they have the approvalRole defined in the strategy. It should not be possible for other roles to cast an action. The _castApproval method verifies if the policyholder has the role passed as an argument but doesn't check if it actually has approvalRole which is eligible to cast an approval. This means any role in the llama contract can participate in the approval with completely different quantities (weights). The same problem occurs for the castDisapproval function as well.", "labels": ["Spearbit", "Llama", "Severity: Critical Risk"]}, {"title": "Reducing the quantity of a policyholder results in an increase instead of a decrease in totalQuan- tity", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "In Llama policyholder can approve or disapprove actions. Each policyholder has a quantity which represents their approval casting power. It is possible to update the quantity of individual policyholder with the setRoleHolder function in the LlamaPolicy. The _setRoleHolder method is not handling the decrease of quantity correctly for the totalQuantity. The totalQuantity describes the sum of the quantities of the individual policyholders for a specific role. In the case of a quantity change, the difference is calculated as follows: uint128 quantityDiff = initialQuantity > quantity ? initialQuantity - quantity : quantity - ,! initialQuantity; However, the quantityDiff is always added instead of being subtracted when the quantity is reduced. This results in an incorrect tracking of the totalQuantity. Adding the quantityDiff should only happen in the increase case. See: LlamaPolicy.sol#L388 // case: willHaveRole=true, hadRoleQuantity=true newTotalQuantity = currentRoleSupply.totalQuantity + quantityDiff;", "labels": ["Spearbit", "Llama", "Severity: High Risk"]}, {"title": "LlamaPolicy.revokePolicy cannot be called repeatedly and may result in burned tokens retaining active roles", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "Llama has two distinct revokePolicy functions. The first revokePolicy function removes all roles of a policyholder and burns the associated token. This function iterates over all existing roles, regardless of whether a policyholder still holds the role. In the next step the token is burned. If the total number of roles becomes too high, this transaction might not fit into one block. A second version of the revokePolicy function allows users to pass an array of roles to be removed. This approach should enable the function to be called multiple times, thus avoiding an \"out-of-gas\" error. An out-of-gas error is currently not very likely considering the maximum possible role number of 255. However, the method exists and could be called with a subset of the roles a policyholder. The method contains the following check: if (balanceOf(policyholder) == 0) revert AddressDoesNotHoldPolicy(policyholder); Therefore, it is not possible to call the method multiple times. The result of a call with a subset of roles would lead to an inconsistent state. The token of the policyholder is burned, but the policyholder could still use the remaining roles in Llama. Important methods like LlamaPolicy.hasRole don't check if LlamaPolicy.sol#L250) the token has been burned. (See", "labels": ["Spearbit", "Llama", "Severity: Medium Risk"]}, {"title": "Role, permission, strategy, and guard management or config errors may prevent creating/approving/queuing/executing actions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "LlamaCore deployment from the factory will only succeed if one of the roles is the BOOTSTRAP_ROLE. As the comments note: // There must be at least one role holder with role ID of 1, since that role ID is initially // given permission to call `setRolePermission`. This is required to reduce the chance that an // instance is deployed with an invalid configuration that results in the instance being unusable. // Role ID 1 is referred to as the bootstrap role. There are still several ways a user can misstep and lose access to LlamaCore.  Bootstrap Role Scenarios While the bootstrap role is still needed: 1. Setting an expiry on the bootstrap role's policyholder RoleHolderData and allowing the timestamp to pass. Once passed any caller may remove the BOOTSTRAP_ROLE from expired policyholders. 2. Removing the BOOTSTRAP_ROLE from all policyholders. 3. Revoking the role's permission with setRolePermission(BOOTSTRAP_ROLE, bootstrapPermissionId, false).  General Roles and Permissions Similarly, users may allow other permissions to expire, or remove/revoke them, which can leave the contract in a state where no permissions exist to interact with it. The BOOTSTRAP_- ROLE would need to be revoked or otherwise out of use for this to be a problem.  Misconfigured Strategies A misconfigured strategy may also result in the inability to process new actions. For example: 1. Setting minApprovals too high. 2. Setting queuingPeriod unreasonably high 3. Calling revokePolicy when doing so would make policy.getRoleSupplyAsQuantitySum(approvalRole) fall below minApprovals (or fall below minApprovals - actionCreatorApprovalRoleQty). 1 & 2 but applied to disapprovals. And more, depending on the strategy (e.g. if a strategy always responded true to isActive).  Removal of Strategies It should not be possible to remove the last strategy of a Llama instance It is possible to remove all strategies from an Ilama instance. It would not be possible to create a new action afterward. An action is required to add other strategies back. As a result, the instance would become unusable, and access to funds locked in the Accounts would be lost.  Misconfigured Guards An accidentally overly aggressive guard could block all transactions. There is a built-in protection to prevent guards from getting in the way of basic management if (target == address(this) || target == address(policy)) revert CannotUseCoreOrPolicy();. Again, the BOOTSTRAP_ROLE would need to be revoked or otherwise out of use for this to be a problem.", "labels": ["Spearbit", "Llama", "Severity: Medium Risk"]}, {"title": "LlamaPolicy.hasRole doesn't check if a policyholder holds a token", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "Incorrect usage of the revokePolicy function can result in a case, where the token of a policyholder is already burned but still holds a role. The hasRole function doesn't check if in addition to the role the policyholder still holds the token to be active. The role could still be used in the Llama system.", "labels": ["Spearbit", "Llama", "Severity: Medium Risk"]}, {"title": "Incorrect isActionApproved behavior if new policyholders get added after the createAction in the same block.timestamp", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "Llama utilizes Checkpoints to store approval quantities per timestamp. If the current quantity changes, the previous values are preserved. The block.timestamp of createAction is used as a snapshot for the approval. (See: LlamaCore.sol#L597) Thus, in addition to the Checkpoints, the totalQuantity or numberOfHolders at the createAction are included in the snapshot. However, if new policyholders are added or their quantities change after the createAction within the same block.timestamp, they are not considered in the snapshot but remain eligible to cast an approval. For example, if there are four policyholders together 50% minimum approval: If a new action is created and two policyholders are added subsequently within the same block.timestamp. 9 The numberOfHolders would be 4 in the snapshot instead of 6. All 6 policyholders could participate in the approval, and two approvals would be sufficient instead of 4. Adding new policyholders together with creating a new action could happen easily in a llama script, which allows to bundle different actions. If a separate action is used to add a new policyholder, the final execution happens via a public callable function. An attacker could exploit this by trying to execute the add new policyholder action if a new action is created", "labels": ["Spearbit", "Llama", "Severity: Medium Risk"]}, {"title": "LlamaCore delegate calls can bring Llama into an unusable state", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "The core contract in Llama allows the execution of actions through a delegate_call. An action is executed as a delegate_call when the target is added as an authorizedScript. This enables batching multiple tasks into a contract, which can be executed as a single action. In the delegate_call, a script contract could modify arbitrary any slot of the core contract. The Llama team is aware of this fact and has added additional safety-checks to see if the slot0 has been modified by the delegate_call. The slot0 contains values that should never be allowed to change. bytes32 originalStorage = _readSlot0(); (success, result) = actionInfo.target.delegatecall(actionInfo.data); if (originalStorage != _readSlot0()) revert Slot0Changed(); A script might be intended to modify certain storage slots. However, incorrect SSTORE operations can completely break the contracts. For example, setting actionsCount = type(uint).max would prevent creating any new actions, and access to funds stored in the Account would be lost.", "labels": ["Spearbit", "Llama", "Severity: Medium Risk"]}, {"title": "The execution opcode of an action can be changed from call to delegate_call after approval", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "In Llama an action only defines the target address and the function which should be called. An action doesn't implicitly define if the opcode should be a call or a delegate_call. This only depends on whether the target address is added to authorizedScripts mapping. However, adding a target to the authorizedScripts can be done after the approval in a different action. The authorizedScript action could use a different set of signers with a different approval strategy. The change of adding a target to authorizedScript should not impact actions which are already approved and in the queuing state. This could lead to security issues when policyholders approved the action under the assumption the opcode will be a call instead of a delegate call.", "labels": ["Spearbit", "Llama", "Severity: Medium Risk"]}, {"title": "LlamaFactory is governed by Llama itself", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "Llama uses their own governance system to govern the LlamaFactory contract. The LlamaFactory contract is responsible for authorizing new LlamaStrategies. We can identify several potential drawbacks with this approach. If only a single strategy contract is used and a critical bug is discovered, the implications could be significant. In such a scenario, it would mean a broken strategy contract needs to be used by the Factory governance to deploy a fixed version of the strategy contract or enable other strategies. The likelihood for this to happen is still low but implications could be critical.", "labels": ["Spearbit", "Llama", "Severity: Low Risk"]}, {"title": "The permissionId doesn't include call or delegate-call for LlamaAccount.execute", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "The decision if LlamaAccount.execute is a delegate_call depends on the bool flag parameter withDelegatecall. This parameter is not included in the permissionId, which controls role permissions in Llama. The permissionId in Llama is calculated in the following way: PermissionData memory permission = PermissionData(target, bytes4(data), strategy); bytes32 permissionId = keccak256(abi.encode(permission)); The permissionId required for a role to perform an action only includes the function signature but not the param- eters themselves. It is impossible to define the opcode as part of the permissionId.", "labels": ["Spearbit", "Llama", "Severity: Low Risk"]}, {"title": "Nonconforming EIP-712 typehash", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "Incorrect strings used in computing the EIP-712 typehash. 1. The strings contain space( ) after comma(,) which is not standard EIP-712 behaviour. 2. ActionInfo is not used in typehash. There will be a mismatch when comparing to hashes produced by JS libs or solidity (if implemented), etc.. Not adhering to EIP-712 spec means wallets will not render correctly and any supporting tools will produce a different typehash.", "labels": ["Spearbit", "Llama", "Severity: Low Risk"]}, {"title": "Various events do not add the role as parameter", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "Note: During the audit, the client discovered an issue that affects their offchain infrastructure. Various events do not emit the role as parameter: 1. event ActionCreated(uint256 id, address indexed creator, ILlamaStrategy indexed strategy, address indexed target, uint256 value, bytes data, string description); 2. event ApprovalCast(uint256 id, address indexed policyholder, uint256 quantity, string reason); 3. event DisapprovalCast(uint256 id, address indexed policyholder, uint256 quantity, string reason);", "labels": ["Spearbit", "Llama", "Severity: Low Risk"]}, {"title": "LlamaCore doesn't check if minExecutionTime returned by strategy is in the past", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "The minExecutionTime returned by a strategy is not validated.", "labels": ["Spearbit", "Llama", "Severity: Low Risk"]}, {"title": "Address parsing from tokenId to address string does not account for leading 0s", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "Policy tokenIds are derived from the holder's account address. The address is intended to be displayed in the svg generated when calling tokenURI. Currently, leading 0s are truncated rendering the incorrect address string: e.g. 0x015b... vs 0x0000...be60 for address 0x0000000000015B23C7e20b0eA5eBd84c39dCbE60.", "labels": ["Spearbit", "Llama", "Severity: Low Risk"]}, {"title": "The ALL_HOLDERS_ROLE can be set as a force role by mistake", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "During the initialization, an array of roles that must be assigned as force approval/disapproval can be sent. The logic does not account for ALL_HOLDERS_ROLE (which is role id 0, the default value of uint8) which can be sent as a mistake by the user. This is a low issue as if the above scenario happens, the strategy can become obsolete which will render the owner redeploy the strategy with correct initialization configs. We must mention that the force roles can not be changed after they are set within the initialization.", "labels": ["Spearbit", "Llama", "Severity: Low Risk"]}, {"title": "LlamaPolicy.setRolePermission allows to set permissions for non existing roles", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "It is possible to set a permission for a role that doesn't exist, yet. In other functions like assigning a role to a policyholder, this check happens. (See: LlamaPolicy.sol#L343) A related issue, very close to this, is the updateRoleDescription method which can emit an event for a role that does not exists. This is just an informational issue as it does not affect with anything the on-chain logic, might affect off-chain logic if any logic will ever rely on it.", "labels": ["Spearbit", "Llama", "Severity: Low Risk"]}, {"title": "The RoleAssigned event in LlamaPolicy emits the currentRoleSupply instead of the quantity", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "During the audit, the client discovered an issue that affects their off-chain infrastructure. The RoleAssigned event in LlamaPolicy emits the currentRoleSupply instead of the quantity. From an off-chain perspective, there is currently no way to get the quantity assigned for a role to a policyholder at Role Assignment time. The event would be more useful if it emitted quantity instead of currentRoleSupply (since the latter can be just be calculated off-chain from the former).", "labels": ["Spearbit", "Llama", "Severity: Low Risk"]}, {"title": "ETH can remain in the contract if msg.value is greater than expected", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "When an action is created, the creator can specify an amount of ETH that needs to be sent when executing the transaction. This is necessary in order to forward ETH to a target call. Currently, when executing the action the msg.value is checked to be at least the required amount of ETH needed to be forwarded. if (msg.value < actionInfo.value) revert InsufficientMsgValue(); This can result in ETH remaining in the contract after the execution. From our point of view, LlamaCore should not hold any balance of ETH.", "labels": ["Spearbit", "Llama", "Severity: Low Risk"]}, {"title": "Cannot re-authorize an unauthorized strategy config", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "Strategies are deployed using a create2 salt. The salt is derived from the strategy config itself (see LlamaCore.sol#L709-L710). This means that any unauthorized strategy cannot be used in the future, even if a user decides to re-enable it.", "labels": ["Spearbit", "Llama", "Severity: Low Risk"]}, {"title": "Signed messages may not be cancelled", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "Creating, approving, and disapproving actions may all be done by signing a message and having another account call the relevant *BySig function. Currently, there is no way for a signed message to be revoked without a successful *BySig function call containing the nonce of the message to be revoked.", "labels": ["Spearbit", "Llama", "Severity: Low Risk"]}, {"title": "LlamaCore name open to squatting or impersonation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "When deploying a LlamaCore clone, the create2 salt is derived from the name. This means that no two may have the same name, and name squatting, or impersonation, may occur.", "labels": ["Spearbit", "Llama", "Severity: Low Risk"]}, {"title": "Expired policyholders are active until they are explicitly revoked", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "Each policyholder in Llama has an expiration timestamp. However, policyholder can still use the power of their role after the expiration has passed. The final revoke only happens after the public LlamaPolicy.revokeExpiredRole method is called. Anyone can call this method after the expiration timestamp is passed. For the Llama system to function effectively with role expiration, it is essential that external keepers vigilantly monitor the contract and promptly revoke expired roles. A final revoke exactly at the expiration can not be guaranteed.", "labels": ["Spearbit", "Llama", "Severity: Low Risk"]}, {"title": "Gas optimizations", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "Throughout the codebase we've identified gas improvements that were aggregated into one issue for a better management. RelativeStrategy.sol#L159  The if (disapprovalPolicySupply == 0) revert RoleHasZeroSupply(disapprovalRole); check and actionDisapprovalSupply[actionInfo.id] = disapprovalPolicySupply; can be wrapped in an if block in case disapprovals are enabled  The uint128 newNumberOfHolders; and uint128 newTotalQuantity; variables are obsolete as the up- dates on the currentRoleSupply can be done in the if branches. LlamaPolicy.sol#L380-L392  The exists check is redundant LlamaPolicy.sol#L252  The _validateActionInfoHash(action.infoHash, actionInfo); is redundant as it's already done in the getActionState LlamaCore.sol#L292 LlamaCore.sol#L280 LlamaCore.sol#L672  Finding the BOOTSTRAP_ROLE in the LlamaFactory._deploy could happen by expecting the role at a cer- tain position like position 0 instead of paying gas for an on-chain search operation to iterate the array. LlamaFactory.sol#L205  quantityDiff calculation guaranteed to not overflow as the ternary checks initialQuantity > quantity before subtracting.  Infeasible for numberOfHolders and totalQuantity to overflow. See also LlamaPolicy.sol#L422-L423  Infeasible for numberOfHolders to overflow.", "labels": ["Spearbit", "Llama", "Severity: Gas Optimization"]}, {"title": "Unused code", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "Various parts of the code is unused or unnecessary.  CallReverted and MissingAdmin in LlamaPolicy.sol#L27-L29  DisapprovalThresholdNotMet in RelativeStrategy.sol#L28  Unused errors in LlamaCore.sol InvalidCancelation, ProhibitedByActionGuard, ProhibitedByStrategy, ProhibitedByStrategy(bytes32 reason) and RoleHasZeroSupply(uint8 role)  /// - Action creators are not allowed to cast approvals or disapprovals on their own actions, The comment is inaccurate, this strategy, the creators have no restrictions on their actions. RelativeStrategy.sol#L19 17", "labels": ["Spearbit", "Llama", "Severity: Gas Optimization"]}, {"title": "Duplicate storage reads and external calls", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "When creating, approving, disapproving, queuing, and executing actions, there are calls between the various contracts in the system. Due to the external calls, the compiler will not cache storage reads, meaning the gas cost of warm sloads is incurred multiple times. The same is true for view function calls between the contracts. A number of these calls are returning the same value multiple times in a transaction.", "labels": ["Spearbit", "Llama", "Severity: Gas Optimization"]}, {"title": "Consider clones-with-immutable-args", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "The cloned contracts have immutable values that are written to storage on initialization due to proxies being used. Reading from storage costs extra gas but also puts some of the storage values at risk of being overwritten when making delegate calls.", "labels": ["Spearbit", "Llama", "Severity: Gas Optimization"]}, {"title": "The domainSeperator may be cached", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "The domainSeperator is computed for each use. Some gas may be saved by using caching and deferring to the cached value.", "labels": ["Spearbit", "Llama", "Severity: Gas Optimization"]}, {"title": "Prefer on-chain SVGs or IPFS links over server links for contractURI", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "Llama uses on-chain SVG for LlamaPolicy.tokenURI. The same could be implemented for LlamaPolicy.contractURI as well. In general IPFS links or on-chain SVG for visual representations provide better properties than centralized server links.", "labels": ["Spearbit", "Llama", "Severity: Informational"]}, {"title": "Consider making the delegate-call scripts functions only callable by delegate-call", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "An additional safety check could be added to scripts if a function should be only callable via a delegate-call.", "labels": ["Spearbit", "Llama", "Severity: Informational"]}, {"title": "Missing tests for SingleUseScript.sol", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "There are no tests for SingleUseScript.sol in Llama.", "labels": ["Spearbit", "Llama", "Severity: Informational"]}, {"title": "Role not available to Guards", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "Use cases where Guards require knowing the creation or approval role for the action are not sup- ported. ActionInfo does reference the strategy, and the two implemented strategies do have public functions referencing the approvalRole, allowing for a workaround. However, this is not mandated by the ILlamaStrategy interface and is not guaranteed to be present in future strategies.", "labels": ["Spearbit", "Llama", "Severity: Informational"]}, {"title": "Global guards are not supported", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "Other protocols use of guards applies them to the account (i.e. globally). In other words, if global guards existed and if there are some properties you know to apply to the entire LlamaCore instance a global guard could be applied. The current implementation allows granular control, but it also requires granular control with no ability to set global guards.", "labels": ["Spearbit", "Llama", "Severity: Informational"]}, {"title": "Consider using _disableInitializers in constructor", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "OpenZeppelin added the _disableInitializers() in 4.6.0 which prevents initialization of the im- plementation contract and recommends its use.", "labels": ["Spearbit", "Llama", "Severity: Informational"]}, {"title": "Revoking and setting a role edge cases", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "This issue highlights a number of edge-case behaviors 1. Calling setRoleHolder passing in an account with balanceOf == 0, 0 quantity, and 0 expiration results in minting the NFT. 2. Revoking all policies through revokeExpiredRole leaves an address with no roles except for the ALL_- HOLDERS_ROLE and a balanceOf == 1. 3. Revoking may be conducted on policies the address does not have (building on the previous scenario):  Alice is given role 1 with expiry.  Expiry passes.  Anyone calls revokeExpiredRole.  Role is revoked but Alice still has balanceOf == 1.  LlamaCore later calls revokePolicy with roles array of [2].  A role Alice never had is revoked.  The NFT is burned.", "labels": ["Spearbit", "Llama", "Severity: Informational"]}, {"title": "Use built in string.concat", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "The solidity version used has a built-in string.concat which can replace the instances of string(abi.encodePacked(...). The client notes there are no gas implications of this change while the change does offer semantic clarity.", "labels": ["Spearbit", "Llama", "Severity: Informational"]}, {"title": "Inconsistencies", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "Throughout the codebase, we've encountered some inconsistencies that we decided to point out. for(uint256 i = 0... is not used everywhere e.g. AbsoluteStrategy.sol#L130  Sometimes, a returned value is not named. e.g. named return value function createAction( uint8 role, ILlamaStrategy strategy, address target, uint256 value, bytes calldata data, string memory description ) external returns (uint256 actionId) { unnamed return value function createActionBySig( uint8 role, ILlamaStrategy strategy, address target, uint256 value, bytes calldata data, address policyholder, uint8 v, bytes32 r, bytes32 s ) external returns (uint256) {  Missing NatSpec on various functions. e.g. LlamaPolicy.sol#L102  _uncheckedIncrement is not used everywhere.  Naming of modifiers In all contracts the onlyLlama modfiier only refers to the llamaCore. The only exception is LlamaPolicyMetadataParamRegistry which has the same name but refers to llamaCore and rootLlama but is called onlyLlama. See LlamaPolicyMetadataParamRegistry.sol#L16  Console.log debug output in RelativeStrategy console.log in RelativeStrategy See: RelativeStrat- egy.sol#L215  In GovernanceScript.sol both of SetRolePermission and SetRoleHolder mirror structs defined in the shared lib/Structs.sol file. Additionally, some contracts declare their own structs over inheriting all structs from lib/Structs.sol:  LlamaAccount  GovernanceScript  LlamaPolicy Recommend removing duplicate structs and, where relevant, continue making use of the shared Structs.sol for struct definitions.", "labels": ["Spearbit", "Llama", "Severity: Informational"]}, {"title": "Policyholders with large quantities may not both create and exercise their large quantity for the same action", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "The AbsoluteStrategy removes the action creator from the set of policyholders who may approve / disapprove an action. This is a departure from how the RelativeStrategy handles action creators. Not permitting action creators to approve / disapprove is simple to reason about when each policyholder has a quantity of 1; creating can even be thought of an implicit approval and may be factored in when choosing a minApprovals value. However, in scenarios where a policyholder has a large quantity (in effect a large weight to their casted approval), creating an action means they forfeit the use of the vast majority of their quantity for that particular action.", "labels": ["Spearbit", "Llama", "Severity: Informational"]}, {"title": "The roleBalanceCheckpoints can run out of gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "The roleBalanceCheckpoints function returns the Checkpoints history of a balance. This check will copy into memory the whole history which can end up in a out of gas error. This is an informational issue as this function was designed for off-chain usage and the caller can use eth_call with a higher gas limit.", "labels": ["Spearbit", "Llama", "Severity: Informational"]}, {"title": "GovernanceScript.revokeExpiredRoles should be avoided in favor of calling LlamaPol- icy.revokeExpiredRole from EOA", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "GovernanceScript.revokeExpiredRoles is intended to be delagate called from LlamaCore. Given that LlamaPolicy.revokeExpiredRole is already public and without access controls, it will always be cheaper, and less complex, to call directly from an EOA or batching a multicall, again from an EOA.", "labels": ["Spearbit", "Llama", "Severity: Informational"]}, {"title": "The InvalidActionState can be improved", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "Currently, the InvalidActionState includes the expected state as an argument, this is unnecessary as you can derive the state from the method call, would make more sense to take the current state instead of the expected state.", "labels": ["Spearbit", "Llama", "Severity: Informational"]}, {"title": "_uncheckedIncrement function written in multiple contracts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf", "body": "Multiple contracts make use of an _uncheckedIncrementfunction and each duplicates the function definition. Similarly the slot0 function appears in both LlamaAccount and LlamaCore and _toUint64 appears in the two strategy contracts plus LlamaCore.", "labels": ["Spearbit", "Llama", "Severity: Informational"]}, {"title": "Side effects of LTV = 0 assets: Morpho's users will not be able to withdraw (collateral and \"pure\" supply), borrow and liquidate", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "When an AToken has LTV = 0, Aave restricts the usage of some operations. In particular, if the user owns at least one AToken as collateral that has LTV = 0, operations could revert. 1) Withdraw: if the asset withdrawn is collateral, the user is borrowing something, the operation will revert if the withdrawn collateral is an AToken with LTV > 0. 2) Transfer: if the from is using the asset as collateral, is borrowing something and the asset transferred is an AToken with LTV > 0 the operation will revert. 3) Set the reserve of an AToken as not collateral: if the AToken you are trying to set as non-collateral is an AToken with LTV > 0 the operation will revert. Note that all those checks are done on top of the \"normal\" checks that would usually prevent an operation, de- pending on the operation itself (like, for example, an HF check). While a \"normal\" Aave user could simply withdraw, transfer or set that asset as non-collateral, Morpho, with the current implementation, cannot do it. Because of the impossibility to remove from the Morpho wallet the \"poisoned AToken\", part of the Morpho mechanics will break.  Morpho's users could not be able to withdraw both collateral and \"pure\" supply  Morpho's users could not be able to borrow  Morpho's users could not be able to liquidate  Morpho's users could not be able to claim rewards via claimRewards if one of those rewards is an AToken with LTV > 0", "labels": ["Spearbit", "Morpho-Av3", "Severity: Critical Risk"]}, {"title": "Morpho is vulnerable to attackers sending LTV = 0 collateral tokens, supply/supplyCollateral, bor- row and liquidate operations could stop working", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "When an AToken has LTV = 0, Aave restricts the usage of some operations. In particular, if the user owns at least one AToken as collateral that has LTV = 0, these operations could revert 1) Withdraw: if the asset withdrawn is collateral, the user is borrowing something, the operation will revert if the withdrawn collateral is an AToken with LTV > 0 2) Transfer: if the from is using the asset as collateral, is borrowing something and the asset transferred is an AToken with LTV > 0 the operation will revert 3) Set the reserve of an AToken as not collateral: if the AToken you are trying to set as non-collateral is an AToken with LTV > 0 the operation will revert Note that all those checks are done on top of the \"normal\" checks that would usually prevent an operation, de- pending on the operation itself (like, for example, an HF check). In the attack scenario, the bad actor could simply supply an underlying that is associated with an LTV = 0 AToken and transfer it to the Morpho contract. If the victim does not own any balance of the asset, it will be set as collateral and the victim will suffer from all the side effects previously explained. While a \"normal\" Aave user could simply withdraw, transfer or set that asset as non-collateral, Morpho, with the current implementation, cannot do it. Because of the impossibility to remove from the Morpho wallet the \"poisoned AToken\", part of the Morpho mechanics will break.  Morpho's users could not be able to withdraw both collateral and \"pure\" supply. 6  Morpho's users could not be able to borrow.  Morpho's users could not be able to liquidate.  Morpho's users could not be able to claim rewards via claimRewards if one of those rewards is an AToken with LTV > 0.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Critical Risk"]}, {"title": "Morpho is not correctly handling the asset price in _getAssetPrice when isInEMode == true but priceSource is addres(0)", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "The current implementation of _getAssetPrice returns the asset's price based on the value of isInEMode function _getAssetPrice(address underlying, IAaveOracle oracle, bool isInEMode, address priceSource) internal view returns (uint256) if (isInEMode) { uint256 eModePrice = oracle.getAssetPrice(priceSource); if (eModePrice != 0) return eModePrice; } return oracle.getAssetPrice(underlying); { } As you can see from the code, if isInEMode is equal to true they call oracle.getAssetPrice no matter what the value of priceSource that could be address(0). 7 If we look inside the AaveOracle implementation, we could assume that in the case where asset is address(0) (in this case, Morpho pass priceSource _getAssetPrice parameter) it would probably return _fallbackOra- cle.getAssetPrice(asset). In any case, the Morpho logic diverges compared to what Aave implements. On Aave, if the user is not in e-mode, the e-mode oracle is address(0) or the asset's e-mode is not equal to the user's e-mode (in case the user is in e-mode), Aave always uses the asset price of the underlying and not the one in the e-mode priceSource. The impact is that if no explicit eMode oracle has been set, Morpho might revert in price computations, breaking liquidations, collateral withdrawals, and borrows if the fallback oracle does not support the asset, or it will return the fallback oracle's price which is different from the price that Aave would use.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Critical Risk"]}, {"title": "Isolated assets are treated as collateral in Morpho", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "Aave-v3 introduced isolation assets and isolation mode for users: \"Borrowers supplying an isolated asset as collateral cannot supply other assets as collateral (though they can still supply to capture yield). Only stablecoins that have been permitted by Aave governance to be borrowable in isolation the mode can be borrowed by users utilizing isolated collateral up to a specified debt ceiling.\" The Morpho contract is intended not to be in isolation mode to avoid its restrictions. Supplying an isolated asset to Aave while there are already other (non-isolated) assets set as collateral will simply supply the asset to earn yield without setting it as collateral. However, Morpho will still set these isolated assets as collateral for the supplying user. Morpho users can borrow any asset against them which should not be possible:  Isolated assets are by definition riskier when used as collateral and should only allow borrowing up to a specific debt ceiling.  The borrows are not backed on Aave as the isolated asset is not treated as collateral there, lowering the Morpho Aave position's health factor and putting the system at risk of liquidation on Aave.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Critical Risk"]}, {"title": "Morpho's logic to handle LTV = 0 AToken diverges from the Aave logic and could decrease the user's HF/borrowing power compared to what the same user would have on Aave", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "The current implementation of Morpho has a specific logic to handle the scenario where Aave sets the asset's LTV to zero. We can see how Morpho is handling it in the _assetLiquidityData function function _assetLiquidityData(address underlying, Types.LiquidityVars memory vars) internal view returns (uint256 underlyingPrice, uint256 ltv, uint256 liquidationThreshold, uint256 tokenUnit) { ,! } // other function code... // If the LTV is 0 on Aave V3, the asset cannot be used as collateral to borrow upon a breaking withdraw. // In response, Morpho disables the asset as collateral and sets its liquidation threshold // to 0 and the governance should warn users to repay their debt. if (config.getLtv() == 0) return (underlyingPrice, 0, 0, tokenUnit); // other function code... The _assetLiquidityData function is used to calculate the number of assets a user can borrow and the maximum debt a user can reach before being liquidated. Those values are then used to calculate the user Health Factor. The Health Factor is used to  Calculate both if a user can be liquidated and in which percentage the collateral can be seized.  Calculate if a user can withdraw part of his/her collateral. The debt and borrowable amount are used in the Borrowing operations to know if a user is allowed to borrow the specified amount of tokens. On Aave, this situation is handled differently. First, there's a specific distinction when the liquidation threshold is equal to zero and when the Loan to Value of the asset is equal to zero. Note that Aave enforces (on the configuration setter of a reserve) that ltv must be <= of liquidationThreshold, this implies that if the LT is zero, the LTV must be zero. In the first case (liquidation threshold equal to zero) the collateral is not counted as collateral. This is the same behavior followed by Morpho, but the difference is that Morpho also follows it when the Liquidation Threshold is greater than zero. In the second case (LT > 0, LTV = 0) Aave still counts the collateral as part of the user's total collateral but does not increase the user's borrowing power (it does not increase the average LTV of the user). This influences the user's health factor (and so all the operations based on it) but not as impactfully as Morpho is doing. In conclusion, when the LTV of an asset is equal to zero, Morpho is not applying the same logic as Aave is doing, removing the collateral from the user's collateral and increasing the possibility (based on the user's health factor, user's debt, user's total collateral and all the asset's configurations on Aave) to  Deny a user's collateral withdrawal (while an Aave user could have done it).  Deny a user's borrow (while an Aave user could have done it).  Make a user liquidable (while an Aave user could have been healthy).  Increasing the possibility to allow the liquidator to seize the full collateral of the borrower (instead of 50%). 9", "labels": ["Spearbit", "Morpho-Av3", "Severity: High Risk MorphoInternal.sol#L324,"]}, {"title": "RewardsManager does not take in account users that have supplied collateral directly to the pool", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "Inside RewardsManager._getUserAssetBalances Morpho is calculating the amount of the supplied and borrowed balance for a specific user. In the current implementation, Morpho is ignoring the amount that the user has supplied as collateral directly into the Aave pool. As a consequence, the user will be eligible for fewer rewards or even zero in the case where he/she has supplied only collateral.", "labels": ["Spearbit", "Morpho-Av3", "Severity: High Risk"]}, {"title": "Accounting issue when repaying P2P fees while having a borrow delta", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "When repaying debt on Morpho, any potential borrow delta is matched first. Repaying the delta should involve both decreasing the scaledDelta as well as decreasing the scaledP2PAmount by the matched amount. [1] However, the scaledP2PAmount update is delayed until the end of the repay function. The following repayFee call then reads the un-updated market.deltas.borrow.scaledP2PAmount storage variable leading to a larger estimation of the P2P fees that can be repaid. The excess fee that is repaid will stay in the contract and not be accounted for, when it should have been used to promote borrowers, increase idle supply or demote suppliers. For example, there could now be P2P suppliers that should have been demoted but are not and in reality don't have any P2P counterparty, leaving the entire accounting system in a broken state.  Example (all values are in underlying amounts for brevity.) Imagine a borrow delta of 1000, borrow.scaledP2PTotal = 10,000 supply.scaledP2PTotal = 8,000, so the repayable fee should be (10,000 - 1000) - (8,000 - 0) = 1,000. Now a P2P borrower wants to repay 3000 debt: 1. Pool repay: no pool repay as they have no pool borrow balance. 2. Decrease p2p borrow delta: decreaseDelta is called which sets market.deltas.borrow.scaledDelta = 0 (but does not update market.deltas.borrow.scaledP2PAmount yet!) and returns matchedBorrowDelta = 1000 3. repayFee is called and it computes (10,000 - 0) - (8,000 - 1,000) = 2,000. They repay more than the actual fee.", "labels": ["Spearbit", "Morpho-Av3", "Severity: High Risk"]}, {"title": "Repaying with ETH does not refund excess", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "Users can repay WETH Morpho positions with ETH using the WETHGateway. The specified repay amount will be wrapped to WETH before calling the Morpho function to repay the WETH debt. However, the Morpho repay function only pulls in Math.min(_getUserBorrowBalanceFromIndexes(underlying, onBehalf, indexes), amount). If the user specified an amount larger than their debt balance, the excess will be stuck in the WETHGateway contract. This might be especially confusing for users because the standard Morpho.repay function does not have this issue and they might be used to specifying a large, round value to be sure to repay all principal and accrued debt once the transaction is mined.", "labels": ["Spearbit", "Morpho-Av3", "Severity: High Risk"]}, {"title": "Morpho can end up in isolation mode", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "Aave-v3 introduced isolation assets and isolation mode for users: \"Borrowers supplying an isolated asset as collateral cannot supply other assets as collateral (though they can still supply to capture yield). Only stablecoins that have been permitted by Aave governance to be borrowable in isolation the mode can be borrowed by users utilizing isolated collateral up to a specified debt ceiling.\" The Morpho contract has a single Aave position for all its users and does therefore not want to end up in isolation mode due to its restrictions. The Morpho code would still treat the supplied non-isolation assets as collateral for their Morpho users, allowing them to borrow against them, but the Aave position does not treat them as collateral anymore. Furthermore, Morpho can only borrow stablecoins up to a certain debt ceiling. Morpho can be brought into isolation mode:  Up to deployment, an attacker maliciously sends an isolated asset to the address of the proxy. Aave sets assets as collateral when transferred, such that the Morpho contract already starts out in isolation mode. This can even happen before deployment by precomputing addresses or simply frontrunning the deployment. This attack also works if Morpho does not intend to create a market for the isolated asset.  Upon deployment and market creation: An attacker or unknowing user is the first to supply an asset and this asset is an isolated asset, Morpho's Aave position automatically enters isolation mode.  At any time if an isolated asset is the only collateral asset. This can happen when collateral assets are turned off on Aave, for example, by withdrawing (or liquidating) the entire balance.", "labels": ["Spearbit", "Morpho-Av3", "Severity: High Risk"]}, {"title": "Collateral setters for Morpho / Aave can end up in a deadlock", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "One can end up in a deadlock where changing the Aave pool or Morpho collateral state is not possible anymore because it can happen that Aave automatically turns the collateral asset off (for example, when withdrawing everything / getting liquidated). Imagine a collateral asset is turned on for both protocols: setAssetIsCollateralOnPool(true) setAssetIsCollateral(true) Then, a user withdraws everything on Morpho / Aave, and Aave automatically turns it off. It's off on Aave but on on Morpho. It can't be turned on for Aave anymore because: if (market.isCollateral) revert Errors.AssetIsCollateralOnMorpho(); But it also can't be turned off on Morpho anymore because of: if (!_pool.getUserConfiguration(address(this)).isUsingAsCollateral(_pool.getReserveData(underlying).id) ) { revert Errors.AssetNotCollateralOnPool(); ,! ,! } c This will be bad if new users deposit after having withdrawn the entire asset. The asset is collateral on Morpho but not on Aave, breaking an important invariant that could lead to liquidating the Morpho Aave position.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Medium Risk"]}, {"title": "First reward claim is zero for newly listed reward tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "When Aave adds a new reward token for an asset, the reward index for this (asset, reward) pair starts at 0. When an update in Morpho's reward manager occurs, it initializes all rewards for the asset and would initialize this new reward token with a startingIndex of 0. 1. Time passes and emissions accumulate to all pool users, resulting in a new index assetIndex. Users who deposited on the pool through Morpho before this reward token was listed should receive their fair share of the entire emission rewards (assetIndex - 0) * oldBalance but they currently receive zero because getRewards returns early if the user's computed index is 0. 2. Also note that the external getUserAssetIndex(address user, address asset, address reward) can be inaccurate because it doesn't simulate setting the startingIndex for reward tokens that haven't been set yet. 3. A smaller issue that can happen when new reward tokens are added is that updates to the startingIndex are late, the startingIndex isn't initialized to 0 but to some asset index that accrued emissions for some time. Morpho on-pool users would lose some rewards until the first update to the asset. (They should accrue from index 0 but accrue from startingIndex.) Given frequent calls to the RewardManager that initializes all rewards for an asset, this difference should be negligible.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Medium Risk"]}, {"title": "Disable creating markets for siloed assets", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "Aave-v3 introduced siloed-borrow assets and siloed-borrow mode for users \"This feature allow assets with potentially manipulatable oracles (for example illiquid Uni V3 pairs) to be listed on Aave as single borrow asset i.e. if user borrows siloed asset, they cannot borrow any other asset. This helps mitigating the risk associated with such assets from impacting the overall solvency of the protocol.\" - Aave Docs The Morpho contract should not be in siloed-borrowing mode to avoid its restrictions on borrowing any other listed assets, especially as borrowing on the pool might be required for withdrawals. If a market for the siloed asset is created at deployment, users might borrow the siloed asset and break borrowing any of the other assets.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Medium Risk"]}, {"title": "A high value of _defaultIterations could make the withdrawal and repay operations revert because of OOG", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "When the user executes some actions, he/she can specify their own maxIterations parameter. The user maxIterations parameter is directly used in supplyLogic and borrowLogic. In the withdrawLogic Morpho is recalculating the maxIterations to be used internally as Math.max(_default- Iterations.withdraw, maxIterations) and in repayLogic is directly using _defaultIterations.repay as the max number of iterations. This parameter is used as the maximum number of iterations that the matching engine can do to match suppli- ers/borrowers during promotion/demotion operations. 15 function _promoteOrDemote( LogarithmicBuckets.Buckets storage poolBuckets, LogarithmicBuckets.Buckets storage p2pBuckets, Types.MatchingEngineVars memory vars ) internal returns (uint256 processed, uint256 iterationsDone) { if (vars.maxIterations == 0) return (0, 0); uint256 remaining = vars.amount; // matching engine code... for (; iterationsDone < vars.maxIterations && remaining != 0; ++iterationsDone) { // matching engine code (onPool, inP2P, remaining) = vars.step(...); // matching engine code... } // matching engine code... } As you can see, the iteration keeps going on until the matching engine has matched enough balance or the iterations have reached the maximum number of iterations. If the matching engine cannot match enough balance, it could revert because of OOG if vars.maxIterations is a high value. For the supply or borrow operations, the user is responsible for the specified number of iterations that might be done during the matching process, in that case, if the operations revert because of OGG, it's not an issue per se. The problem arises for withdraw and replay operations where Morpho is forcing the number of operations and could make all those transactions always revert in case the matching engine does not match enough balance in time. Keep in mind that even if the transaction does not revert during the _promoteOrDemote logic, it could revert during the following operations just because the _promoteOrDemote has consumed enough gas to make the following operations to use the remaining gas.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Medium Risk"]}, {"title": "Morpho should check that the _positionsManager used has the same _E_MODE_CATEGORY_ID and _- ADDRESSES_PROVIDER values used by the Morpho contract itself", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "Because _E_MODE_CATEGORY_ID and _ADDRESSES_PROVIDER are immutable variables and because Morpho is calling the PositionsManager in a delegatecall context, it's fundamental that both Morpho and Posi- tionsManager have been initialized with the same _E_MODE_CATEGORY_ID and _ADDRESSES_PROVIDER values. Morpho should also check the value of the PositionsManager._E_MODE_CATEGORY_ID and PositionsManager._- ADDRESSES_PROVIDER in both the setPositionsManager and initialize function.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Medium Risk"]}, {"title": "In _authorizeLiquidate, when healthFactor is equal to Constants.DEFAULT_LIQUIDATION_THRESHOLD Morpho is wrongly setting close factor to DEFAULT_CLOSE_FACTOR", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "When the borrower's healthFactor is equal to Constants.MIN_LIQUIDATION_THRESHOLD Morpho is returning the wrong value for the closeFactor allowing only liquidate 50% of the collateral instead of the whole amount. When the healthFactor is lower or equal to the Constants.MIN_LIQUIDATION_THRESHOLD Morpho should return Constants.MAX_CLOSE_FACTOR following the same logic applied by Aave. Note that the user cannot be liquidated even if healthFactor == MIN_LIQUIDATION_THRESHOLD if the priceOr- acleSentinel is set and IPriceOracleSentinel(params.priceOracleSentinel).isLiquidationAllowed() == false. See how Aave performs the check inside validateLiquidationCall.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Medium Risk"]}, {"title": "_authorizeBorrow does not check if the Aave price oracle sentinel allows the borrowing operation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "Inside the Aave validation logic for the borrow operation, there's an additional check that prevents the user from performing the operation if it has been not allowed inside the priceOracleSentinel require( params.priceOracleSentinel == address(0) || IPriceOracleSentinel(params.priceOracleSentinel).isBorrowAllowed(), Errors.PRICE_ORACLE_SENTINEL_CHECK_FAILED ); 17 Morpho should implement the same check. If for any reason the borrow operation has been disabled on Aave, it should also be disabled on Morpho itself. While the transaction would fail in case Morpho's user would need to perform the borrow on the pool, there could be cases where the user is completely matched in P2P. In those cases, the user would have performed a borrow even if the borrow operation was not allowed on the underlying Aave pool.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Medium Risk"]}, {"title": "_updateInDS does not \"bubble up\" the updated values of onPool and inP2P", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "The _updateInDS function takes as input uint256 onPool and uint256 inP2P that are passed not as reference, but as pure values. function _updateInDS( address poolToken, address user, LogarithmicBuckets.Buckets storage poolBuckets, LogarithmicBuckets.Buckets storage p2pBuckets, uint256 onPool, uint256 inP2P, bool demoting ) internal { if (onPool <= Constants.DUST_THRESHOLD) onPool = 0; if (inP2P <= Constants.DUST_THRESHOLD) inP2P = 0; // ... other logic of the function } Those values, if lower or equal to Constants.DUST_THRESHOLD will be set to 0. The issue is that the updated version of onPool and inP2P is never bubbled up to the original caller that will later use those values that could have been changed by the _updateInDS logic. For example, the _updateBorrowerInDS function call _updateInDS and relies on the value of onPool and inP2P to understand if the user should be removed or added to the list of borrowers. function _updateBorrowerInDS(address underlying, address user, uint256 onPool, uint256 inP2P, bool ,! demoting) internal { _updateInDS( _market[underlying].variableDebtToken, user, _marketBalances[underlying].poolBorrowers, _marketBalances[underlying].p2pBorrowers, onPool, inP2P, demoting ); if (onPool == 0 && inP2P == 0) _userBorrows[user].remove(underlying); else _userBorrows[user].add(underlying); } 18 Let's assume that inP2P and onPool passed as _updateBorrowerInDS inputs were equal to 1 (the value of DUST_- THRESHOLD). In this case, _updateInDS would update those values to zero because 1 <= DUST_THRESHOLD and would remove the user from both the poolBucket and p2pBuckets of the underlying. When then the function returns in the _updateBorrowerInDS context, the same user would not remove the under- lying from his/her _userBorrows list of assets because the updated values of onPool and inP2P have not been bubbled up by the _updateInDS function. The same conclusion could be made for all the \"root\" level codes that rely on the onPool and inP2P values that could not have been updated with the new 0 value set by _updateInDS.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Low Risk"]}, {"title": "There is no guarantee that the _rewardsManager is set when calling claimRewards", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "Since the _rewardsManager address is set using a setter function in Morpho only and not in the MorphoStorage.sol constructor there is no guarantee that the _rewardsManager is not the default address(0) value. This could cause failures when calling claimRewards if Morpho forgets to set the _rewardsManager.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Low Risk"]}, {"title": "Its Impossible to set _isClaimRewardsPaused", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "The claimRewards function checks the isClaimRewardsPaused boolean value and reverts if it is true. Currently, there is no setter function in the code base that sets the _isClaimRewardsPaused boolean so it is impossible to change.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Low Risk"]}, {"title": "User rewards can be claimed to treasury by DAO", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "When a user claims rewards, the rewards for the entire Morpho contract position on Aave are claimed. The excess rewards remain in the Morpho contract for until all users claimed their rewards. These rewards are not tracked and can be withdrawn by the DAO through a claimToTreasury call.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Low Risk"]}, {"title": "decreaseDelta lib function should return early if amount == 0", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "The passed in amount should be checked for a zero value, and in that condition, return early from the function. The way it currently is unnecessarily consumes more gas, and emits change events that for values that don't end up changing (newScaledDelta). Checking for amount == 0 is already being done in the increaseDelta function.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Gas Optimization"]}, {"title": "Smaller gas optimizations", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "There are several small expressions that can be further gas optimized.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Gas Optimization"]}, {"title": "Gas: Optimize LogarithmicBuckets.getMatch", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "The getMatch function of the logarithmic bucket first checks for a bucket that is the next higher bucket If no higher bucket is found it searches for a bucket that is the than the bucket the provided value would be in. highest bucket that \"is in both bucketsMask and lowerMask.\" However, we already know that any bucket we can now find will be in lowerMask as lowerMask is the mask corresponding to all buckets less than or equal to value's bucket. Instead, we can just directly look for the highest bucket in bucketsMask.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Gas Optimization"]}, {"title": "Consider reverting the supplyCollateralLogic execution when amount.rayDivDown(poolSupplyIndex) is equal to zero", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "In Aave, when an AToken/VariableDebtToken is minted or burned, the transaction will revert if the amount divided by the index is equal to zero. You can see the check in the implementation of _mintScaled and _burnScaled functions in the Aave codebase. Morpho, with PR 688, has decided to prevent supply to the pool in this scenario to avoid a revert of the operation. Before the PR, if the user had supplied an amount for which amount.rayDivDown(poolSupplyIndex) would be equal to zero, the operation would have reverted at the Aave level during the mint operation of the AToken. With the PR, the operation will proceed because the supply to the Aave pool is skipped (see PoolLib.supplyToPool). Allowing this scenario in this specific context for the supplyCollateralLogic function will bring the following side effects:  The supplied user's amount will remain in Morpho's contract and will not be supplied to the Aave pool.  The user's accounting system is not updated because collateralBalance is increased by amount.rayDivDown(poolSupplyIndex) which is equal to zero. 21  If the marketBalances.collateral[onBehalf] was equal to zero (the user has never supplied the underly- ing to Morpho) the underlying token would be wrongly added to the _userCollaterals[onBehalf] storage, even if the amount supplied to Morpho (and to Aave) is equal to zero.  The user will not be able to withdraw the provided amount because the amount has not been accounted for in the storage.  Events.CollateralSupplied event is emitted even if the amount (used as an event parameter) has not been accounted to the user.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Informational"]}, {"title": "WETHGateway does not validate the constructor's input parameters", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "The current implementation of the WETHGateway contracts does not validate the user's parameters during the constructor. In this specific case, the constructor should revert if morpho address is equal to ad- dress(0).", "labels": ["Spearbit", "Morpho-Av3", "Severity: Informational"]}, {"title": "Missing/wrong natspec, typos, minor refactors and renaming of variables to be more meaningful", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "In general, the current codebase does not cover all the functions, events, structs, or state variables with proper natspec. Below you can find a list of small specific improvements regarding typos, missing/wrong natspec, or suggestions to rename variables to a more meaningful/correct name  RewardsManager.sol#L28: consider renaming the balance variable in UserAssetBalance to scaledBalance  PositionsManagerInternal.sol#L289-L297, PositionsManagerInternal.sol#L352-L362: consider better docu- menting this part of the code because at first sight it's not crystal clear why the code is structured in this way. For more context, see the PR comment in the spearbit audit repo linked to it. 22  MorphoInternal.sol#L469-L521: consider moving the _calculateAmountToSeize function from MorphoInt- ernal to PositionsManagerInternal contract. This function is only used internally by the PositionsMan- agerInternal. Note that there could be more instances of these kinds of \"refactoring\" of the code inside other contracts.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Informational"]}, {"title": "No validation checks on the newDefaultIterations struct", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "The initialize function takes in a newDefaultIterations struct and does not perform validation for any of its fields.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Informational"]}, {"title": "No validation check for newPositionsManager address", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "The initialize function does not ensure that the newPositionsManager is not a 0 address.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Informational"]}, {"title": "Missing Natspec function documentation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "The repayLogic function currently has Natspec documentation for every function argument except for the repayer argument.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Informational"]}, {"title": "approveManagerWithSig user experience could be improved", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "With the current implementation of the approveManagerWithSig signers must wait that the previous signers have consumed the nonce to be able to call approveManagerWithSig. Inside the function, there's a specific check that will revert if the signature has been signed with a nonce that is not equal to the current one assigned to the delegator, this means that signatures that use \"future\" nonce will not be able to be approved until previous nonce has been consumed. uint256 usedNonce = _userNonce[signatory]++; if (nonce != usedNonce) revert Errors.InvalidNonce(); Let's make an example: delegator want to allow 2 managers via signature 1) Generate sig_0 for manager1 with nonce_0. 2) Generate sig_1 for manager2 with nonce_1. 3) If no-one executes approveManagerWithSig(sig_0) the sig_1 (and all the signatures based on incremented nonces) cannot be executed. It's true that at some point someone/the signer will execute it.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Informational"]}, {"title": "Missing user markets check when liquidating", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "The liquidation does not check if the user who gets liquidated actually joined the collateral and borrow markets.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Informational"]}, {"title": "Consider reverting instead of returning zero inside repayLogic, withdrawLogic, withdrawCollater- alLogic and liquidateLogic function", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "Position manager always checks the user inputs via different validation functions. One of the vali- dations is that the input's amount must be greater than zero, otherwise, the transaction reverts with revert Er- rors.AmountIsZero(). The same behavior is not followed in those cases where the re-calculated amount is still zero. For example, in repayLogic after re-calculating the max amount that can be repaid by executing amount = Math.min(_getUserBorrowBalanceFromIndexes(underlying, onBehalf, indexes), amount); In this case, Morpho simply executes if (amount == 0) return 0; Note that liquidateLogic should be handled differently because both the borrow amount and/or the collateral amount could be equal to zero. In this case, it would be better to revert with a different custom error based on which of the two amounts are equal to zero.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Informational"]}, {"title": "PERMIT2 operations like transferFrom2 and simplePermit2 will revert if amount is greater than type(uint160).max", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "Both Morpho.sol and PositionsManager.sol uses the Permit2 lib. The current implementation of the permit2 lib explicitly restricts the amount of token to uint160 by calling amount.toUint160() On Morpho, the amount is expressed as a uint256 and the user could, in theory, pass an amount that is greater than type(uint160).max. By doing so, the transaction would revert when it interacts with the permit2 lib.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Informational"]}, {"title": "Both _wrapETH and _unwrapAndTransferETH do not check if the amount is zero", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "Both _wrapETH and _unwrapAndTransferETH are not checking if the amount amount of tokens is greater than zero. If the amount is equal to zero, Morpho should avoid making the external call or simply revert.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Informational"]}, {"title": "Document further contraints on BucketDLL's insert and remove functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf", "body": "Besides the constraint that id may not be zero, there are further constraints that are required for the insert and remove functions to work correctly:  insert: \"This function should not be called with an _id that is already in the list.\" Otherwise, it would overwrite the existing _id.  remove: \"This function should not be called with an _id that is not in the list.\" Otherwise, it would set all of _list.accounts[0] to address(0), i.e., mark the list as empty.", "labels": ["Spearbit", "Morpho-Av3", "Severity: Informational"]}, {"title": "Important Balancer fields can be overwritten by EndTime", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "Balancers ManagedPool uses 32 bit values for startTime and endTime but it does not verify if those values exist within that range. Values are stored in a 32-byte _miscData slot in BasePool via the insertUint32() function. Nevertheless, this function does not strip any excess bits, resulting in other fields stored in _miscData to be overwritten. In the version that Aera Vault uses only the \"restrict LP\" field can be overwritten and by carefully crafting the value of endTime, the \"restrict LP\" boolean can be switched off, allowing anyone to use joinPool. The Manager could cause this behavior via the updateWeightsGradually() function while the Owner could do it via enableTradingWithWeights(). Note: This issue has been reported to Balancer by the Spearbit team. contract ManagedPool is BaseWeightedPool, ReentrancyGuard { // f14de92ac443d6daf1f3a42025b1ecdb8918f22e 32 bits | 1 bit 1 bit | | restrict LP | end time 32 bits | ] 7 bits | start time | total tokens | swap flag ] | // [ 64 bits // [ reserved | // |MSB | 119 bits | unused function _startGradualWeightChange(uint256 startTime, uint256 endTime, ... ) ... { ... _setMiscData( _getMiscData().insertUint32(startTime, _START_TIME_OFFSET).insertUint32(endTime, ,! _END_TIME_OFFSET) ); // this convert the values to 32 bits ... } } In the latest version of ManagedPool many more fields can be overwritten, including:  LP flag  Fee end/Fee start  Swap flag contract ManagedPool is BaseWeightedPool, AumProtocolFeeCache, ReentrancyGuard { // current version // [ 64 bits ] // [ swap fee | LP flag | fee end | swap flag | fee start | end swap | end wgt | start wgt ] LSB| // |MSB 1 bit | 31 bits | | 31 bits 64 bits | 32 bits | 32 bits 1 bit | | The following POC shows how fields can be manipulated. // SPDX-License-Identifier: MIT pragma solidity ^0.8.13; import \"hardhat/console.sol\"; contract checkbalancer { uint256 private constant _MASK_1 = 2**(1) - 1; uint256 private constant _MASK_31 = 2**(31) - 1; uint256 private constant _MASK_32 = 2**(32) - 1; uint256 private constant _MASK_64 = 2**(64) - 1; uint256 private constant _MASK_192 = 2**(192) - 1; 5 | | 1 bit 64 bits | | 31 bits 1 bit | 31 bits | // [ 64 bits ] // [ swap fee | LP flag | fee end | swap flag | fee start | end swap | end wgt | start wgt ] LSB| // |MSB uint256 private constant _WEIGHT_START_TIME_OFFSET = 0; uint256 private constant _WEIGHT_END_TIME_OFFSET = 32; uint256 private constant _END_SWAP_FEE_PERCENTAGE_OFFSET = 64; uint256 private constant _FEE_START_TIME_OFFSET = 128; uint256 private constant _SWAP_ENABLED_OFFSET = 159; uint256 private constant _FEE_END_TIME_OFFSET = 160; uint256 private constant _MUST_ALLOWLIST_LPS_OFFSET = 191; uint256 private constant _SWAP_FEE_PERCENTAGE_OFFSET = 192; 32 bits | 32 bits function insertUint32(bytes32 word,uint256 value,uint256 offset) internal pure returns (bytes32) { bytes32 clearedWord = bytes32(uint256(word) & ~(_MASK_32 << offset)); return clearedWord | bytes32(value << offset); } function decodeUint31(bytes32 word, uint256 offset) internal pure returns (uint256) { return uint256(word >> offset) & _MASK_31; } function decodeUint32(bytes32 word, uint256 offset) internal pure returns (uint256) { return uint256(word >> offset) & _MASK_32; } function decodeUint64(bytes32 word, uint256 offset) internal pure returns (uint256) { return uint256(word >> offset) & _MASK_64; } function decodeBool(bytes32 word, uint256 offset) internal pure returns (bool) { return (uint256(word >> offset) & _MASK_1) == 1; } function insertBits192(bytes32 word,bytes32 value,uint256 offset) internal pure returns (bytes32) { bytes32 clearedWord = bytes32(uint256(word) & ~(_MASK_192 << offset)); return clearedWord | bytes32((uint256(value) & _MASK_192) << offset); } constructor() { bytes32 poolState; bytes32 miscData; uint startTime = 1 + 2*2**32; uint endTime = 3 + 4*2**32 + 5*2**(32+64) + 2**(32+64+31) + 6*2**(32+64+31+1) + ,! 2**(32+64+31+1+31) + 7*2**(32+64+31+1+31+1); poolState = insertUint32(poolState,startTime, _WEIGHT_START_TIME_OFFSET); poolState = insertUint32(poolState,endTime, _WEIGHT_END_TIME_OFFSET); miscData = insertBits192(miscData,poolState,0); decodeUint32(miscData, console.log(\"startTime\", console.log(\"endTime\", decodeUint32(miscData, console.log(\"endSwapFeePercentage\", decodeUint64(miscData, _WEIGHT_START_TIME_OFFSET)); // 1 // 3 _WEIGHT_END_TIME_OFFSET)); _END_SWAP_FEE_PERCENTAGE_OFFSET)); ,! // 4 console.log(\"Fee startTime\", console.log(\"Swap enabled\", console.log(\"Fee endTime\", console.log(\"AllowlistLP\", decodeUint31(miscData, decodeBool(miscData, decodeUint31(miscData, decodeBool(miscData, _FEE_START_TIME_OFFSET)); // 5 _SWAP_ENABLED_OFFSET)); // true _FEE_END_TIME_OFFSET)); // 6 _MUST_ALLOWLIST_LPS_OFFSET)); // ,! true console.log(\"Swap fee percentage\", console.log(\"Swap fee percentage\", decodeUint64(poolState, _SWAP_FEE_PERCENTAGE_OFFSET)); // 7 _SWAP_FEE_PERCENTAGE_OFFSET)); // 0 decodeUint64(miscData, due to miscData conversion } ,! }", "labels": ["Spearbit", "Gauntlet", "Severity: Critical Risk"]}, {"title": "sweep function should prevent Treasury from withdrawing pools BPTs", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The current sweep() implementation allows the vault owner (the Treasury) to sweep any token owned by the vault including BPTs (Balancer Pool Tokens) that have been minted by the Vault during the pools initialDeposit() function call. The current vault implementation does not need those BPTs to withdraw funds because they are passed directly through the AssetManager flow via withdraw()/finalize(). Being able to withdraw BPTs would allow the Treasury to:  Withdraw funds without respecting the time period between initiateFinalization() and finalize() calls.  Withdraw funds without respecting Validator allowance() limits.  Withdraw funds without paying the managers fee for the last withdraw().  finalize the pool, withdrawing all funds and selling valueless BPTs on the market.  Sell or rent out BPTs and withdraw() funds afterwards, thus doubling the funds. Swap fees would not be paid because Treasury could call setManager(newManager), where the new manager is someone controlled by the Treasury, subsequently calling setSwapFee(0) to remove the swap fee, which would be applied during an exitPool() event. Note: Once the BPT is retrieved it can also be used to call exitPool(), as the mustAllowlistLPs check is ignored in exitPool().", "labels": ["Spearbit", "Gauntlet", "Severity: Critical Risk"]}, {"title": "Manager can cause an immediate weight change", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "Balancers ManagedPool uses 32 bit values for startTime and endTime but it does not verify if those values exist within that range. When endTime is set to 2**32 it becomes larger than startTime so the _require(startTime <= endTime, ...) statement will not revert. When endTime is converted to 32 bits it will get a value of 0, so in _calcu- lateWeightChangeProgress() the test if (currentTime >= endTime) ... will be true, causing the weight to immediately reach the end value. This way the Manager can cause an immediate weight change via the updateWeightsGradually() function and open arbitrage opportunities. Note: startTime is also subject to this overflow problem. Note: the same issues occur in the latest version of ManagedPool. Note: This issue has been reported to Balancer by the Spearbit team. 7 Also see the following issues:  Managed Pools are still undergoing development and may contain bugs and/or change significantly  Important fields of Balancer can be overwritten by EndTime contract ManagedPool is BaseWeightedPool, ReentrancyGuard { function updateWeightsGradually(uint256 startTime, uint256 endTime, ... ) { ... uint256 currentTime = block.timestamp; startTime = Math.max(currentTime, startTime); _require(startTime <= endTime, Errors.GRADUAL_UPDATE_TIME_TRAVEL); // will not revert if ,! endTime == 2**32 ... _startGradualWeightChange(startTime, endTime, _getNormalizedWeights(), endWeights, tokens); } function _startGradualWeightChange(uint256 startTime, uint256 endTime, ... ) ... { ... _setMiscData( _getMiscData().insertUint32(startTime, _START_TIME_OFFSET).insertUint32(endTime, ,! _END_TIME_OFFSET) ); // this convert the values to 32 bits ... } function _calculateWeightChangeProgress() private view returns (uint256) { uint256 currentTime = block.timestamp; bytes32 poolState = _getMiscData(); uint256 startTime = poolState.decodeUint32(_START_TIME_OFFSET); uint256 endTime = poolState.decodeUint32(_END_TIME_OFFSET); if (currentTime >= endTime) { // will be true if endTime == (2**32) capped to 32 bits == 0 return FixedPoint.ONE; } else ... ... } }", "labels": ["Spearbit", "Gauntlet", "Severity: High Risk"]}, {"title": "deposit and withdraw functions are susceptible to sandwich attacks", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "Transactions calling the deposit() function are susceptible to sandwich attacks where an attacker can extract value from deposits. A similar issue exists in the withdraw() function but the minimum check on the pool holdings limits the attacks impact. Consider the following scenario (swap fees ignored for simplicity): 1. Suppose the Balancer pool contains two tokens, WETH and DAI, and weights are 0.5 and 0.5. Currently, there is 1 WETH and 3k DAI in the pool and WETH spot price is 3k. 2. The Treasury wants to add another 3k DAI into the Aera vault, so it calls the deposit() function. 3. The attacker front-runs the Treasurys transaction. They swap 3k DAI into the Balancer pool and get out 0.5 WETH. The weights remain 0.5 and 0.5, but because WETH and DAI balances become 0.5 and 6k, WETHs spot price now becomes 12k. 4. Now, the Treasurys transaction adds 3k DAI into the Balancer pool and upgrades the weights to 0.5*1.5: 0.5 = 0.6: 0.4. 5. The attacker back-runs the transaction and swaps the 0.5 WETH they got in step 3 back to DAI (and recovers the WETHs spot price to near but above 3k). According to the current weights, they can get 9k*(1 - 1/r) = 3.33k DAI from the pool, where r = (20.4)(1/0.6). 6. As a result the attacker profits 3.33k - 3k = 0.33k DAI.", "labels": ["Spearbit", "Gauntlet", "Severity: High Risk"]}, {"title": "allowance() doesnt limit withdraw()s", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The allowance() function is meant to limit withdraw amounts. However, allowance() can only read and not alter state because its visibility is set to view. Therefore, the withdraw() function can be called on demand until the entire Vault/Pool balance has been drained, rendering the allowance() function ineffective. function withdraw(uint256[] calldata amounts) ... { ... uint256[] memory allowances = validator.allowance(); ... for (uint256 i = 0; i < tokens.length; i++) { if (amounts[i] > holdings[i] || amounts[i] > allowances[i]) { revert Aera__AmountExceedAvailable(... ); } } } // can't update state due to view function allowance() external view override returns (uint256[] memory amounts) { amounts = new uint256[](count); for (uint256 i = 0; i < count; i++) { amounts[i] = ANY_AMOUNT; } } from both IWithdrawal-", "labels": ["Spearbit", "Gauntlet", "Severity: High Risk"]}, {"title": "Malicious manager could cause Vault funds to be inaccessible", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The calculateAndDistributeManagerFees() function pushes tokens to the manager and if for unknown reasons this action fails the entire Vault would be blocked and funds become inaccessible. This occurs because the following functions depend on the execution of calculateAndDistributeManagerFees(): deposit(), withdraw(), setManager(), claimManagerFees(), initiateFinalization(), and therefore final- ize() as well. Within calculateAndDistributeManagerFees() the function safeTransfer() is the riskiest and could fail under the following situations:  A token with a callback is used, for example an ERC777 token, and the callback is not implemented correctly.  A token with a blacklist option is used and the manager is blacklisted. For example USDC has such blacklist functionality. Because the manager can be an unknown party, a small risk exist that he is malicious and his address could be blacklisted in USDC. Note: set as high risk because although probability is very small, impact results in Vault funds to become inacces- sible. function calculateAndDistributeManagerFees() internal { ... for (uint256 i = 0; i < amounts.length; i++) { tokens[i].safeTransfer(manager, amounts[i]); } }", "labels": ["Spearbit", "Gauntlet", "Severity: High Risk"]}, {"title": "updateWeightsGradually allows change rates to start in the past with a very high maximumRatio", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The current updateWeightsGradually is using startTime instead of time that should be Math.max(block.timestamp, startTime). Because internally Balancer will use startTime = Math.max(currentTime, startTime); as the startTime, this allows to: the minimal start  Have a startTime in the past.  Have a targetWeights[i] higher than allowed. We also suggest adding another check to prevent startTime > endTime. Although Balancer replicates the same check it is still needed in the Aera implementation to prevent transactions to revert because of an underflow error on uint256 duration = endTime - startTime;", "labels": ["Spearbit", "Gauntlet", "Severity: High Risk"]}, {"title": "The vault manager has unchecked power to create arbitrage using setSwapFees", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "A previously known issue was that a malicious vault manager could arbitrage the vault like in the below scenario: 1. Set the swap fees to a high value by setSwapFee (10% is the maximum). 2. Wait for the market price to move against the spot price. 3. In the same transaction, reduce the swap fees to ~0 (0.0001% is the minimum) and arbitrage the vault. The proposed fix was to limit the percentage change of the swap fee to a maximum of MAXIMUM_SWAP_FEE_- PERCENT_CHANGE each time. However, because there is no restriction on how many times the setSwapFee function can be called in a block or transaction, a malicious manager can still call it multiple times in the same transaction and eventually set the swap fee to the value they want.", "labels": ["Spearbit", "Gauntlet", "Severity: High Risk"]}, {"title": "Implement a function to claim liquidity mining rewards", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "Balancer offers a liquidity mining rewards distribution for liquidity providers. Liquidity Mining distributions are available to claim weekly through the MerkleOrchard contract. Liquid- ity Providers can claim tokens from this contract by submitting claims to the tokens. These claims are checked against a Merkle root of the accrued token balances which are stored in a Merkle tree. Claim- ing through the MerkleOrchard is much more gas-efficient than the previous generation of claiming contracts, especially when claiming multiple weeks of rewards, and when claiming multiple tokens. The AeraVault is itself the only liquidity provider of the Balancer pool deployed, so each week its entitled to claim those rewards. Currently, those rewards cannot be claimed because the AeraVault is missing an implementation to interact with the MerkleOrchard contract, causing all rewards (BAL + other tokens) to remain in the MerkleOrchard forever.", "labels": ["Spearbit", "Gauntlet", "Severity: High Risk"]}, {"title": "Owner can circumvent allowance() via enableTradingWithWeights()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The vault Owner can set arbitrary weights via disableTrading() and then call enableTrading- WithWeights() to set the spot price and create arbitrage opportunities for himself. This way allowance() in withdraw() checks, which limit the amount of funds an owner can withdraw, can be circumvented. Something similar can be done with enableTradingRiskingArbitrage() in combination with sufficient time. Also see the following issues:  allowance() doesnt limit withdraw()s  enableTradingWithWeights allow the Treasury to change the pools weights even if the swap is not disabled  Separation of concerns Owner and Manager function disableTrading() ... onlyOwnerOrManager ... { setSwapEnabled(false); } function enableTradingWithWeights(uint256[] calldata weights) ... onlyOwner ... { ... pool.updateWeightsGradually(timestamp, timestamp, weights); setSwapEnabled(true); } function enableTradingRiskingArbitrage() ... onlyOwner ... { setSwapEnabled(true); } 13", "labels": ["Spearbit", "Gauntlet", "Severity: Medium Risk"]}, {"title": "Front-running attacks on finalize could affect received token amounts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The returnFunds() function (called by finalize()) withdraws the entire holdings in the Balancer pool but does not allow the caller to specify and enforce the minimum amount of received tokens. Without such check the finalize() function could be susceptible to a front-running attack. A potential exploit scenario looks as follows: 1. The notice period has passed and the Treasury calls finalize() on the Aera vault. Assume the Balancer pool contains 1 WETH and 3000 DAI, and that WETH and DAI weights are both 0.5. 2. An attacker front-runs the Treasurys transaction and swaps in 3000 DAI to get 0.5 WETH from the pool. 3. As an unexpected result, the Treasury receives 0.5 WETH and 6000 DAI. Therefore an attacker can force the Treasury to accept the trade that they offer. Although the Treasury can execute a reverse trade on another market to recover the token amount and distribution, not every Treasury can execute such trade (e.g., if a timelock controls it). Notice that the attacker may not profit from the swap because of slippage but they could be incentivized to perform such an attack if it causes considerable damage to the Treasury.", "labels": ["Spearbit", "Gauntlet", "Severity: Medium Risk"]}, {"title": "safeApprove in depositToken could revert for non-standard token like USDT", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "Some non-standard tokens like USDT will revert when a contract or a user tries to approve an al- lowance when the spender allowance has already been set to a non zero value. In the current code we have not seen any real problem with this fact because the amount retrieved via depositToken() is approved send to the Balancer pool via joinPool() and managePoolBalance(). Balancer transfers the same amount, lowering the approval to 0 again. However, if the approval is not lowered to exactly 0 (due to a rounding error or another unfore- seen situation) then the next approval in depositToken() will fail (assuming a token like USDT is used), blocking all further deposits. Note: Set to medium risk because the probability of this happening is low but impact would be high. We also should note that OpenZeppelin has officially deprecated the safeApprove function, suggesting to use instead safeIncreaseAllowance and safeDecreaseAllowance.", "labels": ["Spearbit", "Gauntlet", "Severity: Medium Risk"]}, {"title": "Consult with Balancer team about best approach to add and remove funds", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The Aera Vault uses AssetManagers functionality of function managePoolBalance() to add and remove funds. The standard way to add and remove funds in Balancer is via joinPool() / exitPool(). Using the managePoolBalance() function might lead to future unexpected behavior. Additionally, this disables the capacity to implement the original intention of AssetManagers functionality, e.g. storing funds elsewhere to generate yield.", "labels": ["Spearbit", "Gauntlet", "Severity: Medium Risk"]}, {"title": "Fee on transfer can block several functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "Some tokens have a fee on transfer, for example USDT. Usually such fee is not enabled but could be re-enabled at any time. With this fee enabled the withdrawFromPool() function would receive slightly less tokens than the amounts requested from Balancer causing the next safeTransfer() call to fail because there are not enough tokens inside the contract. This means withdraw() calls will fail. Functions deposit() and calculateAndDistributeManagerFees() can also fail because they have similar code. Note: The function returnFunds() is more robust and can handle this problem. Note: The problem can be alleviated by sending additional tokens directly to the Aera Vault contract to compensate for fees, lowering the severity of the problem to medium. function withdraw(uint256[] calldata amounts) ... { ... withdrawFromPool(amounts); // could get slightly less than amount with a fee on transfer ... for (uint256 i = 0; i < amounts.length; i++) { if (amounts[i] > 0) { tokens[i].safeTransfer(owner(), amounts[i]); // could revert it the full amounts[i] isn't ,! available ... } ... } }", "labels": ["Spearbit", "Gauntlet", "Severity: Medium Risk"]}, {"title": "enableTradingWithWeights allow the Treasury to change the pools weights even if the swap is not disabled", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "enableTradingWithWeights is a function that can only be called by the owner of the Aera Vault contract and that should be used only to re-enable the swap feature on the pool while updating token weights. The function does not verify if the pools swap feature is enabled and for this reason, as a result, it allows the Treasury to act as the manager who is the only actor allowed to change the pool weights. The function should add a check to ensure that it is only callable when the pools swap is disabled.", "labels": ["Spearbit", "Gauntlet", "Severity: Medium Risk"]}, {"title": "AeraVault constructor is not checking all the input parameters", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The Aera Vault constructor has the role to handle Balancers ManagedPool deployment. The con- structor should increase the number of user input validation and the Gauntlet team should be aware of the possible edge case that could happen given that the deployment of the Aera Vault is handled directly by the Treasury and not by the Gauntlet team itself. We are going to list all the worst-case scenarios that could happen given the premise that the deployments are handled by the Treasury. 1. factory could be a wrapper contract that will deploy a ManagedPool. This would mean that the deployer could pass correct parameters to Aera Vault to pass these checks, but will use custom and malicious parameters on the factory wrapper to deploy the real Balancer pool. 2. swapFeePercentage value is not checked. On Balancer, the deployment will revert if the value is not in- side this range >= 1e12 (0.0001%) and <= 1e17 (10% - this fits in 64 bits). Without any check, the Gauntlet accept to follow the Balancers swap requirements. 3. manager_ is not checked. They could set the manager as the Treasury (owner of the vault) itself. This would give the Treasury the full power to manage the Vault. At least these values should be checked: address(0), address(this) or owner(). The same checks should also be done in the setManager() function. 4. validator_ could be set to a custom contract that will give full allowances to the Treasury. This would make the withdraw() act like finalize() allowing to withdraw all the funds from the vault/pool. 17 5. noticePeriod_ has only a max value check. Gauntlet team explained that a time delay between the ini- tialization of the finalize process and the actual finalize is needed to prevent the Treasury to be able to instantly withdraw all the funds. Not having a min value check allow the Treasury to set the value to 0 so there would be no delay between the initiateFinalization() and finalize() because noticeTimeoutAt == block.timestamp. 6. managementFee_ has no minimum value check. This would allow the Treasury to not pay the manager because the managerFeeIndex would always be 0. 7. description_ can be empty. From the Specification PDF, the description of the vault has the role to De- scribes vault purpose and modelling assumptions for differentiating between vaults. Being empty could lead to a bad UX for external services that needs to differentiate different vaults. These are all the checks that are done directly by Balancer during deployment via the Pool Factory:  BasePool constructor#L94-L95 min and max number of tokens.  BasePool constructor#L102token array is sorted following Balancer specification (sorted by token address).  BasePool constructor calling _setSwapFeePercentage min and max value for swapFeePercentage.  BasePool constructor calling vault.registerTokens token address uniqueness (cant have same Following the pathBasePool is calling from function _registerMinimalSwapInfoPoolTokens it also checks that token != IERC20(0). should that call token in the pool), vault.registerTokens MinimalSwapInfoPoolsBalance.  ManagedPool constructor calling _startGradualWeightChange Check min value of weight and that the total sum of the weights are equal to 100%. _startGradualWeightChange internally check that endWeight >= WeightedMath._MIN_WEIGHT and normalizedSum == FixedPoint.ONE.", "labels": ["Spearbit", "Gauntlet", "Severity: Medium Risk"]}, {"title": "Possible mismatch between Validator.count and AeraVault assets count", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "A weak connection between WithdrawalValidator and Aera Vault could lead to the inability of withdrawing from a Vault. Consider the following scenario: The Validator is deployed with a tokenCount < than Vault.getTokens().length. Inside the withdraw() function we reference the following code block: uint256[] memory allowances = validator.allowance(); uint256[] memory weights = getNormalizedWeights(); uint256[] memory newWeights = new uint256[](tokens.length); for (uint256 i = 0; i < tokens.length; i++) { if (amounts[i] > holdings[i] || amounts[i] > allowances[i]) { revert Aera__AmountExceedAvailable( address(tokens[i]), amounts[i], holdings[i].min(allowances[i]) ); } } A scenario where allowances.length < tokens.length would cause this function to revert with an Index out of bounds error. The only way for the Treasury to withdraw funds would be via the finalize() method which has a time delay.", "labels": ["Spearbit", "Gauntlet", "Severity: Medium Risk"]}, {"title": "Ensure vaults deployment integrity", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The treasury could deploy on purpose or by accident a slightly different version of the contract and introduce bugs or backdoors. This might not be recognized by parties taking on Manager responsibilities (e.g. usually Gauntlet will be involved here).", "labels": ["Spearbit", "Gauntlet", "Severity: Low Risk"]}, {"title": "Frequent calling of calculateAndDistributeManagerFees() lowers fees", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "Via calculateAndDistributeManagerFees() a percentage of the Pool is subtracted and sent to the Manager. If this function is called too frequently his fees will be lower. For example:  If he calls it twice, while both time getting 1%, he actually gets: 1% + 1% * (100% - 1%) = 1.99%  If he waits longer until he has earned 2%, he actually gets: 2%, which is slightly more than 1.99%  If called very frequently the fees go to 0 (especially taking in account the rounding down). However the gas cost would be very high. The Manager can (accidentally) do this by calling claimManagerFees(). The Owner can (accidentally or on pur- pose (e.g. using 0 balance change) ) do this by calling deposit(), withdraw() or setManager(). Note: Rounding errors make this slightly worse. Also see the following issue: Possible rounding down of fees function claimManagerFees() ... { calculateAndDistributeManagerFees(); // get a percentage of the Pool }", "labels": ["Spearbit", "Gauntlet", "Severity: Low Risk"]}, {"title": "OpenZeppelin best practices", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The Aera Vault uses OpenZeppelin release 4.3.2 which is copied into their github. The current release of OpenZeppelin is 4.6.0 and includes several updates and security fixes. The copies of the OpenZeppelin files are also (manually) changed to adapt the import paths. This has the risk of making a mistake in the process. import \"./dependencies/openzeppelin/SafeERC20.sol\"; import \"./dependencies/openzeppelin/IERC20.sol\"; import \"./dependencies/openzeppelin/IERC165.sol\"; import \"./dependencies/openzeppelin/Ownable.sol\"; import \"./dependencies/openzeppelin/ReentrancyGuard.sol\"; import \"./dependencies/openzeppelin/Math.sol\"; import \"./dependencies/openzeppelin/SafeCast.sol\"; import \"./dependencies/openzeppelin/ERC165Checker.sol\";", "labels": ["Spearbit", "Gauntlet", "Severity: Low Risk"]}, {"title": "Possible rounding down of fees", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "If certain token has a few decimals numbers then fees could be rounded down to 0, especially if time between calculateAndDistributeManagerFees() is relatively small. This also could slightly shift the spot price because the balance of one coin is lowered while the other remains still. With fewer decimals the situation worsens, e.g. Gemini USD GUSD has 2 decimals, therefore the problem occurs with a balance of 10_000 GUSD. Note: The rounding down is probably neglectable in most cases. function calculateAndDistributeManagerFees() internal { ... for (uint256 i = 0; i < tokens.length; i++) { amounts[i] = (holdings[i] * managerFeeIndex) / ONE; // could be rounded down to 0 } ... } With 1 USDC in the vault and 2 hours between calculateAndDistributeManagerFees(), the fee for USDC is rounded down to 0. This behavior is demonstrated in the following POC: 21 import \"hardhat/console.sol\"; contract testcontract { uint256 constant ONE = 10**18; uint managementFee = 10**8; constructor() { // MAX_MANAGEMENT_FEE = 10**9; // 1 USDC uint holdings = 1E6; uint delay = 2 hours; uint managerFeeIndex = delay * managementFee; uint amounts = (holdings * managerFeeIndex) / ONE; console.log(\"Fee\",amounts); // fee is 0 } }", "labels": ["Spearbit", "Gauntlet", "Severity: Low Risk"]}, {"title": "Missing nonReentrant modifier on initiateFinalization(), setManager() and claimManagerFees() functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The initiateFinalization() function is missing a nonReentrant modifier while calculateAnd- DistributeManagerFees() executes external calls. Same goes for setManager() and claimManagerFees() func- tions.", "labels": ["Spearbit", "Gauntlet", "Severity: Low Risk"]}, {"title": "Potential division by 0", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "If the balance (e.g. holdings[]) of a token is 0 in deposit() then the dividing by holdings[] would cause a revert. Note: Function withdraw() has similar code but when holdings[]==0 its not possible to withdraw() anyway. Note: The current Mannon vault code will not allow the balances to be 0. Note: Although not used in the current code, in order to do a deregisterTokens(), Balancer requires the balance to be 0. Additionally, refer to the following Balancer documentation about the-vault#deregistertokens. The worst case scenario is deposit() not working. function deposit(uint256[] calldata amounts) ... { ... for (uint256 i = 0; i < amounts.length; i++) { if (amounts[i] > 0) { depositToken(tokens[i], amounts[i]); uint256 newBalance = holdings[i] + amounts[i]; newWeights[i] = (weights[i] * newBalance) / holdings[i]; // would revert if holdings[i] == 0 } ... ... } Similar divisions by 0 could occur in getWeightChangeRatio(). The function is called from updateWeightsGradu- ally(). If this is due to targetWeight being 0, then it is the desired result. Current weight should not be 0 due balancer checks. function getWeightChangeRatio(uint256 weight, uint256 targetWeight) ... { return weight > targetWeight ? (ONE * weight) / targetWeight : (ONE * targetWeight) / weight; // could revert if targetWeight == 0 // could revert if weight== 0 }", "labels": ["Spearbit", "Gauntlet", "Severity: Low Risk"]}, {"title": "Use ManagedPoolFactory instead of BaseManagedPoolFactory to deploy the Balancer pool", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "Currently the Aera Vault is using BaseManagedPoolFactory as the factory to deploy the Balancer pool while Balancers documentation recommends and encourages the usage of ManagedPoolFactory. Quoting the doc inside the BaseManagedPoolFactory: This is a base factory designed to be called from other factories to deploy a ManagedPool with a particular controller/owner. It should NOT be used directly to deploy ManagedPools without controllers. ManagedPools controlled by EOAs would be very dangerous for LPs. There are no restrictions on what the managers can do, so a malicious manager could easily manipulate prices and drain the pool. In this design, other controller-specific factories will deploy a pool controller, then call this factory to deploy the pool, passing in the controller as the owner. 23", "labels": ["Spearbit", "Gauntlet", "Severity: Low Risk"]}, {"title": "Adopt the two-step ownership transfer pattern", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "To prevent the Aera vault Owner, i.e. the Treasury, from calling renounceOwnership() and effec- tively breaking vault critical functions such as withdraw() and finalize(), the renounceOwnership() function is explicitly overridden to revert the transaction every time. However, the transferOwnership() function may also lead to the same issue if the ownership is transferred to an uncontrollable address because of human errors or attacks on the Treasury.", "labels": ["Spearbit", "Gauntlet", "Severity: Low Risk"]}, {"title": "Implement zero-address check for manager_", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "Non-existent zero-address checks inside the constuctor for the manager_ parameter. If manager_- becomes a zero address then calls to calculateAndDistributeManagerFees will burn tokens (transfer them to address(0)).", "labels": ["Spearbit", "Gauntlet", "Severity: Low Risk"]}, {"title": "Simplify tracking of managerFeeIndex", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The calculateAndDistributeManagerFees() function uses updateManagerFeeIndex() to keep track of management fees. It keeps track of both managerFeeIndex and lastFeeCheckpoint in storage vari- ables (e.g. costing SLOAD/SSTORE). However, because managementFee is immutable this can be simplified to one storage variable, saving gas and improving code legibility. uint256 public immutable managementFee; // can't be changed function calculateAndDistributeManagerFees() internal { updateManagerFeeIndex(); ... if (managerFeeIndex == 0) { return; use managerFeeIndex } ... // ... managerFeeIndex = 0; ... } function updateManagerFeeIndex() internal { managerFeeIndex += (block.timestamp - lastFeeCheckpoint) * managementFee; lastFeeCheckpoint = block.timestamp.toUint64(); }", "labels": ["Spearbit", "Gauntlet", "Severity: Gas Optimization"]}, {"title": "Directly call getTokensData() from returnFunds()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The function returnFunds() calls getHoldings() and getTokens(). Both functions call getTokens- Data() thus waste gas unnecessarily. function returnFunds() internal returns (uint256[] memory amounts) { uint256[] memory holdings = getHoldings(); IERC20[] memory tokens = getTokens(); ... } function getHoldings() public view override returns (uint256[] memory amounts) { (, amounts, ) = getTokensData(); } function getTokens() public view override returns (IERC20[] memory tokens) { (tokens, , ) = getTokensData(); }", "labels": ["Spearbit", "Gauntlet", "Severity: Gas Optimization"]}, {"title": "Change uint32 and uint64 to uint256", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The contract contains a few variables/constants that are smaller than uint256: noticePeriod, no- ticeTimeoutAt and lastFeeCheckpoint. This doesnt actually save gas because they are not part of a struct and still take up a storage slot. It even costs more gas because additional bits have to be stripped off. Additionally, there is a very small risk of lastFeeCheckpoint wrapping to 0 in the updateManagerFeeIndex() function. If that would happen, managerFeeIndex would get far too large and too many fees would be paid out. Finally, using int256 simplifies the code. contract AeraVaultV1 is IAeraVaultV1, Ownable, ReentrancyGuard { ... uint32 public immutable noticePeriod; ... uint64 public noticeTimeoutAt; ... uint64 public lastFeeCheckpoint = type(uint64).max; ... } function updateManagerFeeIndex() internal { managerFeeIndex += (block.timestamp - lastFeeCheckpoint) * managementFee; // could get large when lastFeeCheckpoint wraps lastFeeCheckpoint = block.timestamp.toUint64(); }", "labels": ["Spearbit", "Gauntlet", "Severity: Gas Optimization"]}, {"title": "Use block.timestamp directly instead of assigning it to a temporary variable.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "It is preferable to use block.timestamp directly in your code instead of assigning it to a temporary variable as it only uses 2 gas.", "labels": ["Spearbit", "Gauntlet", "Severity: Gas Optimization"]}, {"title": "Consider replacing pool.getPoolId() with bytes32 public immutable poolId to save gas and ex- ternal calls", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The current implementation of Aera Vault always calls pool.getPoolId() or indirectly getPoolId() to retrieve the ID of the immutable state variable pool that has been declared at constructor time. The pool.getPoolId() is a getter function defined in the Balancer BasePool contract: function getPoolId() public view override returns (bytes32) { return _poolId; } Inside the same BasePool contract the _poolId is defined as immutable which means that after creating a pool it will never change. For this reason it is possible to apply the same logic inside the Aera Vault and use an immutable variable to avoiding external calls and save gas.", "labels": ["Spearbit", "Gauntlet", "Severity: Gas Optimization"]}, {"title": "Save values in temporary variables", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "We observed multiple occurrences in the codebase where <var>.length was used in for loops. This could lead to more gas consumption as .length gets called repetitively until the for loop finishes. When indexed variables are used multiple times inside the loop in a read only way these can be stored in a temporary variable to save some gas. for (uint256 i = 0; i < tokens.length; i++) { // tokens.length has to be calculated repeatedly ... ... = tokens[i].balanceOf(...); tokens[i].safeTransfer(owner(), ...); } // tokens[i] has to be evaluated multiple times", "labels": ["Spearbit", "Gauntlet", "Severity: Gas Optimization"]}, {"title": "Aera could be prone to out-of-gas transaction revert when managing a high number of tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The Balancer ManagedPool used by Aera has a max limit of 50 token. Functions like: initialDeposit(), deposit(), withdraw() and finalize() involve numerous external direct and indirect (made by Balancer itself when called by Aera) calls and math calculations that are done for each token managed by the pool. The functions deposit() and withdraw() are especially gas intensive, given that they also internally call calcu- lateAndDistributeManagerFees() that will transfer, for each token, a management fee to the manager. For these reasons Aera should be aware that a high number of tokens managed by the Aera Vault could lead to out-of-gas reverts (max block size depends on which chain the project will be deployed).", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Use a consistent way to call getNormalizedWeights()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The functions deposit() and withdraw() call function getNormalizedWeights() while the function updateWeightsGradually() and cancelWeightUpdates() call pool.getNormalizedWeights(). Although this is functionally the same, it is not consistent. 29 function deposit(uint256[] calldata amounts) ... { ... uint256[] memory weights = getNormalizedWeights(); ... emit Deposit(amounts, getNormalizedWeights()); } function withdraw(uint256[] calldata amounts) ... { ... uint256[] memory weights = getNormalizedWeights(); ... emit Withdraw(amounts, allowances, getNormalizedWeights()); } function updateWeightsGradually(...) ... { ... uint256[] memory weights = pool.getNormalizedWeights(); ... } function cancelWeightUpdates() ... { ... uint256[] memory weights = pool.getNormalizedWeights(); ... } function getNormalizedWeights() ... { return pool.getNormalizedWeights(); }", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Add function disableTrading() to IManagerAPI.sol", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The disableTrading() function can also be called by managers because of the onlyOwnerOrMan- agermodifier. However in AeraVaultV1.sol it is located in the PROTOCOL API section. It is also not present in IManagerAPI.sol. contract AeraVaultV1 is IAeraVaultV1, Ownable, ReentrancyGuard { /// PROTOCOL API /// function disableTrading() ... onlyOwnerOrManager ... { ... } /// MANAGER API /// } interface IManagerAPI { function updateWeightsGradually(...) external; function cancelWeightUpdates() external; function setSwapFee(uint256 newSwapFee) external; function claimManagerFees() external; } // disableTrading() isn't present 30", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Doublecheck layout functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "Different ways are used to layout functions. Especially the part between ( ... ) and between ) ... { is sometimes done on one line and sometimes split in multiple lines. Also { is sometimes at the end of a line and sometimes at the beginning. Although the layout is not disturbing it might be useful to doublecheck it. Here are a few examples of different layouts: function updateWeights(uint256[] memory weights, uint256 weightSum) internal ... { } function depositToken(IERC20 token, uint256 amount) internal { ... } function updatePoolBalance( uint256[] memory amounts, IBVault.PoolBalanceOpKind kind ) internal { ... } function updateWeights(uint256[] memory weights, uint256 weightSum) internal ... { } function updateWeightsGradually( uint256[] calldata targetWeights, uint256 startTime, uint256 endTime ) external override onlyManager whenInitialized whenNotFinalizing { ... } function getWeightChangeRatio(uint256 weight, uint256 targetWeight) internal pure returns (uint256) { } ...", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Use Math library functions in a consistent way", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "In the AeraVaultV1 contract, the OZs Math library functions are attached to the type uint256. The min function is used as a member function whereas the max function is used as a library function.", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Separation of concerns Owner and Manager", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The Owner and Manager roles are separated on purpose. Role separation usually helps to improve quality. However this separation can be broken if the Owner calls setManager(). This way the Owner can set the Manager to one of his own addresses, do Manager functions (for example setSwapFee()) and perhaps set it back to the Manager. Note: as everything happens on chain these actions can be tracked. function setManager(address newManager) external override onlyOwner { if (newManager == address(0)) { revert Aera__ManagerIsZeroAddress(); } if (initialized && noticeTimeoutAt == 0) { calculateAndDistributeManagerFees(); } emit ManagerChanged(manager, newManager); manager = newManager; }", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Add modifier whenInitialized to function finalize()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The function finalize() does not have the modifier whenInitialized while most other functions have this modifier. This does not create any real issues because the function contains the check noticeTimeoutAt == 0 which can only be skipped after initiateFinalization(), and this function does have the whenInitialized modifier. function finalize() external override nonReentrant onlyOwner { // no modifier whenInitialized if (noticeTimeoutAt == 0) { // can only be set via initiateFinalization() revert Aera__FinalizationNotInitialized(); } ... }", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Document the use of mustAllowlistLPs", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "In the Mannon Vault it is important that no other accounts can use joinPool() on the balancer pool. If other accounts are able to call joinPool(), they would get Balancer Pool Tokens (BPT) which could rise in value once more funds are added to the pool. Luckily this is prevented by the mustAllowlistLPs parameter in NewPoolParams. Readers could easily overlook this parameter. pool = IBManagedPool( IBManagedPoolFactory(factory).create( IBManagedPoolFactory.NewPoolParams({ vault: IBVault(address(0)), name: name, symbol: symbol, tokens: tokens, normalizedWeights: weights, assetManagers: managers, swapFeePercentage: swapFeePercentage, pauseWindowDuration: 0, bufferPeriodDuration: 0, owner: address(this), swapEnabledOnStart: false, mustAllowlistLPs: true, managementSwapFeePercentage: 0 // prevent other account to use joinPool }) ) );", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "finalize can be called multiple times", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The finalize function can be called multiple time, leading to the possibility to waste gas for no reason and emitting again a conceptually wrong Finalized event. Currently, theres no check that will prevent to call the function multiple time and there is no explicit flag to allow external sources (web app, external contract) to know whether the AeraVault has been finalized or not. Scenario: the AeraVault has already been finalized but the owner (that could be a contract and not a single EOA) is not aware of it. He calls finalize again and wastes gas because of the external calls in a loop done in returnFunds and emit an additional event Finalized(owner(), [0, 0, ..., 0]) with an array of zeros in the amounts event parameter.", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Consider updating finalize to have a more \"clean\" final state for the AeraVault/Balancer pool", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "This is just a suggestion and not an issue per se. The finalize function should ensure that the pool is in a finalized state for both a better UX and DX. Currently, the finalize function is only withdrawing all the funds from the pool after a noticePeriod but is not ensuring that the swap have been disabled and that all the rewards, entitled to the Vault (owned by the Treasury), have been claimed.", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "enableTradingWithWeights is not emitting an event for pools weight change", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "enableTradingWithWeights is both changing the pools weight and enabling the swap feature, but its only emitting the swap related event (done by calling setSwapEnabled). Both of those operations should be correctly tracked via events to be monitored by external tools.", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Document Balancer checks", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "Balancer has a large number of internal checks. Weve discussed the use of additional checks in the Aera Vault functions. The advantage of this is that it could result in more user friendly error messages. Additionally it protects against potential future change in the Balancer code. contract AeraVaultV1 is IAeraVaultV1, Ownable, ReentrancyGuard { function enableTradingWithWeights(uint256[] calldata weights) ... { { ... // doesn't check weights.length pool.updateWeightsGradually(timestamp, timestamp, weights); ... } } Balancer code: function updateWeightsGradually( ..., uint256[] memory endWeights) ... { (IERC20[] memory tokens, , ) = getVault().getPoolTokens(getPoolId()); ... InputHelpers.ensureInputLengthMatch(tokens.length, endWeights.length); // length check is here ... }", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Rename FinalizationInitialized to FinalizationInitiated for code consistency", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The function at L517 was renamed from initializeFinalization to initiateFinalization to avoid confusion with the Aera vault initialization. For code consistency, the corresponding event and error names should be changed.", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Consider enforcing an explicit check on token order to avoid human error", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The Balancer protocol require (and enforce during the pool creation) that the pools token must be ordered by the token address. The following functions accept an uint256[] of amounts or weights without knowing if the order inside that array follow the same order of the tokens inside the Balancer pool.  initialDeposit  deposit  withdraw  enableTradingWithWeights  updateWeightsGradually While its impossible to totally prevent the human error (they could specify the correct token order but wrongly swap the input order of the amount/weight) we could force the user to be more aware of the specific order in which the amounts/weights must be specified. A possible solution applied to the initialDeposit as an example could be: 37 function initialDeposit(IERC20[] calldata tokensSorted, uint256[] calldata amounts) external override onlyOwner { // ... other code IERC20[] memory tokens = getTokens(); // check that also the tokensSorted length match the lenght of other arrays if (tokens.length != amounts.length || tokens.length != tokensSorted.length) { revert Aera__AmountLengthIsNotSame( tokens.length, amounts.length ); } // ... other code for (uint256 i = 0; i < tokens.length; i++) { // check that the token position associated to the amount has the same position of the one in ,! the balancer pool if( address(tokens[i]) != address(tokensSorted[i]) ) { revert Aera__TokenOrderIsNotSame( address(tokens[i]), address(tokensSorted[i]), i ); } depositToken(tokens[i], amounts[i]); } // ... other code } Another possible implementation would be to introduce a custom struct struct TokenAmount { IERC20 token; uint256 value; } Update the function signature function initialDeposit(TokenAmount[] calldata tokenWithAmount) and up- date the example code following the new parameter model. Its important to note that while this solution will not completely prevent the human error, it will increase the gas consumption of each function.", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Swap is not enabled after initialDeposit execution", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "In the current deployment flow of the AeraVault the Balancer pool is created (by the constructor) with swapEnabledOnStart set as false. When the pool receives their initial funds via initialDeposit the pool has still the swap functionality disabled. It is not explicitly clear in the specification document and in the code when the swap functionality should be enabled. If the protocol wants to enable the swap as soon as the funds are deposited in the pool, they should call, after bVault.joinPool(...), setSwapEnabled(true) or enableTradingWithWeights(uint256[] calldata weights) in case the external spot price is not aligned (both functions will also trigger a SetSwapEnabled event)", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Remove commented code and replace input values with Balancer enum", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "Inside initialDeposit function, there is some commented code (used as example) that should be removed for clarity and future confusion. The initUserData should not use direct input values (0 in this case) but use the correct Balancers enum value to avoid any possible confusion. Following the Balancer documentation  Encoding userData  JoinKind The correct way to declare initUserData is using the WeightedPoolUserData.JoinKind.INIT enum value.", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "The Created event is not including all the information used to deploy the Balancer pool and are missing indexed properties", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The current Created event is defined as 39 event Created( address indexed factory, IERC20[] tokens, uint256[] weights, address manager, address validator, uint32 noticePeriod, string description ); And is missing some of the information that are used to deploy the pool. To allow external tools to better monitor the deployment of the pools, it should be better to include all the information that have been used to deploy the pool on Balancer. The following information is currently missing from the event definition:  name  symbol  managementFee  swapFeePercentage The event could also define both manager and validator as indexed event parameters to allow external tools to filter those events by those values.", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Rename temp variable managers to assetManagers to avoid confusions and any potential future mistakes", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The managers declared in the linked code (see context) are in reality Asset Manager that have a totally different role compared to the AeraVault Manager role. The AssetManager is able to control the pools balance, withdrawing from it or depositing into it. To avoid confusion and any potential future mistakes, it should be better to rename the temporary variable managers to a more appropriate name like assetManagers. - address[] memory managers = new address[](tokens.length); + address[] memory assetManagers = new address[](tokens.length); for (uint256 i = 0; i < tokens.length; i++) { - + } managers[i] = address(this); assetManagers[i] = address(this); pool = IBManagedPool( IBManagedPoolFactory(factory).create( - + IBManagedPoolFactory.NewPoolParams({ vault: IBVault(address(0)), name: name, symbol: symbol, tokens: tokens, normalizedWeights: weights, assetManagers: managers, assetManagers: assetManagers, swapFeePercentage: swapFeePercentage, pauseWindowDuration: 0, bufferPeriodDuration: 0, owner: address(this), swapEnabledOnStart: false, mustAllowlistLPs: true, managementSwapFeePercentage: 0 }) ) ); 41", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Move description declaration inside the storage slot code block", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "In the current code, the description state variable is in the block of /// STORAGE /// where all the immutable variable are re-grouped. As the dev comment say, string cannot be immutable bytecode but only set in constructor so it would be better to move it inside the /// STORAGE SLOT START /// block of variables that regroup all the non-constant and non-immutable state variables.", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Remove unused imports from code", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The current implementation of the AeraVaultV1 contract is importing OpenZeppelin IERC165 inter- face, but that interface is never used or references in the code.", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "shortfall is repeated twice in IWithdrawalValidator natspec comments", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The word shortfall is repeated twice in the natspec comment.", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "Provide definition of weights & managementFee_ in the NatSpec comment", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf", "body": "The NatSpec Format is special form of comments to provide rich documentation for functions, return variables and more. We observed an occurrence where the NatSpec comments are missing for two of the user inputs (weights & managementFee_).", "labels": ["Spearbit", "Gauntlet", "Severity: Informational"]}, {"title": "ERC721SeaDrop's modifier onlyOwnerOrAdministrator would allow either the owner or the admin to override the other person's config parameters.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "The following 4 external functions in ERC721SeaDrop have the onlyOwnerOrAdministrator modifier which allows either one to override the other person's work.  updateAllowedSeaDrop  updateAllowList  updateDropURI  updateSigner That means there should be some sort of off-chain trust established between these 2 entities. Otherwise, there are possible vectors of attack. Here is an example of how the owner can override AllowListData.merkleRoot and the other fields within AllowListData to generate proofs for any allowed SeaDrop's mintAllowList endpoint that would have MintParams.feeBps equal to 0: 1. The admin calls updateAllowList to set the Merkle root for this contract and emit ERC721SeaDrop.updateAllowList: SeaDrop.sol#L827 the other parameters as logs. for an allowed SeaDrop implementation The SeaDrop endpoint being called by 2. The owner calls updateAllowList but this time with new parameters, specifically a new Merkle root that is computed from leaves that have MintParams.feeBps == 0. 3. Users/minters use the generated proof corresponding to the latest allow list update and pass their mintParams.feeBps as 0. And thus avoiding the protocol fee deduction for the creatorPaymentAddress (SeaDrop.sol#L187-L194).", "labels": ["Spearbit", "Seadrop", "Severity: High Risk"]}, {"title": "Reentrancy of fee payment can be used to circumvent max mints per wallet check", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "In case of a mintPublic call, the function _checkMintQuantity checks whether the minter has exceeded the parameter maxMintsPerWallet, among other things. However, re-entrancy in the above fee dispersal mechanism can be used to circumvent the check. The following is an example contract that can be employed by the feeRecipent (assume that maxMintsPerWallet is 1): 7 contract MaliciousRecipient { bool public startAttack; address public token; SeaDrop public seaDrop; fallback() external payable { if (startAttack) { startAttack = false; seaDrop.mintPublic{value: 1 ether}({ nftContract: token, feeRecipient: address(this), minterIfNotPayer: address(this), quantity: 1 }); } } // Call `attack` with at least 2 ether. function attack(SeaDrop _seaDrop, address _token) external payable { token = _token; seaDrop = _seaDrop; startAttack = true; _seaDrop.mintPublic{value: 1 ether}({ nftContract: _token, feeRecipient: address(this), minterIfNotPayer: address(this), quantity: 1 }); token = address(0); seaDrop = SeaDrop(address(0)); } } This is especially bad when the parameter PublicDrop.restrictFeeRecipients is set to false, in which case, anyone can circumvent the max mints check, making it a high severity issue. In the other case, only privileged users, i.e., should be part of _allowedFeeRecipients[nftContract] mapping, would be able to circumvent the check--lower severity due to needed privileged access. Also, creatorPaymentAddress can use re-entrancy to get around the same check. See SeaDrop.sol#L571.", "labels": ["Spearbit", "Seadrop", "Severity: High Risk"]}, {"title": "Cross SeaDrop reentrancy", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "The contract that implements IERC721SeaDrop can work with multiple Seadrop implementations, for example, a Seadrop that accepts ETH as payment as well as another Seadrop contract that accepts USDC as payment at the same time. This introduces the risk of cross contract re-entrancy that can be used to circumvent the maxMintsPerWallet check. Here's an example of the attack: 1. Consider an ERC721 token that that has two allowed SeaDrop, one that accepts ETH as payment and the other that accepts USDC as payment, both with public mints and restrictedFeeRecipients set to false. 2. Let maxMintPerWallet be 1 for both these cases. 3. A malicious fee receiver can now do the following:  Call mintPublic for the Seadrop with ETH fees, which does the _checkMintQuantity check and trans- fers the fees in ETH to the receiver.  The receiver now calls mintPublic for Seadrop with USDC fees, which does the _checkMintQuantity check that still passes.  The mint succeeds in the Seadrop-USDC case.  The mint succeeds in the Seadrop-ETH case.  The minter has 2 NFTs even though it's capped at 1. Even if a re-entrancy lock is added in the SeaDrop, the same issue persists as it only enters each Seadrop contract once.", "labels": ["Spearbit", "Seadrop", "Severity: Medium Risk"]}, {"title": "Lack of replay protection for mintAllowList and mintSigned", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "merkle proofs) there are no checks that prevent re-using the same signature or Merkle proof multiple This is indirectly enforced by the _checkMintQuantity function that checks the mint statistics times. using exceeds maxMintsPerWallet. Replays can happen if a wallet does not claim all of maxMintsPerWallet in one transaction. For example, assume that maxMintsPerWallet is set to 2. A user can call mintSigned with a valid signature and quantity = 1 twice. IERC721SeaDrop(nftContract).getMintStats(minter) reverting quantity and the if Typically, contracts try to avoid any forms of signature replays, i.e., a signature can only be used once. This simpli- fies the security properties. In the current implementation of the ERC721Seadrop contract, we couldn't see a way to exploit replay protection to mint beyond what could be minted in a single initial transaction with the maximum value of quantity supplied. However, this relies on the contract correctly implementing IERC721SeaDrop.getMintStats.", "labels": ["Spearbit", "Seadrop", "Severity: Medium Risk"]}, {"title": "The digest in SeaDrop.mintSigned is not calculated correctly according to EIP-712", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "mintParams in the calculation of the digest in mintSigned is of struct type, so we would need to calculate and use its hashStruct , not the actual variable on its own.", "labels": ["Spearbit", "Seadrop", "Severity: Medium Risk"]}, {"title": "ERC721A has mint caps that are not checked by ERC721SeaDrop", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "ERC721SeaDrop inherits from ERC721A which packs balance, numberMinted, numberBurned, and an extra data chunk in 1 storage slot (64 bits per substorage) for every address. This would add an inherent cap of 264 (cid:0) 1 to all these different fields. Currently, there is no check in ERC721A's _mint for quantity nor in ERC721SeaDrop's mintSeaDrop function. Also, if we almost reach the max cap for a balance by an owner and someone else transfers a token to this owner, there would be an overflow for the balance and possibly the number of mints in the _packedAddressData. The overflow could possibly reduce the balance and the numberMinted to a way lower numer and numberBurned to a way higher number", "labels": ["Spearbit", "Seadrop", "Severity: Medium Risk"]}, {"title": "ERC721SeaDrop owner can choose an address they control as the admin when the constructor is called.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "The owner/creator can call the contract directly (skip using the UI) and set the administrator as themselves or another address that they can control. Then after they create a PublicDrop or TokenGatedDrop, they can call either updatePublicDropFee or updateTokenGatedDropFee and set the feeBps to  zero  or another number and also call the updateAllowedFeeRecipient to add the same or another address they control as a feeRecipient. This way they can circumvent the protocol fee.", "labels": ["Spearbit", "Seadrop", "Severity: Medium Risk"]}, {"title": "ERC721SeaDrop's admin would need to set feeBps manually after/before creation of each drop by the owner", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "When an owner of a ERC721SeaDrop token creates either a public or a token gated drop by calling updatePublicDrop or updateTokenGatedDrop, the PublicDrop.feeBps/TokenGatedDropStage.feeBps is initially set to 0. So the admin would need to set the feeBps parameter at some point (before or after). Forgetting to set this parameter results in not receiving the protocol fees.", "labels": ["Spearbit", "Seadrop", "Severity: Medium Risk"]}, {"title": "owner can reset feeBps set by admin for token gated drops", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "Only the admin can call updateTokenGatedDropFee to update feeBps. However, the owner can call updateTokenGatedDrop(address seaDropImpl, address allowedNftToken, TokenGatedDropStage calldata drop- Stage) twice after that to reset the feeBps to 0 for a drop. 1. Once with dropStage.maxTotalMintableByWallet equal to 0 to wipe out the storage on the SeaDrop side. 2. Then with the same allowedNftToken address and the other desired parameters, which would retrieve the previously wiped out drop stage data (with feeBps equal to 0). NOTE: This type of attack does not apply to updatePublicDrop and updatePublicDropFee pair. Since updatePub- licDrop cannot remove or update the feeBps. Once updatePublicDropFee is called with a specific feeBps that value remains for this ERC721SeaDrop contract-related storage on SeaDrop (_publicDrops[msg.sender] = pub- licDrop). And any number of consecutive calls to updatePublicDrop with any parameters cannot change the already set feeBps.", "labels": ["Spearbit", "Seadrop", "Severity: Medium Risk"]}, {"title": "Update the start token id for ERC721SeaDrop to 1", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "ERC721SeaDrop's mintSeaDrop uses _mint from ERC721A library which starts the token ids for minting from 0. /// contracts/ERC721A.sol#L154-L156 /** * @dev Returns the starting token ID. * To change the starting token ID, please override this function. */ function _startTokenId() internal view virtual returns (uint256) { return 0; }", "labels": ["Spearbit", "Seadrop", "Severity: Low Risk"]}, {"title": "Update the ERC721A library due to an unpadded toString() function", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "The audit repo uses ERC721A at dca00fffdc8978ef517fa2bb6a5a776b544c002a which does not add a trailing zero padding to the returned string. Some projects have had issues reusing the toString() where the off-chain call returned some dirty-bits at the end (similar to Seaport 1.0's name()).", "labels": ["Spearbit", "Seadrop", "Severity: Low Risk"]}, {"title": "Warn contracts implementing IERC721SeaDrop to revert on quantity == 0 case", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "There are no checks in Seadrop that prevents minting for the case when quantity == 0. This would call the function mintSeadrop(minter, quantity) for a contract implementing IERC721SeaDrop with quantity == 0. It is up to the implementing contract to revert in such cases. The ERC721A library reverts when quantity == 0--the correct behaviour. However, there has been instances in the past where ignoring quantity == 0 checks have led to security issues.", "labels": ["Spearbit", "Seadrop", "Severity: Low Risk"]}, {"title": "Missing parameter in _SIGNED_MINT_TYPEHASH", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "A parameter is missing (uint256 maxTokenSupplyForStage) and got caught after reformatting.", "labels": ["Spearbit", "Seadrop", "Severity: Low Risk"]}, {"title": "Missing address(0) check", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "All update functions having an address as an argument check them against address(0). This is missing in updateTokenGatedDrop. This is also not protected in ERC721SeaDrop.sol#updateTokenGatedDrop(), so address(0) could pass as a valid value.", "labels": ["Spearbit", "Seadrop", "Severity: Low Risk SeaDrop.sol#L856, SeaDrop.sol#L907-L909, SeaDrop.sol#L927-L929, SeaDrop.sol#L966-L968,"]}, {"title": "Missing boundary checks on feeBps", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "There's a missing check when setting feeBps from ERC721SeaDrop.sol while one exists when the value is used at a later stage in Seadrop.sol, which could cause a InvalidFeeBps error.", "labels": ["Spearbit", "Seadrop", "Severity: Low Risk"]}, {"title": "Upgrade openzeppelin/contracts's version", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "There are known vulnerabilities in the current @openzeppelin/contracts version used. This affects SeaDrop.sol with a potential Improper Verification of Cryptographic Signature vulnerability as ECDSA.recover is used.", "labels": ["Spearbit", "Seadrop", "Severity: Low Risk"]}, {"title": "struct TokenGatedDropStage is expected to fit into 1 storage slot", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "struct TokenGatedDropStage is expected to be tightly packed into 1 storage slot, as per announced in its @notice tag. However, the struct actually takes 2 slots. This is unexpected, as only one slot is loaded in the dropStageExists assembly check.", "labels": ["Spearbit", "Seadrop", "Severity: Low Risk"]}, {"title": "Avoid expensive iterations on removal of list elements by providing the index of element to be removed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "Iterating through an array (address[] storage enumeration) to find the desired element (address toRemove) can be an expensive operation. Instead, it would be best to also provide the index to be removed along with the other parameters to avoid looping over all elements. Also note in the case of _removeFromEnumeration(signer, enumeratedStorage), hopefully, there wouldn't be too many signers corresponding to a contract. So practically, this wouldn't be an issue. But something to note. Although the owner or admin can stuff the signer list with a lot of signers as the other person would not be able to remove from the list (DoS attack). For example, if the owner has stuffed the signer list with malicious signers, the admin would not be able to remove them.", "labels": ["Spearbit", "Seadrop", "Severity: Gas Optimization"]}, {"title": "mintParams.allowedNftToken should be cached", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "mintParams.allowedNftToken is accessed several times in the mintAllowedTokenHolder function. It would be cheaper to cache it: // Put the allowedNftToken on the stack for more efficient access. address allowedNftToken = mintParams.allowedNftToken;", "labels": ["Spearbit", "Seadrop", "Severity: Gas Optimization"]}, {"title": "Immutables which are calculated using keccak256 of a string literal can be made constant.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "Since Solidity 0.6.12, keccak256 expressions are evaluated at compile-time: Code Generator: Evaluate keccak256 of string literals at compile-time. The suggestion of marking these expressions as immutable to save gas isn't true for compiler versions >= 0.6.12. As a reminder, before that, the occurrences of constant keccak256 expressions were replaced by the expressions instead of the computed values, which added a computation cost.", "labels": ["Spearbit", "Seadrop", "Severity: Informational"]}, {"title": "Combine a pair of mapping to a list and mapping to a mapping into mapping to a linked-list", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "SeaDrop uses 3 pairs of mapping to a list and mapping to a mapping that can be combined into just one mapping. The pairs: 1. _allowedFeeRecipients and _enumeratedFeeRecipients 2. _signers and _enumeratedSigners 3. _tokenGatedDrops and _enumeratedTokenGatedTokens Here we have variables that come in pairs. One variable is used for data retrievals (a flag or a custom struct) and the other for iteration/enumeration. mapping(address => mapping(address => CustomStructOrBool)) private variable; mapping(address => address[]) private _enumeratedVariable;", "labels": ["Spearbit", "Seadrop", "Severity: Gas Optimization"]}, {"title": "The onlyAllowedSeaDrop modifier is redundant", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "The onlyAllowedSeaDrop modifier is always used next to another one (onlyOwner, onlyAdminis- trator or onlyOwnerOrAdministrator). As the owner, which is the least privileged role, already has the privilege to update the allowed SeaDrop registry list for this contract (by calling updateAllowedSeaDrop), this makes this second modifier redundant.", "labels": ["Spearbit", "Seadrop", "Severity: Gas Optimization"]}, {"title": "Combine _allowedSeaDrop and _enumeratedAllowedSeaDrop in ERC721SeaDrop to save storage and gas.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "Combine _allowedSeaDrop and _enumeratedAllowedSeaDrop into just one variable using a cyclic linked-list data structure. This would reduce storage space and save gas when storing or retrieving parameters.", "labels": ["Spearbit", "Seadrop", "Severity: Gas Optimization"]}, {"title": "<array>.length should not be looked up in every loop of a for-loop", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "Reading an array's length at each iteration of a loop consumes more gas than necessary.", "labels": ["Spearbit", "Seadrop", "Severity: Gas Optimization"]}, {"title": "A storage pointer should be cached instead of computed multiple times", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "Caching a mapping's value in a local storage variable when the value is accessed multiple times saves gas due to not having to perform the same offset calculation every time.", "labels": ["Spearbit", "Seadrop", "Severity: Gas Optimization"]}, {"title": "Comparing a boolean to a constant", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "Comparing to a constant (true or false) is a bit more expensive than directly checking the returned boolean value.", "labels": ["Spearbit", "Seadrop", "Severity: Gas Optimization"]}, {"title": "mintAllowList, mintSigned, or mintAllowedTokenHolder have an inherent cap for minting", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "mintAllowedTokenHolder is stored in a uint40 (after this audit uint32) which limits the maximum token id that can be minted using mintAllowList, mintSigned, or mintAllowedTokenHolder.", "labels": ["Spearbit", "Seadrop", "Severity: Informational"]}, {"title": "Consider replacing minterIfNotPayer parameter to always correspond to the minter", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "Currently, the variable minterIfNotPayer is treated in the following way: if the value is 0, then msg.sender would be considered as the minter. Otherwise, minterIfNotPayer would be considered as the minter. The logic can be simplified to always treat this variable as the minter. The 0 can be replaced by setting msg.sender as minterIfNotPayer. The variable should then be renamed as well--we recommend calling it minter afterwards.", "labels": ["Spearbit", "Seadrop", "Severity: Informational"]}, {"title": "The interface IERC721ContractMetadata does not extend IERC721 interface", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "The current interface IERC721ContractMetadata does not include the ERC-721 functions. As a comparision, OpenZeppelin's IERC721Metadata.sol extends the IERC721 interface.", "labels": ["Spearbit", "Seadrop", "Severity: Informational"]}, {"title": "Add unit tests for mintSigned and mintAllowList in SeaDrop", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "The only test for the mintSigned and the mintAllowList functions are fuzz tests.", "labels": ["Spearbit", "Seadrop", "Severity: Informational"]}, {"title": "Rename a variable with a misleading name", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "enumeratedDropsLength variable name in SeaDrop._removeFromEnumeration is a bit misleading since _removeFromEnumeration is used also for signer lists, feeRecipient lists, etc..", "labels": ["Spearbit", "Seadrop", "Severity: Informational"]}, {"title": "The protocol rounds the fees in the favour of creatorPaymentAddress", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "The feeAmount calculation rounds down, i.e., rounds in the favour of creatorPaymentAddress and against feeRecipient. For a minuscule amount of ETH (price such that price * feeBps < 10000), the fees received by the feeRecipient would be 0. An interesting case here would be if the value quantity * price * feeBps is greater than or equal to 10000 and price * feeBps < 10000. In this case, the user can split the mint transaction into multiple transactions to skip the fees. However, this is unlikely to be profitable, considering the gas overhead involved as well as the minuscule amount of savings.", "labels": ["Spearbit", "Seadrop", "Severity: Informational"]}, {"title": "Consider using type(uint).max as the magic value for maxTokenSupplyForStage instead of 0", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "The value 0 is currently used as magic value to mean that maxTokenSupplyForStage to mean that the check quantity + currentTotalSupply > maxTokenSupplyForStage. However, the value type(uint).max is a more appropriate magic value in this case. This also avoids the need for additional branching if (maxTo- kenSupplyForStage != MAGIC_VALUE) as the condition quantity + currentTotalSupply > type(uint).max is never true.", "labels": ["Spearbit", "Seadrop", "Severity: Informational"]}, {"title": "Missing edge case tests on uninitialized AllowList", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "The default value for _allowListMerkleRoots[nftContract] is 0. A transaction that tries to mint an NFT in this case with an empty proof (or any other proof) should revert. There were no tests for this case.", "labels": ["Spearbit", "Seadrop", "Severity: Informational"]}, {"title": "Consider naming state variables as public to replace the user-defined getters", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "Several state variables, for example, mapping(address => PublicDrop) private _publicDrops; but have corresponding getters defined (function getPublicDrop(address have private visibility, nftContract)). Replacing private by public and renaming the variable name can decrease the code. There are several examples of the above pattern in the codebase, however we are only listing one here for brevity.", "labels": ["Spearbit", "Seadrop", "Severity: Informational"]}, {"title": "Use bytes.concat instead of abi.encodePacked for concatenation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "While one of the uses of abi.encodePacked is to perform concatenation, the Solidity language does contain a reserved function for this: bytes.concat.", "labels": ["Spearbit", "Seadrop", "Severity: Informational"]}, {"title": "Misleading comment", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "The comment says // Check that the sender is the owner of the allowedNftTokenId.. However, minter isn't necessarily the sender due to how it's set: address minter = minterIfNotPayer != address(0) ? minterIfNotPayer : msg.sender;.", "labels": ["Spearbit", "Seadrop", "Severity: Informational"]}, {"title": "Use i instead of j as an index name for a non-nested for-loop", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "Using an index named j instead of i is confusing, as this naming convention makes developers expect that the for-loop is nested, but this is not the case. Using i is more standard and less surprising.", "labels": ["Spearbit", "Seadrop", "Severity: Informational"]}, {"title": "Avoid duplicating code for consistency", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "The _checkActive function is used in every mint function besides mintPublic where the code is almost the same.", "labels": ["Spearbit", "Seadrop", "Severity: Informational"]}, {"title": "restrictFeeRecipients is always true for either PublicDrop or TokenGatedDrop in ERC721SeaDrop", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "restrictFeeRecipients is always true for either PublicDrops or TokenGatedDrops. When either one of these drops gets created/updated by calling one of the four functions below on a ERC721SeaDrop contract, its value is hardcoded as true:  updatePublicDrop  updatePublicDropFee  updateTokenGatedDrop  updateTokenGatedDropFee", "labels": ["Spearbit", "Seadrop", "Severity: Informational"]}, {"title": "Reformat lines for better readability", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "These lines are too long to be readable. A mistake isn't easy to spot.", "labels": ["Spearbit", "Seadrop", "Severity: Informational"]}, {"title": "Comment is a copy-paste", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": "This comment is exactly the same as this one. This is a copy-paste mistake.", "labels": ["Spearbit", "Seadrop", "Severity: Informational"]}, {"title": "Usage of floating pragma is not recommended", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf", "body": " 0.8.11 is declared in files.  In foundry.toml: solc_version = '0.8.15' is used for the default build profile.  In hardhat.config.ts and hardhat-coverage.config.ts: \"0.8.14\" is used. 31", "labels": ["Spearbit", "Seadrop", "Severity: Informational"]}, {"title": "Clones with malicious extradata are also considered valid clones", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "Spearbit discovered that the functions verifying if a contract is a pair do so by only checking the rst 54 bytes (i.e. the Proxy code). An attacker could deploy a contract that starts with the rst 54 bytes of proxy code but have a malicious payload, and these functions will still verify it as a legitimate clone. We have found this to be a critical issue based on the feasibility of a potential exploit. Consider the following scenario: 1. An attacker creates a malicious pair by making a copy of the source of cloneETHPair() supplying malicious values for factory, bondingCurve, nft and poolType using a valid template for the connected contract. 2. The attacker has a contract with valid proxy code, connected to a valid template, but the rest of the parameters are invalid. 3. The Pair is initialized via a copy of initialize() of LSSVMPair, which calls __Ownable_init() to set a malicious owner. 4 4. The malicious owner calls call(), with target equal to the router contract and the calldata for the function pairTransferERC20From(): // Owner is set by pair creator function call(address payable target, bytes calldata data) external onlyOwner { // Factory is malicious LSSVMPairFactoryLike _factory = factory(); // `callAllowed()` is malicious and returns true require(_factory.callAllowed(target), \"Target must be whitelisted\"); (bool result, ) = target.call{value: 0}(data); require(result, \"Call failed\"); ,! } 5. The check for onlyOwner and require pass, therefore pairTransferERC20From() is called with the malicious Pair as msg.sender. 6. The router checks if it is called from a valid pair via isPair(): function pairTransferERC20From(...) external { // Verify caller is a trusted pair contract // The malicious pair passed this test require(factory.isPair(msg.sender, variant), \"Not pair\"); ... token.safeTransferFrom(from, to, amount); } 7. Because the function isPair() only checks the rst 54 bytes (the runtime code including the implementation address), isPair() does not check for extra parameters factory, bondingCurve, nft or poolType: 5 function isPair(address potentialPair, PairVariant variant) ... { ... } else if (variant == PairVariant.ENUMERABLE_ETH) { return ,! LSSVMPairCloner.isETHPairClone(address(enumerableETHTemplate),potentialPair); } ... } function isETHPairClone(address implementation, address query) ... { ... // Compare expected bytecode with that of the queried contract let other := add(ptr, 0x40) extcodecopy(query, other, 0, 0x36) result := and( eq(mload(ptr), mload(other)), // Checks 32 + 22 = 54 bytes eq(mload(add(ptr, 0x16)), mload(add(other, 0x16))) ) } 8. Now the malicious pair is considered valid, the require statement in pair- TransferERC20From() has passed and tokens can be transferred to the attacker from anyone who has set an allowance for the router.", "labels": ["Spearbit", "Sudoswap", "Severity: Critical Risk"]}, {"title": "Factory Owner can steal user funds approved to the Router", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "A pair owner can make arbitrary calls to any contract that has been approved by the factory owner. The code in the factory intends to prevent 6 router contracts from being approved for calls because router contracts can have access to user funds. An example includes the pairTransferERC20From() function, that can be used to steal funds from any account which has given it approval. The router contracts can nevertheless be whitelisted by rst being removed as a router and then being whitelisted. This way anyone can deploy a pair and use the call function to steal user funds.", "labels": ["Spearbit", "Sudoswap", "Severity: High Risk"]}, {"title": "Missing check in the number of Received Tokens when tokens are transferred directly", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "Within the function _validateTokenInput() of LSSVMPairERC20, two methods exist to transfer tokens. In the rst method via router.pairTrans ferERC20From() a check is performed on the number of received tokens. In the second method no checks are done. Recent hacks (e.g. Qubit nance) have successfully exploited safeTransfer- From() functions which did not revert nor transfer tokens. Additionally, with malicious or re-balancing tokens the number of transferred tokens might be dif- ferent from the amount requested to be transferred. 7 function _validateTokenInput(...) ... { ... if (isRouter) { ... // Call router to transfer tokens from user uint256 beforeBalance = _token.balanceOf(_assetRecipient); router.pairTransferERC20From(...) // Verify token transfer (protect pair against malicious router) require( _token.balanceOf(_assetRecipient) - beforeBalance == ,! inputAmount, \"ERC20 not transferred in\"); } else { // Transfer tokens directly _token.safeTransferFrom(msg.sender, _assetRecipient, inputAmount); } }", "labels": ["Spearbit", "Sudoswap", "Severity: Medium Risk"]}, {"title": "Malicious assetRecipient could get an unfair amount of tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "The function _swapNFTsForToken() of LSSVMRouter calls safe- TransferFrom(), which then calls ERC721Received of assetRecipient. A ma- licious assetRecipient could manipulate its NFT balance by buying additional NFTs via the Pair and sending or selling them back to the Pair, enabling the malicious actor to obtain an unfair amount of tokens via routerSwapNFTsForTo- ken(). 8 function _swapNFTsForToken(...) ... { ... swapList[i].pair.cacheAssetRecipientNFTBalance(); ... for (uint256 j = 0; j < swapList[i].nftIds.length; j++) { ,! ,! nft.safeTransferFrom(msg.sender,assetRecipient,swapList[i].nftIds[j]); // call to onERC721Received of assetRecipient } ... outputAmount += swapList[i].pair.routerSwapNFTsForToken(tokenRecipient); // checks the token balance of assetRecipient } ,! ,! }", "labels": ["Spearbit", "Sudoswap", "Severity: Medium Risk"]}, {"title": "Malicious Router can exploit cacheAssetRecipientNFTBalance to drain pair funds", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "A malicious router could be whitelisted by an inattentive or a ma- licious factory owner and drain pair funds in the following exploit scenario: 1. Call the cache function. Suppose that the current balance is 10, so it gets cached. 2. Sell 5 NFTs to the pair and get paid using swapNFTsForToken. Total bal- ance is now 15 but the cached balance is still 10. 3. Call routerSwapNFTsForToken. This function will compute total_balance 9 - cached_balance, assume 5 NFTs have been sent to it and pay the user. However, no new NFTs have been sent and it already paid for them in Step 2.", "labels": ["Spearbit", "Sudoswap", "Severity: Medium Risk"]}, {"title": "Malicious Router can steal NFTs via Re-Entrancy attack", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "If the factory owner approves a malicious _router, it is possible for the malicious router to call functions like swapTokenForAnyNFTs() and set is- Router to true. Once that function reaches router.pairTransferERC20From() in _validateTokenInput(), they can re-enter the pair from the router and call swapTokenForAnyNFTs() again. This second time the function reaches router.pairTransferERC20From(), al- lowing the malicious router to execute a token transfer so that the require of _validateTokenInput is satised when the context returns to the pair. When the context returns from the reentrant call back to the original call, the require of _validateTokenInput would still pass because the balance was cached be- fore the reentrant call. Therefore, an attacker will receive 2 NFTs by sending tokens only once.", "labels": ["Spearbit", "Sudoswap", "Severity: Medium Risk"]}, {"title": "getAllHeldIds() of LSSVMPairMissingEnumerable is vulnerable to a denial of service attack", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "The contract LSSVMPairMissingEnumerable tries to compensate for NFT contracts that do not have ERC721Enumerable implemented. However, this cannot be done for everything as it is possible to use transferFrom() to send an NFT from the same collection to the Pair. In that case the callback on- ERC721Received() will not be triggered and the idSet administration of LSSVM- PairMissingEnumerable will not be updated. This means that nft().balanceO f(address(this)); can be different from the elements in idSet. Assuming an actor accidentally, or on purpose, uses transferFrom() to send additional NFTs to the Pair, getAllHeldIds() will fail as idSet.at(i) for unregistered NFTs will fail. This can be used in a grieng attack. getAllHeldIds() in LSSVMPairMissingEnumerable: function getAllHeldIds() external view override returns (uint256[] memory) { uint256 numNFTs = nft().balanceOf(address(this)); // returns the registered + unregistered NFTs uint256[] memory ids = new uint256[](numNFTs); for (uint256 i; i < numNFTs; i++) { ids[i] = idSet.at(i); // will fail at the unregistered NFTs } return ids; ,! } The following checks performed with _nft.balanceOf() might not be accurate in combination with LSSVMPairMissingEnumerable. Risk is low because any additional NFTs making later calls to _sendAnyNFTsToRecipient() and _send- SpecificNFTsToRecipient() will fail. However, this might make it more difcult to troubleshoot issues. 11 function swapTokenForAnyNFTs(...) .. { ,! ... require((numNFTs > 0) && (numNFTs <= _nft.balanceOf(address(this))),\"Ask for > 0 and <= balanceOf NFTs\"); ... _sendAnyNFTsToRecipient(_nft, nftRecipient, numNFTs); // could fail ... } function swapTokenForSpecificNFTs(...) ... { ... require((nftIds.length > 0) && (nftIds.length <= _nft.balanceOf(address(this))),\"Must ask for > 0 and < balanceOf NFTs\"); // '<' should be '<=' ... _sendSpecificNFTsToRecipient(_nft, nftRecipient, nftIds); // could fail ... ,! ,! } Note: The error string < balanceOf NFTs is not accurate.", "labels": ["Spearbit", "Sudoswap", "Severity: Medium Risk"]}, {"title": "With NFT pools the protocol fees end up in assetRecipient instead of _factory", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "Assume a scenario where an NFT pool with assetRecipient set have the received funds sent directly to the assetRecipient. Now, suppose a user executes the swapTokenForSpecificNFTs(). The function _validateTokenInput() sends the required input funds, including fees to the assetRecipient. The function _payProtocolFee() tries to send the fees to the _factory. However, this function attempts to do so from the pair con- tract. The pair contract does not have any funds because they have been sent directly to the assetRecipient. So following this action the payProtocolFee() lowers the fees to 0 and sends this number to the _factory while fees end up at assetRecipient' instead of at the _factory. The fees then end up at assetRecipient instead of at the _factory. Note:  The same issue occurs in swapTokenForAnyNFTs().  This issue occurs with both ETH and ERC20 NFT Pools, although their logic is slightly different.  This issue occurs both when swapTokenForSpecificNFTs() is called di- rectly as well as indirectly via the LSSVMRouter.  Although the pool fees are 0 with NFT pools, the factory fee is still present.  Luckily, TRADE pools cannot have an assetRecipient as this would also create issues. 13 abstract contract LSSVMPair is Ownable, ReentrancyGuard { ... function swapTokenForSpecificNFTs(...) external payable virtual returns (uint256 inputAmount) { ,! ... _validateTokenInput(inputAmount, isRouter, routerCaller, _factory); // ,! sends inputAmount to assetRecipient _sendSpecificNFTsToRecipient(_nft, nftRecipient, nftIds); _refundTokenToSender(inputAmount); _payProtocolFee(_factory, protocolFee); ... } } abstract contract LSSVMPairERC20 is LSSVMPair { ... function _payProtocolFee(LSSVMPairFactoryLike _factory, uint256 protocolFee) internal override { ,! ... uint256 pairTokenBalance = _token.balanceOf(address(this)); if (protocolFee > pairTokenBalance) { protocolFee = pairTokenBalance; } _token.safeTransfer(address(_factory), protocolFee); // tries to send from the Pair contract } ,! } abstract contract LSSVMPairETH is LSSVMPair { function _payProtocolFee(LSSVMPairFactoryLike _factory, uint256 protocolFee) internal override { ,! ... uint256 pairETHBalance = address(this).balance; if (protocolFee > pairETHBalance) { protocolFee = pairETHBalance; } payable(address(_factory)).safeTransferETH(protocolFee); // tries to send from the Pair contract } ,! }", "labels": ["Spearbit", "Sudoswap", "Severity: Medium Risk"]}, {"title": "Error codes of Quote functions are unchecked", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "The error return values from functions getBuyNFTQuote() and getSellNFTQuote() are not checked in contract LSSVMRouter.sol, whereas other functions in contract LSSVMPair.sol do check for error==CurveErrorCodes.Err or.OK. abstract contract LSSVMPair is Ownable, ReentrancyGuard { ,! ,! ,! ... function getBuyNFTQuote(uint256 numNFTs) external view returns (CurveErrorCodes.Error error, ...) { (error, ...) = bondingCurve().getBuyInfo(...); } function getSellNFTQuote(uint256 numNFTs) external view returns (CurveErrorCodes.Error error, ...) { (error, ...) = bondingCurve().getSellInfo(...); } function swapTokenForAnyNFTs(...) (uint256 inputAmount) { external payable virtual returns ... (error, ...) = _bondingCurve.getBuyInfo(...); require(error == CurveErrorCodes.Error.OK, \"Bonding curve error\"); ... } } LSSVMRouter.sol#L526 (, , pairOutput, ) = swapList[i].pair.getSellNFTQuote(...); The following contract lines contain the same code snippet below: LSSVMRoute r.sol#L360, LSSVMRouter.sol#L407, LSSVMRouter.sol#L450, LSSVMRouter.so l#L493, LSSVMRouter.sol#L627, LSSVMRouter.sol#L664 (, , pairCost, ) = swapList[i].pair.getBuyNFTQuote(...); Note: The current Curve contracts, which implement the getBuyNFTQuote() and getSellNFTQuote() functions, have a limited number of potential errors. However, future Curve contracts might add additional error codes.", "labels": ["Spearbit", "Sudoswap", "Severity: Medium Risk"]}, {"title": "Swaps can be front run by Pair Owner to extract any prot from slippage allowance", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "If the user adds a nonzero slippage allowance, the pair owner can front run the swap to increase the fee/spot price and steal all of the slippage allowance. This basically makes sandwich attacks much easier and cheaper to execute for the pair owner.", "labels": ["Spearbit", "Sudoswap", "Severity: Low Risk"]}, {"title": "Add check for numItems == 0", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "Functions getBuyInfo() and getSellInfo() in LinearCurve.sol check that numItems != 0. However, the same getBuyInfo() and getSellInfo() functions in ExponentialCurve.sol do not perform this check. 17 contract LinearCurve is ICurve, CurveErrorCodes { function getBuyInfo(...) ... { // We only calculate changes for buying 1 or more NFTs if (numItems == 0) { return (Error.INVALID_NUMITEMS, 0, 0, 0); } ... } function getSellInfo(...) ... { // We only calculate changes for selling 1 or more NFTs if (numItems == 0) { return (Error.INVALID_NUMITEMS, 0, 0, 0); } ... } } contract ExponentialCurve is ICurve, CurveErrorCodes { function getBuyInfo(...) ... { // No check on `numItems` uint256 deltaPowN = delta.fpow(numItems, FixedPointMathLib.WAD); ... } function getSellInfo(... ) ... { // No check on `numItems` uint256 invDelta = ,! FixedPointMathLib.WAD.fdiv(delta,FixedPointMathLib.WAD); ... } } If the code remains unchanged, an erroneous situation may not be caught and funds might be sent when selling 0 NFTs. Luckily, when numItems == 0 then result outputValue of the functions in Expo- nentialCurve is still 0, so there is no real issue. However, it is still important to x this because a derived version of these functions might be used by future developers.", "labels": ["Spearbit", "Sudoswap", "Severity: Low Risk"]}, {"title": "Disallow arbitrary function calls to LSSVMPairETH", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "The contract LSSVMPairETH contains an open fallback() func- tion. The fallback() is most likely necessary because the proxy adds calldata and the receive() function, therefore not receiving the ETH. However, without additional checks any function call to an ETH Pair will succeed. This could result in unforseen scenarios which hackers could potentially exploit. fallback() external payable { emit TokenDeposited(msg.value); }", "labels": ["Spearbit", "Sudoswap", "Severity: Low Risk"]}, {"title": "Only transfer relevant funds for PoolType", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "The functions _initializePairETH() and _initializePairERC20() allow for the transfer of ETH/ERC20 and NFTs even when this is not relevant for the PoolType. Although funds can be rescued from the Pair, it is perhaps better to prevent these types of mistakes. 19 function _initializePairETH(...) ... { ... // Transfer initial `ETH` to `pair` // Only relevant for `PoolType.TOKEN` or `PoolType.TRADE` payable(address(_pair)).safeTransferETH(msg.value); ... // Transfer initial `NFT`s from `sender` to `pair` for (uint256 i = 0; i < _initialNFTIDs.length; i++) { // Only relevant for PoolType.NFT or PoolType.TRADE _nft.safeTransferFrom(msg.sender,address(_pair),_initialNFTIDs[i]); } } function _initializePairERC20(...) ... { ... // Transfer initial tokens to pair // Only relevant for PoolType.TOKEN or PoolType.TRADE _token.safeTransferFrom(msg.sender,address(_pair),_initialTokenBalance); ... // Transfer initial NFTs from sender to pair for (uint256 i = 0; i < _initialNFTIDs.length; i++) { // Only relevant for PoolType.NFT or PoolType.TRADE _nft.safeTransferFrom(msg.sender,address(_pair),_initialNFTIDs[i]); } }", "labels": ["Spearbit", "Sudoswap", "Severity: Low Risk"]}, {"title": "Check for 0 parameters", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "Functions setCallAllowed() and setBondingCurveAllowed() do not check that target != 0 while the comparable function setRouterAllowed() does check for _router != 0. 20 function setCallAllowed(address payable target, bool isAllowed) external ,! onlyOwner { ... // No check on target callAllowed[target] = isAllowed; } function setBondingCurveAllowed(ICurve bondingCurve, bool isAllowed) external ,! onlyOwner { ... // No check on bondingCurve bondingCurveAllowed[bondingCurve] = isAllowed; } function setRouterAllowed(LSSVMRouter _router, bool isAllowed) external onlyOwner { require(address(_router) != address(0), \"0 router address\"); ... routerAllowed[_router] = isAllowed; ,! }", "labels": ["Spearbit", "Sudoswap", "Severity: Low Risk"]}, {"title": "Potentially undetected underow In assembly", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "Functions factory(), bondingCurve(), nft(), poolType(), and token() have an assembly based calculation where the paramsLength is sub- tracted from calldatasize(). Assembly underow checks are disregarded and if too few parameters are supplied in calls to the functions in the LSSVMPair contract, this calculation may underow, resulting in the values for factory(), bondingCurve(), nft(), poolType(), and token() to be read from unexpected pieces of memory. This will be usually zeroed therefore execution will stop at some point. However, it is safer to prevent this from ever happening. 21 function factory() public pure returns (LSSVMPairFactoryLike _factory) { ... assembly {_factory := shr(0x60,calldataload(sub(calldatasize(), paramsLength)))} ,! } function bondingCurve() public pure returns (ICurve _bondingCurve) { ... assembly {_bondingCurve := shr(0x60,calldataload(add(sub(calldatasize(), paramsLength), 20)))} ,! } function nft() public pure returns (IERC721 _nft) { ... assembly {_nft := shr(0x60,calldataload(add(sub(calldatasize(), paramsLength), 40)))} ,! } function poolType() public pure returns (PoolType _poolType) { ... assembly {_poolType := shr(0xf8,calldataload(add(sub(calldatasize(), paramsLength), 60)))} ,! } function token() public pure returns (ERC20 _token) { ... assembly {_token := shr(0x60,calldataload(add(sub(calldatasize(), paramsLength), 61)))} ,! }", "labels": ["Spearbit", "Sudoswap", "Severity: Low Risk"]}, {"title": "Check number of NFTs is not 0", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "Functions swapNFTsForToken(), routerSwapNFTsForToken(), and getSellNFTQuote() in LSSVMPair.sol do not perform input verication on the number of NFTs. If _bondingCurve.getSellInfo() accidentally happens to re- turn a non-zero value, then an unfair amount of tokens will be given back to the caller. The current two versions of bondingCurve do return 0, but a future version might accidentally return non-zero. Note: 1. getSellInfo() is supposed to return an error when numNFTs == 0, but this does not always happen. This error code is not always checked. function swapNFTsForToken(uint256[] calldata nftIds, ...) external virtual ,! ,! returns (uint256 outputAmount) { ... // No check on `nftIds.length` (error, newSpotPrice, outputAmount, protocolFee) = nftIds.length,..); _bondingCurve.getSellInfo(..., ... } function routerSwapNFTsForToken(address payable tokenRecipient) ... { ,! ... uint256 numNFTs = _nft.balanceOf(getAssetRecipient()) - _assetRecipientNFTBalanceAtTransferStart; ... // No check that `numNFTs > 0` (error, newSpotPrice, outputAmount, protocolFee) = _bondingCurve.getSellInfo(..., numNFTs, ...); ,! } function getSellNFTQuote(uint256 numNFTs) ... { ... // No check that `numNFTs > 0` (error, newSpotPrice, outputAmount, protocolFee) = bondingCurve().getSellInfo(..., numNFTs,...); ... ,! } 2. For comparison, the function swapTokenForSpecificNFTs() does perform an entry check on the number of requested NFTs. 23 function swapTokenForSpecificNFTs(uint256[] calldata nftIds,...) ... { ... //There is a check on the number of requested `NFT`s require( (nftIds.length > 0) && (nftIds.length <= _nft.balanceOf(address(this))), \"Must ask for > 0 and < balanceOf NFTs\"); // check is present ... ,! ,! }", "labels": ["Spearbit", "Sudoswap", "Severity: Low Risk 22"]}, {"title": "Avoid utilizing inside knowledge of functions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "ETH based swap functions use isRouter==false and router- Caller==address(0) as parameters to swapTokenForAnyNFTs() and swapToken- ForSpecificNFTs(). These parameters end up in _validateTokenInput(). The LSSVMPairETH version of this function does not use those parameters, so it is not a problem at this point. However, the call actually originates from the Router so functionally isRouter should be true. Our concern is that using inside knowledge of the functions might potentially introduce subtle issues in the following scenarios: 24 function robustSwapETHForAnyNFTs(...) ... { ... remainingValue -= swapList[i].pair.swapTokenForAnyNFTs{value: pairCost}(swapList[i].numItems, nftRecipient, false, address(0)); ... ,! } function robustSwapETHForSpecificNFTs(...) ... { ... remainingValue -= swapList[i].pair.swapTokenForSpecificNFTs{value: pairCost}(swapList[i].nftIds, nftRecipient, false, address(0)); ... ,! } function _swapETHForAnyNFTs(...) ... { ... remainingValue -= swapList[i].pair.swapTokenForAnyNFTs{value: pairCost}(swapList[i].numItems, nftRecipient, false, address(0)); ... ,! } function _swapETHForSpecificNFTs(...) ... { ... remainingValue -= swapList[i].pair.swapTokenForSpecificNFTs{value: ,! pairCost}(swapList[i].nftIds, nftRecipient, false, address(0)); ... } function swapTokenForAnyNFTs(..., bool isRouter, address routerCaller) ... { ... _validateTokenInput(inputAmount, isRouter, routerCaller, _factory); ... } function swapTokenForSpecificNFTs(..., bool isRouter, address routerCaller) ... { ... _validateTokenInput(inputAmount, isRouter, routerCaller, _factory); ... ,! } abstract contract LSSVMPairETH is LSSVMPair { function _validateTokenInput(..., bool, /*isRouter*/ /*routerCaller*/ ... ) { address, // doesn't use isRouter and routerCaller } ,! }", "labels": ["Spearbit", "Sudoswap", "Severity: Low Risk"]}, {"title": "Add Reentrancy Guards", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "The abovementioned permalinks and corresponding functions are listed for Sudoswaps consideration to introduce reentrancy guard modiers. Currently, there is only one function that uses a reentrancy guard modier: withdrawAllETH() in LSSVMPairETH.sol#L94. Other functions in the codebase may also require reentrancy guard modiers. We have only seen reentrancy problems when malicious routers, assetRecip- ients, curves, factory owner or protocolFeeRecipient are involved. Despite normal prohibitions on this occurence, it is better to protect ones codebase than regret leaving open vulnerabilities available for potential attackers. There are three categories of functions that Sudoswap should consider applying reen- trancy guard modiers to: functions withdrawing ETH, functions sending ETH, and uses of safeTransferFrom() to external addresses (which will trigger an onERC1155Received() callback to receiving contracts). Examples of functions withdrawing ETH within LSSVM: LSSVMPairFactory.sol#L272 LSSVMPairETH.sol#L104 Instances of functions sending ETH within LSSVM: LSSVMPairETH.sol#L34 LSSVMPairETH.sol#L46 A couple of instances that use safeTransferFrom() to call external addresses, which will trigger an onERC1155Received() callback to receiving contracts: LSSVM- PairFactory.sol#L428 LSSVMRouter.sol#L544", "labels": ["Spearbit", "Sudoswap", "Severity: Low Risk"]}, {"title": "Saving 1 byte off the constructor() code", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "The dup2 before the return in the code below indicates a possible optimization by rearranging the stack. function cloneETHPair(...) ... { assembly { ... | RETURNDATASIZE // 3d | PUSH1 runtime // 60 runtime | DUP1 // 80 // 60 creation | PUSH1 creation (c) // 3d // 39 | RETURNDATASIZE | CODECOPY ,! ,! ,! [0-2d]: runtime code // 81 | DUP2 [0-2d]: runtime code // f3 | RETURN [0-2d]: runtime code ... } } | 0 (r) | r 0 | r r 0 | c r r 0 | 0 c r r 0 | r 0 | 0 c 0 | 0 |  |  |  |  |  | | |", "labels": ["Spearbit", "Sudoswap", "Severity: Gas Optimization"]}, {"title": "Decode extradata in calldata in one go", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "Spearbit discovered that the functions factory(), bondingCurve() and nft() are called independently but in most use cases all of the data is re- quired.", "labels": ["Spearbit", "Sudoswap", "Severity: Gas Optimization"]}, {"title": "Transfer last NFT instead of rst", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "When executing _sendAnyNFTsToRecipient() NFTs are retrieved by taking the rst available NFT and then sending it to nftRecipient. In (most) ERC721 implementations as well as in the EnumerableSet implementation, the array that stores the ownership is updated by swapping the last element with the selected element, to be able to shrink the array afterwards. When you always transfer the last NFT instead of the rst NFT, swapping isnt necessary so gas is saved. Code related to LSSVMPairEnumerable.sol: 29 abstract contract LSSVMPairEnumerable is LSSVMPair { function _sendAnyNFTsToRecipient(IERC721 _nft, address nftRecipient, uint256 numNFTs) internal override { ... for (uint256 i = 0; i < numNFTs; i++) { uint256 nftId = IERC721Enumerable(address(_nft)).tokenOfOwnerByIndex(address(this), 0); take the first NFT // _nft.safeTransferFrom(address(this), nftRecipient, nftId); // this calls _beforeTokenTransfer of ERC721Enumerable ,! ,! ,! ,! } } } abstract contract ERC721Enumerable is ERC721, IERC721Enumerable { function _beforeTokenTransfer(address from, address to, uint256 tokenId) internal virtual override { ,! ... _removeTokenFromOwnerEnumeration(from, tokenId); ... } function _removeTokenFromOwnerEnumeration(address from, uint256 tokenId) private { ... uint256 lastTokenIndex = ERC721.balanceOf(from) - 1; uint256 tokenIndex = _ownedTokensIndex[tokenId]; // When the token to delete is the last token, the swap operation is unnecessary ==> we can make use of this if (tokenIndex != lastTokenIndex) { uint256 lastTokenId = _ownedTokens[from][lastTokenIndex]; _ownedTokens[from][tokenIndex] = lastTokenId; // Move the last token to the slot of the to-delete token _ownedTokensIndex[lastTokenId] = tokenIndex; // Update the moved token's index } // This also deletes the contents at the last position of the array delete _ownedTokensIndex[tokenId]; delete _ownedTokens[from][lastTokenIndex]; ,! ,! ,! ,! } } Code related to LSSVMPairMissingEnumerable.sol: 30 abstract contract LSSVMPairMissingEnumerable is LSSVMPair { function _sendAnyNFTsToRecipient(IERC721 _nft, address nftRecipient, uint256 numNFTs) internal override { ,! ... for (uint256 i = 0; i < numNFTs; i++) { uint256 nftId = idSet.at(0); // take the first NFT _nft.safeTransferFrom(address(this), nftRecipient, nftId); idSet.remove(nftId); // finally calls _remove() } } } library EnumerableSet { function _remove(Set storage set, bytes32 value) private returns (bool) { ... uint256 toDeleteIndex = valueIndex - 1; uint256 lastIndex = set._values.length - 1; if (lastIndex != toDeleteIndex) { // ==> we can make use of this bytes32 lastvalue = set._values[lastIndex]; set._values[toDeleteIndex] = lastvalue; // Move the last value to the index where the value to delete is set._indexes[lastvalue] = valueIndex; // Replace lastvalue's index to valueIndex ,! ,! } set._values.pop(); delete set._indexes[value]; ... // Delete the slot where the moved value was stored // Delete the index for the deleted slot } }", "labels": ["Spearbit", "Sudoswap", "Severity: Gas Optimization"]}, {"title": "Simplify the connection between Pair and Router", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "There are two ways to interact between Pair and Router: 1. LSSVMPairERC20.sol calls router.pairTransferERC20From, where the goal is to transfer ERC20 2. _swapNFTsForToken calls pair.cacheAssetRecipientNFTBalance and pa ir.routerSwapNFTsForToken, where the goal is to transfer NFTs Using two different patterns to solve the same problem makes the code more com- plex and larger than necessary. Patterns with cacheAssetRecipientNFTBa lance() are also error prone. abstract contract LSSVMPairERC20 is LSSVMPair { function _validateTokenInput(..., bool isRouter, ...) ... { ... if (isRouter) { LSSVMRouter router = LSSVMRouter(payable(msg.sender)); // Verify ,! if router is allowed require(_factory.routerAllowed(router), \"Not router\"); ... router.pairTransferERC20From( _token, routerCaller, _assetRecipient, inputAmount, pairVariant() ); ... } ... } } contract LSSVMRouter { function pairTransferERC20From(...) ... { // verify caller is a trusted pair contract require(factory.isPair(msg.sender, variant), \"Not pair\"); ... // transfer tokens to pair token.safeTransferFrom(from, to, amount); // transfer ERC20 from the original caller } ,! } 33 contract LSSVMRouter { function _swapNFTsForToken(...) ... { ... // Cache current asset recipient balance swapList[i].pair.cacheAssetRecipientNFTBalance(); ... for (uint256 j = 0; j < swapList[i].nftIds.length; j++) { ,! ,! nft.safeTransferFrom(msg.sender,assetRecipient,swapList[i].nftIds[j]); // transfer NFTs from the original caller } ... outputAmount += ,! swapList[i].pair.routerSwapNFTsForToken(tokenRecipient); ... } } abstract contract LSSVMPair is Ownable, ReentrancyGuard { function cacheAssetRecipientNFTBalance() external { require(factory().routerAllowed(LSSVMRouter(payable(msg.sender))),\"Not router\"); // Verify if router is allowed assetRecipientNFTBalanceAtTransferStart = nft().balanceOf(getAssetRecipient()) + 2; } ,! ,! }", "labels": ["Spearbit", "Sudoswap", "Severity: Gas Optimization"]}, {"title": "Cache array length", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "An array length is frequently used in for loops. This value is an evaluation for every iteration of the loop. Assuming the arrays are regularly larger than 1, it saves some gas to store the array length in a temporary variable. The following snippets are samples of the above context for lines of code where this is relevant: LSSVMPairEnumerable.sol#L51 LSSVMPairFactory.sol#L378 LSSVMPairMissingEnumerable.sol#L57 LSSVMRouter.sol#L358 For more examples, please see the context above for exact lines where this applies. The following contains examples of the overusage of nftIds.length: 35 function swapTokenForSpecificNFTs(...) ... { ... require((nftIds.length > 0) && (nftIds.length <= _nft.balanceOf(address(this))),\"Must ask for > 0 and < balanceOf NFTs\"); ... (error, newSpotPrice, inputAmount, protocolFee) = _bondingCurve ,! .getBuyInfo( spotPrice, delta, nftIds.length, fee, _factory.protocolFeeMultiplier() ); ... }", "labels": ["Spearbit", "Sudoswap", "Severity: Gas Optimization"]}, {"title": "Use Custom Errors", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "Strings are used to encode error messages. With the current Solidity versions it is possible to replace them with custom errors, which are more gas efcient. Example of non-custom errors used in LSSVM : LSSVMRouter.sol#L604 require(block.timestamp <= deadline, \"Deadline passed\"); LSSVMRouter.sol#L788 require(outputAmount >= minOutput, \"outputAmount too low\"); Note: This pattern has been used in Ownable.sol#L6-L7", "labels": ["Spearbit", "Sudoswap", "Severity: Gas Optimization"]}, {"title": "Alternatives for the immutable Proxy variables", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "In the current LSSVMPairClone, the immutable variables stored in the proxy are sent along with every call. It may be possible to optimize this. 37", "labels": ["Spearbit", "Sudoswap", "Severity: Gas Optimization"]}, {"title": "Pair implementations may not be Proxies", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "The security of function pairTransferERC20From() relies on is- Pair(). In turn, isPair() relies on both isETHPairClone() and isERC20PairClone(). These functions check that a valid proxy is used with a valid implementation ad- dress. However, if the implementation address itself is a proxy it could link to any other contract. In this case security could be undermined depending on the implementation details. This is not how the protocol is designed, but future developers or developers using a fork of the code might not be aware of this.", "labels": ["Spearbit", "Sudoswap", "Severity: Informational"]}, {"title": "NFT and Token Pools can be signed orders instead", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "Currently if any actor wants to create a buy/sell order they would have to create a new pool and pay gas for it. However, the advantage of this is unclear. TOKEN and NFT type pools can really be buy/sell orders at a price curve using signed data. This is reminiscent of how similar limit orders implemented by OpenSea, 1Inch, and SushiSwap currently function. Amending this in the codebase would make creating buy/sell orders free and should attract more liquidity and/or orders to Sudoswap.", "labels": ["Spearbit", "Sudoswap", "Severity: Informational"]}, {"title": "Remove Code Duplication", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "Functions like swapTokenForAnyNFTs and swapTokenForSpeci- ficNFTs are nearly identical and can be deduplicated by creating a common internal function. On the other hand this will slightly increase gas usage due to an extra jump.", "labels": ["Spearbit", "Sudoswap", "Severity: Informational"]}, {"title": "Unclear Function Name", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "The functions _validateTokenInput() of both LSSVMPairETH and LSSVMPairERC20 do not only validate the token input but also transfer ETH/ERC20. The function name does not reasonably imply this and therefore can create some confusion. 40 abstract contract LSSVMPairETH is LSSVMPair { function _validateTokenInput(...) ... { ... _assetRecipient.safeTransferETH(inputAmount); ... } } abstract contract LSSVMPairERC20 is LSSVMPair { function _validateTokenInput(...) ... { ... if (isRouter) { ... router.pairTransferERC20From(...); // transfer of tokens ... } else { // Transfer tokens directly _token.safeTransferFrom(msg.sender, _assetRecipient, inputAmount); } } }", "labels": ["Spearbit", "Sudoswap", "Severity: Informational"]}, {"title": "Inaccurate Message About MAX_FEE", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "The function initialize() of LSSVMPair has an error message containing less than 100%. This is likely an error and should probably be less than 90%, as in the changeFee() function and because MAX_FEE == 90%. 41 // 90%, must <= 1 - MAX_PROTOCOL_FEE (set in LSSVMPairFactory) uint256 internal constant MAX_FEE = 9e17; function initialize(..., uint256 _fee, ...) external payable { ... require(_fee < MAX_FEE, \"Trade fee must be less than 100%\"); // 100% should be 90% ... ,! } function changeFee(uint256 newFee) external onlyOwner { ... require(newFee < MAX_FEE, \"Trade fee must be less than 90%\"); ... }", "labels": ["Spearbit", "Sudoswap", "Severity: Informational"]}, {"title": "Inaccurate comment for assetRecipientNFTBalanceAtTransferStart", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "The comment in LSSVMPair notes that assetRecipientNFTBal- anceAtTransferStart is 0; however, in routerSwapNFTsForToken() the variable assetRecipientNFTBalanceAtTransferStart is set to 1. As such, the below comment is probably inaccurate. // Temporarily used during LSSVMRouter::_swapNFTsForToken to store the number of NFTs transferred ,! // directly to the pair. Should be 0 outside of the execution of routerSwapAnyNFTsForToken. ,! uint256 internal `assetRecipientNFTBalanceAtTransferStart`; function routerSwapNFTsForToken(address payable tokenRecipient) ... { ... assetRecipientNFTBalanceAtTransferStart = 1; ... } 42", "labels": ["Spearbit", "Sudoswap", "Severity: Informational"]}, {"title": "IERC1155 not utilized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "The contract LSSVMPair references IERC1155, but does not utilitze the interface within LSSVMPair.sol. import {IERC1155} from \"@openzeppelin/contracts/token/ERC1155/IERC1155.sol\"; The struct TokenToTokenTrade is dened in LSSVMRouter, but the contract does not utilize the interface either. struct TokenToTokenTrade { PairSwapSpecific[] tokenToNFTTrades; PairSwapSpecific[] nftToTokenTrades; } It is better to remove unused code due to potential confusion.", "labels": ["Spearbit", "Sudoswap", "Severity: Informational"]}, {"title": "Use Fractions", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "In some occasions percentages are indicated in a number format ending in e17. It is also possible to use fractions of e18. Considering e18 is the standard base format, using fractions might be easier to read. 43 LSSVMPairFactory.sol#L28 LSSVMPair.sol#L25", "labels": ["Spearbit", "Sudoswap", "Severity: Informational"]}, {"title": "Two families of token libraries used", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf", "body": "The Sudoswap contract imports token libraries from both Open- Zeppelin and Solmate. If Sudoswap sticks within one library family, then it will not be necessary to track potential issues from two separate families of libraries.", "labels": ["Spearbit", "Sudoswap", "Severity: Informational"]}, {"title": "swapInternal() shouldn't use msg.sender", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "As reported by the Connext team, the internal stable swap checks if msg.sender has sufficient funds on execute(). This msg.sender is the relayer which normally wouldn't have these funds so the swaps would fail. The local funds should come from the Connext diamond itself. BridgeFacet.sol function execute(ExecuteArgs calldata _args) external nonReentrant whenNotPaused returns (bytes32) { ... (uint256 amountOut, address asset, address local) = _handleExecuteLiquidity(...); ... } function _handleExecuteLiquidity(...) ... { ... (uint256 amount, address adopted) = AssetLogic.swapFromLocalAssetIfNeeded(...); ... } AssetLogic.sol function swapFromLocalAssetIfNeeded(...) ... { ... return _swapAsset(...); } function _swapAsset(... ) ... { ... SwapUtils.Swap storage ipool = s.swapStorages[_key]; if (ipool.exists()) { // Swap via the internal pool. return ... ipool.swapInternal(...) ... } } SwapUtils.sol function swapInternal(...) ... { IERC20 tokenFrom = self.pooledTokens[tokenIndexFrom]; require(dx <= tokenFrom.balanceOf(msg.sender), \"more than you own\"); ... } // msg.sender is the relayer", "labels": ["Spearbit", "ConnextNxtp", "Severity: High Risk"]}, {"title": "MERKLE.insert does not return the updated tree leaf count", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The NatSpec comment for insert is * @return uint256 Updated count (number of nodes in the tree). But that is not true. If the updated count is 2k (2n + 1) where k , n 2 N [ 0 then the return value would be 2n + 1. Currently, the returned value of insert is not being used, otherwise, this could be a bigger issue.", "labels": ["Spearbit", "ConnextNxtp", "Severity: High Risk"]}, {"title": "PolygonSpokeConnector or PolygonHubConnector can get compromised and DoSed if an address(0) is passed to their constructor for _mirrorConnector", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "PolygonSpokeConnector (PolygonHubConnector) inherits from SpokeConnector (HubConnector) and FxBaseChildTunnel (FxBaseRootTunnel). When PolygonSpokeConnector (PolygonHubConnector) gets de- ployed and its constructor is called, if _mirrorConnector == address(0) then setting the mirrorConnector stor- age variable is skipped: // File: Connector.sol#L118-L121 if (_mirrorConnector != address(0)) { _setMirrorConnector(_mirrorConnector); } Now since the setFxRootTunnel (setFxChildTunnel) is an unprotected endpoint that is not overridden by it and assign their own fxRootTunnel PolygonSpokeConnector (PolygonHubConnector) anyone can call (fxChildTunnel) address (note, fxRootTunnel (fxChildTunnel) is supposed to correspond to mirrorConnector on the destination domain). the require statement in setFxRootTunnel (setFxChildTunnel) only allows fxRootTunnel Note that (fxChildTunnel) to be set once (non-zero address value) so afterward even the owner cannot update this value. If at some later time the owner tries to call setMirrorConnector to assign the mirrorConnector, since _setMir- rorConnector is overridden by PolygonSpokeConnector (PolygonHubConnector) the following will try to execute: 9 // File: PolygonSpokeConnector.sol#L78-L82 function _setMirrorConnector(address _mirrorConnector) internal override { super._setMirrorConnector(_mirrorConnector); setFxRootTunnel(_mirrorConnector); } Or for PolygonHubConnector: // File: PolygonHubConnector.sol#L51-L55 function _setMirrorConnector(address _mirrorConnector) internal override { super._setMirrorConnector(_mirrorConnector); setFxChildTunnel(_mirrorConnector); } But this will revert since fxRootTunnel (fxChildTunnel) is already set. Thus if the owner of PolygonSpokeConnec- tor (PolygonHubConnector) does not provide a non-zero address value for mirrorConnector upon deployment, a malicious actor can set fxRootTunnel which will cause: 1. Rerouting of messages from Polygon to Ethereum to an address decided by the malicious actor (or vice versa for PolygonHubConnector). 2. DoSing the setMirrorConnector and setFxRootTunnel (fxChildTunnel) endpoints for the owner. PolygonSpokeConnector's", "labels": ["Spearbit", "ConnextNxtp", "Severity: High Risk"]}, {"title": "A malicious owner or user with a Role.Router role can drain a router's liquidity", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "A malicious owner or user with Role.Router Role denominated as A in this example, can drain a router's liquidity for a current router (a router that has already been added to the system and might potentially have added big liquidities to some assets). Here is how A can do it (can also be done atomically): 1. Remove the router by calling removeRouter. 2. Add the router back by calling setupRouter and set the owner and recipient parameters to accounts A has access to / control over. 3. Loop over all tokens that the router has liquidity and call removeRouterLiquidityFor to drain/redirect the funds into accounts A has control over. That means all routers would need to put their trust in the owner (of this connext instance) and any user who has a Role.Router Role with their liquidity. So the setup is not trustless currently.", "labels": ["Spearbit", "ConnextNxtp", "Severity: High Risk"]}, {"title": "Users are forced to accept any slippage on the destination chain", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The documentation mentioned that there is cancel function on the destination domain that allows users to send the funds back to the origin domain, accepting the loss incurred by slippage from the origin pool. However, this feature is not found in the current codebase. If the high slippage rate persists continuously on the destination domain, the users will be forced to accept the high slippage rate. Otherwise, their funds will be stuck in Connext.", "labels": ["Spearbit", "ConnextNxtp", "Severity: High Risk"]}, {"title": "Preservation of msg.sender in ZkSync could break certain trust assumption", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "For ZkSync chain, the msg.sender is preserved for L1 -> L2 calls. One of the rules when pursuing a cross-chain strategy is to never assume that address control between L1 and L2 is always guaranteed. For EOAs (i.e., non-contract accounts), this is generally true that any account that can be accessed on Ethereum will also be accessible on other EVM-based chains. However, this is not always true for contract-based accounts as the same account/wallet address might be owned by different persons on different chains. This might happen if there is a poorly implemented smart contract wallet factory on multiple EVM-based chains that deterministically deploys a wallet based on some user-defined inputs. For instance, if a smart contract wallet factory deployed on both EVM-based chains uses deterministic CREATE2 which allows users to define its salt when deploying the wallet, Bob might use ABC as salt in Ethereum and Alice might use ABC as salt in Zksync. Both of them will end up getting the same wallet address on two different chains. A similar issue occurred in the Optimism-Wintermute Hack, but the actual incident is more complicated. Assume that 0xABC is a smart contract wallet owned and deployed by Alice on ZkSync chain. Alice performs a xcall from Ethereum to ZkSync with delegate set to 0xABC address. Thus, on the destination chain (ZkSync), only Alice's smart contract wallet 0xABC is authorized to call functions protected by the onlyDelegate modifier. 11 Bob (attacker) saw that the 0xABC address is not owned by anyone on Ethereum. Therefore, he proceeds to take ownership of the 0xABC by interacting with the wallet factory to deploy a smart contract wallet on the same address on Ethereum. Bob can do so by checking out the inputs that Alice used to create the wallet previously. Thus, Bob can technically make a request from L1 -> L2 to impersonate Alice's wallet (0xABC) and bypass the onlyDelegate modifier on ZkSync. Additionally, Bob could make a L1 -> L2 request by calling the ZKSync's BridgeFacet.xcall directly to steal Alice's approved funds. Since the xcall relies on msg.sender, it will assume that the caller is Alice. This issue is only specific to ZkSync chain due to the preservation of msg.sender for L1 -> L2 calls. For the other chains, the msg.sender is not preserved for L1 -> L2 calls and will always point to the L2's AMB forwarding the requests.", "labels": ["Spearbit", "ConnextNxtp", "Severity: High Risk"]}, {"title": "No way to update a Stable Swap once assigned to a key", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Once a Stable Swap is assigned to a key (the hash of the canonical id and domain for token), it cannot be updated nor deleted. A Swap can be hacked or an improved version may be released which will warrant updating the Swap for a key.", "labels": ["Spearbit", "ConnextNxtp", "Severity: High Risk"]}, {"title": "Renouncing ownership or admin role could affect the normal operation of Connext", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Consider the following scenarios.  Instance 1 - Renouncing ownership All the contracts that extend from ProposedOwnable or ProposedOwnableUpgradeable inherit a method called renounceOwnership. The owner of the contract can use this method to give up their ownership, thereby leaving the contract without an owner. If that were to happen, it would not be possible to perform any owner-specific functionality on that contract anymore. The following is a summary of the affected contracts and their impact if the ownership has been renounced. 12 One of the most significant impacts is that Connext's message system cannot recover after a fraud has been resolved since there is no way to unpause and add the connector back to the system.  Instance 2 - Renouncing admin role All the contracts that extend from ProposedOwnableFacet inherit a method called revokeRole. 1. Assume that the Owner has renounced its power and the only Admin remaining used revokeRole to re- nounce its Admin role. 2. Now the contract is left with Zero Owner & Admin. 3. All swap operations collect adminFees via SwapUtils.sol contract. In absence of any Admin & Owner, these fees will get stuck in the contract with no way to retrieve them. Normally it would have been withdrawn using withdrawSwapAdminFees|SwapAdminFacet.sol. 4. This is simply one example, there are multiple other critical functionalities impacted once both Admin and Owner revoke their roles.", "labels": ["Spearbit", "ConnextNxtp", "Severity: High Risk"]}, {"title": "No way of removing Fraudulent Roots", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Fraudulent Roots cannot be removed once fraud is detected by the Watcher. This means that Fraud Roots will be propogated to each chain.", "labels": ["Spearbit", "ConnextNxtp", "Severity: High Risk"]}, {"title": "Large number of inbound roots can DOS the RootManager", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "It is possible to perform a DOS against the RootManager by exploiting the dequeueVerified function or insert function of the RootManager.sol. The following describes the possible attack path: 1. Assume that a malicious user calls the permissionless GnosisSpokeConnector.send function 1000 times (or any number of times that will cause an Out-of-Gas error later) within a single transaction/block on Gnosis causing a large number of Gnosis's outboundRoots to be forwarded to GnosisHubConnector on Ethereum. 2. Since the 1000 outboundRoots were sent at the same transaction/block earlier, all of them should arrive at the GnosisHubConnector within the same block/transaction on Ethereum. 13 3. For each of the 1000 outboundRoots received, the GnosisHubConnector.processMessage function will be triggered to process it, which will in turn call the RootManager.aggregate function to add the received out- boundRoot into the pendingInboundRoots queue. As a result, 1000 outboundRoots with the same commit- Block will be added to the pendingInboundRoots queue. 4. After the delay period, the RootManager.propagate function will be triggered. The function will call the dequeueVerified function to dequeue 1000 verified outboundRoots from the pendingInboundRoots queue by looping through the queue. This might result in an Out-of-Gas error and cause a revert. 5. If the above dequeueVerified function does not revert, the RootManager.propagate function will attempt to insert 1000 verified outboundRoots to the aggregated Merkle tree, which might also result in an Out-of-Gas error and cause a revert. If the RootManager.propagate function reverts when called, the latest aggregated Merkle root cannot be forwarded to the spokes. As a result, none of the messages can be proven and processed on the destination chains. Note: the processing on the Hub (which is on mainnet) can also become very expensive, as the mainnet usually as a far higher gas cost than the Spoke.", "labels": ["Spearbit", "ConnextNxtp", "Severity: High Risk"]}, {"title": "Missing mirrorConnector check on Optimism hub connector", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "processMessageFromRoot() calls _processMessage() to process messages for the \"fast\" path. But _processMessage() can also be called by the AMB in the slow path. The second call to _processMessage() is not necessary (and could double process the message, which luckily is prevented via the processed[] mapping). The second call (from the AMB directly to _processMessage()) also doesn't properly verify the origin of the message, which might allow the insertion of fraudulent messages. 14 function processMessageFromRoot(...) ... { ... _processMessage(abi.encode(_data)); ... } function _processMessage(bytes memory _data) internal override { // sanity check root length require(_data.length == 32, \"!length\"); // get root from data bytes32 root = bytes32(_data); if (!processed[root]) { // set root to processed processed[root] = true; // update the root on the root manager IRootManager(ROOT_MANAGER).aggregate(MIRROR_DOMAIN, root); } // otherwise root was already sent to root manager }", "labels": ["Spearbit", "ConnextNxtp", "Severity: High Risk"]}, {"title": "Add _mirrorConnector to _sendMessage of BaseMultichain", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The function _sendMessage() of BaseMultichain sends the message to the address of the _amb. This doesn't seem right as the first parameter is the target contract to interact with according to multichain cross- chain. This should probably be the _mirrorConnector. function _sendMessage(address _amb, bytes memory _data) internal { Multichain(_amb).anyCall( _amb, // Same address on every chain, using AMB as it is immutable ... ); }", "labels": ["Spearbit", "ConnextNxtp", "Severity: High Risk"]}, {"title": "Unauthorized access to change acceptanceDelay", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The acceptanceDelay along with supportedInterfaces[] can be set by any user without the need of any Authorization once the init function of DiamondInit has been called and set. This is happening since caller checks (LibDiamond.enforceIsContractOwner();) are missing for these fields. Since acceptanceDelay defines the time post which certain action could be executed, setting a very large value could DOS the system (new owner cannot be set) and setting very low value could make changes without consid- eration time (Setting/Renounce Admin, Disable whitelisting etc at ProposedOwnableFacet.sol )", "labels": ["Spearbit", "ConnextNxtp", "Severity: High Risk"]}, {"title": "Messages destined for ZkSync cannot be processed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "For ZkSync chain, L2 to L1 communication is free, but L1 to L2 communication requires a certain amount of ETH to be supplied to cover the base cost of the transaction (including the _l2Value) + layer 2 operator tip. The _sendMessage function of ZkSyncHubConnector.sol relies on the IZkSync(AMB).requestL2Transaction function to send messages from L1 to L2. However, the requestL2Transaction call will always fail because no ETH is supplied to the transaction (msg.value is zero). As a result, the ZkSync's hub connector on Ethereum cannot forward the latest aggregated Merkle root to the ZkSync's spoke connector on ZkSync chain. Thus, any message destined for ZkSync chain cannot be processed since incoming messages cannot be proven without the latest aggregated Merkle root. 16 function _sendMessage(bytes memory _data) internal override { // Should always be dispatching the aggregate root require(_data.length == 32, \"!length\"); // Get the calldata bytes memory _calldata = abi.encodeWithSelector(Connector.processMessage.selector, _data); // Dispatch message // [v2-docs.zksync.io/dev/developer-guides/Bridging/l1-l2.html#structure](https://v2-docs.zksync.io/d ,! ev/developer-guides/Bridging/l1-l2.html#structure) // calling L2 smart contract from L1 Example contract // note: msg.value must be passed in and can be retrieved from the AMB view function ,! `l2TransactionBaseCost` c // [v2-docs.zksync.io/dev/developer-guides/Bridging/l1-l2.html#using-contract-interface-in-your-proje ct](https://v2-docs.zksync.io/dev/developer-guides/Bridging/l1-l2.html#using-contract-interface-in- your-project) c c ,! ,! IZkSync(AMB).requestL2Transaction{value: msg.value}( // The address of the L2 contract to call mirrorConnector, // We pass no ETH with the call 0, // Encoding the calldata for the execute _calldata, // Ergs limit 10000, // factory dependencies new bytes[]0 ); } Additionally, the ZkSync's hub connector contract needs to be loaded with ETH so that it can forward the appro- priate amount of ETH when calling the ZkSync's requestL2Transaction. However, it is not possible to do so because no receive(), fallback or payable function has been implemented within the contract and its parent contracts for accepting ETH.", "labels": ["Spearbit", "ConnextNxtp", "Severity: High Risk"]}, {"title": "Cross-chain messaging via Multichain protocol will fail", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Multichain v6 is supported by Connext for cross-chain messaging. The _sendMessage function of BaseMultichain.sol relies on Multichain's anyCall for cross-chain messaging. Per the Anycall V6 documentation, a gas fee for transaction execution needs to be paid either on the source or destination chain when an anyCall is called. However, the anyCall is called without consideration of the gas fee within the connectors, and thus the anyCall will always fail. Since Multichain's hub and spoke connectors are unable to send messages, cross-chain messaging using Multichain within Connext will not work. 17 function _sendMessage(address _amb, bytes memory _data) internal { Multichain(_amb).anyCall( _amb, // Same address on every chain, using AMB as it is immutable _data, address(0), // fallback address on origin chain MIRROR_CHAIN_ID, 0 // fee paid on origin chain ); } Additionally, for the payment of the execution gas fee, a project can choose to implement either of the following methods:  Pay on the source chain by depositing the gas fee to the caller contracts.  Pay on the destination chain by depositing the gas fee to Multichain's anyCall contract at the destination chain. If Connext decides to pay the gas fee on the source chain, they would need to deposit some ETH to the connector contracts. However, it is not possible because no receive(), fallback or payable function has been implemented within the contracts and their parent contracts for accepting ETH.", "labels": ["Spearbit", "ConnextNxtp", "Severity: High Risk"]}, {"title": "_domainSeparatorV4() not updated after name/symbol change", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The BridgeToken allows updating the name and symbol of a token. However the _CACHED_DOMAIN_- SEPARATOR (of EIP712) isn't updated. This means that permit(), which uses _hashTypedDataV4() and _CACHED_- DOMAIN_SEPARATOR, still uses the old value. On the other hand DOMAIN_SEPARATOR() is updated. Both and especially their combination can give unexpected results. BridgeToken.sol function setDetails(string calldata _newName, string calldata _newSymbol) external override onlyOwner { // careful with naming convention change here token.name = _newName; token.symbol = _newSymbol; emit UpdateDetails(_newName, _newSymbol); } OZERC20.sol 18 function DOMAIN_SEPARATOR() external view override returns (bytes32) { // See {EIP712._buildDomainSeparator} return keccak256( abi.encode(_TYPE_HASH, keccak256(abi.encode(token.name)), _HASHED_VERSION, block.chainid, ,! address(this)) ); } function permit(...) ... { ... bytes32 _hash = _hashTypedDataV4(_structHash); ... } draft-EIP712.sol import \"./EIP712.sol\"; EIP712.sol function _hashTypedDataV4(bytes32 structHash) internal view virtual returns (bytes32) { return ECDSA.toTypedDataHash(_domainSeparatorV4(), structHash); } function _domainSeparatorV4() internal view returns (bytes32) { if (address(this) == _CACHED_THIS && block.chainid == _CACHED_CHAIN_ID) { return _CACHED_DOMAIN_SEPARATOR; } else { return _buildDomainSeparator(_TYPE_HASH, _HASHED_NAME, _HASHED_VERSION); } }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Medium Risk"]}, {"title": "diamondCut() allows re-execution of old updates", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Once diamondCut() is executed, ds.acceptanceTimes[keccak256(abi.encode(_diamondCut, _- init, _calldata))] is not reset to zero. This means the contract owner can rerun the old updates again without any delay by executing diamondCut() function. Assume the following: diamondCut() function is executed to update the facet selector with version_2 A bug is found in ver- sion_2 and it is rolled back Owner can still execute diamondCut() function which will again update the facet selector to version 2 since ds.acceptanceTimes[keccak256(abi.encode(_diamondCut, _init, _calldata))] is still valid", "labels": ["Spearbit", "ConnextNxtp", "Severity: Medium Risk"]}, {"title": "User may not be able to override slippage on destination", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "If BridgeFacet.execute() is executed before BridgeFacet.forceUpdateSlippage(), user won't be able to update slippage on the destination chain. In this case, the slippage specified on the source chain is used. Due to different conditions on these chains, a user may want to specify different slippage values. This can result in user loss, as a slippage higher than necessary will result the swap trade being sandwiched.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Medium Risk"]}, {"title": "Do not rely on token balance to determine when cap is reached", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Connext Diamond defines a cap on each token. Any transfer making the total token balance more than the cap is reverted. uint256 custodied = IERC20(_local).balanceOf(address(this)) + _amount; uint256 cap = s.caps[key]; if (cap > 0 && custodied > cap) { revert RoutersFacet__addLiquidityForRouter_capReached(); } Anyone can send tokens to Connext Diamond to artificially increase the custodied amount since it depends on the token balance. This can be an expensive attack but it can become viable if price of a token (including next assets) drops.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Medium Risk"]}, {"title": "Router recipient can be configured more than once", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The comments from the setRouterRecipient function mentioned that the router should only be able to set the recipient once. Otherwise, no problem is solved. However, based on the current implementation, it is possible for the router to set its recipient more than once. /** File: RoutersFacet.sol 394: 395: 396: 397: 398: 399: 400: 401: * @notice Sets the designated recipient for a router * @dev Router should only be able to set this once otherwise if router key compromised, * no problem is solved since attacker could just update recipient * @param router Router address to set recipient * @param recipient Recipient Address to set to router */ function setRouterRecipient(address router, address recipient) external onlyRouterOwner(router) { Let's assume that during router setup, the setupRouter function is being called and the owner is set to Alice's first EOA (0x123), and the recipient is set to Alice's second EOA (0x456). Although the comment mentioned that the setRouterRecipient should only be set once, this is not true because this function will only revert if the _- prevRecipient == recipient. As long as the new recipient is not the same as the previous recipient, the function will happily accept the new recipient. Therefore, if the router's signing key is compromised by Bob (attacker), he could call the setRouterRecipient function to change the new recipient to his personal EOA and drain the funds within the router. The setRouterRecipient function is protected by onlyRouterOwner modifier. Since Bob's has the compromised router's signing key, he will be able to pass this validation check. 21 /** File: RoutersFacet.sol 157: 158: 159: 160: 161: 162: 163: 164: 165: _; } * @notice Asserts caller is the router owner (if set) or the router itself */ modifier onlyRouterOwner(address _router) { address owner = s.routerPermissionInfo.routerOwners[_router]; if (!((owner == address(0) && msg.sender == _router) || owner == msg.sender)) revert RoutersFacet__onlyRouterOwner_notRouterOwner(); The second validation is at Line 404, which checks if the new recipient is not the same as the previous recipient. The recipient variable is set to Bob's EOA wallet, while _prevRecipient variable is set to Alice's second EOA (0x456). Therefore, the condition at Line 404 is False, and it will not revert. So Bob successfully set the recipient to his EOA at Line 407. File: RoutersFacet.sol 401: 402: 403: 404: 405: 406: 407: function setRouterRecipient(address router, address recipient) external onlyRouterOwner(router) { // Check recipient is changing address _prevRecipient = s.routerPermissionInfo.routerRecipients[router]; if (_prevRecipient == recipient) revert RoutersFacet__setRouterRecipient_notNewRecipient(); // Set new recipient s.routerPermissionInfo.routerRecipients[router] = recipient; Per the Github discussion, the motivation for such a design is the following: If a routers signing key is compromised, the attacker could drain the liquidity stored on the contract and send it to any specified address. This effectively means the key is in control of all unused liquidity on chain, which prevents router operators from adding large amounts of liquidity directly to the contract. Routers should be able to delegate the safe withdrawal address of any unused liquidity, creating a separation of concerns between router key and liquidity safety. In summary, the team is trying to create a separation of concerns between router key and liquidity safety. With the current implementation, there is no security benefit of segregating the router owner role and recipient role unless the router owner has been burned (e.g. set to address zero). Because once the router's signing key is compromised, the attacker can change the recipient anyway. The security benefits of separation of concerns will only be achieved if the recipient can truly be set only once.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Medium Risk"]}, {"title": "The set of tokens in an internal swap pool cannot be updated", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Once a swap is initialized by the owner or an admin (indexed by the key parameter) the _pooledTo- kens or the set of tokens used in this stable swap pool cannot be updated. Now the s.swapStorages[_key] pools are used in other facets for assets that have the hash of their canonical token id and canonical domain equal to _key, for example when we need to swap between a local and adopted asset or when a user provides liquidity or interact with other external endpoints of StableSwapFacet. If the submitted set of tokens to this pool _pooledTokens beside the local and adopted token corresponding to _key include some other bad/malicious tokens, users' funds can be at risk in the pool in question. If this happens, we need to pause the protocol, push an update, and initializeSwap again.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Medium Risk"]}, {"title": "An incorrect decimal supplied to initializeSwap for a token cannot be corrected", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Once a swap is initialized by the owner or an admin (indexed by the key parameter) the decimal precisions per tokens, and therefore tokenPrecisionMultipliers cannot be changed. If the supplied decimals also include a wrong value, it would cause incorrect calculation when a swap is being made and currently there is no update mechanism for tokenPrecisionMultipliers nor a mechanism for removing the swapStorages[_key].", "labels": ["Spearbit", "ConnextNxtp", "Severity: Medium Risk"]}, {"title": "Presence of delegate not enforced", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "A delegate address on the destination chain can be used to fix stuck transactions by changing the slippage limits and by re-executing transactions. However, the presence of a delegate address isn't checked in _xcall(). Note: set to medium risk because tokens could get lost 23 function forceUpdateSlippage(TransferInfo calldata _params, uint256 _slippage) external ,! onlyDelegate(_params) { ... } function execute(ExecuteArgs calldata _args) external nonReentrant whenNotPaused returns (bytes32) { (bytes32 transferId, DestinationTransferStatus status) = _executeSanityChecks(_args); ... } function _executeSanityChecks(ExecuteArgs calldata _args) private view returns (bytes32, ,! DestinationTransferStatus) { // If the sender is not approved relayer, revert if (!s.approvedRelayers[msg.sender] && msg.sender != _args.params.delegate) { revert BridgeFacet__execute_unapprovedSender(); } }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Medium Risk"]}, {"title": "Relayer could lose funds", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The xReceive function on the receiver side can contain unreliable code which Relayer is unaware of. In the future, more relayers will participate in completing the transaction. Consider the following scenario: 1. Say that Relayer A executes the xReceive function on receiver side. 2. In the xReceive function, a call to withdraw function in a foreign contract is made where Relayer A is holding some balance. 3. If this foreign contract is checking tx.origin (say deposit/withdrawal were done via third party), then Relayer A's funds will be withdrawn without his permission (since tx.origin will be the Relayer).", "labels": ["Spearbit", "ConnextNxtp", "Severity: Medium Risk"]}, {"title": "TypedMemView.sameType does not use the correct right shift value to compare two bytes29s", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The function sameType should shift 2 x 12 + 3 bytes to access the type flag (TTTTTTTTTT) when comparing it to 0. This is due to the fact that when using bytes29 type in bitwise operations and also comparisons to 0, a paramater of type bytes29 is zero padded from the right so that it fits into a uint256 under the hood. 0x TTTTTTTTTT AAAAAAAAAAAAAAAAAAAAAAAA LLLLLLLLLLLLLLLLLLLLLLLL 00 00 00 Currently, sameType only shifts the xored value 2 x 12 bytes so the comparison compares the type flag and the 3 leading bytes of memory address in the packing specified below: // First 5 bytes are a type flag. // - ff_ffff_fffe is reserved for unknown type. // - ff_ffff_ffff is reserved for invalid types/errors. // next 12 are memory address // next 12 are len // bottom 3 bytes are empty The function is not used in the codebase but can pose an important issue if incorporated into the project in the future. function sameType(bytes29 left, bytes29 right) internal pure returns (bool) { return (left ^ right) >> (2 * TWELVE_BYTES) == 0; }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Medium Risk"]}, {"title": "Incorrect formula for the scaled amplification coefficient in NatSpec comments", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "In the context above, the scaled amplification coefficient a is described by the formula An(n (cid:0) 1) where A is the actual amplification coefficient in the stable swap invariant equation for n tokens. * @param a the amplification coefficient * n * (n - 1) ... The actual adjusted/scaled amplification coefficient would need to be Ann(cid:0)1 and not An(n (cid:0) 1), otherwise, most of the calculations done when swapping between 2 tokens in a pool with more than 2 tokens would be wrong. For the special case of n = 2, those values are actually equal 22(cid:0)1 = 2 = 2 (cid:1) 1. So for swaps or pools that involve only 2 tokens, the issue in the comment is not so critical. But if the number of tokens are more than 2, then we need to make sure we calculate and feed the right parameter to AppStorage.swapStorages.{initial, future}A", "labels": ["Spearbit", "ConnextNxtp", "Severity: Medium Risk"]}, {"title": "RootManager.propagate does not operate in a fail-safe manner", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "A bridge failure on one of the supported chains will cause the entire messaging network to break down. When the RootManager.propagate function is called, it will loop through the hub connector of all six chains (Ar- bitrum, Gnosis, Multichain, Optimism, Polygon, ZKSync) and attempt to send over the latest aggregated root by making a function call to the respective chain's AMB contract. There is a tight dependency between the chain's AMB and hub connector. The problem is that if one of the function calls to the chain's AMB contract reverts (e.g. one of the bridges is paused), the entire RootManager.propagate function will revert, and the messaging network will stop working until someone figure out the problem and manually removes the problematic hub connector. As Connext grows, the number of chains supported will increase, and the risk of this issue occurring will also increase.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Medium Risk"]}, {"title": "Arborist once whitelisted cannot be removed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Arborist has the power to write over the Merkle root. In case Arborist starts misbehaving (compro- mised or security issue) then there is no way to remove this Arborist from the whitelist.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Medium Risk"]}, {"title": "WatcherManager is not set correctly", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The setWatcherManager function missed to actually update the watcherManager, instead it is just emitting an event mentioning that Watcher Manager is updated when it is not. This could become a problem once new modules are added/revised in WatcherManager contract and Watcher- Client wants to use this upgraded WatcherManager. WatcherClient will be forced to use the outdated Watcher- Manager contract code.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Medium Risk"]}, {"title": "Check __GAPs", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "All __GAPs have the same size, while the different contracts have a different number of storage variables. If the __GAP size isn't logical it is more difficult to maintain the code. Note: set to a risk rating of medium because the probably of something going wrong with future upgrades is low to medium, and the impact of mistakes would be medium to high. LPToken.sol: uint256[49] private __GAP; // should probably be 50 OwnerPausableUpgradeable.sol: uint256[49] private __GAP; // should probably be 50 uint256[49] private __GAP; // should probably be 48 StableSwap.sol: uint256[49] private __GAP; // should probably be 48 Merkle.sol: uint256[49] private __GAP; // should probably be 47 ProposedOwnable.sol: 27", "labels": ["Spearbit", "ConnextNxtp", "Severity: Medium Risk LPToken.sol#L16, OwnerPausableUpgradeable.sol#L16, StableSwap.sol#L39, Merkle.sol#L37,"]}, {"title": "Message can be delivered out of order", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Messages can be delivered out of order on the spoke. Anyone can call the permissionless prove- AndProcess to process the messages in any order they want. A malicious user can force the spoke to process messages in a way that is beneficial to them (e.g., front-run).", "labels": ["Spearbit", "ConnextNxtp", "Severity: Medium Risk"]}, {"title": "Extra checks in _verifySender() of GnosisBase", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "According to the Gnosis bridge documentation the source chain id should also be checked using messageSourceChainId(). This is because in the future the same arbitrary message bridge contract could handle requests from different chains. If a malicious actor would be able to have access to the contract at mirrorConnector on a to-be-supported chain that is not the MIRROR_DOMAIN, they can send an arbitrary root to this mainnet/L1 hub connector which the con- nector would mark it as coming from the MIRROR_DOMAIN. So the attacker can spoof/forge function calls and asset transfers by creating a payload root and using this along with their access to mirrorConnector on chain to send a cross-chain processMessage to the Gnosis hub connector and after they can use their payload root and proofs to forge/spoof transfers on the L1 chain. Although it is unlikely that any other party could add a contract with the same address as _amb on another chain, it is safer to add additional checks. function _verifySender(address _amb, address _expected) internal view returns (bool) { require(msg.sender == _amb, \"!bridge\"); return GnosisAmb(_amb).messageSender() == _expected; } 28", "labels": ["Spearbit", "ConnextNxtp", "Severity: Medium Risk"]}, {"title": "Absence of Minimum delayBlocks", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Owner can accidentally set delayBlocks as 0 (or a very small delay block) which will collapse the whole fraud protection mechanism. Since there is no check for minimum delay before setting a new delay value so even a low value will be accepted by setDelayBlocks function function setDelayBlocks(uint256 _delayBlocks) public onlyOwner { require(_delayBlocks != delayBlocks, \"!delayBlocks\"); emit DelayBlocksUpdated(_delayBlocks, delayBlocks); delayBlocks = _delayBlocks; }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Medium Risk"]}, {"title": "Add extra 0 checks in verifyAggregateRoot() and proveMessageRoot()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The functions verifyAggregateRoot() and proveMessageRoot() verify and confirm roots. A root value of 0 is a special case. If this value would be allowed, then the functions could allow invalid roots to be passed. Currently the functions verifyAggregateRoot() and proveMessageRoot() don't explicitly verify the roots are not 0. 29 function verifyAggregateRoot(bytes32 _aggregateRoot) internal { if (provenAggregateRoots[_aggregateRoot]) { return; } ... // do several verifications provenAggregateRoots[_aggregateRoot] = true; ... } function proveMessageRoot(...) ... { if (provenMessageRoots[_messageRoot]) { return; } ... // do several verifications provenMessageRoots[_messageRoot] = true; }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Medium Risk"]}, {"title": "_removeAssetId() should also clear custodied", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "In one of the fixes in PR 2530, _removeAssetId() doesn't clear custodied as it is assumed to be 0. function _removeAssetId(...) ... { // NOTE: custodied will always be 0 at this point } However custodied isn't always 0. Suppose cap & custodied have a value (!=0), then _setLiquidityCap() is called to set the cap to 0. The function doesn't reset the custodied value so it will stay at !=0.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Remove liquidity while paused", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The function removeLiquidity() in StableSwapFacet.sol has a whenNotPaused modifier, while the comment shows Liquidity can always be removed, even when the pool is paused.. On the other hand function removeLiquidity() in StableSwap.sol doesn't have this modifier. StableSwapFacet.sol#L394-L446 // Liquidity can always be removed, even when the pool is paused. function removeLiquidity(...) external ... nonReentrant whenNotPaused ... { ... } function removeLiquidityOneToken(...) external ... nonReentrant whenNotPaused function removeLiquidityImbalance(...) external ... nonReentrant whenNotPaused ... { ... } ... { ... } StableSwap.sol#L394-L446 // Liquidity can always be removed, even when the pool is paused. function removeLiquidity(...) external ... nonReentrant ... { ... } function removeLiquidityOneToken(...) external ... nonReentrant whenNotPaused function removeLiquidityImbalance(...) external ... nonReentrant whenNotPaused ... { ... } ... { ... }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Relayers can frontrun each other's calls to BridgeFacet.execute", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Relayers can front run each other's calls to BridgeFacet.execute. Currently, there is no on-chain mechanism to track how many fees should be allocated to each relayer. All the transfer bump fees are funneled into one address s.relayerFeeVault.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "OptimismHubConnector.processMessageFromRoot emits MessageProcessed for already processed messages", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Calls to processMessageFromRoot with an already processed _data still emit MessageProcessed. This might cause issues for off-chain agents like relayers monitoring this event.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Add max cap for domains", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Currently there isn't any cap on the maximum amount of domains which system can support. If the size of the domains and connectors grow, at some point due to out-of-gas errors in updateHashes function, both addDomain and removeDomain could DOS.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "In certain scenarios calls to xcall... or addRouterLiquidity... can be DoSed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The owner or an admin can frontrun (or it can be by an accident) a call that:  A router has made on a canonical domain of a canonical token to supply that token as liquidity OR  A user has made to xcall... supplying a canonical token on its canonical domain. The frontrunning call would set the cap to a low number (calling updateLiquidityCap). This would cause the calls mentioned in the bullet list to fail due to the checks against IERC20(_local).balanceOf(address(this)).", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Missing a check against address(0) in ConnextPriceOracle's constructor", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "When ConnextPriceOracle is deployed an address _wrapped is passed to its constructor. The current codebase does not check whether the passed _wrapped can be an address(0) or not.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "_executeCalldata() can revert if insufficient gas is supplied", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The function _executeCalldata() contains the statement gasleft() - 10_000. This statement can revert if the available gas is less than 10_000. Perhaps this is the expected behaviour. Note: From the Tangerine Whistle fork only a maximum 63/64 of the available gas is sent to contract being called. Therefore, 1/64th is left for the calling contract. function _executeCalldata(...) ... { ... (success, returnData) = ExcessivelySafeCall.excessivelySafeCall(_params.to, gasleft() - 10_000, ... ); ... ,! }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Be aware of precompiles", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The external calls by _executeCalldata() could call a precompile. Different chains have creative precompile implementations, so this could in theory pose problems. For example precompile 4 copies memory: what-s-the-identity-0x4-precompile Note: precompiles link to dedicated pieces of code written in Rust or Go that can be called from the EVM. Here are a few links for documentation on different chains: moonbeam precompiles, astar precompiles function _executeCalldata(...) ... { ... (success, returnData) = ExcessivelySafeCall.excessivelySafeCall( _params.to, ...); } else { returnData = IXReceiver(_params.to).xReceive(...); } ... }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Upgrade to solidity 0.8.17", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Solidity 0.8.17 released a bugfix where the optimizer could incorrectly remove storage writes if the code fit a certain pattern (see this security alert). This bug was introduced in 0.8.13. Since Connext is using the legacy code generation pipeline, i.e., compiling without the via-IR flag, the current code is not at risk. This is because assembly blocks dont write to storage. However, if this changes and Connext compiles through via-IR code generation, the code is more likely to be affected. One reason to use this code generation pipeline could be to enable gas optimizations not available in legacy code generation.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Add domain check in setupAssetWithDeployedRepresentation()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The function setupAssetWithDeployedRepresentation() links a new _representation asset. However this should not be done on the canonical domain. So good to check this to prevent potential mistakes. function setupAssetWithDeployedRepresentation(...) ... { bytes32 key = _enrollAdoptedAndLocalAssets(_adoptedAssetId, _representation, _stableSwapPool, _canonical); ... ,! }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "If an adopted token and its canonical live on the same domain the cap for the custodied amount is applied for each of those tokens", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "If _local is an adopted asset that lives on its canonical's original chain, then we are comparing the to-be-updated balance of this contract (custodied) with s.caps[key]. That means we are also comparing the balance of an adopted asset with the property above with the cap. For example, if A is the canonical token and B the adopted, then cap = s.caps[key] is used to cap the custodied amount in this contract for both of those tokens. So if the cap is 1000, the contract can have a balance of 1000 A and 1000 B, which is twice the amount meant to be capped. This is true basically for any approved asset with the above properties. When the owner or the admin calls setu- pAsset: // File: https://github.com/connext/nxtp/blob/32a0370edc917cc45c231565591740ff274b5c05/packages/deploym ents/contracts/contracts/core/connext/facets/TokenFacet.sol#L164-L172 ,! function setupAsset( c TokenId calldata _canonical, uint8 _canonicalDecimals, string memory _representationName, string memory _representationSymbol, address _adoptedAssetId, address _stableSwapPool, uint256 _cap ) external onlyOwnerOrAdmin returns (address _local) { such that _canonical.domain == s.domain and _adoptedAssetId != 0, then this asset has the property in ques- tion.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "There are no checks/constraints against the _representation provided to setupAssetWithDe- ployedRepresentation", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "setupAssetWithDeployedRepresentation is similar to setupAsset in terms of functionality, except it does not deploy a representation token if necessary. It actually uses the _representation address given as the representation token. The _representation parameter given does not have any checks in terms of functionality compared to when setupAsset which deploys a new BridgeToken instance: // File: packages\\deployments\\contracts\\contracts\\core\\connext\\facets\\TokenFacet.sol#L399 _token = address(new BridgeToken(_decimals, _name, _symbol)); Basically, representation needs to implement IBridgeToken (mint, burn, setDetails, ... ) and some sort of IERC20. Otherwise, if a function from IBridgeToken is not implemented or if it does not have IERC20 functionality, it can cause failure/reverts in some functions in this codebase. Another thing that is important is that the decimals for _representation should be equal to the decimals precision of the canonical token. And that _representation should not be able to update/change its decimals. Also, this opens an opportunity for a bad owner or admin to provide a malicious _representation to this function. This does not have to be a malicious act, it can also happen by mistake from for example an admin. Additionally the Connext Diamond must have the \"right\" to mint() and burn() the tokens.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "In dequeueVerified when no verified items are found in the queue last == first - 1", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The comment in dequeueVerified mentions that when no verified items are found in the queue, then last == first. But this is not true since the loop condition is last >= first and the loop only terminates (not considering the break) when last == first - 1. It is important to correct this incorrect statement in the comment, since a dev/user can by mistake take this state- ment as true and modify/use the code with this incorrect assumption in mind.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Dirty bytes in _loc and _len can override other values when packing a typed memory view in unsafeBuildUnchecked", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "For a TypeedMemView, the location and the length are supposed to occupy 12 bytes (uint96), but the type used for these values for the input parameters for unsafeBuildUnchecked is uint256. This would allow those values to carry dirty bytes and when the following calculations are performed: newView := shl(96, or(newView, _type)) // insert type newView := shl(96, or(newView, _loc)) // insert loc newView := shl(24, or(newView, _len)) // empty bottom 3 bytes _loc can potentially manipulate the type section of the view and _len can potentially manipulate both the _loc and the _type section.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "To use sha2, hash160 and hash256 of TypedMemView the hard-coded precompile addresses would need to be checked to make sure they return the corresponding hash values.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "sha2, hash160 and hash256 assume that the precompile contracts at address(2) and address(3) calculate and return the sha256 and ripemd160 hashes of the provided memory chunks. These assumptions depend on the chain that the project is going to be deployed on.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "sha2, hash160 and hash256 of TypedMemView.sha2 do not clear the memory after calculating the hash", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "When a call to the precompile contract at address(2) (or at address(3)) is made, the returned value is placed at the slot pointed by the free memory pointer and then placed on the stack. The free memory pointer is not incremented to account for this used memory position nor the code tries to clean this memory slot of 32 bytes. Therefore after a call to sha2, hash160 or hash256, we would end up with dirty bytes.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Fee on transfer token support", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "It seems that only the addLiquidity function is currently supporting the fee on transfer token. All operations like swapping are prohibiting the fee on transfer token. Note: The SwapUtilsExternal.sol contract allow fee on transfer token and as per product team, this is expected from this token", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Fee on transfer tokens can stuck the transaction", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Consider the following scenario. 1. Assume User has made a xcall with amount A of token X with calldata C1. Since their was no fee while transferring funds, transfer was a success. 2. Now, before this amount can be transferred on the destination domain,token X introduced a fee on transfer. 3. Relayer now executes this transaction on destination domain via _handleExecuteTransaction function on BridgeFacet.sol#L756. 4. This transfers the amount A of token X to destination domain but since now the fee on this token has been introduced, destination domain receives amount A-delta. 5. This calldata is called on destination domain but the amount passed is A instead of A-delta so if the IXRe- ceiver has amount check then it will fail because it will now expect A amount when it really got A-delta amount.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Initial Liquidity Provider can trick the system", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Since there is no cap on the amount which initial depositor can deposit, an attacker can trick the system in bypassing admin fees for other users by selling liquidity at half admin fees. Consider the following scenario. 1. User A provides the first liquidity of a huge amount. 2. Since there aren't any fees from initial liquidity, admin fees are not collected from User A. 3. Now User A can sell his liquidity to other users with half admin fees. 4. Other users can mint larger liquidity due to lesser fees and User A also get benefit of adminFees/2.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Ensure non-zero local asset in _xcall()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Local asset fetched in _xcall() is not verified to be a non-zero address. In case, if token mappings are not updated correctly and to future-proof from later changes, it's better to revert if a zero address local asset is fetched. local = _getLocalAsset(key, canonical.id, canonical.domain);", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Use ExcessivelySafeCall to call xReceive()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "xReceive(). This is done to avoid copying large amount of return data in memory. This same attack vector exists for non-reconciled transfers, however in this case a usual function call is made for xReceive(). For However, in case non-reconciled calls fail due to this error, they can always be retried after reconciliation.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "A router's liquidity might get trapped if the router is removed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "If the owner or a user with Role.Router Role removes a router that does not implement calling re- moveRouterLiquidity or removeRouterLiquidityFor, then any liquidity remaining in the contract for the removed router cannot be transferred back to the router.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "In-flight transfers by the relayer can be reverted when setMaxRoutersPerTransfer is called before- hand by a lower number", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "For in-flight transfers where an approved sequencer has picked and signed an x number of routers for a transfer, from the time a relayer or another 3rd party grabs this ExecuteArgs _args to the time this party submits it to the destination domain by calling execute on a connext instance, the owner or an admin can call setMaxRoutersPerTransfer with a number lower than x on purpose or not. And this would cause the call to execute to revert with BridgeFacet__execute_maxRoutersExceeded.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "All the privileged users that can call withdrawSwapAdminFees would need to trust each other", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The owner needs to trust all the admins and also all admins need to trust each other. Since any admin can call withdrawSwapAdminFees endpoint to withdraw all the pool's admin fees into their account.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "The supplied _a to initializeSwap cannot be directly updated but only ramped", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Once a swap is initialized by the owner or an admin (indexed by the key parameter) the supplied _a (the scaled amplification coefficient, Ann(cid:0)1 ) to initializeSwap cannot be directly updated but only ramped. The owner or the admin can still call rampA to update _a, but it will take some time for it to reach the desired value. This is mostly important if by mistake an incorrect value for _a is provided to initializeSwap.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Inconsistent behavior when xcall with a non-existent _params.to", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "A xcall with a non-existent _params.to behaves differently depending on the path taken. 1. Fast Liquidity Path - Use IXReceiver(_params.to).xReceive. The _executeCalldata function will revert if _params.to is non-existent. Which technically means that the execution has failed. 2. Slow Path - Use ExcessivelySafeCall.excessivelySafeCall. This function uses the low-level call, which will not revert and will return true if the _params.to is non-existent. The _executeCalldata function will return with success set to True, which means the execution has succeeded.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "The lpToken cloned in initializeSwap cannot be updated", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Once a swap is initialized by the owner or an admin (indexed by the key parameter) an LPToken lpToken is created by cloning the provided lpTokenTargetAddress to the initializeSwap endpoint. There is no restriction on lpTokenTargetAddress except that it would need to be of LPToken like, but it can be malicious under the hood or have some security vulnerabilities, so it can not be trusted.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Lack of zero check", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Consider the following scenarions.  Instance 1 - BridgeFacet.addSequencer The addSequencer function of BridgeFacet.sol does not check that the sequencer address is not zero before adding them. function addSequencer(address _sequencer) external onlyOwnerOrAdmin { if (s.approvedSequencers[_sequencer]) revert BridgeFacet__addSequencer_alreadyApproved(); s.approvedSequencers[_sequencer] = true; emit SequencerAdded(_sequencer, msg.sender); } If there is a mistake during initialization or upgrade, and set s.approvedSequencers[0] = true, anyone might be able to craft a payload to execute on the bridge because the attacker can bypass the following validation within the execute function. if (!s.approvedSequencers[_args.sequencer]) { revert BridgeFacet__execute_notSupportedSequencer(); }  Instance 2 - BridgeFacet.enrollRemoteRouter 43 The enrollRemoteRouter function of BridgeFacet.sol does not check that the domain or router address is not zero before adding them. function enrollRemoteRouter(uint32 _domain, bytes32 _router) external onlyOwnerOrAdmin { // Make sure we aren't setting the current domain as the connextion. if (_domain == s.domain) { revert BridgeFacet__addRemote_invalidDomain(); } s.remotes[_domain] = _router; emit RemoteAdded(_domain, TypeCasts.bytes32ToAddress(_router), msg.sender); }  Instance 3 - TokenFacet._enrollAdoptedAndLocalAssets The _enrollAdoptedAndLocalAssets function of TokenFacet.sol does not check that the _canonical.domain and _canonical.id are not zero before adding them. function _enrollAdoptedAndLocalAssets( address _adopted, address _local, address _stableSwapPool, TokenId calldata _canonical ) internal returns (bytes32 _key) { // Get the key _key = AssetLogic.calculateCanonicalHash(_canonical.id, _canonical.domain); // Get true adopted address adopted = _adopted == address(0) ? _local : _adopted; // Sanity check: needs approval if (s.approvedAssets[_key]) revert TokenFacet__addAssetId_alreadyAdded(); // Update approved assets mapping s.approvedAssets[_key] = true; // Update the adopted mapping using convention of local == adopted iff (_adooted == address(0)) s.adoptedToCanonical[adopted].domain = _canonical.domain; s.adoptedToCanonical[adopted].id = _canonical.id; These two values are used for generating the key to determine if a particular asset has been approved. Additionally, zero value is treated as a null check within the AssetLogic.getCanonicalTokenId function: // Check to see if candidate is an adopted asset. _canonical = s.adoptedToCanonical[_candidate]; if (_canonical.domain != 0) { // Candidate is an adopted asset, return canonical info. return _canonical; }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "When initializing Connext bridge make sure _xAppConnectionManager domain matches the one pro- vided to the initialization function for the bridgee", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The only contract that implements IConnectorManager fully is SpokeConnector (through inheriting ConnectorManager and overriding localDomain): 45 // File: SpokeConnector.sol function localDomain() external view override returns (uint32) { return DOMAIN; } So a SpokeConnector or a IConnectorManager has its own concept of the local domain (the domain that it lives / is deployed on). And this domain is used when we are hashing messages and inserting them into the SpokeCon- nector's merkle tree: // File: SpokeConnector.sol bytes memory _message = Message.formatMessage( DOMAIN, bytes32(uint256(uint160(msg.sender))), _nonce, _destinationDomain, _recipientAddress, _messageBody ); // Insert the hashed message into the Merkle tree. bytes32 _messageHash = keccak256(_message); // Returns the root calculated after insertion of message, needed for events for // watchers (bytes32 _root, uint256 _count) = MERKLE.insert(_messageHash); We need to make sure that this local domain matches the _domain provided to this init function. Otherwise, the message hashes that are inserted into SpokeConnector's merkle tree would have 2 different origin domains linked to them. One from SpokeConnector in this message hash and one from connext's s.domain = _domain which is used in calculating the transfer id hash. The same issue applies to setXAppConnectionManager.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "The stable swap pools used in Connext are incompatible with tokens with varying decimals", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The stable swap functionality used in Connext calculates and stores for each token in a pool, the token's precision relative to the pool's precision. The token precision calculation uses the token's decimals. And since this precision is only set once, for a token that can have its decimals changed at a later time in the future, the precision used might not be always accurate in the future. And so in the event of a token decimal change, the swap calculations involving this token would be inaccurate. For exmpale in _xp(...): function _xp(uint256[] memory balances, uint256[] memory precisionMultipliers) internal pure returns (uint256[] memory) uint256 numTokens = balances.length; require(numTokens == precisionMultipliers.length, \"mismatch multipliers\"); uint256[] memory xp = new uint256[]numTokens; for (uint256 i; i < numTokens; ) { xp[i] = balances[i] * precisionMultipliers[i]; unchecked { ++i; } } return xp; { } We are multiplying in xp[i] = balances[i] * precisionMultipliers[i]; and cannot use division for tokens that have higher precision than the pool's default precision.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "When Connext reaches the cap allowed custodied, race conditions can be created", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "When IERC20(local).balanceOf(address(this)) is close to s.caps[key] (this can be relative/subjective) for a canonical token on its canonical domain, a race condition gets created where users might try to frontrun each others calls to xcall or xcallIntoLocal to be included in a cross chain transfer. This race condition is actually between all users and all liquidity routers. Since there is a same type of check when routers try to add liquidity. uint256 custodied = IERC20(_local).balanceOf(address(this)) + _amount; uint256 cap = s.caps[key]; if (cap > 0 && custodied > cap) { revert RoutersFacet__addLiquidityForRouter_capReached(); }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Prevent sequencers from signing multiple routes for the same cross-chain transfer", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Liquidity routers only sign the hash of (transferId, pathLength) combo. This means that each router does not have a say in: 1. The ordering of routers provided/signed by the sequencer. 2. What other routers are used in the sequence. If a sequencer signs 2 different routes (set of routers) for a cross-chain transfer, a relayer can decide which set of routers to use and provide to BridgeFacet.execute to make sure the liquidity from a specific set of routers' balances is used (also the same possibility if 2 different sequencers sign 2 different routes for a cross-chain transfer).", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Well-funded malicious actors can DOS the bridge", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "A malicious actor (e.g. a well-funded cross-chain messaging competitor) can DOS the bridge cheaply. Assume Ethereum <-> Polygon bridge and the liquidity cap is set to 1m for USDC. 1. Using a slow transfer to avoid router liquidity fees, Bob (attacker) transferred 1m USDC from Ethereum to Polygon. 1m USDC will be locked on Connext's Bridge. Since the liquidity cap for USDC is filled, no one will be able to transfer any USDC from Ethereum to Polygon unless someone transfers POS-USDC from Polygon to Ethereum to reduce the amount of USDC held by the bridge. 2. On the destination chain, nextUSDC (local bridge asset) will be swapped to POS-USDC (adopted asset). The swap will incur low slippage because it is a stablewap. Assume that Bob will receive 999,900 POS-USDC back on Polygon. A few hundred or thousand loss is probably nothing for a determined competitor that wants to harm the reputation of Connext. 3. Bob bridged back the 999,900 POS-USDC using Polygon's Native POS bridge. Bob will receive 999,900 USDC in his wallet in Ethereum after 30 minutes. It is a 1-1 exchange using a native bridge, so no loss is incurred here. 4. Whenever the liquidity cap for USDC gets reduced on Connext's Bridge, Bob will repeat the same trick to keep the bridge in an locked state. 5. If Bob is well-funded enough, he could perform this against all Connext's bridges linked to other chains for popular assets (e.g. USDC), and normal users will have issues transferring popular assets when using xcall.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "calculateTokenAmount is not checking whether amounts provided has the same length as balances", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "There is no check to make sure amounts.length == balances.length in calculateTokenAmount: function calculateTokenAmount( Swap storage self, uint256[] calldata amounts, bool deposit ) internal view returns (uint256) { uint256 a = _getAPrecise(self); uint256[] memory balances = self.balances; ... There are 2 bad cases: 49 1. amounts.length > balances.length, in this case, we have provided extra data which will be ignored silently and might cause miscalculation on or off chain. 2. amounts.length < balances.length, the loop in calculateTokenAmount would/should revert becasue of an index-out-of-bound error. In this case, we might spend more gas than necessary compared to if we had performed the check and reverted early.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Rearrange an expression in _calculateSwapInv to avoid underflows", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "In the following expression used in SwapUtils_calculateSwapInv, if xp[tokenIndexFrom] = x + 1 the expression would underflow and revert. We can arrange the expression to avoid reverting in this edge case. dx = x - xp[tokenIndexFrom] + 1;", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "The pre-image of DIAMOND_STORAGE_POSITION's storage slot is known", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The preimage of the hashed storage slot DIAMOND_STORAGE_POSITION is known.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "The @param NatSpec comment for _key in AssetLogic._swapAsset is incorrect", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The @param NatSpec for _key indicates that this parameter is a canonical token id where instead it should mention that it is a hash of a canonical id and its corresponding domain. We need to make sure the correct value has been passed down to _swapAsset.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Malicious routers can temporarily DOS the bridge by depositing a large amount of liquidity", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Both router and bridge share the same liquidity cap on the Connext bridge. Assume that the liquidity cap for USDC is 1 million on Ethereum. Shortly after the Connext Amarok launch, a router adds 1 million USDC liquidity. No one would be able to perform a xcall transfer with USDC from Ethereum to other chains as it will always revert because the liquidity cap has exceeded. The DOS is temporary because the router's liquidity on Ethereum will be reduced if there is USDC liquidity flowing in the opposite direction (e.g., From Polygon to Ethereum)", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Prevent deploying a representation token twice", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The function setupAsset() is protected by _enrollAdoptedAndLocalAssets() which checks s.approvedAssets[_key] to prevent accidentally setting up an asset twice. However the function _removeAssetId() is rather thorough and removes the s.approvedAssets[_key] flag. After a call to _removeAssetId(), an asset can be recreated via setupAsset(). This will deploy a second representation token which will be confusing to users of Connext. Note: The function setupAssetWithDeployedRepresentation() could be used to connect a previous presentation token again to the canonical token. Note: All these functions are authorized so it would only be a problem if mistakes are made. 51 function setupAsset(...) ... onlyOwnerOrAdmin ... { if (_canonical.domain != s.domain) { _local = _deployRepresentation(...); // deploys a new token } else { ... } bytes32 key = _enrollAdoptedAndLocalAssets(_adoptedAssetId, _local, _stableSwapPool, _canonical); ... } function _enrollAdoptedAndLocalAssets(...) ... { ... if (s.approvedAssets[_key]) revert TokenFacet__addAssetId_alreadyAdded(); s.approvedAssets[_key] = true; ... } function _removeAssetId(...) ... { ... delete s.approvedAssets[_key]; ... }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Extra safety checks in _removeAssetId()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The function _removeAssetId() deletes assets but it doesn't check if the passed parameters are a consistent set. This allows for mistakes where the wrong values are accidentally deleted. function _removeAssetId(bytes32 _key, address _adoptedAssetId, address _representation) internal { ... delete s.adoptedToCanonical[_adoptedAssetId]; delete s.representationToCanonical[_representation]; ... }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Data length not validated", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The following functions do not validate that the input _data is 32 bytes.  GnosisSpokeConnector._sendMessag  GnosisSpokeConnector._processMessage  BaseMultichain.sendMessage  OptimismSpokeConnector._sendMessage The input _data contains the outbound Merkle root or aggregated Merkle root, which is always 32 bytes. If the root is not 32 bytes, it is invalid and should be rejected.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Verify timestamp reliability on L2", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Timestamp information on rollups can be less reliable than on mainnet. For instance, Arbitrum docs say: As a general rule, any timing assumptions a contract makes about block numbers and timestamps should be considered generally reliable in the longer term (i.e., on the order of at least several hours) but unreliable in the shorter term (minutes). (It so happens these are generally the same assumptions one should operate under when using block numbers directly on Ethereum!) Uniswap docs mention this for Optimism: The block.timestamp of these blocks, however, reflect the block.timestamp of the last L1 block ingested by the Sequencer.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "MirrorConnector cannot be changed once set", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "For chains other than Polygon, it is allowed to change mirror connector any number of times. For Polygon chain, the _setMirrorConnector is overridden. 1. Let's take PolygonHubConnector contract example: function _setMirrorConnector(address _mirrorConnector) internal override { super._setMirrorConnector(_mirrorConnector); setFxChildTunnel(_mirrorConnector); } 2. Since setFxChildTunnel(PolygonHubConnector) can only be called once due to below require check, this also restricts the number of time mirror connector can be altered. function setFxChildTunnel(address _fxChildTunnel) public virtual { require(fxChildTunnel == address(0x0), \"FxBaseRootTunnel: CHILD_TUNNEL_ALREADY_SET\"); ... } 54", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Possible infinite loop in dequeueVerified()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The loop in function dequeueVerified() doesn't end if queue.first == queue.last == 0. In this situation, at unchecked { --last; } the following happens: last wraps to type(uint128).max. Now last is very large and is surely >=first and thus the loop keeps running. This problem can occur when queue isn't initialized. function dequeueVerified(Queue storage queue, uint256 delay) internal returns (bytes32[] memory) { uint128 first = queue.first; uint128 last = queue.last; require(last >= first, \"queue empty\"); for (last; last >= first; ) { ... unchecked { --last; } // underflows when last == 0 (e.g. queue isn't initialized) } }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Do not ignore staticcall's return value", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "TypedMemView calls several precompiles through staticcall opcode and never checks its return value assuming it is a success. For instance: TypedMemView.sol#L668-L669, TypedMemView.sol#L685-L686, // use the identity precompile to copy // guaranteed not to fail, so pop the success pop(staticcall(gas(), 4, _oldLoc, _len, _newLoc, _len)) However, there are rare cases when call to precompiles can fail. For example, when the call runs out of gas (since 63/64 of the gas is passed, the remaining execution can still have gas). Generally, not checking for success of calls is dangerous and can have unintended consequences.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk TypedMemView.sol#L652,"]}, {"title": "Renounce wait time can be extended", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The _proposedOwnershipTimestamp updates everytime on calling proposeNewOwner with newlyPro- posed as zero address. This elongates the time when owner can be renounced.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "Extra parameter in function checker() at encodeWithSelector()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The function checker() sets up the parameters to call the function sendMessage(). However, it adds an extra parameter outboundRoot, which isn't necessary. function sendMessage() external { ... } function checker() external view override returns (bool canExec, bytes memory execPayload) { ... execPayload = abi.encodeWithSelector(this.sendMessage.selector, outboundRoot); // extra parameter ... }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Low Risk"]}, {"title": "MerkleLib.insert() can be optimized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "storage. Each call to MerkleLib.insert() reads the entire tree from storage, and writes 2 (tree.count and tree.branch[i]) back to storage. These storage operations can be done only once at the beginning, by loading them in memory. The updated count and branches can be written back to the storage at the end saving expensive SSTORE and SLOAD operations.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "EIP712 domain separator can be cached", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The domain separator can be cached for gas-optimization.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "stateCommitmentChain can be made immutable", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Once assigned in constructor, stateCommitmentChain cannot be changed.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Nonce can be updated in single step", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Nonce can be incremented in single step instead of using a second step which will save some gas", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "ZkSyncSpokeConnector._sendMessage encodes unnecessary data", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Augmenting the _data with the processMessage function selector is unnecessary. Since on the mirror domain, we just need to provide the right parameters to ZkSyncHubConnector.processMessageFromRoot (which by the way anyone can call) to prove the L2 message inclusion of the merkle root _data. Thus the current implementation is wasting gas.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "getD can be optimized by removing an extra multiplication by d per iteration", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The calculation for the new d can be simplified by canceling a d from the numerator and denominator. Basically, we have : f (D) = 1 nn+1a Q xi Dn+1 + (1 (cid:0) 1 na )D (cid:0) X xi 59 and having/assuming n, a, xi are fixed, we are using Newton's method to find a solution for f = 0. The original implementation is using: D0 = D (cid:0) f (D) f 0(D) = which can be simplified to: (na P xi + Dn+1 nn(cid:0)1 Q xi )D (na (cid:0) 1)D + (n + 1) Dn+1 nn Q xi na P xi + D0 = Dn nn(cid:0)1 (na (cid:0) 1) + (n + 1) D Q xi Dn Q xi nn", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "_recordOutputAsSpent in ArbitrumHubConnector can be optimized by changing the require condition", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "In _recordOutputAsSpent, _index is compared with a literal value that is a power of 2. The expo- nentiation in this statement can be completely removed to save gas.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Message.leaf's memory manipulation is redundant", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The chunk of memory related to _message is dissected into pieces and then copied into another section of memory and hashed.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "coerceBytes32 can be more optimized", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "It would be cheaper to not use TypedMemView in coerceBytes32(). We would only need to check the length and mask. Note: coerceBytes32 doesn't seem to be used. If that is the case it could also be removed.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Consider removing domains from propagate() arguments", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "propagate(uint32[] calldata _domains, address[] calldata _connectors) only uses _do- mains to verify its hash against domainsHash, and to emit an event. Hence, its only use seems to be to notify off-chain agents of the supported domains.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Loop counter can be made uint256 to save gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "There are several loops that use an uint8 as the type for the loop variable. Changing that to uint256 can save some gas.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Set owner directly to zero address in renounceOwnership", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "1. In renounceOwnership function, _proposed will always be address zero so instead of setting the variable _proposed as owner, we can directly set address(0) as the new owner. 2. Similarly for renounceOwnership function also set address(0) as the new owner.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Retrieve decimals() once", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "There are several locations where the number of decimals() of tokens are retrieved. As all tokens are whitelisted, it would also be possible to retrieve the decimals() once and store these to save gas. BridgeFacet.sol import {ERC20} from \"@openzeppelin/contracts/token/ERC20/ERC20.sol\"; ... function _xcall(...) ... { ... ... AssetLogic.normalizeDecimals(ERC20(_asset).decimals(), uint8(18), _amount); ... } AssetLogic.sol import {ERC20} from \"@openzeppelin/contracts/token/ERC20/ERC20.sol\"; ... function swapToLocalAssetIfNeeded(...) ... { ... ... calculateSlippageBoundary(ERC20(_asset).decimals(), ERC20(_local).decimals(), _amount, _slippage) ... ... ,! } function swapFromLocalAssetIfNeeded(...) ... { ... ... calculateSlippageBoundary(uint8(18), ERC20(adopted).decimals(), _normalizedIn, _slippage) ... ... }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "The root... function in Merkle.sol can be optimized by using YUL, unrolling loops and using the scratch space", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "We can use assembly, unroll loops, and use the scratch space to save gas. Also, rootWithCtx can be removed (would save us from jumping) since it has only been used here.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "The insert function in Merkle.sol can be optimized by using YUL, unrolling loops and using the scratch space", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "If we use assembly. the scratch space for hashing and unrolling the loop, we can save some gas.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "branchRoot function in Merkle.sol can be more optimized by using YUL, unrolling the loop and using the scratch space", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "We can use assembly, unroll the loop in branchRoot, and use the scratch space to save gas.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Replace divisions by powers of 2 by right shifts and multiplications by left shifts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "When a variable X is divided (multiplied) by a power of 2 (C = 2  c) which is a constant value, the division (multiplication) operation can be replaced by a right (left) shift to save gas.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "TypedMemView.castTo can be optimized by using bitmasks instead of multiple shifts", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "TypedMemView.castTo uses bit shifts to clear the type flag bits of a memView, instead masking can be used. Also an extra OR is used to calculate the final view.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Make domain immutable in Facets", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Domain in Connector.sol is an immutable variable, however it is defined as a storage variable in LibConnextStorage.sol. Also once initialized in DiamondInit.sol, it cannot be updated again. To save gas, domain can be made an immutable variable to avoid reading from storage.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Cache router balance in repayAavePortal()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "repayAavePortal() reads s.routerBalances[msg.sender][local] twice: if (s.routerBalances[msg.sender][local] < _maxIn) revert PortalFacet__repayAavePortal_insufficientFunds(); ,! ... s.routerBalances[msg.sender][local] -= amountDebited; This can be cached to only read it once.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Unrequired if condition", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The below if condition is not required as price will always be 0. This is because if contract finds direct price for asset it returns early, otherwise if no direct price then tokenPrice is set to 0. This means for the code ahead tokenPrice will currently be 0. function getTokenPrice(address _tokenAddress) public view override returns (uint256, uint256) { ... uint256 tokenPrice = assetPrices[tokenAddress].price; if (tokenPrice != 0 && ((block.timestamp - assetPrices[tokenAddress].updatedAt) <= VALID_PERIOD)) { return (tokenPrice, uint256(PriceSource.DIRECT)); } else { tokenPrice = 0; } if (tokenPrice == 0) { ... }", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Delete slippage for gas refund", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "Once s.slippage[_transferId] is read, it's never read again. It can be deleted to get some gas refund.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Emit event at the beginning in _setOwner()", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "_setOwner() maintains an extra variable oldOwner just to emit an event later: function _setOwner(address newOwner) internal { address oldOwner = _owner; _owner = newOwner; _proposedOwnershipTimestamp = 0; _proposed = address(0); emit OwnershipTransferred(oldOwner, newOwner); } If this emit is done at the beginning, oldOwner can be removed.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Simplify the assignment logic of _params.normalizedIn in _xcall", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "When amount > 0 we should have asset != address(0) since otherwise the call would revert: if (_asset == address(0) && _amount != 0) { revert BridgeFacet__xcall_nativeAssetNotSupported(); } and when amount == 0 _params.normalizedIn is 0 which is the value passed to _xcall from xcall or xcall- IntoLocal. So we can move the calculation for _params.normalizedIn into the if (_amount > 0) { block. 90 if (_amount > 0) { // Transfer funds of input asset to the contract from the user. AssetLogic.handleIncomingAsset(_asset, _amount); // Swap to the local asset from adopted if applicable. // TODO: drop the \"IfNeeded\", instead just check whether the asset is already local / needs swap here. _params.bridgedAmt = AssetLogic.swapToLocalAssetIfNeeded(key, _asset, local, _amount, ,! _params.slippage); // Get the normalized amount in (amount sent in by user in 18 decimals). _params.normalizedIn = AssetLogic.normalizeDecimals(ERC20(_asset).decimals(), uint8(18), _amount); } gas saved according to test cases: test_Connext__bridgeFastOriginLocalToDestinationAdoptedShouldWork() (gas: -39 (-0.001%)) test_Connext__bridgeFastAdoptedShouldWork() (gas: -39 (-0.001%)) test_Connext__unpermissionedCallsWork() (gas: -39 (-0.003%)) test_BridgeFacet__xcall_worksWithPositiveSlippage() (gas: -39 (-0.003%)) test_BridgeFacet__xcall_adoptedTransferWorks() (gas: -39 (-0.003%)) test_Connext__permissionedCallsWork() (gas: -39 (-0.003%)) test_BridgeFacet__xcallIntoLocal_works() (gas: -39 (-0.003%)) test_BridgeFacet__xcall_localTokenTransferWorksWithAdopted() (gas: -39 (-0.003%)) test_Connext__bridgeFastLocalShouldWork() (gas: -39 (-0.004%)) test_BridgeFacet__xcall_localTokenTransferWorksWhenNotAdopted() (gas: -39 (-0.004%)) test_Connext__bridgeSlowLocalShouldWork() (gas: -39 (-0.005%)) test_Connext__zeroValueTransferWithEmptyAssetShouldWork() (gas: -54 (-0.006%)) test_BridgeFacet__xcall_worksIfPreexistingRelayerFee() (gas: -39 (-0.013%)) test_BridgeFacet__xcall_localTokenTransferWorksWithoutAdopted() (gas: -39 (-0.013%)) test_BridgeFacet__xcall_zeroRelayerFeeWorks() (gas: -32 (-0.014%)) test_BridgeFacet__xcall_canonicalTokenTransferWorks() (gas: -39 (-0.014%)) test_LibDiamond__initializeDiamondCut_withZeroAcceptanceDelay_works() (gas: -3812 (-0.015%)) test_BridgeFacet__xcall_zeroValueEmptyAssetWorks() (gas: -54 (-0.034%)) test_BridgeFacet__xcall_worksWithoutValue() (gas: -795 (-0.074%)) test_Connext__zeroValueTransferShouldWork() (gas: -761 (-0.091%)) Overall gas change: -6054 (-0.308%) Note, we need to make sure in future updates the value of _params.normalizedIn == 0 for any invocation of _xcall. Connext: Solved in PR 2511. Spearbit: Verified.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Simplify BridgeFacet._sendMessage by defining _token only when needed", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "In BridgeFacet._sendMessage, _local might be a canonical token that does not necessarily have to follow the IBridgeToken interface. But that is not an issue since _token is only used when !_isCanonical.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Using BridgeMessage library in BridgeFacet._sendMessage can be avoid to save gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "The usage of BridgeMessage library to calculate _tokenId, _action, and finally the formatted mes- sage involves lots of unnecessary memory writes, redundant checks, and overall complicates understanding the flow of the codebase. The BridgeMessage.formatMessage(_tokenId, _action) value passed to IOutbox(s.xAppConnectionManager.home()).dispatch is at the end with the current implementation supposed to be: 92 abi.encodePacked( _canonical.domain, _canonical.id, BridgeMessage.Types.Transfer, _amount, _transferId ); Also, it is redundant that the BridgeMessage.Types.Transfer has been passed to dispatch. it does not add any information to the message unless dispatch also accepts other types. This also adds extra gas overhead due to memory consumption both in the origin and destination domains.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "s.aavePool can be cached to save gas in _backLoan", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "s.aavePool can be cached to save gas by only reading once from the storage.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "<= or >= when comparing a constant can be converted to < or > to save gas", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "In this context, we are doing the following comparison: X <= C // or X >= C Where X is a variable and C is a constant expression. But since the right-hand side of <= (or >=) is the constant expression C we can convert <= into < (or >= into >) to avoid extra opcode/bytecodes being produced by the compiler.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "Use memory's scratch space to calculateCanonicalHash", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "calculateCanonicalHash uses abi.encode to prepare a memory chuck to calculate and return a hash value. Since only 2 words of memory are required to calculate the hash we can utilize the memory's scratch space [0x00, 0x40) for this regard. Using this approach would prevent from paying for memory expansion costs among other things.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "isLocalOrigin can be optimized by using a named return parameter", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "isLocalOrigin after getting the code size of _token returns a comparison result as a bool: assembly { _codeSize := extcodesize(_token) } return _codeSize != 0; This last comparison can be avoided if we use a named return variable since the cast to bool type would automat- ically does the check for us. Currently, the check/comparison is performed twice under the hood. Note: also see issue \"Use contract.code.length\".", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}, {"title": "The branching decision in AmplificationUtils._getAPrecise can be removed.", "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf", "body": "_getAPrecise uses if/else block to compare a1 to a0. This comparison is unnecessary if we use a more simplified formula to return the interpolated value of a.", "labels": ["Spearbit", "ConnextNxtp", "Severity: Gas Optimization"]}]