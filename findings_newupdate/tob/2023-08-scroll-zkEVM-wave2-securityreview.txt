1. PoseidonLookup is not implemented Severity: Informational Diﬃculty: N/A Type: Testing Finding ID: TOB-SCROLL2-1 Target: src/gadgets/poseidon.rs Description Poseidon hashing is performed within the MPT circuit by performing lookups into a Poseidon table via the PoseidonLookup trait, shown in ﬁgure 1.1. /// Lookup represent the poseidon table in zkevm circuit pub trait PoseidonLookup { fn lookup_columns(&self) -> (FixedColumn, [AdviceColumn; 5]) { let (fixed, adv) = self.lookup_columns_generic(); (FixedColumn(fixed), adv.map(AdviceColumn)) } fn lookup_columns_generic(&self) -> (Column<Fixed>, [Column<Advice>; 5]) { let (fixed, adv) = self.lookup_columns(); (fixed.0, adv.map(|col| col.0)) } } Figure 1.1: src/gadgets/poseidon.rs#11–21 This trait is not implemented by any types except the testing-only PoseidonTable shown in ﬁgure 1.2, which does not constrain its columns at all. #[cfg(test)] #[derive(Clone, Copy)] pub struct PoseidonTable { q_enable: FixedColumn, left: AdviceColumn, right: AdviceColumn, hash: AdviceColumn, control: AdviceColumn, head_mark: AdviceColumn, } #[cfg(test)] impl PoseidonTable { pub fn configure<F: FieldExt>(cs: &mut ConstraintSystem<F>) -> Self { let [hash, left, right, control, head_mark] = [0; 5].map(|_| AdviceColumn(cs.advice_column())); Self { left, right, hash, control, head_mark, q_enable: FixedColumn(cs.fixed_column()), } } Figure 1.2: src/gadgets/poseidon.rs#56–80 The rest of the codebase treats this trait as a black-box implementation, so this does not seem to cause correctness problems elsewhere. However, it does limit one’s ability to test some negative cases, and it makes the test coverage rely on the correctness of the PoseidonTable struct’s witness generation. Recommendations Short term, create a concrete implementation of the PoseidonLookup trait to enable full testing of the MPT circuit. Long term, ensure that all parts of the MPT circuit are tested with both positive and negative tests. 
2. IsZeroGadget does not constrain the inverse witness when the value is zero Severity: Informational Diﬃculty: N/A Type: Cryptography Finding ID: TOB-SCROLL2-2 Target: src/gadgets/is_zero.rs Description The IsZeroGadget implementation allows for an arbitrary inverse_or_zero witness value when the value parameter is 0. The gadget returns 1 when value is 0; otherwise, it returns 0. The implementation relies on the existence of an inverse for when value is nonzero and on correctly constraining that value * (1 - value * inverse_or_zero) == 0. However, when value is 0, the constraint is immediately satisﬁed, regardless of the value of the inverse_or_zero witness. This allows an arbitrary value to be provided for that witness value. pub fn configure<F: FieldExt>( cs: &mut ConstraintSystem<F>, cb: &mut ConstraintBuilder<F>, value: AdviceColumn, // TODO: make this a query once Query is clonable/copyable..... ) -> Self { let inverse_or_zero = AdviceColumn(cs.advice_column()); cb.assert_zero( "value is 0 or inverse_or_zero is inverse of value", value.current() * (Query::one() - value.current() * inverse_or_zero.current()), ); Self { value, inverse_or_zero, } } Figure 2.1: mpt-circuit/src/gadgets/is_zero.rs#48–62 Recommendations Short term, ensure that the circuit is deterministic by constraining inverse_or_zero to equal 0 when value is 0. Long term, document which circuits have nondeterministic witnesses; over time, constrain them so that all circuits have deterministic witnesses. 
3. The MPT nonexistence proof gadget is missing constraints speciﬁed in the documentation Severity: Informational Diﬃculty: N/A Type: Cryptography Finding ID: TOB-SCROLL2-3 Target: src/gadgets/mpt_update/nonexistence_proof.rs Description The gadget for checking the consistency of nonexistence proofs is missing several constraints related to type 2 nonexistence proofs. The circuit speciﬁcation includes constraints for the nonexistence of path proofs that are not included in the implementation. This causes the witness values to be unconstrained in some cases. For example, the following constraints are speciﬁed: ● other_key_hash should equal 0 when key does not equal other_key. ● other_leaf_data_hash should equal the hash of the empty node (pointer by other_key). Neither of these constraints is enforced in the implementation: this is because the implementation has no explicit constraints imposed for the type 2 nonexistence proofs. Figure 3.1 shows that the circuit constrains these values only for type 1 proofs. pub fn configure<F: FieldExt>( cb: &mut ConstraintBuilder<F>, value: SecondPhaseAdviceColumn, key: AdviceColumn, other_key: AdviceColumn, key_equals_other_key: IsZeroGadget, hash: AdviceColumn, hash_is_zero: IsZeroGadget, other_key_hash: AdviceColumn, other_leaf_data_hash: AdviceColumn, poseidon: &impl PoseidonLookup, ) { cb.assert_zero("value is 0 for empty node", value.current()); cb.assert_equal( "key_minus_other_key = key - other key", key_equals_other_key.value.current(), key.current() - other_key.current(), ); cb.assert_equal( "hash_is_zero input == hash", hash_is_zero.value.current(), hash.current(), ); let is_type_1 = !key_equals_other_key.current(); let is_type_2 = hash_is_zero.current(); cb.assert_equal( "Empty account is either type 1 xor type 2", Query::one(), Query::from(is_type_1.clone()) + Query::from(is_type_2), ); cb.condition(is_type_1, |cb| { cb.poseidon_lookup( "other_key_hash == h(1, other_key)", [Query::one(), other_key.current(), other_key_hash.current()], poseidon, ); cb.poseidon_lookup( "hash == h(key_hash, other_leaf_data_hash)", [ other_key_hash.current(), other_leaf_data_hash.current(), hash.current(), ], poseidon, ); }); Figure 3.1: mpt-circuit/src/gadgets/mpt_update/nonexistence_proof.rs#7–54 The Scroll team has stated that this is a speciﬁcation error and that the missing constraints do not impact the soundness of the circuit. Recommendations Short term, update the speciﬁcation to remove the description of these constraints; ensure that the documentation is kept updated. Long term, add positive and negative tests for both types of nonexistence proofs. 
4. Discrepancies between the MPT circuit speciﬁcation and implementation Severity: Informational Diﬃculty: N/A Type: Cryptography Finding ID: TOB-SCROLL2-4 Target: Several ﬁles Description The MPT circuit implementation is not faithful to the circuit speciﬁcation in many areas and does not contain comments for the constraints that are either missing from the implementation or that diverge from those in the speciﬁcation. The allowed segment transitions depend on the proof type. For the NonceChanged proof type, the speciﬁcation states that the Start segment type can transition to Start and that the AccountLeaf0 segment type also can transition to Start. However, neither of these paths is allowed in the implementation. MPTProofType::NonceChanged | MPTProofType::BalanceChanged | MPTProofType::CodeSizeExists | MPTProofType::CodeHashExists => [ SegmentType::Start, vec![ SegmentType::AccountTrie, // mpt has > 1 account SegmentType::AccountLeaf0, // mpt has <= 1 account ], ( ), ( SegmentType::AccountTrie, vec![ SegmentType::AccountTrie, SegmentType::AccountLeaf0, SegmentType::Start, // empty account proof ], ), (SegmentType::AccountLeaf0, vec![SegmentType::AccountLeaf1]), (SegmentType::AccountLeaf1, vec![SegmentType::AccountLeaf2]), (SegmentType::AccountLeaf2, vec![SegmentType::AccountLeaf3]), (SegmentType::AccountLeaf3, vec![SegmentType::Start]), Figure 4.1: mpt-circuit/src/gadgets/mpt_update/segment.rs#20– Figure 4.2: Part of the MPT speciﬁcation (spec/mpt-proof.md#L318-L328) The transitions allowed for the PoseidonCodeHashExists proof type also do not match: the speciﬁcation states that it has the same transitions as the NonceChanged proof type, but the implementation has diﬀerent transitions. The key depth direction checks also do not match the speciﬁcation. The speciﬁcation states that the depth parameter should be used but the implementation uses depth - 1. cb.condition(is_trie.clone(), |cb| { cb.add_lookup( "direction is correct for key and depth", [key.current(), depth.current() - 1, direction.current()], key_bit.lookup(), ); cb.assert_equal( "depth increases by 1 in trie segments", depth.current(), depth.previous() + 1, ); cb.condition(path_type.current_matches(&[PathType::Common]), |cb| { cb.add_lookup( "direction is correct for other_key and depth", [ other_key.current(), depth.current() - 1, Figure 4.3: mpt-circuit/src/gadgets/mpt_update.rs#188– Figure 4.4: Part of the MPT speciﬁcation (spec/mpt-proof.md#L279-L282) Finally, the speciﬁcation states that when a segment type is a non-trie type, the value of key should be constrained to 0, but this constraint is omitted from the implementation. cb.condition(!is_trie, |cb| { cb.assert_zero("depth is 0 in non-trie segments", depth.current()); }); Figure 4.5: mpt-circuit/src/gadgets/mpt_update.rs#212–214 Figure 4.6: Part of the MPT speciﬁcation (spec/mpt-proof.md#L284-L286) Recommendations Short term, review the speciﬁcation and ensure its consistency. Match the implementation with the speciﬁcation, and document possible optimizations that remove constraints, detailing why they do not cause soundness issues. Long term, include both positive and negative tests for all edge cases in the speciﬁcation. 
5. Redundant lookups in the Word RLC circuit Severity: Informational Diﬃculty: N/A Type: Cryptography Finding ID: TOB-SCROLL2-5 Target: src/gadgets/mpt_update/word_rlc.rs Description The Word RLC circuit has two redundant lookups into the BytesLookup table. The Word RLC circuit combines the random linear combination (RLC) for the lower and upper 16 bytes of a word into a single RLC value. For this, it checks that the lower and upper word segments are 16 bytes by looking into the BytesLookup table, and it checks that their RLCs are correctly computed by looking into the RlcLookup table. However, the lookup into the RlcLookup table will also ensure that the lower and upper segments of the word have the correct 16 bytes, making the ﬁrst two lookups redundant. pub fn configure<F: FieldExt>( cb: &mut ConstraintBuilder<F>, [word_hash, high, low]: [AdviceColumn; 3], [rlc_word, rlc_high, rlc_low]: [SecondPhaseAdviceColumn; 3], poseidon: &impl PoseidonLookup, bytes: &impl BytesLookup, rlc: &impl RlcLookup, randomness: Query<F>, ) { cb.add_lookup( "old_high is 16 bytes", [high.current(), Query::from(15)], bytes.lookup(), ); cb.add_lookup( "old_low is 16 bytes", [low.current(), Query::from(15)], bytes.lookup(), ); cb.poseidon_lookup( "word_hash = poseidon(high, low)", [high.current(), low.current(), word_hash.current()], poseidon, ); cb.add_lookup( "rlc_high = rlc(high) and high is 16 bytes", [high.current(), Query::from(15), rlc_high.current()], rlc.lookup(), ); cb.add_lookup( "rlc_low = rlc(low) and low is 16 bytes", [low.current(), Query::from(15), rlc_low.current()], rlc.lookup(), Figure 5.1: mpt-circuit/src/gadgets/mpt_update/word_rlc.rs#16–49 Although the WordRLC::configure function receives two diﬀerent lookup objects, bytes and rlc, they are instantiated with the same concrete lookup: let mpt_update = MptUpdateConfig::configure( cs, &mut cb, poseidon, &key_bit, &byte_representation, &byte_representation, &rlc_randomness, &canonical_representation, ); Figure 5.2: mpt-circuit/src/mpt.rs#60–69 We also note that the labels refer to the upper and lower bytes as old_high and old_low instead of just high and low. Recommendations Short term, determine whether both the BytesLookup and RlcLookup tables are needed for this circuit, and refactor the circuit accordingly, removing the redundant constraints. Long term, review the codebase for duplicated or redundant constraints using manual and automated methods. 
6. The NonceChanged conﬁguration circuit does not constrain the new value nonce value Severity: High Diﬃculty: Low Type: Cryptography Finding ID: TOB-SCROLL2-6 Target: src/gadgets/mpt_update.rs Description The NonceChanged conﬁguration circuit does not constrain the config.new_value parameter to be 8 bytes. Instead, there is a duplicated constraint for config.old_value: SegmentType::AccountLeaf3 => { cb.assert_zero("direction is 0", config.direction.current()); let old_code_size = (config.old_hash.current() - config.old_value.current()) * Query::Constant(F::from(1 << 32).square().invert().unwrap()); let new_code_size = (config.new_hash.current() - config.new_value.current()) * Query::Constant(F::from(1 << 32).square().invert().unwrap()); cb.condition( config.path_type.current_matches(&[PathType::Common]), |cb| { cb.add_lookup( "old nonce is 8 bytes", [config.old_value.current(), Query::from(7)], bytes.lookup(), ); cb.add_lookup( "new nonce is 8 bytes", [config.old_value.current(), Query::from(7)], bytes.lookup(), ); Figure 6.1: mpt-circuit/src/gadgets/mpt_update.rs#1209–1228 This means that a malicious prover could update the Account node with a value of arbitrary length for the Nonce and Codesize parameters. The same constraint (with a correct label but incorrect value) is used in the ExtensionNew path type: cb.condition( config.path_type.current_matches(&[PathType::ExtensionNew]), |cb| { cb.add_lookup( "new nonce is 8 bytes", [config.old_value.current(), Query::from(7)], bytes.lookup(), ); Figure 6.2: mpt-circuit/src/gadgets/mpt_update.rs#1241–1248 Exploit Scenario A malicious prover uses the NonceChanged proof to update the nonce with a larger than expected value. Recommendations Short term, enforce the constraint for the config.new_value witness. Long term, add positive and negative testing of the edge cases present in the speciﬁcation. For both the Common and ExtensionNew path types, there should be a negative test that fails because it changes the new nonce to a value larger than 8 bytes. Use automated testing tools like Semgrep to ﬁnd redundant and duplicate constraints, as these could indicate that a constraint is incorrect. 
7. The Copy circuit does not totally enforce the tag values Severity: Informational Diﬃculty: N/A Type: Cryptography Finding ID: TOB-SCROLL2-7 Target: src/copy_circuit/copy_gadgets.rs Description The Copy table includes a tag column that indicates the type of data for that particular row. However, the Copy circuit tag validation function does not totally ensure that the tag matches one of the predeﬁned tag values. The implementation uses the copy_gadgets::constrain_tag function to bind the is_precompiled, is_tx_calldata, is_bytecode, is_memory, and is_tx_log witnesses to the actual tag value. However, the code does not ensure that exactly one of these Boolean values is true. #[allow(clippy::too_many_arguments)] pub fn constrain_tag<F: Field>( meta: &mut ConstraintSystem<F>, q_enable: Column<Fixed>, tag: BinaryNumberConfig<CopyDataType, 4>, is_precompiled: Column<Advice>, is_tx_calldata: Column<Advice>, is_bytecode: Column<Advice>, is_memory: Column<Advice>, is_tx_log: Column<Advice>, ) { meta.create_gate("decode tag", |meta| { let enabled = meta.query_fixed(q_enable, CURRENT); let is_precompile = meta.query_advice(is_precompiled, CURRENT); let is_tx_calldata = meta.query_advice(is_tx_calldata, CURRENT); let is_bytecode = meta.query_advice(is_bytecode, CURRENT); let is_memory = meta.query_advice(is_memory, CURRENT); let is_tx_log = meta.query_advice(is_tx_log, CURRENT); let precompiles = sum::expr([ tag.value_equals( CopyDataType::Precompile(PrecompileCalls::Ecrecover), CURRENT, )(meta), tag.value_equals(CopyDataType::Precompile(PrecompileCalls::Sha256), CURRENT)(meta), tag.value_equals( CopyDataType::Precompile(PrecompileCalls::Ripemd160), CURRENT, )(meta), tag.value_equals(CopyDataType::Precompile(PrecompileCalls::Identity), CURRENT)(meta), tag.value_equals(CopyDataType::Precompile(PrecompileCalls::Modexp), CURRENT)(meta), tag.value_equals(CopyDataType::Precompile(PrecompileCalls::Bn128Add), CURRENT)(meta), tag.value_equals(CopyDataType::Precompile(PrecompileCalls::Bn128Mul), CURRENT)(meta), tag.value_equals( CopyDataType::Precompile(PrecompileCalls::Bn128Pairing), CURRENT, )(meta), tag.value_equals(CopyDataType::Precompile(PrecompileCalls::Blake2F), CURRENT)(meta), ]); vec![ // Match boolean indicators to their respective tag values. enabled.expr() * (is_precompile - precompiles), enabled.expr() * (is_tx_calldata - tag.value_equals(CopyDataType::TxCalldata, CURRENT)(meta)), enabled.expr() CURRENT)(meta)), * (is_bytecode - tag.value_equals(CopyDataType::Bytecode, enabled.expr() * (is_memory - tag.value_equals(CopyDataType::Memory, CURRENT)(meta)), enabled.expr() * (is_tx_log - tag.value_equals(CopyDataType::TxLog, CURRENT)(meta)), ] }); } Figure 7.1: copy_circuit/copy_gadgets.rs#13–62 In fact, the tag value could equal CopyDataType::RlcAcc, as in the SHA3 gadget. The CopyDataType::Padding value is also not currently matched. In the current state of the codebase, this issue does not appear to cause any soundness issues because the lookups into the Copy table either use a statically set source and destination tag or, as in the case of precompiles, the value is correctly bounded and does not pose an avenue of attack for a malicious prover. We also observe that the Copy circuit speciﬁcation mentions a witness value for the is_rlc_acc case, but this is not reﬂected in the code. Recommendations Short term, ensure that the tag column is fully constrained. Review the circuit speciﬁcation and match the implementation with the speciﬁcation, documenting possible optimizations that remove constraints and detailing why they do not cause soundness issues. Long term, include negative tests for an unintended tag value. 
8. The “invalid creation” error handling circuit is unconstrained Severity: High Diﬃculty: Medium Type: Cryptography Finding ID: TOB-SCROLL2-8 Target: evm_circuit/execution/error_invalid_creation_code.rs Description The “invalid creation” error handling circuit does not constrain the ﬁrst byte of the actual memory to be 0xef as intended. This allows a malicious prover to redirect the EVM execution to a halt after the CREATE opcode is called, regardless of the memory value. The ErrorInvalidCreationCodeGadget circuit was updated to accommodate the memory addressing optimizations. However, in doing so, the first_byte witness value that was bound to the memory’s ﬁrst byte is no longer bound to it. Therefore, a malicious prover can always satisfy the circuit constraints, even if they are not in an error state after the CREATE opcode is called. fn configure(cb: &mut EVMConstraintBuilder<F>) -> Self { let opcode = cb.query_cell(); let first_byte = cb.query_cell(); //let address = cb.query_word_rlc(); let offset = cb.query_word_rlc(); let length = cb.query_word_rlc(); let value_left = cb.query_word_rlc(); cb.stack_pop(offset.expr()); cb.stack_pop(length.expr()); cb.require_true("is_create is true", cb.curr.state.is_create.expr()); let address_word = MemoryWordAddress::construct(cb, offset.clone()); // lookup memory for first word cb.memory_lookup( 0.expr(), address_word.addr_left(), value_left.expr(), value_left.expr(), None, ); // let first_byte = value_left.cells[address_word.shift()]; // constrain first byte is 0xef let is_first_byte_invalid = IsEqualGadget::construct(cb, first_byte.expr(), 0xef.expr()); cb.require_true( "is_first_byte_invalid is true", is_first_byte_invalid.expr(), ); Figure 8.1: evm_circuit/execution/error_invalid_creation_code.rs#36–67 Exploit Scenario A malicious prover generates two diﬀerent proofs for the same transaction, one leading to the error state, and the other successfully executing the CREATE opcode. Distributing these proofs to two ends of a bridge leads to state divergence and a loss of funds. Recommendations Short term, bind the first_byte witness value to the memory value; ensure that the successful CREATE end state checks that the ﬁrst byte is diﬀerent from 0xef. Long term, investigate ways to generate malicious traces that could be added to the test suite; every time a new soundness issue is found, create such a malicious trace and add it to the test suite. 
9. The OneHot primitive allows more than one value at once Severity: High Diﬃculty: Low Type: Cryptography Finding ID: TOB-SCROLL2-9 Target: constraint_builder/binary_column.rs Description The OneHot primitive uses BinaryQuery values as witness values. However, despite their name, these values are not constrained to be Boolean values, allowing a malicious prover to choose more than one “hot” value in the data structure. impl<T: IntoEnumIterator + Hash + Eq> OneHot<T> { pub fn configure<F: FieldExt>( cs: &mut ConstraintSystem<F>, cb: &mut ConstraintBuilder<F>, ) -> Self { let mut columns = HashMap::new(); for variant in Self::nonfirst_variants() { columns.insert(variant, cb.binary_columns::<1>(cs)[0]); } let config = Self { columns }; cb.assert( "sum of binary columns in OneHot is 0 or 1", config.sum(0).or(!config.sum(0)), ); config } Figure 9.1: mpt-circuit/src/gadgets/one_hot.rs#14–30 The reason the BinaryQuery values are not constrained to be Boolean is because the BinaryColumn conﬁguration does not constrain the advice values to be Boolean, and the conﬁguration is simply a type wrapper around the Column<Advice> type. This provides no guarantees to the users of this API, who might assume that these values are guaranteed to be Boolean. pub fn configure<F: FieldExt>( cs: &mut ConstraintSystem<F>, _cb: &mut ConstraintBuilder<F>, ) -> Self { let advice_column = cs.advice_column(); // TODO: constrain to be binary here... // cb.add_constraint() Self(advice_column) } Figure 9.2: mpt-circuit/src/constraint_builder/binary_column.rs#29–37 The OneHot primitive is used to implement the Merkle path–checking state machine, including critical properties such as requiring the key and other_key columns to remain unchanged along a given Merkle path calculation, as shown in ﬁgure 9.3. cb.condition( !segment_type.current_matches(&[SegmentType::Start, SegmentType::AccountLeaf3]), |cb| { cb.assert_equal( "key can only change on Start or AccountLeaf3 rows", key.current(), key.previous(), ); cb.assert_equal( "other_key can only change on Start or AccountLeaf3 rows", other_key.current(), other_key.previous(), ); }, ); Figure 9.3: mpt-circuit/src/gadgets/mpt_update.rs#170–184 We did not develop a proof-of-concept exploit for the path-checking table, so it may be the case that the constraint in ﬁgure 9.3 is not exploitable due to other constraints. However, if at any point it is possible to match both SegmentType::Start and some other segment type (such as by setting one OneHot cell to 1 and another to -1), a malicious prover would be able to change the key partway through and forge Merkle updates. Exploit Scenario A malicious prover uses the OneHot soundness issue to bypass constraints, ensuring that the key and other_key columns remain unchanged along a given Merkle path calculation. This allows the attacker to successfully forge MPT update proofs that update an arbitrary key. Recommendations Short term, add constraints that ensure that the advice values from these columns are Boolean. Long term, add positive and negative tests ensuring that these constraint builders operate according to their expectations. 
1. PoseidonLookup is not implemented Severity: Informational Diﬃculty: N/A Type: Testing Finding ID: TOB-SCROLL2-1 Target: src/gadgets/poseidon.rs Description Poseidon hashing is performed within the MPT circuit by performing lookups into a Poseidon table via the PoseidonLookup trait, shown in ﬁgure 1.1. /// Lookup represent the poseidon table in zkevm circuit pub trait PoseidonLookup { fn lookup_columns(&self) -> (FixedColumn, [AdviceColumn; 5]) { let (fixed, adv) = self.lookup_columns_generic(); (FixedColumn(fixed), adv.map(AdviceColumn)) } fn lookup_columns_generic(&self) -> (Column<Fixed>, [Column<Advice>; 5]) { let (fixed, adv) = self.lookup_columns(); (fixed.0, adv.map(|col| col.0)) } } Figure 1.1: src/gadgets/poseidon.rs#11–21 This trait is not implemented by any types except the testing-only PoseidonTable shown in ﬁgure 1.2, which does not constrain its columns at all. #[cfg(test)] #[derive(Clone, Copy)] pub struct PoseidonTable { q_enable: FixedColumn, left: AdviceColumn, right: AdviceColumn, hash: AdviceColumn, control: AdviceColumn, head_mark: AdviceColumn, } #[cfg(test)] impl PoseidonTable { pub fn configure<F: FieldExt>(cs: &mut ConstraintSystem<F>) -> Self { let [hash, left, right, control, head_mark] = [0; 5].map(|_| AdviceColumn(cs.advice_column())); Self { left, right, hash, control, head_mark, q_enable: FixedColumn(cs.fixed_column()), } } Figure 1.2: src/gadgets/poseidon.rs#56–80 The rest of the codebase treats this trait as a black-box implementation, so this does not seem to cause correctness problems elsewhere. However, it does limit one’s ability to test some negative cases, and it makes the test coverage rely on the correctness of the PoseidonTable struct’s witness generation. Recommendations Short term, create a concrete implementation of the PoseidonLookup trait to enable full testing of the MPT circuit. Long term, ensure that all parts of the MPT circuit are tested with both positive and negative tests. 
2. IsZeroGadget does not constrain the inverse witness when the value is zero Severity: Informational Diﬃculty: N/A Type: Cryptography Finding ID: TOB-SCROLL2-2 Target: src/gadgets/is_zero.rs Description The IsZeroGadget implementation allows for an arbitrary inverse_or_zero witness value when the value parameter is 0. The gadget returns 1 when value is 0; otherwise, it returns 0. The implementation relies on the existence of an inverse for when value is nonzero and on correctly constraining that value * (1 - value * inverse_or_zero) == 0. However, when value is 0, the constraint is immediately satisﬁed, regardless of the value of the inverse_or_zero witness. This allows an arbitrary value to be provided for that witness value. pub fn configure<F: FieldExt>( cs: &mut ConstraintSystem<F>, cb: &mut ConstraintBuilder<F>, value: AdviceColumn, // TODO: make this a query once Query is clonable/copyable..... ) -> Self { let inverse_or_zero = AdviceColumn(cs.advice_column()); cb.assert_zero( "value is 0 or inverse_or_zero is inverse of value", value.current() * (Query::one() - value.current() * inverse_or_zero.current()), ); Self { value, inverse_or_zero, } } Figure 2.1: mpt-circuit/src/gadgets/is_zero.rs#48–62 Recommendations Short term, ensure that the circuit is deterministic by constraining inverse_or_zero to equal 0 when value is 0. Long term, document which circuits have nondeterministic witnesses; over time, constrain them so that all circuits have deterministic witnesses. 
3. The MPT nonexistence proof gadget is missing constraints speciﬁed in the documentation Severity: Informational Diﬃculty: N/A Type: Cryptography Finding ID: TOB-SCROLL2-3 Target: src/gadgets/mpt_update/nonexistence_proof.rs Description The gadget for checking the consistency of nonexistence proofs is missing several constraints related to type 2 nonexistence proofs. The circuit speciﬁcation includes constraints for the nonexistence of path proofs that are not included in the implementation. This causes the witness values to be unconstrained in some cases. For example, the following constraints are speciﬁed: ● other_key_hash should equal 0 when key does not equal other_key. ● other_leaf_data_hash should equal the hash of the empty node (pointer by other_key). Neither of these constraints is enforced in the implementation: this is because the implementation has no explicit constraints imposed for the type 2 nonexistence proofs. Figure 3.1 shows that the circuit constrains these values only for type 1 proofs. pub fn configure<F: FieldExt>( cb: &mut ConstraintBuilder<F>, value: SecondPhaseAdviceColumn, key: AdviceColumn, other_key: AdviceColumn, key_equals_other_key: IsZeroGadget, hash: AdviceColumn, hash_is_zero: IsZeroGadget, other_key_hash: AdviceColumn, other_leaf_data_hash: AdviceColumn, poseidon: &impl PoseidonLookup, ) { cb.assert_zero("value is 0 for empty node", value.current()); cb.assert_equal( "key_minus_other_key = key - other key", key_equals_other_key.value.current(), key.current() - other_key.current(), ); cb.assert_equal( "hash_is_zero input == hash", hash_is_zero.value.current(), hash.current(), ); let is_type_1 = !key_equals_other_key.current(); let is_type_2 = hash_is_zero.current(); cb.assert_equal( "Empty account is either type 1 xor type 2", Query::one(), Query::from(is_type_1.clone()) + Query::from(is_type_2), ); cb.condition(is_type_1, |cb| { cb.poseidon_lookup( "other_key_hash == h(1, other_key)", [Query::one(), other_key.current(), other_key_hash.current()], poseidon, ); cb.poseidon_lookup( "hash == h(key_hash, other_leaf_data_hash)", [ other_key_hash.current(), other_leaf_data_hash.current(), hash.current(), ], poseidon, ); }); Figure 3.1: mpt-circuit/src/gadgets/mpt_update/nonexistence_proof.rs#7–54 The Scroll team has stated that this is a speciﬁcation error and that the missing constraints do not impact the soundness of the circuit. Recommendations Short term, update the speciﬁcation to remove the description of these constraints; ensure that the documentation is kept updated. Long term, add positive and negative tests for both types of nonexistence proofs. 
4. Discrepancies between the MPT circuit speciﬁcation and implementation Severity: Informational Diﬃculty: N/A Type: Cryptography Finding ID: TOB-SCROLL2-4 Target: Several ﬁles Description The MPT circuit implementation is not faithful to the circuit speciﬁcation in many areas and does not contain comments for the constraints that are either missing from the implementation or that diverge from those in the speciﬁcation. The allowed segment transitions depend on the proof type. For the NonceChanged proof type, the speciﬁcation states that the Start segment type can transition to Start and that the AccountLeaf0 segment type also can transition to Start. However, neither of these paths is allowed in the implementation. MPTProofType::NonceChanged | MPTProofType::BalanceChanged | MPTProofType::CodeSizeExists | MPTProofType::CodeHashExists => [ SegmentType::Start, vec![ SegmentType::AccountTrie, // mpt has > 1 account SegmentType::AccountLeaf0, // mpt has <= 1 account ], ( ), ( SegmentType::AccountTrie, vec![ SegmentType::AccountTrie, SegmentType::AccountLeaf0, SegmentType::Start, // empty account proof ], ), (SegmentType::AccountLeaf0, vec![SegmentType::AccountLeaf1]), (SegmentType::AccountLeaf1, vec![SegmentType::AccountLeaf2]), (SegmentType::AccountLeaf2, vec![SegmentType::AccountLeaf3]), (SegmentType::AccountLeaf3, vec![SegmentType::Start]), Figure 4.1: mpt-circuit/src/gadgets/mpt_update/segment.rs#20– Figure 4.2: Part of the MPT speciﬁcation (spec/mpt-proof.md#L318-L328) The transitions allowed for the PoseidonCodeHashExists proof type also do not match: the speciﬁcation states that it has the same transitions as the NonceChanged proof type, but the implementation has diﬀerent transitions. The key depth direction checks also do not match the speciﬁcation. The speciﬁcation states that the depth parameter should be used but the implementation uses depth - 1. cb.condition(is_trie.clone(), |cb| { cb.add_lookup( "direction is correct for key and depth", [key.current(), depth.current() - 1, direction.current()], key_bit.lookup(), ); cb.assert_equal( "depth increases by 1 in trie segments", depth.current(), depth.previous() + 1, ); cb.condition(path_type.current_matches(&[PathType::Common]), |cb| { cb.add_lookup( "direction is correct for other_key and depth", [ other_key.current(), depth.current() - 1, Figure 4.3: mpt-circuit/src/gadgets/mpt_update.rs#188– Figure 4.4: Part of the MPT speciﬁcation (spec/mpt-proof.md#L279-L282) Finally, the speciﬁcation states that when a segment type is a non-trie type, the value of key should be constrained to 0, but this constraint is omitted from the implementation. cb.condition(!is_trie, |cb| { cb.assert_zero("depth is 0 in non-trie segments", depth.current()); }); Figure 4.5: mpt-circuit/src/gadgets/mpt_update.rs#212–214 Figure 4.6: Part of the MPT speciﬁcation (spec/mpt-proof.md#L284-L286) Recommendations Short term, review the speciﬁcation and ensure its consistency. Match the implementation with the speciﬁcation, and document possible optimizations that remove constraints, detailing why they do not cause soundness issues. Long term, include both positive and negative tests for all edge cases in the speciﬁcation. 
5. Redundant lookups in the Word RLC circuit Severity: Informational Diﬃculty: N/A Type: Cryptography Finding ID: TOB-SCROLL2-5 Target: src/gadgets/mpt_update/word_rlc.rs Description The Word RLC circuit has two redundant lookups into the BytesLookup table. The Word RLC circuit combines the random linear combination (RLC) for the lower and upper 16 bytes of a word into a single RLC value. For this, it checks that the lower and upper word segments are 16 bytes by looking into the BytesLookup table, and it checks that their RLCs are correctly computed by looking into the RlcLookup table. However, the lookup into the RlcLookup table will also ensure that the lower and upper segments of the word have the correct 16 bytes, making the ﬁrst two lookups redundant. pub fn configure<F: FieldExt>( cb: &mut ConstraintBuilder<F>, [word_hash, high, low]: [AdviceColumn; 3], [rlc_word, rlc_high, rlc_low]: [SecondPhaseAdviceColumn; 3], poseidon: &impl PoseidonLookup, bytes: &impl BytesLookup, rlc: &impl RlcLookup, randomness: Query<F>, ) { cb.add_lookup( "old_high is 16 bytes", [high.current(), Query::from(15)], bytes.lookup(), ); cb.add_lookup( "old_low is 16 bytes", [low.current(), Query::from(15)], bytes.lookup(), ); cb.poseidon_lookup( "word_hash = poseidon(high, low)", [high.current(), low.current(), word_hash.current()], poseidon, ); cb.add_lookup( "rlc_high = rlc(high) and high is 16 bytes", [high.current(), Query::from(15), rlc_high.current()], rlc.lookup(), ); cb.add_lookup( "rlc_low = rlc(low) and low is 16 bytes", [low.current(), Query::from(15), rlc_low.current()], rlc.lookup(), Figure 5.1: mpt-circuit/src/gadgets/mpt_update/word_rlc.rs#16–49 Although the WordRLC::configure function receives two diﬀerent lookup objects, bytes and rlc, they are instantiated with the same concrete lookup: let mpt_update = MptUpdateConfig::configure( cs, &mut cb, poseidon, &key_bit, &byte_representation, &byte_representation, &rlc_randomness, &canonical_representation, ); Figure 5.2: mpt-circuit/src/mpt.rs#60–69 We also note that the labels refer to the upper and lower bytes as old_high and old_low instead of just high and low. Recommendations Short term, determine whether both the BytesLookup and RlcLookup tables are needed for this circuit, and refactor the circuit accordingly, removing the redundant constraints. Long term, review the codebase for duplicated or redundant constraints using manual and automated methods. 
6. The NonceChanged conﬁguration circuit does not constrain the new value nonce value Severity: High Diﬃculty: Low Type: Cryptography Finding ID: TOB-SCROLL2-6 Target: src/gadgets/mpt_update.rs Description The NonceChanged conﬁguration circuit does not constrain the config.new_value parameter to be 8 bytes. Instead, there is a duplicated constraint for config.old_value: SegmentType::AccountLeaf3 => { cb.assert_zero("direction is 0", config.direction.current()); let old_code_size = (config.old_hash.current() - config.old_value.current()) * Query::Constant(F::from(1 << 32).square().invert().unwrap()); let new_code_size = (config.new_hash.current() - config.new_value.current()) * Query::Constant(F::from(1 << 32).square().invert().unwrap()); cb.condition( config.path_type.current_matches(&[PathType::Common]), |cb| { cb.add_lookup( "old nonce is 8 bytes", [config.old_value.current(), Query::from(7)], bytes.lookup(), ); cb.add_lookup( "new nonce is 8 bytes", [config.old_value.current(), Query::from(7)], bytes.lookup(), ); Figure 6.1: mpt-circuit/src/gadgets/mpt_update.rs#1209–1228 This means that a malicious prover could update the Account node with a value of arbitrary length for the Nonce and Codesize parameters. The same constraint (with a correct label but incorrect value) is used in the ExtensionNew path type: cb.condition( config.path_type.current_matches(&[PathType::ExtensionNew]), |cb| { cb.add_lookup( "new nonce is 8 bytes", [config.old_value.current(), Query::from(7)], bytes.lookup(), ); Figure 6.2: mpt-circuit/src/gadgets/mpt_update.rs#1241–1248 Exploit Scenario A malicious prover uses the NonceChanged proof to update the nonce with a larger than expected value. Recommendations Short term, enforce the constraint for the config.new_value witness. Long term, add positive and negative testing of the edge cases present in the speciﬁcation. For both the Common and ExtensionNew path types, there should be a negative test that fails because it changes the new nonce to a value larger than 8 bytes. Use automated testing tools like Semgrep to ﬁnd redundant and duplicate constraints, as these could indicate that a constraint is incorrect. 
7. The Copy circuit does not totally enforce the tag values Severity: Informational Diﬃculty: N/A Type: Cryptography Finding ID: TOB-SCROLL2-7 Target: src/copy_circuit/copy_gadgets.rs Description The Copy table includes a tag column that indicates the type of data for that particular row. However, the Copy circuit tag validation function does not totally ensure that the tag matches one of the predeﬁned tag values. The implementation uses the copy_gadgets::constrain_tag function to bind the is_precompiled, is_tx_calldata, is_bytecode, is_memory, and is_tx_log witnesses to the actual tag value. However, the code does not ensure that exactly one of these Boolean values is true. #[allow(clippy::too_many_arguments)] pub fn constrain_tag<F: Field>( meta: &mut ConstraintSystem<F>, q_enable: Column<Fixed>, tag: BinaryNumberConfig<CopyDataType, 4>, is_precompiled: Column<Advice>, is_tx_calldata: Column<Advice>, is_bytecode: Column<Advice>, is_memory: Column<Advice>, is_tx_log: Column<Advice>, ) { meta.create_gate("decode tag", |meta| { let enabled = meta.query_fixed(q_enable, CURRENT); let is_precompile = meta.query_advice(is_precompiled, CURRENT); let is_tx_calldata = meta.query_advice(is_tx_calldata, CURRENT); let is_bytecode = meta.query_advice(is_bytecode, CURRENT); let is_memory = meta.query_advice(is_memory, CURRENT); let is_tx_log = meta.query_advice(is_tx_log, CURRENT); let precompiles = sum::expr([ tag.value_equals( CopyDataType::Precompile(PrecompileCalls::Ecrecover), CURRENT, )(meta), tag.value_equals(CopyDataType::Precompile(PrecompileCalls::Sha256), CURRENT)(meta), tag.value_equals( CopyDataType::Precompile(PrecompileCalls::Ripemd160), CURRENT, )(meta), tag.value_equals(CopyDataType::Precompile(PrecompileCalls::Identity), CURRENT)(meta), tag.value_equals(CopyDataType::Precompile(PrecompileCalls::Modexp), CURRENT)(meta), tag.value_equals(CopyDataType::Precompile(PrecompileCalls::Bn128Add), CURRENT)(meta), tag.value_equals(CopyDataType::Precompile(PrecompileCalls::Bn128Mul), CURRENT)(meta), tag.value_equals( CopyDataType::Precompile(PrecompileCalls::Bn128Pairing), CURRENT, )(meta), tag.value_equals(CopyDataType::Precompile(PrecompileCalls::Blake2F), CURRENT)(meta), ]); vec![ // Match boolean indicators to their respective tag values. enabled.expr() * (is_precompile - precompiles), enabled.expr() * (is_tx_calldata - tag.value_equals(CopyDataType::TxCalldata, CURRENT)(meta)), enabled.expr() CURRENT)(meta)), * (is_bytecode - tag.value_equals(CopyDataType::Bytecode, enabled.expr() * (is_memory - tag.value_equals(CopyDataType::Memory, CURRENT)(meta)), enabled.expr() * (is_tx_log - tag.value_equals(CopyDataType::TxLog, CURRENT)(meta)), ] }); } Figure 7.1: copy_circuit/copy_gadgets.rs#13–62 In fact, the tag value could equal CopyDataType::RlcAcc, as in the SHA3 gadget. The CopyDataType::Padding value is also not currently matched. In the current state of the codebase, this issue does not appear to cause any soundness issues because the lookups into the Copy table either use a statically set source and destination tag or, as in the case of precompiles, the value is correctly bounded and does not pose an avenue of attack for a malicious prover. We also observe that the Copy circuit speciﬁcation mentions a witness value for the is_rlc_acc case, but this is not reﬂected in the code. Recommendations Short term, ensure that the tag column is fully constrained. Review the circuit speciﬁcation and match the implementation with the speciﬁcation, documenting possible optimizations that remove constraints and detailing why they do not cause soundness issues. Long term, include negative tests for an unintended tag value. 
8. The “invalid creation” error handling circuit is unconstrained Severity: High Diﬃculty: Medium Type: Cryptography Finding ID: TOB-SCROLL2-8 Target: evm_circuit/execution/error_invalid_creation_code.rs Description The “invalid creation” error handling circuit does not constrain the ﬁrst byte of the actual memory to be 0xef as intended. This allows a malicious prover to redirect the EVM execution to a halt after the CREATE opcode is called, regardless of the memory value. The ErrorInvalidCreationCodeGadget circuit was updated to accommodate the memory addressing optimizations. However, in doing so, the first_byte witness value that was bound to the memory’s ﬁrst byte is no longer bound to it. Therefore, a malicious prover can always satisfy the circuit constraints, even if they are not in an error state after the CREATE opcode is called. fn configure(cb: &mut EVMConstraintBuilder<F>) -> Self { let opcode = cb.query_cell(); let first_byte = cb.query_cell(); //let address = cb.query_word_rlc(); let offset = cb.query_word_rlc(); let length = cb.query_word_rlc(); let value_left = cb.query_word_rlc(); cb.stack_pop(offset.expr()); cb.stack_pop(length.expr()); cb.require_true("is_create is true", cb.curr.state.is_create.expr()); let address_word = MemoryWordAddress::construct(cb, offset.clone()); // lookup memory for first word cb.memory_lookup( 0.expr(), address_word.addr_left(), value_left.expr(), value_left.expr(), None, ); // let first_byte = value_left.cells[address_word.shift()]; // constrain first byte is 0xef let is_first_byte_invalid = IsEqualGadget::construct(cb, first_byte.expr(), 0xef.expr()); cb.require_true( "is_first_byte_invalid is true", is_first_byte_invalid.expr(), ); Figure 8.1: evm_circuit/execution/error_invalid_creation_code.rs#36–67 Exploit Scenario A malicious prover generates two diﬀerent proofs for the same transaction, one leading to the error state, and the other successfully executing the CREATE opcode. Distributing these proofs to two ends of a bridge leads to state divergence and a loss of funds. Recommendations Short term, bind the first_byte witness value to the memory value; ensure that the successful CREATE end state checks that the ﬁrst byte is diﬀerent from 0xef. Long term, investigate ways to generate malicious traces that could be added to the test suite; every time a new soundness issue is found, create such a malicious trace and add it to the test suite. 
9. The OneHot primitive allows more than one value at once Severity: High Diﬃculty: Low Type: Cryptography Finding ID: TOB-SCROLL2-9 Target: constraint_builder/binary_column.rs Description The OneHot primitive uses BinaryQuery values as witness values. However, despite their name, these values are not constrained to be Boolean values, allowing a malicious prover to choose more than one “hot” value in the data structure. impl<T: IntoEnumIterator + Hash + Eq> OneHot<T> { pub fn configure<F: FieldExt>( cs: &mut ConstraintSystem<F>, cb: &mut ConstraintBuilder<F>, ) -> Self { let mut columns = HashMap::new(); for variant in Self::nonfirst_variants() { columns.insert(variant, cb.binary_columns::<1>(cs)[0]); } let config = Self { columns }; cb.assert( "sum of binary columns in OneHot is 0 or 1", config.sum(0).or(!config.sum(0)), ); config } Figure 9.1: mpt-circuit/src/gadgets/one_hot.rs#14–30 The reason the BinaryQuery values are not constrained to be Boolean is because the BinaryColumn conﬁguration does not constrain the advice values to be Boolean, and the conﬁguration is simply a type wrapper around the Column<Advice> type. This provides no guarantees to the users of this API, who might assume that these values are guaranteed to be Boolean. pub fn configure<F: FieldExt>( cs: &mut ConstraintSystem<F>, _cb: &mut ConstraintBuilder<F>, ) -> Self { let advice_column = cs.advice_column(); // TODO: constrain to be binary here... // cb.add_constraint() Self(advice_column) } Figure 9.2: mpt-circuit/src/constraint_builder/binary_column.rs#29–37 The OneHot primitive is used to implement the Merkle path–checking state machine, including critical properties such as requiring the key and other_key columns to remain unchanged along a given Merkle path calculation, as shown in ﬁgure 9.3. cb.condition( !segment_type.current_matches(&[SegmentType::Start, SegmentType::AccountLeaf3]), |cb| { cb.assert_equal( "key can only change on Start or AccountLeaf3 rows", key.current(), key.previous(), ); cb.assert_equal( "other_key can only change on Start or AccountLeaf3 rows", other_key.current(), other_key.previous(), ); }, ); Figure 9.3: mpt-circuit/src/gadgets/mpt_update.rs#170–184 We did not develop a proof-of-concept exploit for the path-checking table, so it may be the case that the constraint in ﬁgure 9.3 is not exploitable due to other constraints. However, if at any point it is possible to match both SegmentType::Start and some other segment type (such as by setting one OneHot cell to 1 and another to -1), a malicious prover would be able to change the key partway through and forge Merkle updates. Exploit Scenario A malicious prover uses the OneHot soundness issue to bypass constraints, ensuring that the key and other_key columns remain unchanged along a given Merkle path calculation. This allows the attacker to successfully forge MPT update proofs that update an arbitrary key. Recommendations Short term, add constraints that ensure that the advice values from these columns are Boolean. Long term, add positive and negative tests ensuring that these constraint builders operate according to their expectations. 
10. Intermediate columns are not explicit Severity: Informational Diﬃculty: N/A Type: Cryptography Finding ID: TOB-SCROLL2-10 Target: src/mpt_update.rs Description The MPT update circuit includes two arrays of “intermediate value” columns, as shown in ﬁgure 10.1. intermediate_values: [AdviceColumn; 10], // can be 4? second_phase_intermediate_values: [SecondPhaseAdviceColumn; 10], // 4? Figure 10.1: mpt-circuit/src/gadgets/mpt_update.rs#65–66 These columns are used as general-use cells for values that are only conditionally needed in a given row, reducing the total number of columns needed. For example, ﬁgure 10.2 shows that intermediate_values[0] is used for the address value in rows that match SegmentType::Start, but as shown in ﬁgure 10.3, rows representing the SegmentType::AccountLeaf3 state of a Keccak code-hash proof use that same slot for the old_high value. let address = self.intermediate_values[0].current() * is_start(); Figure 10.2: mpt-circuit/src/gadgets/mpt_update.rs#78 SegmentType::AccountLeaf3 => { cb.assert_equal("direction is 1", config.direction.current(), Query::one()); let [old_high, old_low, new_high, new_low, ..] = config.intermediate_values; Figure 10.3: mpt-circuit/src/gadgets/mpt_update.rs#1632–1635 In some cases, cells of intermediate_values are used starting from the end of the intermediate_values column, such as the other_key_hash and other_leaf_data_hash values in PathType::ExtensionOld rows, as illustrated in ﬁgure 10.4. let [.., key_equals_other_key, new_hash_is_zero] = config.is_zero_gadgets; let [.., other_key_hash, other_leaf_data_hash] = config.intermediate_values; nonexistence_proof::configure( cb, config.new_value, config.key, config.other_key, key_equals_other_key, config.new_hash, new_hash_is_zero, other_key_hash, other_leaf_data_hash, poseidon, ); Figure 10.4: mpt-circuit/src/gadgets/mpt_update.rs#1036–1049 Although we did not ﬁnd any mistakes such as misused columns, this pattern is ad hoc and error-prone, and evaluating the correctness of this pattern requires checking every individual use of intermediate_values. Recommendations Short term, document the assignment of all intermediate_values columns in each relevant case. Long term, consider using Rust types to express the diﬀerent uses of the various intermediate_values columns. For example, one could deﬁne an IntermediateValues enum, with cases like StartRow { address: &AdviceColumn } and ExtensionOld { other_key_hash: &AdviceColumn, other_leaf_data_hash: &AdviceColumn }, and a single function fn parse_intermediate_values(segment_type: SegmentType, path_type: PathType, columns: &[AdviceColumn; 10]) -> IntermediateValues. Then, the correct assignment and use of intermediate_values columns can be audited only by checking parse_intermediate_values. A. Vulnerability Categories The following tables describe the vulnerability categories, severity levels, and diﬃculty levels used in this document. Vulnerability Categories Category Description Access Controls Insuﬃcient authorization or assessment of rights Auditing and Logging Insuﬃcient auditing of actions or logging of problems Authentication Improper identiﬁcation of users Conﬁguration Misconﬁgured servers, devices, or software components Cryptography A breach of system conﬁdentiality or integrity Data Exposure Exposure of sensitive information Data Validation Improper reliance on the structure or values of data Denial of Service A system failure with an availability impact Error Reporting Insecure or insuﬃcient reporting of error conditions Patching Use of an outdated software package or library Session Management Improper identiﬁcation of authenticated users Testing Timing Insuﬃcient test methodology or test coverage Race conditions or other order-of-operations ﬂaws Undeﬁned Behavior Undeﬁned behavior triggered within the system Severity Levels Severity Description Informational The issue does not pose an immediate risk but is relevant to security best practices. Undetermined The extent of the risk was not determined during this engagement. Low The risk is small or is not one the client has indicated is important. Medium High User information is at risk; exploitation could pose reputational, legal, or moderate ﬁnancial risks. The ﬂaw could aﬀect numerous users and have serious reputational, legal, or ﬁnancial implications. Diﬃculty Levels Diﬃculty Description Undetermined The diﬃculty of exploitation was not determined during this engagement. Low Medium High The ﬂaw is well known; public tools for its exploitation exist or can be scripted. An attacker must write an exploit or will need in-depth knowledge of the system. An attacker must have privileged access to the system, may need to know complex technical details, or must discover other weaknesses to exploit this issue. B. Code Maturity Categories The following tables describe the code maturity categories and rating criteria used in this document. Code Maturity Categories Category Description Arithmetic The proper use of mathematical operations and semantics Complexity Management The presence of clear structures designed to manage system complexity, including the separation of system logic into clearly deﬁned functions Cryptography and Key Management The safe use of cryptographic primitives and functions, along with the presence of robust mechanisms for key generation and distribution Documentation The presence of comprehensive and readable codebase documentation Memory Safety and Error Handling The presence of memory safety and robust error-handling mechanisms Testing and Veriﬁcation The presence of robust testing procedures (e.g., unit tests, integration tests, and veriﬁcation methods) and suﬃcient test coverage Rating Criteria Rating Strong Description No issues were found, and the system exceeds industry standards. Satisfactory Minor issues were found, but the system is compliant with best practices. Moderate Some issues that may aﬀect system safety were found. Weak Many issues that aﬀect system safety were found. Missing A required component is missing, signiﬁcantly aﬀecting system safety. Not Applicable The category is not applicable to this review. Not Considered The category was not considered in this review. Further Investigation Required Further investigation is required to reach a meaningful conclusion. C. Code Quality Findings We identiﬁed the following code quality issues through manual and automatic code review. ● Allow the dead_code lint and ﬁx all issues. The dead_code lint is currently disabled; it should be enabled to allow developers to quickly detect unused functions and variables. ● Several constraints have meaningless labels. Constraint labels are useful for explaining the intention behind constraints; using meaningless labels hinders code readability. region .assign_fixed( || "asdfasdfawe", self.0, Figure C.1: mpt-circuit/src/constraint_builder/column.rs#52–55 cb.assert_equal("???????", rlc.current(), byte.current()); }); cb.condition(!index_is_zero.current(), |cb| { cb.assert_equal( "value can only change when index = 0", value.current(), value.previous(), ); cb.assert_equal( "differences_are_zero_so_far = difference == 0 && differences_are_zero_so_far.previous() when index != 0", differences_are_zero_so_far.current().into(), differences_are_zero_so_far .previous() .and(difference_is_zero.previous()) .into(), ); cb.assert_equal( "???", Figure C.2: mpt-circuit/src/gadgets/canonical_representation.rs#72–89 ● There are duplicate and unused functions in the codebase. The types.rs and util.rs ﬁles have several duplicate functions: fr, hash, storage_key_hash, split_word, hi_lo, and Bit. ● The following constraint label was incorrectly copy-pasted. cb.assert_equal( "old_value does not change", new_value.current(), new_value.previous(), ); Figure C.3: mpt-circuit/src/gadgets/mpt_update.rs#163–167 ● There are redundant constraints in empty storage/account constraints. The configure_empty_storage and configure_empty_account functions require the new_value and old_value ﬁelds to be 0 but also constrain them to be equal. cb.assert_zero( "old value is 0 for empty storage", config.old_value.current(), ); cb.assert_zero( "new value is 0 for empty storage", config.new_value.current(), ); ... cb.assert_equal( "old value = new value for empty account proof", config.old_value.current(), config.new_value.current(), ); Figure C.4: mpt-circuit/src/gadgets/mpt_update.rs#1785–1811 cb.assert_zero("old value is 0", config.old_value.current()); cb.assert_zero("new value is 0", config.new_value.current()); ... cb.assert_equal( "old value = new value for empty account proof", config.old_value.current(), config.new_value.current(), ); Figure C.5: mpt-circuit/src/gadgets/mpt_update.rs#1869–1893 ● The following constraint label is imprecise. The label should read rwc_inc_left[1] == rwc_inc_left[0] - rwc_diff, or 0 at the end to match the code. // Decrement rwc_inc_left for the next row, when an RW operation happens. let rwc_diff = is_rw_type.expr() * is_word_end.expr(); let new_value = meta.query_advice(rwc_inc_left, CURRENT) - rwc_diff; // At the end, it must reach 0. let update_or_finish = select::expr( not::expr(is_last.expr()), meta.query_advice(rwc_inc_left, NEXT_ROW), 0.expr(), ); cb.require_equal( "rwc_inc_left[2] == rwc_inc_left[0] - rwc_diff, or 0 at the end", new_value, update_or_finish, ); Figure C.6: src/copy_circuit/copy_gadgets.rs#524–537 ● The IsZeroGadget assign function does not assign the witness value. pub fn assign<F: FieldExt, T: Copy + TryInto<F>>( &self, region: &mut Region<'_, F>, offset: usize, value: T, ) where <T as TryInto<F>>::Error: Debug, { } self.inverse_or_zero.assign( region, offset, value.try_into().unwrap().invert().unwrap_or(F::zero()), ); // TODO: get rid of assign method in favor of it. pub fn assign_value_and_inverse<F: FieldExt, T: Copy + TryInto<F>>( &self, region: &mut Region<'_, F>, offset: usize, value: T, ) where <T as TryInto<F>>::Error: Debug, { } self.value.assign(region, offset, value); self.assign(region, offset, value); Figure C.7: mpt-circuit/src/gadgets/is_zero.rs#20–46 ● The OneHot assign function should ensure that no more than one item is assigned. pub fn assign<F: FieldExt>(&self, region: &mut Region<'_, F>, offset: usize, value: T) { if let Some(c) = self.columns.get(&value) { c.assign(region, offset, true) } } Figure C.8: mpt-circuit/src/gadgets/one_hot.rs#31– ● There is a redundant condition in the configure_empty_account function. The function could just match SegmentType::Start. SegmentType::Start | SegmentType::AccountTrie => { let is_final_segment = config.segment_type.next_matches(&[SegmentType::Start]); cb.condition(is_final_segment, |cb| { Figure C.9: mpt-circuit/src/gadgets/mpt_update.rs#1878–1880 ● There is a redundant .and() call in the MptUpdateConfig configure function. The cb.every_row_selector() function returns the ﬁrst condition in the condition stack, so this condition is equivalent to is_start. cb.condition(is_start.clone().and(cb.every_row_selector()), |cb| { Figure C.10: mpt-circuit/src/gadgets/mpt_update.rs#124 ● The rw_counter constraints could be consolidated. Constraining rw_counter requires constraining the tag to Memory or TxLog and constraining the Padding to 
0. These constraints are implemented in diﬀerent locations in the codebase, making the code harder to understand. let is_rw_type = meta.query_advice(is_memory, CURRENT) + is_tx_log.expr(); Figure C.11: src/copy_circuit.rs#340–341 // Decrement rwc_inc_left for the next row, when an RW operation happens. let rwc_diff = is_rw_type.expr() * is_word_end.expr(); Figure C.12: copy_circuit/copy_gadgets.rs#L525 ● The following constraint label is imprecise. The label should read assign real_bytes_left {}. // real_bytes_left region.assign_advice( || format!("assign bytes_left {}", *offset), self.copy_table.real_bytes_left, *offset, || Value::known(F::zero()), )?; Figure C.13: src/copy_circuit.rs#776– D. Automated Analysis Tool Conﬁguration As part of this assessment, we used the tools described below to perform automated testing of the codebase. D.1. Semgrep We used the static analyzer Semgrep to search for risky API patterns and weaknesses in the source code repository. For this purpose, we wrote rules speciﬁcally targeting the ConstraintBuilder APIs and the ExecutionGadget trait. semgrep --metrics=off --sarif --config=custom_rule_path.yml Figure D.1: The invocation command used to run Semgrep for each custom rule Duplicate Constraints The presence of duplicate constraints, with potentially diﬀerent labels, indicates either a redundant constraint that can be removed or an intended constraint that was not correctly updated. This pattern was written to ﬁnd variants of ﬁnding TOB-SCROLL2-6, but no other instances of it were found in the codebase. However, this pattern should be added as a CI/CD Semgrep rule to prevent a similar issue from recurring in the codebase. rules: - id: repeated-constraints message: "Found redundant or incorrectly updated constraint" languages: [rust] severity: ERROR patterns: - pattern: | cb.$FUNC($LABEL1, $LEFT, $RIGHT); ... cb.$FUNC($LABEL2, $LEFT, $RIGHT); Figure D.2: The repeated-constraints Semgrep rule Constraints with Repeated Labels The presence of a repeated label could indicate a copy-pasted label that should be updated. rules: - id: constraints-with-repeated-labels message: "Found constraints with the same label" languages: [rust] severity: ERROR patterns: - pattern: | cb.$FUNC("$LABEL", ...); ... cb.$FUNC("$LABEL", ...); Figure D.3: The repeated-labels Semgrep rule D.2. cargo llvm-cov cargo-llvm-cov generates Rust code coverage reports. We used the cargo llvm-cov --open command in the MPT codebase to generate the coverage report presented in the Automated Testing section. D.3. cargo edit cargo-edit allows developers to quickly ﬁnd outdated Rust crates. The tool can be installed with the cargo install cargo-edit command and the cargo upgrade --incompatible --dry-run command can be used to ﬁnd outdated crates. D.4. Clippy The Rust linter Clippy can be installed using rustup by running the command rustup component add clippy. Invoking cargo clippy --workspace -- -W clippy::pedantic in the root directory of the project runs the tool with the pedantic ruleset. cargo clippy --workspace -- -W clippy::pedantic Figure D.4: The invocation command used to run Clippy in the codebase E. Fix Review Results When undertaking a ﬁx review, reviews the ﬁxes implemented for issues identiﬁed in the original report. This work involves a review of speciﬁc areas of the source code and system conﬁguration, not comprehensive analysis of the system. From September 25 to September 29, 2023, reviewed the ﬁxes and mitigations implemented by the Scroll team for the issues identiﬁed in this report. We reviewed each ﬁx to determine its eﬀectiveness in resolving the associated issue. Scroll provided PRs with ﬁxes for all high-severity ﬁndings and for the informational-severity ﬁnding TOB-SCROLL2-7. Scroll did not submit ﬁxes for the remaining informational-severity ﬁndings. In summary, of the 10 issues described in this report, Scroll has resolved three issues and has partially resolved one issue. Scroll indicated that it does not intend to ﬁx ﬁnding TOB-SCROLL2-2, so its status is unresolved. No ﬁx PRs were provided for the remaining ﬁve issues, so their ﬁx statuses are undetermined. For additional information, please see the Detailed Fix Review Results below. ID Title Status 7 8 9 The Copy circuit does not totally enforce the tag values Partially Resolved The “invalid creation” error handling circuit is unconstrained Resolved The OneHot primitive allows more than one value at once Resolved Detailed Fix Review Results TOB-SCROLL2-1: PoseidonLookup is not implemented Undetermined. No ﬁx was provided for this issue, so we do not know whether this issue has been addressed. TOB-SCROLL2-2: IsZeroGadget does not constrain the inverse witness when the value is zero Unresolved. The Scroll team has indicated that it does not intend to ﬁx this issue. TOB-SCROLL2-3: The MPT nonexistence proof gadget is missing constraints speciﬁed in the documentation Undetermined. No ﬁx was provided for this issue, so we do not know whether this issue has been addressed. TOB-SCROLL2-4: Discrepancies between the MPT circuit speciﬁcation and implementation Undetermined. No ﬁx was provided for this issue, so we do not know whether this issue has been addressed. TOB-SCROLL2-5: Redundant lookups in the Word RLC circuit Undetermined. No ﬁx was provided for this issue, so we do not know whether this issue has been addressed. TOB-SCROLL2-6: The NonceChanged conﬁguration circuit does not constrain the new value nonce value Resolved in PR #73. The two conditional constraints that referred to old_value instead of new_value have been factored out into a single unconditional constraint referring to new_value, and the ExtensionOld case has been removed entirely in favor of a blanket assertion forbidding that case of configure_nonce. TOB-SCROLL2-7: The Copy circuit does not totally enforce the tag values Partially resolved in PR #809. Several cases of the CopyDataType tag have been removed, and an assertion has been added to document that the Padding tag value is internal only. We did not fully evaluate whether this prevents tag values outside the expected range. TOB-SCROLL2-8: The “invalid creation” error handling circuit is unconstrained Resolved in PR #751. The MemoryMask gadget is used to extract the correct byte from the word at offset and to constrain it to equal 0xef. TOB-SCROLL2-9: The OneHot primitive allows more than one value at once Resolved in PR #69. Each binary column value v is constrained by enforcing 1 - v.or(!v) == 0. It is not immediately obvious that this constraint suﬃces, but it is equivalent to 𝑣(1 − 𝑣) = 0 by the following reasoning: 1 - v.or(!v) == 1 - !((!v).and(!!v) == 1 - (1 - ((!v)*(!!v))) … … == ((1-v)*(1-(1-v))) == (1-v)*v In addition, another related issue with the OneHot primitive, which was not discovered during the initial review engagement, was ﬁxed in PR #68. The related problem was a typo causing OneHot::previous to return the result of the current row rather than the previous row. Its exploit scenario would be eﬀectively the same as the one described in ﬁnding TOB-SCROLL2-9. The Scroll team ﬁxed this by replacing the value BinaryColumn::current with BinaryColumn::previous. TOB-SCROLL2-10: Intermediate columns are not explicit Undetermined. No ﬁx was provided for this issue, so we do not know whether this issue has been addressed. F. Fix Review Status Categories The following table describes the statuses used to indicate whether an issue has been suﬃciently addressed. Fix Status Status Description Undetermined The status of the issue was not determined during this engagement. Unresolved The issue persists and has not been resolved. Partially Resolved The issue persists but has been partially resolved. Resolved The issue has been suﬃciently resolved. 
