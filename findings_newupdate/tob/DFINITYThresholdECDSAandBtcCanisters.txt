1. Lack of validation of signed dealing against original dealing Severity: Medium Diﬃculty: Medium Type: Data Validation Finding ID: TOB-DFTECDSA-1 Target: ic/rs/consensus/src/ecdsa/pre_signer.rs Description The EcdsaPreSignerImpl::validate_dealing_support method does not check that the content of signed dealings matches the original dealings. A malicious receiver could exploit this lack of validation by changing the requested height (that is, the support.content.requested_height ﬁeld) or internal data (the support.content.idk_dealing.internal_dealing_raw ﬁeld) before signing the ECDSA dealing. The resulting signature would not be ﬂagged as invalid by the validate_dealing_support method but would result in an invalid aggregated signature. After all nodes sign a dealing, the EcdsaTranscriptBuilderImpl::build_transcript method checks the signed dealings’ content hashes before attempting to aggregate all the dealing support signatures to produce the ﬁnal aggregated signature. The method logs a warning when the hashes do not agree, but does not otherwise act on signed dealings with diﬀerent content. let mut content_hash = BTreeSet::new(); for share in &support_shares { content_hash.insert(ic_crypto::crypto_hash(&share.content)); } if content_hash.len() > 1 { warn!( self.log, "Unexpected multi share content: support_shares = {}, content_hash = {}", support_shares.len(), content_hash.len() ); self.metrics.payload_errors_inc("invalid_content_hash"); } if let Some(multi_sig) = self.crypto_aggregate_dealing_support( transcript_state.transcript_params, &support_shares, ) { } transcript_state.add_completed_dealing(signed_dealing.content, multi_sig); Figure 1.1: ic/rs/consensus/src/ecdsa/pre_signer.rs:1015-1034 The dealing content is added to the set of completed dealings along with the aggregated signature. When the node attempts to create a new transcript from the dealing, the aggregated signature is checked by IDkgProtocol::create_transcript. If a malicious receiver changes the content of a dealing before signing it, the resulting invalid aggregated signature would be rejected by this method. In such a case, the EcdsaTranscriptBuilderImpl methods build_transcript and get_completed_transcript would return None for the corresponding transcript ID. That is, neither the transcript nor the corresponding quadruple would be completed. Additionally, since signing requests are deterministically matched against quadruples, including quadruples that are not yet available, this issue could allow a single node to block the service of individual signing requests. pub(crate) fn get_signing_requests<'a>( ecdsa_payload: &ecdsa::EcdsaPayload, sign_with_ecdsa_contexts: &'a BTreeMap<CallbackId, SignWithEcdsaContext>, ) -> BTreeMap<ecdsa::RequestId, &'a SignWithEcdsaContext> { let known_random_ids: BTreeSet<[u8; 32]> = ecdsa_payload .iter_request_ids() .map(|id| id.pseudo_random_id) .collect::<BTreeSet<_>>(); let mut unassigned_quadruple_ids = ecdsa_payload.unassigned_quadruple_ids().collect::<Vec<_>>(); // sort in reverse order (bigger to smaller). unassigned_quadruple_ids.sort_by(|a, b| b.cmp(a)); let mut new_requests = BTreeMap::new(); // The following iteration goes through contexts in the order // of their keys, which is the callback_id. Therefore we are // traversing the requests in the order they were created. for context in sign_with_ecdsa_contexts.values() { if known_random_ids.contains(context.pseudo_random_id.as_slice()) { continue; }; if let Some(quadruple_id) = unassigned_quadruple_ids.pop() { let request_id = ecdsa::RequestId { quadruple_id, pseudo_random_id: context.pseudo_random_id, }; new_requests.insert(request_id, context); } else { break; } } new_requests } Figure 1.2: ic/rs/consensus/src/ecdsa/payload_builder.rs:752-782 Exploit Scenario A malicious node wants to prevent the signing request SRi from completing. Assume that the corresponding quadruple, Qi, is not yet available. The node waits until it receives a dealing corresponding to quadruple Qi. It generates a support message for the dealing, but before signing the dealing, the malicious node changes the dealing.idk_dealing.internal_dealing_raw ﬁeld. The signature is valid for the updated dealing but not for the original dealing. The malicious dealing support is gossiped to the other nodes in the network. Since the signature on the dealing support is correct, all nodes move the dealing support to the validated pool. However, when the dealing support signatures are aggregated by the other nodes, the aggregated signature is rejected as invalid, and no new transcript is created for the dealing. This means that the quadruple Qi never completes. Since the matching of signing requests to quadruples is deterministic, SRi is matched with Qi every time a new ECDSA payload is created. Thus, SRi is never serviced. Recommendations Short term, add validation code in EcdsaPreSignerImpl::validate_dealing_support to verify that a signed dealing’s content hash is identical to the hash of the original dealing. Long term, consider whether the BLS multisignature aggregation APIs need to be better documented to ensure that API consumers verify that all individual signatures are over the same message. 
2. The ECDSA payload is not updated if a quadruple fails to complete Severity: Low Diﬃculty: Medium Type: Data Validation Finding ID: TOB-DFTECDSA-2 Target: Consensus integration Description If a transcript fails to complete (as described in TOB-DFTECDSA-1), the corresponding quadruple, Qi, will also fail to complete. This means that the quadruple ID for Qi will remain in the quadruples_in_creation set until the key is reshared and the set is purged. (Currently, the key is reshared if a node joins or leaves the subnet, which is an uncommon occurrence.) Moreover, if a transcript and the corresponding Qi fail to complete, so will the corresponding signing request, SRi, as it is matched deterministically with Qi. let ecdsa_payload = ecdsa::EcdsaPayload { signature_agreements: ecdsa_payload.signature_agreements.clone(), ongoing_signatures: ecdsa_payload.ongoing_signatures.clone(), available_quadruples: if is_new_key_transcript { BTreeMap::new() } else { ecdsa_payload.available_quadruples.clone() }, quadruples_in_creation: if is_new_key_transcript { BTreeMap::new() } else { ecdsa_payload.quadruples_in_creation.clone() }, uid_generator: ecdsa_payload.uid_generator.clone(), idkg_transcripts: BTreeMap::new(), ongoing_xnet_reshares: if is_new_key_transcript { // This will clear the current ongoing reshares, and // the execution requests will be restarted with the // new key and different transcript IDs. BTreeMap::new() } else { ecdsa_payload.ongoing_xnet_reshares.clone() }, xnet_reshare_agreements: ecdsa_payload.xnet_reshare_agreements.clone(), }; Figure 2.1: The quadruples_in_creation set will be purged only when the key is reshared. The canister will never be notiﬁed that the signing request failed and will be left waiting indeﬁnitely for the corresponding reply from the distributed signing service. Recommendations Short term, revise the code so that if a transcript (permanently) fails to complete, the quadruple ID and corresponding transcripts are dropped from the ECDSA payload. To ensure that a malicious node cannot inﬂuence how signing requests are matched with quadruples, revise the code so that it notiﬁes the canister that the signing request failed. 
3. Malicious canisters can exhaust the number of available quadruples Severity: Undetermined Diﬃculty: Low Type: Denial of Service Finding ID: TOB-DFTECDSA-3 Target: Consensus integration Description By requesting a large number of signatures, a canister (or set of canisters) could exhaust the number of available quadruples, preventing other signature requests from completing in a timely manner. The ECDSA payload builder defaults to creating one extra quadruple in create_data_payload if there is no ECDSA conﬁguration for the subnet in the registry. let ecdsa_config = registry_client .get_ecdsa_config(subnet_id, summary_registry_version)? .unwrap_or(EcdsaConfig { quadruples_to_create_in_advance: 1, // default value ..EcdsaConfig::default() }); Figure 3.1: ic/rs/consensus/src/ecdsa/payload_builder.rs:400-405 Signing requests are serviced by the system in the order in which they are made (as determined by their CallbackID values). If a canister (or set of canisters) makes a large number of signing requests, the system would be overwhelmed and would take a long time to recover. This issue is partly mitigated by the fee that is charged for signing requests. However, we believe that the ﬁnancial ramiﬁcations of this problem could outweigh the fees paid by attackers. For example, the type of denial-of-service attack described in this ﬁnding could be devastating for a DeFi application that is sensitive to small price ﬂuctuations in the Bitcoin market. Since the ECDSA threshold signature service is not yet deployed on the Internet Computer, it is unclear how the service will be used in practice, making the severity of this issue diﬃcult to determine. Therefore, the severity of this issue is marked as undetermined. Exploit Scenario A malicious canister learns that another canister on the Internet Computer is about to request a time-sensitive signature on a message. The malicious canister immediately requests a large number of signatures from the signing service, exhausting the number of available quadruples and preventing the original signature from completing in a timely manner. Recommendations One possible mitigation is to increase the number of quadruples that the system creates in advance, making it more expensive for an attacker to carry out a denial-of-service attack on the ECDSA signing service. Another possibility is to run multiple signing services on multiple subnets of the Internet Computer. This would have the added beneﬁt of protecting the system from resource exhaustion related to cross-network bandwidth limitations. However, both of these solutions scale only linearly with the number of added quadruples/subnets. Another potential mitigation is to introduce a dynamic fee or stake based on the number of outstanding signing requests. In the case of a dynamic fee, the canister would pay a set number of tokens proportional to the number of outstanding signing requests whenever it requests a new signature from the service. In the case of a stake-based system, the canister would stake funds proportional to the number of outstanding requests but would recover those funds once the signing request completed. As any signing service that depends on consensus will have limited throughput compared to a centralized service, this issue is diﬃcult to mitigate completely. However, it is important that canister developers are aware of the limits of the implementation. Therefore, regardless of the mitigations imposed, we recommend that the DFINITY team clearly document the limits of the current implementation. 
1. Lack of validation of signed dealing against original dealing Severity: Medium Diﬃculty: Medium Type: Data Validation Finding ID: TOB-DFTECDSA-1 Target: ic/rs/consensus/src/ecdsa/pre_signer.rs Description The EcdsaPreSignerImpl::validate_dealing_support method does not check that the content of signed dealings matches the original dealings. A malicious receiver could exploit this lack of validation by changing the requested height (that is, the support.content.requested_height ﬁeld) or internal data (the support.content.idk_dealing.internal_dealing_raw ﬁeld) before signing the ECDSA dealing. The resulting signature would not be ﬂagged as invalid by the validate_dealing_support method but would result in an invalid aggregated signature. After all nodes sign a dealing, the EcdsaTranscriptBuilderImpl::build_transcript method checks the signed dealings’ content hashes before attempting to aggregate all the dealing support signatures to produce the ﬁnal aggregated signature. The method logs a warning when the hashes do not agree, but does not otherwise act on signed dealings with diﬀerent content. let mut content_hash = BTreeSet::new(); for share in &support_shares { content_hash.insert(ic_crypto::crypto_hash(&share.content)); } if content_hash.len() > 1 { warn!( self.log, "Unexpected multi share content: support_shares = {}, content_hash = {}", support_shares.len(), content_hash.len() ); self.metrics.payload_errors_inc("invalid_content_hash"); } if let Some(multi_sig) = self.crypto_aggregate_dealing_support( transcript_state.transcript_params, &support_shares, ) { } transcript_state.add_completed_dealing(signed_dealing.content, multi_sig); Figure 1.1: ic/rs/consensus/src/ecdsa/pre_signer.rs:1015-1034 The dealing content is added to the set of completed dealings along with the aggregated signature. When the node attempts to create a new transcript from the dealing, the aggregated signature is checked by IDkgProtocol::create_transcript. If a malicious receiver changes the content of a dealing before signing it, the resulting invalid aggregated signature would be rejected by this method. In such a case, the EcdsaTranscriptBuilderImpl methods build_transcript and get_completed_transcript would return None for the corresponding transcript ID. That is, neither the transcript nor the corresponding quadruple would be completed. Additionally, since signing requests are deterministically matched against quadruples, including quadruples that are not yet available, this issue could allow a single node to block the service of individual signing requests. pub(crate) fn get_signing_requests<'a>( ecdsa_payload: &ecdsa::EcdsaPayload, sign_with_ecdsa_contexts: &'a BTreeMap<CallbackId, SignWithEcdsaContext>, ) -> BTreeMap<ecdsa::RequestId, &'a SignWithEcdsaContext> { let known_random_ids: BTreeSet<[u8; 32]> = ecdsa_payload .iter_request_ids() .map(|id| id.pseudo_random_id) .collect::<BTreeSet<_>>(); let mut unassigned_quadruple_ids = ecdsa_payload.unassigned_quadruple_ids().collect::<Vec<_>>(); // sort in reverse order (bigger to smaller). unassigned_quadruple_ids.sort_by(|a, b| b.cmp(a)); let mut new_requests = BTreeMap::new(); // The following iteration goes through contexts in the order // of their keys, which is the callback_id. Therefore we are // traversing the requests in the order they were created. for context in sign_with_ecdsa_contexts.values() { if known_random_ids.contains(context.pseudo_random_id.as_slice()) { continue; }; if let Some(quadruple_id) = unassigned_quadruple_ids.pop() { let request_id = ecdsa::RequestId { quadruple_id, pseudo_random_id: context.pseudo_random_id, }; new_requests.insert(request_id, context); } else { break; } } new_requests } Figure 1.2: ic/rs/consensus/src/ecdsa/payload_builder.rs:752-782 Exploit Scenario A malicious node wants to prevent the signing request SRi from completing. Assume that the corresponding quadruple, Qi, is not yet available. The node waits until it receives a dealing corresponding to quadruple Qi. It generates a support message for the dealing, but before signing the dealing, the malicious node changes the dealing.idk_dealing.internal_dealing_raw ﬁeld. The signature is valid for the updated dealing but not for the original dealing. The malicious dealing support is gossiped to the other nodes in the network. Since the signature on the dealing support is correct, all nodes move the dealing support to the validated pool. However, when the dealing support signatures are aggregated by the other nodes, the aggregated signature is rejected as invalid, and no new transcript is created for the dealing. This means that the quadruple Qi never completes. Since the matching of signing requests to quadruples is deterministic, SRi is matched with Qi every time a new ECDSA payload is created. Thus, SRi is never serviced. Recommendations Short term, add validation code in EcdsaPreSignerImpl::validate_dealing_support to verify that a signed dealing’s content hash is identical to the hash of the original dealing. Long term, consider whether the BLS multisignature aggregation APIs need to be better documented to ensure that API consumers verify that all individual signatures are over the same message. 
2. The ECDSA payload is not updated if a quadruple fails to complete Severity: Low Diﬃculty: Medium Type: Data Validation Finding ID: TOB-DFTECDSA-2 Target: Consensus integration Description If a transcript fails to complete (as described in TOB-DFTECDSA-1), the corresponding quadruple, Qi, will also fail to complete. This means that the quadruple ID for Qi will remain in the quadruples_in_creation set until the key is reshared and the set is purged. (Currently, the key is reshared if a node joins or leaves the subnet, which is an uncommon occurrence.) Moreover, if a transcript and the corresponding Qi fail to complete, so will the corresponding signing request, SRi, as it is matched deterministically with Qi. let ecdsa_payload = ecdsa::EcdsaPayload { signature_agreements: ecdsa_payload.signature_agreements.clone(), ongoing_signatures: ecdsa_payload.ongoing_signatures.clone(), available_quadruples: if is_new_key_transcript { BTreeMap::new() } else { ecdsa_payload.available_quadruples.clone() }, quadruples_in_creation: if is_new_key_transcript { BTreeMap::new() } else { ecdsa_payload.quadruples_in_creation.clone() }, uid_generator: ecdsa_payload.uid_generator.clone(), idkg_transcripts: BTreeMap::new(), ongoing_xnet_reshares: if is_new_key_transcript { // This will clear the current ongoing reshares, and // the execution requests will be restarted with the // new key and different transcript IDs. BTreeMap::new() } else { ecdsa_payload.ongoing_xnet_reshares.clone() }, xnet_reshare_agreements: ecdsa_payload.xnet_reshare_agreements.clone(), }; Figure 2.1: The quadruples_in_creation set will be purged only when the key is reshared. The canister will never be notiﬁed that the signing request failed and will be left waiting indeﬁnitely for the corresponding reply from the distributed signing service. Recommendations Short term, revise the code so that if a transcript (permanently) fails to complete, the quadruple ID and corresponding transcripts are dropped from the ECDSA payload. To ensure that a malicious node cannot inﬂuence how signing requests are matched with quadruples, revise the code so that it notiﬁes the canister that the signing request failed. 
3. Malicious canisters can exhaust the number of available quadruples Severity: Undetermined Diﬃculty: Low Type: Denial of Service Finding ID: TOB-DFTECDSA-3 Target: Consensus integration Description By requesting a large number of signatures, a canister (or set of canisters) could exhaust the number of available quadruples, preventing other signature requests from completing in a timely manner. The ECDSA payload builder defaults to creating one extra quadruple in create_data_payload if there is no ECDSA conﬁguration for the subnet in the registry. let ecdsa_config = registry_client .get_ecdsa_config(subnet_id, summary_registry_version)? .unwrap_or(EcdsaConfig { quadruples_to_create_in_advance: 1, // default value ..EcdsaConfig::default() }); Figure 3.1: ic/rs/consensus/src/ecdsa/payload_builder.rs:400-405 Signing requests are serviced by the system in the order in which they are made (as determined by their CallbackID values). If a canister (or set of canisters) makes a large number of signing requests, the system would be overwhelmed and would take a long time to recover. This issue is partly mitigated by the fee that is charged for signing requests. However, we believe that the ﬁnancial ramiﬁcations of this problem could outweigh the fees paid by attackers. For example, the type of denial-of-service attack described in this ﬁnding could be devastating for a DeFi application that is sensitive to small price ﬂuctuations in the Bitcoin market. Since the ECDSA threshold signature service is not yet deployed on the Internet Computer, it is unclear how the service will be used in practice, making the severity of this issue diﬃcult to determine. Therefore, the severity of this issue is marked as undetermined. Exploit Scenario A malicious canister learns that another canister on the Internet Computer is about to request a time-sensitive signature on a message. The malicious canister immediately requests a large number of signatures from the signing service, exhausting the number of available quadruples and preventing the original signature from completing in a timely manner. Recommendations One possible mitigation is to increase the number of quadruples that the system creates in advance, making it more expensive for an attacker to carry out a denial-of-service attack on the ECDSA signing service. Another possibility is to run multiple signing services on multiple subnets of the Internet Computer. This would have the added beneﬁt of protecting the system from resource exhaustion related to cross-network bandwidth limitations. However, both of these solutions scale only linearly with the number of added quadruples/subnets. Another potential mitigation is to introduce a dynamic fee or stake based on the number of outstanding signing requests. In the case of a dynamic fee, the canister would pay a set number of tokens proportional to the number of outstanding signing requests whenever it requests a new signature from the service. In the case of a stake-based system, the canister would stake funds proportional to the number of outstanding requests but would recover those funds once the signing request completed. As any signing service that depends on consensus will have limited throughput compared to a centralized service, this issue is diﬃcult to mitigate completely. However, it is important that canister developers are aware of the limits of the implementation. Therefore, regardless of the mitigations imposed, we recommend that the DFINITY team clearly document the limits of the current implementation. 
4. Aggregated signatures are dropped if their request IDs are not recognized Severity: Informational Diﬃculty: N/A Type: Denial of Service Finding ID: TOB-DFTECDSA-4 Target: ic/rs/consensus/src/ecdsa/payload_builder.rs Description The update_signature_agreements function populates the set of completed signatures in the ECDSA payload. The function aggregates the completed signatures from the ECDSA pool by calling EcdsaSignatureBuilderImpl::get_completed_signatures. However, if a signature’s associated signing request ID is not in the set of ongoing signatures, update_signature_agreements simply drops the signature. for (request_id, signature) in builder.get_completed_signatures( chain, ecdsa_pool.deref() ) { if payload.ongoing_signatures.remove(&request_id).is_none() { warn!( log, "ECDSA signing request {:?} is not found in payload but we have a signature for it", request_id ); } else { payload .signature_agreements .insert(request_id, ecdsa::CompletedSignature::Unreported(signature)); } } Figure 4.1: ic/rs/consensus/src/ecdsa/payload_builder.rs:817-830 Barring an implementation error, this should not happen under normal circumstances. Recommendations Short term, consider adding the signature to the set of completed signatures on the next ECDSA payload. This will ensure that all outstanding signing requests are completed. A. Vulnerability Categories The following tables describe the vulnerability categories, severity levels, and diﬃculty levels used in this document. Vulnerability Categories Category Description Access Controls Insuﬃcient authorization or assessment of rights Auditing and Logging Insuﬃcient auditing of actions or logging of problems Authentication Improper identiﬁcation of users Conﬁguration Misconﬁgured servers, devices, or software components Cryptography A breach of system conﬁdentiality or integrity Data Exposure Exposure of sensitive information Data Validation Improper reliance on the structure or values of data Denial of Service A system failure with an availability impact Error Reporting Insecure or insuﬃcient reporting of error conditions Patching Use of an outdated software package or library Session Management Improper identiﬁcation of authenticated users Testing Timing Insuﬃcient test methodology or test coverage Race conditions or other order-of-operations ﬂaws Undeﬁned Behavior Undeﬁned behavior triggered within the system Severity Levels Severity Description Informational The issue does not pose an immediate risk but is relevant to security best practices. Undetermined The extent of the risk was not determined during this engagement. Low The risk is small or is not one the client has indicated is important. Medium High User information is at risk; exploitation could pose reputational, legal, or moderate ﬁnancial risks. The ﬂaw could aﬀect numerous users and have serious reputational, legal, or ﬁnancial implications. Diﬃculty Levels Diﬃculty Description Undetermined The diﬃculty of exploitation was not determined during this engagement. Low Medium High The ﬂaw is well known; public tools for its exploitation exist or can be scripted. An attacker must write an exploit or will need in-depth knowledge of the system. An attacker must have privileged access to the system, may need to know complex technical details, or must discover other weaknesses to exploit this issue. B. Code Maturity Categories The following tables describe the code maturity categories and rating criteria used in this document. Code Maturity Categories Category Description Arithmetic The proper use of mathematical operations and semantics Auditing The use of event auditing and logging to support monitoring Authentication / Access Controls The use of robust access controls to handle identiﬁcation and authorization and to ensure safe interactions with the system Complexity Management The presence of clear structures designed to manage system complexity, including the separation of system logic into clearly deﬁned functions Conﬁguration The conﬁguration of system components in accordance with best practices Cryptography and Key Management The safe use of cryptographic primitives and functions, along with the presence of robust mechanisms for key generation and distribution Data Handling The safe handling of user inputs and data processed by the system Documentation The presence of comprehensive and readable codebase documentation Maintenance The timely maintenance of system components to mitigate risk Memory Safety and Error Handling The presence of memory safety and robust error-handling mechanisms Testing and Veriﬁcation The presence of robust testing procedures (e.g., unit tests, integration tests, and veriﬁcation methods) and suﬃcient test coverage Rating Criteria Rating Strong Description No issues were found, and the system exceeds industry standards. Satisfactory Minor issues were found, but the system is compliant with best practices. Moderate Some issues that may aﬀect system safety were found. Weak Many issues that aﬀect system safety were found. Missing A required component is missing, signiﬁcantly aﬀecting system safety. Not Applicable The category is not applicable to this review. Not Considered The category was not considered in this review. Further Investigation Required Further investigation is required to reach a meaningful conclusion. C. Automated Testing This section describes the setup for the various automated analysis tools used during this audit. Clippy The Rust linter Clippy can be installed using rustup by running the command rustup component add clippy. Invoking cargo clippy in the root directory of the project runs the tool. We ran Clippy on the consensus crate. This run did not generate any ﬁndings or code quality recommendations. Semgrep Semgrep can be installed using pip by running python3 -m pip install semgrep. To run Semgrep on a codebase, simply run semgrep --config “<CONFIGURATION>” in the root directory of the project. Here, <CONFIGURATION> can be either a single rule, a directory of rules, or the name of a rule set hosted on the Semgrep registry. We ran a number of custom Semgrep rules on the consensus crate. Since support for Rust is still experimental, we focused on locating the following small set of issues: ● The use of panicking functions like assert, unreachable, unwrap, and expect in production code (that is, outside unit tests) rules: - id: panic-in-function-returning-result patterns: - pattern-inside: | fn $FUNC(...) -> Result<$T> { ... } - pattern-either: - pattern: $EXPR.unwrap() - pattern: $EXPR.expect(...) message: | `expect` or `unwrap` called in function returning a `Result`. languages: [rust] severity: WARNING Figure C.1: panic-in-function-returning-result.yaml rules: - id: unwrap-outside-test patterns: - pattern: $RESULT.unwrap() - pattern-not-inside: " #[test] fn $TEST() { ... $RESULT.unwrap() ... } " message: Calling `unwrap` outside unit test languages: [rust] severity: WARNING Figure C.2: unwrap-outside-test.yaml rules: - id: expect-outside-test patterns: - pattern: $RESULT.expect(...) - pattern-not-inside: " #[test] fn $TEST() { ... $RESULT.expect(...) ... } " message: Calling `expect` outside unit test languages: [rust] severity: WARNING Figure C.3: expect-outside-test.yaml ● The use of the as keyword, which may silently truncate integers during casting (for example, casting data.len() to a u32, may truncate the input length on 64-bit systems) rules: - id: length-to-smaller-integer pattern-either: - pattern: $VAR.len() as u32 - pattern: $VAR.len() as i32 - pattern: $VAR.len() as u16 - pattern: $VAR.len() as i16 - pattern: $VAR.len() as u8 - pattern: $VAR.len() as i8 message: | Casting `usize` length to smaller integer size silently drops high bits on 64-bit platforms languages: [rust] severity: WARNING Figure C.4: length-to-smaller-integer.yaml ● Unexpected comparisons before subtractions (for example, ensuring that x < y before subtracting y from x), which may indicate errors in the code rules: - id: switched-underflow-guard pattern-either: - patterns: - pattern-inside: | if $Y > $X { ... } - pattern-not-inside: | if $Y > $X { } else { ... } - pattern: $X - $Y - patterns: - pattern-inside: | if $Y >= $X { ... } - pattern-not-inside: | if $Y >= $X { } else { ... } - pattern: $X - $Y - patterns: - pattern-inside: | if $Y < $X { ... } - pattern-not-inside: | if $Y < $X { } else { ... } - pattern: $Y - $X - patterns: - pattern-inside: | if $Y <= $X { ... } - pattern-not-inside: | if $Y <= $X { } else { ... } - pattern: $X - $Y - patterns: - pattern-inside: | if $Y > $X { } else { ... } - pattern: $Y - $X - patterns: - pattern-inside: | if $Y >= $X { } else { ... } - pattern: $Y - $X - patterns: - pattern-inside: | if $Y < $X { } else { ... } - pattern: $X - $Y - patterns: - pattern-inside: | if $Y <= $X { } else { ... } - pattern: $X - $Y - patterns: - pattern: | if $X < $Y { } ... message: Potentially switched comparison in if-statement condition languages: [rust] severity: WARNING Figure C.5: switched-underflow-guard.yaml This run did not result in any issues or code quality recommendations. Tarpaulin Tarpaulin can be installed using Cargo by running cargo install cargo-tarpaulin. To execute Tarpaulin on Linux, simply run the command cargo tarpaulin in the crate root directory. Note that we failed to obtain unit test coverage data using Tarpaulin because of a compilation issue. We also tried to use llvm-cov and kcov to generate coverage data but were unsuccessful. D. Code Quality Recommendations The following is a list of ﬁndings that were not identiﬁed as immediate security issues but may warrant further investigation. ECDSA Consensus Integration ● The update_quadruples_in_creation function (which advances quadruple creation) is called after update_ongoing_signatures (which matches new signing requests against available quadruples) when a new ECDSA data payload is created in create_data_payload (in src/ecdsa/payload_builder.rs). This means that new quadruples will not be available until the next block. Reordering the calls would allow new signing requests to complete one block earlier. update_ongoing_signatures( new_signing_requests, current_key_transcript, &mut ecdsa_payload, log.clone(), )?; // ... <redacted> let mut new_transcripts = update_quadruples_in_creation( current_key_transcript, &mut ecdsa_payload, &mut transcript_cache, height, &log, )?; Figure D.1: New quadruples are not completed when signatures are matched against available quadruples in create_data_payload. Bitcoin Network Integration ● The code occasionally uses Rust's unwrap function instead of expect. While these uses of unwrap should not result in a crash, we recommend replacing them with expect, which would help developers more quickly troubleshoot the issue in the unlikely event of a crash. ● Some features of the Bitcoin canister are not implemented. Most importantly, the canister does not communicate to the adapter that a transaction must be posted to the Bitcoin network. ● Because the replica running the Bitcoin canister and the one running the adapter are two diﬀerent versions of software, they could grow out of sync on a node. Some safety measures should be put in place to prevent the use of the Bitcoin feature when this occurs. 
