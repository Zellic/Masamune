1. Use of fmt.Sprintf to build host:port string Severity: Informational Diﬃculty: Medium Type: Data Validation Finding ID: TOB-KEDA-1 Targets: ● pkg/scalers/cassandra_scaler.go ● pkg/scalers/mongo_scaler.go ● pkg/scalers/mssql_scaler.go ● pkg/scalers/mysql_scaler.go ● pkg/scalers/predictkube_scaler.go ● pkg/scalers/redis_scaler.go Description Several scalers use a construct like fmt.Sprintf("%s:%s", host, port) to create a host:port address string from a user-supplied host and port. This approach is problematic when the host is a literal IPv6 address, which should be enclosed in square brackets when the address is part of a resource identiﬁer. An address created using simple string concatenation, such as with fmt.Sprintf , may fail to parse when given to Go standard library functions. The following source ﬁles incorrectly use fmt.Sprintf to create an address: ● pkg/scalers/cassandra_scaler.go:115 ● pkg/scalers/mongo_scaler.go:191 ● pkg/scalers/mssql_scaler.go:220 ● pkg/scalers/mysql_scaler.go:149 ● pkg/scalers/predictkube_scaler.go:128 ● pkg/scalers/redis_scaler.go:296 ● pkg/scalers/redis_scaler.go:364 Recommendations Short term, use net.JoinHostPort instead of fmt.Sprintf to construct network addresses. The documentation for the net package states the following: JoinHostPort combines host and port into a network address of the form host:port . If host contains a colon, as found in literal IPv6 addresses, then JoinHostPort returns [host]:port . Long term, use Semgrep and the sprintf-host-port rule of semgrep-go to detect future instances of this issue. 2. MongoDB scaler does not encode username and password in connection string Severity: Low Diﬃculty: Low Type: Data Validation Finding ID: TOB-KEDA-2 Target: pkg/scalers/mongo_scaler.go Description The MongoDB scaler creates a connection string URI by concatenating the conﬁgured host, port, username, and password: addr := fmt.Sprintf( "%s:%s" , meta.host, meta.port) auth := fmt.Sprintf( "%s:%s" , meta.username, meta.password) connStr = "mongodb://" + auth + "@" + addr + "/" + meta.dbName Figure 2.1: pkg/scalers/mongo_scaler.go#L191-L193 Per MongoDB documentation, if either the username or password contains a character in the set :/?#[]@ , it must be percent-encoded . However, KEDA does not do this. As a result, the constructed connection string could fail to parse. Exploit Scenario A user conﬁgures the MongoDB scaler with a password containing an ‘ @ ’ character, and the MongoDB scaler does not encode the password in the connection string. As a result, when the client object is initialized, the URL fails to parse, an error is thrown, and the scaler does not function. Recommendations Short term, percent-encode the user-supplied username and password before constructing the connection string. Long term, use the custom Semgrep rule provided in Appendix C to detect future instances of this issue. 3. Prometheus metrics server does not support TLS Severity: Low Diﬃculty: Low Type: Cryptography Finding ID: TOB-KEDA-3 Target: pkg/prommetrics/adapter_prommetrics.go Description The KEDA Metrics Adapter exposes Prometheus metrics on an HTTP server listening on port 9022. Though Prometheus supports scraping metrics over TLS-enabled connections, KEDA does not oﬀer TLS for this server. The function responsible for starting the HTTP server, prommetrics.NewServer , does so using the http.ListenAndServe function, which does not enable TLS. func (metricsServer PrometheusMetricServer) NewServer(address string , pattern string ) { http.HandleFunc( "/healthz" , func (w http.ResponseWriter, _ *http.Request) { w.WriteHeader(http.StatusOK) _, err := w.Write([] byte ( "OK" )) if err != nil { log.Fatalf( "Unable to write to serve custom metrics: %v" , err) } }) log.Printf( "Starting metrics server at %v" , address) http.Handle(pattern, promhttp.HandlerFor(registry, promhttp.HandlerOpts{})) // initialize the total error metric _, errscaler := scalerErrorsTotal.GetMetricWith(prometheus.Labels{}) if errscaler != nil { log.Fatalf( "Unable to initialize total error metrics as : %v" , errscaler) } log.Fatal( http.ListenAndServe(address, nil ) ) } Figure 3.1: prommetrics.NewServer exposes Prometheus metrics without TLS ( pkg/prommetrics/adapter_prommetrics.go#L82-L99 ). Exploit Scenario A user sets up KEDA with Prometheus integration, enabling the scraping of metrics on port 9022. When Prometheus makes a connection to the server, it is unencrypted, leaving both the request and response vulnerable to interception and tampering in transit. As KEDA does not support TLS for the server, the user has no way to ensure the conﬁdentiality and integrity of these metrics. Recommendations Short term, provide a ﬂag to enable TLS for Prometheus metrics exposed by the Metrics Adapter. The usual way to enable TLS for an HTTP server is using the http.ListenAndServeTLS function. 4. Return value is dereferenced before error check Severity: Low Diﬃculty: Undetermined Type: Data Validation Finding ID: TOB-KEDA-4 Target: pkg/scalers/openstack/keystone_authentication.go , pkg/scalers/artemis_scaler.go Description After certain calls to http.NewRequestWithContext , the *Request return value is dereferenced before the error return value is checked (see the highlighted lines in ﬁgures 4.1 and 4.2). checkTokenRequest, err := http.NewRequestWithContext(ctx, "HEAD" , tokenURL.String(), nil ) checkTokenRequest.Header.Set( "X-Subject-Token" , token) checkTokenRequest.Header.Set( "X-Auth-Token" , token) if err != nil { return false , err } Figure 4.1: pkg/scalers/openstack/keystone_authentication.go#L118-L124 req, err := http.NewRequestWithContext(ctx, "GET" , url, nil ) req.SetBasicAuth(s.metadata.username, s.metadata.password) req.Header.Set( "Origin" , s.metadata.corsHeader) if err != nil { return - 1 , err } Figure 4.2: pkg/scalers/artemis_scaler.go#L241-L248 If an error occurred in the call to NewRequestWithContext , this behavior could result in a panic due to a nil pointer dereference. Exploit Scenario One of the calls to http.NewRequestWithContext shown in ﬁgures 4.1 and 4.2 returns an error and a nil *Request pointer. The subsequent code dereferences the nil pointer, resulting in a panic, crash, and DoS condition for the aﬀected KEDA scaler. Recommendations Short term, check the error return value before accessing the returned *Request (e.g., by calling methods on it). Long term, use CodeQL and its go/missing-error-check query to detect future instances of this issue. 5. Unescaped components in PostgreSQL connection string Severity: Low Diﬃculty: Low Type: Data Validation Finding ID: TOB-KEDA-5 Target: pkg/scalers/postgresql_scaler.go Description The PostgreSQL scaler creates a connection string by formatting the conﬁgured host, port, username, database name, SSL mode, and password with fmt.Sprintf : meta.connection = fmt.Sprintf( "host=%s port=%s user=%s dbname=%s sslmode=%s password=%s" , host, port, userName, dbName, sslmode, password, ) Figure 5.1: pkg/scalers/postgresql_scaler.go#L127-L135 However, none of the parameters included in the format string are escaped before the call to fmt.Sprintf . According to the PostgreSQL documentation , “ To write an empty value, or a value containing spaces, surround it with single quotes, for example keyword = 'a value' . Single quotes and backslashes within a value must be escaped with a backslash, i.e., \' and \\ .” As KEDA does not perform this escaping, the connection string could fail to parse if any of the conﬁguration parameters (e.g., the password) contains symbols with special meaning in PostgreSQL connection strings. Furthermore, this issue may allow the injection of harmful or unintended parameters into the connection string using spaces and equal signs. Although the latter attack violates assumptions about the application’s behavior, it is not a severe issue in KEDA’s case because users can already pass full connection strings via the connectionFromEnv conﬁguration parameter. Exploit Scenario A user conﬁgures the PostgreSQL scaler with a password containing a space. As the PostgreSQL scaler does not escape the password in the connection string, when the client connection is initialized, the string fails to parse, an error is thrown, and the scaler does not function. Recommendations Short term, escape the user-provided PostgreSQL parameters using the method described in the PostgreSQL documentation . Long term, use the custom Semgrep rule provided in Appendix C to detect future instances of this issue. 6. Redis scalers set InsecureSkipVerify when TLS is enabled Severity: High Diﬃculty: High Type: Cryptography Finding ID: TOB-KEDA-6 Target: pkg/scalers/redis_scaler.go Description The Redis Lists scaler (of which most of the code is reused by the Redis Streams scaler) supports the enableTLS option to allow the connection to the Redis server to use Transport Layer Security (TLS). However, when creating the TLSConfig for the Redis client, the scaler assigns the InsecureSkipVerify ﬁeld to the value of enableTLS (Figure 6.1), which means that certiﬁcate and server name veriﬁcation is always disabled when TLS is enabled. This allows trivial MitM attacks, rendering TLS ineﬀective. if info.enableTLS { options.TLSConfig = &tls.Config{ InsecureSkipVerify: info.enableTLS, } } Figure 6.1: KEDA sets InsecureSkipVerify to the value of info.enableTLS , which is always true in the block above. This pattern occurs in three locations: pkg/scalers/redis_scaler.go#L472-L476 , pkg/scalers/redis_scaler.go#L496-L500 , and pkg/scalers/redis_scaler.go#L517-L521 . KEDA does not document this insecure behavior, and users likely expect that enableTLS is implemented securely to prevent MitM attacks. The only public mention of this behavior is a stale, closed issue concerning this problem on GitHub . Exploit Scenario A user deploys KEDA with the Redis Lists or Redis Streams scaler. To protect the conﬁdentiality and integrity of data in transit between KEDA and the Redis server, the user sets the enableTLS metadata ﬁeld to true . Unbeknownst to the user, KEDA has disabled TLS certiﬁcate veriﬁcation, allowing attackers on the network to modify the data in transit. An adversary can then falsify metrics coming from Redis to maliciously inﬂuence the scaling behavior of KEDA and the Kubernetes cluster (e.g., by causing a DoS). Recommendations Short term, add a warning to the public documentation that the enableTLS option, as currently implemented, is not secure. Short term, do not enable InsecureSkipVerify when the user speciﬁes the enableTLS parameter. 7. Insu cient check against nil Severity: Low Diﬃculty: High Type: Data Validation Finding ID: TOB-KEDA-7 Target: pkg/scalers/azure_eventhub_scaler.go#L253-L259 Description Within a function in the scaler for Azure event hubs, the object partitionInfo is dereferenced before correctly checking it against nil . Before the object is used, a check conﬁrms that partitionInfo is not nil . However, this check is insuﬃcient because the function returns if the condition is met, and the function subsequently uses partitionInfo without additional checks against nil . As a result, a panic may occur when partitionInfo is later used in the same function. func (s *azureEventHubScaler) GetUnprocessedEventCountInPartition(ctx context.Context, partitionInfo *eventhub.HubPartitionRuntimeInformation) (newEventCount int64 , checkpoint azure.Checkpoint, err error ) { // if partitionInfo.LastEnqueuedOffset = -1, that means event hub partition is empty if partitionInfo != nil && partitionInfo.LastEnqueuedOffset == "-1" { return 0 , azure.Checkpoint{}, nil } checkpoint, err = azure.GetCheckpointFromBlobStorage(ctx, s.httpClient, s.metadata.eventHubInfo, partitionInfo.PartitionID ) Figure 7.1: partionInfo is dereferenced before a nil check pkg/scalers/azure_eventhub_scaler.go#L253-L259 Exploit Scenario While the Azure event hub performs its usual applications, an application error causes GetUnprocessedEventCountInPartition to be called with a nil partitionInfo parameter. This causes a panic and the scaler to crash and to stop monitoring events. Recommendations Short term, edit the code so that partitionInfo is checked against nil before dereferencing it. Long term, use CodeQL and its go/missing-error-check query to detect future instances of this issue. 8. Prometheus metrics server does not support authentication Severity: Low Diﬃculty: High Type: Authentication Finding ID: TOB-KEDA-8 Target: pkg/prommetrics/adapter_prommetrics.go Description When scraping metrics, Prometheus supports multiple forms of authentication , including Basic authentication, Bearer authentication, and OAuth 2.0. KEDA exposes Prometheus metrics but does not oﬀer the ability to protect its metrics server with any of the supported authentication types. Exploit Scenario A user deploys KEDA on a network. An adversary gains access to the network and is able to issue HTTP requests to KEDA’s Prometheus metrics server. As KEDA does not support authentication for the server, the attacker can trivially view the exposed metrics. Recommendations Short term, implement one or more of the authentication types that Prometheus supports for scrape targets. A. Vulnerability Categories The following tables describe the vulnerability categories, severity levels, and diﬃculty levels used in this document. Vulnerability Categories Category Description Access Controls Insuﬃcient authorization or assessment of rights Auditing and Logging Insuﬃcient auditing of actions or logging of problems Authentication Improper identiﬁcation of users Conﬁguration Misconﬁgured servers, devices, or software components Cryptography A breach of system conﬁdentiality or integrity Data Exposure Exposure of sensitive information Data Validation Improper reliance on the structure or values of data Denial of Service A system failure with an availability impact Error Reporting Insecure or insuﬃcient reporting of error conditions Patching Use of an outdated software package or library Session Management Improper identiﬁcation of authenticated users Testing Timing Insuﬃcient test methodology or test coverage Race conditions or other order-of-operations ﬂaws Undeﬁned Behavior Undeﬁned behavior triggered within the system Severity Levels Severity Description Informational The issue does not pose an immediate risk but is relevant to security best practices. Undetermined The extent of the risk was not determined during this engagement. Low The risk is small or is not one the client has indicated is important. Medium High User information is at risk; exploitation could pose reputational, legal, or moderate ﬁnancial risks. The ﬂaw could aﬀect numerous users and have serious reputational, legal, or ﬁnancial implications. Diﬃculty Levels Diﬃculty Description Undetermined The diﬃculty of exploitation was not determined during this engagement. Low Medium High The ﬂaw is well known; public tools for its exploitation exist or can be scripted. An attacker must write an exploit or will need in-depth knowledge of the system. An attacker must have privileged access to the system, may need to know complex technical details, or must discover other weaknesses to exploit this issue. B. Code Maturity Categories The following tables describe the code maturity categories and rating criteria used in this document. Code Maturity Categories Category Description Arithmetic The proper use of mathematical operations and semantics Auditing The use of event auditing and logging to support monitoring Authentication / Access Controls The use of robust access controls to handle identiﬁcation and authorization and to ensure safe interactions with the system Complexity Management The presence of clear structures designed to manage system complexity, including the separation of system logic into clearly deﬁned functions Conﬁguration The conﬁguration of system components in accordance with best practices Cryptography and Key Management The safe use of cryptographic primitives and functions, along with the presence of robust mechanisms for key generation and distribution Data Handling The safe handling of user inputs and data processed by the system Documentation The presence of comprehensive and readable codebase documentation Maintenance The timely maintenance of system components to mitigate risk Memory Safety and Error Handling The presence of memory safety and robust error-handling mechanisms Testing and Veriﬁcation The presence of robust testing procedures (e.g., unit tests, integration tests, and veriﬁcation methods) and suﬃcient test coverage Rating Criteria Rating Strong Description No issues were found, and the system exceeds industry standards. Satisfactory Minor issues were found, but the system is compliant with best practices. Moderate Some issues that may aﬀect system safety were found. Weak Many issues that aﬀect system safety were found. Missing A required component is missing, signiﬁcantly aﬀecting system safety. Not Applicable The category is not applicable to this review. Not Considered The category was not considered in this review. Further Investigation Required Further investigation is required to reach a meaningful conclusion. C. Connection String Semgrep Rule The Semgrep rule deﬁnition given in ﬁgure C.1 detects the use of database connection strings built with string concatenation or fmt.Sprintf , which may indicate the presence of user input that requires encoding or escaping to prevent parsing failures and parameter injection. rules : - id : db-connection-string patterns : - pattern-either : - pattern : "$CONNSTR = ... + $DBPARAM" - pattern : "$CONNSTR = $DBPARAM + ..." - pattern : $CONNSTR = "..." + $DBPARAM + ... - pattern : "$CONNSTR = fmt.Sprintf(..., $DBPARAM, ...)" - metavariable-regex : metavariable : $CONNSTR regex : (?i).*conn.* - metavariable-regex : metavariable : $DBPARAM regex : (?i).*(auth|addr|host|user|pass|dbname) message : | Semgrep found a possible database connection string built with string concatenation. Check for proper encoding/escaping of components to prevent parse errors and injection vulnerabilities. severity : WARNING languages : - go Figure C.1: Semgrep rule to detect database connection strings built from potentially untrusted input
3. Prometheus metrics server does not support TLS Severity: Low Diﬃculty: Low Type: Cryptography Finding ID: TOB-KEDA-3 Target: pkg/prommetrics/adapter_prommetrics.go Description The KEDA Metrics Adapter exposes Prometheus metrics on an HTTP server listening on port 9022. Though Prometheus supports scraping metrics over TLS-enabled connections, KEDA does not oﬀer TLS for this server. The function responsible for starting the HTTP server, prommetrics.NewServer , does so using the http.ListenAndServe function, which does not enable TLS. func (metricsServer PrometheusMetricServer) NewServer(address string , pattern string ) { http.HandleFunc( "/healthz" , func (w http.ResponseWriter, _ *http.Request) { w.WriteHeader(http.StatusOK) _, err := w.Write([] byte ( "OK" )) if err != nil { log.Fatalf( "Unable to write to serve custom metrics: %v" , err) } }) log.Printf( "Starting metrics server at %v" , address) http.Handle(pattern, promhttp.HandlerFor(registry, promhttp.HandlerOpts{})) // initialize the total error metric _, errscaler := scalerErrorsTotal.GetMetricWith(prometheus.Labels{}) if errscaler != nil { log.Fatalf( "Unable to initialize total error metrics as : %v" , errscaler) } log.Fatal( http.ListenAndServe(address, nil ) ) } Figure 3.1: prommetrics.NewServer exposes Prometheus metrics without TLS ( pkg/prommetrics/adapter_prommetrics.go#L82-L99 ). Exploit Scenario A user sets up KEDA with Prometheus integration, enabling the scraping of metrics on port 9022. When Prometheus makes a connection to the server, it is unencrypted, leaving both the request and response vulnerable to interception and tampering in transit. As KEDA does not support TLS for the server, the user has no way to ensure the conﬁdentiality and integrity of these metrics. Recommendations Short term, provide a ﬂag to enable TLS for Prometheus metrics exposed by the Metrics Adapter. The usual way to enable TLS for an HTTP server is using the http.ListenAndServeTLS function. 
4. Return value is dereferenced before error check Severity: Low Diﬃculty: Undetermined Type: Data Validation Finding ID: TOB-KEDA-4 Target: pkg/scalers/openstack/keystone_authentication.go , pkg/scalers/artemis_scaler.go Description After certain calls to http.NewRequestWithContext , the *Request return value is dereferenced before the error return value is checked (see the highlighted lines in ﬁgures 4.1 and 4.2). checkTokenRequest, err := http.NewRequestWithContext(ctx, "HEAD" , tokenURL.String(), nil ) checkTokenRequest.Header.Set( "X-Subject-Token" , token) checkTokenRequest.Header.Set( "X-Auth-Token" , token) if err != nil { return false , err } Figure 4.1: pkg/scalers/openstack/keystone_authentication.go#L118-L124 req, err := http.NewRequestWithContext(ctx, "GET" , url, nil ) req.SetBasicAuth(s.metadata.username, s.metadata.password) req.Header.Set( "Origin" , s.metadata.corsHeader) if err != nil { return - 1 , err } Figure 4.2: pkg/scalers/artemis_scaler.go#L241-L248 If an error occurred in the call to NewRequestWithContext , this behavior could result in a panic due to a nil pointer dereference. Exploit Scenario One of the calls to http.NewRequestWithContext shown in ﬁgures 4.1 and 4.2 returns an error and a nil *Request pointer. The subsequent code dereferences the nil pointer, resulting in a panic, crash, and DoS condition for the aﬀected KEDA scaler. Recommendations Short term, check the error return value before accessing the returned *Request (e.g., by calling methods on it). Long term, use CodeQL and its go/missing-error-check query to detect future instances of this issue. 
5. Unescaped components in PostgreSQL connection string Severity: Low Diﬃculty: Low Type: Data Validation Finding ID: TOB-KEDA-5 Target: pkg/scalers/postgresql_scaler.go Description The PostgreSQL scaler creates a connection string by formatting the conﬁgured host, port, username, database name, SSL mode, and password with fmt.Sprintf : meta.connection = fmt.Sprintf( "host=%s port=%s user=%s dbname=%s sslmode=%s password=%s" , host, port, userName, dbName, sslmode, password, ) Figure 5.1: pkg/scalers/postgresql_scaler.go#L127-L135 However, none of the parameters included in the format string are escaped before the call to fmt.Sprintf . According to the PostgreSQL documentation , “ To write an empty value, or a value containing spaces, surround it with single quotes, for example keyword = 'a value' . Single quotes and backslashes within a value must be escaped with a backslash, i.e., \' and \\ .” As KEDA does not perform this escaping, the connection string could fail to parse if any of the conﬁguration parameters (e.g., the password) contains symbols with special meaning in PostgreSQL connection strings. Furthermore, this issue may allow the injection of harmful or unintended parameters into the connection string using spaces and equal signs. Although the latter attack violates assumptions about the application’s behavior, it is not a severe issue in KEDA’s case because users can already pass full connection strings via the connectionFromEnv conﬁguration parameter. Exploit Scenario A user conﬁgures the PostgreSQL scaler with a password containing a space. As the PostgreSQL scaler does not escape the password in the connection string, when the client connection is initialized, the string fails to parse, an error is thrown, and the scaler does not function. Recommendations Short term, escape the user-provided PostgreSQL parameters using the method described in the PostgreSQL documentation . Long term, use the custom Semgrep rule provided in Appendix C to detect future instances of this issue. 
6. Redis scalers set InsecureSkipVerify when TLS is enabled Severity: High Diﬃculty: High Type: Cryptography Finding ID: TOB-KEDA-6 Target: pkg/scalers/redis_scaler.go Description The Redis Lists scaler (of which most of the code is reused by the Redis Streams scaler) supports the enableTLS option to allow the connection to the Redis server to use Transport Layer Security (TLS). However, when creating the TLSConfig for the Redis client, the scaler assigns the InsecureSkipVerify ﬁeld to the value of enableTLS (Figure 6.1), which means that certiﬁcate and server name veriﬁcation is always disabled when TLS is enabled. This allows trivial MitM attacks, rendering TLS ineﬀective. if info.enableTLS { options.TLSConfig = &tls.Config{ InsecureSkipVerify: info.enableTLS, } } Figure 6.1: KEDA sets InsecureSkipVerify to the value of info.enableTLS , which is always true in the block above. This pattern occurs in three locations: pkg/scalers/redis_scaler.go#L472-L476 , pkg/scalers/redis_scaler.go#L496-L500 , and pkg/scalers/redis_scaler.go#L517-L521 . KEDA does not document this insecure behavior, and users likely expect that enableTLS is implemented securely to prevent MitM attacks. The only public mention of this behavior is a stale, closed issue concerning this problem on GitHub . Exploit Scenario A user deploys KEDA with the Redis Lists or Redis Streams scaler. To protect the conﬁdentiality and integrity of data in transit between KEDA and the Redis server, the user sets the enableTLS metadata ﬁeld to true . Unbeknownst to the user, KEDA has disabled TLS certiﬁcate veriﬁcation, allowing attackers on the network to modify the data in transit. An adversary can then falsify metrics coming from Redis to maliciously inﬂuence the scaling behavior of KEDA and the Kubernetes cluster (e.g., by causing a DoS). Recommendations Short term, add a warning to the public documentation that the enableTLS option, as currently implemented, is not secure. Short term, do not enable InsecureSkipVerify when the user speciﬁes the enableTLS parameter. 7. Insu cient check against nil Severity: Low Diﬃculty: High Type: Data Validation Finding ID: TOB-KEDA-7 Target: pkg/scalers/azure_eventhub_scaler.go#L253-L259 Description Within a function in the scaler for Azure event hubs, the object partitionInfo is dereferenced before correctly checking it against nil . Before the object is used, a check conﬁrms that partitionInfo is not nil . However, this check is insuﬃcient because the function returns if the condition is met, and the function subsequently uses partitionInfo without additional checks against nil . As a result, a panic may occur when partitionInfo is later used in the same function. func (s *azureEventHubScaler) GetUnprocessedEventCountInPartition(ctx context.Context, partitionInfo *eventhub.HubPartitionRuntimeInformation) (newEventCount int64 , checkpoint azure.Checkpoint, err error ) { // if partitionInfo.LastEnqueuedOffset = -1, that means event hub partition is empty if partitionInfo != nil && partitionInfo.LastEnqueuedOffset == "-1" { return 0 , azure.Checkpoint{}, nil } checkpoint, err = azure.GetCheckpointFromBlobStorage(ctx, s.httpClient, s.metadata.eventHubInfo, partitionInfo.PartitionID ) Figure 7.1: partionInfo is dereferenced before a nil check pkg/scalers/azure_eventhub_scaler.go#L253-L259 Exploit Scenario While the Azure event hub performs its usual applications, an application error causes GetUnprocessedEventCountInPartition to be called with a nil partitionInfo parameter. This causes a panic and the scaler to crash and to stop monitoring events. Recommendations Short term, edit the code so that partitionInfo is checked against nil before dereferencing it. Long term, use CodeQL and its go/missing-error-check query to detect future instances of this issue. 8. Prometheus metrics server does not support authentication Severity: Low Diﬃculty: High Type: Authentication Finding ID: TOB-KEDA-8 Target: pkg/prommetrics/adapter_prommetrics.go Description When scraping metrics, Prometheus supports multiple forms of authentication , including Basic authentication, Bearer authentication, and OAuth 2.0. KEDA exposes Prometheus metrics but does not oﬀer the ability to protect its metrics server with any of the supported authentication types. Exploit Scenario A user deploys KEDA on a network. An adversary gains access to the network and is able to issue HTTP requests to KEDA’s Prometheus metrics server. As KEDA does not support authentication for the server, the attacker can trivially view the exposed metrics. Recommendations Short term, implement one or more of the authentication types that Prometheus supports for scrape targets. A. Vulnerability Categories The following tables describe the vulnerability categories, severity levels, and diﬃculty levels used in this document. Vulnerability Categories Category Description Access Controls Insuﬃcient authorization or assessment of rights Auditing and Logging Insuﬃcient auditing of actions or logging of problems Authentication Improper identiﬁcation of users Conﬁguration Misconﬁgured servers, devices, or software components Cryptography A breach of system conﬁdentiality or integrity Data Exposure Exposure of sensitive information Data Validation Improper reliance on the structure or values of data Denial of Service A system failure with an availability impact Error Reporting Insecure or insuﬃcient reporting of error conditions Patching Use of an outdated software package or library Session Management Improper identiﬁcation of authenticated users Testing Timing Insuﬃcient test methodology or test coverage Race conditions or other order-of-operations ﬂaws Undeﬁned Behavior Undeﬁned behavior triggered within the system Severity Levels Severity Description Informational The issue does not pose an immediate risk but is relevant to security best practices. Undetermined The extent of the risk was not determined during this engagement. Low The risk is small or is not one the client has indicated is important. Medium High User information is at risk; exploitation could pose reputational, legal, or moderate ﬁnancial risks. The ﬂaw could aﬀect numerous users and have serious reputational, legal, or ﬁnancial implications. Diﬃculty Levels Diﬃculty Description Undetermined The diﬃculty of exploitation was not determined during this engagement. Low Medium High The ﬂaw is well known; public tools for its exploitation exist or can be scripted. An attacker must write an exploit or will need in-depth knowledge of the system. An attacker must have privileged access to the system, may need to know complex technical details, or must discover other weaknesses to exploit this issue. B. Code Maturity Categories The following tables describe the code maturity categories and rating criteria used in this document. Code Maturity Categories Category Description Arithmetic The proper use of mathematical operations and semantics Auditing The use of event auditing and logging to support monitoring Authentication / Access Controls The use of robust access controls to handle identiﬁcation and authorization and to ensure safe interactions with the system Complexity Management The presence of clear structures designed to manage system complexity, including the separation of system logic into clearly deﬁned functions Conﬁguration The conﬁguration of system components in accordance with best practices Cryptography and Key Management The safe use of cryptographic primitives and functions, along with the presence of robust mechanisms for key generation and distribution Data Handling The safe handling of user inputs and data processed by the system Documentation The presence of comprehensive and readable codebase documentation Maintenance The timely maintenance of system components to mitigate risk Memory Safety and Error Handling The presence of memory safety and robust error-handling mechanisms Testing and Veriﬁcation The presence of robust testing procedures (e.g., unit tests, integration tests, and veriﬁcation methods) and suﬃcient test coverage Rating Criteria Rating Strong Description No issues were found, and the system exceeds industry standards. Satisfactory Minor issues were found, but the system is compliant with best practices. Moderate Some issues that may aﬀect system safety were found. Weak Many issues that aﬀect system safety were found. Missing A required component is missing, signiﬁcantly aﬀecting system safety. Not Applicable The category is not applicable to this review. Not Considered The category was not considered in this review. Further Investigation Required Further investigation is required to reach a meaningful conclusion. C. Connection String Semgrep Rule The Semgrep rule deﬁnition given in ﬁgure C.1 detects the use of database connection strings built with string concatenation or fmt.Sprintf , which may indicate the presence of user input that requires encoding or escaping to prevent parsing failures and parameter injection. rules : - id : db-connection-string patterns : - pattern-either : - pattern : "$CONNSTR = ... + $DBPARAM" - pattern : "$CONNSTR = $DBPARAM + ..." - pattern : $CONNSTR = "..." + $DBPARAM + ... - pattern : "$CONNSTR = fmt.Sprintf(..., $DBPARAM, ...)" - metavariable-regex : metavariable : $CONNSTR regex : (?i).*conn.* - metavariable-regex : metavariable : $DBPARAM regex : (?i).*(auth|addr|host|user|pass|dbname) message : | Semgrep found a possible database connection string built with string concatenation. Check for proper encoding/escaping of components to prevent parse errors and injection vulnerabilities. severity : WARNING languages : - go Figure C.1: Semgrep rule to detect database connection strings built from potentially untrusted input
1. Use of fmt.Sprintf to build host:port string Severity: Informational Diﬃculty: Medium Type: Data Validation Finding ID: TOB-KEDA-1 Targets: ● pkg/scalers/cassandra_scaler.go ● pkg/scalers/mongo_scaler.go ● pkg/scalers/mssql_scaler.go ● pkg/scalers/mysql_scaler.go ● pkg/scalers/predictkube_scaler.go ● pkg/scalers/redis_scaler.go Description Several scalers use a construct like fmt.Sprintf("%s:%s", host, port) to create a host:port address string from a user-supplied host and port. This approach is problematic when the host is a literal IPv6 address, which should be enclosed in square brackets when the address is part of a resource identiﬁer. An address created using simple string concatenation, such as with fmt.Sprintf , may fail to parse when given to Go standard library functions. The following source ﬁles incorrectly use fmt.Sprintf to create an address: ● pkg/scalers/cassandra_scaler.go:115 ● pkg/scalers/mongo_scaler.go:191 ● pkg/scalers/mssql_scaler.go:220 ● pkg/scalers/mysql_scaler.go:149 ● pkg/scalers/predictkube_scaler.go:128 ● pkg/scalers/redis_scaler.go:296 ● pkg/scalers/redis_scaler.go:364 Recommendations Short term, use net.JoinHostPort instead of fmt.Sprintf to construct network addresses. The documentation for the net package states the following: JoinHostPort combines host and port into a network address of the form host:port . If host contains a colon, as found in literal IPv6 addresses, then JoinHostPort returns [host]:port . Long term, use Semgrep and the sprintf-host-port rule of semgrep-go to detect future instances of this issue. 
2. MongoDB scaler does not encode username and password in connection string Severity: Low Diﬃculty: Low Type: Data Validation Finding ID: TOB-KEDA-2 Target: pkg/scalers/mongo_scaler.go Description The MongoDB scaler creates a connection string URI by concatenating the conﬁgured host, port, username, and password: addr := fmt.Sprintf( "%s:%s" , meta.host, meta.port) auth := fmt.Sprintf( "%s:%s" , meta.username, meta.password) connStr = "mongodb://" + auth + "@" + addr + "/" + meta.dbName Figure 2.1: pkg/scalers/mongo_scaler.go#L191-L193 Per MongoDB documentation, if either the username or password contains a character in the set :/?#[]@ , it must be percent-encoded . However, KEDA does not do this. As a result, the constructed connection string could fail to parse. Exploit Scenario A user conﬁgures the MongoDB scaler with a password containing an ‘ @ ’ character, and the MongoDB scaler does not encode the password in the connection string. As a result, when the client object is initialized, the URL fails to parse, an error is thrown, and the scaler does not function. Recommendations Short term, percent-encode the user-supplied username and password before constructing the connection string. Long term, use the custom Semgrep rule provided in Appendix C to detect future instances of this issue. 
3. Prometheus metrics server does not support TLS Severity: Low Diﬃculty: Low Type: Cryptography Finding ID: TOB-KEDA-3 Target: pkg/prommetrics/adapter_prommetrics.go Description The KEDA Metrics Adapter exposes Prometheus metrics on an HTTP server listening on port 9022. Though Prometheus supports scraping metrics over TLS-enabled connections, KEDA does not oﬀer TLS for this server. The function responsible for starting the HTTP server, prommetrics.NewServer , does so using the http.ListenAndServe function, which does not enable TLS. func (metricsServer PrometheusMetricServer) NewServer(address string , pattern string ) { http.HandleFunc( "/healthz" , func (w http.ResponseWriter, _ *http.Request) { w.WriteHeader(http.StatusOK) _, err := w.Write([] byte ( "OK" )) if err != nil { log.Fatalf( "Unable to write to serve custom metrics: %v" , err) } }) log.Printf( "Starting metrics server at %v" , address) http.Handle(pattern, promhttp.HandlerFor(registry, promhttp.HandlerOpts{})) // initialize the total error metric _, errscaler := scalerErrorsTotal.GetMetricWith(prometheus.Labels{}) if errscaler != nil { log.Fatalf( "Unable to initialize total error metrics as : %v" , errscaler) } log.Fatal( http.ListenAndServe(address, nil ) ) } Figure 3.1: prommetrics.NewServer exposes Prometheus metrics without TLS ( pkg/prommetrics/adapter_prommetrics.go#L82-L99 ). Exploit Scenario A user sets up KEDA with Prometheus integration, enabling the scraping of metrics on port 
9022. When Prometheus makes a connection to the server, it is unencrypted, leaving both the request and response vulnerable to interception and tampering in transit. As KEDA does not support TLS for the server, the user has no way to ensure the conﬁdentiality and integrity of these metrics. Recommendations Short term, provide a ﬂag to enable TLS for Prometheus metrics exposed by the Metrics Adapter. The usual way to enable TLS for an HTTP server is using the http.ListenAndServeTLS function. 
4. Return value is dereferenced before error check Severity: Low Diﬃculty: Undetermined Type: Data Validation Finding ID: TOB-KEDA-4 Target: pkg/scalers/openstack/keystone_authentication.go , pkg/scalers/artemis_scaler.go Description After certain calls to http.NewRequestWithContext , the *Request return value is dereferenced before the error return value is checked (see the highlighted lines in ﬁgures 4.1 and 4.2). checkTokenRequest, err := http.NewRequestWithContext(ctx, "HEAD" , tokenURL.String(), nil ) checkTokenRequest.Header.Set( "X-Subject-Token" , token) checkTokenRequest.Header.Set( "X-Auth-Token" , token) if err != nil { return false , err } Figure 4.1: pkg/scalers/openstack/keystone_authentication.go#L118-L124 req, err := http.NewRequestWithContext(ctx, "GET" , url, nil ) req.SetBasicAuth(s.metadata.username, s.metadata.password) req.Header.Set( "Origin" , s.metadata.corsHeader) if err != nil { return - 1 , err } Figure 4.2: pkg/scalers/artemis_scaler.go#L241-L248 If an error occurred in the call to NewRequestWithContext , this behavior could result in a panic due to a nil pointer dereference. Exploit Scenario One of the calls to http.NewRequestWithContext shown in ﬁgures 4.1 and 4.2 returns an error and a nil *Request pointer. The subsequent code dereferences the nil pointer, resulting in a panic, crash, and DoS condition for the aﬀected KEDA scaler. Recommendations Short term, check the error return value before accessing the returned *Request (e.g., by calling methods on it). Long term, use CodeQL and its go/missing-error-check query to detect future instances of this issue. 
5. Unescaped components in PostgreSQL connection string Severity: Low Diﬃculty: Low Type: Data Validation Finding ID: TOB-KEDA-5 Target: pkg/scalers/postgresql_scaler.go Description The PostgreSQL scaler creates a connection string by formatting the conﬁgured host, port, username, database name, SSL mode, and password with fmt.Sprintf : meta.connection = fmt.Sprintf( "host=%s port=%s user=%s dbname=%s sslmode=%s password=%s" , host, port, userName, dbName, sslmode, password, ) Figure 5.1: pkg/scalers/postgresql_scaler.go#L127-L135 However, none of the parameters included in the format string are escaped before the call to fmt.Sprintf . According to the PostgreSQL documentation , “ To write an empty value, or a value containing spaces, surround it with single quotes, for example keyword = 'a value' . Single quotes and backslashes within a value must be escaped with a backslash, i.e., \' and \\ .” As KEDA does not perform this escaping, the connection string could fail to parse if any of the conﬁguration parameters (e.g., the password) contains symbols with special meaning in PostgreSQL connection strings. Furthermore, this issue may allow the injection of harmful or unintended parameters into the connection string using spaces and equal signs. Although the latter attack violates assumptions about the application’s behavior, it is not a severe issue in KEDA’s case because users can already pass full connection strings via the connectionFromEnv conﬁguration parameter. Exploit Scenario A user conﬁgures the PostgreSQL scaler with a password containing a space. As the PostgreSQL scaler does not escape the password in the connection string, when the client connection is initialized, the string fails to parse, an error is thrown, and the scaler does not function. Recommendations Short term, escape the user-provided PostgreSQL parameters using the method described in the PostgreSQL documentation . Long term, use the custom Semgrep rule provided in Appendix C to detect future instances of this issue. 
6. Redis scalers set InsecureSkipVerify when TLS is enabled Severity: High Diﬃculty: High Type: Cryptography Finding ID: TOB-KEDA-6 Target: pkg/scalers/redis_scaler.go Description The Redis Lists scaler (of which most of the code is reused by the Redis Streams scaler) supports the enableTLS option to allow the connection to the Redis server to use Transport Layer Security (TLS). However, when creating the TLSConfig for the Redis client, the scaler assigns the InsecureSkipVerify ﬁeld to the value of enableTLS (Figure 6.1), which means that certiﬁcate and server name veriﬁcation is always disabled when TLS is enabled. This allows trivial MitM attacks, rendering TLS ineﬀective. if info.enableTLS { options.TLSConfig = &tls.Config{ InsecureSkipVerify: info.enableTLS, } } Figure 6.1: KEDA sets InsecureSkipVerify to the value of info.enableTLS , which is always true in the block above. This pattern occurs in three locations: pkg/scalers/redis_scaler.go#L472-L476 , pkg/scalers/redis_scaler.go#L496-L500 , and pkg/scalers/redis_scaler.go#L517-L521 . KEDA does not document this insecure behavior, and users likely expect that enableTLS is implemented securely to prevent MitM attacks. The only public mention of this behavior is a stale, closed issue concerning this problem on GitHub . Exploit Scenario A user deploys KEDA with the Redis Lists or Redis Streams scaler. To protect the conﬁdentiality and integrity of data in transit between KEDA and the Redis server, the user sets the enableTLS metadata ﬁeld to true . Unbeknownst to the user, KEDA has disabled TLS certiﬁcate veriﬁcation, allowing attackers on the network to modify the data in transit. An adversary can then falsify metrics coming from Redis to maliciously inﬂuence the scaling behavior of KEDA and the Kubernetes cluster (e.g., by causing a DoS). Recommendations Short term, add a warning to the public documentation that the enableTLS option, as currently implemented, is not secure. Short term, do not enable InsecureSkipVerify when the user speciﬁes the enableTLS parameter. 
7. Insu cient check against nil Severity: Low Diﬃculty: High Type: Data Validation Finding ID: TOB-KEDA-7 Target: pkg/scalers/azure_eventhub_scaler.go#L253-L259 Description Within a function in the scaler for Azure event hubs, the object partitionInfo is dereferenced before correctly checking it against nil . Before the object is used, a check conﬁrms that partitionInfo is not nil . However, this check is insuﬃcient because the function returns if the condition is met, and the function subsequently uses partitionInfo without additional checks against nil . As a result, a panic may occur when partitionInfo is later used in the same function. func (s *azureEventHubScaler) GetUnprocessedEventCountInPartition(ctx context.Context, partitionInfo *eventhub.HubPartitionRuntimeInformation) (newEventCount int64 , checkpoint azure.Checkpoint, err error ) { // if partitionInfo.LastEnqueuedOffset = -1, that means event hub partition is empty if partitionInfo != nil && partitionInfo.LastEnqueuedOffset == "-1" { return 0 , azure.Checkpoint{}, nil } checkpoint, err = azure.GetCheckpointFromBlobStorage(ctx, s.httpClient, s.metadata.eventHubInfo, partitionInfo.PartitionID ) Figure 7.1: partionInfo is dereferenced before a nil check pkg/scalers/azure_eventhub_scaler.go#L253-L259 Exploit Scenario While the Azure event hub performs its usual applications, an application error causes GetUnprocessedEventCountInPartition to be called with a nil partitionInfo parameter. This causes a panic and the scaler to crash and to stop monitoring events. Recommendations Short term, edit the code so that partitionInfo is checked against nil before dereferencing it. Long term, use CodeQL and its go/missing-error-check query to detect future instances of this issue. 
8. Prometheus metrics server does not support authentication Severity: Low Diﬃculty: High Type: Authentication Finding ID: TOB-KEDA-8 Target: pkg/prommetrics/adapter_prommetrics.go Description When scraping metrics, Prometheus supports multiple forms of authentication , including Basic authentication, Bearer authentication, and OAuth 2.0. KEDA exposes Prometheus metrics but does not oﬀer the ability to protect its metrics server with any of the supported authentication types. Exploit Scenario A user deploys KEDA on a network. An adversary gains access to the network and is able to issue HTTP requests to KEDA’s Prometheus metrics server. As KEDA does not support authentication for the server, the attacker can trivially view the exposed metrics. Recommendations Short term, implement one or more of the authentication types that Prometheus supports for scrape targets. A. Vulnerability Categories The following tables describe the vulnerability categories, severity levels, and diﬃculty levels used in this document. Vulnerability Categories Category Description Access Controls Insuﬃcient authorization or assessment of rights Auditing and Logging Insuﬃcient auditing of actions or logging of problems Authentication Improper identiﬁcation of users Conﬁguration Misconﬁgured servers, devices, or software components Cryptography A breach of system conﬁdentiality or integrity Data Exposure Exposure of sensitive information Data Validation Improper reliance on the structure or values of data Denial of Service A system failure with an availability impact Error Reporting Insecure or insuﬃcient reporting of error conditions Patching Use of an outdated software package or library Session Management Improper identiﬁcation of authenticated users Testing Timing Insuﬃcient test methodology or test coverage Race conditions or other order-of-operations ﬂaws Undeﬁned Behavior Undeﬁned behavior triggered within the system Severity Levels Severity Description Informational The issue does not pose an immediate risk but is relevant to security best practices. Undetermined The extent of the risk was not determined during this engagement. Low The risk is small or is not one the client has indicated is important. Medium High User information is at risk; exploitation could pose reputational, legal, or moderate ﬁnancial risks. The ﬂaw could aﬀect numerous users and have serious reputational, legal, or ﬁnancial implications. Diﬃculty Levels Diﬃculty Description Undetermined The diﬃculty of exploitation was not determined during this engagement. Low Medium High The ﬂaw is well known; public tools for its exploitation exist or can be scripted. An attacker must write an exploit or will need in-depth knowledge of the system. An attacker must have privileged access to the system, may need to know complex technical details, or must discover other weaknesses to exploit this issue. B. Code Maturity Categories The following tables describe the code maturity categories and rating criteria used in this document. Code Maturity Categories Category Description Arithmetic The proper use of mathematical operations and semantics Auditing The use of event auditing and logging to support monitoring Authentication / Access Controls The use of robust access controls to handle identiﬁcation and authorization and to ensure safe interactions with the system Complexity Management The presence of clear structures designed to manage system complexity, including the separation of system logic into clearly deﬁned functions Conﬁguration The conﬁguration of system components in accordance with best practices Cryptography and Key Management The safe use of cryptographic primitives and functions, along with the presence of robust mechanisms for key generation and distribution Data Handling The safe handling of user inputs and data processed by the system Documentation The presence of comprehensive and readable codebase documentation Maintenance The timely maintenance of system components to mitigate risk Memory Safety and Error Handling The presence of memory safety and robust error-handling mechanisms Testing and Veriﬁcation The presence of robust testing procedures (e.g., unit tests, integration tests, and veriﬁcation methods) and suﬃcient test coverage Rating Criteria Rating Strong Description No issues were found, and the system exceeds industry standards. Satisfactory Minor issues were found, but the system is compliant with best practices. Moderate Some issues that may aﬀect system safety were found. Weak Many issues that aﬀect system safety were found. Missing A required component is missing, signiﬁcantly aﬀecting system safety. Not Applicable The category is not applicable to this review. Not Considered The category was not considered in this review. Further Investigation Required Further investigation is required to reach a meaningful conclusion. C. Connection String Semgrep Rule The Semgrep rule deﬁnition given in ﬁgure C.1 detects the use of database connection strings built with string concatenation or fmt.Sprintf , which may indicate the presence of user input that requires encoding or escaping to prevent parsing failures and parameter injection. rules : - id : db-connection-string patterns : - pattern-either : - pattern : "$CONNSTR = ... + $DBPARAM" - pattern : "$CONNSTR = $DBPARAM + ..." - pattern : $CONNSTR = "..." + $DBPARAM + ... - pattern : "$CONNSTR = fmt.Sprintf(..., $DBPARAM, ...)" - metavariable-regex : metavariable : $CONNSTR regex : (?i).*conn.* - metavariable-regex : metavariable : $DBPARAM regex : (?i).*(auth|addr|host|user|pass|dbname) message : | Semgrep found a possible database connection string built with string concatenation. Check for proper encoding/escaping of components to prevent parse errors and injection vulnerabilities. severity : WARNING languages : - go Figure C.1: Semgrep rule to detect database connection strings built from potentially untrusted input 
